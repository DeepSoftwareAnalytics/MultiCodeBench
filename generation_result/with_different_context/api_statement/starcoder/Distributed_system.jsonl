{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait_time = (self.loop_wait - 2) * 1000\n    return wait_time, self._orig_kazoo_connect(*args)\n\n", "CodeBleu_score": 48.782559605236955}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    start_time = time.time()\n    result = self._orig_kazoo_connect(*args)\n    end_time = time.time()\n    time_elapsed = end_time - start_time\n    wait_time = max(2, self.loop_wait - time_elapsed) * 1000\n    return wait_time, result\n\n", "CodeBleu_score": 49.30095919636856}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    start = time.time()\n    self._orig_kazoo_connect(*args)\n    return max(2, self.loop_wait - (time.time() - start)) * 1000, self._orig_kazoo_connect(*args)\n\n", "CodeBleu_score": 48.07826141510802}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if not isinstance(config, Config):\n        config = Config(config)\n    if self._config.retry_timeout != config.retry_timeout:\n        self.set_retry_timeout(config.retry_timeout)\n    if self._config.loop_wait != config.loop_wait:\n        self.set_loop_wait(config.loop_wait)\n    if self._config.ttl != config.ttl:\n        try:\n            self.set_ttl(config.ttl)\n        except Exception:\n            if self._config.loop_wait != config.loop_wait:\n                self.close()\n            raise\n\n", "CodeBleu_score": 36.849262312140105}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, Config):\n        self.config = config\n    else:\n        self.config = Config(config)\n    self.set_retry_timeout()\n    if self.loop_wait_time != self.config.loop_wait:\n        if self.config.loop_wait > 0:\n            self.set_ttl()\n        else:\n            self.close()\n    else:\n        self.loop_wait_time = self.config.loop_wait\n\n", "CodeBleu_score": 32.26174326842495}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if not isinstance(config, Config):\n        config = Config(config)\n    if self.retry_timeout != config.retry_timeout:\n        self.set_retry_timeout(config.retry_timeout)\n    if self.loop_wait != config.loop_wait:\n        self.loop_wait = config.loop_wait\n        if isinstance(self.handler, PatroniSequentialThreadingHandler):\n            self.set_connect_timeout(config.loop_wait)\n    if self.ttl != config.ttl:\n        try:\n            self.set_ttl(config.ttl)\n        except Exception:\n            if self.loop_wait != config.loop_wait:\n                self.close()\n                raise\n\n", "CodeBleu_score": 36.68931787647219}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    # Check if the path exists\n    if not os.path.exists(path):\n        raise FileNotFoundError(f\"The specified path '{path}' does not exist.\")\n\n    # Load the initialization state\n    init_state = self.get_init_state(path)\n\n    # Load the configuration\n    config = self.get_config(path)\n\n    # Load the timeline history\n    timeline_history = self.get_timeline_history(path)\n\n    # Load the synchronization state\n    sync_state = self.get_sync_state(path)\n\n    # Load the members\n    members = self.load_members(path)\n\n    # Load the leader information\n    leader = self.get_leader(path)\n\n    # Load the cluster status\n    status = self.get_status(path)\n\n    # Load the failover state\n    failover = self.get_failover(path)\n\n    # Load the failsafe configuration\n    failsafe = self.get_failsafe(path)\n\n    # Return the cluster\n    return Cluster(\n        init_state=init_state,\n        config=config,\n        timeline_history=timeline_history,\n        sync_state=sync_state,\n        members=members,\n        leader=leader,\n        status=status,\n        failover=failover,\n        failsafe=failsafe,\n    )\n", "CodeBleu_score": 13.648951940317353}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster()\n    cluster.path = path\n\n    # Check if the cluster is initialized\n    if not os.path.exists(os.path.join(path, \"postmaster.pid\")):\n        cluster.initialized = False\n        return cluster\n\n    # Check if the cluster is running\n    cluster.running = os.path.exists(os.path.join(path, \"postmaster.pid\"))\n\n    # Check if the cluster is in recovery\n    if os.path.exists(os.path.join(path, \"recovery.conf\")):\n        cluster.in_recovery = True\n\n    # Check if the cluster is a standby\n    if os.path.exists(os.path.join(path, \"recovery.done\")):\n        cluster.standby = True\n\n    # Check if the cluster is a read-only replica\n    if os.path.exists(os.path.join(path, \"recovery.conf.backup\")):\n        cluster.read_only = True\n\n    # Load the configuration\n    cluster.config = ClusterConfig.from_node(os.path.join(path, \"postgresql.conf\"))\n\n    # Load the timeline history\n    cluster.timeline_history = TimelineHistory.from_node(\n        os.path.join(path, \"pg_xlog\", \"timeline\")\n    )\n\n    # Load the synchronization state\n    cluster.sync_state = SyncState.from_node(\n        os.path.join(path, \"pg_xlog\", \"pg_current_xlog_location\")\n    )\n\n    # Load the members\n    cluster.load_members()\n\n    # Load the leader\n    cluster.leader = Leader.from_node(\n        os.path.join(path, \"recovery.conf\"), cluster.members\n    )\n\n    # Load the cluster status\n    cluster.status = self.get_status(cluster.members)\n\n    # Load the failover state\n    cluster.failover = Failover.from_node(\n        os.path.join(path, \"recovery.conf\"), cluster.members\n    )\n\n    # Load the failsafe configuration\n    cluster.failsafe_config = FailsafeConfig.from_node(\n        os.path.join(path, \"recovery.conf\")\n    )\n\n    return cluster\n\n", "CodeBleu_score": 17.97789631296257}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    if not os.path.exists(path):\n        raise FileNotFoundError(\"The specified path does not exist.\")\n\n    self.logger.debug(\"Loading PostgreSQL cluster configuration from %s.\", path)\n\n    cluster = Cluster()\n\n    cluster.init = self.get_init(path)\n    cluster.config = self.get_config(path)\n    cluster.history = self.get_history(path)\n    cluster.state = self.get_state(path)\n    cluster.members = self.load_members(path)\n    cluster.leader = self.get_leader(path)\n    cluster.status = self.get_status(path)\n    cluster.failover = self.get_failover(path)\n    cluster.failsafe = self.get_failsafe(path)\n\n    return cluster\n\n", "CodeBleu_score": 11.3224349998386}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.leader_path, self.id.encode(), ephemeral=True, sequence=True)\n        return True\n    except NodeExistsError:\n        logger.info(f\"Another instance has the lock: {self.id}\")\n        return False\n    except Exception as e:\n        if isinstance(e, ZooKeeperError):\n            raise e\n        logger.error(f\"Error while attempting to acquire leader lock: {e}\")\n        return False\n\n", "CodeBleu_score": 40.52730992793371}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.leader_path, ephemeral=True)\n        return True\n    except NoNodeError:\n        self.zk.ensure_path(self.leader_path)\n        return attempt_to_acquire_leader(self)\n    except NodeExistsError:\n        logger.info(\"Another instance has the lock.\")\n        return False\n    except ZooKeeperError:\n        raise\n    except Exception as e:\n        logger.error(\"Failed to acquire the leader lock: %s\", e)\n        raise ZooKeeperError(\"Failed to acquire the leader lock\")\n\n", "CodeBleu_score": 48.72003595629709}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    while True:\n        try:\n            self.zk.create(self.leader_path, ephemeral=True)\n            return True\n        except (ConnectionLoss, SessionExpiredError, OperationTimeoutError, ZooKeeperError):\n            logger.info(\"Failed to acquire leader lock. Retrying...\")\n            time.sleep(1)\n        except NodeExistsError:\n            logger.info(\"Another instance has the leader lock.\")\n            return False\n        except Exception as e:\n            logger.error(f\"Unexpected exception: {e}\")\n            raise e\n\n", "CodeBleu_score": 47.53674802300729}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    # Check if the current client ID matches the leader's session.\n    if self.client_id != leader.session_id:\n        # If there is a mismatch, log a warning and attempt to delete the existing leader ZNode.\n        logger.warning(\n            \"The current client ID does not match the leader's session. Deleting the leader ZNode.\"\n        )\n        try:\n            self.delete(leader.path)\n        except NoNodeError:\n            logger.warning(\"The leader ZNode does not exist. Continuing.\")\n        except (ConnectionClosedError, RetryFailedError) as e:\n            logger.error(\n                \"Failed to delete the leader ZNode. Retrying the operation. Error: %s\", e\n            )\n            return False\n        # In case of errors such as `NoNodeError`, `ConnectionClosedError`, or `RetryFailedError`, it handles them appropriately, either by ignoring or raising a `ZooKeeperError`.\n    # If deletion is successful, it tries to create a new leader ZNode with the current client's name encoded in UTF-8.\n    try:\n        self.create(leader.path, self.client_id.encode(\"utf-8\"))\n    except NodeExistsError:\n        logger.warning(\"The leader ZNode already exists. Continuing.\")\n    except (ConnectionClosedError, RetryFailedError) as e:\n        logger.error(\n            \"Failed to create the leader ZNode. Retrying the operation. Error: %s\", e\n        )\n        return False\n    # Any errors during creation are logged, and the function returns `False`.\n    except Exception as e:\n        logger.error(\"Failed to create the leader ZNode. Error: %s\", e)\n        return False\n    # If everything succeeds, it returns `True`.\n    return True\n\n", "CodeBleu_score": 50.077529524740605}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.client_id != self.client_id:\n        logger.warning(\n            \"The current client ID does not match the leader's client ID. \"\n            \"Attempting to delete the leader ZNode.\"\n        )\n        try:\n            self.delete(leader.path)\n        except NoNodeError:\n            logger.warning(\n                \"The leader ZNode does not exist. Creating a new leader ZNode.\"\n            )\n        except (ConnectionClosedError, RetryFailedError) as e:\n            logger.error(\n                \"Failed to delete the leader ZNode. Error: %s. \"\n                \"Attempting to create a new leader ZNode.\",\n                e,\n            )\n            return False\n        else:\n            logger.warning(\n                \"The leader ZNode was successfully deleted. \"\n                \"Creating a new leader ZNode.\"\n            )\n    try:\n        self.create(leader.path, value=self.client_id.encode(\"utf-8\"))\n    except NodeExistsError:\n        logger.warning(\n            \"The leader ZNode already exists. \"\n            \"Updating the leader ZNode with the current client ID.\"\n        )\n        try:\n            self.set_data(leader.path, value=self.client_id.encode(\"utf-8\"))\n        except NoNodeError:\n            logger.warning(\n                \"The leader ZNode does not exist. Creating a new leader ZNode.\"\n            )\n        except (ConnectionClosedError, RetryFailedError) as e:\n            logger.error(\n                \"Failed to update the leader ZNode. Error: %s. \"\n                \"Attempting to create a new leader ZNode.\",\n                e,\n            )\n            return False\n    except (ConnectionClosedError, RetryFailedError) as e:\n        logger.error(\n            \"Failed to create the leader ZNode. Error: %s. \"\n            \"Attempting to create a new leader ZNode.\",\n            e,\n        )\n        return False\n    else:\n        logger.warning(\n            \"The leader ZNode was successfully created or updated. \"\n            \"Updating the leader object with the current client ID.\"\n        )\n        leader.client_id = self.client_id\n        return True\n\n", "CodeBleu_score": 45.227678338490485}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.client_id != self.client_id:\n        logger.warning(f\"The leader's client ID ({leader.client_id}) does not match the current client ID ({self.client_id}). Deleting the leader ZNode...\")\n        try:\n            self.delete(self.leader_path)\n        except NoNodeError:\n            logger.warning(\"The leader ZNode does not exist.\")\n        except ConnectionClosedError:\n            logger.error(\"The connection to ZooKeeper was closed.\")\n            raise\n        except RetryFailedError:\n            logger.error(\"The operation to ZooKeeper failed due to retry failures.\")\n            raise\n        except ZooKeeperError:\n            logger.error(\"An unexpected error occurred while deleting the leader ZNode.\")\n            raise\n\n    logger.info(f\"Creating a new leader ZNode with the current client ID ({self.client_id})...\")\n    try:\n        self.create(self.leader_path, str.encode(self.client_id))\n    except NodeExistsError:\n        logger.warning(\"The leader ZNode already exists.\")\n    except ConnectionClosedError:\n        logger.error(\"The connection to ZooKeeper was closed.\")\n        raise\n    except RetryFailedError:\n        logger.error(\"The operation to ZooKeeper failed due to retry failures.\")\n        raise\n    except ZooKeeperError:\n        logger.error(\"An unexpected error occurred while creating the leader ZNode.\")\n        raise\n\n    return True\n", "CodeBleu_score": 35.41910901317999}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    if self._last_poll is None:\n        self._last_poll = time.time()\n\n    if self._last_poll + self._poll_interval > time.time():\n        return False\n\n    self._last_poll = time.time()\n\n    try:\n        exhibitors = self._query_exhibitors()\n    except Exception as e:\n        logger.info(\"Error querying exhibitors: %s\", e)\n        return False\n\n    if not exhibitors:\n        return False\n\n    if self._exhibitors != exhibitors:\n        self._exhibitors = exhibitors\n        self._update_zookeeper_connection_string()\n        return True\n\n    return False\n\n", "CodeBleu_score": 29.10898636764739}, {"code": "def poll(self) -> bool\n\t\n    if not self._should_poll():\n        return False\n    try:\n        self._query_exhibitors()\n    except Exception:\n        logger.exception(\"Error querying exhibitors\")\n        return False\n    if self._has_changed():\n        self._update_zookeeper_connection_string()\n        return True\n    return False\n\n", "CodeBleu_score": 15.605741139314638}, {"code": "def poll(self) -> bool\n\t\n    if time.time() - self._last_poll_time > self._poll_interval:\n        self._last_poll_time = time.time()\n        try:\n            self._query_exhibitors()\n            if self._exhibitors:\n                self._update_zookeeper_connection_string()\n                return True\n        except Exception as e:\n            logger.info(\"Exception while polling exhibitors: %s\", e)\n    return False\n\n", "CodeBleu_score": 20.19296716925817}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self.ensemble_provider is not None:\n        self.ensemble_provider.update_client(self)\n    return super()._load_cluster(path, loader)\n", "CodeBleu_score": 58.946529653495425}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    # Load the cluster configuration\n    cluster = loader(path)\n\n    # If the ensemble provider is available, update the client's hosts with the Zookeeper hosts\n    if self._ensemble_provider is not None:\n        self._ensemble_provider.update_hosts(cluster)\n\n    # Invoke the parent class's _load_cluster method\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 59.41300566584925}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self.ensemble_provider is not None:\n        self.ensemble_provider.update_client(self)\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 58.946529653495425}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = getGroup();\n\tString dataId = getDataId();\n\tif (StringUtils.isEmpty(group) || StringUtils.isEmpty(dataId)) {\n\t\treturn;\n\t}\n\tlogUnsubscribeStarted(group, dataId);\n\ttry {\n\t\tzookeeperListener.unsubscribe(group, dataId);\n\t} catch (Exception e) {\n\t\tlogUnsubscribeFailed(group, dataId, e);\n\t}\n}", "CodeBleu_score": 73.22173392301022}, {"code": "public void destroy(){\n\tif (zookeeperListener == null) {\nreturn;\n}\nString group = getGroup();\nString dataId = getDataId();\nif (group == null || dataId == null) {\nlog.warn(\"The group or dataId is null, so the unsubscribe process cannot be started.\");\nreturn;\n}\ntry {\nlogUnsubscribeStarted(group, dataId);\nzookeeperListener.unsubscribe(group, dataId);\n} catch (Exception e) {\nlogUnsubscribeFailed(group, dataId, e);\n}\n}", "CodeBleu_score": 70.99395290123755}, {"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = getGroup();\n\tString dataId = getDataId();\n\tif (StringUtils.isBlank(group) || StringUtils.isBlank(dataId)) {\n\t\tlogger.error(\"Failed to unsubscribe from Zookeeper, group or dataId is empty.\");\n\t\treturn;\n\t}\n\ttry {\n\t\tlogger.info(\"Unsubscribing from the Zookeeper configuration, group: \" + group + \", dataId: \" + dataId);\n\t\tzookeeperListener.unsubscribe(group, dataId);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Failed to unsubscribe from Zookeeper, group: \" + group + \", dataId: \" + dataId, e);\n\t}\n}", "CodeBleu_score": 67.13001182013315}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getPayload().getMetadata();\n\t} else {\n\t\treturn new HashMap<String, String>();\n\t}\n}", "CodeBleu_score": 37.42210315805}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tMap<String, String> metadata = new HashMap<String, String>();\n\tif (server instanceof ZookeeperServer) {\n\t\tmetadata = ((ZookeeperServer) server).getPayload().getMetadata();\n\t}\n\treturn metadata;\n}", "CodeBleu_score": 48.06473123211482}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getPayload().getMetadata();\n\t} else {\n\t\treturn new HashMap<String, String>();\n\t}\n}", "CodeBleu_score": 37.42210315805}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = ZookeeperPathConstants.CONFIG_PATH + \"/\" + group + \"/\" + serviceId;\n\tNodeCache nodeCache = new NodeCache(client, path);\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener(zookeeperSubscribeCallback);\n\tnodeCache.getListenable().addListener(nodeCacheListener);\n\tnodeCache.start();\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n\tclient.subscribeStateChanges(zookeeperListener);\n\treturn zookeeperListener;\n}", "CodeBleu_score": 47.27371986125506}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = getPath(group, serviceId);\n\tNodeCache nodeCache = NodeCache.newBuilder().setPath(path).build();\n\tnodeCache.getListenable().addListener(new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tbyte[] data = nodeCache.getCurrentData().getData();\n\t\t\tString config = new String(data, StandardCharsets.UTF_8);\n\t\t\tConfig updatedConfig = convertConfig(config);\n\t\t\tzookeeperSubscribeCallback.configChanged(updatedConfig);\n\t\t}\n\t});\n\tnodeCache.start();\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache);\n\tzookeeperListener.addListener(zookeeperSubscribeCallback);\n\tzookeeperListener.connect();\n\treturn zookeeperListener;\n}", "CodeBleu_score": 62.64404404833825}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = buildConfigPath(group, serviceId);\n\tNodeCache nodeCache = new NodeCache(curatorFramework, path);\n\tnodeCache.getListenable().addListener(new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tbyte[] data = nodeCache.getCurrentData().getData();\n\t\t\tif (data != null) {\n\t\t\t\tString config = new String(data, \"UTF-8\");\n\t\t\t\tcallback.configChanged(config);\n\t\t\t}\n\t\t}\n\t});\n\tnodeCache.start();\n\tZookeeperListener listener = new ZookeeperListener(nodeCache, zookeeperSubscribeCallback);\n\tcuratorFramework.getCuratorListenable().addListener(listener);\n\treturn listener;\n}", "CodeBleu_score": 62.147288658587385}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\treturn new ZookeeperServerList(config, serviceDiscovery);\n}", "CodeBleu_score": 16.401172213609332}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tZookeeperServerList serverList = new ZookeeperServerList(serviceDiscovery);\n\tserverList.initWithNiwsConfig(config);\n\tserverList.setLoadBalanceListenerExecutor(config.getExecutor());\n\tString clientName = config.getClientName();\n\tif (StringUtils.hasText(clientName)) {\n\t\tserverList.setServiceId(clientName);\n\t}\n\treturn serverList;\n}", "CodeBleu_score": 56.23219776047086}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tZookeeperServerList serverList = new ZookeeperServerList(serviceDiscovery);\n\tserverList.initWithNiwsConfig(config);\n\tserverList.setLoadBalanceListenerExecutor(config.get(CommonClientConfigKey.NFLoadBalancerPingInterval, 10), TimeUnit.SECONDS);\n\tserverList.setServiceId(config.getClientName());\n\treturn serverList;\n}", "CodeBleu_score": 65.13232340632389}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor listener = (RegisterListenerExecutor) applicationContext.getBean(\"registerListenerExecutor\");\nlistener.onRegister(registration);\n} catch (BeansException e) {\nlogger.debug(\"No register listener found, continuing with registration\", e);\n}\nserviceRegistry.register(registration);\n}", "CodeBleu_score": 62.95788778346034}, {"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor listenerExecutor = getBean(RegisterListenerExecutor.class);\n\t\tif (listenerExecutor != null) {\n\t\t\tlistenerExecutor.onRegister(registration);\n\t\t}\n\t}\n\tcatch (BeansException be) {\n\t\tlogger.warn(\"Failed to execute onRegister method on RegisterListenerExecutor\", be);\n\t}\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 50.563152391046216}, {"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor listener = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tlistener.onRegister(registration);\n\t} catch (BeansException e) {\n\t\t// ignore\n\t}\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 75.25304114556087}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor listenerExecutor = getBean(RegisterListenerExecutor.class);\n\t\tlistenerExecutor.onDeregister(registration);\n\t} catch (BeansException e) {\n\t\tlogger.error(\"Error executing onDeregister method on RegisterListenerExecutor\", e);\n\t}\n\tserviceRegistry.remove(registration);\n}", "CodeBleu_score": 55.568785161169764}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor listener = getBean(RegisterListenerExecutor.class);\n\t\tif (listener != null) {\n\t\t\tlistener.onDeregister(registration);\n\t\t}\n\t} catch (BeansException e) {\n\t\tlog.warn(\"Error while deregistering\", e);\n\t}\n\tserviceRegistry.remove(registration);\n}", "CodeBleu_score": 54.84660871783019}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor listener = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tlistener.onDeregister(registration);\n\t}\n\tcatch (BeansException e) {\n\t\tlog.debug(\"No RegisterListenerExecutor bean found in the application context\");\n\t}\n\tserviceRegistry.remove(registration);\n}", "CodeBleu_score": 63.92120793007058}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor listenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tlistenerExecutor.onClose();\n\t}\n\tcatch (BeansException ex) {\n\t\tlogger.debug(\"Failed to close RegisterListenerExecutor\", ex);\n\t}\n\tserviceRegistry.close();\n}", "CodeBleu_score": 69.06780387044229}, {"code": "public void close(){\n\t\ttry {\n\t\tif (this.registerListenerExecutor != null) {\n\t\t\tthis.registerListenerExecutor.onClose();\n\t\t}\n\t}\n\tcatch (BeansException ex) {\n\t\tlogger.warn(\"Failed to call onClose on RegisterListenerExecutor\", ex);\n\t}\n\tfinally {\n\t\tthis.serviceRegistry.close();\n\t}\n}", "CodeBleu_score": 26.774432968424723}, {"code": "public void close(){\n\t\ttry {\n\t\t// 1.\u4ece\u5e94\u7528\u4e0a\u4e0b\u6587\u4e2d\u83b7\u53d6RegisterListenerExecutor bean\n\t\tRegisterListenerExecutor executor = this.applicationContext.getBean(RegisterListenerExecutor.class);\n\t\t// 2.\u8c03\u7528RegisterListenerExecutor\u7684onClose()\u65b9\u6cd5\n\t\texecutor.onClose();\n\t}\n\tcatch (BeansException ex) {\n\t\tlogger.debug(\"Failed to close RegisterListenerExecutor\", ex);\n\t}\n\tfinally {\n\t\t// 3.\u8c03\u7528ServiceRegistry\u7684close()\u65b9\u6cd5\n\t\tthis.serviceRegistry.close();\n\t}\n}", "CodeBleu_score": 52.19928429990941}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = null;\n\tString dataId = null;\n\ttry {\n\t\tgroup = config.getGroup();\n\t\tdataId = config.getDataId();\n\t} catch (Exception e) {\n\t\tlogger.error(\"Failed to get group or dataId from config\", e);\n\t\treturn null;\n\t}\n\tlogger.info(\"Subscribe config, group:\" + group + \", dataId:\" + dataId + \", global:\" + globalConfig);\n\ttry {\n\t\treturn zookeeperOperation.subscribeConfig(group, dataId, globalConfig, new ConfigCallback());\n\t} catch (Exception e) {\n\t\tlogger.error(\"Failed to subscribe config, group:\" + group + \", dataId:\" + dataId + \", global:\" + globalConfig, e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 38.08356288554634}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = globalConfig ? GLOBAL_GROUP : config.getGroup();\n\tString dataId = globalConfig ? GLOBAL_DATA_ID : config.getDataId();\n\tLOGGER.info(\"Subscribe config, group: {}, dataId: {}\", group, dataId);\n\ttry {\n\t\treturn zookeeperOperation.subscribeData(group, dataId, new ConfigListener());\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"Subscribe config failed, group: {}, dataId: {}\", group, dataId, e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 35.57341251306096}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = globalConfig ? GLOBAL_CONFIG_GROUP : group;\n\tString dataId = globalConfig ? GLOBAL_CONFIG_DATA_ID : dataId;\n\tLOGGER.info(\"Subscribe to config, group: {}, dataId: {}\", group, dataId);\n\tZookeeperListener listener = new ZookeeperListener() {\n\t\t@Override\n\t\tpublic void handleDataChange(String dataId, Object data) {\n\t\t\tLOGGER.info(\"Config data change, dataId: {}, data: {}\", dataId, data);\n\t\t\ttry {\n\t\t\t\t// TODO: 2018/10/12 \u8fd9\u91cc\u9700\u8981\u505a\u4e00\u4e2a\u914d\u7f6e\u7684\u66f4\u65b0\uff0c\u7136\u540e\u91cd\u65b0\u542f\u52a8\u4e00\u4e0b\uff0c\u7136\u540e\u91cd\u65b0\u8ba2\u9605\u914d\u7f6e\n\t\t\t\t// TODO: 2018/10/12 \u8fd9\u91cc\u9700\u8981\u505a\u4e00\u4e2a\u914d\u7f6e\u7684\u66f4\u65b0\uff0c\u7136\u540e\u91cd\u65b0\u542f\u52a8\u4e00\u4e0b\uff0c\u7136\u540e\u91cd\u65b0\u8ba2\u9605\u914d\u7f6e\n\t\t\t\t// TODO: 2018/10/12 \u8fd9\u91cc\u9700\u8981\u505a\u4e00\u4e2a\u914d\u7f6e\u7684\u66f4\u65b0\uff0c\u7136\u540e\u91cd\u65b0\u542f\u52a8\u4e00\u4e0b\uff0c\u7136\u540e\u91cd\u65b0\u8ba2\u9605\u914d\u7f6e\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOGGER.error(\"Failed to update config\", e);\n\t\t\t}\n\t\t}\n\n\t\t@Override\n\t\tpublic void handleDataDeleted(String dataId) {\n\t\t\tLOGGER.info(\"Config data deleted, dataId: {}\", dataId);\n\t\t}\n\t};\n\ttry {\n\t\treturn zookeeperOperation.subscribeConfig(group, dataId, listener);\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"Failed to subscribe config, group: {}, dataId: {}\", group, dataId, e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 39.15938055443045}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\tString connectionString = System.getenv(\"ZOOKEEPER_CONNECTION_STRING\");\nif (StringUtils.isEmpty(connectionString)) {\nthrow new DiscoveryException(\"Zookeeper connection string not found\");\n}\nint retryCount = Integer.parseInt(System.getenv(\"ZOOKEEPER_RETRY_COUNT\"));\nint sleepTime = Integer.parseInt(System.getenv(\"ZOOKEEPER_SLEEP_TIME\"));\nExponentialBackoffRetry retryPolicy = new ExponentialBackoffRetry(sleepTime, retryCount);\nCuratorFramework curatorFramework = CuratorFrameworkFactory.builder().connectString(connectionString).retryPolicy(retryPolicy).build();\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 43.51005183219871}, {"code": "public CuratorFramework curatorFramework(){\n\t\tString connectionString = System.getenv(\"ZOOKEEPER_CONNECTION_STRING\");\n\tif (connectionString == null || connectionString.isEmpty()) {\n\t\tthrow new DiscoveryException(\"Zookeeper connection string is empty\");\n\t}\n\tint retryCount = Integer.parseInt(System.getenv(\"ZOOKEEPER_RETRY_COUNT\"));\n\tint sleepTime = Integer.parseInt(System.getenv(\"ZOOKEEPER_SLEEP_TIME\"));\n\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(sleepTime, retryCount);\n\tCuratorFrameworkBuilder builder = CuratorFrameworkFactory.builder();\n\tbuilder.connectString(connectionString);\n\tbuilder.retryPolicy(retryPolicy);\n\tCuratorFramework curatorFramework = builder.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 40.52464134836093}, {"code": "public CuratorFramework curatorFramework(){\n\tString connectionString = System.getenv(\"ZOOKEEPER_CONNECTION_STRING\");\nif (connectionString == null || connectionString.isEmpty()) {\nthrow new DiscoveryException(\"Zookeeper connection string is empty\");\n}\n\nint retryCount = Integer.parseInt(System.getenv(\"ZOOKEEPER_RETRY_COUNT\"));\nint sleepTime = Integer.parseInt(System.getenv(\"ZOOKEEPER_SLEEP_TIME\"));\nExponentialBackoffRetry retryPolicy = new ExponentialBackoffRetry(sleepTime, retryCount);\nCuratorFrameworkBuilder builder = CuratorFrameworkFactory.builder().connectString(connectionString).retryPolicy(retryPolicy);\nCuratorFramework curatorFramework = builder.build();\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 44.36436726260952}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n}", "CodeBleu_score": 1.570350114839098}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t@Bean\n\t@ConditionalOnMissingBean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(\n\t\t\tRouteLocator routeLocator, RouteDefinitionLocator routeDefinitionLocator,\n\t\t\tRouteDefinitionWriter routeDefinitionWriter, ZookeeperDiscoveryProperties zookeeperDiscoveryProperties,\n\t\t\tRouteDefinitionRouteLocator routeDefinitionRouteLocator) {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor(routeLocator, routeDefinitionLocator, routeDefinitionWriter,\n\t\t\t\tzookeeperDiscoveryProperties, routeDefinitionRouteLocator);\n\t}\n}", "CodeBleu_score": 36.007581344326205}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t@Bean\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 64.84153440569132}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t//        RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n        RetryPolicy retryPolicy = new RetryNTimes(3, 1000);\n        CuratorFramework cf = CuratorFrameworkFactory.builder()\n                .connectString(getZkHosts())\n                .namespace(getNamespace())\n                .sessionTimeoutMs(getSessionTimeout())\n                .retryPolicy(retryPolicy)\n                .build();\n        cf.start();\n        return cf;\n    }", "CodeBleu_score": 51.419637211142025}, {"code": "public  CuratorFramework createCuratorFramework(){\n\tif (builder == null) {\n\n\nlog.info(\"builder is null\");\n}\n}", "CodeBleu_score": 1.8610109198260598}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t// create curator client\nCuratorFramework client = CuratorFrameworkFactory.builder()\n.connectString(zkHosts)\n.sessionTimeoutMs(sessionTimeoutMs)\n.namespace(namespace)\n.retryPolicy(retryPolicy)\n.build();\nclient.start();\nreturn client;\n}", "CodeBleu_score": 31.64193917621867}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\t\tInterProcessMutex lock = null;\n\ttry {\n\t\tlock = getZkCleint().getLock(path);\n\t\tlock.acquire();\n\t\tlocksMap.put(path, lock);\n\t} catch (Exception e) {\n\t\tthrow new DistributedLockException(\"Error while acquiring lock for path: \" + path, e);\n\t}\n}", "CodeBleu_score": 23.0344646316352}, {"code": "public void lock(String path) throws DistributedLockException{\n\tif (locksMap.containsKey(path)) {\ntry {\nInterProcessMutex lock = locksMap.get(path);\nlock.acquire();\n} catch (Exception e) {\nthrow new DistributedLockException(e);\n}\n} else {\ntry {\nInterProcessMutex lock = new InterProcessMutex(getZkCleint(), path);\nlock.acquire();\nlocksMap.put(path, lock);\n} catch (Exception e) {\nthrow new DistributedLockException(e);\n}\n}\n}", "CodeBleu_score": 30.49371128539193}, {"code": "public void lock(String path) throws DistributedLockException{\n\tif (locksMap.containsKey(path)) {\n// The current thread already holds a lock for the given path. Re-acquire the lock.\nInterProcessMutex lock = locksMap.get(path);\ntry {\nlock.acquire();\n} catch (Exception e) {\nthrow new DistributedLockException(e);\n}\n} else {\n// The current thread does not hold a lock for the given path. Acquire a new lock and store it in locksMap.\nInterProcessMutex lock = null;\ntry {\nlock = getZkClient().getInterProcessMutex(path);\nlock.acquire();\nlocksMap.put(path, lock);\n} catch (Exception e) {\nif (lock != null) {\ntry {\nlock.release();\n} catch (Exception e1) {\n// Ignore\n}\n}\nthrow new DistributedLockException(e);\n}\n}\n}", "CodeBleu_score": 34.41728006320947}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties.getZookeeperConnectString(), dtpProperties.getSessionTimeoutMs(), dtpProperties.getRetryPolicy());\n\tString nodePath = getNodePath(dtpProperties);\n\tMap<Object, Object> propertiesMap = new HashMap<>();\n\tif (dtpProperties.getConfigType().equals(ConfigType.PROPERTIES)) {\n\t\tpropertiesMap = genPropertiesTypeMap(dtpProperties);\n\t} else if (dtpProperties.getConfigType().equals(ConfigType.JSON)) {\n\t\tString configKey = getConfigKey(dtpProperties);\n\t\tString value = getValue(curatorFramework, nodePath, configKey);\n\t\tpropertiesMap = parseConfig(value);\n\t}\n\treturn propertiesMap;\n}", "CodeBleu_score": 45.212685788094014}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tMap<Object, Object> propertiesMap = new HashMap<>();\n\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tString nodePath = getNodePath(dtpProperties, curatorFramework);\n\tif (dtpProperties.getConfigurationType() == DtpProperties.ConfigurationType.PROPERTIES) {\n\t\tpropertiesMap = genPropertiesTypeMap(dtpProperties, nodePath);\n\t} else {\n\t\tString configKey = getConfigKey(dtpProperties, nodePath);\n\t\tString val = getValue(dtpProperties, curatorFramework, nodePath, configKey);\n\t\tpropertiesMap = parseConfig(dtpProperties, val);\n\t}\n\treturn propertiesMap;\n}", "CodeBleu_score": 45.66689497807085}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties.getZookeeper());\n\tString nodePath = getNodePath(dtpProperties.getDtpName(), dtpProperties.getConfigKey());\n\tString value = getValue(curatorFramework, nodePath);\n\tif (dtpProperties.getConfigType() == ConfigType.PROPERTIES) {\n\t\treturn genPropertiesTypeMap(value);\n\t} else if (dtpProperties.getConfigType() == ConfigType.JSON) {\n\t\treturn ConfigHandler.parseConfig(value);\n\t}\n\treturn new HashMap<Object, Object>();\n}", "CodeBleu_score": 37.71598638223161}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = getInstance();\n\tenvironment.getPropertySources().addFirst(createZkPropertySource(dtpProperties));\n\tbindDtpProperties(environment, dtpProperties);\n\tcheckPropertyExist(environment, dtpProperties);\n\tgenPropertiesMap(environment, dtpProperties);\n}", "CodeBleu_score": 42.0105248987183}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = getInstance();\n\tenvironment.getPropertySources().addFirst(createZkPropertySource(dtpProperties));\n\tbindDtpProperties(environment, dtpProperties);\n\tgenPropertiesMap(environment, dtpProperties);\n\tcheckPropertyExist(environment, dtpProperties);\n}", "CodeBleu_score": 42.0105248987183}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = DtpProperties.getInstance();\n\tenvironment.getPropertySources().addFirst(createZkPropertySource(dtpProperties));\n\tbindDtpProperties(dtpProperties, environment);\n\tcheckPropertyExist(dtpProperties, environment);\n\tgenPropertiesMap(dtpProperties, environment);\n}", "CodeBleu_score": 45.04400010674113}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t\tif (builder == null) {\n\t\tthrow new ArgumentNullException(nameof(builder));\n\t}\n\n\tif (configInfo == null) {\n\t\tthrow new ArgumentNullException(nameof(configInfo));\n\t}\n\n\tbuilder.AddZooKeeperRouteManager(configInfo);\n\treturn this;\n}", "CodeBleu_score": 20.500917304429255}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tbuilder.Services.AddSingleton<IServiceRouteManager, ZooKeeperServiceRouteManager>();\nbuilder.Services.AddSingleton<IServiceRouteFactory, ZooKeeperServiceRouteFactory>();\nbuilder.Services.AddSingleton<ISerializer<byte[]>, ProtobufSerializer<byte[]>>();\nbuilder.Services.AddSingleton<ISerializer<string>, StringSerializer>();\nbuilder.Services.AddSingleton<IZookeeperClientProvider, ZookeeperClientProvider>();\nbuilder.Services.AddSingleton<ILoggerFactory, LoggerFactory>();\nbuilder.Services.AddSingleton<ILogger<ZooKeeperServiceRouteManager>, ZooKeeperServiceRouteManagerLogger>();\nbuilder.Services.AddSingleton(configInfo);\nbuilder.Services.AddSingleton<IServiceRouteManager, ZooKeeperServiceRouteManager>();\nreturn this;\n}", "CodeBleu_score": 41.53562035717619}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t\tif (builder == null) {\n\t\tthrow new ArgumentNullException(nameof(builder));\n\t}\n\n\tif (configInfo == null) {\n\t\tthrow new ArgumentNullException(nameof(configInfo));\n\t}\n\n\tbuilder.Builder.Register(context => new ZooKeeperServiceRouteManager(\n\t\tconfigInfo.ServiceRouteManagerConfig.RouteConfig,\n\t\tcontext.Resolve<ILogger<ZooKeeperServiceRouteManager>>(),\n\t\tcontext.Resolve<ISerializer<byte[]>>(),\n\t\tcontext.Resolve<IServiceRouteFactory>(),\n\t\tcontext.Resolve<ISerializer<string>>(),\n\t\tcontext.Resolve<IZookeeperClientProvider>()\n\t)).As<IServiceRouteManager>().SingleInstance();\n\n\treturn this;\n}", "CodeBleu_score": 54.8558905576118}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t return builder.UseZooKeeperCommandManager(configInfo);\n }", "CodeBleu_score": 9.90603208990287}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t var zookeeperModule = new ZookeeperModule(configInfo);\n builder.Services.AddSingleton<IZookeeperClientProvider>(provider => new ZookeeperClientProvider(configInfo));\n builder.Services.AddSingleton<ISerializer<byte[]>>(provider => new ProtobufSerializer<byte[]>());\n builder.Services.AddSingleton<ISerializer<string>>(provider => new StringSerializer());\n builder.Services.AddSingleton<ILogger<ZookeeperServiceCommandManager>>(provider => new ZookeeperLogger(configInfo));\n builder.Services.AddSingleton<IServiceEntryManager>(provider => new ZookeeperServiceEntryManager(provider.GetRequiredService<IZookeeperClientProvider>(), provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<ISerializer<string>>(), provider.GetRequiredService<ILogger<ZookeeperServiceEntryManager>>()));\n builder.Services.AddSingleton<IServiceRouteManager>(provider => new ZookeeperServiceRouteManager(provider.GetRequiredService<IZookeeperClientProvider>(), provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<ISerializer<string>>(), provider.GetRequiredService<ILogger<ZookeeperServiceRouteManager>>()));\n builder.Services.AddSingleton<IServiceCommandManager>(provider => new ZookeeperServiceCommandManager(provider.GetRequiredService<IZookeeperClientProvider>(), provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<ISerializer<string>>(), provider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>()));\n return zookeeperModule;\n }", "CodeBleu_score": 48.5393558373169}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t return UseZooKeeperCommandManager(builder, configInfo, null);\n}", "CodeBleu_score": 23.843842901114794}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tif (builder == null) {\nthrow new ArgumentNullException(nameof(builder));\n}\nif (string.IsNullOrEmpty(path)) {\nthrow new ArgumentException(\"The configuration path cannot be null or empty.\", nameof(path));\n}\nif (provider == null && !Path.IsPathRooted(path)) {\nthrow new ArgumentException(\"The configuration path must be rooted.\", nameof(path));\n}\nCheck.NotNull(optional, nameof(optional));\nCheck.NotNull(reloadOnChange, nameof(reloadOnChange));\nif (optional && !File.Exists(path)) {\nreturn builder;\n}\nvar source = new ZookeeperConfigurationSource {\nFileProvider = provider,\nPath = path,\nOptional = optional,\nReloadOnChange = reloadOnChange\n};\nbuilder.Add(source);\nreturn builder;\n}", "CodeBleu_score": 54.55796337330372}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tCheck.NotNull(builder, nameof(builder));\nCheck.NotNull(path, nameof(path));\nif (string.IsNullOrEmpty(path)) {\nthrow new ArgumentException(\"Path cannot be null or empty.\", nameof(path));\n}\nif (Path.IsPathRooted(path)) {\nif (provider == null) {\nprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n}\n}\nelse {\nif (provider == null) {\nthrow new ArgumentException(\"A file provider must be provided when the path is not rooted.\", nameof(provider));\n}\n}\nvar source = new ZookeeperConfigurationSource {\nFileProvider = provider,\nPath = path,\nOptional = optional,\nReloadOnChange = reloadOnChange\n};\nbuilder.Add(source);\nreturn builder;\n}", "CodeBleu_score": 63.15324704567834}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tif (builder == null) {\nthrow new ArgumentNullException(nameof(builder));\n}\nif (string.IsNullOrEmpty(path)) {\nthrow new ArgumentException(\"Argument cannot be null or empty\", nameof(path));\n}\nif (provider == null && !Path.IsPathRooted(path)) {\nthrow new ArgumentException(\"Provider cannot be null if path is not rooted\", nameof(provider));\n}\nif (optional) {\nbuilder.AddIf(new ZookeeperConfigurationSource {\nPath = path,\nOptional = optional,\nReloadOnChange = reloadOnChange\n});\n} else {\nbuilder.Add(new ZookeeperConfigurationSource {\nPath = path,\nOptional = optional,\nReloadOnChange = reloadOnChange\n});\n}\nreturn builder;\n}", "CodeBleu_score": 44.16533989466783}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tawait Task.Run(() => {\n\t\tvar Routes = GetRoutes();\n\t\tforeach (var Route in Routes) {\n\t\t\tRoute.Address.ExceptWith(Address);\n\t\t}\n\t\tSetRoutes(Routes);\n\t});\n}", "CodeBleu_score": 30.51971608638749}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tvar routes = await GetRoutesAsync();\nforeach (var route in routes) {\nif (route.Address.Except != null) {\nroute.Address.Except.AddRange(Address);\n}\nelse {\nroute.Address.Except = Address.ToList();\n}\n}\nawait SetRoutesAsync(routes);\n}", "CodeBleu_score": 62.36898749832448}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tvar routes = await GetRoutesAsync();\nforeach (var route in routes) {\nforeach (var address in Address) {\nif (route.Address.Contains(address)) {\nroute.Address.Remove(address);\n}\n}\n}\nawait SetRoutesAsync(routes);\n}", "CodeBleu_score": 58.48698732735329}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tvar oldRouteIds = _routes.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\nvar zooKeeperClients = _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeeperClients) {\nvar path = _zookeeperRoutePath + \"/\" + zooKeeper.Item1;\nvar addresses = routes.Select(i => i.Address).ToArray();\nif (addresses.Contains(hostAddr)) {\nvar deletedRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\nforeach (var deletedRouteId in deletedRouteIds) {\nvar routePath = path + \"/\" + deletedRouteId;\nif (routePath.EndsWith(hostAddr.ToString())) {\nawait zooKeeper.Item2.deleteAsync(routePath);\n}\n}\n}\n}\n}", "CodeBleu_score": 50.69901690624212}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tvar oldRouteIds = _routes.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\nvar zooKeeperClients = _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeeperClients) {\nvar path = _routePathBuilder.Build(hostAddr);\nvar addresses = routes.Select(i => i.Address).ToArray();\nvar nodes = await zooKeeper.Item2.getChildrenAsync(path);\nforeach (var node in nodes) {\nvar routeId = node.Split(new char[] { '/' }, StringSplitOptions.RemoveEmptyEntries).Last();\nif (deletedRouteIds.Contains(routeId) && addresses.Contains(hostAddr)) {\nawait zooKeeper.Item2.deleteAsync(path + \"/\" + node);\n}\n}\n}\n}", "CodeBleu_score": 46.78793828947636}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\tvar zooKeeper = await _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeperClient in zooKeeper) {\n\t\tvar path = _zookeeperClientProvider.GetRoutePath(zooKeeperClient.Options.Path);\n\t\tvar addresses = await zooKeeperClient.getChildrenAsync(path);\n\t\tvar oldRouteIds = addresses.Select(i => i.Split(new[] { \"/\" }, StringSplitOptions.RemoveEmptyEntries)[1]).ToArray();\n\t\tvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n\t\tvar deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n\t\tforeach (var deletedRouteId in deletedRouteIds) {\n\t\t\tif (addresses.Contains(deletedRouteId + \"/\" + hostAddr.ToString())) {\n\t\t\t\tawait zooKeeperClient.deleteAsync(path + \"/\" + deletedRouteId);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 45.01483591102471}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {", "CodeBleu_score": 7.931985721341224}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {\n_logger.LogDebug\n($\"The provided data is null, so returning null.\");\n            return null;\n        }\n_logger.LogDebug\n($\"The provided data is {BitConverter.ToString(data)}, so deserializing into a ServiceRouteDescriptor and returning the first ServiceRoute.\");\n            var descriptor = _serializer.Deserialize<ServiceRouteDescriptor>(data);\n            return (await CreateServiceRoutesAsync(new[] { descriptor })).First();\n        }", "CodeBleu_score": 44.80221622608808}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {\n_logger.LogDebug\n($\"The data is null, so returning null.\");\nreturn null;\n}\n_logger.LogDebug\n($\"The data is not null, so deserializing into a ServiceRouteDescriptor and using a service route factory to create and return the first ServiceRoute.\");\nvar descriptor = _serializationService.Deserialize<ServiceRouteDescriptor>(data);\nreturn (await CreateServiceRoutesAsync(new[] { descriptor })).First();\n}", "CodeBleu_score": 44.15583495217996}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (oldData == null || newData == null) return;\n\nvar oldRoute = Route.Deserialize(oldData);\nvar newRoute = Route.Deserialize(newData);\n\nif (oldRoute == newRoute) return;\n\nawait _lock.WaitAsync();\ntry {\nvar oldRouteIndex = _routes.FindIndex(i => i.ServiceDescriptor.Id == oldRoute.ServiceDescriptor.Id);\nif (oldRouteIndex < 0) return;\n\n_routes[oldRouteIndex] = newRoute;\n}\nfinally {\n_lock.Release();\n}\n\nawait OnChanged(new RouteChangedEventArgs(oldRoute, newRoute));\n}", "CodeBleu_score": 34.36403670551316}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (oldData == null) {\nthrow new ArgumentNullException(nameof(oldData));\n}\nif (newData == null) {\nthrow new ArgumentNullException(nameof(newData));\n}\nif (oldData.Length == 0) {\nthrow new ArgumentException(\"oldData cannot be empty.\", nameof(oldData));\n}\nif (newData.Length == 0) {\nthrow new ArgumentException(\"newData cannot be empty.\", nameof(newData));\n}\nif (newData.Length > MaxDataLength) {\nthrow new ArgumentException(\"newData cannot be longer than \" + MaxDataLength + \" bytes.\", nameof(newData));\n}\n\nvar newRoute = Route.FromBytes(newData);\nif (newRoute == null) {\nthrow new ArgumentException(\"newData is not a valid route.\", nameof(newData));\n}\n\nRoute oldRoute = null;\nusing (await _lock.LockAsync()) {\noldRoute = _routes.Find(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id);\nif (oldRoute != null) {\n_routes = _routes.Where(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id)\n.Concat(new[] { newRoute }).ToArray();\n}\n}\n\n//\u89e6\u53d1\u8def\u7531\u53d8\u66f4\u4e8b\u4ef6\u3002\n\nawait OnChanged.InvokeAsync(new RouteChangedEventArgs(oldRoute, newRoute));\n}", "CodeBleu_score": 56.89259222581276}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (oldData == newData)\nreturn;\n\nRoute newRoute = Route.FromBytes(newData);\nRoute oldRoute = Route.FromBytes(oldData);\n\n//\u5982\u679c\u8def\u7531\u7684\u670d\u52a1\u63cf\u8ff0\u7b26ID\u4e0e\u65b0\u8def\u7531\u7684\u670d\u52a1\u63cf\u8ff0\u7b26ID\u4e0d\u76f8\u7b49\uff0c\u5219\u8868\u793a\u670d\u52a1\u63cf\u8ff0\u7b26\u53d1\u751f\u4e86\u53d8\u5316\uff0c\u56e0\u6b64\u9700\u8981\u5c06\u8def\u7531\u6dfb\u52a0\u5230\u8def\u7531\u8868\u4e2d\u3002\n\nif (oldRoute.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id) {\nlock (_routes) {\n_routes = _routes.Where(i => i.ServiceDescriptor.Id != oldRoute.ServiceDescriptor.Id)\n.Concat(new[] { newRoute }).ToArray();\n}\n}\n\n//\u89e6\u53d1\u8def\u7531\u53d8\u66f4\u4e8b\u4ef6\u3002\n\nawait OnChanged(newRoute, oldRoute);\n}", "CodeBleu_score": 57.231278932280915}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t\tvar existingSubscribers = await GetSubscribersAsync(subscribers.Select(s => s.ServiceDescriptor.Id));\n\tforeach (var subscriber in subscribers) {\n\t\tvar existingSubscriber = existingSubscribers.Where(s => s.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n\t\tif (existingSubscriber == null) {\n\t\t\tawait base.SetSubscribersAsync(new[] { subscriber });\n\t\t}\n\t\telse {\n\t\t\tsubscriber.Address = existingSubscriber.Address.Concat(subscriber.Address).Except(existingSubscriber.Address).ToArray();\n\t\t\tawait base.SetSubscribersAsync(new[] { subscriber });\n\t\t}\n\t}\n}", "CodeBleu_score": 60.52376795590917}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t\tif (subscribers == null) {\n\t\tthrow new ArgumentNullException(nameof(subscribers));\n\t}\n\n\tvar serviceSubscribers = await GetSubscribersAsync();\n\tforeach (var subscriber in subscribers) {\n\t\tvar existingSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n\t\tif (existingSubscriber != null) {\n\t\t\texistingSubscriber.Address = existingSubscriber.Address.Concat(subscriber.Address).Except(subscriber.Address);\n\t\t}\n\t}\n\n\tawait base.SetSubscribersAsync(serviceSubscribers);\n}", "CodeBleu_score": 66.24988879378004}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tif (subscribers == null) {\nthrow new ArgumentNullException(nameof(subscribers));\n}\n\nvar existingSubscribers = GetSubscribers();\nvar updatedSubscribers = subscribers.Select(subscriber => {\nvar existingSubscriber = existingSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\nif (existingSubscriber == null) {\nreturn subscriber;\n}\n\nsubscriber.Address = existingSubscriber.Address.Concat(subscriber.Address).Except(existingSubscriber.Address).ToList();\nreturn subscriber;\n}).ToList();\nawait base.SetSubscribersAsync(updatedSubscribers);\n}", "CodeBleu_score": 35.86831286253428}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar rootPath = ServiceHelper.GetSubscribersRootPath();\nvar subscribers = new List<ServiceSubscriber>();\nforeach (var child in childrens) {\nvar childPath = Path.Combine(rootPath, child);\nvar subscriber = await ServiceHelper.GetServiceSubscriber(childPath);\nif (subscriber != null) {\nsubscribers.Add(subscriber);\n}\n}\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 35.66907063327017}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t_logger.LogDebug", "CodeBleu_score": 5.482993425100544}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t_logger.LogDebug\nstring rootPath = _service.RootPath;\nList<ServiceSubscriber> subscribers = new List<ServiceSubscriber>();\nforeach (string child in childrens) {\nstring fullPath = rootPath + \"/\" + child;\nServiceSubscriber subscriber = await _service.GetSubscriber(fullPath);\nsubscribers.Add(subscriber);\n}\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 29.971631638961988}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\t\tif (_subscribers != null) {\n\t\treturn;\n\t}\n\n\tvar zooKeeper = await GetZooKeeper();\n\tif (zooKeeper == null) {\n\t\treturn;\n\t}\n\n\tvar result = await zooKeeper.Item2.existsAsync(SubscribersPath);\n\tif (result.Item1 == ZooKeeper.States.CONNECTED) {\n\t\tvar children = await zooKeeper.Item2.getChildrenAsync(SubscribersPath);\n\t\tif (children.Item1 == ZooKeeper.States.CONNECTED) {\n\t\t\t_subscribers = children.Item2.Select(x => x.Split('/').Last()).ToArray();\n\t\t}\n\t}\n}", "CodeBleu_score": 45.03244455951948}, {"code": "private async Task EnterSubscribers(){\n\tif (_subscribers != null) {\nreturn;\n}\n\n_logger.LogInformation(\"EnterSubscribers: Entering\");\n\nvar zooKeeper = GetZooKeeper();\nawait zooKeeper.Item2.existsAsync(SubscriberPath, false);\nvar result = await zooKeeper.Item2.getChildrenAsync(SubscriberPath, false);\nvar children = result.Children.ToArray();\nvar subscribers = new List<Subscriber>();\nforeach (var child in children) {\nvar childData = await zooKeeper.Item2.getDataAsync(SubscriberPath + \"/\" + child, false);\nsubscribers.Add(JsonConvert.DeserializeObject<Subscriber>(Encoding.UTF8.GetString(childData.Data)));\n}\n_subscribers = subscribers.ToArray();\n_logger.LogInformation(\"EnterSubscribers: Exiting\");\n}", "CodeBleu_score": 42.861476986650096}, {"code": "private async Task EnterSubscribers(){\n\t\tif (_subscribers != null) {\n\t\treturn;\n\t}\n\n\tvar zooKeeper = GetZooKeeper();\n\tif (zooKeeper == null) {\n\t\treturn;\n\t}\n\n\ttry {\n\t\tawait zooKeeper.Item2.getChildrenAsync(SubscriberPath, false, null);\n\t}\n\tcatch (Exception ex) {\n\t\t_logger.LogWarning(ex, \"EnterSubscribers failed to get children for path {SubscriberPath}\", SubscriberPath);\n\t\treturn;\n\t}\n\n\tvar result = await zooKeeper.Item1.Task;\n\tif (result.Children == null) {\n\t\t_logger.LogWarning(\"EnterSubscribers failed to get children for path {SubscriberPath}\", SubscriberPath);\n\t\treturn;\n\t}\n\n\tvar children = result.Children.ToArray();\n\t_subscribers = new HashSet<string>(children, StringComparer.OrdinalIgnoreCase);\n}", "CodeBleu_score": 46.3617719368683}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tvar oldNode = new Node(oldData);\nvar newNode = new Node(newData);\n//\u5982\u679c\u8282\u70b9\u6570\u636e\u53d1\u751f\u53d8\u5316\uff0c\u5219\u83b7\u53d6\u670d\u52a1\u547d\u4ee4\u3002\nif (!oldNode.DataEquals(newNode)) {\nvar newCommand = GetServiceCommand(newNode);\n//\u5982\u679c\u670d\u52a1\u547d\u4ee4\u53d1\u751f\u53d8\u5316\uff0c\u5219\u66f4\u65b0\u670d\u52a1\u547d\u4ee4\u5217\u8868\u3002\nif (newCommand != null) {\nServiceCommands = ServiceCommands.Where(i => i.ServiceId != newCommand.ServiceId)\n.Concat(new[] { newCommand }).ToArray();\n}\n//\u89e6\u53d1\u670d\u52a1\u547d\u4ee4\u53d8\u66f4\u4e8b\u4ef6\u3002\nOnChanged?.Invoke(newCommand, oldCommand);\n}\n}", "CodeBleu_score": 63.32548827274006}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tif (oldData == null && newData == null) {\nreturn;\n}\nif (oldData == null || newData == null) {\n//\u89e6\u53d1\u670d\u52a1\u547d\u4ee4\u53d8\u66f4\u4e8b\u4ef6\u3002\nOnChanged(null, null);\nreturn;\n}\n//\u5982\u679c\u8282\u70b9\u6570\u636e\u53d1\u751f\u4e86\u53d8\u5316\uff0c\u5219\u83b7\u53d6\u65b0\u7684\u670d\u52a1\u547d\u4ee4\u3002\nbyte[] command = GetServiceCommand(newData);\nif (command == null) {\n//\u89e6\u53d1\u670d\u52a1\u547d\u4ee4\u53d8\u66f4\u4e8b\u4ef6\u3002\nOnChanged(null, null);\nreturn;\n}\n//\u5982\u679c\u670d\u52a1\u547d\u4ee4\u53d1\u751f\u4e86\u53d8\u5316\uff0c\u5219\u66f4\u65b0\u670d\u52a1\u547d\u4ee4\u5217\u8868\u3002\nif (!command.SequenceEqual(oldData)) {\nServiceCommand[] commands = ServiceCommands.Where(i => i.ServiceId != ServiceId)\n.Concat(new[] { new ServiceCommand(ServiceId, command) }).ToArray();\n//\u89e6\u53d1\u670d\u52a1\u547d\u4ee4\u53d8\u66f4\u4e8b\u4ef6\u3002\nOnChanged(ServiceCommands, commands);\n}\n}", "CodeBleu_score": 35.25335585788582}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tif (oldData == null && newData == null)\nreturn;\nif (oldData == null) {\n//\u5982\u679c\u662f\u65b0\u8282\u70b9\uff0c\u5219\u521b\u5efa\u670d\u52a1\u547d\u4ee4\u3002\nforeach (var newCommand in GetServiceCommands(newData))\nCommands = Commands.TakeWhile(i => i.ServiceId != newCommand.ServiceId).Concat(new[] { newCommand }).ToArray();\n} else if (newData == null) {\n//\u5982\u679c\u662f\u65e7\u8282\u70b9\uff0c\u5219\u5220\u9664\u670d\u52a1\u547d\u4ee4\u3002\nCommands = Commands.Where(i => !oldData.Contains(i.ServiceId)).ToArray();\n} else {\n//\u5982\u679c\u662f\u66f4\u65b0\u8282\u70b9\uff0c\u5219\u66f4\u65b0\u670d\u52a1\u547d\u4ee4\u3002\nforeach (var newCommand in GetServiceCommands(newData))\nCommands = Commands.TakeWhile(i => i.ServiceId != newCommand.ServiceId).Concat(new[] { newCommand }).ToArray();\n}\n//\u89e6\u53d1\u670d\u52a1\u547d\u4ee4\u53d8\u66f4\u4e8b\u4ef6\u3002\nOnChanged?.Invoke(Commands.ToArray(), oldData, newData);\n}", "CodeBleu_score": 58.19322734550446}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\tif (watchedEvent.get_Type() == EventType.NodeDataChanged) {\nvar currentData = _watcher.GetCurrentData();\nvar newData = await _zooKeeperCall(zooKeeper => zooKeeper.Item2.getDataAsync(currentData.Item1, currentData.Item2, _watcher));\nawait _action(currentData.Item3, newData);\n}\n}", "CodeBleu_score": 21.225579706427027}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\n/// <summary>", "CodeBleu_score": 1.9605292502682936}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\tvar zooKeeper = _zooKeeperCall.GetZooKeeper();\nvar item = _zooKeeperCall.GetItem();\nvar watcher = _zooKeeperCall.GetWatcher();\nvar data = await zooKeeper.GetDataAsync(item.Path);\nvar newData = new NodeData(data.Data, item.Path);\nvar action = _action.GetAction();\nif (action != null) {\naction(newData, watcher.CurrentData);\n}\nwatcher.SetCurrentData(newData);\n}", "CodeBleu_score": 52.092698010611294}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tbuilder.Services.Register(provider =>\n       new DefaultZookeeperClientProvider(\n           GetConfigInfo(configInfo),\n        provider.Resolve<IHealthCheckService>(),\n          provider.Resolve<IZookeeperAddressSelector>(),\n          provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>\nbuilder.Services.Register(provider =>\n       new DefaultZookeeperClientProvider(\n           GetConfigInfo(configInfo),\n        provider.Resolve<IHealthCheckService>(),\n          provider.Resolve<IZookeeperAddressSelector>(),\n          provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance\nreturn builder\n}", "CodeBleu_score": 73.1701620510977}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tbuilder.Services.Register(provider =>\n       new DefaultZookeeperClientProvider(\n           GetConfigInfo(configInfo),\n        provider.Resolve<IHealthCheckService>(),\n          provider.Resolve<IZookeeperAddressSelector>(),\n          provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>\nbuilder.Services.Register(provider =>\n       new DefaultZookeeperClientProvider(\n           GetConfigInfo(configInfo),\n        provider.Resolve<IHealthCheckService>(),\n          provider.Resolve<IZookeeperAddressSelector>(),\n          provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance\nreturn builder\n}", "CodeBleu_score": 73.1701620510977}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tbuilder.Services.Register(provider =>\n       new DefaultZookeeperClientProvider(\n           GetConfigInfo(configInfo),\n        provider.Resolve<IHealthCheckService>(),\n          provider.Resolve<IZookeeperAddressSelector>(),\n          provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>\nbuilder.Services.Register(provider =>\n       new DefaultZookeeperClientProvider(\n           GetConfigInfo(configInfo),\n        provider.Resolve<IHealthCheckService>(),\n          provider.Resolve<IZookeeperAddressSelector>(),\n          provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance\nreturn builder;\n}", "CodeBleu_score": 75.24772742588345}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\tif (routes == null) {\nthrow new ArgumentNullException(nameof(routes));\n}\nvar serviceRoutes = routes.ToList();\nif (!serviceRoutes.Any()) {\nreturn;\n}\nvar zooKeepers = _provider.GetZooKeepers();\nvar tasks = new List<Task>();\nforeach (var zooKeeper in zooKeepers) {\nvar task = SetRoutesAsync(zooKeeper, serviceRoutes);\ntasks.Add(task);\n}\nawait Task.WhenAll(tasks);\n}", "CodeBleu_score": 14.47061036565367}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\nlogger.LogInformation(\n", "CodeBleu_score": 4.954345305588415}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\nvar routeCount = routes.Count();", "CodeBleu_score": 6.788118222010548}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tvar zooKeeper = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zk in zooKeeper) {\nvar addresses = zk.Item2.getChildrenAsync(RoutePath).Result.Select(a => a.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries).Last()).ToArray();\nvar oldRouteTopics = addresses.Select(a => a.Split(new[] { '_' }, StringSplitOptions.RemoveEmptyEntries).First()).ToArray();\nvar newRouteTopics = routes.Select(r => r.MqttDescriptor.Topic).ToArray();\nvar deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\nforeach (var deletedRouteTopic in deletedRouteTopics) {\nif (addresses.Contains(deletedRouteTopic + \"_\" + hostAddr.ToString())) {\nawait zk.Item2.deleteAsync(RoutePath + \"/\" + deletedRouteTopic + \"_\" + hostAddr.ToString());\n}\n}\n}\n}", "CodeBleu_score": 51.37303927027175}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tvar oldRouteTopics = _routes.Select(p => p.MqttDescriptor.Topic).ToArray();\nvar newRouteTopics = routes.Select(p => p.MqttDescriptor.Topic).ToArray();\nvar deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\nvar zooKeeperClients = _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeeperClients) {\nvar addresses = await zooKeeper.Item2.getChildrenAsync(_zookeeperRoutePath);\nforeach (var deletedRouteTopic in deletedRouteTopics) {\nif (addresses.Contains(deletedRouteTopic)) {\nawait zooKeeper.Item2.deleteAsync(_zookeeperRoutePath + \"/\" + deletedRouteTopic);\n}\n}\n}\n}", "CodeBleu_score": 43.694583381109695}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tif (routes == null) {\nthrow new ArgumentNullException(nameof(routes));\n}\n\nif (hostAddr == null) {\nthrow new ArgumentNullException(nameof(hostAddr));\n}\n\nvar oldRouteTopics = routes.Select(p => p.MqttDescriptor.Topic).ToArray();\nvar newRouteTopics = oldRouteTopics.Except(new[] { hostAddr.Topic }).ToArray();\nvar zooKeeper = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zk in zooKeeper) {\nvar addresses = await zk.Item2.getChildrenAsync(zk.Item1);\nvar deletedRouteTopics = addresses.Except(newRouteTopics).ToArray();\nforeach (var deletedRouteTopic in deletedRouteTopics) {\nif (addresses.Contains(hostAddr.Topic)) {\nawait zk.Item2.deleteAsync(zk.Item1 + \"/\" + deletedRouteTopic);\n}\n}\n}\n}", "CodeBleu_score": 47.461118363309154}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\nif (cacheDescriptors == null) {\nthrow new ArgumentNullException(nameof(cacheDescriptors));\n}\n\nvar cacheDescriptorList = cacheDescriptors.ToList();\nif (cacheDescriptorList.Count == 0) {\nreturn;\n}\n\nvar cachePath = GetCachePath(cacheDescriptorList[0].ServiceId);\nvar zooKeeper = await GetZooKeeperClientAsync();\nif (zooKeeper == null) {\nreturn;\n}\n\nvar cachePathExists = await zooKeeper.ExistsAsync(cachePath);\nif (cachePathExists == null) {\nawait zooKeeper.CreateRecursiveAsync(cachePath);\n}\n\nvar cacheDescriptorTasks = new List<Task>();\nforeach (var cacheDescriptor in cacheDescriptorList) {\nvar cacheDescriptorPath = GetCacheDescriptorPath(cachePath, cacheDescriptor.CacheId);\ncacheDescriptorTasks.Add(zooKeeper.SetDataAsync(cacheDescriptorPath, Serialize(cacheDescriptor)));\n}\n\nawait Task.WhenAll(cacheDescriptorTasks);\n\n_logger.LogInformation(\n\"\u6210\u529f\u6dfb\u52a0\u670d\u52a1\u7f13\u5b58\u3002\u670d\u52a1ID\uff1a{serviceId}\uff0c\u7f13\u5b58ID\uff1a{cacheIds}\",\ncacheDescriptorList[0].ServiceId,\nstring.Join(\",\", cacheDescriptorList.Select(x => x.CacheId)));\n}", "CodeBleu_score": 21.186374076839336}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\tif (cacheDescriptors == null) {", "CodeBleu_score": 1.3754413583535943}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\tif (cacheDescriptors == null) {\nthrow new ArgumentNullException(nameof(cacheDescriptors));\n}\n_logger.LogInformation(\n\"Setting service caches in Zookeeper\"\n);\nvar zooKeeper = await GetZooKeepersAsync();\nif (zooKeeper == null) {\nreturn;\n}\nvar cacheDescriptorList = cacheDescriptors.ToList();\nvar cacheDescriptorCount = cacheDescriptorList.Count;\nvar cacheDescriptorIndex = 0;\nforeach (var zooKeeperClient in zooKeeper) {\nvar cacheDescriptor = cacheDescriptorList[cacheDescriptorIndex];\nvar cachePath = GetCachePath(cacheDescriptor.ServiceName);\nif (!await zooKeeperClient.ExistsAsync(cachePath) == null) {\nawait zooKeeperClient.CreatePersistentAsync(cachePath, true);\n}\nforeach (var nodePath in GetNodePaths(cacheDescriptor.ServiceName, cacheDescriptor.CacheId)) {\nvar nodeData = Serialize(cacheDescriptor);\nif (!await zooKeeperClient.ExistsAsync(nodePath) == null) {\nawait zooKeeperClient.CreatePersistentAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n} else {\nif (!DataEquals(nodeData)) {\nawait zooKeeperClient.SetDataAsync(nodePath, nodeData);\n}\n}\n}\ncacheDescriptorIndex++;\n}\n_logger.LogInformation(\nstring.Format(\n\"Successfully set {0} service caches in Zookeeper\",\ncacheDescriptorCount\n)\n);\n}", "CodeBleu_score": 39.72999084212644}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t_logger.LogInformation", "CodeBleu_score": 9.890160924483387}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t/// <summary>", "CodeBleu_score": 6.677050525407208}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\tvar nodePath = path;", "CodeBleu_score": 8.030930778170346}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var address in _config.Addresses) {\nvar healthCheckService = _healthCheckServiceFactory.CreateHealthCheckService(address);\nif (await healthCheckService.IsHealth()) {\nvar zooKeeper = await _zooKeeperFactory.CreateZooKeeper(address);\nvar healthCheckEvent = new ManualResetEvent(false);\nhealthCheckService.OnHealthChanged += (sender, args) => {\nif (args.IsHealthy) {\nhealthCheckEvent.Set();\n} else {\nhealthCheckEvent.Reset();\n}\n};\nresult.Add((healthCheckEvent, zooKeeper));\n}\n}\nreturn result;\n}", "CodeBleu_score": 53.88766239245811}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\n\tforeach (var address in _config.ZooKeeperAddresses) {\n\t\tvar healthCheckResult = await _healthCheckService.IsHealth(address);\n\t\tif (healthCheckResult.IsHealthy) {\n\t\t\tvar resetEvent = new ManualResetEvent(false);\n\t\t\tvar zooKeeper = new ZooKeeper(address, _config.SessionTimeout, resetEvent);\n\t\t\tresult.Add((resetEvent, zooKeeper));\n\t\t}\n\t}\n\treturn result;\n}", "CodeBleu_score": 66.70136704609007}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var address in _addresses) {\nvar healthCheckService = _healthCheckServiceFactory(address);\nif (await healthCheckService.IsHealth()) {\nvar event = new ManualResetEvent(false);\nvar zooKeeper = await CreateZooKeeper(address, event);\nresult.Add((event, zooKeeper));\n}\n}\nreturn result;\n}", "CodeBleu_score": 68.18046763619911}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tsynchronized (this) {\n\t\tif (zk == null) {\n\t\t\tzk = newZooKeeper();\n\t\t}\n\t}\n\treturn zk;\n}", "CodeBleu_score": 14.748587673510402}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tif (zooKeeper == null) {\n\t\tsynchronized(this) {\n\t\t\tif (zooKeeper == null) {\n\t\t\t\tif (connectionString == null) {\n\t\t\t\t\tthrow new Exception(\"The connection string is null.\");\n\t\t\t\t}\n\t\t\t\tzooKeeper = newZooKeeper(connectionString, sessionTimeout, this);\n\t\t\t}\n\t\t}\n\t}\n\treturn zooKeeper;\n}", "CodeBleu_score": 23.90411252781387}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tsynchronized (this) {\n\t\tif (zooKeeper == null) {\n\t\t\tzooKeeper = newZooKeeper();\n\t\t}\n\t}\n\treturn zooKeeper;\n}", "CodeBleu_score": 15.710534260562936}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (zk != null) {\n\t\ttry {\n\t\t\tzk.close();\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\t\tzk = null;\n\t}\n}", "CodeBleu_score": 15.216165987840338}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (this.zooKeeper != null) {\n\t\ttry {\n\t\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\t\tthis.zooKeeper.close(waitForShutdownTimeoutMs);\n\t\t\t} else {\n\t\t\t\tthis.zooKeeper.close();\n\t\t\t}\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t\tthrow e;\n\t\t} finally {\n\t\t\tthis.zooKeeper = null;\n\t\t}\n\t}\n}", "CodeBleu_score": 19.918339660554217}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (this.zk != null) {\n\t\tthis.zk.close();\n\t\tthis.zk = null;\n\t}\n\tif (waitForShutdownTimeoutMs > 0) {\n\t\ttry {\n\t\t\tThread.sleep(waitForShutdownTimeoutMs);\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\t}\n}", "CodeBleu_score": 20.68762000078404}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tif (debug) {\n\t\tSystem.out.println(\"Entering blockUntilConnectedOrTimedOut\");\n\t}\n\tlong startTime = System.currentTimeMillis();\n\tboolean isConnected = false;\n\tif (debug) {\n\t\tSystem.out.println(\"Checking if the client is started\");\n\t}\n\tcheckState();\n\tif (debug) {\n\t\tSystem.out.println(\"Client is started\");\n\t}\n\tif (debug) {\n\t\tSystem.out.println(\"Waiting for the client to connect\");\n\t}\n\tsynchronized (this) {\n\t\twhile (!isConnected) {\n\t\t\tif (debug) {\n\t\t\t\tSystem.out.println(\"Checking if the client is connected\");\n\t\t\t}\n\t\t\tisConnected = isConnected();\n\t\t\tif (!isConnected) {\n\t\t\t\tif (debug) {\n\t\t\t\t\tSystem.out.println(\"Client is not connected\");\n\t\t\t\t}\n\t\t\t\twait(1000);\n\t\t\t}\n\t\t}\n\t}\n\tif (debug) {\n\t\tSystem.out.println(\"Client is connected\");\n\t}\n\tlong endTime = System.currentTimeMillis();\n\tif (debug) {\n\t\tSystem.out.println(\"Exiting blockUntilConnectedOrTimedOut\");\n\t}\n\tif (debug) {\n\t\tSystem.out.println(\"blockUntilConnectedOrTimedOut took \" + (endTime - startTime) + \" milliseconds\");\n\t}\n\treturn isConnected;\n}", "CodeBleu_score": 37.394402116988324}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tif (isConnected()) {\n\t\treturn true;\n\t}\n\tlong startTime = System.currentTimeMillis();\n\tlong timeout = getConnectTimeout();\n\tif (timeout == 0) {\n\t\ttimeout = 1000;\n\t}\n\tlong endTime = startTime + timeout;\n\tboolean connected = false;\n\tif (logger.isLoggable(Level.FINEST)) {\n\t\tlogger.finest(\"Client.blockUntilConnectedOrTimedOut() - start\");\n\t}\n\ttry {\n\t\tinternalBlockUntilConnectedOrTimedOut();\n\t\tconnected = isConnected();\n\t} finally {\n\t\tif (logger.isLoggable(Level.FINEST)) {\n\t\t\tlogger.finest(\"Client.blockUntilConnectedOrTimedOut() - end - connected: \" + connected);\n\t\t}\n\t}\n\tif (connected) {\n\t\treturn true;\n\t}\n\tlong currentTime = System.currentTimeMillis();\n\tif (currentTime >= endTime) {\n\t\treturn false;\n\t}\n\tlong sleepTime = endTime - currentTime;\n\tif (sleepTime > 0) {\n\t\tThread.sleep(sleepTime);\n\t}\n\treturn isConnected();\n}", "CodeBleu_score": 40.21272564769295}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tif (debug)\n\t\tSystem.out.println(\"Client.blockUntilConnectedOrTimedOut() - start\");\n\tlong startTime = System.currentTimeMillis();\n\tboolean connected = false;\n\tsynchronized (this) {\n\t\twhile (!connected) {\n\t\t\tif (debug)\n\t\t\t\tSystem.out.println(\"Client.blockUntilConnectedOrTimedOut() - check state\");\n\t\t\tcheckState();\n\t\t\tif (debug)\n\t\t\t\tSystem.out.println(\"Client.blockUntilConnectedOrTimedOut() - check if connected\");\n\t\t\tconnected = isConnected();\n\t\t\tif (!connected) {\n\t\t\t\tif (debug)\n\t\t\t\t\tSystem.out.println(\"Client.blockUntilConnectedOrTimedOut() - not connected, wait\");\n\t\t\t\twait(1000);\n\t\t\t}\n\t\t}\n\t}\n\tif (debug)\n\t\tSystem.out.println(\"Client.blockUntilConnectedOrTimedOut() - connected, trace\");\n\tstartAdvancedTracer();\n\tif (debug)\n\t\tSystem.out.println(\"Client.blockUntilConnectedOrTimedOut() - end\");\n\tlong endTime = System.currentTimeMillis();\n\tif (debug)\n\t\tSystem.out.println(\"Client.blockUntilConnectedOrTimedOut() - elapsed time: \" + (endTime - startTime) + \"ms\");\n\treturn connected;\n}", "CodeBleu_score": 38.073019796636146}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tlogger.info(\"Attempting to shut down the service with a timeout of {} ms.\", waitForShutdownTimeoutMs);\n\tstarted.set(false);\n\ttry {\n\t\tstate.close(waitForShutdownTimeoutMs);\n\t} catch (IOException e) {\n\t\tif (Thread.interrupted()) {\n\t\t\tlogger.warn(\"The service was interrupted while attempting to close.\", e);\n\t\t} else {\n\t\t\tlogger.error(\"The service encountered an error while attempting to close.\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 63.680645356591405}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tlog.info(\"Attempting to close the service\");\n\tstarted = false;\n\ttry {\n\t\tstate.close(waitForShutdownTimeoutMs);\n\t} catch (IOException e) {\n\t\tcheckInterrupted();\n\t\tlog.error(\"Failed to close the state\", e);\n\t}\n}", "CodeBleu_score": 46.80689543876721}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tif (logger.isDebugEnabled()) {\n\t\tlogger.debug(\"Closing \" + getClass().getSimpleName() + \" with timeout \" + waitForShutdownTimeoutMs);\n\t}\n\tlogger.info(\"Shutting down \" + getClass().getSimpleName());\n\tstarted = false;\n\ttry {\n\t\tclose(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n\t} catch (InterruptedException e) {\n\t\tlogger.error(\"Interrupted while shutting down \" + getClass().getSimpleName() + \". Attempting to close anyways.\", e);\n\t\tclose(1000, TimeUnit.MILLISECONDS);\n\t}\n}", "CodeBleu_score": 40.45989635567132}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tsynchronized(this) {\n\t\tif (this.state == ConnectionState.CONNECTED) {\n\t\t\treturn;\n\t\t}\n\t\tif (this.state == ConnectionState.DISCONNECTED) {\n\t\t\tthrow new IllegalStateException(\"The connection is already disconnected.\");\n\t\t}\n\t\tif (this.state == ConnectionState.DISCONNECTING) {\n\t\t\tthrow new IllegalStateException(\"The connection is already disconnecting.\");\n\t\t}\n\t\tif (this.state == ConnectionState.CONNECTING) {\n\t\t\tthrow new IllegalStateException(\"The connection is already connecting.\");\n\t\t}\n\t\tif (this.state == ConnectionState.RECONNECTING) {\n\t\t\tthrow new IllegalStateException(\"The connection is already reconnecting.\");\n\t\t}\n\t}\n\tCountDownLatch latch = new CountDownLatch(1);\n\tConnectionWatcher watcher = new ConnectionWatcher(latch);\n\tsynchronized(this) {\n\t\tthis.addConnectionWatcher(watcher);\n\t}\n\ttry {\n\t\tboolean connected = latch.await(this.connectionTimeout, TimeUnit.MILLISECONDS);\n\t\tif (!connected) {\n\t\t\tthrow new TimeoutException(\"Timed out waiting for connection.\");\n\t\t}\n\t} finally {\n\t\tsynchronized(this) {\n\t\t\tthis.removeConnectionWatcher(watcher);\n\t\t}\n\t}\n}", "CodeBleu_score": 17.682678983624523}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tsynchronized (this) {\n\t\tif (this.isConnected()) {\n\t\t\treturn;\n\t\t}\n\t\tCountDownLatch latch = new CountDownLatch(1);\n\t\tinternalAddConnectionStateListener(new ConnectionStateListener() {\n\t\t\t@Override\n\t\t\tpublic void onConnectionStateChanged(ConnectionState state) {\n\t\t\t\tif (state == ConnectionState.CONNECTED) {\n\t\t\t\t\tlatch.countDown();\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t\tlong remainingWaitTime = this.connectionTimeout;\n\t\twhile (remainingWaitTime > 0 && !latch.await(remainingWaitTime, TimeUnit.MILLISECONDS)) {\n\t\t\tremainingWaitTime -= this.connectionTimeout;\n\t\t}\n\t\tinternalRemoveConnectionStateListener(this.connectionStateListener);\n\t\tif (remainingWaitTime <= 0) {\n\t\t\tthrow new TimeoutException(\"Connection timed out after \" + this.connectionTimeout + \"ms\");\n\t\t}\n\t}\n}", "CodeBleu_score": 26.593348426585834}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tlong startTime = System.currentTimeMillis();\n\tlong waitTime = 0;\n\tboolean isConnected = false;\n\tCountDownLatch countdown = new CountDownLatch(1);\n\tConnectionStateWatcher watcher = new ConnectionStateWatcher(countdown);\n\tsynchronized(this) {\n\t\tthis.addConnectionStateListener(watcher);\n\t}\n\ttry {\n\t\twhile (!isConnected && waitTime < this.connectionTimeout) {\n\t\t\twaitTime = System.currentTimeMillis() - startTime;\n\t\t\tisConnected = this.isConnected();\n\t\t\tif (!isConnected) {\n\t\t\t\tthis.wait(this.connectionTimeout - waitTime);\n\t\t\t}\n\t\t}\n\t} finally {\n\t\tsynchronized(this) {\n\t\t\tthis.removeConnectionStateListener(watcher);\n\t\t}\n\t}\n\tif (!isConnected) {\n\t\tthrow new TimeoutException(\"Timed out waiting for connection to be established.\");\n\t}\n}", "CodeBleu_score": 27.12172673281989}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tlong sessionId = client.getZooKeeper().getSessionId();\nString sessionPasswd = client.getZooKeeper().getSessionPasswd();\nString sessionPasswdHex = Hex.encodeHexString(sessionPasswd);\nif ( createMode == CreateMode.EPHEMERAL ) {\nif ( foundNode != null ) {\nif ( foundNode.contains(sessionPasswdHex) ) {\n//\n// The node exists and the session ID is valid.\n//\nreturn foundNode;\n}\nelse {\n//\n// The node exists, but the session ID is not valid.\n//\nLOG.warn(\"Node \" + foundNode + \" exists, but the session ID is not valid. It will be recreated.\");\n}\n}\n}\nelse {\n//\n// The node does not exist.\n//\nLOG.warn(\"Node \" + foundNode + \" does not exist.\");\n}\n}", "CodeBleu_score": 36.31783271119306}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tlong sessionId = client.getZooKeeper().getSessionId();\nString sessionNode = null;\nif (createMode == CreateMode.EPHEMERAL) {\nsessionNode = EPHEMERAL_NODES_ROOT + \"/\" + sessionId;\nif (!foundNode.startsWith(sessionNode)) {\n// The session ID has changed\nString oldSessionId = foundNode.substring(foundNode.lastIndexOf(\"/\") + 1);\nString oldSessionNode = EPHEMERAL_NODES_ROOT + \"/\" + oldSessionId;\nif (client.getZooKeeper().exists(oldSessionNode, false) != null) {\n// The old session node still exists. Delete it.\nclient.getZooKeeper().delete(oldSessionNode, -1);\n}\n// Log the change\nLOGGER.info(\"Session ID changed from \" + oldSessionId + \" to \" + sessionId);\n}\n}\nreturn foundNode;\n}", "CodeBleu_score": 40.22539378112056}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tif (foundNode == null) {\nreturn foundNode;\n}\n\nif (createMode == CreateMode.EPHEMERAL) {\nString[] parts = foundNode.split(ZookeeperClient.DELIMITER);\nif (parts.length < 2) {\nthrow new Exception(\"Invalid node name: \" + foundNode);\n}\n\nString sessionId = parts[parts.length - 1];\nif (!sessionId.equals(client.getZooKeeper().getSessionId())) {\nString oldSessionId = parts[parts.length - 2];\nString oldNode = foundNode.substring(0, foundNode.length() - oldSessionId.length() - 1);\nString newSessionId = Long.toHexString(client.getZooKeeper().getSessionId());\nString newNode = oldNode + newSessionId + ZookeeperClient.DELIMITER;\nLOG.warn(\"Session ID has changed from \" + oldSessionId + \" to \" + newSessionId + \". Deleting node \" + oldNode + \" and replacing with \" + newNode);\nclient.getZooKeeper().delete(oldNode, -1);\nfoundNode = newNode;\n}\n}\n\nreturn foundNode;\n}", "CodeBleu_score": 41.52327268437275}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\t// Start an advanced trace for the operation\n\tfinal Trace advancedTrace = traceFactory.createAdvancedTrace(TraceType.ZK_SET_ACL);\n\tadvancedTrace.start();\n\n\t// Create a retry loop\n\tfinal RetryLoop retryLoop = new RetryLoop(config.getSetAclRetryCount(), config.getSetAclRetryDelay());\n\n\t// Execute the operation\n\tStat result = null;\n\twhile (retryLoop.shouldContinue()) {\n\t\ttry {\n\t\t\t// Execute the operation\n\t\t\tresult = zookeeper.setACL(path, aclList, -1);\n\t\t\tadvancedTrace.setSuccess();\n\t\t\tbreak;\n\t\t} catch (final KeeperException.ConnectionLossException e) {\n\t\t\tadvancedTrace.setFailure(e);\n\t\t\tretryLoop.retry();\n\t\t} catch (final KeeperException.InvalidACLException e) {\n\t\t\tadvancedTrace.setFailure(e);\n\t\t\tbreak;\n\t\t} catch (final KeeperException.NoNodeException e) {\n\t\t\tadvancedTrace.setFailure(e);\n\t\t\tbreak;\n\t\t} catch (final KeeperException.NotEmptyException e) {\n\t\t\tadvancedTrace.setFailure(e);\n\t\t\tbreak;\n\t\t} catch (final KeeperException.OperationTimeoutException e) {\n\t\t\tadvancedTrace.setFailure(e);\n\t\t\tretryLoop.retry();\n\t\t} catch (final KeeperException e) {\n\t\t\tadvancedTrace.setFailure(e);\n\t\t\tbreak;\n\t\t} catch (final Exception e) {\n\t\t\tadvancedTrace.setFailure(e);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\t// Record the result\n\tadvancedTrace.addResult(\"path\", path);\n\tadvancedTrace.addResult(\"status\", result);\n\n\t// Commit the trace\n\tadvancedTrace.commit();\n\n\t// Return the result\n\treturn result;\n}", "CodeBleu_score": 32.35126759896814}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tStat stat = null;\n\ttry {\n\t\t// Start an advanced trace for the operation.\n\t\tTrace.start(\"ZooKeeper\", \"setACL\");\n\t\t// Use a retry loop to ensure the ACL is set successfully.\n\t\tRetry retry = new Retry() {\n\t\t\tpublic boolean execute() throws Exception {\n\t\t\t\tstat = zk.setACL(path, aclList, -1);\n\t\t\t\treturn stat != null;\n\t\t\t}\n\t\t};\n\t\tretry.execute();\n\t} finally {\n\t\t// Record the result, including the path and the status, in the trace, which is then committed.\n\t\tTrace.log(\"Path: \" + path + \", Status: \" + (stat == null ? \"FAILED\" : \"SUCCESS\"));\n\t\tTrace.stop();\n\t}\n\treturn stat;\n}", "CodeBleu_score": 33.05268181659701}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\t// Create the ACL list\n\tfinal List<ACL> aclListToUse = aclList != null ? aclList : ZooDefs.Ids.OPEN_ACL_UNSAFE;\n\n\t// Create the trace\n\tfinal Trace trace = Trace.start(\"pathInForeground\", \"path=\" + path, \"acl=\" + aclListToUse);\n\n\t// Start the retry loop\n\tint retryCount = 0;\n\tStat stat = null;\n\twhile (retryCount < 5) {\n\t\t// Create a ZooKeeper instance\n\t\tfinal ZooKeeper zk = new ZooKeeper(zookeeperConnectionString, 10000, this);\n\n\t\t// Try to set the ACL\n\t\ttry {\n\t\t\tstat = zk.setACL(path, aclListToUse, -1);\n\t\t\tbreak;\n\t\t}\n\t\tcatch (final KeeperException.NoNodeException e) {\n\t\t\t// If the node doesn't exist, try to create it\n\t\t\ttry {\n\t\t\t\tzk.create(path, null, aclListToUse, CreateMode.PERSISTENT);\n\t\t\t}\n\t\t\tcatch (final KeeperException.NodeExistsException e2) {\n\t\t\t\t// If the node exists, just ignore it\n\t\t\t}\n\t\t}\n\t\tcatch (final KeeperException.BadVersionException e) {\n\t\t\t// If the version doesn't match, just ignore it\n\t\t}\n\n\t\t// Close the ZooKeeper instance\n\t\tzk.close();\n\n\t\t// Increment the retry count\n\t\tretryCount++;\n\t}\n\n\t// Stop the trace\n\ttrace.stop();\n\n\t// Return the result\n\treturn stat;\n}", "CodeBleu_score": 33.21867006790284}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis(client, membershipPath, thisId, payload, true);\n}", "CodeBleu_score": 11.678679461650034}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tsuper(client, membershipPath, thisId, payload);\n\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\n\t// check the validity of the member ID\n\tif (thisId == null || thisId.length() == 0) {\n\t\tthrow new IllegalArgumentException(\"Invalid member ID\");\n\t}\n\n\t// create a CuratorCache for the membership path\n\tcache = CuratorCacheBuilder.builder(client, membershipPath).build();\n\tcache.listenable().addListener(new MembershipListener(this));\n\tcache.start();\n\n\t// create a PersistentNode with ephemeral mode for the member\n\tPersistentNode node = PersistentNode.builder(client, membershipPath, thisId.getBytes()).setMode(PersistentNode.Mode.EPHEMERAL).build();\n\tnode.start();\n}", "CodeBleu_score": 49.00965607417497}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tsuper(client, thisId);\n\tPreconditions.checkArgument(StringUtils.isNotBlank(membershipPath), \"membershipPath must not be blank\");\n\tPreconditions.checkArgument(StringUtils.isNotBlank(thisId), \"thisId must not be blank\");\n\tPreconditions.checkArgument(payload != null, \"payload must not be null\");\n\tthis.membershipPath = membershipPath;\n\tthis.payload = payload;\n\tthis.memberPath = makePath(membershipPath, thisId);\n\tthis.cache = CuratorCacheBuilder.builder(client, PathChildrenCache.StartMode.POST_INITIALIZED_EVENT).withPath(membershipPath).withCacheData(true).build();\n\tthis.cache.listenable().addListener(new GroupMemberListener(this));\n\tthis.node = PersistentNode.makePersistent(client, memberPath, payload, EnumSet.of(CreateMode.EPHEMERAL));\n\tthis.node.start();\n}", "CodeBleu_score": 41.15465985950605}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\ttry {\n    client.create().inBackground().forPath(path);\n    client.getCuratorListenable().addListener(new CuratorListener() {\n        @Override\n        public void eventReceived(CuratorFramework client, CuratorEvent event) throws Exception {\n            if (event.getType() == CuratorEventType.CREATE) {\n                handleWatchedStage(client, event);\n            }\n        }\n    });\n} catch (Exception e) {\n    e.printStackTrace();\n}\n}", "CodeBleu_score": 37.182694688350416}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\ttry {\nclient.create().creatingParentsIfNeeded().withMode(CreateMode.PERSISTENT).inBackground(\n(client, event) -> {\nif (event.getType() == Watcher.Event.EventType.CREATED) {\nSystem.out.println(\"node created\");\n} else {\nSystem.out.println(\"node deleted\");\n}\n}, executor).forPath(path);\n} catch (Exception e) {\ne.printStackTrace();\n}\n}", "CodeBleu_score": 30.12900940058926}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\ttry {\nclient.create().forPath(path);\nSystem.out.println(\"Node created\");\n} catch (Exception e) {\nSystem.out.println(\"Error creating node\");\ne.printStackTrace();\n}\n}", "CodeBleu_score": 25.43851234244189}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\tList<OpResult> opResults = zooKeeper.multi(ops);\nOpResult opResult = opResults.get(0);\nif (opResult.getErr() != 0) {\nint err = opResult.getErr();\nif (err == KeeperException.Code.NONODE.intValue()) {\nthrow new KeeperException(KeeperException.Code.NONODE);\n} else if (err == KeeperException.Code.BADVERSION.intValue()) {\nthrow new KeeperException(KeeperException.Code.BADVERSION);\n} else if (err == KeeperException.Code.NOAUTH.intValue()) {\nthrow new KeeperException(KeeperException.Code.NOAUTH);\n} else if (err == KeeperException.Code.BADARGUMENTS.intValue()) {\nthrow new KeeperException(KeeperException.Code.BADARGUMENTS);\n} else if (err == KeeperException.Code.NOTEMPTY.intValue()) {\nthrow new KeeperException(KeeperException.Code.NOTEMPTY);\n} else if (err == KeeperException.Code.SESSIONEXPIRED.intValue()) {\nthrow new KeeperException(KeeperException.Code.SESSIONEXPIRED);\n} else if (err == KeeperException.Code.INVALIDCALLBACK.intValue()) {\nthrow new KeeperException(KeeperException.Code.INVALIDCALLBACK);\n} else if (err == KeeperException.Code.INVALIDACLS.intValue()) {\nthrow new KeeperException(KeeperException.Code.INVALIDACLS);\n} else if (err == KeeperException.Code.AUTHFAILED.intValue()) {\nthrow new KeeperException(KeeperException.Code.AUTHFAILED);\n} else if (err == KeeperException.Code.SESSIONMOVED.intValue()) {\nthrow new KeeperException(KeeperException.Code.SESSIONMOVED);\n} else {\nthrow new KeeperException(KeeperException.Code.get(err));\n}\n}\nreturn opResults;\n}", "CodeBleu_score": 32.25599058842328}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> opResultList = zk.multi(ops);\n\tOpResult opResult = opResultList.get(0);\n\tif (opResult.getErr() != 0) {\n\t\tString errMsg = opResult.getErrStr();\n\t\tif (opResult.getErr() == KeeperException.Code.NONODE.intValue()) {\n\t\t\terrMsg = errMsg + \" (NONODE)\";\n\t\t}\n\t\tthrow new KeeperException(KeeperException.Code.get(opResult.getErr()), errMsg);\n\t}\n\treturn opResultList;\n}", "CodeBleu_score": 34.24620020698986}, {"code": "private List<OpResult> doOperation() throws Exception{\n\tList<OpResult> opResults = multi(ops);\nOpResult opResult = opResults.get(0);\nint errCode = opResult.getErr();\nif (errCode != 0) {\nif (errCode == KeeperException.Code.NONODE.intValue()) {\nthrow new KeeperException.NoNodeException();\n} else if (errCode == KeeperException.Code.NODEEXISTS.intValue()) {\nthrow new KeeperException.NodeExistsException();\n} else if (errCode == KeeperException.Code.NOTEMPTY.intValue()) {\nthrow new KeeperException.NotEmptyException();\n} else {\nthrow new KeeperException(KeeperException.Code.get(errCode));\n}\n}\nreturn opResults;\n}", "CodeBleu_score": 38.49619381844311}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\n// Retrieve all service names and their corresponding instances from the given ServiceDiscovery instance.\nList<String> serviceNames = serviceDiscovery.queryForNames();\n\n// If no service names are registered, catch the NoNodeException and print an error message.\nif (serviceNames.isEmpty()) {\nSystem.err.println(\"No service names are registered.\");\nreturn;\n}\n\n// For each service name, print the service name and its instances.\nfor (String serviceName : serviceNames) {\n\n// Retrieve the instances of the service name from the given ServiceDiscovery instance.\nList<InstanceDetails> instances = serviceDiscovery.queryForInstances(serviceName);\n\n// If no instances are registered, catch the NoNodeException and print an error message.\nif (instances.isEmpty()) {\nSystem.err.println(\"No instances are registered for the service name \" + serviceName + \".\");\ncontinue;\n}\n\n// Print the service name and its instances.\nSystem.out.println(\"Instances for service name \" + serviceName + \":\");\nfor (InstanceDetails instance : instances) {\noutputInstance(instance);\n}\n}\n\n// Close the ServiceDiscovery instance quietly.\nserviceDiscovery.closeQuietly();\n}", "CodeBleu_score": 54.59286975622191}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\n// Retrieve all service names and their corresponding instances from the given ServiceDiscovery instance\nMap<String, Collection<InstanceDetails>> queryForNames = serviceDiscovery.queryForNames();\n\n// Print each service name and its instances\nfor (Map.Entry<String, Collection<InstanceDetails>> entry : queryForNames.entrySet()) {\nSystem.out.println(\"Service name: \" + entry.getKey());\n\n// Print each instance\nfor (InstanceDetails instance : entry.getValue()) {\nSystem.out.println(\"Instance: \" + instance.getInstanceId());\n}\n}\n\n// Catch the NoNodeException and print an error message\n}", "CodeBleu_score": 27.354661831090997}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\n// Retrieve the list of service names\nList<String> serviceNames = serviceDiscovery.queryForNames();\n\n// If no service names are registered, print an error message\nif (serviceNames.isEmpty()) {\nSystem.out.println(\"No services registered\");\n} else {\n\n// For each service name, query for its instances\nfor (String serviceName : serviceNames) {\n\n// Retrieve the list of instances for the service\nList<InstanceDetails> instances = serviceDiscovery.queryForInstances(serviceName);\n\n// Print the service name and its instances\nSystem.out.println(\"Service Name: \" + serviceName);\nfor (InstanceDetails instance : instances) {\nSystem.out.println(\"\\tInstance Id: \" + instance.getInstanceId());\nSystem.out.println(\"\\tHost: \" + instance.getHostName());\nSystem.out.println(\"\\tPort: \" + instance.getPort());\nSystem.out.println(\"\\tSecure Port: \" + instance.getSecurePort());\nSystem.out.println(\"\\tScheme: \" + instance.getScheme());\n}\n}\n}\n\n// Close the ServiceDiscovery instance quietly\nserviceDiscovery.closeQuietly();\n}", "CodeBleu_score": 46.001549068129776}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tList<String> filteredChildren = children.stream().filter(child -> !child.equals(READY_NODE)).collect(Collectors.toList());\n\tfilteredChildren.sort(Comparator.naturalOrder());\n\treturn filteredChildren;\n}", "CodeBleu_score": 34.22554460100965}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tList<String> filteredChildren = new ArrayList<String>();\n\tfor (String child : children) {\n\t\tif (!child.equals(READY_NODE)) {\n\t\t\tfilteredChildren.add(child);\n\t\t}\n\t}\n\tCollections.sort(filteredChildren);\n\treturn filteredChildren;\n}", "CodeBleu_score": 29.59661396283041}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tchildren.remove(READY_NODE);\n\tchildren.sort();\n\treturn children;\n}", "CodeBleu_score": 15.732405714756245}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk != null) {\n\t\tzk.close();\n\t}\n\tzk = new ZooKeeper(newHost, sessionTimeout, this);\n\tzk.exists(path, false);\n\tzk.sync(path, false);\n\tif (readOnly) {\n\t\tzk.setACL(path, Ids.CREATOR_ALL_ACL, -1);\n\t}\n}", "CodeBleu_score": 25.999261846760895}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk != null) {\n\t\tzk.close();\n\t\tzk = null;\n\t}\n\tzk = new ZooKeeper(newHost, 3000, this);\n\tif (read_only) {\n\t\tzk.setACL(new ArrayList<ACL>(), ZooDefs.Ids.READ_ACL_UNSAFE);\n\t}\n}", "CodeBleu_score": 25.91175403014072}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\t// Close the existing connection if there is one\n\tif (zk != null) {\n\t\tzk.close();\n\t\tzk = null;\n\t}\n\t// Create a new ZooKeeper instance\n\tzk = new ZooKeeper(newHost, timeout, this);\n\t// Wait until the ZooKeeper instance is connected\n\twhile (!zk.getState().isConnected()) {\n\t\tThread.sleep(100);\n\t}\n\t// If the connection is read-only, set the read-only flag\n\tif (readOnly) {\n\t\tzk.setReadOnlyMode();\n\t}\n}", "CodeBleu_score": 30.123866214829896}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acls = new ArrayList<ACL>();\nif (aclString == null) {\nreturn acls;\n}\nString[] aclsStrings = aclString.split(\",\");\nfor (String aclString : aclsStrings) {\nString[] aclComponents = aclString.split(\":\");\nif (aclComponents.length != 3) {\nLOG.error(\"Invalid ACL: \" + aclString);\ncontinue;\n}\ntry {\nacls.add(new ACL(aclComponents[0], aclComponents[1], aclComponents[2]));\n} catch (IllegalArgumentException e) {\nLOG.error(\"Invalid ACL: \" + aclString);\n}\n}\nreturn acls;\n}", "CodeBleu_score": 22.755907860848854}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acls = new ArrayList<ACL>();\nString[] aclStrings = aclString.split(\",\");\nfor (String aclStr : aclStrings) {\nString[] parts = aclStr.split(\":\");\nif (parts.length != 3) {\nLOG.error(\"Invalid ACL syntax: \" + aclStr);\ncontinue;\n}\nACL acl = new ACL(parts[0]);\nacl.setId(new Id(parts[1]));\nacl.setPerms(Short.parseShort(parts[2], 8));\nacls.add(acl);\n}\nreturn acls;\n}", "CodeBleu_score": 24.672138299161173}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acls = new ArrayList<ACL>();\nString[] aclStrings = aclString.split(\",\");\nfor (String aclString : aclStrings) {\nif (aclString.isEmpty()) {\ncontinue;\n}\n\nString[] parts = aclString.split(\":\");\nif (parts.length != 3) {\nLOG.error(\"Invalid ACL syntax: \" + aclString);\ncontinue;\n}\n\ntry {\nacls.add(new ACL(parts[0], parts[1], parts[2]));\n} catch (IllegalArgumentException e) {\nLOG.error(\"Invalid ACL syntax: \" + aclString);\n}\n}\nreturn acls;\n}", "CodeBleu_score": 22.960359253857344}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tif (pathList == null) {\nthrow new IllegalArgumentException(\"Path list cannot be null\");\n}\nif (pathList.size() < 20) {\nfor (String path : pathList) {\ndelete(serverId, path);\n}\n} else {\ndeleteAsync(serverId, pathList);\n}\n}", "CodeBleu_score": 52.89318945068684}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tif (pathList == null) {\nthrow new IllegalArgumentException(\"pathList is null\");\n}\nif (pathList.size() < 20) {\nfor (String path : pathList) {\ndelete(serverId, path);\n}\n} else {\ndeleteAsync(serverId, pathList);\n}\n}", "CodeBleu_score": 52.72722668995527}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tif (pathList == null || pathList.isEmpty()) {\nthrow new IllegalArgumentException(\"pathList must not be null or empty\");\n}\nif (pathList.size() < 20) {\nfor (String path : pathList) {\ndelete(serverId, path);\n}\n} else {\ndeleteAsync(serverId, pathList);\n}\n}", "CodeBleu_score": 53.45774771158464}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tTerminal terminal = new Terminal(id, url, null, null);\n\n// Write connecting message to writer\nwriter.write(String.format(\"Connecting to Zookeeper at %s\n\", url));\n\n// Create connection\nCuratorZookeeperConnectionFactory factory = new CuratorZookeeperConnectionFactory(url);\nZookeeperConnection connection = factory.create();\n\n// Write success message to writer\nwriter.write(String.format(\"Connected to Zookeeper at %s\n\", url));\n\n// Create ZooKeeperMain\nZooKeeperMain zooKeeperMain = new ZooKeeperMain(connection);\n\n// Return new terminal with id, url, connection, and ZooKeeperMain\nreturn new Terminal(id, url, connection, zooKeeperMain);\n}", "CodeBleu_score": 36.81177289047221}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t\tif (id == null) {\n\t\tthrow new IllegalArgumentException(\"id cannot be null\");\n\t}\n\tif (url == null) {\n\t\tthrow new IllegalArgumentException(\"url cannot be null\");\n\t}\n\tif (writer == null) {\n\t\tthrow new IllegalArgumentException(\"writer cannot be null\");\n\t}\n\twriter.write(\"Connecting to Zookeeper instance at \" + url + \"...\n\");\n\tCuratorZookeeperConnectionFactory connectionFactory = new CuratorZookeeperConnectionFactory(url);\n\tZookeeperClient client = connectionFactory.create();\n\twriter.write(\"Successfully connected to Zookeeper instance at \" + url + \".\n\");\n\tZooKeeperMain main = new ZooKeeperMain(client);\n\treturn new Terminal(id, url, client, main);\n}", "CodeBleu_score": 33.71379531189551}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t\nTerminal terminal = new Terminal(id, url);\n\n// Write connecting message\nwriter.write(\"Connecting to Zookeeper at \" + url + \"...\n\");\n\n// Create connection\nCuratorZookeeperConnection connection = new CuratorZookeeperConnectionFactory().create(url);\n\n// Write success message\nwriter.write(\"Connected to Zookeeper at \" + url + \"!\n\");\n\n// Create ZooKeeperMain instance\nZooKeeperMain zkMain = new ZooKeeperMain(connection);\n\n// Create Terminal instance\nterminal.setConnection(connection);\nterminal.setZooKeeperMain(zkMain);\n\nreturn terminal;\n\n}", "CodeBleu_score": 34.22955642506231}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\t\tint retries = 0;\n\twhile (!isConnected() && retries < 6) {\n\t\ttry {\n\t\t\tlog.info(\"Attempting to connect to SSH tunnel on port \" + tunnelPort + \"...\");\n\t\t\tconnect();\n\t\t\tlog.info(\"Connected to SSH tunnel on port \" + tunnelPort);\n\t\t\treturn;\n\t\t} catch (Exception e) {\n\t\t\tlog.info(\"Failed to connect to SSH tunnel on port \" + tunnelPort + \": \" + e.getMessage());\n\t\t\tclose();\n\t\t\tretries++;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException e1) {\n\t\t\t\tlog.warn(\"Interrupted while waiting to retry SSH tunnel connection\", e1);\n\t\t\t\tclose();\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tif (!isConnected()) {\n\t\tthrow new IllegalStateException(\"Failed to connect to SSH tunnel on port \" + tunnelPort + \" after \" + retries + \" attempts\");\n\t}\n}", "CodeBleu_score": 46.32352846703034}, {"code": "public void blockUntilConnected(){\n\t\tint retries = 6;\n\twhile (retries-- > 0) {\n\t\ttry {\n\t\t\tif (isConnected()) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tclose();\n\t\t\tthrow new IllegalStateException(\"Failed to connect to SSH tunnel\", e);\n\t\t}\n\t\ttry {\n\t\t\tlog.info(\"Attempting to connect to SSH tunnel ({} retries remaining)\", retries);\n\t\t\tconnect();\n\t\t} catch (Exception e) {\n\t\t\tclose();\n\t\t\tthrow new IllegalStateException(\"Failed to connect to SSH tunnel\", e);\n\t\t}\n\t\ttry {\n\t\t\tThread.sleep(1000);\n\t\t} catch (InterruptedException e) {\n\t\t\tclose();\n\t\t\tthrow new IllegalStateException(\"Interrupted while waiting for SSH tunnel to connect\", e);\n\t\t}\n\t}\n\tclose();\n\tthrow new IllegalStateException(\"Failed to connect to SSH tunnel\");\n}", "CodeBleu_score": 34.693972285047}, {"code": "public void blockUntilConnected(){\n\t\tint retryCount = 0;\n\twhile (!isConnected() && retryCount < 6) {\n\t\ttry {\n\t\t\tlog.info(\"Attempting to connect to \" + getHost() + \":\" + getPort());\n\t\t\tconnect();\n\t\t\tlog.info(\"Successfully connected to \" + getHost() + \":\" + getPort());\n\t\t\tbreak;\n\t\t} catch (JSchException e) {\n\t\t\tlog.info(\"Failed to connect to \" + getHost() + \":\" + getPort());\n\t\t\tretryCount++;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException e1) {\n\t\t\t\t// Ignore\n\t\t\t}\n\t\t}\n\t}\n\tif (!isConnected()) {\n\t\tlog.error(\"Failed to connect to \" + getHost() + \":\" + getPort());\n\t\tclose();\n\t\tthrow new IllegalStateException(\"Failed to connect to \" + getHost() + \":\" + getPort());\n\t}\n}", "CodeBleu_score": 38.56910996782676}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"Error deleting node: \" + e.getMessage());\n\t\tthrow new IllegalStateException(\"Error deleting node: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 56.21626232689694}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.delete(serverId, pathList);\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"An error occurred while deleting nodes from server {}.\", serverId);\n\t\tthrow new IllegalStateException(\"An error occurred while deleting nodes from server \" + serverId + \".\", e);\n\t}\n}", "CodeBleu_score": 64.73818655588217}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.delete(serverId, pathList);\n\t}\n\tcatch (Exception e) {\n\t\tlogger.error(\"Exception caught in deleteNode()\", e);\n\t\tthrow new IllegalStateException(\"Exception caught in deleteNode()\", e);\n\t}\n}", "CodeBleu_score": 68.42510326313712}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\t\t// TODO: Implement this method\n}", "CodeBleu_score": 3.3910150352935258}, {"code": "public void disconnect(String id){\n\t\tif (id == null) {\n\t\tthrow new IllegalArgumentException(\"The server ID cannot be null\");\n\t}\n\tServerTreeItem server = serverCache.get(id);\n\tif (server == null) {\n\t\tthrow new IllegalArgumentException(\"The server with ID \" + id + \" is not in the cache\");\n\t}\n\tserverCache.remove(id);\n\ttry {\n\t\tserver.disconnect();\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n}", "CodeBleu_score": 32.12972426978929}, {"code": "public void disconnect(String id){\n\t\tServerConfiguration serverConfiguration = getServerConfiguration(id);\n\tif (serverConfiguration != null) {\n\t\ttry {\n\t\t\tserverConfiguration.disconnect();\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(e.getMessage(), e);\n\t\t\tAlert alert = new Alert(AlertType.ERROR, e.getMessage(), ButtonType.OK);\n\t\t\talert.showAndWait();\n\t\t} finally {\n\t\t\tTreeItem<ServerConfiguration> serverTreeItem = serverTree.getRoot().getChildren().stream().filter(\n\t\t\t\ttreeItem -> treeItem.getValue().getId().equals(id)).findFirst().orElse(null);\n\t\t\tif (serverTreeItem != null) {\n\t\t\t\tserverTree.getRoot().getChildren().remove(serverTreeItem);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 36.00302294616531}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tfinal Server server = serverService.getServer(serverId);\n\tif (server == null) {\n\t\tthrow new IllegalArgumentException(\"Server with id '\" + serverId + \"' does not exist\");\n\t}\n\tfinal String connectionUrl = getConnectionUrl(server);\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 27.83074452794282}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tServer server = getServer(serverId);\n\tString connectionUrl = getConnectionUrl(server);\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 18.382766808669125}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tServer server = getServer(serverId);\n\tif (server == null) {\n\t\tthrow new IllegalArgumentException(\"No server with ID \" + serverId + \" found\");\n\t}\n\tString connectionUrl = getConnectionUrl(server, stream);\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl);\n}", "CodeBleu_score": 23.302872110755253}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tzk.command(id, command);\n\t} catch (ZkMarshallingError e) {\n\t\tSystem.out.println(\"Error executing command '\" + command + \"' on server \" + id + \": \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 42.94444903248278}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tzk = new ZooKeeper(id, 3000, this);\n\t\tzk.addAuthInfo(\"digest\", \"admin:admin\".getBytes());\n\t\tzk.create(\"/command\", command.getBytes(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t} catch (IOException e) {\n\t\tSystem.out.println(\"Unable to connect to server \" + id + \" with command \" + command);\n\t}\n}", "CodeBleu_score": 36.57884182193739}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tzk = new ZooKeeper(\"localhost:\" + id, 1500, this);\n\t\tzk.addAuthInfo(\"digest\", \"admin:admin\".getBytes());\n\t\tzk.create(\"/zk-book\", \"123\".getBytes(), Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);\n\t\tzk.create(\"/zk-book/c1\", \"123\".getBytes(), Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);\n\t\tzk.create(\"/zk-book/c2\", \"123\".getBytes(), Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);\n\t\tzk.create(\"/zk-book/c3\", \"123\".getBytes(), Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);\n\t\tzk.create(\"/zk-book/c4\", \"123\".getBytes(), Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);\n\t\tzk.create(\"/zk-book/c5\", \"123\".getBytes(), Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);\n\t\tzk.create(\"/zk-book/c6\", \"123\".getBytes(), Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);\n\t\tzk.create(\"/zk-book/c7\", \"123\".getBytes(), Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);\n\t\tzk.create(\"/zk-book/c8\", \"123\".getBytes(), Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);\n\t\tzk.create(\"/zk-book/c9\", \"123\".getBytes(), Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);\n\t\tzk.create(\"/zk-book/c10\", \"123\".getBytes(), Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);\n\t\tzk.create(\"/zk-book/c11\", \"123\".getBytes(), Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);\n\t\tzk.create(\"/zk-book/c12\", \"123\".getBytes(), Ids.CREATOR_", "CodeBleu_score": 20.49893611153696}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\tProperties properties = new Properties();\ntry {\nFile file = new File(ZOOKEEPER_PROPERTIES_FILE_PATH);\nif (file.exists()) {\nproperties.load(new FileInputStream(file));\nlogger.info(\"Loaded Zookeeper properties from \" + ZOOKEEPER_PROPERTIES_FILE_PATH);\n} else {\nlogger.error(\"Unable to load Zookeeper properties from \" + ZOOKEEPER_PROPERTIES_FILE_PATH + \" as the file does not exist\");\n}\n} catch (IOException e) {\nlogger.error(\"Unable to load Zookeeper properties from \" + ZOOKEEPER_PROPERTIES_FILE_PATH, e);\n}\nreturn properties;\n}", "CodeBleu_score": 42.9903598147168}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties props = new Properties();\n\tString path = System.getProperty(\"zookeeper.properties.file\");\n\tif (path == null) {\n\t\tSystem.err.println(\"zookeeper.properties.file system property not set\");\n\t\treturn props;\n\t}\n\tFile file = new File(path);\n\tif (!file.exists()) {\n\t\tSystem.err.println(\"zookeeper.properties.file file does not exist\");\n\t\treturn props;\n\t}\n\ttry {\n\t\tprops.load(new FileInputStream(file));\n\t} catch (IOException e) {\n\t\tSystem.err.println(\"Error loading zookeeper.properties.file file\");\n\t\treturn props;\n\t}\n\tSystem.out.println(\"Loaded zookeeper.properties.file file\");\n\treturn props;\n}", "CodeBleu_score": 38.416486162024576}, {"code": "public Properties loadZookeeperSystemProperties(){\n\tProperties props = new Properties();\n\ntry {\nprops.load(new FileInputStream(ZOOKEEPER_PROPERTIES_FILE));\nSystem.out.println(\"Loaded system properties from \" + ZOOKEEPER_PROPERTIES_FILE);\n} catch (FileNotFoundException e) {\nSystem.out.println(\"Unable to find \" + ZOOKEEPER_PROPERTIES_FILE + \" file, using defaults\");\n} catch (IOException e) {\nSystem.out.println(\"Unable to load \" + ZOOKEEPER_PROPERTIES_FILE + \" file, using defaults\");\n}\n\nreturn props;\n}", "CodeBleu_score": 31.158647068791034}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\t\ttry {\n\t\tProperties props = new Properties();\n\t\tprops.load(new StringReader(content));\n\t\ttry {\n\t\t\tprops.store(new FileOutputStream(SYS_PROP_PATH), \"Zookeeper system properties\");\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Error saving Zookeeper system properties\", e);\n\t\t\tNotifications.create().title(\"Error saving Zookeeper system properties\").text(\"Error saving Zookeeper system properties: \" + e.getMessage()).showError();\n\t\t}\n\t} catch (IOException e) {\n\t\tlog.error(\"Error loading Zookeeper system properties\", e);\n\t\tNotifications.create().title(\"Error loading Zookeeper system properties\").text(\"Error loading Zookeeper system properties: \" + e.getMessage()).showError();\n\t}\n}", "CodeBleu_score": 37.08046675155824}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\ttry {\n\t\tProperties properties = new Properties();\n\t\tproperties.load(new StringReader(content));\n\t\tif (properties.isEmpty()) {\n\t\t\treturn;\n\t\t}\n\t\ttry {\n\t\t\tFileOutputStream out = new FileOutputStream(SYS_PROP_PATH);\n\t\t\tproperties.store(out, \"Zookeeper system properties\");\n\t\t\tout.close();\n\t\t\tshowNotification(\"System Properties Saved\", \"System properties saved to \" + SYS_PROP_PATH);\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Unable to save system properties to file\", e);\n\t\t\tshowNotification(\"Unable to save system properties\", \"Unable to save system properties to \" + SYS_PROP_PATH + \" due to \" + e.getMessage());\n\t\t}\n\t} catch (IOException e) {\n\t\tlog.error(\"Unable to load system properties from content\", e);\n\t\tshowNotification(\"Unable to load system properties\", \"Unable to load system properties from content due to \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 39.196714855246015}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\ttry {\n\t\tProperties properties = new Properties();\n\t\tproperties.load(new StringReader(content));\n\t\tsaveZookeeperSystemProperties(properties);\n\t} catch (IOException e) {\n\t\tlog.error(\"Error loading Zookeeper system properties\", e);\n\t\tshowErrorDialog(\"Error loading Zookeeper system properties\", e);\n\t}\n}", "CodeBleu_score": 19.142166164351927}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\t\ttry {\n\t\tBufferedReader br = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tStringBuilder sb = new StringBuilder();\n\t\tString line;\n\t\twhile ((line = br.readLine()) != null) {\n\t\t\tsb.append(line);\n\t\t}\n\t\tcleanup(client);\n\t\treturn sb.toString();\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Error reading response from client\", e);\n\t}\n}", "CodeBleu_score": 50.81250041279226}, {"code": "private String response(Socket client){\n\t\ttry {\n\t\tStringBuilder sb = new StringBuilder();\n\t\tBufferedReader br = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tString line = br.readLine();\n\t\twhile (line != null) {\n\t\t\tsb.append(line);\n\t\t\tline = br.readLine();\n\t\t}\n\t\tbr.close();\n\t\tclient.close();\n\t\treturn sb.toString();\n\t} catch (Exception e) {\n\t\tthrow new IllegalStateException(\"Could not read from socket\", e);\n\t}\n}", "CodeBleu_score": 49.649156830877594}, {"code": "private String response(Socket client){\n\t\ttry {\n\t\tBufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tStringBuilder sb = new StringBuilder();\n\t\tString line;\n\t\twhile ((line = in.readLine()) != null) {\n\t\t\tsb.append(line);\n\t\t}\n\t\tcleanup(client);\n\t\treturn sb.toString();\n\t} catch (Exception e) {\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 56.09571664436128}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\ttry {\n\t\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(params.getConnectString(), params.getSessionTimeoutMs(), params.getConnectionTimeoutMs(), new RetryNTimes(params.getRetryCount(), params.getRetryIntervalMs()));\n\t\tcuratorFramework.start();\n\t\tcuratorFramework.blockUntilConnected(params.getConnectionTimeoutMs(), TimeUnit.MILLISECONDS);\n\t\treturn new CuratorZookeeperConnection(curatorFramework);\n\t} catch (Exception e) {\n\t\tclose(null);\n\t\tthrow new ZookeeperException(\"Unable to connect to zookeeper\", e);\n\t}\n}", "CodeBleu_score": 43.53988783348488}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tif (params == null) {\nthrow new IllegalArgumentException(\"params must not be null\");\n}\n\nString connectionString = params.getConnectionString();\nif (StringUtils.isEmpty(connectionString)) {\nthrow new IllegalArgumentException(\"connectionString must not be null or empty\");\n}\n\nint sessionTimeoutMs = params.getSessionTimeoutMs();\nif (sessionTimeoutMs <= 0) {\nthrow new IllegalArgumentException(\"sessionTimeoutMs must be greater than 0\");\n}\n\nint connectionTimeoutMs = params.getConnectionTimeoutMs();\nif (connectionTimeoutMs <= 0) {\nthrow new IllegalArgumentException(\"connectionTimeoutMs must be greater than 0\");\n}\n\nint retryBaseSleepTimeMs = params.getRetryBaseSleepTimeMs();\nif (retryBaseSleepTimeMs <= 0) {\nthrow new IllegalArgumentException(\"retryBaseSleepTimeMs must be greater than 0\");\n}\n\nint retryMaxAttempts = params.getRetryMaxAttempts();\nif (retryMaxAttempts <= 0) {\nthrow new IllegalArgumentException(\"retryMaxAttempts must be greater than 0\");\n}\n\n// Create the CuratorFramework instance\nCuratorFramework client = CuratorFrameworkFactory.newClient(connectionString, sessionTimeoutMs, connectionTimeoutMs, new ExponentialBackoffRetry(retryBaseSleepTimeMs, retryMaxAttempts));\n\n// Start the client\nclient.start();\n\n// Wait for the client to be connected\nclient.blockUntilConnected();\n\n// Return the new connection\nreturn new CuratorZookeeperConnection(client);\n}", "CodeBleu_score": 35.22400056655975}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\ttry {\n\t\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n\t\t\t\t.connectString(params.getConnectString())\n\t\t\t\t.retryPolicy(new ExponentialBackoffRetry(1000, 3))\n\t\t\t\t.namespace(params.getNamespace())\n\t\t\t\t.build();\n\t\tcuratorFramework.start();\n\t\tcuratorFramework.blockUntilConnected(5, TimeUnit.SECONDS);\n\t\treturn new CuratorZookeeperConnection(curatorFramework);\n\t} catch (Exception e) {\n\t\tthrow new ZookeeperConnectionException(\"Could not connect to Zookeeper\", e);\n\t}\n}", "CodeBleu_score": 46.61818506739872}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\tif (listeners == null || listeners.isEmpty()) {\n\t\tlogger.warn(\"No listeners specified for synchronization\");\n\t\treturn;\n\t}\n\n\tString zkConnectionString = getCurrentConnectionString();\n\tif (zkConnectionString == null) {\n\t\tlogger.warn(\"No Zookeeper connection string specified\");\n\t\treturn;\n\t}\n\n\tif (isSyncInProgress(zkConnectionString)) {\n\t\tlogger.info(\"Synchronization already in progress\");\n\t\treturn;\n\t}\n\n\tlogger.info(\"Starting synchronization of Zookeeper nodes\");\n\taddListener(new CuratorTreeCacheListener(listeners));\n\ttry {\n\t\tCuratorFramework client = getZookeeperClient(zkConnectionString);\n\t\tclient.start();\n\t\tTreeCache cache = new TreeCache(client, \"/\");\n\t\tcache.start();\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error synchronizing Zookeeper nodes\", e);\n\t}\n}", "CodeBleu_score": 41.3116471158371}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\tif (listeners == null || listeners.isEmpty()) {\n\t\tthrow new IllegalArgumentException(\"The list of ZookeeperNodeListeners must not be null or empty\");\n\t}\n\tif (log.isInfoEnabled()) {\n\t\tlog.info(\"Starting synchronization of Zookeeper nodes\");\n\t}\n\ttry {\n\t\tString connectionString = getCurrentConnectionString();\n\t\tif (treeCache == null) {\n\t\t\ttreeCache = CuratorTreeCache.getInstance(connectionString, new CuratorTreeCacheListener(listeners));\n\t\t\ttreeCache.start();\n\t\t} else {\n\t\t\tlog.info(\"Zookeeper synchronization is already in progress\");\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(\"Failed to synchronize Zookeeper nodes\", e);\n\t}\n}", "CodeBleu_score": 43.93031978465778}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tString currentConnectionString = getCurrentConnectionString();\nif (!isSyncInProgress(currentConnectionString)) {\nLOGGER.info(\"Starting sync of Zookeeper nodes for connection string: \" + currentConnectionString);\naddListener(new CuratorTreeCacheListener(listeners));\ntry {\nTreeCache treeCache = getTreeCache();\ntreeCache.start();\n} catch (Exception e) {\nLOGGER.error(\"Error starting TreeCache\", e);\n}\n} else {\nLOGGER.info(\"Sync already in progress for connection string: \" + currentConnectionString);\n}\n}", "CodeBleu_score": 35.99807210896035}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.getListenable().addListener(listener);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n}", "CodeBleu_score": 69.20128486956945}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tif (zkClient == null) {\n\t\tthrow new Exception(\"Zookeeper client not connected.\");\n\t}\n\tif (path == null) {\n\t\tthrow new Exception(\"Path is null.\");\n\t}\n\tif (listener == null) {\n\t\tthrow new Exception(\"Listener is null.\");\n\t}\n\tif (path.length() == 0) {\n\t\tthrow new Exception(\"Path is empty.\");\n\t}\n\tif (path.charAt(0) != '/') {\n\t\tthrow new Exception(\"Path does not start with '/'.\");\n\t}\n\tPathChildrenCache cache = new PathChildrenCache(zkClient, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 51.64491479583147}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.61037577866037}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t\tSystem.out.println(\"Unregistering service\");\n\ttry {\n\t\tclient.start();\n\t\tSystem.out.println(\"Connected to Zookeeper\");\n\t\tfor (String path : paths) {\n\t\t\ttry {\n\t\t\t\tclient.delete().deletingChildrenIfNeeded().forPath(path);\n\t\t\t\tSystem.out.println(\"Deleted \" + path);\n\t\t\t} catch (Exception e) {\n\t\t\t\tSystem.out.println(\"Could not delete \" + path);\n\t\t\t\tSystem.out.println(e.getMessage());\n\t\t\t}\n\t\t}\n\t} catch (Exception e) {\n\t\tSystem.out.println(\"Could not connect to Zookeeper\");\n\t\tSystem.out.println(e.getMessage());\n\t} finally {\n\t\ttry {\n\t\t\tclient.close();\n\t\t} catch (IOException e) {\n\t\t\tSystem.out.println(\"Could not close Zookeeper client\");\n\t\t\tSystem.out.println(e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 38.440721677679825}, {"code": "public void unregisterService(){\n\t\tSystem.out.println(\"Unregistering services...\");\n\ttry {\n\t\tclient.start();\n\t\tSystem.out.println(\"Connected to Zookeeper\");\n\t\tfor (String path : paths) {\n\t\t\tSystem.out.println(\"Deleting \" + path);\n\t\t\tdeletePath(path);\n\t\t}\n\t\tSystem.out.println(\"Services unregistered\");\n\t} catch (Exception e) {\n\t\tSystem.out.println(\"Error unregistering services: \" + e.getMessage());\n\t} finally {\n\t\tclose();\n\t}\n}", "CodeBleu_score": 39.55573336666202}, {"code": "public void unregisterService(){\n\t\tSystem.out.println(\"Unregistering service...\");\n\ttry {\n\t\tList<String> paths = zkClient.getChildren().forPath(path);\n\t\tfor (String child : paths) {\n\t\t\tdeletePath(child);\n\t\t}\n\t} catch (Exception e) {\n\t\tSystem.out.println(e.getMessage());\n\t} finally {\n\t\tclose();\n\t}\n}", "CodeBleu_score": 26.745929101593525}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\t\tif (listener == null) {\n\t\tthrow new IllegalArgumentException(\"listener can't be null\");\n\t}\n\tif (isShutdown.get()) {\n\t\tthrow new IllegalStateException(\"The client is already shutdown\");\n\t}\n\tif (isStarting.get()) {\n\t\tLOGGER.warn(\"The client is still starting, the listener will be added once the client is ready\");\n\t\tsynchronized (this) {\n\t\t\tif (isStarting.get()) {\n\t\t\t\tlisteners.add(listener);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n\tif (isExpired.get()) {\n\t\tLOGGER.warn(\"The client has expired, the listener will not be added\");\n\t\treturn;\n\t}\n\tif (isClosed.get()) {\n\t\tLOGGER.warn(\"The client has been closed, the listener will not be added\");\n\t\treturn;\n\t}\n\tif (isConnected.get()) {\n\t\tLOGGER.info(\"The client is already connected, the listener will be added\");\n\t}\n\tmakeClientReady().thenAccept(v -> {\n\t\tif (isClosed.get()) {\n\t\t\tLOGGER.warn(\"The client has been closed, the listener will not be added\");\n\t\t\treturn;\n\t\t}\n\t\tif (isConnected.get()) {\n\t\t\tLOGGER.info(\"The client is already connected, the listener will be added\");\n\t\t}\n\t\tsynchronized (this) {\n\t\t\tif (isClosed.get()) {\n\t\t\t\tLOGGER.warn(\"The client has been closed, the listener will not be added\");\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (isConnected.get()) {\n\t\t\t\tLOGGER.info(\"The client is already connected, the listener will be added\");\n\t\t\t}\n\t\t\tif (isExpired.get()) {\n\t\t\t\tLOGGER.warn(\"The client has expired, the listener will not be added\");\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (isShutdown.get()) {\n\t\t\t\tLOGGER.warn(\"The client is already shutdown, the listener will not be added\");\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tLOGGER.info(\"Adding listener: \" + listener);\n\t\t\tlisteners.add(listener);\n\t\t\tsubscribeStateChanges();\n\t\t}\n\t});\n}", "CodeBleu_score": 39.044782201285344}, {"code": "public void addListener(IZkStateListener listener){\n\t\tCompletableFuture<Void> future = new CompletableFuture<>();\n\tfuture.completeExceptionally(new ZkTimeoutException(\"Unable to connect to zookeeper server within connection timeout\"));\n\texecutorService.submit(new Runnable() {\n\t\t@Override\n\t\tpublic void run() {\n\t\t\ttry {\n\t\t\t\tmakeClientReady();\n\t\t\t\tsubscribeStateChanges(listener);\n\t\t\t\tfuture.complete(null);\n\t\t\t} catch (Exception e) {\n\t\t\t\tfuture.completeExceptionally(e);\n\t\t\t}\n\t\t}\n\t});\n\ttry {\n\t\tfuture.get(connectionTimeout, TimeUnit.MILLISECONDS);\n\t} catch (InterruptedException e) {\n\t\tThread.currentThread().interrupt();\n\t} catch (ExecutionException e) {\n\t\tthrow new ZkInterruptedException(\"Interrupted while waiting for client to be connected\", e);\n\t} catch (TimeoutException e) {\n\t\tthrow new ZkTimeoutException(\"Unable to connect to zookeeper server within connection timeout\");\n\t}\n}", "CodeBleu_score": 19.79122909174068}, {"code": "public void addListener(IZkStateListener listener){\n\t\tCompletableFuture<ZkClient> completableFuture = new CompletableFuture<>();\n\taddListener(listener, completableFuture);\n}", "CodeBleu_score": 20.41484828255882}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tsuper(serverAddr, authority);\n}", "CodeBleu_score": 3.410257367308593}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis(serverAddr, authority, null);\n}", "CodeBleu_score": 3.410257367310611}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis(serverAddr, authority, 10000, 30000, 10000, 10000, 10000, 10000);\n}", "CodeBleu_score": 3.4102601335805067}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (path == null || path.isEmpty()) {\n\t\tthrow new IllegalArgumentException(\"Path cannot be null or empty\");\n\t}\n\tif (listener == null) {\n\t\tthrow new IllegalArgumentException(\"Listener cannot be null\");\n\t}\n\tMap<ChildListener, TargetChildListener> listenerMap = childListenerMap.get(path);\n\tif (listenerMap == null) {\n\t\treturn;\n\t}\n\tTargetChildListener targetChildListener = listenerMap.remove(listener);\n\tif (targetChildListener == null) {\n\t\treturn;\n\t}\n\ttargetChildListener.remove();\n\tif (listenerMap.isEmpty()) {\n\t\tchildListenerMap.remove(path);\n\t}\n}", "CodeBleu_score": 49.3976217535481}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (path == null) {\n\t\tthrow new IllegalArgumentException(\"Path must not be null\");\n\t}\n\tif (listener == null) {\n\t\tthrow new IllegalArgumentException(\"Listener must not be null\");\n\t}\n\tMap<ChildListener, ChildListener> childListenerMap = listeners.get(path);\n\tif (childListenerMap == null) {\n\t\treturn;\n\t}\n\tchildListenerMap.remove(listener);\n\tif (childListenerMap.isEmpty()) {\n\t\tlisteners.remove(path);\n\t}\n\tTargetChildListener targetChildListener = targetChildListenerMap.get(path);\n\tif (targetChildListener != null) {\n\t\ttarget.removeTargetChildListener(path, targetChildListener);\n\t\ttargetChildListenerMap.remove(path);\n\t}\n}", "CodeBleu_score": 43.90467121577147}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (path == null || listener == null) {\n\t\tthrow new IllegalArgumentException(\"Arguments cannot be null\");\n\t}\n\tif (path.length() == 0) {\n\t\tthrow new IllegalArgumentException(\"Path cannot be empty\");\n\t}\n\tif (path.charAt(0) != '/') {\n\t\tthrow new IllegalArgumentException(\"Path must begin with '/'\");\n\t}\n\tif (path.charAt(path.length() - 1) == '/') {\n\t\tthrow new IllegalArgumentException(\"Path must not end with '/'\");\n\t}\n\tsynchronized (lock) {\n\t\tMap<String, List<ChildListener>> pathListeners = listeners.get(path);\n\t\tif (pathListeners != null) {\n\t\t\tList<ChildListener> childListeners = pathListeners.get(path);\n\t\t\tif (childListeners != null) {\n\t\t\t\tchildListeners.remove(listener);\n\t\t\t\tif (childListeners.isEmpty()) {\n\t\t\t\t\tpathListeners.remove(path);\n\t\t\t\t\tif (pathListeners.isEmpty()) {\n\t\t\t\t\t\tlisteners.remove(path);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tTargetChildListener targetChildListener = targetChildListenerMap.get(path);\n\t\tif (targetChildListener != null) {\n\t\t\ttarget.removeChildListener(path, targetChildListener);\n\t\t\ttargetChildListenerMap.remove(path);\n\t\t}\n\t}\n}", "CodeBleu_score": 43.57726365382535}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (zh == NULL) {\n\t\tLOG_ERR(\"Invalid ZooKeeper handle\");\n\t\treturn -1;\n\t}\n\n\t/* Get and delete the IDC host information from the handle */\n\tchar *idc_host = deserialize_from_idc_host(zh);\n\tif (idc_host == NULL) {\n\t\tLOG_ERR(\"Unable to deserialize IDC host information from ZooKeeper handle\");\n\t\treturn -1;\n\t}\n\tlock_ht_delete(zh, idc_host);\n\n\t/* Close the old handle */\n\tint rc = zookeeper_close(zh);\n\tif (rc != ZOK) {\n\t\tLOG_ERR(\"Unable to close ZooKeeper handle: %s\", zerror(rc));\n\t\treturn -1;\n\t}\n\n\t/* Deserialize the IDC and host information */\n\tchar *idc = deserialize_from_idc(zh);\n\tif (idc == NULL) {\n\t\tLOG_ERR(\"Unable to deserialize IDC information from ZooKeeper handle\");\n\t\treturn -1;\n\t}\n\tchar *host = deserialize_from_host(zh);\n\tif (host == NULL) {\n\t\tLOG_ERR(\"Unable to deserialize host information from ZooKeeper handle\");\n\t\treturn -1;\n\t}\n\n\t/* Initialize a new handle */\n\tzh = zookeeper_init(idc, watcher_func, 10000, host, 0, 0, 0);\n\tif (zh == NULL) {\n\t\tLOG_ERR(\"Unable to initialize ZooKeeper handle\");\n\t\treturn -1;\n\t}\n\n\t/* Initialize the environment for the new handle */\n\trc = init_env_for_zk(zh);\n\tif (rc != 0) {\n\t\tLOG_ERR(\"Unable to initialize environment for ZooKeeper handle\");\n\t\treturn -1;\n\t}\n\n\t/* Reset the table watcher */\n\trc = reset_table_watcher(zh);\n\tif (rc != 0) {\n\t\tLOG_ERR(\"Unable to reset table watcher\");\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}", "CodeBleu_score": 27.856322185093834}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\tif (zh == NULL) {\nLOG_ERR(\"zh is NULL\");\nreturn -1;\n}\n\n/*\n * Retrieve and delete the IDC host information associated with the handle.\n */\nchar *idc_host = deserialize_from_idc_host(zh);\nif (idc_host == NULL) {\nLOG_ERR(\"deserialize_from_idc_host failed\");\nreturn -1;\n}\n\n/*\n * Close the old handle.\n */\nzookeeper_close(zh);\n\n/*\n * Deserialize the IDC and host information and initialize a new ZooKeeper handle with this information.\n */\nint rc = init_env_for_zk(idc_host, &zh);\nif (rc != 0) {\nLOG_ERR(\"init_env_for_zk failed\");\nreturn -1;\n}\n\n/*\n * Initialize the environment for the new handle and reset the table watcher.\n */\nrc = init_env_for_table_watcher(zh);\nif (rc != 0) {\nLOG_ERR(\"init_env_for_table_watcher failed\");\nreturn -1;\n}\n\nreturn 0;\n}", "CodeBleu_score": 18.32031060250779}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (zh == NULL) {\n\t\tLOG_ERR(\"zh is null\");\n\t\treturn -1;\n\t}\n\t// Retrieve and delete the IDC host information associated with the handle.\n\tchar *idc_host = deserialize_from_idc_host(zh);\n\tif (idc_host == NULL) {\n\t\tLOG_ERR(\"Failed to deserialize idc_host\");\n\t\treturn -1;\n\t}\n\tlock_ht_delete(zh, idc_host);\n\t// Close the old handle.\n\tint rc = zookeeper_close(zh);\n\tif (rc != ZOK) {\n\t\tLOG_ERR(\"Failed to close zookeeper handle: %s\", zerror(rc));\n\t\treturn -1;\n\t}\n\t// Deserialize the IDC and host information and initialize a new ZooKeeper handle with this information.\n\tint idc_port;\n\tchar *zk_hosts = deserialize_from_idc_host(zh, &idc_port);\n\tif (zk_hosts == NULL) {\n\t\tLOG_ERR(\"Failed to deserialize zk_hosts\");\n\t\treturn -1;\n\t}\n\trc = zookeeper_init(zk_hosts, watcher_reconnect_to_zookeeper, 10000, &zh, NULL);\n\tif (rc != ZOK) {\n\t\tLOG_ERR(\"Failed to initialize zookeeper handle: %s\", zerror(rc));\n\t\treturn -1;\n\t}\n\t// Initialize the environment for the new handle and reset the table watcher.\n\tinit_env_for_zk(zh, idc_host, idc_port);\n\treturn 0;\n}", "CodeBleu_score": 35.699764565885964}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\t/*\n\t * Update internal tables with the handle and host information.\n\t */\n\tg_zk_handle_map[zh] = idc;\n\tg_zk_host_map[zh] = idc_host;\n\tg_zk_host_idc_map[idc_host] = idc;\n\t/*\n\t * Check the connection state of the Zookeeper handle.\n\t */\n\tif (ZOO_CONNECTED_STATE != zookeeper_state(zh)) {\n\t\tLOG_FATAL_ERR(\"zookeeper is not connected\");\n\t\treturn;\n\t}\n\t/*\n\t * Register the current host on the Zookeeper server and set a watcher on the notify node.\n\t */\n\tint rc = zk_register_ephemeral(zh, zk_notify_node, g_zk_host_map[zh].c_str(), g_zk_host_map[zh].size());\n\tif (ZOK != rc) {\n\t\tLOG_FATAL_ERR(\"zk_register_ephemeral failed, zk_notify_node=%s, host=%s, rc=%d\", zk_notify_node, g_zk_host_map[zh].c_str(), rc);\n\t\treturn;\n\t}\n\t/*\n\t * Depending on the result of setting the watcher, add the IDC to a gray list or log an error if the operation fails.\n\t */\n\tif (ZOK != (rc = watch_notify_node(zh))) {\n\t\tLOG_FATAL_ERR(\"watch_notify_node failed, rc=%d\", rc);\n\t\treturn;\n\t}\n}", "CodeBleu_score": 44.16584284069221}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\tconst string &zk_notify_node = get_zk_notify_node();\n\tconst string &zk_host_node = get_zk_host_node(idc_host);\n\tconst string &zk_gray_idc_node = get_zk_gray_idc_node();\n\tconst string &zk_gray_idc_host_node = get_zk_gray_idc_host_node(idc_host);\n\tconst string &zk_gray_idc_host_idc_node = get_zk_gray_idc_host_idc_node(idc_host, idc);\n\tconst string &zk_gray_idc_idc_node = get_zk_gray_idc_idc_node(idc);\n\tconst string &zk_gray_idc_host_idc_state_node = get_zk_gray_idc_host_idc_state_node(idc_host, idc);\n\tconst string &zk_gray_idc_host_idc_state_lock_node = get_zk_gray_idc_host_idc_state_lock_node(idc_host, idc);\n\tconst string &zk_gray_idc_host_idc_state_lock_value = get_zk_gray_idc_host_idc_state_lock_value();\n\tconst string &zk_gray_idc_host_idc_state_value = get_zk_gray_idc_host_idc_state_value(idc_host, idc);\n\tconst string &zk_gray_idc_host_idc_state_value_gray = get_zk_gray_idc_host_idc_state_value_gray();\n\tconst string &zk_gray_idc_host_idc_state_value_gray_expire = get_zk_gray_idc_host_idc_state_value_gray_expire();\n\tconst string &zk_gray_idc_host_idc_state_value_gray_expire_time = get_zk_gray_idc_host_idc_state_value_gray_expire_time();\n\tconst string &", "CodeBleu_score": 22.961546035287803}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\tzhandle_t *zk = zh;\n\tstring notify_node;\n\tstring zk_host;\n\tstring zk_idc;\n\tstring zk_host_idc;\n\tstring zk_host_idc_path;\n\tstring zk_host_path;\n\tstring zk_idc_path;\n\tstring zk_notify_node_path;\n\tstring zk_host_idc_notify_node_path;\n\tstring zk_host_notify_node_path;\n\tstring zk_idc_notify_node_path;\n\tstring zk_host_idc_notify_node_value;\n\tstring zk_host_notify_node_value;\n\tstring zk_idc_notify_node_value;\n\tint ret;\n\tbool is_gray_idc;\n\tbool is_new_idc;\n\tbool is_new_host;\n\tbool is_new_host_idc;\n\tbool is_new_notify_node;\n\tbool is_new_host_idc_notify_node;\n\tbool is_new_host_notify_node;\n\tbool is_new_idc_notify_node;\n\tbool is_new_host_idc_notify_node_value;\n\tbool is_new_host_notify_node_value;\n\tbool is_new_idc_notify_node_value;\n\tbool is_new_host_idc_path;\n\tbool is_new_host_path;\n\tbool is_new_idc_path;\n\tbool is_new_host_idc_notify_node_path;\n\tbool is_new_host_notify_node_path;\n\tbool is_new_idc_notify_node_path;\n\tbool is_new_host_idc_notify_node_value;\n\tbool is_new_host_notify_node_value;\n\tbool is_new_idc_notify_node_value;\n\tbool is_new_host_idc_path;\n\tbool is_new_host_path;\n\tbool is_new_idc_path;\n\tbool is_new_host_idc_notify_node_path;\n\tbool", "CodeBleu_score": 23.00673972580104}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode('utf-8') + password.encode('utf-8')).digest()\n    return username + ':' + base64.b64encode(cred_hash).decode('utf-8')\n", "CodeBleu_score": 33.38930290766906}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode() + password.encode()).digest()\n    return username + ':' + base64.b64encode(cred_hash).decode()\n\n", "CodeBleu_score": 28.989018596872096}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode() + password.encode()).digest()\n    return username + ':' + b64encode(cred_hash).decode()\n\n", "CodeBleu_score": 26.643382481303934}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if not self.processing_element:\n        return False\n    lock_path = self.processing_element + \"/lock\"\n    self.zookeeper_client.sync(lock_path)\n    lock_value = self.zookeeper_client.get(lock_path)[0].decode()\n    if lock_value == self.instance_id:\n        return True\n    else:\n        return False\n\n", "CodeBleu_score": 41.91230102338173}, {"code": "def holds_lock(self)\n\t\n    if not self.processing_element:\n        return False\n\n    lock_path = self.processing_element.path + '/lock'\n    lock_value = self.processing_element.client.sync(lock_path)\n    return lock_value == self.processing_element.id\n\n", "CodeBleu_score": 32.40818665322969}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_path = self.processing_element + \"/\" + self.lock_name\n    self.client.sync(lock_path)\n    lock_value = self.client.get(lock_path)[0]\n    return lock_value == self.instance_id\n\n", "CodeBleu_score": 48.16090783484162}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    pass\n", "CodeBleu_score": 0.45454545454545453}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    if self.holds_lock:\n        transaction.delete(self.processing_element)\n        self.processing_element = None\n        return True\n    else:\n        return False\n\n", "CodeBleu_score": 23.9403234418488}, {"code": "def consume(self)\n\t\n    pass\n", "CodeBleu_score": 0.45454545454545453}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header = await self._read_header(read_timeout)\n    except asyncio.TimeoutError:\n        if self._session_callback is not None:\n            self._session_callback(self)\n        raise\n    except Exception as e:\n        if self._session_callback is not None:\n            self._session_callback(self)\n        raise e\n    if header.xid == PING_XID:\n        self._logger.debug(\"Received ping from server\")\n        self._outstanding_ping = False\n    elif header.xid == AUTH_XID:\n        if header.type == AUTH_REPLY:\n            if header.status == AUTH_STATUS_SUCCESS:\n                self._logger.debug(\"Authentication succeeded\")\n            else:\n                self._logger.debug(\"Authentication failed\")\n                self._auth_failed = True\n                self._session_callback(self)\n                raise AuthFailedError(\"Authentication failed\")\n        else:\n            self._logger.debug(\"Received unexpected message type %d\", header.type)\n    elif header.xid == WATCH_XID:\n        self._read_watch_event(header)\n    else:\n        self._logger.debug(\"Received message with xid %d\", header.xid)\n        self._read_response(header)\n\n", "CodeBleu_score": 36.193714256946976}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header = await self._read_header(read_timeout)\n    except asyncio.TimeoutError:\n        return\n\n    if header.xid == PING_XID:\n        self._logger.debug(\"Received ping, clearing outstanding ping flag.\")\n        self._outstanding_ping = False\n        return\n\n    if header.xid == AUTH_XID:\n        await self._read_auth_response(header)\n        return\n\n    if header.xid == WATCH_XID:\n        await self._read_watch_event(header)\n        return\n\n    self._logger.debug(\"Received response with xid: %d\", header.xid)\n    self._read_response(header)\n\n", "CodeBleu_score": 33.60916581071407}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header = self._read_header(read_timeout)\n        if header.xid == PING_XID:\n            self.logger.debug(\"Received ping from server\")\n            self.outstanding_ping = False\n        elif header.xid == AUTH_XID:\n            self.logger.debug(\"Received authentication response from server\")\n            if header.type == MSG_REPLY:\n                if header.err:\n                    self.logger.error(\"Authentication failed\")\n                    self.async_object.set_exception(AuthFailedError(\"Authentication failed\"))\n                else:\n                    self.logger.debug(\"Authentication succeeded\")\n                    self.async_object.set()\n            else:\n                self.logger.error(\"Received unexpected authentication response\")\n                self.async_object.set_exception(UnexpectedMessageError(\"Received unexpected authentication response\"))\n        elif header.xid == WATCH_XID:\n            self.logger.debug(\"Received watch event from server\")\n            self._read_watch_event(header)\n        else:\n            self.logger.debug(\"Received response from server\")\n            self._read_response(header)\n    except asyncio.CancelledError:\n        self.logger.debug(\"Read socket cancelled\")\n        self.async_object.set_exception(asyncio.CancelledError())\n    except Exception as e:\n        self.logger.error(\"Exception while reading from socket: {}\".format(e))\n        self.async_object.set_exception(e)\n\n", "CodeBleu_score": 36.316740844173}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.log.debug(\"Starting Zookeeper connection loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.retry(self.connect)\n            self.log.debug(\"Connection loop stopped\")\n            self.connection_stopped.set()\n            self.session_callback(state=KazooState.LOST)\n            self.log.debug(\"Session callback called\")\n            break\n        except Exception:\n            self.log.warning(\"Unable to connect to Zookeeper\", exc_info=True)\n    self.log.debug(\"Zookeeper connection loop stopped\")\n", "CodeBleu_score": 44.43891363577735}, {"code": "def zk_loop(self)\n\t\n    self.log.debug(\"Starting zk_loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.retry(self.connect)\n            self.session_callback(KeeperState.CONNECTED)\n            while not self.stopped.is_set():\n                self.read_loop()\n        except Exception:\n            self.log.warning(\"Connection to Zookeeper failed\", exc_info=True)\n        finally:\n            self.connection_stopped.set()\n            self.session_callback(KeeperState.CLOSED)\n    self.log.debug(\"Ending zk_loop\")\n\n", "CodeBleu_score": 44.95037790543278}, {"code": "def zk_loop(self)\n\t\n    self.logger.info(\"Starting Zookeeper connection loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.retry(self.connect)\n            self.connection_stopped.set()\n            self.session_callback(state=KazooState.LOST)\n            self.logger.info(\"Zookeeper connection loop has stopped\")\n        except Exception:\n            self.logger.warning(\n                \"Zookeeper connection loop has stopped due to connection failure\",\n                exc_info=True,\n            )\n            self.connection_stopped.set()\n            self.session_callback(state=KazooState.SUSPENDED)\n            self.logger.info(\"Zookeeper connection loop has stopped\")\n\n", "CodeBleu_score": 43.40727637789147}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    index = sorted_members.index(identifier)\n    return sorted_partitions[index::len(members)]\n", "CodeBleu_score": 37.493399878959686}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    index = sorted_members.index(identifier)\n    return sorted_partitions[index::len(members)]\n\n", "CodeBleu_score": 37.493399878959686}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    partitions = sorted(partitions)\n    members = sorted(members)\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 39.65957835883439}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    try:\n        self._leave()\n    except Exception:\n        self._best_effort_cleanup()\n        raise\n    self._participating = False\n\n", "CodeBleu_score": 41.739666878235646}, {"code": "def leave(self)\n\t\n    self._participating = False\n    self._best_effort_cleanup()\n    self._leave()", "CodeBleu_score": 25.340651759982123}, {"code": "def leave(self)\n\t\n    self._participating = False\n    self._best_effort_cleanup()\n    retry = self._retry\n    self._retry = 0\n    try:\n        self._leave()\n    except Exception:\n        self._best_effort_cleanup()\n        raise\n    finally:\n        self._retry = retry", "CodeBleu_score": 41.95025032104272}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t\tResult result = null;\n\ttry {\n\t\t// Check the server status\n\t\tresult = status();\n\t\tif (result.isSuccess()) {\n\t\t\t// Server is running, return success\n\t\t\tresult = new Result(Result.SUCCESS, \"Server is already running\");\n\t\t} else {\n\t\t\t// Server is not running, start it\n\t\t\tString command = \"sudo -u \" + userName + \" \" + startServer;\n\t\t\tresult = executeCommand(command);\n\t\t}\n\t} catch (Exception e) {\n\t\tresult = new Result(Result.ERROR, e.getMessage());\n\t}\n\treturn result;\n}", "CodeBleu_score": 33.927441402249045}, {"code": "public Result start(){\n\t\tif (statusServer() == Result.SERVER_RUNNING) {\n\t\treturn Result.SERVER_RUNNING;\n\t}\n\ttry {\n\t\tstartServer();\n\t\treturn Result.SUCCESS;\n\t} catch (Exception e) {\n\t\treturn Result.ERROR;\n\t}\n}", "CodeBleu_score": 17.844391217489523}, {"code": "public Result start(){\n\t\tResult result = new Result();\n\ttry {\n\t\tif (!statusServer()) {\n\t\t\tstartServer();\n\t\t}\n\t\tresult.setSuccess(true);\n\t} catch (Exception e) {\n\t\tresult.setSuccess(false);\n\t\tresult.setMessage(e.getMessage());\n\t}\n\treturn result;\n}", "CodeBleu_score": 29.721257529759033}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t\tif (serverRunning) {\n\t\ttry {\n\t\t\tserver.stop();\n\t\t\tserverRunning = false;\n\t\t\treturn new Result(true, \"Server stopped successfully.\");\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Error stopping FTP server.\", e);\n\t\t\treturn new Result(false, \"Error stopping FTP server.\");\n\t\t}\n\t} else {\n\t\treturn new Result(false, \"Server is not running.\");\n\t}\n}", "CodeBleu_score": 32.370798107677764}, {"code": "public Result stop(){\n\t\tResult result = new Result();\n\ttry {\n\t\tif (ftpServer.getServerStatus()) {\n\t\t\tftpServer.stopServer();\n\t\t\tresult.setSuccess(true);\n\t\t\tresult.setMessage(\"Successfully stopped the FTP server\");\n\t\t} else {\n\t\t\tresult.setSuccess(false);\n\t\t\tresult.setMessage(\"The FTP server is not running\");\n\t\t}\n\t} catch (Exception e) {\n\t\tlogger.error(e.getMessage(), e);\n\t\tresult.setSuccess(false);\n\t\tresult.setMessage(\"Error while stopping the FTP server\");\n\t}\n\treturn result;\n}", "CodeBleu_score": 31.220270288815655}, {"code": "public Result stop(){\n\t\tResult result = new Result();\n\ttry {\n\t\tif (ftpServer.isServerRunning()) {\n\t\t\tftpServer.stopServer();\n\t\t\tresult.setSuccess(true);\n\t\t\tresult.setMessage(\"Successfully stopped the FTP server.\");\n\t\t} else {\n\t\t\tresult.setSuccess(false);\n\t\t\tresult.setMessage(\"The FTP server is not running.\");\n\t\t}\n\t} catch (Exception e) {\n\t\tresult.setSuccess(false);\n\t\tresult.setMessage(\"An error occurred while attempting to stop the FTP server.\");\n\t\tlogger.error(result.getMessage(), e);\n\t}\n\treturn result;\n}", "CodeBleu_score": 30.727905528676853}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\t// Check to see if there are any authorities available.\n\tif (this.getAuthorities() == null || this.getAuthorities().isEmpty()) {\n\t\treturn null;\n\t}\n\n\t// Iterate through each authority to see if they can authorize the request.\n\tfor (final Authority authority : this.getAuthorities()) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\treturn authority.authorize(request);\n\t\t}\n\t}\n\n\t// If authorization fails at any point, return null.\n\treturn null;\n}", "CodeBleu_score": 28.69706639201462}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tif (authorities == null || authorities.isEmpty()) {\n\t\treturn null;\n\t}\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\trequest = authority.authorize(request);\n\t\t\tif (request != null) {\n\t\t\t\treturn request;\n\t\t\t}\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 39.58485064391623}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tif (authorities == null || authorities.isEmpty()) {\n\t\treturn null;\n\t}\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\treturn authority.authorize(request);\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 25.08358919975603}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t\ttry {\n\t\tdfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\tprintStackTrace(e);\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 38.68321912778951}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tdfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\tprintStackTrace(e);\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 38.68321912778951}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tfs = FileSystem.get(conf);\n\t\treturn fs.mkdirs(new Path(fullPath));\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 61.66652075452301}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t\ttry {\n\t\tfs.delete(new Path(fullPath), true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 48.22449048674285}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tdfs = getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 65.04796763658184}, {"code": "public boolean delete(){\n\t\tboolean success = false;\n\ttry {\n\t\tfs.delete(new Path(fullPath), true);\n\t\tsuccess = true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n\treturn success;\n}", "CodeBleu_score": 45.3618414053776}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t\tboolean success = false;\n\ttry {\n\t\tPath newPath = new Path(ftpFile.getParent(), ftpFile.getName());\n\t\tboolean renamed = fs.rename(path, newPath);\n\t\tif (renamed) {\n\t\t\tpath = newPath;\n\t\t\tsuccess = true;\n\t\t}\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n\treturn success;\n}", "CodeBleu_score": 42.4296585894771}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFile file = new File(ftpFile.getParent(), ftpFile.getName());\n\t\tboolean success = file.renameTo(new File(ftpFile.getPath()));\n\t\tif (success) {\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 53.744534046873085}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tString parent = ftpFile.getParent();\n\t\tString name = ftpFile.getName();\n\t\tString newPath = parent + \"/\" + name;\n\t\trename(newPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 56.98970700383351}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tList<FtpFile> files = new ArrayList<>();\n\t\tfor (FileStatus status : fs.listStatus(new Path(this.path))) {\n\t\t\tfiles.add(new FtpFile(status));\n\t\t}\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\tlogger.error(e.getMessage(), e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 18.916663407383634}, {"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileSystem fs = getDfs();\n\t\tFileStatus[] statuses = fs.listStatus(getPath());\n\t\tList<FtpFile> files = new ArrayList<FtpFile>(statuses.length);\n\t\tfor (FileStatus status : statuses) {\n\t\t\tfiles.add(new FtpFile(this, status));\n\t\t}\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error listing files in \" + getPath(), e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 25.70779650311099}, {"code": "public List<FtpFile> listFiles(){\n\ttry {\nList<FtpFile> files = new ArrayList<FtpFile>();\nString path = getAbsolutePath();\nif (path.length() > 1 && path.charAt(path.length() - 1) != '/') {\npath += \"/\";\n}\n\nFileSystem fs = getDfs();\nFileStatus[] fileStatuses = fs.listStatus(new Path(path));\nfor (FileStatus fileStatus : fileStatuses) {\nString fileName = fileStatus.getPath().getName();\nif (fileName.charAt(fileName.length() - 1) == '_') {\ncontinue;\n}\n\nfiles.add(new FtpFile(fileName, fileStatus.isDirectory()));\n}\n\nreturn Collections.unmodifiableList(files);\n} catch (IOException e) {\nLOG.error(\"Could not list files in directory \" + getAbsolutePath() + \": \" + e.getMessage());\nreturn null;\n}\n}", "CodeBleu_score": 38.40945011756109}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t\ttry {\n\t\t// Check if the user data file exists\n\t\tif (new File(getUserDataFilePath()).exists()) {\n\t\t\t// Load the user data file\n\t\t\tload(getUserDataFilePath());\n\t\t} else {\n\t\t\t// Create the user data file\n\t\t\tFileOutputStream fos = new FileOutputStream(getUserDataFilePath());\n\t\t\tfos.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\"Error while creating user data file: \" + getUserDataFilePath(), e);\n\t}\n\n\t// Set the configuration state to true\n\tsetConfigurationState(true);\n\n\t// Convert any deprecated property names\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 31.38513145235918}, {"code": "public void configure(){\n\t\ttry {\n\t\tif (isConfigured) {\n\t\t\treturn;\n\t\t}\n\t\tisConfigured = true;\n\t\tif (getUserDataFile().exists()) {\n\t\t\tload();\n\t\t}\n\t\tconvertDeprecatedPropertyNames();\n\t}\n\tcatch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(getUserDataFile().getAbsolutePath(), e);\n\t}\n}", "CodeBleu_score": 22.708487537370182}, {"code": "public void configure(){\n\t\tif (isConfigured) {\n\t\treturn;\n\t}\n\tisConfigured = true;\n\tif (!isPathAbsolute(userFile)) {\n\t\tuserFile = getAbsolutePath(userFile);\n\t}\n\ttry {\n\t\tload(userFile);\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(userFile, e);\n\t}\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 29.909665770510163}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\tFile userDataFile = new File(getUserDataFilePath());\nFile parent = userDataFile.getParentFile();\nif (!parent.exists()) {\ntry {\nparent.mkdirs();\n} catch (SecurityException e) {\nthrow new FtpException(\"Could not create directory \" + parent.getAbsolutePath());\n}\n}\ntry {\nFileOutputStream fos = new FileOutputStream(userDataFile);\nstore(fos, \"FTP Client User Data\");\nfos.close();\n} catch (IOException e) {\nerror(\"Could not save user data to \" + getUserDataFilePath());\nthrow new FtpException(\"Could not save user data to \" + getUserDataFilePath());\n}\n}", "CodeBleu_score": 39.65176757219427}, {"code": "private void saveUserData() throws FtpException{\n\t\tFile file = new File(getUserDataFilename());\n\tFile parent = file.getParentFile();\n\tif (!parent.exists()) {\n\t\ttry {\n\t\t\tparent.mkdirs();\n\t\t} catch (SecurityException e) {\n\t\t\tthrow new FtpException(e.getMessage());\n\t\t}\n\t}\n\ttry {\n\t\tFileOutputStream fos = new FileOutputStream(file);\n\t\tstore(fos, null);\n\t\tfos.close();\n\t} catch (IOException e) {\n\t\tlog.error(\"Error while saving user data: \" + e.getMessage());\n\t\tthrow new FtpException(e.getMessage());\n\t}\n}", "CodeBleu_score": 34.97579630788493}, {"code": "private void saveUserData() throws FtpException{\n\tFile file = new File(getUserDataFile());\nif (!file.getParentFile().exists()) {\ntry {\nfile.getParentFile().mkdirs();\n} catch (Exception e) {\nthrow new FtpException(e.getMessage());\n}\n}\ntry {\nFileOutputStream out = new FileOutputStream(file);\nout.write(userData.getBytes());\nout.close();\n} catch (IOException e) {\nlogger.error(e.getMessage());\nthrow new FtpException(e.getMessage());\n}\n}", "CodeBleu_score": 28.761777403811667}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t\tResult result = null;\n\ttry {\n\t\tHdfsUserManager userManager = new HdfsUserManager();\n\t\tuserManager.setFile(\"users.properties\");\n\t\tuserManager.delete(user);\n\t\tresult = new Result(Result.SUCCESS, \"Successfully deleted user \" + user);\n\t} catch (Exception e) {\n\t\tresult = new Result(Result.FAILURE, \"Error deleting user \" + user + \": \" + e.getMessage());\n\t\tlog.error(result.getMessage());\n\t}\n\treturn result;\n}", "CodeBleu_score": 39.441325105987325}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t\ttry {\n\t\tHdfsUserManager userManager = new HdfsUserManager();\n\t\tuserManager.setFile(\"users.properties\");\n\t\tuserManager.delete(user);\n\t\treturn new Result(\"success\", \"User \" + user + \" deleted successfully.\");\n\t} catch (Exception e) {\n\t\tlog.error(e.getMessage());\n\t\treturn new Result(\"failure\", e.getMessage());\n\t}\n}", "CodeBleu_score": 47.241965049883916}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t\ttry {\n\t\tHdfsUserManager userManager = new HdfsUserManager();\n\t\tuserManager.setFile(\"users.properties\");\n\t\tuserManager.delete(user);\n\t\treturn new Result(true, \"Successfully deleted user\");\n\t} catch (Exception e) {\n\t\tlogger.error(e.getMessage());\n\t\treturn new Result(false, e.getMessage());\n\t}\n}", "CodeBleu_score": 49.59212466074116}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.info(\"open: \" + path + \" with buffer size \" + bufferSize);\n\tpath = qualify(path);\n\tFSDataInputStream stream = null;\n\ttry {\n\t\tstream = openFileForRead(path, bufferSize);\n\t} catch (IOException e) {\n\t\tLOG.warn(\"open: \" + path + \" with buffer size \" + bufferSize + \" failed\", e);\n\t\treturn null;\n\t}\n\treturn stream;\n}", "CodeBleu_score": 32.05095829991893}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.info(\"Open \" + path + \" with buffer size \" + bufferSize);\n\tPath qualifiedPath = qualify(path);\n\tLOG.info(\"Qualified path: \" + qualifiedPath);\n\tFSDataInputStream inputStream = openFileForRead(qualifiedPath, bufferSize);\n\treturn inputStream;\n}", "CodeBleu_score": 21.97309343230785}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.debug(\"open(path={}, bufferSize={})\", path, bufferSize);\n\tPath qualifiedPath = qualify(path);\n\tint confBlockSize = getConf().getInt(SEAWEED_BLOCK_SIZE_KEY, SEAWEED_BLOCK_SIZE_DEFAULT);\n\tif (bufferSize > confBlockSize) {\n\t\tLOG.warn(\"bufferSize {} > configured block size {}\", bufferSize, confBlockSize);\n\t}\n\tFSDataInputStream fsdis = openFileForRead(qualifiedPath);\n\treturn fsdis;\n}", "CodeBleu_score": 36.36404225320112}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\tif (LOG.isTraceEnabled()) {\n\t\tLOG.trace(\"rename(\" + src + \", \" + dst + \")\");\n\t}\n\tif (src.isRoot() || src.equals(dst)) {\n\t\treturn false;\n\t}\n\tPath qualifiedDst = dst;\n\tif (dst.isRoot()) {\n\t\tqualifiedDst = new Path(dst, src.getName());\n\t} else {\n\t\tFileStatus dstStatus = getFileStatus(dst);\n\t\tif (dstStatus.isDirectory()) {\n\t\t\tqualifiedDst = new Path(dst, src.getName());\n\t\t}\n\t}\n\tPath qualifiedSrc = qualify(src);\n\tPath qualifiedDstPath = qualify(qualifiedDst);\n\tif (LOG.isTraceEnabled()) {\n\t\tLOG.trace(\"rename(\" + qualifiedSrc + \", \" + qualifiedDstPath + \")\");\n\t}\n\treturn store.rename(qualifiedSrc, qualifiedDstPath);\n}", "CodeBleu_score": 45.912080414877664}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tif (LOG.isDebugEnabled()) {\n\n\nlog.info(\"rename from\");\n}\nif (src.isRoot()) {\nreturn false;\n}\nif (src.equals(dst)) {\nreturn true;\n}\nPath qualifiedDst = dst;\nif (dst.isAbsolute()) {\nqualifiedDst = dst.makeQualified(this.fs.getUri(), this.fs.getWorkingDirectory());\n} else {\nPath qualifiedSrc = src.makeQualified(this.fs.getUri(), this.fs.getWorkingDirectory());\nqualifiedDst = new Path(qualifiedSrc.getParent(), dst);\n}\nif (LOG.isDebugEnabled()) {\n\n\nlog.info(\"rename to\");\n}\nPath qualifiedSrc = src.makeQualified(this.fs.getUri(), this.fs.getWorkingDirectory());\nif (LOG.isDebugEnabled()) {\n\n\nlog.info(\"rename qualified src\");\n}\nFileStatus srcStatus = getFileStatus(qualifiedSrc);\nif (LOG.isDebugEnabled()) {\n\n\nlog.info(\"rename qualified dst\");\n}\nFileStatus dstStatus = getFileStatus(qualifiedDst);\nif (LOG.isDebugEnabled()) {\n\n\nlog.info(\"rename srcstatus\");\n}\nif (dstStatus != null && dstStatus.isDirectory()) {\nif (LOG.isDebugEnabled()) {\n\n\nlog.info(\"rename dststatus\");\n}\nPath qualifiedNewDst = new Path(qualifiedDst, srcStatus.getPath().getName());\nif (LOG.isDebugEnabled()) {\n\n\nlog.info(\"rename qualified newdst\");\n}\nqualifiedDst = qualifiedNewDst;\n}\nif (LOG.isDebugEnabled()) {\n\n\nlog.info(\"rename qualified dst\");\n}\nif (LOG.isDebugEnabled()) {\n\n\nlog.info(\"rename src\");\n}\nif (LOG.isDebugEnabled()) {\n\n\nlog.info(\"rename qualified dst\");\n}\nreturn this.fs.rename(qualifiedSrc, qualifiedDst);\n}", "CodeBleu_score": 47.37281637948798}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\tif (LOG.isInfoEnabled()) {\n\t\tLOG.info(\"rename \" + src + \" to \" + dst);\n\t}\n\tif (src.equals(dst)) {\n\t\treturn true;\n\t}\n\tif (src.isRoot()) {\n\t\treturn false;\n\t}\n\t//\n\t// Check if the destination exists. If it does, and it is a directory,\n\t// then adjust the destination path.\n\t//\n\tPath qualifiedDst = qualify(dst);\n\tFileStatus dstStatus = getFileStatus(qualifiedDst);\n\tif (dstStatus != null) {\n\t\tif (dstStatus.isDirectory()) {\n\t\t\tqualifiedDst = new Path(qualifiedDst, src.getName());\n\t\t}\n\t}\n\t//\n\t// Check if the source and destination are in the same file system.\n\t//\n\tif (!src.getFileSystem().equals(qualifiedDst.getFileSystem())) {\n\t\treturn false;\n\t}\n\t//\n\t// Rename the source to the destination.\n\t//\n\treturn store.rename(src, qualifiedDst);\n}", "CodeBleu_score": 47.161600679534246}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t\treturn capability.toLowerCase().equals(\"hsync\") || capability.toLowerCase().equals(\"hflush\");\n}", "CodeBleu_score": 32.4268216617816}, {"code": "public boolean hasCapability(String capability){\n\t\treturn capability.toLowerCase().equals(\"hsync\") || capability.toLowerCase().equals(\"hflush\");\n}", "CodeBleu_score": 32.4268216617816}, {"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 20.756031968442706}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tif (offset < 0) {\n\t\tthrow new IllegalArgumentException(\"offset is negative: \" + offset);\n\t}\n\tfinal long size = offset - this.lastFlushOffset;\n\tif (size <= 0) {\n\t\treturn;\n\t}\n\tthis.lastFlushOffset = offset;\n\tthis.service.write(this.buffer, offset, size);\n\tthis.writeMeta();\n}", "CodeBleu_score": 35.366855600309734}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tfinal long flushOffset = Math.max(offset, lastFlushOffset);\n\tif (flushOffset >= 0) {\n\t\tfinal long flushLength = Math.min(writtenBytes.length() - flushOffset, maxFlushLength);\n\t\tif (flushLength > 0) {\n\t\t\tfinal byte[] flushBuffer = new byte[(int) flushLength];\n\t\t\twrittenBytes.get(flushOffset, flushBuffer);\n\t\t\twriteBytesToService(flushBuffer, flushOffset);\n\t\t\tlastFlushOffset = flushOffset + flushLength;\n\t\t\tif (lastFlushOffset == writtenBytes.length()) {\n\t\t\t\twrittenBytes.clear();\n\t\t\t\tlastFlushOffset = -1;\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 20.0950035844507}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tif (offset < 0) {\n\t\tthrow new IllegalArgumentException(\"offset must be non-negative\");\n\t}\n\tif (offset > lastFlushOffset) {\n\t\t// Write metadata to the filer client\n\t\tfinal long writeOffset = offset - bytesWritten;\n\t\tfinal long writeLength = bytesWritten;\n\t\tfinal long writeCrc = crc.getValue();\n\t\tfinal long writeVersion = version;\n\t\tfinal long writeParentDirectory = getParentDirectory();\n\t\tfinal long writeLastFlushOffset = offset;\n\t\tfinal long writeLastFlushTime = System.currentTimeMillis();\n\t\tfinal long writeLastFlushLength = bytesWritten;\n\t\tfinal long writeLastFlushCrc = writeCrc;\n\t\tfinal long writeLastFlushVersion = version;\n\t\tfinal long writeLastFlushParentDirectory = writeParentDirectory;\n\t\tfinal long writeLastFlushTimeNanos = System.nanoTime();\n\t\tfinal long writeLastFlushLengthNanos = System.nanoTime();\n\t\tfinal long writeLastFlushCrcNanos = System.nanoTime();\n\t\tfinal long writeLastFlushVersionNanos = System.nanoTime();\n\t\tfinal long writeLastFlushParentDirectoryNanos = System.nanoTime();\n\t\tfinal long writeLastFlushTimeMillis = System.currentTimeMillis();\n\t\tfinal long writeLastFlushLengthMillis = System.currentTimeMillis();\n\t\tfinal long writeLastFlushCrcMillis = System.currentTimeMillis();\n\t\tfinal long writeLastFlushVersionMillis = System.currentTimeMillis();\n\t\tfinal long writeLastFlushParentDirectoryMillis = System.currentTimeMillis();\n\t\tfinal long writeLastFlushTimeMicros = System.nanoTime() / 1000L;\n\t\tfinal long writeLastFlushLengthMicros = System.nanoTime() / 1000L;\n\t\tfinal long writeLastFlushCrcMicros = System.nanoTime() / 1000L;\n\t\tfinal long writeLastFlushVersionMicros = System.nanoTime() / 1000L;\n\t\tfinal long writeLastFlushParentDirectoryMicros = System.nanoTime() / 1000L;\n\t\tfinal long writeLastFlushTimeNanos2 = System.nanoTime();\n\t\tfinal long writeLastFlushLengthNanos2 = System.nanoTime();\n\t\tfinal long writeLastFlushCrcNanos2 = System.nanoTime();\n\t\tfinal long writeLastFlushVersionNanos2 = System.nanoTime", "CodeBleu_score": 25.5365419725309}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\tfinal int bytesToWrite = bufferToWrite.limit();\n\tfinal int bytesRemaining = bytesToWrite;\n\tfinal int bytesWritten = 0;\n\tfinal int bytesToWriteThisTime = bytesRemaining;\n\tfinal int bytesToWriteNextTime = 0;\n\tfinal int bytesWrittenThisTime = 0;\n\tfinal int bytesWrittenNextTime = 0;\n\tfinal int bytesWrittenTotal = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n\tfinal int bytesWrittenTotalNextTime = 0;\n\tfinal int bytesWrittenTotalThisTime = 0;\n", "CodeBleu_score": 16.608152037423043}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\tfinal int bytesToWrite = bufferToWrite.remaining();\n\tfinal int bytesWritten = bytesToWrite;\n\tif (bytesToWrite > 0) {\n\t\tfinal ByteBuffer bufferToWriteForService = bufferToWrite.duplicate();\n\t\tbufferToWriteForService.flip();\n\t\tfinal int bytesToWriteForService = bytesToWrite;\n\t\tfinal int bytesWrittenForService = bytesToWriteForService;\n\t\tfinal long writePositionForService = writePosition;\n\t\tfinal Future<Integer> future = completionService.submit(new Callable<Integer>() {\n\t\t\t@Override\n\t\t\tpublic Integer call() throws IOException {\n\t\t\t\treturn writeData(bufferToWriteForService, bytesToWriteForService, writePositionForService);\n\t\t\t}\n\t\t});\n\t\twriteOperations.add(new WriteOperation(future, bufferToWrite, bytesWritten, writePosition));\n\t\tif (writeOperations.size() > maxWriteOperations) {\n\t\t\twaitForTaskToComplete(writeOperations.remove());\n\t\t}\n\t}\n\treturn bytesWritten;\n}", "CodeBleu_score": 38.01966196906813}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\tfinal int bytesToWrite = bufferToWrite.remaining();\nfinal int bytesWritten = Math.min(bytesToWrite, MAX_WRITE_SIZE);\nfinal ByteBuffer bufferToWriteSlice = bufferToWrite.slice();\nbufferToWriteSlice.limit(bytesWritten);\nbufferToWrite.position(bufferToWrite.position() + bytesWritten);\nfinal long writePositionToWrite = writePosition + bytesWritten;\nfinal Future<Integer> writeFuture = completionService.submit(new WriteTask(bufferToWriteSlice, writePositionToWrite));\nwriteOperations.put(writePositionToWrite, writeFuture);\nif (writeOperations.size() > MAX_WRITE_QUEUE_SIZE) {\nLOGGER.warn(\"Write queue size {} is greater than max size {}\", writeOperations.size(), MAX_WRITE_QUEUE_SIZE);\n}\nreturn bytesWritten;\n}", "CodeBleu_score": 37.226338010947615}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\ttry {\n\t\t\tFuture<Integer> task = completionService.take();\n\t\t\ttask.get();\n\t\t\tbreak;\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new IOException(e);\n\t\t} catch (ExecutionException e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 25.335024963704566}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\ttry {\n\t\t\tFuture<String> future = completionService.take();\n\t\t\tString result = future.get();\n\t\t\tSystem.out.println(result);\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new IOException(e);\n\t\t} catch (ExecutionException e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 27.514682903570865}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\tFuture<Integer> future = completionService.poll();\n\t\tif (future == null) {\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IOException(e);\n\t\t\t}\n\t\t} else {\n\t\t\ttry {\n\t\t\t\tfuture.get();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IOException(e);\n\t\t\t} catch (ExecutionException e) {\n\t\t\t\tthrow new IOException(e);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 27.900792345134718}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\twhile (!writeOperationsQueue.isEmpty()) {\n\t\tWriteOperation writeOperation = writeOperationsQueue.peek();\n\t\tif (writeOperation.isDone()) {\n\t\t\twriteOperationsQueue.remove();\n\t\t\tappendOffset += writeOperation.getLength();\n\t\t\tif (writeOperation.getException() != null) {\n\t\t\t\tthrow new IOException(\"Write operation failed\", writeOperation.getException());\n\t\t\t}\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 27.80019708525372}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\twhile (!writeOperationQueue.isEmpty()) {\nWriteOperation writeOperation = writeOperationQueue.peek();\nif (writeOperation.isDone()) {\nwriteOperationQueue.remove();\ntotalAppendOffset += writeOperation.getLength();\n} else {\nbreak;\n}\n}\n}", "CodeBleu_score": 25.261559911614977}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\twhile (!writeOperationQueue.isEmpty()) {\nWriteOperation writeOperation = writeOperationQueue.peek();\nif (writeOperation.isDone()) {\nwriteOperationQueue.remove();\nif (writeOperation.getException() != null) {\nthrow new IOException(\"Exception while writing data\", writeOperation.getException());\n}\nappendOffset += writeOperation.getLength();\n} else {\nbreak;\n}\n}\n}", "CodeBleu_score": 29.352795705491502}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t\tsuper(user);\n\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"The user must not be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"The user's home directory must not be null\");\n\t}\n\thomePath = user.getHomeDirectory();\n}", "CodeBleu_score": 62.45078994779121}, {"code": "protected HdfsFileSystemView(User user){\n\t\tsuper(user);\n\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"user is null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"user's home directory is null\");\n\t}\n\thomePath = user.getHomeDirectory();\n}", "CodeBleu_score": 59.29005793656543}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"user cannot be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"user home directory cannot be null\");\n\t}\n\thomePath = user.getHomeDirectory();\n\tthis.user = user;\n}", "CodeBleu_score": 69.40984327544378}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir.charAt(0) == '/') {\n\t\tif (dir.equals(root)) {\n\t\t\treturn true;\n\t\t}\n\t\tif (dir.length() > 1) {\n\t\t\tcurrentPath = new Path(dir);\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\telse {\n\t\tif (currentPath.equals(root)) {\n\t\t\treturn false;\n\t\t}\n\t\tString newPath = currentPath.toString() + dir;\n\t\tif (newPath.charAt(newPath.length() - 1) == '/') {\n\t\t\tnewPath = newPath.substring(0, newPath.length() - 1);\n\t\t}\n\t\tcurrentPath = new Path(newPath);\n\t\treturn true;\n\t}\n}", "CodeBleu_score": 31.05147718487561}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir.startsWith(\"/\")) {\n\t\tcurrentPath = new Path(dir);\n\t\treturn true;\n\t}\n\tPath newPath = new Path(currentPath, dir);\n\tif (newPath.isDirectory()) {\n\t\tcurrentPath = newPath;\n\t\treturn true;\n\t}\n\treturn false;\n}", "CodeBleu_score": 17.890226124048738}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir.startsWith(root)) {\n\t\tcurrentPath = new Path(dir);\n\t\treturn true;\n\t}\n\treturn false;\n}", "CodeBleu_score": 7.341979060592249}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\tsuper(host, port, grpcPort, conf);\nif (conf.getBoolean(ACCESS_MODE_KEY, false)) {\nString accessMode = conf.get(ACCESS_MODE_KEY, \"direct\");\nif (accessMode.equals(\"direct\")) {\nsetAccessVolumeServerByDirect();\n} else if (accessMode.equals(\"publicUrl\")) {\nsetAccessVolumeServerByPublicUrl();\n} else if (accessMode.equals(\"filerProxy\")) {\nsetAccessVolumeServerByFilerProxy();\n} else {\nthrow new IllegalArgumentException(\"Unknown access mode: \" + accessMode);\n}\n}\n}", "CodeBleu_score": 40.128765610367495}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\tsuper(host, port, grpcPort, conf);\naccessMode = conf.get(ACCESS_MODE_KEY, DEFAULT_ACCESS_MODE);\nif (accessMode.equals(DIRECT)) {\nsetAccessVolumeServerByDirect();\n} else if (accessMode.equals(PUBLIC_URL)) {\nsetAccessVolumeServerByPublicUrl();\n} else if (accessMode.equals(FILER_PROXY)) {\nsetAccessVolumeServerByFilerProxy();\n} else {\nthrow new IllegalArgumentException(\"Invalid access mode: \" + accessMode);\n}\n}", "CodeBleu_score": 35.204936699362584}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\tsuper(host, port, grpcPort, conf);\nthis.filerClient = new FilerClient(host, port, grpcPort, conf);\nString accessMode = conf.get(ACCESS_MODE_KEY, DEFAULT_ACCESS_MODE);\nif (accessMode.equals(DIRECT_ACCESS_MODE)) {\nsetAccessVolumeServerByDirect(filerClient);\n} else if (accessMode.equals(PUBLIC_URL_ACCESS_MODE)) {\nsetAccessVolumeServerByPublicUrl(filerClient);\n} else if (accessMode.equals(FILER_PROXY_ACCESS_MODE)) {\nsetAccessVolumeServerByFilerProxy(filerClient);\n} else {\nthrow new IllegalArgumentException(\"Invalid access mode: \" + accessMode);\n}\n}", "CodeBleu_score": 38.53236419675397}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\tPath qualifiedPath = toQualifiedPath(path);\nLOG.debug(\"Opening file for read: {}\", qualifiedPath);\nEntry entry = lookupEntry(qualifiedPath);\nif (entry == null) {\nthrow new FileNotFoundException(\"File does not exist: \" + qualifiedPath);\n}\nreturn new SeaweedHadoopInputStream(filerClient, entry, statistics, qualifiedPath);\n}", "CodeBleu_score": 58.80772430696025}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\tfinal SeaweedHadoopFileSystem fs = (SeaweedHadoopFileSystem) path.getFileSystem(conf);\nfinal SeaweedFilerClient filerClient = fs.getFilerClient();\nfinal SeaweedFilerProto.LookupEntryResponse lookupEntryResponse = filerClient.lookupEntry(toUri(path));\nif (lookupEntryResponse.hasError()) {\nthrow new FileNotFoundException(lookupEntryResponse.getError().toString());\n}\nfinal SeaweedFilerProto.Entry entry = lookupEntryResponse.getEntry();\nfinal String fileName = entry.getName();\nLOG.debug(\"openFileForRead: \" + path);\nreturn new SeaweedHadoopInputStream(fs, filerClient, statistics, path, fileName);\n}", "CodeBleu_score": 42.97181375866581}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t// Log the path being opened\nLOG.debug(\"Opening file for read: \" + path);\n// Look up the file entry\nFileEntry fileEntry = lookupEntry(path);\nif (fileEntry == null) {\nthrow new FileNotFoundException(\"File \" + path + \" does not exist\");\n}\n// Return a new SeaweedHadoopInputStream\nreturn new SeaweedHadoopInputStream(fileEntry, filerClient, statistics, path);\n}", "CodeBleu_score": 58.761760342780214}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\tthis.localHost = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tthis.localHost = \"localhost\";\n\t}\n\tthis.numThreads = conf.getInt(\"mapred.map.tasks\", 1);\n\tthis.numFilesPerThread = conf.getInt(\"mapred.map.tasks.files.per.thread\", 1);\n\tthis.threadPool = newFixedThreadPool(this.numThreads);\n\tfor (int i = 0; i < this.numThreads; i++) {\n\t\tthis.threadPool.execute(new MapRunner());\n\t}\n}", "CodeBleu_score": 34.626116459411335}, {"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\tthis.hostName = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tthis.hostName = \"localhost\";\n\t}\n\tthis.numThreads = conf.getInt(\"mapred.map.tasks\", 1);\n\tthis.numFiles = conf.getInt(\"mapred.map.maxattempts\", 1);\n\tthis.pool = newFixedThreadPool(this.numThreads);\n\tfor (int i = 0; i < this.numThreads; i++) {\n\t\tthis.pool.execute(new Thread(this));\n\t}\n}", "CodeBleu_score": 35.175707954102975}, {"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\thostName = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\thostName = \"localhost\";\n\t}\n\tnumThreads = conf.getInt(\"mapred.map.tasks\", 1);\n\tnumFiles = conf.getInt(\"mapred.map.tasks.files\", 1);\n\tpool = newFixedThreadPool(numThreads);\n\tfor (int i = 0; i < numThreads; i++) {\n\t\tpool.execute(new TaskRunner());\n\t}\n}", "CodeBleu_score": 49.24970059710467}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\ttry {\nString host = getHost(uri);\nString emptier = getEmptier(uri);\nUserGroupInformation superUser = createRemoteUser(host);\nif (isRunning(host, emptier)) {\n\n\nlog.info(\"trash emptier is already running for host\");\n}\n}\n}", "CodeBleu_score": 13.964576241102995}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t\t// Check if the trash emptier is already running for the specified host\n\tif (isRunning(uri)) {\n\t\tLOG.info(\"Trash emptier already running for \" + uri);\n\t\treturn;\n\t}\n\n\t// Create a superuser\n\tUserGroupInformation ugi = createRemoteUser(conf);\n\n\t// Initialize a JuiceFileSystemImpl instance as the superuser\n\tFileSystem fs = initialize(ugi, conf);\n\n\t// Start the trash emptier task using the initialized file system and the trash configuration\n\tscheduleTrashEmptier(fs, conf);\n}", "CodeBleu_score": 14.04121073069079}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tfinal String host = getHost(uri);\nif (isRunning(host)) {\n\n\nlog.info(\"trash emptier is already running for host\");\n}\n}", "CodeBleu_score": 7.844630447957298}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t\tif (context == null) {\n\t\tthrow new Exception(\"Context cannot be null\");\n\t}\n\tif (context.length() > 255) {\n\t\tthrow new Exception(\"Context cannot be longer than 255 characters\");\n\t}\n\tString current = getCurrent();\n\tif (current == null) {\n\t\tsetCurrent(context);\n\t} else {\n\t\tString[] parts = current.split(\"\\\\|\");\n\t\tboolean found = false;\n\t\tfor (String part : parts) {\n\t\t\tif (part.equals(context)) {\n\t\t\t\tfound = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (!found) {\n\t\t\tsetCurrent(current + \"|\" + context);\n\t\t}\n\t}\n}", "CodeBleu_score": 29.71386989364582}, {"code": "public static void setContext(String context) throws Exception{\n\t\tif (context == null || context.isEmpty()) {\n\t\tthrow new Exception(\"Context cannot be null or empty\");\n\t}\n\n\t// Get the current context\n\tString currentContext = getCurrent();\n\tif (currentContext == null) {\n\t\t// Create a new context\n\t\tcurrentContext = context;\n\t\tsetCurrent(currentContext);\n\t} else {\n\t\t// Check if the current context is valid\n\t\tif (!isContextValid(currentContext)) {\n\t\t\tthrow new Exception(\"Current context is invalid\");\n\t\t}\n\n\t\t// Check if the current context already contains the new context\n\t\tif (currentContext.contains(context)) {\n\t\t\treturn;\n\t\t}\n\n\t\t// Check if the current context already contains a signature\n\t\tif (currentContext.endsWith(SIGNATURE_SEPARATOR)) {\n\t\t\t// Append the new context to the existing one\n\t\t\tcurrentContext = currentContext + context;\n\t\t} else {\n\t\t\t// Append the new context and a signature to the existing one\n\t\t\tcurrentContext = currentContext + SIGNATURE_SEPARATOR + context;\n\t\t}\n\n\t\t// Set the new context\n\t\tsetCurrent(currentContext);\n\t}\n}", "CodeBleu_score": 26.806971868577268}, {"code": "public static void setContext(String context) throws Exception{\n\t\tif (context == null) {\n\t\tthrow new Exception(\"Context cannot be null\");\n\t}\n\tString currentContext = getCurrent();\n\tif (currentContext == null) {\n\t\tsetCurrent(context);\n\t} else {\n\t\tif (!isContextValid(currentContext)) {\n\t\t\tsetCurrent(context);\n\t\t} else {\n\t\t\tif (!currentContext.endsWith(SIGNATURE_SEPARATOR)) {\n\t\t\t\tsetCurrent(currentContext + SIGNATURE_SEPARATOR + context);\n\t\t\t} else {\n\t\t\t\tif (currentContext.contains(context)) {\n\t\t\t\t\treturn;\n\t\t\t\t} else {\n\t\t\t\t\tsetCurrent(currentContext + context);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 23.05543419370692}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t\n}", "CodeBleu_score": 4.1687620148226046}, {"code": "Status HDFS::remove_file(const URI& uri){\n\tconst char* path = uri.to_path().c_str();\n\n// Connect to the HDFS file system\nRETURN_NOT_OK(connect());\n\n// Delete the file\nLOG_STATUS(Status_HDFSError(hdfsDelete(hdfs_conn_, path, 0)));\n\nreturn Status::Ok();\n}", "CodeBleu_score": 32.912399025022424}, {"code": "Status HDFS::remove_file(const URI& uri){\n\tLOG_TRACE", "CodeBleu_score": 4.141911376668391}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\tstd::string", "CodeBleu_score": 2.550587212109684}, {"code": "Status HDFS::sync(const URI& uri){\n\tRETURN_NOT_OK(connect());\nconst std::string& path = uri.to_path();\nif (!is_file(path)) {\nreturn Status::Ok();\n}\n\nStatus_HDFSFile file = libhdfs_->hdfsOpenFile(hdfs_fs_, path.c_str(), O_WRONLY | O_APPEND);\nif (!file.ok()) {\nLOG_STATUS(Status_HDFSError(\"Failed to open file \" + uri.to_string(), file.status));\nreturn Status_HDFSError(\"Failed to open file \" + uri.to_string(), file.status);\n}\n\nStatus_HDFSFile flush = libhdfs_->hdfsHFlush(hdfs_fs_, file.get());\nif (!flush.ok()) {\nLOG_STATUS(Status_HDFSError(\"Failed to flush file \" + uri.to_string(), flush.status));\nreturn Status_HDFSError(\"Failed to flush file \" + uri.to_string(), flush.status);\n}\n\nStatus_HDFSFile close = libhdfs_->hdfsCloseFile(hdfs_fs_, file.get());\nif (!close.ok()) {\nLOG_STATUS(Status_HDFSError(\"Failed to close file \" + uri.to_string(), close.status));\nreturn Status_HDFSError(\"Failed to close file \" + uri.to_string(), close.status);\n}\n\nreturn Status::Ok();\n}", "CodeBleu_score": 46.83019884814651}, {"code": "Status HDFS::sync(const URI& uri){\n\tstd::string", "CodeBleu_score": 2.550587212109684}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\thdfsFS fs;\nhdfsFileInfo* file_info;\n*nbytes = 0;\nRETURN_NOT_OK(connect(uri, &fs));\nfile_info = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\nif (file_info == NULL) {\nLOG_STATUS(Status_HDFSError(\"Cannot get file info for \" + uri.to_string()));\n} else if (file_info->mKind != kObjectKindFile) {\nLOG_STATUS(Status_HDFSError(\"Not a file: \" + uri.to_string()));\n} else {\n*nbytes = file_info->mSize;\nlibhdfs_->hdfsFreeFileInfo(file_info, 1);\n}\nRETURN_NOT_OK(Status::Ok());\n}", "CodeBleu_score": 54.31678692224092}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\thdfsFS fs;", "CodeBleu_score": 3.3272544246322013}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t\tLOG_STATUS(connect(uri));\n\thdfsFileInfo* file_info = libhdfs_->hdfsGetPathInfo(hdfs_conn_, uri.to_path().c_str());\n\tif (file_info == nullptr) {\n\t\tstd::string msg = \"Cannot get file information for \" + uri.to_string();\n\t\tLOG_STATUS(Status_HDFSError(msg));\n\t} else {\n\t\tif (file_info->mKind != kObjectKindFile) {\n\t\t\tstd::string msg = \"Cannot get the size of \" + uri.to_string() + \" because it is not a file\";\n\t\t\tLOG_STATUS(Status_HDFSError(msg));\n\t\t} else {\n\t\t\t*nbytes = file_info->mSize;\n\t\t\tlibhdfs_->hdfsFreeFileInfo(file_info, 1);\n\t\t}\n\t}\n\treturn Status::Ok();\n}", "CodeBleu_score": 51.07775210565747}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tif (hbaseCfgString == null) {\n\t\tthrow new IllegalArgumentException(\"HBase configuration string cannot be null\");\n\t}\n\tString[] hbaseCfgTokens = hbaseCfgString.split(\";\");\n\tString zookeeperQuorum = null;\n\tString znodeParent = DEFAULT_ZNODE_PARENT;\n\tfor (String hbaseCfgToken : hbaseCfgTokens) {\n\t\tif (hbaseCfgToken.startsWith(\"hbase.zookeeper.quorum\")) {\n\t\t\tzookeeperQuorum = hbaseCfgToken.split(\"=\")[1];\n\t\t}\n\t\tif (hbaseCfgToken.startsWith(\"zookeeper.znode.parent\")) {\n\t\t\tznodeParent = hbaseCfgToken.split(\"=\")[1];\n\t\t}\n\t}\n\tif (zookeeperQuorum == null) {\n\t\tthrow new IllegalArgumentException(\"HBase configuration string is missing the hbase.zookeeper.quorum property\");\n\t}\n\tif (!zookeeperQuorum.contains(\":\")) {\n\t\tzookeeperQuorum += \":2181\";\n\t}\n\treturn Pair.of(zookeeperQuorum, znodeParent);\n}", "CodeBleu_score": 23.281589575111326}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString[] cfg = hbaseCfgString.split(\";\");\n\tString quorum = cfg[0];\n\tString znode = \"/hbase\";\n\tif (cfg.length > 1) {\n\t\tznode = cfg[1];\n\t}\n\tif (!quorum.contains(\":\")) {\n\t\tquorum += \":2181\";\n\t}\n\treturn new Pair<>(quorum, znode);\n}", "CodeBleu_score": 21.917350722193103}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString zookeeperQuorum = \"\";\n\tString znodeParent = \"/hbase\";\n\tString[] hbaseCfgStringParts = hbaseCfgString.split(\",\");\n\tfor (String hbaseCfgStringPart : hbaseCfgStringParts) {\n\t\tString[] hbaseCfgStringPartParts = hbaseCfgStringPart.split(\"=\");\n\t\tif (hbaseCfgStringPartParts[0].equals(\"hbase.zookeeper.quorum\")) {\n\t\t\tzookeeperQuorum = hbaseCfgStringPartParts[1];\n\t\t}\n\t\tif (hbaseCfgStringPartParts[0].equals(\"zookeeper.znode.parent\")) {\n\t\t\tznodeParent = hbaseCfgStringPartParts[1];\n\t\t}\n\t}\n\tif (zookeeperQuorum.isEmpty()) {\n\t\tthrow new IllegalArgumentException(\"The HBase configuration string must contain the property 'hbase.zookeeper.quorum'.\");\n\t}\n\tif (!zookeeperQuorum.contains(\":\")) {\n\t\tzookeeperQuorum += \":2181\";\n\t}\n\tif (znodeParent.isEmpty()) {\n\t\tznodeParent = \"/hbase\";\n\t}\n\treturn new Pair<>(zookeeperQuorum, znodeParent);\n}", "CodeBleu_score": 25.569995512533584}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\ttry {\n\t\tLOG.info(\"validate hbase writer config\");\n\t\tString namespace = cfg.getNamespace();\n\t\tString tableName = cfg.getTableName();\n\t\tString[] column = cfg.getColumn();\n\t\tString[] split = tableName.split(\"\\\\.\");\n\t\tif (split.length > 1) {\n\t\t\tnamespace = split[0];\n\t\t\ttableName = split[1];\n\t\t}\n\t\tLOG.info(\"namespace : [{}], tableName : [{}], column : [{}]\", namespace, tableName, column);\n\t\tConnection conn = getJdbcConnection(cfg.getUsername(), cfg.getPassword(), cfg.getJdbcUrl(), cfg.getDriverClass());\n\t\tcheckTable(conn, namespace, tableName);\n\t\tTableSchema tableSchema = getTableSchema(conn, namespace, tableName);\n\t\tLOG.info(\"tableSchema : [{}]\", tableSchema);\n\t\tfor (String col : column) {\n\t\t\tgetColumnForColumnName(tableSchema, col);\n\t\t}\n\t} catch (Exception e) {\n\t\tLOG.error(\"validate hbase writer config error\", e);\n\t\tthrow AddaxException.asAddaxException(HBASE_SQL_PLUGIN_ID, \"validate hbase writer config error\", e);\n\t}\n}", "CodeBleu_score": 29.697974235333945}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\ttry (Connection conn = getJdbcConnection(cfg)) {\n\t\tcheckTable(conn, cfg.getNamespace(), cfg.getTableName(), cfg.getColumns());\n\t} catch (SQLException e) {\n\t\tthrow AddaxException.asAddaxException(\n\t\t\t\tHbaseSQLWriterErrorCode.JDBC_CONNECTION_ERROR, e);\n\t}\n}", "CodeBleu_score": 14.968442688283313}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\ttry {\n\t\tConnection conn = getJdbcConnection(cfg);\n\t\tif (cfg.isThinClient()) {\n\t\t\tif (cfg.getZkQuorum() == null || cfg.getZkQuorum().isEmpty()) {\n\t\t\t\tthrow new AddaxException(\"The parameter 'zkQuorum' is required when using a thin client connection.\");\n\t\t\t}\n\t\t\tif (cfg.getZkClientPort() == null || cfg.getZkClientPort().isEmpty()) {\n\t\t\t\tthrow new AddaxException(\"The parameter 'zkClientPort' is required when using a thin client connection.\");\n\t\t\t}\n\t\t}\n\t\tString namespace = getNamespace(cfg);\n\t\tif (namespace == null || namespace.isEmpty()) {\n\t\t\tthrow new AddaxException(\"The parameter 'namespace' is required.\");\n\t\t}\n\t\tString tableName = getTableName(cfg);\n\t\tif (tableName == null || tableName.isEmpty()) {\n\t\t\tthrow new AddaxException(\"The parameter 'table' is required.\");\n\t\t}\n\t\tcheckTable(conn, namespace, tableName);\n\t\tList<String> columns = getColumns(conn, namespace, tableName);\n\t\tfor (String column : cfg.getColumn()) {\n\t\t\tif (!columns.contains(column)) {\n\t\t\t\tthrow new AddaxException(\"The column '\" + column + \"' does not exist in the table '\" + tableName + \"'.\");\n\t\t\t}\n\t\t}\n\t} catch (SQLException e) {\n\t\tthrow new AddaxException(\"An error occurred while validating the configuration for HbaseSQLWriter: \" + e.getMessage(), e);\n\t}\n}", "CodeBleu_score": 37.38733390262821}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\n\t\tLOGGER.info(\"Kerberos authentication for principal {} from keytab file {}\", kerberosPrincipal, kerberosKeytabFilePath);\n\t\tConfiguration hadoopConf = new Configuration();\n\t\thadoopConf.set(\"hadoop.security.authentication\", \"kerberos\");\n\t\thadoopConf.set(\"hadoop.security.authorization\", \"true\");\n\t\tUserGroupInformation.setConfiguration(hadoopConf);\n\t\ttry {\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tthrow AddaxException.asAddaxException(\n\t\t\t\t\tFrameworkErrorCode.CONFIG_ERROR,\n\t\t\t\t\tString.format(\"Failed to login using principal %s from keytab file %s\", kerberosPrincipal, kerberosKeytabFilePath), e);\n\t\t}\n\t}\n}", "CodeBleu_score": 49.46924210506916}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\n\t\tlog.info(\"Kerberos authentication is enabled. Attempting to login using principal: {} and keytab file: {}\", kerberosPrincipal, kerberosKeytabFilePath);\n\t\tConfiguration conf = HdfsHelper.getConfiguration();\n\t\tconf.set(\"hadoop.security.authentication\", \"kerberos\");\n\t\tUserGroupInformation.setConfiguration(conf);\n\t\ttry {\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t\tlog.info(\"Successfully logged in using principal: {} and keytab file: {}\", kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tthrow new AsAddaxException(\"Kerberos login failed using principal: \" + kerberosPrincipal + \" and keytab file: \" + kerberosKeytabFilePath + \". Please ensure that the principal and keytab file are valid.\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 47.453882676525474}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\n\t\ttry {\n\t\t\tUserGroupInformation.setConfiguration(new Configuration());\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tthrow AddaxException.asAddaxException(\n\t\t\t\t\tFrameworkErrorCode.CONFIG_ERROR,\n\t\t\t\t\tString.format(\"Kerberos login failure, please check kerberos configuration:%s,%s\", kerberosPrincipal,\n\t\t\t\t\t\t\tkerberosKeytabFilePath));\n\t\t}\n\t}\n}", "CodeBleu_score": 35.557485301514745}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> colMap = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\nResultSetMetaData md = rs.getMetaData();\nint colCount = md.getColumnCount();\nfor (int i = 1; i <= colCount; i++) {\nString colName = md.getColumnLabel(i);\nif (colName == null) {\nthrow new SQLException(\"Column name cannot be null\");\n}\nint colType = md.getColumnType(i);\nif (colType == 0) {\nthrow new SQLException(\"Column type cannot be null\");\n}\ncolMap.put(colName, new ThinClientPTable.ThinClientPColumn(colName,\nType.fromSqlTypeName(md.getColumnTypeName(i))));\n}\nreturn colMap;\n}", "CodeBleu_score": 39.760973400263374}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> colMap = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\nResultSetMetaData rsmd = rs.getMetaData();\nint colCount = rsmd.getColumnCount();\nfor (int i = 1; i <= colCount; i++) {\nString colName = rsmd.getColumnLabel(i);\nString typeName = rsmd.getColumnTypeName(i);\nif (colName == null || typeName == null) {\nthrow new SQLException(\"Column name or type is null.\");\n}\ncolMap.put(colName, new ThinClientPTable.ThinClientPColumn(colName,\ntoPDataType(typeName)));\n}\nreturn colMap;\n}", "CodeBleu_score": 38.68358105022657}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> colMap = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\nResultSetMetaData rsmd = rs.getMetaData();\nint colCount = rsmd.getColumnCount();\nfor (int i = 1; i <= colCount; i++) {\nString colName = rsmd.getColumnLabel(i);\nif (colName == null) {\nthrow new SQLException(\"Column name cannot be null\");\n}\nString colType = rsmd.getColumnTypeName(i);\nif (colType == null) {\nthrow new SQLException(\"Column type cannot be null\");\n}\ncolMap.put(colName, new ThinClientPTable.ThinClientPColumn(colName,\nType.fromSqlTypeName(colType)));\n}\nreturn colMap;\n}", "CodeBleu_score": 38.955625622598674}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\ttry {\n// Unwrap the connection\nPhoenixConnection pconn = conn.unwrap(PhoenixConnection.class);\n// Get the HBase Admin instance\nHBaseAdmin admin = pconn.getQueryServices().getAdmin();\n// Check if the table exists\nif (admin.tableExists(tableName)) {\n// Disable the table\nadmin.disableTable(tableName);\n// Truncate the table\nadmin.truncateTable(tableName, true);\n// Log a debug message\nLOG.debug(\"Successfully truncated table \" + tableName);\n} else {\n// Throw an exception with an error code and message\nthrow new AddaxException(ErrorCode.TABLE_NOT_EXIST, \"Table \" + tableName + \" does not exist\");\n}\n} catch (Exception e) {\n// Throw an exception with an error code and message\nthrow new AddaxException(ErrorCode.ILLEGAL_VALUE, \"Failed to truncate table \" + tableName, e);\n} finally {\n// Ensure the Admin instance is closed properly\ntry {\nadmin.close();\n} catch (IOException e) {\n// Ignore\n}\n}\n}", "CodeBleu_score": 41.51347973022184}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t\ttry {\n\t\tif (conn == null) {\n\t\t\tthrow new AddaxException(ErrorCode.CONFIG_INVALID_PARAMETER, \"The input connection is null\");\n\t\t}\n\t\tif (StringUtils.isEmpty(tableName)) {\n\t\t\tthrow new AddaxException(ErrorCode.CONFIG_INVALID_PARAMETER, \"The input table name is null or empty\");\n\t\t}\n\t\t// Unwrap the connection to get the PhoenixConnection\n\t\tPhoenixConnection phxConn = conn.unwrap(PhoenixConnection.class);\n\t\t// Get the HBase Admin instance\n\t\tHBaseAdmin admin = phxConn.getQueryServices().getAdmin();\n\t\t// Check if the table exists\n\t\tif (!admin.tableExists(tableName)) {\n\t\t\tthrow new AddaxException(ErrorCode.CONFIG_INVALID_PARAMETER, \"The table \" + tableName + \" does not exist\");\n\t\t}\n\t\t// Disable the table\n\t\tadmin.disableTable(tableName);\n\t\t// Truncate the table\n\t\tadmin.truncateTable(tableName, true);\n\t\t// Log a debug message\n\t\tLOG.debug(\"The table \" + tableName + \" has been truncated\");\n\t} catch (Exception e) {\n\t\tthrow AddaxException.asAddaxException(e);\n\t} finally {\n\t\t// Ensure the Admin instance is closed properly\n\t\ttry {\n\t\t\tif (conn != null) {\n\t\t\t\tconn.close();\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tthrow AddaxException.asAddaxException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 47.04576838127218}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t\ttry {\n\t\tPhoenixConnection pconn = conn.unwrap(PhoenixConnection.class);\n\t\tHBaseAdmin admin = pconn.getQueryServices().getAdmin();\n\t\tif (admin.tableExists(tableName)) {\n\t\t\tadmin.disableTable(tableName);\n\t\t\tadmin.truncateTable(tableName, true);\n\t\t\tLOGGER.debug(\"Table \" + tableName + \" truncated.\");\n\t\t} else {\n\t\t\tLOGGER.debug(\"Table \" + tableName + \" does not exist.\");\n\t\t}\n\t} catch (Exception e) {\n\t\tthrow new AsAddaxException(ErrorCode.CONFIG_UNABLE_TO_TRUNCATE_HBASE_TABLE, e);\n\t} finally {\n\t\ttry {\n\t\t\tconn.closeAdmin();\n\t\t} catch (Exception e) {\n\t\t\tLOGGER.error(\"Error closing HBase Admin instance.\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 40.292143534617175}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\tif (filePath.endsWith(fileType)) {\ninfo(\"add file [\" + filePath + \"] to source files list\");\nsourceFiles.add(filePath);\n} else {\nString errorMessage = \"unsupported file type: \" + filePath;\nerror(errorMessage);\nthrow new AddaxException(errorMessage);\n}\n}", "CodeBleu_score": 16.95602359406701}, {"code": "private void addSourceFileByType(String filePath){\n\tif (filePath == null) {\nthrow new IllegalArgumentException(\"File path is null\");\n}\n\nString fileType = getHdfsFileType(filePath);\nif (fileType == null) {\nthrow new IllegalArgumentException(\"Unsupported file type: \" + filePath);\n}\n\nif (fileType.equals(fileType)) {\nlogger.info(\"Adding file: \" + filePath);\nsourceFiles.add(filePath);\n} else {\nlogger.error(\"Unsupported file type: \" + filePath);\nthrow new IllegalArgumentException(\"Unsupported file type: \" + filePath);\n}\n}", "CodeBleu_score": 22.948076330533056}, {"code": "private void addSourceFileByType(String filePath){\n\tif (filePath.endsWith(format.getFileType())) {\ninfo(\"add file [\" + filePath + \"] to source file list\");\nsourceFiles.add(filePath);\n} else {\nerror(\"unsupported file type [\" + filePath + \"], only \" + format.getFileType() + \" files are supported\");\nthrow new asAddaxException(\"unsupported file type [\" + filePath + \"], only \" + format.getFileType() + \" files are supported\");\n}\n}", "CodeBleu_score": 18.296236166928878}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\ttry {\n\t\tlogger.info(\"The sequence file path to be read is: [{}]\", sourceSequenceFilePath);\n\t\tFileSystem fs = FileSystem.get(readerSliceConfig);\n\t\tPath path = new Path(sourceSequenceFilePath);\n\t\tif (!fs.exists(path)) {\n\t\t\tthrow AddaxException.asAddaxException(\n\t\t\t\t\tFrameworkErrorCode.CONFIG_ERROR,\n\t\t\t\t\tString.format(\"The file path [%s] of sequence file does not exist.\", sourceSequenceFilePath));\n\t\t}\n\t\tif (fs.isDirectory(path)) {\n\t\t\tthrow AddaxException.asAddaxException(\n\t\t\t\t\tFrameworkErrorCode.CONFIG_ERROR,\n\t\t\t\t\tString.format(\"The file path [%s] of sequence file is a directory.\", sourceSequenceFilePath));\n\t\t}\n\t\tlogger.info(\"The start read sequence file [{}] successfully.\", sourceSequenceFilePath);\n\t\tFSDataInputStream inputStream = fs.open(path);\n\t\tBufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream));\n\t\tString line;\n\t\twhile ((line = bufferedReader.readLine()) != null) {\n\t\t\tif (StringUtils.isBlank(line)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tString[] splitedLine = line.split(Constant.SPLIT_STRING);\n\t\t\tif (splitedLine.length != 2) {\n\t\t\t\tthrow AddaxException.asAddaxException(\n\t\t\t\t\t\tFrameworkErrorCode.CONFIG_ERROR,\n\t\t\t\t\t\tString.format(\"The format of sequence file is incorrect. The correct format is [key\\\\tvalue]. The actual format is [%s]\", line));\n\t\t\t}\n\t\t\tbyte[] key = splitedLine[0].getBytes();\n\t\t\tbyte[] value = splitedLine[1].getBytes();\n\t\t\ttransportOneRecord(recordSender, key, value, taskPluginCollector);\n\t\t}\n\t\tlogger.info(\"All the data in sequence file [{}] have been read.\", sourceSequenceFilePath);\n\t} catch (Exception e) {\n\t\tString errorMessage = String.format(\"Failed to read sequence file [%s] as a HDFS file. Because of the following exception:\", sourceSequenceFilePath);\n\t\tlogger.error(errorMessage, e);\n\t\tthrow AddaxException.asAddaxException(FrameworkErrorCode.READ_RECORD_FAILED, errorMessage, e);\n\t}\n}", "CodeBleu_score": 39.01960564013871}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\ttry {\n\t\tlogger.info(\"The source file path to be read by the sequence file reader is: [{}]\", sourceSequenceFilePath);\n\t\tFileSystem fs = FileSystem.get(readerSliceConfig);\n\t\tPath path = new Path(sourceSequenceFilePath);\n\t\tif (!fs.exists(path)) {\n\t\t\tthrow AddaxException.asAddaxException(\n\t\t\t\t\tHiveReaderErrorCode.READ_FILE_PATH_NOT_EXISTS,\n\t\t\t\t\tString.format(\"The file path [%s] does not exist.\", sourceSequenceFilePath));\n\t\t}\n\t\tlogger.info(\"The start read time of the current file to be read is: [{}].\", System.currentTimeMillis());\n\t\tFSDataInputStream inputStream = fs.open(path);\n\t\tDataInputStream dis = new DataInputStream(inputStream);\n\t\tWritable key = ReflectionUtils.newInstance(readerSliceConfig.getClass(\n\t\t\t\tKey.KEY_CLASS_NAME, null), readerSliceConfig);\n\t\tWritable value = ReflectionUtils.newInstance(readerSliceConfig.getClass(\n\t\t\t\tValue.VALUE_CLASS_NAME, null), readerSliceConfig);\n\t\tSequenceFile.Reader reader = null;\n\t\ttry {\n\t\t\treader = new SequenceFile.Reader(dis);\n\t\t\treader.sync(reader.getPosition());\n\t\t\twhile (reader.next(key, value)) {\n\t\t\t\tif (null != key && null != value) {\n\t\t\t\t\ttransportOneRecord(recordSender, readerSliceConfig, key, value, taskPluginCollector);\n\t\t\t\t}\n\t\t\t}\n\t\t} finally {\n\t\t\tif (null != reader) {\n\t\t\t\treader.close();\n\t\t\t}\n\t\t}\n\t\tlogger.info(\"The end read time of the current file has been reached. The total read time of the current file is: [{}].\",\n\t\t\t\tSystem.currentTimeMillis());\n\t} catch (Exception e) {\n\t\tString errorMessage = String.format(\"Failed to read the sequence file. %s\", e.getMessage());\n\t\tlogger.error(errorMessage);\n\t\tthrow AddaxException.asAddaxException(HiveReaderErrorCode.READ_FILE_IO_ERROR, e);\n\t}\n}", "CodeBleu_score": 46.80755146550914}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\tString path = String.format(\"Read sequence file [%s] by [Thread-%d] task\", sourceSequenceFilePath,\n\t\t\tTaskPluginCollector.getTaskPluginCollector().getTaskInfo().getTaskId());\n\tLOGGER.info(String.format(\"The sequence file [{}] starts to be read.\", sourceSequenceFilePath));\n\tFileSystem fs = null;\n\tFSDataInputStream inputStream = null;\n\ttry {\n\t\tfs = FileSystem.get(readerSliceConfig);\n\t\tinputStream = fs.open(new Path(sourceSequenceFilePath));\n\t} catch (Exception e) {\n\t\tLOGGER.error(String.format(\"Failed to read the sequence file [%s].\", sourceSequenceFilePath), e);\n\t.error(String.format(\"Failed to read the sequence file [%s].\", sourceSequenceFilePath), e);\n\t\tthrow AddaxException.asAddaxException(\n\t\t\t\tFrameworkErrorCode.READ_RECORD_FAILED, e);\n\t}\n\tSequenceFile.Reader reader = null;\n\ttry {\n\t\treader = new SequenceFile.Reader(inputStream, readerSliceConfig);\n\t} catch (Exception e) {\n\t\tLOGGER.error(String.format(\"Failed to create the reader for the sequence file [%s].\", sourceSequenceFilePath),\n\t\t\t\te);\n\t\tthrow AddaxException.asAddaxException(\n\t\t\t\tFrameworkErrorCode.READ_RECORD_FAILED, e);\n\t}\n\tClass<? extends Writable> keyClass = reader.getKeyClass();\n\tClass<? extends Writable> valueClass = reader.getValueClass();\n\ttry {\n\t\tWritable key = ReflectionUtils.newInstance(keyClass, readerSliceConfig);\n\t\tWritable value = ReflectionUtils.newInstance(valueClass, readerSliceConfig);\n\t\twhile (reader.next(key, value)) {\n\t\t\tif (null != key) {\n\t\t\t\tString valueString = value.toString();\n\t\t\t\tif (StringUtils.isNotBlank(valueString)) {\n\t\t\t\t\ttransportOneRecord(recordSender, valueString, taskPluginCollector);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} catch (Exception e) {\n\t\tLOGGER.error(String.format(\"Failed to transport the record for the sequence file [%s].\", sourceSequenceFilePath),\n\t\t\t\te);\n\t\tthrow AddaxException.asAddaxException(\n\t\t\t\tFrameworkErrorCode.READ_RECORD_FAILED, e);\n\t} finally {\n\t\tIO", "CodeBleu_score": 42.498595565876144}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\ttry {\nFileSystem fs = FileSystem.get(URI.create(filepath), new Configuration());\nPath path = new Path(filepath);\nif (specifiedFileType.equalsIgnoreCase(\"orc\")) {\nreturn isORCFile(fs, path);\n} else if (specifiedFileType.equalsIgnoreCase(\"rc\")) {\nreturn isRCFile(fs, path);\n} else if (specifiedFileType.equalsIgnoreCase(\"sequence\")) {\nreturn isSequenceFile(fs, path);\n} else if (specifiedFileType.equalsIgnoreCase(\"parquet\")) {\nreturn isParquetFile(fs, path);\n} else if (specifiedFileType.equalsIgnoreCase(\"csv\")) {\nreturn isCSVFile(fs, path);\n} else if (specifiedFileType.equalsIgnoreCase(\"text\")) {\nreturn isTextFile(fs, path);\n} else {\nthrow AddaxException.asAddaxException(\nErrorCode.CONFIG_INVALID_TYPE,\nString.format(\"The specified file type %s is not supported. Only ORC, RC, Sequence, Parquet, CSV, and Text file types are supported.\", specifiedFileType));\n}\n} catch (Exception e) {\nLOGGER.error(\"Failed to check the file type of HDFS file. The file path is: \" + filepath, e);\nthrow AddaxException.asAddaxException(\nErrorCode.CONFIG_INVALID_VALUE,\nString.format(\"Failed to check the file type of HDFS file. The file path is: %s\", filepath), e);\n}\n}", "CodeBleu_score": 41.91006160202062}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(URI.create(filepath), new Configuration());\n\t\tPath path = new Path(filepath);\n\t\tif (specifiedFileType.equals(\"orc\")) {\n\t\t\tif (fs.isFile(path) && fs.exists(path) && fs.getFileSystem(URI.create(filepath)).getConf().get(\"fs.default.name\").startsWith(\"hdfs\")) {\n\t\t\t\treturn isORCFile(filepath);\n\t\t\t}\n\t\t} else if (specifiedFileType.equals(\"rc\")) {\n\t\t\tif (fs.isFile(path) && fs.exists(path) && fs.getFileSystem(URI.create(filepath)).getConf().get(\"fs.default.name\").startsWith(\"hdfs\")) {\n\t\t\t\treturn isRcFile(filepath);\n\t\t\t}\n\t\t} else if (specifiedFileType.equals(\"sequence\")) {\n\t\t\tif (fs.isFile(path) && fs.exists(path) && fs.getFileSystem(URI.create(filepath)).getConf().get(\"fs.default.name\").startsWith(\"hdfs\")) {\n\t\t\t\treturn isSequenceFile(filepath);\n\t\t\t}\n\t\t} else if (specifiedFileType.equals(\"parquet\")) {\n\t\t\tif (fs.isFile(path) && fs.exists(path) && fs.getFileSystem(URI.create(filepath)).getConf().get(\"fs.default.name\").startsWith(\"hdfs\")) {\n\t\t\t\treturn isParquetFile(filepath);\n\t\t\t}\n\t\t} else if (specifiedFileType.equals(\"csv\")) {\n\t\t\tif (fs.isFile(path) && fs.exists(path) && fs.getFileSystem(URI.create(filepath)).getConf().get(\"fs.default.name\").startsWith(\"hdfs\")) {\n\t\t\t\treturn isCsvFile(filepath);\n\t\t\t}\n\t\t} else if (specifiedFileType.equals(\"text\")) {\n\t\t\tif (fs.isFile(path) && fs.exists(path) && fs.getFileSystem(URI.create(filepath)).getConf().get(\"fs.default.name\").startsWith(\"hdfs\")) {\n\t\t\t\treturn isTextFile(filepath);\n\t\t\t}\n\t\t} else {\n\t\t\tthrow AddaxException.asAddaxException(\n\t\t\t\t\tFrameworkErrorCode.CONFIG_ERROR,\n\t\t\t\t\t\"The specified file type is not supported. Please specify one of the following file types: orc, rc, sequence, parquet", "CodeBleu_score": 30.712710589619846}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\tFileSystem fs = null;\ntry {\nfs = FileSystem.get(new URI(filepath), new Configuration());\n} catch (URISyntaxException e) {\nthrow new AddaxException(e);\n} catch (IOException e) {\nthrow new AddaxException(e);\n}\nif (specifiedFileType.equalsIgnoreCase(\"orc\")) {\nreturn isORCFile(fs, filepath);\n} else if (specifiedFileType.equalsIgnoreCase(\"rc\")) {\nreturn isRCFile(fs, filepath);\n} else if (specifiedFileType.equalsIgnoreCase(\"sequence\")) {\nreturn isSequenceFile(fs, filepath);\n} else if (specifiedFileType.equalsIgnoreCase(\"parquet\")) {\nreturn isParquetFile(fs, filepath);\n} else if (specifiedFileType.equalsIgnoreCase(\"csv\")) {\nreturn isCSVFile(fs, filepath);\n} else if (specifiedFileType.equalsIgnoreCase(\"text\")) {\nreturn isTextFile(fs, filepath);\n} else {\nlogger.error(\"\u4e0d\u652f\u6301\u7684\u6587\u4ef6\u7c7b\u578b:\" + specifiedFileType);\nreturn false;\n}\n}", "CodeBleu_score": 28.656224519668683}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection != null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow asAddaxException(e);\n\t}\n}", "CodeBleu_score": 39.227215121291025}, {"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection != null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new AddaxException(e);\n\t}\n}", "CodeBleu_score": 39.32550763271724}, {"code": "public static void closeConnection(Connection hConnection){\n\t\tif (hConnection != null) {\n\t\ttry {\n\t\t\thConnection.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new AddaxException(\n\t\t\t\t\tHBase20xHelper.class,\n\t\t\t\t\t\"close connection failed.\",\n\t\t\t\t\te);\n\t\t}\n\t}\n}", "CodeBleu_score": 42.359397356194556}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin != null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new AddaxException(\n\t\t\t\t\tHBase20xSQLReaderErrorCode.CLOSE_ADMIN_ERROR,\n\t\t\t\t\tString.format(\"HBase \u8fde\u63a5\u5173\u95ed\u5931\u8d25. \u5931\u8d25\u4fe1\u606f\u662f: %s\", e.getMessage()), e);\n\t\t}\n\t}\n}", "CodeBleu_score": 52.2756341438952}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin != null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new AddaxException(\n\t\t\t\t\t\"HBaseWriter: HBase admin instance close exception, please check HBase connection configuration.\",\n\t\t\t\t\t AddaxException.HBASE_CLOSE_ADMIN_ERROR);\n\t\t}\n\t}\n}", "CodeBleu_score": 40.02785804589676}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin != null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new AddaxException(\n\t\t\t\t\tHBase20xSQLReaderErrorCode.CLOSE_HBASE_ADMIN_ERROR,\n\t\t\t\t\tString.format(\"Failed to close HBase Admin instance. message:%s\", e.getMessage()), e);\n\t\t}\n\t}\n}", "CodeBleu_score": 44.42039434402382}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\t// Extract the row key\n\tbyte[] row = cell.getRowArray();\n\tint rowOffset = cell.getRowOffset();\n\tint rowLength = cell.getRowLength();\n\t// Extract the timestamp\n\tlong timestamp = cell.getTimestamp();\n\t// Extract the column family, qualifier, and value\n\tbyte[] family = cell.getFamilyArray();\n\tint familyOffset = cell.getFamilyOffset();\n\tint familyLength = cell.getFamilyLength();\n\tbyte[] qualifier = cell.getQualifierArray();\n\tint qualifierOffset = cell.getQualifierOffset();\n\tint qualifierLength = cell.getQualifierLength();\n\tbyte[] value = cell.getValueArray();\n\tint valueOffset = cell.getValueOffset();\n\tint valueLength = cell.getValueLength();\n\t// Convert the row key to a string\n\tString rowKey = convertBytesToAssignType(row, rowOffset, rowLength, \"STRING\", null);\n\t// Convert the column family to a string\n\tString familyName = convertBytesToAssignType(family, familyOffset, familyLength, \"STRING\", null);\n\t// Convert the column qualifier to a string\n\tString qualifierName = convertBytesToAssignType(qualifier, qualifierOffset, qualifierLength, \"STRING\", null);\n\t// Convert the column value to the appropriate type and format\n\tString valueStr = convertBytesToAssignType(value, valueOffset, valueLength, \"STRING\", null);\n\t// Add the row key, family, qualifier, timestamp, and value as columns to the record\n\trecord.addColumn(rowKey, familyName, qualifierName, timestamp, valueStr);\n}", "CodeBleu_score": 29.263976404051007}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\t// Extract the row key and timestamp from the cell.\n\tbyte[] rowKey = cell.getRowArray();\n\tbyte[] timestamp = cell.getTimestampBytes();\n\t// Extract the column family, qualifier, and value from the cell.\n\tbyte[] family = CellUtil.cloneFamily(cell);\n\tbyte[] qualifier = CellUtil.cloneQualifier(cell);\n\tbyte[] value = CellUtil.cloneValue(cell);\n\t// Convert the row key and timestamp to the appropriate types.\n\tString rowKeyString = convertBytesToAssignType(rowKey, rowKeyFormat);\n\tLong timestampLong = convertBytesToAssignType(timestamp, timestampFormat);\n\t// Convert the column family, qualifier, and value to the appropriate types.\n\tString familyString = convertBytesToAssignType(family, familyFormat);\n\tString qualifierString = convertBytesToAssignType(qualifier, qualifierFormat);\n\tString valueString = convertBytesToAssignType(value, valueFormat);\n\t// Add the row key, family, qualifier, timestamp, and value as columns to the record.\n\trecord.setString(rowKeyColumn, rowKeyString);\n\trecord.setString(familyColumn, familyString);\n\trecord.setString(qualifierColumn, qualifierString);\n\trecord.setLong(timestampColumn, timestampLong);\n\trecord.setString(valueColumn, valueString);\n}", "CodeBleu_score": 28.150338668818314}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t// Get the row key and timestamp from the cell.\nbyte[] rowKey = cell.getRowArray();\nbyte[] timestamp = cell.getTimestampBytes();\n\n// Get the column family, qualifier, and value from the cell.\nbyte[] family = CellUtil.cloneFamily(cell);\nbyte[] qualifier = CellUtil.cloneQualifier(cell);\nbyte[] value = CellUtil.cloneValue(cell);\n\n// Convert the row key to a string.\nString rowKeyString = Bytes.toString(rowKey);\n\n// Convert the timestamp to a string.\nString timestampString = Bytes.toString(timestamp);\n\n// Convert the column family to a string.\nString familyString = Bytes.toString(family);\n\n// Convert the column qualifier to a string.\nString qualifierString = Bytes.toString(qualifier);\n\n// Convert the column value to a string.\nString valueString = Bytes.toString(value);\n\n// Add the row key, family, qualifier, timestamp, and value to the record.\nrecord.add(rowKeyString, familyString, qualifierString, timestampString, valueString);\n}", "CodeBleu_score": 22.04662967987907}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString userStartRowkey = configuration.get(Constants.START_ROWKEY);\n\tif (isBlank(userStartRowkey)) {\n\t\treturn new byte[0];\n\t} else if (isBinaryRowkey(userStartRowkey)) {\n\t\treturn stringToBytes(userStartRowkey);\n\t} else {\n\t\treturn userStartRowkey.getBytes(Constants.UTF8);\n\t}\n}", "CodeBleu_score": 37.47940772462472}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowkey = getString(configuration, \"hbase.startrowkey\", \"\");\n\tbyte[] startRowkeyBytes = startRowkey.getBytes();\n\tif (isBlank(startRowkeyBytes)) {\n\t\tstartRowkeyBytes = new byte[0];\n\t}\n\treturn startRowkeyBytes;\n}", "CodeBleu_score": 31.73320024895349}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString userStartRowkey = configuration.get(HConstants.START_ROW);\n\tif (isBlank(userStartRowkey)) {\n\t\treturn new byte[0];\n\t}\n\tboolean isBinaryRowkey = configuration.getBoolean(HConstants.BINARY_START_ROW, false);\n\tif (isBinaryRowkey) {\n\t\treturn Bytes.toBytesBinary(userStartRowkey);\n\t}\n\treturn Bytes.toBytes(userStartRowkey);\n}", "CodeBleu_score": 49.42614915409538}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(Constants.START_ROWKEY);\n\tif (isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t}\n\treturn toBytesBinary(startRowkey);\n}", "CodeBleu_score": 50.387765232864176}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(Constants.START_ROWKEY);\n\tif (StringUtils.isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t}\n\treturn toBytesBinary(startRowkey);\n}", "CodeBleu_score": 59.04781235038418}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(START_ROWKEY);\n\tif (isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t}\n\treturn toBytesBinary(startRowkey);\n}", "CodeBleu_score": 42.97930523872383}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tsuper(new TbQueueMsgUUID(record.key()));\nheaders = new TbQueueMsgHeaders();\nrecord.headers().forEach(header -> headers.put(header.key(), header.value().toString()));\ndata = record.value();\n}", "CodeBleu_score": 34.687574193095706}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tsuper(UUID.fromString(record.key()), new TbQueueMsgHeaders(record.headers()));\n\tthis.data = record.value();\n}", "CodeBleu_score": 28.212235702799543}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tsuper(new UUID(record.key()));\nheaders = new TbQueueMsgHeaders();\nrecord.headers().forEach(header -> headers.put(header.key(), header.value().toString()));\ndata = record.value();\n}", "CodeBleu_score": 33.71361767702346}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\treturn new TbQueueProducer<>(createTransportNotificationsMsgProducerTemplate());\n}", "CodeBleu_score": 8.628081372505441}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\tTbKafkaSettings kafkaSettings = new TbKafkaSettings();\n\tkafkaSettings.setBootstrapServers(settings.getKafka().getBootstrapServers());\n\tkafkaSettings.setSecurityProtocol(settings.getKafka().getSecurityProtocol());\n\tkafkaSettings.setSslKeystoreLocation(settings.getKafka().getSslKeystoreLocation());\n\tkafkaSettings.setSslKeystorePassword(settings.getKafka().getSslKeystorePassword());\n\tkafkaSettings.setSslKeystoreType(settings.getKafka().getSslKeystoreType());\n\tkafkaSettings.setSslTruststoreLocation(settings.getKafka().getSslTruststoreLocation());\n\tkafkaSettings.setSslTruststorePassword(settings.getKafka().getSslTruststorePassword());\n\tkafkaSettings.setSslTruststoreType(settings.getKafka().getSslTruststoreType());\n\tkafkaSettings.setAcks(settings.getKafka().getAcks());\n\tkafkaSettings.setRetries(settings.getKafka().getRetries());\n\tkafkaSettings.setBatchSize(settings.getKafka().getBatchSize());\n\tkafkaSettings.setLingerMs(settings.getKafka().getLingerMs());\n\tkafkaSettings.setBufferMemory(settings.getKafka().getBufferMemory());\n\tkafkaSettings.setKeySerializer(settings.getKafka().getKeySerializer());\n\tkafkaSettings.setValueSerializer(settings.getKafka().getValueSerializer());\n\tkafkaSettings.setCompressionType(settings.getKafka().getCompressionType());\n\tkafkaSettings.setClientId(clientId);\n\tkafkaSettings.setPollTimeoutMs(settings.getKafka().getPollTimeoutMs());\n\tkafkaSettings.setMaxInFlightRequestsPerConnection(settings.getKafka().getMaxInFlightRequestsPerConnection());\n\tkafkaSettings.setRequestTimeoutMs(settings.getKafka().getRequestTimeoutMs());\n\tkafkaSettings.setConnectionsMaxIdleMs(settings.getKafka().getConnectionsMaxIdleMs());\n\tkafkaSettings.setConsumerGroup(settings.getKafka().getConsumerGroup());\n\tkafkaSettings.setEnableIdempotence(settings.getKafka().getEnableIdempotence());\n\tkafkaSettings.setTransactionTimeoutMs(settings.getKafka().getTransactionTimeoutMs());\n\tkafkaSettings.setTransactionIdPrefix(settings.getKafka().getTransactionIdPrefix());\n\tkafkaSettings.setKeyDeserializationClass(settings.get", "CodeBleu_score": 35.49251062867488}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\n}", "CodeBleu_score": 5.886600204806592}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\treturn new TbKafkaConsumerTemplate<ToCoreNotificationMsg>(\n\t\t\tsettings,\n\t\t\tbuildNotificationsTopicName(),\n\t\t\tclientId,\n\t\t\tgroupId,\n\t\t\tnew TbProtoQueueMsgKafkaDecoder<>(ToCoreNotificationMsg.getDefaultInstance()))\n\t\t\t.withAdmin(admin)\n\t\t\t.withStatistics(statsService)\n\t\t\t.build();\n}", "CodeBleu_score": 16.956960589032953}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tTbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate = new TbKafkaConsumerTemplate<>();\n\tconsumerTemplate.setTopic(getNotificationsTopic());\n\tconsumerTemplate.setClientId(getClientId());\n\tconsumerTemplate.setGroupId(getGroupId());\n\tconsumerTemplate.setDecoder(new TbProtoQueueMsgDecoder<>(ToCoreNotificationMsg.class));\n\tconsumerTemplate.setAdmin(admin);\n\tconsumerTemplate.setStatsService(statsService);\n\treturn consumerTemplate.create();\n}", "CodeBleu_score": 27.75183361979041}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t// Create a consumer template with the specified settings, topic, client ID, and group ID.\nTbKafkaConsumerTemplate<ToCoreNotificationMsg> consumerTemplate = new TbKafkaConsumerTemplate<>();\nconsumerTemplate.setSettings(getKafkaSettings());\nconsumerTemplate.setTopic(getNotificationsTopic());\nconsumerTemplate.setClientId(getClientId());\nconsumerTemplate.setGroupId(getGroupId());\n\n// Set a message decoder to parse the messages and configure the consumer with an admin and a statistics service.\nconsumerTemplate.setDecoder(new TbProtoQueueMsgDecoder<>(ToCoreNotificationMsg.class));\nconsumerTemplate.setAdmin(getAdmin());\nconsumerTemplate.setStatistics(getStatsService());\n\n// Return the constructed Kafka consumer.\nreturn consumerTemplate.createConsumer();\n}", "CodeBleu_score": 25.503292470735982}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\tif (topicNames.isEmpty()) {\nlogger.info(\"Unsubscribing from all topics.\");\nunsubscribe();\n} else {\nfor (String topicName : topicNames) {\n// Ensure the topic exists\nif (!adminClient.topics().exists(topicName).isExists()) {\nNewTopic newTopic = new NewTopic(topicName, 1, (short) 1);\nadminClient.createTopics(Collections.singleton(newTopic));\nlogger.info(\"Created topic '{}' as it did not already exist.\", topicName);\n}\n// Subscribe to the topic\nsubscribe(topicName);\nlogger.info(\"Subscribed to topic '{}'.\", topicName);\n}\n}\n}", "CodeBleu_score": 47.65983354556148}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames.isEmpty()) {\n\t\tlog.info(\"Unsubscribing from all topics\");\n\t\tunsubscribe();\n\t} else {\n\t\tlog.info(\"Subscribing to topics: {}\", topicNames);\n\t\ttopicNames.forEach(this::subscribe);\n\t}\n}", "CodeBleu_score": 50.739110321007296}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames.isEmpty()) {\n\t\tlogger.info(\"Unsubscribing from all topics\");\n\t\tunsubscribe();\n\t} else {\n\t\tfor (String topicName : topicNames) {\n\t\t\tif (!isTopicExists(topicName)) {\n\t\t\t\tcreateTopic(topicName);\n\t\t\t}\n\t\t}\n\t\tsubscribe(topicNames);\n\t}\n}", "CodeBleu_score": 52.26951606682735}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tList<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n\tStopwatch stopwatch = Stopwatch.createStarted();\n\tlogger.info(\"Polling Kafka topic {} for {} milliseconds\", topic, durationInMillis);\n\trecords = consumer.poll(durationInMillis).records(topic);\n\tstopwatch.stop();\n\tlogger.info(\"Polled {} records from Kafka topic {} in {} milliseconds\", records.size(), topic, stopwatch.elapsed(TimeUnit.MILLISECONDS));\n\treturn records;\n}", "CodeBleu_score": 43.258757515058235}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tStopwatch stopwatch = Stopwatch.createStarted();\n\tlog.info(\"Polling Kafka topic '{}' for {} milliseconds\", topic, durationInMillis);\n\tList<ConsumerRecord<String, byte[]>> records = consumer.poll(durationInMillis).records(topic);\n\tstopwatch.stop();\n\tlog.info(\"Polled {} records from Kafka topic '{}' in {} milliseconds\", records.size(), topic, stopwatch.elapsed(TimeUnit.MILLISECONDS));\n\treturn records;\n}", "CodeBleu_score": 41.323696461043454}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tList<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n\tStopwatch stopwatch = Stopwatch.createStarted();\n\tlog.info(\"Polling topic {} for {} millis\", topic, durationInMillis);\n\trecords = consumer.poll(durationInMillis).records(topic);\n\tstopwatch.stop();\n\tlog.info(\"Polled {} records from topic {} in {} millis\", records.size(), topic, stopwatch.elapsed(TimeUnit.MILLISECONDS));\n\treturn records;\n}", "CodeBleu_score": 42.78459325982717}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\tif (!initialized) {\n\t\tctx.tellFailure(ctx.getRuleNode().getId(), new RuntimeException(\"Failed to initialize Kafka producer!\"));\n\t\treturn;\n\t}\n\tString topic = getTopicPattern();\n\tString key = getKeyPattern();\n\tString value = msg.getData();\n\tif (topic == null || topic.isEmpty()) {\n\t\ttopic = msg.getTopic();\n\t}\n\tif (key == null || key.isEmpty()) {\n\t\tkey = msg.getMetaData().getValue(\"kafka_key\");\n\t}\n\tctx.logJsEval(log, \"Processing Kafka message\", \"topic: \" + topic + \", key: \" + key + \", value: \" + value);\n\tctx.executeAsync(new TbExecCallback() {\n\t\t@Override\n\t\tpublic void onFailure(Throwable e) {\n\t\t\tctx.logJsEval(log, \"Failed to send Kafka message\", e.getMessage());\n\t\t\tctx.tellFailure(ctx.getRuleNode().getId(), e);\n\t\t}\n\t\t@Override\n\t\tpublic void onSuccess(Object result) {\n\t\t\tctx.logJsEval(log, \"Sent Kafka message\", \"topic: \" + topic + \", key: \" + key + \", value: \" + value);\n\t\t\tctx.tellSuccess(ctx.getRuleNode().getId());\n\t\t}\n\t}, new KafkaProducerTask(topic, key, value));\n}", "CodeBleu_score": 34.80673024337997}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\tif (ctx.isRuleChainInitialized()) {\n\t\tString topic = getTopicPattern();\n\t\tString key = getKeyPattern();\n\t\tString payload = msg.getPayload();\n\t\tctx.getAsyncHttpClient().executeAsync(getExternalCallExecutor(), getProcessPattern(), new TbKafkaCallback(ctx, msg), topic, key, payload);\n\t} else {\n\t\tctx.tellFailure(msg, \"Kafka integration is not configured!\");\n\t}\n}", "CodeBleu_score": 20.76484231110963}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\tif (ctx.isRuleChainInitialized()) {\n\t\tString topic = ctx.getRuleNode().getConfig().get(\"topicPattern\");\n\t\tString key = ctx.getRuleNode().getConfig().get(\"keyPattern\");\n\t\tif (topic == null || key == null) {\n\t\t\tctx.tellFailure(ctx.getRuleNode(), new RuntimeException(\"Missing topic or key pattern configuration!\"));\n\t\t} else {\n\t\t\tctx.executeAsync(ctx.getSelf(), new SendMsgTask(ctx, topic, key, msg));\n\t\t}\n\t} else {\n\t\tctx.tellFailure(ctx.getRuleNode(), new RuntimeException(\"Failed to initialize rule chain!\"));\n\t}\n}", "CodeBleu_score": 26.67568494273278}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\ttry {\n\t\t// Get the metadata from the message\n\t\tMap<String, String> metadata = getMetaData(msg);\n\t\t// If metadata should be added as headers, create headers from the metadata\n\t\tif (metadata != null && !metadata.isEmpty()) {\n\t\t\t// Create headers from the metadata\n\t\t\tHeaders headers = new RecordHeaders();\n\t\t\tmetadata.forEach((k, v) -> {\n\t\t\t\theaders.add(k, v.getBytes());\n\t\t\t});\n\t\t\t// Send the message with the headers\n\t\t\tctx.getProducer().send(new ProducerRecord<>(topic, key, msg.getData(), headers), (recordMetadata, e) -> {\n\t\t\t\tif (e != null) {\n\t\t\t\t\tlog.debug(\"[{}] Failed to publish message to Kafka topic [{}], error: {}\", ctx.getTenantId(), topic, e.getMessage());\n\t\t\t\t} else {\n\t\t\t\t\tprocessRecord(ctx, recordMetadata, msg);\n\t\t\t\t}\n\t\t\t});\n\t\t} else {\n\t\t\t// Send the message without headers\n\t\t\tctx.getProducer().send(new ProducerRecord<>(topic, key, msg.getData()), (recordMetadata, e) -> {\n\t\t\t\tif (e != null) {\n\t\t\t\t\tlog.debug(\"[{}] Failed to publish message to Kafka topic [{}], error: {}\", ctx.getTenantId(), topic, e.getMessage());\n\t\t\t\t} else {\n\t\t\t\t\tprocessRecord(ctx, recordMetadata, msg);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.debug(\"[{}] Failed to publish message to Kafka topic [{}], error: {}\", ctx.getTenantId(), topic, e.getMessage());\n\t}\n}", "CodeBleu_score": 41.54038778075659}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\ttry {\nTbMsgMetaData metaData = msg.getMetaData();\nif (metaData != null) {\nMap<String, String> metadataMap = metaData.getData();\nif (metadataMap != null && !metadataMap.isEmpty()) {\nList<Header> headers = new ArrayList<>();\nfor (Map.Entry<String, String> entry : metadataMap.entrySet()) {\nheaders.add(new RecordHeader(entry.getKey(), entry.getValue().getBytes(StandardCharsets.UTF_8)));\n}\nctx.getTelemetryService().saveAndSend(ctx, msg, topic, key, headers, new TbMsgCallback() {\n@Override\npublic void onResponse(TbMsg response) {\nprocessRecord(ctx, response);\n}\n\n@Override\npublic void onFailure(Throwable e) {\nlog.debug(\"Failed to send the message [{}] due to [{}]\", ctx.getSelfId(), e.getMessage());\n}\n});\n} else {\nctx.getTelemetryService().saveAndSend(ctx, msg, topic, key, new TbMsgCallback() {\n@Override\npublic void onResponse(TbMsg response) {\nprocessRecord(ctx, response);\n}\n\n@Override\npublic void onFailure(Throwable e) {\nlog.debug(\"Failed to send the message [{}] due to [{}]\", ctx.getSelfId(), e.getMessage());\n}\n});\n}\n} else {\nctx.getTelemetryService().saveAndSend(ctx, msg, topic, key, new TbMsgCallback() {\n@Override\npublic void onResponse(TbMsg response) {\nprocessRecord(ctx, response);\n}\n\n@Override\npublic void onFailure(Throwable e) {\nlog.debug(\"Failed to send the message [{}] due to [{}]\", ctx.getSelfId(), e.getMessage());\n}\n});\n}\n} catch (Exception e) {\nlog.debug(\"Failed to send the message [{}] due to [{}]\", ctx.getSelfId(), e.getMessage());\n}\n}", "CodeBleu_score": 31.624362927755357}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\tif (msg.getMetaData() != null && !msg.getMetaData().isEmpty()) {", "CodeBleu_score": 10.540375760277435}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\t\tif (producer != null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Error closing Kafka producer: {}\", e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 44.025854625539985}, {"code": "public void destroy(){\n\t\tif (producer != null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Failed to close the Kafka producer\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 59.99754801528869}, {"code": "public void destroy(){\n\t\tif (producer != null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Error closing Kafka producer: {}\", e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 43.87700734159251}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> producer = new TbQueueProducer<>();\n\tTbKafkaProducerTemplate.Builder<TbProtoQueueMsg<ToRuleEngineMsg>> builder = producer.getTemplateBuilder();\n\tbuilder.settings(settings).topic(getTopic()).defaultTopic(defaultTopic).admin(admin).clientId(getClientId());\n\treturn producer;\n}", "CodeBleu_score": 36.16500195871703}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\nfinal String clientId = getServiceId();\nfinal String defaultTopic = getDefaultTopic();\nfinal String bootstrapServers = getBootstrapServers();\n\nfinal Properties settings = new Properties();\nsettings.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nsettings.put(ProducerConfig.CLIENT_ID_CONFIG, clientId);\nsettings.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\nsettings.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, TbProtoSerializer.class);\n\nfinal KafkaAdmin admin = new KafkaAdmin(settings);\n\nfinal TbKafkaProducerTemplate.Builder<String, ToRuleEngineMsg> builder = new TbKafkaProducerTemplate.Builder<>();\nbuilder.usingAdmin(admin);\nbuilder.withTopic(defaultTopic);\nbuilder.withValueSerializer(new TbProtoSerializer<ToRuleEngineMsg>() {});\n\nreturn builder.build();\n}", "CodeBleu_score": 33.342465673971965}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tTbKafkaSettings settings = new TbKafkaSettings();\n\tsettings.setServers(kafkaBootstrapServers);\n\tsettings.setAcks(1);\n\tsettings.setRetries(0);\n\tsettings.setBatchSize(16384);\n\tsettings.setLINGER(10);\n\tsettings.setBufferMemory(33554432);\n\tsettings.setKeySerializer(StringSerializer.class);\n\tsettings.setValueSerializer(ProtoBufSerializer.class);\n\tsettings.setPollTimeoutMs(kafkaPollTimeoutMs);\n\tsettings.setTopic(ruleEngineTopic);\n\tsettings.setClientId(clientId);\n\tsettings.setAdmin(admin);\n\treturn new TbKafkaProducerTemplate<ToRuleEngineMsg>(settings);\n}", "CodeBleu_score": 27.30602570151386}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\tScheduledFuture<?> scheduledFuture = null;\ntry {\nscheduledFuture = scheduledExecutor.scheduleWithFixedDelay(new KafkaConsumerGroupStatsTask(),\nkafkaResponseTimeoutMs, kafkaResponseTimeoutMs, TimeUnit.MILLISECONDS);\n} catch (Exception e) {\nLOGGER.warn(\"Error while scheduling Kafka consumer group statistics logging task\", e);\n}\n}", "CodeBleu_score": 10.61225611645353}, {"code": "private void startLogScheduling(){\n\t\tScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);\n\tscheduler.scheduleWithFixedDelay(new Runnable() {\n\t\t@Override\n\t\tpublic void run() {\n\t\t\ttry {\n\t\t\t\tif (isStatsPrintRequired()) {\n\t\t\t\t\tMap<String, Map<TopicPartition, OffsetAndMetadata>> groupOffsets = getGroupOffsets();\n\t\t\t\t\tMap<String, Map<TopicPartition, OffsetAndMetadata>> endOffsets = getEndOffsets();\n\t\t\t\t\tfor (String consumerGroup : groupOffsets.keySet()) {\n\t\t\t\t\t\tMap<TopicPartition, OffsetAndMetadata> groupOffsetMap = groupOffsets.get(consumerGroup);\n\t\t\t\t\t\tMap<TopicPartition, OffsetAndMetadata> endOffsetMap = endOffsets.get(consumerGroup);\n\t\t\t\t\t\tMap<TopicPartition, OffsetAndMetadata> lagMap = getLagMap(groupOffsetMap, endOffsetMap);\n\t\t\t\t\t\tif (!lagMap.isEmpty()) {\n\t\t\t\t\t\t\tlogLaggingTopics(consumerGroup, lagMap);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch (Exception e) {\n\t\t\t\tlogger.warn(\"Error while checking lag for consumer group {}\", consumerGroup, e);\n\t\t\t\tlogger.trace(\"\", e);\n\t\t\t}\n\t\t}\n\t}, kafkaResponseTimeoutMs, kafkaResponseTimeoutMs, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 27.723273812662143}, {"code": "private void startLogScheduling(){\n\tlong kafkaResponseTimeoutMs = kafkaProperties.getKafkaResponseTimeoutMs();\nlong printIntervalMs = kafkaProperties.getPrintIntervalMs();\nif (printIntervalMs <= 0) {\nreturn;\n}\nlong timeoutDurationMs = kafkaResponseTimeoutMs + printIntervalMs;\nlong initialDelayMs = 0;\nboolean statsPrintRequired = false;\ntry {\nstatsPrintRequired = kafkaAdminClient.isStatsPrintRequired(kafkaProperties.getConsumerGroups());\n} catch (Exception e) {\nlogger.warn(\"Error while checking if statistics printing is required\", e);\n}\nif (statsPrintRequired) {\nlogger.info(\"Scheduling periodic logging of Kafka consumer group statistics with a fixed delay of {} ms\", printIntervalMs);\nScheduledFuture<?> scheduledFuture = scheduledExecutor.scheduleWithFixedDelay(() -> {\ntry {\nMap<String, Map<TopicPartition, OffsetAndMetadata>> consumerGroupOffsets = kafkaAdminClient.listConsumerGroupOffsets(kafkaProperties.getConsumerGroups());\nMap<String, Map<TopicPartition, Long>> consumerGroupEndOffsets = kafkaAdminClient.endOffsets(consumerGroupOffsets.keySet());\nMap<String, Map<TopicPartition, Long>> consumerGroupLag = kafkaAdminClient.getTopicsStatsWithLag(consumerGroupOffsets, consumerGroupEndOffsets);\nif (!consumerGroupLag.isEmpty()) {\nlogger.warn(\"Lagging topics found for consumer groups: {}\", consumerGroupLag.keySet());\nfor (String consumerGroup : consumerGroupLag.keySet()) {\nMap<TopicPartition, Long> lag = consumerGroupLag.get(consumerGroup);\nif (!lag.isEmpty()) {\nlogger.warn(\"Lagging topics for consumer group {}: {}\", consumerGroup, lag);\n}\n}\n}\n} catch (Exception e) {\nlogger.warn(\"Error while checking consumer group offsets\", e);\n}\n}, initialDelayMs, printIntervalMs, TimeUnit.MILLISECONDS);\nscheduledExecutor.schedule(() -> {\ntry {\nscheduledFuture.cancel(true);\n} catch (Exception e) {\nlogger.warn(\"Error while cancelling scheduled task\", e);\n}\n}, timeoutDurationMs, TimeUnit.MILLISECONDS);\n} else {\nlogger.info(\"Periodic logging of Kafka consumer group statistics is not required\");\n}\n}", "CodeBleu_score": 34.9808199724589}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\t\tProperties props = toProps();\n\tprops.setProperty(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n\tprops.setProperty(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, Integer.toString(timeoutMs));\n\tprops.setProperty(AdminClientConfig.RETRIES_CONFIG, Integer.toString(retries));\n\treturn props;\n}", "CodeBleu_score": 68.6707021223699}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(\"bootstrap.servers\", bootstrapServers);\nprops.put(\"retries\", 0);\nreturn props;\n}", "CodeBleu_score": 51.368460714414866}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.setProperty(\"bootstrap.servers\", bootstrapServers);\nprops.setProperty(\"retries\", Integer.toString(retries));\nreturn props;\n}", "CodeBleu_score": 51.67350773340379}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\tMetricName scopedName = getScopedName(metricName, group);\nMap<String, String> tags = getTags(metricName, group);\nMetricEvent event = new MetricEvent(scopedName, tags);\nif (metric instanceof Counter) {\nCounter counter = (Counter) metric;\ncounters.put(counter, event);\n} else if (metric instanceof Gauge) {\nGauge gauge = (Gauge) metric;\ngauges.put(gauge, event);\n} else if (metric instanceof Histogram) {\nHistogram histogram = (Histogram) metric;\nhistograms.put(histogram, event);\n} else if (metric instanceof Meter) {\nMeter meter = (Meter) metric;\nmeters.put(meter, event);\n} else {\nLOG.warn(\"Unknown metric type: \" + metric.getClass().getName());\n}\n}", "CodeBleu_score": 49.854579279682675}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\tString scopedName = getScopedName(metricName, group);\nMap<String, String> tags = getTags(metricName, group);\nMetricEvent metricEvent = new MetricEvent(metric, scopedName, tags);\nif (metric instanceof Counter) {\ncounters.put(scopedName, metricEvent);\n} else if (metric instanceof Gauge) {\ngauges.put(scopedName, metricEvent);\n} else if (metric instanceof Histogram) {\nhistograms.put(scopedName, metricEvent);\n} else if (metric instanceof Meter) {\nmeters.put(scopedName, metricEvent);\n} else {\nLOG.warn(\"Unknown metric type: \" + metric.getClass().getName());\n}\n}", "CodeBleu_score": 50.6604969436085}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\tif (metric instanceof Counter) {\nCounter counter = (Counter) metric;\nString scopedName = getScopedName(metricName, group);\nMetricEvent event = new MetricEvent(scopedName, getTags(metricName, group), counter.getCount());\ncounters.put(scopedName, counter);\ncounterEvents.put(scopedName, event);\n} else if (metric instanceof Gauge) {\nGauge gauge = (Gauge) metric;\nString scopedName = getScopedName(metricName, group);\nMetricEvent event = new MetricEvent(scopedName, getTags(metricName, group), gauge.getValue());\ngauges.put(scopedName, gauge);\ngaugeEvents.put(scopedName, event);\n} else if (metric instanceof Histogram) {\nHistogram histogram = (Histogram) metric;\nString scopedName = getScopedName(metricName, group);\nMetricEvent event = new MetricEvent(scopedName, getTags(metricName, group), histogram.getSnapshot());\nhistograms.put(scopedName, histogram);\nhistogramEvents.put(scopedName, event);\n} else if (metric instanceof Meter) {\nMeter meter = (Meter) metric;\nString scopedName = getScopedName(metricName, group);\nMetricEvent event = new MetricEvent(scopedName, getTags(metricName, group), meter.getRate());\nmeters.put(scopedName, meter);\nmeterEvents.put(scopedName, event);\n} else {\nLOG.warn(\"Unknown metric type: \" + metric.getClass().getName());\n}\n}", "CodeBleu_score": 42.637006056486825}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (metricEvent == null || field == null || gauge == null) {\n\t\treturn metricEvent;\n\t}\n\tMap<String, Object> fields = metricEvent.getFields();\n\tif (fields == null) {\n\t\tfields = new HashMap<>();\n\t}\n\tObject value = gauge.getValue();\n\tif (value instanceof Number) {\n\t\tfields.put(field, ((Number) value).doubleValue());\n\t} else if (value instanceof String) {\n\t\tfields.put(field, value);\n\t} else if (value != null) {\n\t\tfields.put(field, value.toString());\n\t}\n\treturn metricEvent.setFields(fields);\n}", "CodeBleu_score": 55.744821826998425}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tif (value == null) {\n\t\treturn metricEvent;\n\t}\n\tMap<String, Object> fields = metricEvent.getFields();\n\tif (fields == null) {\n\t\tfields = new HashMap<>();\n\t\tmetricEvent.setFields(fields);\n\t}\n\tfields.put(field, value);\n\treturn metricEvent;\n}", "CodeBleu_score": 40.91247863219952}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tif (value == null) {\n\t\treturn metricEvent;\n\t}\n\tMap<String, Object> fields = metricEvent.getFields();\n\tif (fields == null) {\n\t\tfields = new HashMap<>();\n\t\tmetricEvent.setFields(fields);\n\t}\n\tfields.put(field, value);\n\treturn metricEvent;\n}", "CodeBleu_score": 40.91247863219952}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tString[] metricNameParts = gauge.getName().split(\"\\\\.\");\n\tString topic = metricNameParts[1];\n\tString partition = metricNameParts[2];\n\tString metricName = metricNameParts[3];\n\n\tMap<String, Object> fields = metricEvent.getFields();\n\tMap<String, Long> kafkaLagTimes = (Map<String, Long>) fields.get(\"kafkaLagTimes\");\n\tif (kafkaLagTimes == null) {\n\t\tkafkaLagTimes = new HashMap<>();\n\t\tfields.put(\"kafkaLagTimes\", kafkaLagTimes);\n\t}\n\n\tlong kafkaLagTime = 0;\n\tif (kafkaLagTimes.containsKey(topic)) {\n\t\tkafkaLagTime = kafkaLagTimes.get(topic);\n\t}\n\n\tif (metricName.equals(\"Value\")) {\n\t\tlong currentOffset = Long.valueOf(gauge.getValue().toString());\n\t\tlong committedOffset = Long.valueOf(fields.get(\"committedOffset\").toString());\n\t\tlong lag = currentOffset - committedOffset;\n\t\tfields.put(\"currentOffset\", currentOffset);\n\t\tfields.put(\"lag\", lag);\n\t\tkafkaLagTimes.put(topic, timestamp);\n\t\tif (timestamp > kafkaLagTime) {\n\t\t\tmetricEvent.setTimestamp(timestamp);\n\t\t}\n\t\treturn metricEvent;\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 41.93951000539753}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tString metricName = gauge.getName();\n\tString[] metricNameComponents = metricName.split(\"\\\\.\");\n\tString kafkaTopic = metricNameComponents[0];\n\tString kafkaPartition = metricNameComponents[1];\n\tString kafkaGroup = metricNameComponents[2];\n\tString kafkaConsumer = metricNameComponents[3];\n\tString kafkaConsumerType = metricNameComponents[4];\n\tString kafkaConsumerName = metricNameComponents[5];\n\tString kafkaConsumerClientId = metricNameComponents[6];\n\tString kafkaConsumerGroupId = metricNameComponents[7];\n\tString kafkaConsumerGroupGenerationId = metricNameComponents[8];\n\tString kafkaConsumerMemberId = metricNameComponents[9];\n\tString kafkaConsumerClientIdType = metricNameComponents[10];\n\tString kafkaConsumerClientIdName = metricNameComponents[11];\n\tString kafkaConsumerClientIdClientId = metricNameComponents[12];\n\tString kafkaConsumerClientIdGroupId = metricNameComponents[13];\n\tString kafkaConsumerClientIdGroupGenerationId = metricNameComponents[14];\n\tString kafkaConsumerClientIdMemberId = metricNameComponents[15];\n\tString kafkaConsumerClientIdConsumerType = metricNameComponents[16];\n\tString kafkaConsumerClientIdConsumerName = metricNameComponents[17];\n\tString kafkaConsumerClientIdConsumerClientId = metricNameComponents[18];\n\tString kafkaConsumerClientIdConsumerGroupId = metricNameComponents[19];\n\tString kafkaConsumerClientIdConsumerGroupGenerationId = metricNameComponents[20];\n\tString kafkaConsumerClientIdConsumerMemberId = metricNameComponents[21];\n\tString kafkaConsumerClientIdConsumerClientIdType = metricNameComponents[22];\n\tString kafkaConsumerClientIdConsumerClientIdName = metricNameComponents[23];\n\tString kafkaConsumerClientIdConsumerClientIdClientId = metricNameComponents[24];\n\tString kafkaConsumerClientIdConsumerClientIdGroupId = metricNameComponents[25];\n\tString kafkaConsumerClientIdConsumerClientIdGroupGenerationId = metricNameComponents[26];\n\tString kafkaConsumerClientIdConsumerClientIdMemberId = metricNameComponents[27];\n\tString kafkaConsumerClientIdConsumerClientIdConsumerType = metricNameComponents[28];\n\tString kafkaConsumerClientIdConsumerClientIdConsumerName = metricNameComponents[29];\n\tString kafkaConsumerClientIdConsumerClientIdConsumerClientId = metricNameComponents[30];\n\tString kafkaConsumerClientIdConsumerClientIdConsumer", "CodeBleu_score": 18.796205713031156}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tString gaugeName = gauge.getName().getName();\n\tString[] gaugeNameComponents = gaugeName.split(\"\\\\.\");\n\tString kafkaTopic = gaugeNameComponents[0];\n\tString kafkaPartition = gaugeNameComponents[1];\n\tString kafkaGroup = gaugeNameComponents[2];\n\tlong kafkaOffset = gauge.getValue().longValue();\n\tlong kafkaCommittedOffset = getCommittedOffset(kafkaGroup, kafkaTopic, kafkaPartition);\n\tlong kafkaLag = kafkaCommittedOffset - kafkaOffset;\n\tlong kafkaLagTime = System.currentTimeMillis() - timestamp;\n\tif (kafkaLagTime < 0) {\n\t\t// This should never happen, but just in case\n\t\treturn metricEvent;\n\t}\n\tif (kafkaLagTime > 0 && !kafkaLagTimes.containsKey(kafkaGroup + \".\" + kafkaTopic + \".\" + kafkaPartition)) {\n\t\tkafkaLagTimes.put(kafkaGroup + \".\" + kafkaTopic + \".\" + kafkaPartition, kafkaLagTime);\n\t\tmetricEvent.setTimestamp(timestamp);\n\t\tmetricEvent.setFields(new HashMap<>());\n\t\tmetricEvent.getFields().put(\"kafkaTopic\", kafkaTopic);\n\t\tmetricEvent.getFields().put(\"kafkaPartition\", kafkaPartition);\n\t\tmetricEvent.getFields().put(\"kafkaGroup\", kafkaGroup);\n\t\tmetricEvent.getFields().put(\"kafkaOffset\", kafkaOffset);\n\t\tmetricEvent.getFields().put(\"kafkaCommittedOffset\", kafkaCommittedOffset);\n\t\tmetricEvent.getFields().put(\"kafkaLag\", kafkaLag);\n\t\tmetricEvent.getFields().put(\"kafkaLagTime\", kafkaLagTime);\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 31.631374401897112}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\t// get global job parameters\n\tProperties props = getGlobalJobParameters(env);\n\t// build Kafka properties\n\tprops.putAll(buildKafkaProps(props));\n\t// set start from specific offsets based on the given time\n\tsetStartFromSpecificOffsets(props, time);\n\t// create FlinkKafkaConsumer for MetricEvent\n\tFlinkKafkaConsumer<MetricEvent> kafkaConsumer = new FlinkKafkaConsumer<>(topic, new MetricEventDeserializationSchema(), props);\n\t// add consumer as a source to the StreamExecutionEnvironment\n\treturn env.addSource(kafkaConsumer);\n}", "CodeBleu_score": 36.27205511878883}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\t// get global job parameters\n\tProperties props = getGlobalJobParameters(env);\n\t// build Kafka properties\n\tprops = buildKafkaProps(props);\n\t// set the start offset for the consumer\n\tsetStartFromSpecificOffsets(props, time);\n\t// create a FlinkKafkaConsumer for MetricEvent\n\tFlinkKafkaConsumer<MetricEvent> kafkaConsumer = new FlinkKafkaConsumer<MetricEvent>(topic, new MetricEventSchema(), props);\n\t// add the consumer as a source to the StreamExecutionEnvironment\n\tDataStreamSource<MetricEvent> kafkaSource = env.addSource(kafkaConsumer);\n\treturn kafkaSource;\n}", "CodeBleu_score": 38.63592648355797}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\t// get global job parameters\n\tProperties props = getGlobalJobParameters(env);\n\t// build kafka properties\n\tprops = buildKafkaProps(props);\n\t// create kafka consumer\n\tFlinkKafkaConsumer<MetricEvent> kafkaConsumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), props);\n\t// set start from specific offsets based on time\n\tif (time != null) {\n\t\tkafkaConsumer.setStartFromSpecificOffsets(buildOffsetByTime(time));\n\t}\n\t// add kafka consumer as source\n\tDataStreamSource<MetricEvent> kafkaSource = env.addSource(kafkaConsumer);\n\treturn kafkaSource;\n}", "CodeBleu_score": 44.811869852654155}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tString topic = parameterTool.getRequired(\"topic\")\n\tString groupId = \"flink-kafka-consumer-\" + System.currentTimeMillis()\n\tMap<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>()\n\ttry (KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props)) {\n\t\tconsumer.assign(KafkaTopicPartition.of(topic, 0))\n\t\tconsumer.seekToBeginning(KafkaTopicPartition.of(topic, 0))\n\t\tMap<KafkaTopicPartition, OffsetAndTimestamp> partitionTimestamps = consumer.offsetsForTimes(Collections.singletonMap(KafkaTopicPartition.of(topic, 0), time))\n\t\tfor (Map.Entry<KafkaTopicPartition, OffsetAndTimestamp> entry : partitionTimestamps.entrySet()) {\n\t\t\tpartitionOffsets.put(entry.getKey(), entry.getValue().offset())\n\t\t}\n\t}\n\treturn partitionOffsets\n}", "CodeBleu_score": 37.83626622200704}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tString topic = parameterTool.getRequired(\"topic\")\n\tString groupId = \"flink-kafka-consumer-\" + System.currentTimeMillis()\n\tprops.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupId)\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)\n\tMap<KafkaTopicPartition, Long> offsets = new HashMap<>()\n\tconsumer.partitionsFor(topic).forEach(partitionInfo -> {\n\t\tLong offset = consumer.offsetsForTimes(Collections.singletonMap(partitionInfo, time)).get(partitionInfo)\n\t\tif (offset != null) {\n\t\t\toffsets.put(new KafkaTopicPartition(topic, partitionInfo.partition()), offset)\n\t\t}\n\t})\n\tconsumer.close()\n\treturn offsets\n}", "CodeBleu_score": 37.121883529413324}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tString topic = parameterTool.getRequired(\"topic\")\n\tString groupID = \"flink-kafka-consumer-group-by-time-\" + time\n\n\t// set the consumer group id\n\tprops.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupID)\n\t// create the consumer\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)\n\n\t// get the partitions for the specified topic\n\tList<PartitionInfo> partitions = consumer.partitionsFor(topic)\n\tMap<KafkaTopicPartition, Long> topicPartitionOffsets = new HashMap<>()\n\n\t// for each partition, get the offset for the specified time\n\tfor (PartitionInfo partition : partitions) {\n\t\ttopicPartitionOffsets.put(new KafkaTopicPartition(partition.topic(), partition.partition()),\n\t\t\t\tconsumer.offsetsForTimes(Collections.singletonMap(partition, time)).get(partition))\n\t}\n\n\t// close the consumer and return the map of offsets\n\tconsumer.close()\n\treturn topicPartitionOffsets\n}", "CodeBleu_score": 38.68759446555449}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\nprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\nKafkaProducer<String, String> producer = new KafkaProducer<String, String>(props);\n\nMetricEvent event = new MetricEvent();\nevent.setName(\"my.event.name\");\nevent.setTimestamp(System.currentTimeMillis());\nevent.setFields(new HashMap<String, Object>() {{\nput(\"my.field.name\", 123);\n}});\nevent.setTags(new HashMap<String, String>() {{\nput(\"my.tag.name\", \"my.tag.value\");\n}});\n\nProducerRecord<String, String> record = new ProducerRecord<String, String>(\"my.topic.name\", event.toJson());\n\nproducer.send(record);\n\nSystem.out.println(record.value());\nproducer.flush();\nproducer.close();\n}", "CodeBleu_score": 51.54518011342041}, {"code": "public static void writeToKafka() throws InterruptedException{\n\tProperties properties = new Properties();\nproperties.put(\"bootstrap.servers\", \"localhost:9092\");\nproperties.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\nproperties.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\nKafkaProducer<String, String> producer = new KafkaProducer<String, String>(properties);\nMetricEvent metricEvent = new MetricEvent();\nmetricEvent.setName(\"test-metric\");\nmetricEvent.setTimestamp(System.currentTimeMillis());\nmetricEvent.setFields(new HashMap<String, Object>() {{\nput(\"value\", 123);\n}});\nmetricEvent.setTags(new HashMap<String, String>() {{\nput(\"host\", \"localhost\");\nput(\"region\", \"us-west-1\");\n}});\nProducerRecord<String, String> record = new ProducerRecord<String, String>(\"test-topic\", metricEvent.toJson());\nproducer.send(record);\nproducer.flush();\nproducer.close();\nSystem.out.println(record.value());\nSystem.out.flush();\n}", "CodeBleu_score": 49.5242571532896}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t\nProperties props = new Properties();\nprops.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\nprops.put(ProducerConfig.CLIENT_ID_CONFIG, \"example-producer\");\nprops.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\nprops.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n\nKafkaProducer<String, String> producer = new KafkaProducer<String, String>(props);\n\nMetricEvent event = new MetricEvent();\nevent.setTimestamp(System.currentTimeMillis());\nevent.setName(\"test_event\");\nevent.setTags(new HashMap<String, String>() {{\nput(\"tag1\", \"value1\");\nput(\"tag2\", \"value2\");\n}});\nevent.setFields(new HashMap<String, Object>() {{\nput(\"field1\", \"value1\");\nput(\"field2\", \"value2\");\n}});\n\nProducerRecord<String, String> record = new ProducerRecord<String, String>(\"test_topic\", event.toJson());\n\nproducer.send(record);\n\nproducer.flush();\n\nSystem.out.println(\"Sent data to Kafka\");\n\n}", "CodeBleu_score": 44.56471334799692}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\tif (event.getLevel().isMoreSpecificThan(this.getLevel()) && !event.getLoggerName().contains(\"xxx\")) {\n\t\ttry {\n\t\t\tString message = new String(event.getMessage().getFormattedMessage(), StandardCharsets.UTF_8);\n\t\t\tString level = event.getLevel().toString();\n\t\t\tString loggerName = event.getLoggerName();\n\t\t\tString threadName = event.getThreadName();\n\t\t\tString thrown = event.getThrown() == null ? \"\" : event.getThrown().toString();\n\t\t\tString mdc = event.getContextMap() == null ? \"\" : event.getContextMap().toString();\n\t\t\tString ndc = event.getContextStack() == null ? \"\" : event.getContextStack().toString();\n\t\t\tString timeMillis = String.valueOf(event.getTimeMillis());\n\t\t\tString location = event.getSource() == null ? \"\" : event.getSource().toString();\n\t\t\tString loggerFqcn = event.getLoggerFqcn();\n\t\t\tString contextMap = event.getContextMap() == null ? \"\" : event.getContextMap().toString();\n\t\t\tString contextStack = event.getContextStack() == null ? \"\" : event.getContextStack().toString();\n\t\t\tString threadId = String.valueOf(event.getThreadId());\n\t\t\tString threadPriority = String.valueOf(event.getThreadPriority());\n\t\t\tString marker = event.getMarker() == null ? \"\" : event.getMarker().toString();\n\t\t\tString loggerFqcn = event.getLoggerFqcn();\n\t\t\tString loggerContextMap = event.getLoggerContextMap() == null ? \"\" : event.getLoggerContextMap().toString();\n\t\t\tString loggerContextStack = event.getLoggerContextStack() == null ? \"\" : event.getLoggerContextStack().toString();\n\t\t\tString source = event.getSource() == null ? \"\" : event.getSource().toString();\n\t\t\tString message = event.getMessage() == null ? \"\" : event.getMessage().getFormattedMessage();\n\t\t\tString threadName = event.getThreadName();\n\t\t\tString threadPriority = String.valueOf(event.getThreadPriority());\n\t\t\tString timeMillis = String.valueOf(event.getTimeMillis());\n\t\t\tString thrown = event.getThrown() == null ? \"\" : event.getThrown().toString();\n\t\t\tString ndc = event.getContextStack() == null ? \"\" : event.getContextStack().toString();\n\t\t\tString marker = event.getMarker", "CodeBleu_score": 30.62276600500573}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\tif (event.getLevel().isMoreSpecificThan(this.getLevel())) {\n\t\treturn;\n\t}\n\tif (this.getFilter() != null && !this.getFilter().isStarted()) {\n\t\treturn;\n\t}\n\tif (event.getLoggerName().contains(\"xxx\")) {\n\t\treturn;\n\t}\n\ttry {\n\t\tString json = this.layout.toSerializable(event);\n\t\tthis.producer.send(new ProducerRecord(this.topic, json));\n\t}\n\tcatch (Exception var4) {\n\t\torg.apache.logging.log4j.core.helpers.LogManager.getLogger(\"Kafka\").warn(\"Exception occurred while appending event to Kafka\", var4);\n\t}\n}", "CodeBleu_score": 42.26442627831566}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\tif (event.getLevel() == org.apache.logging.log4j.Level.INFO || event.getLevel() == org.apache.logging.log4j.Level.WARN) {\n\t\tif (!event.getLoggerName().contains(\"xxx\")) {\n\t\t\ttry {\n\t\t\t\tString message = event.getMessage().getFormattedMessage();\n\t\t\t\tif (message != null) {\n\t\t\t\t\tif (message.contains(\"password\") || message.contains(\"Password\")) {\n\t\t\t\t\t\tmessage = message.replaceAll(\"password\", \"********\");\n\t\t\t\t\t}\n\t\t\t\t\tif (message.contains(\"Password\") || message.contains(\"password\")) {\n\t\t\t\t\t\tmessage = message.replaceAll(\"Password\", \"********\");\n\t\t\t\t\t}\n\t\t\t\t\tif (message.contains(\"token\") || message.contains(\"Token\")) {\n\t\t\t\t\t\tmessage = message.replaceAll(\"token\", \"********\");\n\t\t\t\t\t}\n\t\t\t\t\tif (message.contains(\"Token\") || message.contains(\"token\")) {\n\t\t\t\t\t\tmessage = message.replaceAll(\"Token\", \"********\");\n\t\t\t\t\t}\n\t\t\t\t\tif (message.contains(\"secret\") || message.contains(\"Secret\")) {\n\t\t\t\t\t\tmessage = message.replaceAll(\"secret\", \"********\");\n\t\t\t\t\t}\n\t\t\t\t\tif (message.contains(\"Secret\") || message.contains(\"secret\")) {\n\t\t\t\t\t\tmessage = message.replaceAll(\"Secret\", \"********\");\n\t\t\t\t\t}\n\t\t\t\t\tif (message.contains(\"key\") || message.contains(\"Key\")) {\n\t\t\t\t\t\tmessage = message.replaceAll(\"key\", \"********\");\n\t\t\t\t\t}\n\t\t\t\t\tif (message.contains(\"Key\") || message.contains(\"key\")) {\n\t\t\t\t\t\tmessage = message.replaceAll(\"Key\", \"********\");\n\t\t\t\t\t}\n\t\t\t\t\tif (message.contains(\"auth\") || message.contains(\"Auth\")) {\n\t\t\t\t\t\tmessage = message.replaceAll(\"auth\", \"********\");\n\t\t\t\t\t}\n\t\t\t\t\tif (message.contains(\"Auth\") || message.contains(\"auth\")) {\n\t\t\t\t\t\tmessage = message.replaceAll(\"Auth\", \"********\");\n\t\t\t\t\t}\n\t\t\t\t\tif (message.contains(\"token\") || message.contains(\"Token\")) {\n\t\t\t\t\t\tmessage = message.replaceAll(\"token\", \"********\");\n\t\t\t\t\t}\n\t\t\t\t\tif (message.contains(\"Token\") || message.contains(\"token\")) {\n\t\t\t\t\t\tmessage = message.replaceAll(\"Token\", \"********\");\n\t\t\t\t\t}\n\t\t\t\t\tif (message.contains(\"pwd\") || message.contains(\"Pwd\")) {\n\t\t\t\t\t\t", "CodeBleu_score": 35.70208837117601}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range ValidTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method %s\", method)\n}", "CodeBleu_score": 93.19931120123317}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tif method == \"\" {\n\t\treturn nil\n\t}\n\tfor _, validMethod := range ValidTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method %s\", method)\n}", "CodeBleu_score": 86.45229406481614}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 89.40480295903943}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \"\" {\n\t\tif tag, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn tag, nil\n\t\t}\n\t\treturn \"\", fmt.Errorf(\"metric %s has no tag %s\", metric.Name(), k.RoutingTag)\n\t}\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 60.93699004513351}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tvar routingKey string\n\tif k.RoutingTag != \"\" {\n\t\tif tag, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\troutingKey = tag\n\t\t} else {\n\t\t\treturn \"\", fmt.Errorf(\"routing tag %q not found\", k.RoutingTag)\n\t\t}\n\t}\n\tif k.RoutingKey == \"random\" {\n\t\troutingKey = uuid.NewV4().String()\n\t} else {\n\t\troutingKey = k.RoutingKey\n\t}\n\treturn routingKey, nil\n}", "CodeBleu_score": 51.6915925098437}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tvar routingKey string\n\tif k.RoutingTag != \"\" {\n\t\tif tag, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\troutingKey = tag\n\t\t} else {\n\t\t\treturn \"\", fmt.Errorf(\"RoutingTag %s not found in metric %s\", k.RoutingTag, metric.Name())\n\t\t}\n\t} else if k.RoutingKey == \"random\" {\n\t\troutingKey = uuid.NewV4().String()\n\t} else {\n\t\troutingKey = k.RoutingKey\n\t}\n\treturn routingKey, nil\n}", "CodeBleu_score": 47.970619873388934}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\t// Create a slice of compiled regular expressions based on the number of topic regular expressions\n\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\t// Iterate through the topic regular expressions\n\tfor i, topic := range k.TopicRegexps {\n\t\t// Compile the regular expression\n\t\tr, err := regexp.Compile(topic)\n\t\t// If compilation fails, return an error\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"error compiling topic regexp %d: %s\", i, err)\n\t\t}\n\t\t// Otherwise, add the compiled regular expression to the slice\n\t\tk.regexps[i] = r\n\t}\n\t// Return nil to indicate success\n\treturn nil\n}", "CodeBleu_score": 58.27797476791572}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, re := range k.TopicRegexps {\n\t\tk.regexps[i] = regexp.MustCompile(re)\n\t}\n\treturn nil\n}", "CodeBleu_score": 42.248879611623046}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topic := range k.TopicRegexps {\n\t\tr, err := regexp.Compile(topic)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile topic regexp %s: %s\", topic, err)\n\t\t}\n\t\tk.regexps[i] = r\n\t}\n\treturn nil\n}", "CodeBleu_score": 58.98902576302807}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg := h.undelivered[track.ID]\n\tif msg != nil {\n\t\tmsg.session.MarkMessage(msg, telegraf.Delivered)\n\t\tdelete(h.undelivered, track.ID)\n\t\th.sem.Release(1)\n\t}\n\th.mu.Unlock()\n}", "CodeBleu_score": 40.30574093982294}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\th.mu.Lock\nmsg, ok := h.undelivered[track.ID]\nif !ok {\nh.mu.Unlock\nreturn\n}\nif msg.session.MarkMessage(track) {\ndelete(h.undelivered, track.ID)\nh.mu.Unlock\nh.sem.Done()\n} else {\nh.mu.Unlock\n}\n}", "CodeBleu_score": 43.75980694930737}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg := h.undelivered[track.ID]\n\tif msg != nil {\n\t\tmsg.session.MarkMessage(msg, telegraf.Delivered)\n\t\tdelete(h.undelivered, track.ID)\n\t}\n\th.mu.Unlock()\n\th.delivered.Done()\n}", "CodeBleu_score": 40.68415232656387}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg := <-claim.Messages():\n\t\t\tif err := h.Handle(ctx, msg); err != nil {\n\t\t\t\tclaim.MarkMessage(msg, \"\")\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tclaim.MarkMessage(msg, \"\")\n\t\t}\n\t}\n}", "CodeBleu_score": 55.1183908970301}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := context.Background()\n\tfor {\n\t\tselect {\n\t\tcase msg := <-claim.Messages():\n\t\t\tif msg == nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.Handle(ctx, msg); err != nil {\n\t\t\t\th.acc.AddError(err)\n\t\t\t}\n\t\t\tsession.MarkMessage(msg, \"\")\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-session.Context().Done():\n\t\t\treturn session.Context().Err()\n\t\t}\n\t}\n}", "CodeBleu_score": 56.74318930820368}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := context.Background()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg := <-claim.Messages():\n\t\t\terr := h.Handle(ctx, msg)\n\t\t\tif err != nil {\n\t\t\t\th.acc.AddError(\"Error handling message\", \"error\", err)\n\t\t\t}\n\t\t\tsession.MarkMessage(msg, \"\")\n\t\t}\n\t}\n}", "CodeBleu_score": 45.19400592083686}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\tif (logkafka_id.isEmpty)\nthrow IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be empty\")\nif (logkafka_id.equals(\".\"))\nthrow IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be \\\".\\\"\")\nif (logkafka_id.equals(\"..\"))\nthrow IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be \\\"..\\\"\")\nif (logkafka_id.length > 255)\nthrow IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be longer than 255 characters\")\nif (!logkafka_id.matches(\"[a-zA-Z0-9._-]+\"))\nthrow IllegalCharacterInLogkafkaId(\"Logkafka ID can only contain alphanumeric characters, underscores, hyphens, and periods\")\n}", "CodeBleu_score": 26.687457560117707}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t\tif (logkafka_id.isEmpty) {\n\t\tthrow new IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be empty\")\n\t}\n\tif (logkafka_id.equals(\".\")) {\n\t\tthrow new IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be '.'\")\n\t}\n\tif (logkafka_id.equals(\"..\")) {\n\t\tthrow new IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be '..'\")\n\t}\n\tif (logkafka_id.length > 255) {\n\t\tthrow new LogkafkaIdTooLong(\"Logkafka ID cannot exceed 255 characters\")\n\t}\n\tif (!logkafka_id.matches(logkafkaIdRegex)) {\n\t\tthrow new IllegalCharacterInLogkafkaId(\"Logkafka ID contains illegal characters\")\n\t}\n}", "CodeBleu_score": 27.79897015377707}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t\tif (logkafka_id.equals(\".\") || logkafka_id.equals(\"..\") || logkafka_id.isEmpty) {\n\t\tthrow new IllegalCharacterInLogkafkaId(logkafka_id)\n\t}\n\tif (logkafka_id.length > 64) {\n\t\tthrow new LogkafkaIdTooLong(logkafka_id)\n\t}\n\tif (!logkafka_id.matches(\"\"\"^[a-zA-Z0-9_-]+$\"\"\")) {\n\t\tthrow new IllegalCharacterInLogkafkaId(logkafka_id)\n\t}\n}", "CodeBleu_score": 29.07805761227089}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tTry", "CodeBleu_score": 5.145501100687216}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tTry", "CodeBleu_score": 5.145501100687216}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\\/-", "CodeBleu_score": 5.120481927710843}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The withKafkaManagerActor function sends a message to the Kafka Manager actor and processes the response.", "CodeBleu_score": 14.030131826741995}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tFuture.successful", "CodeBleu_score": 10.169499117562436}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tFuture.successful(ApiError.from(new IllegalArgumentException(\"msg must not be null\")))", "CodeBleu_score": 11.465417118444595}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\nval request = KMClusterCommandRequest(clusterName, PreferredReplicaLeaderElection)\n", "CodeBleu_score": 10.796306572181571}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t//    val cluster = getCluster(clusterName)\n//    val topicNames = cluster.getTopicNames(topics)\n//    val request = PreferredReplicaElectionCommand(clusterName, topicNames)\n//    val command = KafkaManagerCommand(request)\n//    val future = ask(kafkaManagerActor, command)\n//    future.map(result => result.map(ClusterContext(_)))\n  }", "CodeBleu_score": 8.140979095809902}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\"\"\"\n", "CodeBleu_score": 8.064516129032258}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit ec: ExecutionContext = ExecutionContext.Implicits.global\ngetTopicList(clusterName).flatMap {\ncase error @ Left(_) => Future.successful(error)\ncase Right(topicList) => runPreferredLeaderElection(clusterName, topicList)\n}\n}", "CodeBleu_score": 24.312574726100593}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\tFuture.successful(getTopicList(clusterName)).flatMap(topicList => runPreferredLeaderElection(clusterName, topicList))\n}", "CodeBleu_score": 14.75953177045234}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\tfor {\ntopicList <- getTopicList(clusterName)\nerrorOrTopicList <- EitherT(Future(topicList))\nrunPreferredLeaderElection(clusterName, errorOrTopicList.fold)\n} yield ()\n}", "CodeBleu_score": 16.361920250202544}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\timplicit val executionContext = system.dispatcher", "CodeBleu_score": 7.060336416895289}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\timplicit val executionContext = actorSystem.dispatcher\nval results = for {\nresult <- tryWithKafkaManagerActor(\n  KMClusterCommandRequest(\n    clusterName,\n    CMManualPartitionAssignments(assignments)\n  )\n)\n} yield result\nval errors = results.collect{\ncase ApiError(err) => err\n}\nif(errors.isEmpty) {\n  Success(true)\n} else {\n  Failure(errors)\n}\n}", "CodeBleu_score": 29.78929246535621}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\nval results = tryWithKafkaManagerActor(\n  KMClusterCommandRequest(\n    clusterName,\n    CMManualPartitionAssignments(assignments)\n  )\n)\n\nval result = results.map {\n  case (clusterName, success) => success\n}\n\nval errors = results.collect {\n  case (clusterName, failure) => failure\n}\n\nif (errors.isEmpty) {\n  result\n} else {\n  errors\n}\n}", "CodeBleu_score": 28.60835679490268}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\n// Describe the cluster to get the available nodes within a specified timeout\nDescribeClusterResult describeClusterResult = admin.describeCluster(DescribeClusterOptions.builder().timeoutMs(10000).build());\n\n// Get the list of available nodes\nList<Node> nodes = describeClusterResult.nodes().get();\n\n// If no nodes are available, throw an exception\nif (nodes.isEmpty()) {\nthrow new ConnectException(\"No nodes found in the Kafka cluster.\");\n}\n\n// Select the first node's ID\nNode node = nodes.get(0);\nString nodeId = node.idString();\n\n// Request the configuration for the node\nConfigResource configResource = ConfigResource.Type.BROKER.resource(nodeId);\nConfig config = admin.describeConfigs(Collections.singleton(configResource), DescribeConfigsOptions.builder().includeSynonyms(false).build()).all().get().get(configResource);\n\n// If no configurations are received, throw an exception\nif (config.entries().isEmpty()) {\nthrow new ConnectException(\"No configuration found for the Kafka broker.\");\n}\n\n// Return the broker's configuration\nreturn config;\n}", "CodeBleu_score": 54.601975159070605}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\tConfig config = null;\n\ttry {\n\t\t// describe cluster\n\t\tDescribeClusterResult clusterInfo = admin.describeCluster();\n\t\tCollection<Node> nodes = clusterInfo.nodes().get();\n\n\t\t// if no nodes are available, throw an exception\n\t\tif (nodes.isEmpty()) {\n\t\t\tthrow new ConnectException(\"No Kafka nodes are available.\");\n\t\t}\n\n\t\t// select the first node's ID\n\t\tNode node = nodes.iterator().next();\n\t\tString nodeId = node.idString();\n\n\t\t// request the configuration of the node\n\t\tDescribeConfigsResult configs = admin.describeConfigs(Collections.singleton(nodeId));\n\t\tconfig = configs.all().get().get(nodeId).config();\n\t} catch (Exception e) {\n\t\tthrow new ConnectException(\"Error retrieving Kafka broker configuration.\", e);\n\t}\n\treturn config;\n}", "CodeBleu_score": 47.29893201718245}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\t// Describe the cluster and get the available nodes\n\tDescribeClusterResult describeClusterResult = admin.describeCluster(DescribeClusterOptions.builder().build());\n\tCollection<Node> nodes = describeClusterResult.nodes().get();\n\n\t// If no nodes are available, throw an exception\n\tif (nodes.isEmpty()) {\n\t\tthrow new ConnectException(\"No nodes found in cluster.\");\n\t}\n\n\t// Select the first node's ID and get its configuration\n\tString nodeId = nodes.iterator().next().idString();\n\tConfigResource configResource = new ConfigResource(ConfigResource.Type.BROKER, nodeId);\n\tDescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singleton(configResource), DescribeConfigsOptions.builder().includeSynonyms(false).build());\n\tConfig config = describeConfigsResult.all().get().get(configResource);\n\n\t// If no configuration is received, throw an exception\n\tif (config.entries().isEmpty()) {\n\t\tthrow new ConnectException(\"No configuration found for node \" + nodeId);\n\t}\n\n\t// Return the broker's configuration\n\treturn config;\n}", "CodeBleu_score": 57.64628147031207}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic void configure(Map<String, ?> configs) {\n\t\t\tvalidator.configure(configs);\n\t\t}\n\n\t\t@Override\n\t\tpublic boolean isConfigured() {\n\t\t\treturn validator.isConfigured();\n\t\t}\n\n\t\t@Override\n\t\tpublic void validate(final Config config) {\n\t\t\tif (config.originals().containsKey(SCHEMA_REGISTRY_URL_CONFIG)) {\n\t\t\t\tvalidator.validate(config);\n\t\t\t}\n\t\t}\n\n\t\t@Override\n\t\tpublic ConfigDef config() {\n\t\t\treturn validator.config();\n\t\t}\n\t};\n}", "CodeBleu_score": 25.31174494829199}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic void configure(Map<String, ?> configs) {\n\t\t\t// noop\n\t\t}\n\n\t\t@Override\n\t\tpublic void validate(String topic, byte[] value) {\n\t\t\tif (schemaHistory == KafkaSchemaHistory.KAFKA_SCHEMA_HISTORY) {\n\t\t\t\tvalidator.validate(topic, value);\n\t\t\t}\n\t\t}\n\n\t\t@Override\n\t\tpublic void close() {\n\t\t\t// noop\n\t\t}\n\t};\n}", "CodeBleu_score": 28.38325342617527}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic void configure(Map<String, ?> configs) {\n\t\t\tvalidator.configure(configs);\n\t\t}\n\n\t\t@Override\n\t\tpublic void configure(ConfigDef configDef) {\n\t\t\tvalidator.configure(configDef);\n\t\t}\n\n\t\t@Override\n\t\tpublic void close() {\n\t\t\tvalidator.close();\n\t\t}\n\n\t\t@Override\n\t\tpublic void validate(final Config config) {\n\t\t\tif (config.originals().containsKey(Config.KAFKA_SCHEMA_REGISTRY_URL_CONFIG)) {\n\t\t\t\tvalidator.validate(config);\n\t\t\t}\n\t\t}\n\t};\n}", "CodeBleu_score": 30.378483303402326}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t\tif (topicCreationEnabled == null) {\n\t\ttopicCreationEnabled = parseBoolean(config, TOPIC_CREATION_ENABLE_CONFIG, true);\n\t}\n\treturn topicCreationEnabled;\n}", "CodeBleu_score": 16.68721868590182}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t\tif (version == null) {\n\t\tversion = parseVersion(context.version());\n\t}\n\n\tif (version.compareTo(parseVersion(\"2.0.0\")) < 0) {\n\t\treturn false;\n\t}\n\n\tif (config.containsKey(\"topic.creation.enable\")) {\n\t\treturn parseBoolean(config.get(\"topic.creation.enable\"));\n\t}\n\n\treturn true;\n}", "CodeBleu_score": 29.26946245945452}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t\tif (config.containsKey(TOPIC_CREATION_ENABLE_CONFIG)) {\n\t\treturn parseBoolean(config.get(TOPIC_CREATION_ENABLE_CONFIG));\n\t}\n\telse {\n\t\treturn true;\n\t}\n}", "CodeBleu_score": 12.258950041879887}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\tObjects.requireNonNull(config, \"config cannot be null\");", "CodeBleu_score": 5.070893889960799}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\tObjects.requireNonNull(config, \"config cannot be null\");", "CodeBleu_score": 5.070893889960799}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\tString clientId = config.get(CLIENT_ID_CONFIG);\nif (clientId == null) {\nthrow new IllegalArgumentException(\"Missing required configuration option \" + CLIENT_ID_CONFIG);\n}\nProperties adminProps = new Properties();\nadminProps.putAll(config);\nadminProps.remove(CLIENT_ID_CONFIG);\nSharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\nKafkaOffsetBackingStore store = new KafkaOffsetBackingStore(admin, clientId, converterForOffsetStore(config));\nreturn store;\n}", "CodeBleu_score": 28.29496521633291}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\t_\nif (!node.isObject()) {\nthrow new IOException(\"Expected an object for key, got \" + node.getNodeType());\n}\nif (node.has(payloadFieldName)) {\nreturn readValue(node.get(payloadFieldName));\n}\nIterator<String> fieldNames = node.fieldNames();\nif (!fieldNames.hasNext()) {\nthrow new IOException(\"Expected a field for key, got none\");\n}\nString fieldName = fieldNames.next();\nif (fieldNames.hasNext()) {\nreturn readValue(node);\n}\nreturn readValue(node.get(fieldName));\n}", "CodeBleu_score": 40.24883472221445}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t_fieldNames = node.fieldNames();\nif (node.isObject()) {\nif (node.has(_payloadField)) {\nreturn _mapper.treeToValue(node.get(_payloadField), _keyClass);\n} else {\nif (_fieldNames.hasNext()) {\nString fieldName = _fieldNames.next();\nif (_fieldNames.hasNext()) {\nreturn _mapper.treeToValue(node, _keyClass);\n} else {\nreturn _mapper.treeToValue(node.get(fieldName), _keyClass);\n}\n} else {\nreturn null;\n}\n}\n} else {\nthrow new IOException(\"Key must be an object\");\n}\n}", "CodeBleu_score": 34.3765239047119}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t_return = null;\n    if (node.isObject()) {\n        ObjectNode objNode = (ObjectNode) node;\n        Iterator<String> fieldNames = objNode.fieldNames();\n        if (fieldNames.hasNext()) {\n            String fieldName = fieldNames.next();\n            if (fieldName.equals(SIMPLE_KEY_FIELD_NAME)) {\n                _return = readValue(objNode.get(fieldName), keyType);\n            } else {\n                _return = readValue(objNode, keyType);\n            }\n        }\n    }\n    return _return;\n}", "CodeBleu_score": 42.16592197292626}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t\tString topicName = topicNameFor(id, prefix);\n\treturn sanitize(topicName, delimiter);\n}", "CodeBleu_score": 7.609518133791854}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t\tString topicName = topicNameFor(id, prefix);\n\treturn sanitize(topicName, delimiter);\n}", "CodeBleu_score": 7.609518133791854}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t\tString topicName = topicNameFor(id, prefix);\n\treturn sanitizeTopicName(topicName, delimiter);\n}", "CodeBleu_score": 7.623687416585873}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\n}", "CodeBleu_score": 10.3990398260886}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\n}", "CodeBleu_score": 10.3990398260886}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\n/**\n * The ErrorHandler constructor initializes an error handler for a source connector.", "CodeBleu_score": 12.902757374447106}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\tif (configuration == null) {\nthrow new IllegalArgumentException(\"configuration cannot be null\");\n}\nif (fields == null) {\nthrow new IllegalArgumentException(\"fields cannot be null\");\n}\nfor (Field field : fields) {\nList<String> errorMessages = getErrorMessages(configuration, field);\nif (!errorMessages.isEmpty()) {\nthrow new ConfigException(errorMessages.get(0));\n}\n}\n}", "CodeBleu_score": 28.231441641015582}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\tfor (Field field : fields) {\nList<String> messages = configuration.get(field);\nif (messages != null && !messages.isEmpty()) {\nthrow new ConfigException(field, messages.get(0));\n}\n}\n}", "CodeBleu_score": 24.339309018017687}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\tif (configuration == null) {", "CodeBleu_score": 5.37088066747494}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.isPrimitive()) {\nreturn oldSchema;\n}\nSchemaBuilder builder = SchemaBuilder.struct().name(oldSchema.name());\nfor (Field field : oldSchema.fields()) {\nString name = field.name();\nSchema schema = field.schema();\nif (schema.isPrimitive()) {\nbuilder.field(name, schema);\n} else {\n// Recursively process nested fields.\nbuilder.field(name, buildNewSchema(name, schema, headerToProcess, nestedFields, level + 1));\n}\n}\n// Add fields from headers.\nif (headerToProcess.containsKey(fieldName)) {\nHeader header = headerToProcess.get(fieldName);\nfor (String headerFieldName : header.getFieldNames()) {\nif (!nestedFields.contains(headerFieldName)) {\nSchema headerFieldSchema = header.getSchema(headerFieldName);\nif (headerFieldSchema.isPrimitive()) {\nbuilder.field(headerFieldName, headerFieldSchema);\n} else {\nbuilder.field(headerFieldName, buildNewSchema(headerFieldName, headerFieldSchema, headerToProcess, nestedFields, level + 1));\n}\n}\n}\n}\nreturn builder.build();\n}", "CodeBleu_score": 35.936805790167256}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\tif (oldSchema.isPrimitive()) {\n\t\treturn oldSchema;\n\t}\n\tSchemaBuilder builder = SchemaBuilder.struct().name(oldSchema.getName() + \"_copy\");\n\tfor (Field field : oldSchema.getFields()) {\n\t\tString name = field.name();\n\t\tSchema schema = field.schema();\n\t\tif (schema.type() == Schema.Type.STRUCT) {\n\t\t\tList<String> newNestedFields = new ArrayList<>();\n\t\t\tfor (String nestedField : nestedFields) {\n\t\t\t\tif (nestedField.startsWith(name + \".\")) {\n\t\t\t\t\tnewNestedFields.add(nestedField.replace(name + \".\", \"\"));\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!newNestedFields.isEmpty()) {\n\t\t\t\tbuilder.field(name, buildNewSchema(name, schema, headerToProcess, newNestedFields, level + 1));\n\t\t\t}\n\t\t} else {\n\t\t\tbuilder.field(name, schema);\n\t\t}\n\t}\n\tfor (Map.Entry<String, Header> entry : headerToProcess.entrySet()) {\n\t\tString headerName = entry.getKey();\n\t\tHeader header = entry.getValue();\n\t\tString[] headerFields = header.getFields();\n\t\tfor (String headerField : headerFields) {\n\t\t\tString[] headerFieldParts = headerField.split(\"\\\\.\");\n\t\t\tif (headerFieldParts.length == level + 1 && headerFieldParts[level].equals(fieldName)) {\n\t\t\t\tString[] newNestedFields = new String[level];\n\t\t\t\tfor (int i = 0; i < level; i++) {\n\t\t\t\t\tnewNestedFields[i] = headerFieldParts[i];\n\t\t\t\t}\n\t\t\t\tString newNestedFieldName = headerFieldParts[level];\n\t\t\t\tSchema newNestedFieldSchema = header.getSchema();\n\t\t\t\tif (newNestedFields.length > 1) {\n\t\t\t\t\tfor (int i = 0; i < level; i++) {\n\t\t\t\t\t\tString newNestedFieldNamePart = newNestedFields[i];\n\t\t\t\t\t\tSchemaBuilder nestedBuilder = SchemaBuilder.struct().name(builder.name() + \"_\" + newNestedFieldNamePart);\n\t\t\t\t\t\tnestedBuilder.field(newNestedFieldNamePart, builder.field(newNestedFieldNamePart).schema());\n\t\t\t\t\t\tbuilder = nestedBuilder;\n\t\t\t\t\t\tnewNestedFieldName = newNestedFieldNamePart;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t", "CodeBleu_score": 37.950029696742384}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.isPrimitive()) {\nreturn oldSchema;\n}\nSchemaBuilder builder = SchemaBuilder.struct().name(oldSchema.name()).doc(oldSchema.doc());\nfor (Field field : oldSchema.fields()) {\nString name = field.name();\nif (headerToProcess.containsKey(name)) {\nHeader header = headerToProcess.get(name);\nbuilder.field(name, header.getSchema());\n} else {\nif (level == 0 && nestedFields.contains(name)) {\nSchema schema = buildNewSchema(name, field.schema(), headerToProcess, nestedFields, level + 1);\nbuilder.field(name, schema);\n} else {\nbuilder.field(name, field.schema());\n}\n}\n}\nreturn builder.build();\n}", "CodeBleu_score": 31.762740553294673}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\tif (source.schema().field(SNAPSHOT_KEY) == null) {\nreturn null;\n}\nString snapshotString = source.getString(SNAPSHOT_KEY);\nif (snapshotString == null) {\nreturn null;\n}\nreturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 29.568633960688345}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tif (source == null) {\nreturn null;\n}\n\nString snapshotString = null;\n\ntry {\nsnapshotString = source.getString(SNAPSHOT_KEY);\n} catch (Exception e) {\n// ignore\n}\n\nif (snapshotString == null) {\nreturn null;\n}\n\nreturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 30.65296017356165}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tif (source == null) {\nreturn null;\n}\nString snapshotString = source.getString(SNAPSHOT_KEY);\nif (snapshotString == null) {\nreturn null;\n}\ntry {\nreturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n} catch (IllegalArgumentException e) {\nreturn null;\n}\n}", "CodeBleu_score": 33.00223937593342}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null) {\n\t\treturn Optional.empty();\n\t}\n\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOfRange(parts, 0, 2);\n\t}\n\tString[] parts2 = parts[0].split(\"-\");\n\tif (parts2.length > 1) {\n\t\tparts2 = Arrays.copyOfRange(parts2, 0, 1);\n\t}\n\treturn Optional.of(Float.parseFloat(parts2[0]));\n}", "CodeBleu_score": 53.907386922741466}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null || version.isEmpty()) {\n\t\treturn Optional.empty();\n\t}\n\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOfRange(parts, 0, 2);\n\t}\n\tString[] subParts = parts[0].split(\"-\");\n\tif (subParts.length > 1) {\n\t\tparts[0] = subParts[0];\n\t}\n\treturn Optional.of(Float.parseFloat(parts[0]));\n}", "CodeBleu_score": 53.29718361054594}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null || version.isEmpty()) {\n\t\treturn Optional.empty();\n\t}\n\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOfRange(parts, 0, 2);\n\t}\n\tString[] numbers = parts[0].split(\"-\");\n\tif (numbers.length > 1) {\n\t\tnumbers = Arrays.copyOfRange(numbers, 0, 1);\n\t}\n\treturn Optional.of(Float.parseFloat(numbers[0]));\n}", "CodeBleu_score": 53.41092290792786}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\treturn\ncreateContext\n(\nclusterName,\nconnectName,\nconnector,\nexchange\n)\n.flatMap(ctx -> validateAccess(ctx))\n.map(ctx -> kafkaConnectService.createConnector(ctx.getCluster(), ctx.getConnectName(), ctx.getConnector()))\n.map(connectorDTO -> build(connectorDTO, exchange))\n.map(ResponseEntity::ok)\n.onErrorResume(AccessDeniedException.class, e -> Mono.just(ResponseEntity.status(HttpStatus.FORBIDDEN).build()))\n.onErrorResume(EntityNotFoundException.class, e -> Mono.just(ResponseEntity.notFound().build()));\n}", "CodeBleu_score": 37.05450668524794}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\treturn accessService.buildContextForConnect(clusterName, connectName, exchange)\n.flatMap(context -> accessService.validateAccess(context, CREATE))\n.flatMap(context -> kafkaConnectService.createConnector(context, connector))\n.map(connectorDTO -> {\nauditService.audit(context, CREATE, connectorDTO.getName());\nreturn ResponseEntity.ok(connectorDTO);\n});\n}", "CodeBleu_score": 31.848571793219698}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t\n// Build the AccessContext with relevant details and actions\nAccessContext context = buildAccessContext(clusterName, connectName, exchange);\n\n// Validate access to the cluster\nreturn validateAccess(context)\n.then(connector\n// Call kafkaConnectService to create the connector\n.map(c -> kafkaConnectService.createConnector(context.getCluster(), c))\n// Return the result wrapped in a ResponseEntity\n.map(connectorDTO -> ResponseEntity.ok(connectorDTO))\n.defaultIfEmpty(ResponseEntity.notFound().build()))\n.onErrorResume(AccessDeniedException.class, e -> Mono.just(ResponseEntity.status(HttpStatus.FORBIDDEN).build()));\n}", "CodeBleu_score": 35.140320939054966}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\treturn getCluster(clusterName)\n.flatMap(cluster -> {\nfinal var accessContext = build(cluster, connectName, Operation.DELETE, connectorName, exchange);\nreturn validateAccess(accessContext)\n.then(Mono.defer(() -> kafkaConnectService.deleteConnector(clusterName, connectName, connectorName)))\n.then(Mono.defer(() -> audit(accessContext)));\n});\n}", "CodeBleu_score": 29.780217963903166}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\nreturn\nbuild\n.clusterName(clusterName)\n.connectName(connectName)\n.operationName(operationName)\n.operationParams(Map.of(\"connectorName\", connectorName))\n.validateAccess(exchange)\n.then(Mono.defer(() -> kafkaConnectService.deleteConnector(clusterName, connectName, connectorName)))\n.then(Mono.defer(() -> audit.info(operationName, auditBuilder -> auditBuilder.clusterName(clusterName)\n.resourceName(connectName)\n.resourceKind(\"connect\")\n.operation(\"delete\")\n.params(Map.of(\"connectorName\", connectorName))\n.build())))\n.then(Mono.defer(() -> Mono.just(ResponseEntity.noContent().build())))\n.onErrorResume(AccessDeniedException.class, e -> Mono.defer(() -> Mono.just(ResponseEntity.status(HttpStatus.FORBIDDEN).build())))\n.onErrorResume(ResourceNotFoundException.class, e -> Mono.defer(() -> Mono.just(ResponseEntity.status(HttpStatus.NOT_FOUND).build())))\n.onErrorResume(InvalidRequestException.class, e -> Mono.defer(() -> Mono.just(ResponseEntity.status(HttpStatus.BAD_REQUEST).build())))\n.onErrorResume(e -> Mono.defer(() -> Mono.just(ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build())));\n}", "CodeBleu_score": 29.094648723216892}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\n// Get the cluster from the cache.\nCluster cluster = getCluster(clusterName);\nif (cluster == null) {\nreturn Mono.just(ResponseEntity.notFound().build());\n}\n\n// Create an AccessContext with the required details.\nAccessContext accessContext = AccessContext.builder()\n.clusterName(clusterName)\n.cluster(cluster)\n.connectName(connectName)\n.operationName(KafkaConnectOperations.DELETE_CONNECTOR)\n.userName(exchange.getRequest().getPrincipal().getName())\n.build();\n\n// Validate access to the cluster.\nvalidateAccess(accessContext);\n\n// Build the operation parameters.\nMap<String, String> operationParams = new HashMap<>();\noperationParams.put(KafkaConnectOperations.CONNECTOR_PARAM, connectorName);\n\n// Call the kafkaConnectService to delete the connector.\nreturn kafkaConnectService.deleteConnector(clusterName, connectName, operationParams)\n.then(Mono.defer(() -> {\n// Audit the operation.\naudit.info(accessContext.getUserName(), accessContext.getClusterName(),\naccessContext.getConnectName(), KafkaConnectOperations.DELETE_CONNECTOR.name(),\n\"connectorName=\" + connectorName, \"status=success\");\n\n// Return a response.\nreturn Mono.just(ResponseEntity.noContent().build());\n}))\n.onErrorResume(t -> {\n// Audit the operation.\naudit.error(accessContext.getUserName(), accessContext.getClusterName(),\naccessContext.getConnectName(), KafkaConnectOperations.DELETE_CONNECTOR.name(),\n\"connectorName=\" + connectorName, \"status=failed\", \"error=\" + t.getMessage());\n\n// Return a response.\nreturn Mono.just(ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build());\n});\n}", "CodeBleu_score": 41.60051177739585}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\n// Build the access context\nAccessContext accessContext = buildAccessContext(clusterName, connectName, connectorName, action, exchange);\n\n// Validate access\nvalidateAccess(accessContext);\n\n// Get the kafkaConnectService\nKafkaConnectService kafkaConnectService = getCluster(clusterName).getKafkaConnectService();\n\n// Update the connector state\nreturn kafkaConnectService.updateConnectorState(accessContext, action)\n.then(Mono.defer(() -> {\n// Audit the signal\naudit(accessContext);\n\n// Return a response\nreturn Mono.just(new ResponseEntity<>(HttpStatus.OK));\n}));\n}", "CodeBleu_score": 24.419788479338607}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\n//        // validate access\n//        AccessContext context = AccessContext.builder()\n//                .cluster(getCluster(clusterName))\n//                .user(getUser(exchange))\n//                .request(exchange.getRequest())\n//                .operation(operationName)\n//                .operationParams(operationParams)\n//                .build();\n//        validateAccess(context);\n//\n//        // build the required connect actions\n//        ConnectActions connectActions = build(clusterName, connectName, connectorName, action);\n//\n//        // perform the required connect actions\n//        return doOnEach(connectActions, connector -> kafkaConnectService.updateConnectorState(clusterName, connectName, connector.name(), connector.action()));\n//    }", "CodeBleu_score": 6.624085789973376}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\nreturn getCluster(clusterName)\n.flatMap(cluster -> {\n\nMap<String, Object> operationParams = new HashMap<>();\noperationParams.put(CONNECT_NAME, connectName);\noperationParams.put(CONNECTOR_NAME, connectorName);\noperationParams.put(ACTION, action.name());\n\nreturn build(cluster, exchange)\n.flatMap(context -> validateAccess(context, operationParams))\n.flatMap(context -> doOnEach(context,\n\n// Update the connector state\nconnector -> kafkaConnectService.updateConnectorState(clusterName, connectName, connectorName, action),\n\n// Audit\naudit -> audit.info(String.format(\"Updating connector state for cluster: %s, connect: %s, connector: %s, action: %s\",\nclusterName, connectName, connectorName, action.name()))));\n});\n}", "CodeBleu_score": 30.1962994121041}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\n}", "CodeBleu_score": 8.648212644078399}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\n@RequestMapping(method = RequestMethod.POST, value = \"/clusters/{clusterName}/connectors/{connectorName}/plugins/{pluginName}/config/validate\")\npublic Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig(\n@PathVariable(\"clusterName\") String clusterName,\n@PathVariable(\"connectorName\") String connectorName,\n@PathVariable(\"pluginName\") String pluginName,\n@RequestBody ConnectorPluginConfigValidationRequestDTO connectorPluginConfigValidationRequestDTO) {\n\nreturn kafkaConnectService.validateConnectorPluginConfig(clusterName, connectorName, pluginName, connectorPluginConfigValidationRequestDTO)\n.map(connectorPluginConfigValidationResponseDTO -> {\nif (connectorPluginConfigValidationResponseDTO.hasErrors()) {\nreturn ResponseEntity.status(HttpStatus.BAD_REQUEST).body(connectorPluginConfigValidationResponseDTO);\n} else {\nreturn ResponseEntity.ok(connectorPluginConfigValidationResponseDTO);\n}\n});\n}\n}", "CodeBleu_score": 35.98648073266044}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\npublic Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig(\n@PathVariable(\"clusterName\") String clusterName,\n@PathVariable(\"connectName\") String connectName,\n@PathVariable(\"pluginName\") String pluginName,\n@RequestBody ConnectorPluginConfigValidationRequestDTO connectorPluginConfigValidationRequestDTO) {\n\nreturn kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, connectorPluginConfigValidationRequestDTO)\n.map(connectorPluginConfigValidationResponseDTO -> ResponseEntity.ok(connectorPluginConfigValidationResponseDTO))\n.onErrorResume(ConnectRestException.class, e -> Mono.just(ResponseEntity.status(e.getStatus()).build()));\n}\n\n}", "CodeBleu_score": 38.003575310622175}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\tSpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n\tbuilder.initializers(new DynamicConfigPropertiesInitializer());\n\treturn builder.run(args);\n}", "CodeBleu_score": 32.22881051305274}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t\t.initializers(new DynamicConfigPropertiesInitializer())\n\t\t\t.run(args);\n}", "CodeBleu_score": 40.70921928090663}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t\t.initializers(new DynamicConfigPropertiesInitializer())\n\t\t\t.run(args);\n}", "CodeBleu_score": 40.70921928090663}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\tif (search == null) {\n\t\treturn t -> true;\n\t} else {\n\t\tfinal String searchTerm = search.toLowerCase();\n\t\treturn t -> t.getDisplayName().toLowerCase().contains(searchTerm) || t.getConnectorName().toLowerCase().contains(searchTerm) || t.getBundleName().toLowerCase().contains(searchTerm) || t.getBundleVersion().toLowerCase().contains(searchTerm);\n\t}\n}", "CodeBleu_score": 37.917355668581806}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\treturn new Predicate<FullConnectorInfoDTO>() {\n\t\t@Override\n\t\tpublic boolean test(FullConnectorInfoDTO dto) {\n\t\t\tif (Strings.isNullOrEmpty(search)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\treturn containsIgnoreCase(dto.getDisplayName(), search)\n\t\t\t\t\t|| containsIgnoreCase(dto.getConnectorName(), search)\n\t\t\t\t\t|| containsIgnoreCase(dto.getConnectorDescription(), search)\n\t\t\t\t\t|| containsIgnoreCase(dto.getConnectorCategory(), search);\n\t\t}\n\t};\n}", "CodeBleu_score": 40.548110014187976}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\treturn search == null ? (Predicate<FullConnectorInfoDTO>) c -> true : (Predicate<FullConnectorInfoDTO>) c -> containsIgnoreCase(c.getNames(), search) || containsIgnoreCase(c.getDescriptions(), search) || containsIgnoreCase(c.getLabels(), search);\n}", "CodeBleu_score": 43.774970360046595}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\"\"\"\n\n# The string to append to the end of the file\nend_string = \"\"\"\n  }", "CodeBleu_score": 11.392147302090674}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\nMap<String, Object> flattenedProperties = new HashMap<String, Object>()\n\nif (propertiesMap == null) {\nreturn flattenedProperties\n}\n\nfor (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\nString key = entry.getKey()\nObject value = entry.getValue()\nif (value instanceof Map) {\nflattenedProperties.putAll(flattenClusterProperties(prefix == null ? key : prefix + \".\" + key, (Map<String, Object>) value))\n} else {\nflattenedProperties.put(prefix == null ? key : prefix + \".\" + key, value)\n}\n}\n\nreturn flattenedProperties\n}", "CodeBleu_score": 42.30683845184566}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\tMap<String, Object> flattenedMap = new HashMap<>();\nif (propertiesMap == null) {\nreturn flattenedMap;\n}\n\nfor (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\nString key = entry.getKey();\nObject value = entry.getValue();\nif (prefix != null) {\nkey = prefix + \".\" + key;\n}\n\nif (value instanceof Map) {\nflattenedMap.putAll(flattenClusterProperties(key, (Map<String, Object>) value));\n} else {\nflattenedMap.put(key, value);\n}\n}\n\nreturn flattenedMap;\n}", "CodeBleu_score": 50.72847363392704}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n addClientSslSupport(configDef);\n addClientSaslSupport(configDef);\n Set<String> kafkaConfigKeys = configDef.configKeys().stream().filter(configKey -> configKey.type == ConfigDef.Type.PASSWORD).collect(Collectors.toSet());\n return kafkaConfigKeys;\n }", "CodeBleu_score": 62.041026580669126}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n addClientSslSupport(configDef);\n addClientSaslSupport(configDef);\n Set<String> passwordKeys = configDef.configKeys().stream()\n .filter(configKeys -> configKeys.type == ConfigDef.Type.PASSWORD)\n .map(ConfigDef.ConfigKey::name)\n .collect(Collectors.toSet());\n return passwordKeys;\n }", "CodeBleu_score": 64.40982430223261}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n addClientSslSupport(configDef);\n addClientSaslSupport(configDef);\n Set<String> configKeys = configDef.configKeys().stream()\n .filter(configKey -> configKey.type == ConfigDef.Type.PASSWORD)\n .map(ConfigKey::name)\n .collect(Collectors.toSet());\n return configKeys;\n }", "CodeBleu_score": 63.10536070995948}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t\treturn adminClient.describeAcls(AclBindingFilter.ANY)\n\t.flatMap(acls -> {\n\t\tif (acls.isEmpty()) {\n\t\t\treturn Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n\t\t}\n\t\tSet<AclOperation> authorizedOperations = acls.values().stream()\n\t\t.flatMap(aclBindings -> aclBindings.stream())\n\t\t.map(AclBinding::operation)\n\t\t.collect(Collectors.toSet());\n\t\tif (authorizedOperations.containsAll(AclOperation.ALL_OPERATIONS)) {\n\t\t\treturn Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n\t\t}\n\t\tif (authorizedOperations.containsAll(AclOperation.ALTER_CONFIGS)) {\n\t\t\treturn Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n\t\t}\n\t\treturn Mono.empty();\n\t});\n}", "CodeBleu_score": 43.78511762880105}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t\treturn adminClient.describeAcls(clusterDescription.name())\n\t.map(aclDescription -> {\n\tif (aclDescription.resourcePatternType() == ResourcePatternType.ANY) {\n\treturn clusterDescription.authorizedOperations().containsAll(aclDescription.authorizedOperations())\n\t&& aclDescription.aclOperationType() == AclOperation.ALTER\n\t&& aclDescription.aclPermissionType() == AclPermissionType.ALLOW\n\t&& aclDescription.resourcePatternType() == ResourcePatternType.ANY\n\t&& aclViewEnabled(clusterDescription);\n\t}\n\treturn false;\n\t})\n\t.map(KafkaAclFeature::of)\n\t.defaultIfEmpty(KafkaAclFeature.empty());\n}", "CodeBleu_score": 25.831583702217166}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn adminClient.describeAcls(AclBindingFilter.ANY)\n.map(aclBindingSet -> aclBindingSet.iterator().hasNext())\n.map(aclViewEnabled -> aclViewEnabled ? clusterDescription.authorizedOperations()\n.map(authorizedOperations -> authorizedOperations.containsAll(KAFKA_ACL_EDIT_OPERATIONS))\n.filter(containsAll -> containsAll)\n.map(containsAll -> new ClusterFeature(KAFKA_ACL_EDIT))\n.defaultIfEmpty(ClusterFeature.empty())\n: Mono.empty());\n}", "CodeBleu_score": 30.766022428923424}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\nif (prevRange.isEmpty()) {\n// initialize the map of offsets to read from\nnextRange = seekOperations.getOffsetsForSeek();\n} else {\n// use the last range as the starting point\nfor (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\nTopicPartition tp = entry.getKey();\nFromToOffset prevOffset = entry.getValue();\nlong startOffset = prevOffset.getToOffset();\nlong endOffset = seekOperations.getOffsetsForSeek().get(tp).getToOffset();\nlong numMessages = endOffset - startOffset;\nlong numMessagesToPoll = Math.max(numMessages, minNumMessages);\nlong newStartOffset = Math.max(startOffset - numMessagesToPoll, 0);\nlong newEndOffset = Math.min(newStartOffset + numMessagesToPoll, endOffset);\nFromToOffset newOffset = new FromToOffset(newStartOffset, newEndOffset);\nnextRange.put(tp, newOffset);\n}\n}\nreturn nextRange;\n}", "CodeBleu_score": 33.12768773783049}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> result = new TreeMap<>();", "CodeBleu_score": 9.52784805219219}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n\nif (prevRange.isEmpty()) {\n// If there was no previous range, start from the beginning of the topic\nfor (Map.Entry<TopicPartition, Long> entry : seekOperations.getOffsetsForSeek().entrySet()) {\nTopicPartition tp = entry.getKey();\nlong offset = entry.getValue();\nFromToOffset fromToOffset = new FromToOffset(offset, Long.MAX_VALUE);\nnextRange.put(tp, fromToOffset);\n}\n} else {\n// If there is a previous range, start from the end of the previous range\nfor (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\nTopicPartition tp = entry.getKey();\nFromToOffset fromToOffset = entry.getValue();\nlong offset = fromToOffset.getEndOffset();\nFromToOffset newFromToOffset = new FromToOffset(offset, Long.MAX_VALUE);\nnextRange.put(tp, newFromToOffset);\n}\n}\n\n// Calculate the number of messages to poll for each partition\nint numMessagesPerPartition = calculateNumMessagesPerPartition(nextRange);\n\n// For each partition, calculate the new start offset\nfor (Map.Entry<TopicPartition, FromToOffset> entry : nextRange.entrySet()) {\nTopicPartition tp = entry.getKey();\nFromToOffset fromToOffset = entry.getValue();\nlong offset = fromToOffset.getStartOffset();\nlong newOffset = Math.max(0, offset - (numMessagesPerPartition - 1));\nFromToOffset newFromToOffset = new FromToOffset(newOffset, fromToOffset.getEndOffset());\nnextRange.put(tp, newFromToOffset);\n}\n\nreturn nextRange;\n}", "CodeBleu_score": 31.496874853665425}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\t\tif (input.isLegacyModeEnabled()) {\n\t\tif (input.getConfiguration().getZookeeperConnectString() == null\n\t\t\t\t|| input.getConfiguration().getZookeeperConnectString().isEmpty()) {\n\t\t\tthrow new IllegalArgumentException(\"Zookeeper connection string is required for legacy mode\");\n\t\t}\n\t\tif (input.getConfiguration().getKafkaTopic() == null || input.getConfiguration().getKafkaTopic().isEmpty()) {\n\t\t\tthrow new IllegalArgumentException(\"Kafka topic is required for legacy mode\");\n\t\t}\n\t\tif (input.getConfiguration().getKafkaGroup() == null || input.getConfiguration().getKafkaGroup().isEmpty()) {\n\t\t\tthrow new IllegalArgumentException(\"Kafka group is required for legacy mode\");\n\t\t}\n\t\tinput.setMode(MessageInputMode.LEGACY);\n\t\tinput.setLegacyInput(new LegacyInput(input.getConfiguration()));\n\t\tinput.getLegacyInput().doLaunch();\n\t} else {\n\t\tif (input.getConfiguration().getBootstrapServers() == null\n\t\t\t\t|| input.getConfiguration().getBootstrapServers().isEmpty()) {\n\t\t\tthrow new IllegalArgumentException(\"Bootstrap servers are required for consumer mode\");\n\t\t}\n\t\tif (input.getConfiguration().getKafkaTopic() == null || input.getConfiguration().getKafkaTopic().isEmpty()) {\n\t\t\tthrow new IllegalArgumentException(\"Kafka topic is required for consumer mode\");\n\t\t}\n\t\tif (input.getConfiguration().getKafkaGroup() == null || input.getConfiguration().getKafkaGroup().isEmpty()) {\n\t\t\tthrow new IllegalArgumentException(\"Kafka group is required for consumer mode\");\n\t\t}\n\t\tinput.setMode(MessageInputMode.CONSUMER);\n\t\tinput.setConsumerInput(new ConsumerInput(input.getConfiguration()));\n\t\tinput.getConsumerInput().doLaunch();\n\t}\n\tinput.awaitRunning();\n\tinput.register();\n\tinput.scheduleAtFixedRate(new UpdateLastSecondBytesReadTask(input), 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 28.772040630187472}, {"code": "public void doLaunch(final MessageInput input){\n\tif (input.getLegacyModeEnabled()) {", "CodeBleu_score": 2.425687205391359}, {"code": "public void doLaunch(final MessageInput input){\n\tif (input.getConfiguration().isLegacyModeEnabled()) {\nif (input.getConfiguration().getZookeeperConnectString() == null || input.getConfiguration().getZookeeperConnectString().isEmpty()) {\nthrow new IllegalArgumentException(\"Zookeeper connection string must be specified in legacy mode\");\n}\n\nif (input.getConfiguration().getKafkaBootstrapServers() == null || input.getConfiguration().getKafkaBootstrapServers().isEmpty()) {\nthrow new IllegalArgumentException(\"Kafka bootstrap servers must be specified in legacy mode\");\n}\n\ninput.launchLegacy();\n} else {\ninput.launchConsumer();\n}\n\ninput.awaitRunning();\ninput.registerLifecycleEvents();\n\n// Schedule a task to update the last second bytes read every second\nScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);\nscheduler.scheduleAtFixedRate(input.getAndSetLastSecondBytesReadRunnable(), 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 33.89343361896757}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t\tString customProperties = getString(\"custom.properties\");\n\tif (customProperties != null) {\n\t\tProperties customProps = new Properties();\n\t\ttry {\n\t\t\tcustomProps.load(new StringReader(customProperties));\n\t\t\tprops.putAll(customProps);\n\t\t} catch (IOException e) {\n\t\t\terror(\"Error loading custom properties: \" + e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 39.99374035427139}, {"code": "private void insertCustomProperties(Properties props){\n\t\tString customProperties = null;\n\ttry {\n\t\tcustomProperties = getString(CUSTOM_PROPERTIES_KEY);\n\t\tif (customProperties != null) {\n\t\t\tProperties customProps = new Properties();\n\t\t\tcustomProps.load(new StringReader(customProperties));\n\t\t\tprops.putAll(customProps);\n\t\t}\n\t} catch (IOException e) {\n\t\terror(\"Unable to load custom properties.  Reason: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 40.66251481671191}, {"code": "private void insertCustomProperties(Properties props){\n\t\tString customProperties = null;\n\ttry {\n\t\tcustomProperties = getString(\"customProperties\");\n\t} catch (IOException e) {\n\t\terror(\"Error loading custom properties: \" + e.getMessage());\n\t\treturn;\n\t}\n\tProperties customProps = new Properties();\n\ttry {\n\t\tcustomProps.load(new StringReader(customProperties));\n\t} catch (IOException e) {\n\t\terror(\"Error parsing custom properties: \" + e.getMessage());\n\t\treturn;\n\t}\n\tprops.putAll(customProps);\n}", "CodeBleu_score": 45.976359409725234}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\tif (entries == null || entries.isEmpty()) {\n\t\treturn;\n\t}\n\tlong startTime = System.currentTimeMillis();\n\tlong bytes = 0;\n\tlong messages = 0;\n\tlong writtenBytes = 0;\n\tlong writtenMessages = 0;\n\tfor (RawMessageEvent entry : entries) {\n\t\tif (entry == null) {\n\t\t\tcontinue;\n\t\t}\n\t\tbytes += entry.getEncodedRawMessage().length;\n\t\tmessages++;\n\t}\n\tList<JournalEntry> journalEntries = entries.stream().map(entry -> {\n\t\ttry {\n\t\t\treturn entry.getJournalEntry();\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}).collect(Collectors.toList());\n\ttry {\n\t\tlong written = journal.write(journalEntries);\n\t\twrittenBytes += written;\n\t\twrittenMessages += journalEntries.size();\n\t} catch (JournalException e) {\n\t\tlogger.error(\"Error writing to journal\", e);\n\t\tthrow new MessageQueueException(e);\n\t}\n\tmetrics.addAndGet(MetricName.MESSAGE_BYTES_WRITTEN, bytes);\n\tmetrics.addAndGet(MetricName.MESSAGES_WRITTEN, messages);\n\tmetrics.addAndGet(MetricName.BYTES_WRITTEN, writtenBytes);\n\tmetrics.addAndGet(MetricName.MESSAGES_WRITTEN, writtenMessages);\n\tlong endTime = System.currentTimeMillis();\n\tlong duration = endTime - startTime;\n\tif (duration > 1000) {\n\t\tlogger.warn(\"Writing {} messages took {} ms\", journalEntries.size(), duration);\n\t}\n}", "CodeBleu_score": 35.821680171426486}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t// Filter out null entries\nList<RawMessageEvent> filteredEntries = entries.stream().filter(e -> e != null).collect(Collectors.toList());\n// Map each event to a journal entry\nList<JournalEntry> journalEntries = filteredEntries.stream().map(e -> new JournalEntry(e.getMessageId(), e.getEncodedRawMessage())).collect(Collectors.toList());\n// Calculate the total message bytes\nlong totalMessageBytes = journalEntries.stream().mapToLong(e -> e.getMessageBytes()).sum();\n// Attempt to write the entries to the journal\ntry {\njournal.write(journalEntries);\n} catch (JournalException e) {\n// If the write fails, retry using an exponential back-off strategy\nlong delay = 100;\nwhile (true) {\ntry {\njournal.write(journalEntries);\nbreak;\n} catch (JournalException e) {\nif (delay >= 10000) {\nthrow e;\n}\ntry {\nThread.sleep(delay);\n} catch (InterruptedException e1) {\nthrow new MessageQueueException(\"Interrupted while writing to journal\", e1);\n}\ndelay *= 2;\n}\n}\n}\n// Update the written messages and bytes metrics\nwrittenMessages.addAndGet(journalEntries.size());\nwrittenBytes.addAndGet(totalMessageBytes);\n}", "CodeBleu_score": 44.67616870190717}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\tif (entries == null || entries.isEmpty()) {\n\t\treturn;\n\t}\n\tList<RawMessageEvent> filteredEntries = entries.stream().filter(Objects::nonNull).collect(Collectors.toList());\n\tlong totalBytes = filteredEntries.stream().mapToLong(RawMessageEvent::getEncodedRawMessage).sum();\n\tmetrics.addAndGet(MetricNames.MESSAGES_WRITTEN, filteredEntries.size());\n\tmetrics.addAndGet(MetricNames.BYTES_WRITTEN, totalBytes);\n\ttry {\n\t\tjournal.write(filteredEntries);\n\t} catch (MessageQueueException ex) {\n\t\tmetrics.addAndGet(MetricNames.MESSAGES_FAILED_WRITTEN, filteredEntries.size());\n\t\tmetrics.addAndGet(MetricNames.BYTES_FAILED_WRITTEN, totalBytes);\n\t\tthrow ex;\n\t}\n}", "CodeBleu_score": 30.750474132515077}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\t\tif (messages.isEmpty()) {\n\t\treturn;\n\t}\n\tlong maxId = messages.stream().map(Message::getId).max(Long::compareTo).get();\n\tif (maxId > 0) {\n\t\tacknowledgedMessages.mark(maxId);\n\t\tstream.mark(maxId);\n\t}\n}", "CodeBleu_score": 32.78086389930587}, {"code": "public void acknowledge(List<Message> messages){\n\t// Identify the maximum valid message queue ID from the list of messages.\nlong maxMessageQueueID = messages.stream().map(Message::getMessageQueueID).filter(id -> id >= 0).max(Long::compare).orElse(-1);\n// Acknowledge the maximum valid message queue ID if present.\nif (maxMessageQueueID >= 0) {\nacknowledge(maxMessageQueueID);\n}\n// Update the metrics by marking the number of acknowledged messages.\nmetrics.mark(messages.size());\n}", "CodeBleu_score": 40.97446056242379}, {"code": "public void acknowledge(List<Message> messages){\n\t\tif (messages == null || messages.isEmpty()) {\n\t\treturn;\n\t}\n\tint maxId = messages.stream().map(Message::getId).max(Integer::compare).get();\n\tif (maxId > 0) {\n\t\tacknowledgedMessages.mark(maxId);\n\t}\n}", "CodeBleu_score": 32.01632241744807}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\t\tmetricRegistry.getMetrics().entrySet().stream().filter(entry -> entry.getKey().getName().startsWith(LocalKafkaJournal.class.getName())).forEach(entry -> {\n\t\tString legacyMetricName = entry.getKey().getName().replace(LocalKafkaJournal.class.getName(), \"journal.LocalKafkaJournal\");\n\t\ttry {\n\t\t\tmetricRegistry.register(legacyMetricName, entry.getValue());\n\t\t} catch (IllegalArgumentException e) {\n\t\t\tLOGGER.warn(\"Failed to register legacy metric: \" + legacyMetricName + \" for metric: \" + entry.getKey().getName(), e);\n\t\t}\n\t});\n}", "CodeBleu_score": 48.733922523208975}, {"code": "private void registerLegacyMetrics(){\n\t\tMetricRegistry metricRegistry = MetricRegistry.get();\n\tmetricRegistry.getNames().stream()\n\t\t.filter(name -> name.startsWith(LocalKafkaJournal.class.getName()))\n\t\t.forEach(name -> {\n\t\t\tString legacyName = name.replace(LocalKafkaJournal.class.getName(), LegacyLocalKafkaJournal.class.getName());\n\t\t\ttry {\n\t\t\t\tmetricRegistry.register(legacyName, metricRegistry.getMetrics().get(name));\n\t\t\t} catch (IllegalArgumentException e) {\n\t\t\t\tLOG.warn(\"Failed to register legacy metric {} under name {}. {}\", name, legacyName, e.getMessage());\n\t\t\t}\n\t\t});\n}", "CodeBleu_score": 45.15332319845203}, {"code": "private void registerLegacyMetrics(){\n\t\tfinal String prefix = LocalKafkaJournal.class.getName() + \".\";\n\tfinal Set<String> metrics = metricsRegistry.getMetrics().keySet();\n\tmetrics.stream()\n\t\t.filter(name -> name.startsWith(prefix))\n\t\t.forEach(name -> {\n\t\t\tfinal String legacyName = name.replace(prefix, \"journal.\");\n\t\t\ttry {\n\t\t\t\tmetricsRegistry.register(legacyName, metricsRegistry.getMetrics().get(name));\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOG.warn(\"Failed to register legacy metric {} under {}.\", name, legacyName, e);\n\t\t\t}\n\t\t});\n}", "CodeBleu_score": 41.982945661111536}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\tTimer timer = null;\ntry {\ntimer = metricRegistry.timer(metricName);\n} catch (IllegalArgumentException iae) {\ntimer = metricRegistry.getTimers().get(metricName);\n}\nreturn timer;\n}", "CodeBleu_score": 29.183586619851702}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tTimer timer = null\n\ttry {\n\t\ttimer = metricRegistry.timer(metricName)\n\t} catch (IllegalArgumentException e) {\n\t\ttimer = metricRegistry.timer(metricRegistry.getMetrics().get(metricName).name)\n\t}\n\treturn timer\n}", "CodeBleu_score": 32.950434574996144}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\tTimer timer = metricRegistry.timer(metricName);\ntry {\nreturn metricRegistry.timer(metricName);\n} catch (IllegalArgumentException e) {\n// timer is already registered\n}\nreturn timer;\n}", "CodeBleu_score": 22.923765525259466}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\nmetricRegistry.register(name, (Gauge<Long>) () -> {\nlong committedOffset = getCommittedOffset();\nlong logEndOffset = getLogEndOffset();\nlong uncommittedMessages = 0;\nif (committedOffset == DEFAULT_COMMITTED_OFFSET) {\nuncommittedMessages = logEndOffset - getLogStartOffset();\n} else {\nuncommittedMessages = logEndOffset - committedOffset;\n}\nif (uncommittedMessages < 0) {\nreturn 0L;\n} else {\nreturn uncommittedMessages;\n}\n});\n} catch (IllegalArgumentException e) {\n}\n}", "CodeBleu_score": 46.48000943982904}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\nmetricRegistry.register(name, (Gauge<Integer>) () -> {\nlong committedOffset = getCommittedOffset();\nif (committedOffset == DEFAULT_COMMITTED_OFFSET) {\nreturn (int) (getLogEndOffset() - getLogStartOffset());\n} else {\nreturn (int) (getLogEndOffset() - committedOffset);\n}\n});\n} catch (IllegalArgumentException e) {\n}\n}", "CodeBleu_score": 41.95252034763966}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\nmetricRegistry.register(MetricRegistry.name(name, \"uncommitted\"), new Gauge<Long>() {\n@Override\npublic Long getValue() {\nlong committed = getCommittedOffset();\nif (committed == -1) {\nreturn getLogEndOffset() - getLogStartOffset();\n} else {\nreturn getLogEndOffset() - committed;\n}\n}\n});\n} catch (IllegalArgumentException e) {\n}\n}", "CodeBleu_score": 42.20580256848084}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\nif (debugEnabled) {\ndebug(\"No messages to write to Kafka\")\n}\nreturn lastOffset\n}\n\nif (debugEnabled) {\ndebug(\"Writing \" + messages.size() + \" messages to Kafka\")\n}\n\nlong start = System.nanoTime()\n\n// Create a message set from the list of messages\nByteBufferMessageSet messageSet = new ByteBufferMessageSet(compressionCodec, messages)\n\n// Get the size of the message set\nint messageSetSize = messageSet.sizeInBytes()\n\n// Append the message set to the log\nlastOffset = producer.append(topic, partition, messageSet)\n\n// Update the number of messages written\nmessagesWritten.mark(messages.size())\n\n// Log the details of the write\nif (debugEnabled) {\ndebug(\"Wrote \" + messages.size() + \" messages of \" + payloadSize + \" bytes to Kafka in \" + (System.nanoTime() - start) / 1000000 + \" ms\")\n}\n\nreturn lastOffset\n}", "CodeBleu_score": 43.27555554460676}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\nif (debugEnabled) {\ndebug(\"No messages to flush\")\n}\nreturn lastOffset\n}\nif (debugEnabled) {\ndebug(\"Flushing {} messages with payload size {} bytes\", messages.size(), payloadSize)\n}\nByteBufferMessageSet messageSet = new ByteBufferMessageSet(compressionCodec, payloadSize, messages)\nlong startOffset = lastOffset\nlong endOffset = startOffset + messageSet.sizeInBytes()\nif (debugEnabled) {\ndebug(\"Writing messages with offsets in range [{}, {}] to log {}\", startOffset, endOffset, log)\n}\nlog.append(messageSet)\nlastOffset = log.lastOffset()\nif (debugEnabled) {\ndebug(\"Wrote {} messages to log {} with base offset {} and last offset {}\", messages.size(), log, startOffset, lastOffset)\n}\nmark(messages.size())\nreturn lastOffset\n}", "CodeBleu_score": 44.202436286247725}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\nif (debugEnabled) {\nlog.debug(\"No messages to flush\");\n}\nreturn lastOffset;\n}\n\nByteBufferMessageSet messageSet = new ByteBufferMessageSet(compressionCodec, payloadSize);\nfor (Message message : messages) {\nmessageSet.add(message);\n}\n\nif (debugEnabled) {\nlog.debug(\"Writing {} bytes to log\", messageSet.sizeInBytes());\n}\n\nlastOffset = log.append(messageSet);\nif (debugEnabled) {\nlog.debug(\"Wrote to log, new last offset {}\", lastOffset);\n}\n\nmetrics.markMeter(numBytesOutPerSec, messageSet.sizeInBytes());\nmetrics.markMeter(numMessagesOutPerSec, messages.size());\nmetrics.updateHistogram(messageSizeOutHistogram, messageSet.sizeInBytes());\nmetrics.updateHistogram(messageCountOutHistogram, messages.size());\n\nreturn lastOffset;\n}", "CodeBleu_score": 43.569911303572894}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\tString clusterId = clusterIdMap.get(clusterPhyId);\n\tif (clusterId == null) {\n\t\tlogger.error(\"No cluster ID found for cluster physical ID: \" + clusterPhyId);\n\t\treturn;\n\t}\n\tlogger.info(\"Closing Kafka AdminClient instances for cluster ID: \" + clusterId);\n\tsynchronized (clientMap) {\n\t\tList<AdminClient> clientList = clientMap.get(clusterId);\n\t\tif (clientList == null || clientList.isEmpty()) {\n\t\t\tlogger.info(\"No Kafka AdminClient instances found for cluster ID: \" + clusterId);\n\t\t\treturn;\n\t\t}\n\t\tfor (AdminClient client : clientList) {\n\t\t\ttry {\n\t\t\t\tclient.close();\n\t\t\t\tlogger.info(\"Closed Kafka AdminClient instance for cluster ID: \" + clusterId);\n\t\t\t} catch (Exception e) {\n\t\t\t\tlogger.error(\"Failed to close Kafka AdminClient instance for cluster ID: \" + clusterId, e);\n\t\t\t}\n\t\t}\n\t\tclientMap.remove(clusterId);\n\t}\n}", "CodeBleu_score": 41.3388399293578}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\tif (clusterPhyId == null)  {\n\t\tlogger.error(\"Cluster ID is null. Cannot close AdminClient instances.\")\n\t\treturn\n\t}\n\ttry  {\n\t\tlogger.info(\"Closing AdminClient instances for cluster ID: \" + clusterPhyId)\n\t\tsynchronized (clientMap)  {\n\t\t\tList<AdminClient> clientList = clientMap.get(clusterPhyId)\n\t\t\tif (clientList == null || clientList.isEmpty())  {\n\t\t\t\tlogger.info(\"No AdminClient instances found for cluster ID: \" + clusterPhyId)\n\t\t\t\treturn\n\t\t\t}\n\t\t\tfor (AdminClient client : clientList)  {\n\t\t\t\ttry  {\n\t\t\t\t\tclient.close()\n\t\t\t\t\tlogger.info(\"Closed AdminClient instance for cluster ID: \" + clusterPhyId)\n\t\t\t\t}\n\t\t\t\tcatch (Exception e)  {\n\t\t\t\t\tlogger.error(\"Failed to close AdminClient instance for cluster ID: \" + clusterPhyId, e)\n\t\t\t\t}\n\t\t\t}\n\t\t\tclientMap.remove(clusterPhyId)\n\t\t}\n\t}\n\tfinally  {\n\t\tlock.unlock()\n\t}\n}", "CodeBleu_score": 36.548695729355494}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\t// Start closing process\n\tLOGGER.info(\"Closing Kafka AdminClient instances for cluster ID: \" + clusterPhyId);\n\n\t// Lock the client map to ensure thread safety\n\tsynchronized (clientMap) {\n\t\t// Retrieve the list of AdminClient instances for the specified cluster ID\n\t\tList<AdminClient> clientList = clientMap.get(clusterPhyId);\n\n\t\t// If no clients are found, return\n\t\tif (clientList == null || clientList.isEmpty()) {\n\t\t\tLOGGER.info(\"No Kafka AdminClient instances found for cluster ID: \" + clusterPhyId);\n\t\t\treturn;\n\t\t}\n\n\t\t// Attempt to close all AdminClient instances in the list\n\t\ttry {\n\t\t\tfor (AdminClient client : clientList) {\n\t\t\t\tclient.close();\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tLOGGER.error(\"Error closing Kafka AdminClient instance for cluster ID: \" + clusterPhyId, e);\n\t\t}\n\n\t\t// Log a success message\n\t\tLOGGER.info(\"Successfully closed Kafka AdminClient instances for cluster ID: \" + clusterPhyId);\n\t}\n\n\t// Release the lock\n\tunlock();\n}", "CodeBleu_score": 37.212342790703055}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true\n\tif (adminClientList == null) {\n\t\treturn true\n\t}\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30, TimeUnit.SECONDS)\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Error closing AdminClient for cluster \" + clusterPhyId, e)\n\t\t\tsuccess = false\n\t\t}\n\t}\n\treturn success\n}", "CodeBleu_score": 51.90529350044278}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\tboolean success = true;\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30, TimeUnit.SECONDS);\n\t\t} catch (Exception e) {\n\t\t\tLOGGER.error(\"Failed to close AdminClient for cluster {}.\", clusterPhyId, e);\n\t\t\tsuccess = false;\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 65.8629404912233}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true\n\tif (adminClientList == null) {\n\t\treturn true\n\t}\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30, TimeUnit.SECONDS)\n\t\t} catch (Exception e) {\n\t\t\tsuccess = false\n\t\t\tlog.error(\"Error while closing admin client for cluster {}. {}\", clusterPhyId, e)\n\t\t}\n\t}\n\treturn success\n}", "CodeBleu_score": 47.847535600341416}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\t\tif (app != null)  {\n\t\tapp.stop();\n\t\tint i = 0;\n\t\twhile (isRunning() && i < 5)  {\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\ti++;\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(\"The thread was interrupted while sleeping.\");\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 48.419430070226184}, {"code": "public void stop() {\n\t\tif (app != null) {\n\t\tapp.stop();\n\t\tint attempts = 0;\n\t\twhile (isRunning() && attempts < 5) {\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tattempts++;\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(\"Thread interrupted while waiting for app to stop.\");\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 50.69319147009328}, {"code": "public void stop() {\n\tif (isRunning())  {\ntry {\napp.stop();\n} catch (Exception e) {\nthrow new RuntimeException(e);\n}\nint count = 0;\nwhile (isRunning() && count < 5)  {\ntry {\nThread.sleep(1000);\n} catch (InterruptedException e) {\nthrow new IllegalStateException(\"Interrupted while waiting for app to stop.\");\n}\ncount++;\n}\nif (isRunning())  {\nthrow new IllegalStateException(\"Application failed to stop.\");\n}\napp = null;\n}\n}", "CodeBleu_score": 43.70013780186077}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner serverRunner = new EurekaServerRunner(config);\n\tserverRunner.enableTls();\n\tserverRunner.setKeyStore(keyStore);\n\tserverRunner.setTrustStore(trustStore);\n\tserverRunner.start();\n\treturn serverRunner;\n}", "CodeBleu_score": 40.3411700340253}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config);\n\trunner.enableTls(getKeystore(), getTruststore());\n\trunner.setKeyStore(getKeystore(), getKeystorePassword());\n\trunner.setTrustStore(getTruststore(), getTruststorePassword());\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 40.17601375681649}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\tEurekaServerConfig eurekaServerConfig = new EurekaServerConfig()", "CodeBleu_score": 10.329344111009908}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\treturn startService(server, config, \"testservice\");\n}", "CodeBleu_score": 19.036864529106122}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\trunner.enableTlsClient();\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 62.8496435850721}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\trunner.enableTlsClient();\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 62.8496435850721}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t\tKeyTool keyTool = new KeyTool();\n\tkeyTool.createCA();\n\tkeyTool.saveCert(keyTool.caCert);\n\tkeyTool.saveKeyAndCert(keyTool.caKey, keyTool.caCert);\n\n\tkeyTool.createCA();\n\tkeyTool.saveCert(keyTool.caCert2);\n\tkeyTool.saveKeyAndCert(keyTool.caKey2, keyTool.caCert2);\n\n\tkeyTool.createCert(keyTool.caCert, \"server\", \"127.0.0.1\", 8080);\n\tkeyTool.saveCert(keyTool.serverCert);\n\tkeyTool.saveKeyAndCert(keyTool.serverKey, keyTool.serverCert);\n\n\tkeyTool.createCert(keyTool.caCert, \"client\", \"127.0.0.1\", 8081);\n\tkeyTool.saveCert(keyTool.clientCert);\n\tkeyTool.saveKeyAndCert(keyTool.clientKey, keyTool.clientCert);\n\n\tkeyTool.createCert(keyTool.caCert2, \"client2\", \"127.0.0.1\", 8082);\n\tkeyTool.saveCert(keyTool.clientCert2);\n\tkeyTool.saveKeyAndCert(keyTool.clientKey2, keyTool.clientCert2);\n}", "CodeBleu_score": 21.692891227467054}, {"code": "static void createCertificates() throws Exception{\n\t\t// Create a CA\n\tKeyTool keyTool = new KeyTool();\n\tkeyTool.createCA(CA_NAME, CA_PASSWORD);\n\tkeyTool.saveCert(CA_NAME, CA_PASSWORD);\n\n\t// Create a server certificate and save it\n\tkeyTool.createServerCert(SERVER_NAME, SERVER_PASSWORD, CA_NAME, CA_PASSWORD);\n\tkeyTool.saveCert(SERVER_NAME, SERVER_PASSWORD);\n\n\t// Create a client certificate and save it\n\tkeyTool.createClientCert(CLIENT_NAME, CLIENT_PASSWORD, CA_NAME, CA_PASSWORD);\n\tkeyTool.saveCert(CLIENT_NAME, CLIENT_PASSWORD);\n\n\t// Create a second CA and client certificate pair\n\tkeyTool.createCA(SECOND_CA_NAME, SECOND_CA_PASSWORD);\n\tkeyTool.saveCert(SECOND_CA_NAME, SECOND_CA_PASSWORD);\n\tkeyTool.createClientCert(SECOND_CLIENT_NAME, SECOND_CLIENT_PASSWORD, SECOND_CA_NAME, SECOND_CA_PASSWORD);\n\tkeyTool.saveCert(SECOND_CLIENT_NAME, SECOND_CLIENT_PASSWORD);\n}", "CodeBleu_score": 17.857731718384183}, {"code": "static void createCertificates() throws Exception{\n\t\t// Create a CA certificate\n\tKeyTool caKeyTool = new KeyTool();\n\tcaKeyTool.createCA(\"CA\");\n\tcaKeyTool.saveCert(\"CA\");\n\tcaKeyTool.saveKeyAndCert(\"CA\");\n\n\t// Create a server certificate\n\tKeyTool serverKeyTool = new KeyTool();\n\tserverKeyTool.createCert(\"Server\", \"CA\");\n\tserverKeyTool.sign(\"Server\", \"CA\");\n\tserverKeyTool.saveCert(\"Server\");\n\tserverKeyTool.saveKeyAndCert(\"Server\");\n\n\t// Create a client certificate\n\tKeyTool clientKeyTool = new KeyTool();\n\tclientKeyTool.createCert(\"Client\", \"CA\");\n\tclientKeyTool.sign(\"Client\", \"CA\");\n\tclientKeyTool.saveCert(\"Client\");\n\tclientKeyTool.saveKeyAndCert(\"Client\");\n\n\t// Create a second CA certificate\n\tKeyTool ca2KeyTool = new KeyTool();\n\tca2KeyTool.createCA(\"CA2\");\n\tca2KeyTool.saveCert(\"CA2\");\n\tca2KeyTool.saveKeyAndCert(\"CA2\");\n\n\t// Create a second client certificate\n\tKeyTool client2KeyTool = new KeyTool();\n\tclient2KeyTool.createCert(\"Client2\", \"CA2\");\n\tclient2KeyTool.sign(\"Client2\", \"CA2\");\n\tclient2KeyTool.saveCert(\"Client2\");\n\tclient2KeyTool.saveKeyAndCert(\"Client2\");\n}", "CodeBleu_score": 25.31491966667621}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong limit = System.currentTimeMillis() + seconds * 1000;\n\twhile (!assertion.getAsBoolean()) {\n\t\tif (System.currentTimeMillis() > limit) {\n\t\t\tthrow new RuntimeException(\"Assertion failed\");\n\t\t}\n\t}\n}", "CodeBleu_score": 34.76434471552622}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong start = currentTimeMillis();\n\tlong limit = start + seconds * 1000;\n\twhile (!assertion.getAsBoolean()) {\n\t\tif (currentTimeMillis() > limit) {\n\t\t\tthrow new RuntimeException(\"Assertion failed after \" + seconds + \" seconds\");\n\t\t}\n\t}\n}", "CodeBleu_score": 36.2953440483224}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis();\n\tlong endTime = startTime + seconds * 1000;\n\twhile (System.currentTimeMillis() < endTime) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t}\n\tthrow new RuntimeException(\"Assertion did not pass in \" + seconds + \" seconds\");\n}", "CodeBleu_score": 47.26261161006803}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\t// Create a certificate builder using the public key and CA information.\n\tX509CertificateBuilder certBuilder = new X509CertificateBuilder();\n\tcertBuilder.setPublicKey(keyPair.getPublic());\n\tcertBuilder.setIssuer(ca);\n\n\t// Add key usage and basic constraints extensions to the certificate.\n\taddExtension(certBuilder, \"keyUsage\", \"digitalSignature, keyEncipherment\");\n\taddExtension(certBuilder, \"basicConstraints\", \"CA:FALSE\");\n\n\t// Sign the certificate with the private key.\n\treturn certBuilder.sign(keyPair.getPrivate());\n}", "CodeBleu_score": 33.30231103316097}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tX500Name issuerName = new X500Name(\"CN=Certificate Authority, O=Certificate Authority, C=US\");\n\tX500Name subjectName = new X500Name(\"CN=Certificate Authority, O=Certificate Authority, C=US\");\n\tInstant notBefore = Instant.now();\n\tInstant notAfter = notBefore.plus(Duration.ofDays(365));\n\tBigInteger serialNumber = new BigInteger(64, new SecureRandom());\n\tX509v3CertificateBuilder certBuilder = new X509v3CertificateBuilder(issuerName, serialNumber, notBefore, notAfter, subjectName, keyPair.getPublic());\n\tcertBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\tcertBuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.keyCertSign | KeyUsage.cRLSign));\n\tX509CertificateHolder certHolder = certBuilder.build(new JcaContentSignerBuilder(\"SHA256withRSA\").setProvider(\"BC\").build(keyPair.getPrivate()));\n\treturn new JcaX509CertificateConverter().setProvider(\"BC\").getCertificate(certHolder);\n}", "CodeBleu_score": 31.607664515027267}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\t// Construct a certificate builder with the public key and CA information\n\tX509CertificateBuilder certBuilder = new X509CertificateBuilder();\n\tcertBuilder.setPublicKey(keyPair.getPublic());\n\tcertBuilder.setIssuer(ca);\n\n\t// Add key usage and basic constraints extensions to the certificate\n\tcertBuilder.addExtension(new KeyUsageExtension(false, true, true, true, true, false, false, false));\n\tcertBuilder.addExtension(new BasicConstraintsExtension(false, 0));\n\n\t// Sign the certificate with the private key and return the signed X509 certificate\n\treturn certBuilder.sign(keyPair.getPrivate());\n}", "CodeBleu_score": 33.08765515125218}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\tField registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\t\tmakeAccessible(registrationClientField);\n\t\t\tregistrationClient = (EurekaHttpClient) registrationClientField.get(eurekaTransport);\n\t\t\teurekaHttpClient = (EurekaHttpClient) registrationClient;\n\t\t} catch (IllegalAccessException e) {\n\t\t\tlog.error(\"Cannot access eurekaHttpClient\", e);\n\t\t} catch (NoSuchFieldException e) {\n\t\t\tlog.error(\"Cannot access registrationClient\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 52.503191188537855}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient != null) {\n\t\treturn eurekaHttpClient;\n\t}\n\ttry {\n\t\tField registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\tmakeAccessible(registrationClientField);\n\t\tregistrationClient = registrationClientField.get(eurekaTransport);\n\t\tField eurekaHttpClientField = registrationClient.getClass().getDeclaredField(\"eurekaHttpClient\");\n\t\tmakeAccessible(eurekaHttpClientField);\n\t\teurekaHttpClient = eurekaHttpClientField.get(registrationClient);\n\t} catch (IllegalAccessException | NoSuchFieldException e) {\n\t\tlogger.error(\"Cannot access EurekaHttpClient\", e);\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 41.3963490620606}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient != null) {\n\t\treturn eurekaHttpClient;\n\t}\n\ttry {\n\t\tField registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\tregistrationClientField.setAccessible(true);\n\t\tregistrationClient = (RegistrationClient) registrationClientField.get(eurekaTransport);\n\t\tField eurekaHttpClientField = registrationClient.getClass().getDeclaredField(\"eurekaHttpClient\");\n\t\teurekaHttpClientField.setAccessible(true);\n\t\teurekaHttpClient = (EurekaHttpClient) eurekaHttpClientField.get(registrationClient);\n\t} catch (IllegalAccessException | NoSuchFieldException e) {\n\t\tlog.error(\"Error retrieving EurekaHttpClient\", e);\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 42.72322998504492}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<String>();\n\tList<Application> applications = getApplications();\n\tif (applications == null) {\n\t\treturn services;\n\t}\n\tfor (Application application : applications) {\n\t\tfor (InstanceInfo instance : application.getInstances()) {\n\t\t\tservices.add(instance.getAppName().toLowerCase());\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 47.31210459492723}, {"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<String>();\n\tList<Application> applications = getApplications();\n\tfor (Application application : applications) {\n\t\tList<InstanceInfo> instances = application.getInstances();\n\t\tfor (InstanceInfo instance : instances) {\n\t\t\tString name = instance.getAppName().toLowerCase();\n\t\t\tif (!services.contains(name)) {\n\t\t\t\tservices.add(name);\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 39.799434850590465}, {"code": "public List<String> getServices(){\n\tList<String> services = new ArrayList<>();\nList<Application> applications = getApplications();\nif (applications == null) {\nreturn services;\n}\nfor (Application application : applications) {\nfor (InstanceInfo instance : application.getInstances()) {\nString name = instance.getAppName().toLowerCase();\nif (!services.contains(name)) {\nservices.add(name);\n}\n}\n}\nreturn services;\n}", "CodeBleu_score": 45.50059398314007}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tHealthContributor value = entry.getValue();\n\t\tif (value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor compositeContributor = (DiscoveryCompositeHealthContributor) value;\n\t\t\tfor (HealthContributor indicator : compositeContributor.getIndicators()) {\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(entry.getKey(), indicator);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 43.64767407349182}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tif (healthContributors == null) {\n\t\treturn;\n\t}\n\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tHealthContributor value = entry.getValue();\n\t\tif (value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor composite = (DiscoveryCompositeHealthContributor) value;\n\t\t\tfor (Map.Entry<String, HealthIndicator> indicatorEntry : composite.getIndicators().entrySet()) {\n\t\t\t\tHealthIndicator indicator = indicatorEntry.getValue();\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(indicatorEntry.getKey(), indicator);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\thealthContributors.put(entry.getKey(), value);\n\t\t}\n\t}\n}", "CodeBleu_score": 41.01809386381577}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tif (healthContributors != null) {\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\t\tHealthContributor healthContributor = entry.getValue();\n\t\t\tif (healthContributor instanceof DiscoveryCompositeHealthContributor) {\n\t\t\t\tDiscoveryCompositeHealthContributor discoveryCompositeHealthContributor = (DiscoveryCompositeHealthContributor) healthContributor;\n\t\t\t\tfor (Map.Entry<String, HealthContributor> indicatorEntry : discoveryCompositeHealthContributor.getIndicators().entrySet()) {\n\t\t\t\t\tHealthContributor indicator = indicatorEntry.getValue();\n\t\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\t\thealthContributors.put(indicatorEntry.getKey(), indicator);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 40.16697676403441}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances.size() == 0) {\n\t\tthrow new RuntimeException(\"No instances found for 'provider-application'\");\n\t}\n\tString uri = instances.get(0).getUri();\n\tString response = restTemplate.postForObject(uri + \"/echo\", \"Hello from the Provider\", String.class);\n\treturn response;\n}", "CodeBleu_score": 53.11799347009183}, {"code": "public String hello(){\n\t\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances.size() == 0) {\n\t\tthrow new RuntimeException(\"No instances found for provider-application\");\n\t}\n\tString uri = instances.get(0).getUri();\n\tRestTemplate restTemplate = new RestTemplate();\n\treturn restTemplate.postForObject(uri + \"/echo\", \"Hello from Spring Cloud!\", String.class);\n}", "CodeBleu_score": 43.1767342683465}, {"code": "public String hello(){\n\t\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances.isEmpty()) {\n\t\tthrow new RuntimeException(\"No service instance found for 'provider-application'\");\n\t}\n\tURI uri = instances.get(0).getUri();\n\treturn restTemplate.postForObject(uri + \"/echo\", \"Hello\", String.class);\n}", "CodeBleu_score": 42.68286733285591}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t\tServiceInstance instance = loadBalancerClient.choose(\"provider-application\");\n\tif (instance == null) {\n\t\tthrow new RuntimeException(\"No provider application found\");\n\t}\n\tString url = String.format(\"http://%s:%s/echo\", instance.getHost(), instance.getPort());\n\tRestTemplate restTemplate = new RestTemplate();\n\treturn restTemplate.postForObject(url, \"Hello world\", String.class);\n}", "CodeBleu_score": 52.17714012979893}, {"code": "public String world(){\n\t\tString uri = null;\n\ttry {\n\t\tList<ServiceInstance> instances = this.loadBalancerClient.choose(\"provider-application\");\n\t\turi = instances.get(0).getUri() + \"/echo\";\n\t\treturn this.restTemplate.postForObject(uri, \"Hello, World!\", String.class);\n\t}\n\tcatch (Exception e) {\n\t\tthrow new RuntimeException(\"Could not access service at \" + uri, e);\n\t}\n}", "CodeBleu_score": 37.09610848127836}, {"code": "public String world(){\n\t\tServiceInstance instance = loadBalancerClient.choose(\"provider-application\");\n\tif (instance == null) {\n\t\tthrow new RuntimeException(\"No service instance found\");\n\t}\n\tString serviceUri = String.format(\"http://%s:%s\", instance.getHost(), instance.getPort());\n\tRestTemplate restTemplate = new RestTemplate();\n\treturn restTemplate.postForObject(serviceUri + \"/echo\", \"Hello World\", String.class);\n}", "CodeBleu_score": 55.63485405496036}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\tlog.info(\"Registration successful for \" + serviceName + \" with \" + ip + \":\" + port);\n\t\treturn true;\n\t} else {\n\t\tsynchronized (serverMap) {\n\t\t\tif (!serverMap.containsKey(serviceName)) {\n\t\t\t\tserverMap.put(serviceName, new HashSet<Server>());\n\t\t\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\t\t\tlog.info(\"Registration successful for \" + serviceName + \" with \" + ip + \":\" + port);\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 42.69023141939024}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (!serverMap.containsKey(serviceName)) {\n\t\tsynchronized (serverMap) {\n\t\t\tif (!serverMap.containsKey(serviceName)) {\n\t\t\t\tserverMap.put(serviceName, new HashSet<Server>());\n\t\t\t}\n\t\t}\n\t}\n\tserverMap.get(serviceName).add(new Server(ip, port));\n\tlogger.info(\"Registered service \" + serviceName + \" at \" + ip + \":\" + port);\n\treturn true;\n}", "CodeBleu_score": 47.50503505807813}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\tlog.info(\"Registered service \" + serviceName + \" at \" + ip + \":\" + port);\n\t\treturn true;\n\t}\n\telse {\n\t\tsynchronizedSet = new HashSet<Server>();\n\t\tsynchronizedSet.add(new Server(ip, port));\n\t\tserverMap.put(serviceName, synchronizedSet);\n\t\tlog.info(\"Registered service \" + serviceName + \" at \" + ip + \":\" + port);\n\t\treturn true;\n\t}\n}", "CodeBleu_score": 49.61335485875041}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\t// TODO: Your code here\n\treturn false;\n}", "CodeBleu_score": 15.915118860340804}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serviceName == null || ip == null || port == null) {\n\t\treturn false;\n\t}\n\n\tServer server = serverMap.get(serviceName);\n\n\tif (server != null) {\n\t\tserver.remove(ip, port);\n\t\tlogger.info(String.format(\"Deregistered server %s with ip %s and port %d\", serviceName, ip, port));\n\t\treturn true;\n\t}\n\n\treturn false;\n}", "CodeBleu_score": 47.3224015326699}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\t// TODO: Implement this method\n\t// Retrieve the serverMap from the registry\n\tMap<String, Set<Server>> serverMap = registry.get(\"serverMap\");\n\t// Retrieve the set of servers for the given service name\n\tSet<Server> serverSet = serverMap.get(serviceName);\n\t// Create a new Server object using the ip and port parameters\n\tServer server = new Server(ip, port);\n\t// Remove the Server object from the set\n\tserverSet.remove(server);\n\t// Log the deregistration action\n\tlogger.info(\"Deregistering server \" + server.toString() + \" from service \" + serviceName);\n\t// Return true upon successful deregistration\n\treturn true;\n}", "CodeBleu_score": 55.405248329726255}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n\tif (attributes != null) {\n\t\tMap<String, Object> defaultAttributes = (Map<String, Object>) attributes.get(\"defaultConfiguration\");\n\t\tif (defaultAttributes != null) {\n\t\t\tString name = (String) defaultAttributes.get(\"name\");\n\t\t\tif (StringUtils.hasText(name)) {\n\t\t\t\tBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(RibbonClientConfiguration.class);\n\t\t\t\tbuilder.addPropertyValue(\"name\", name);\n\t\t\t\tbuilder.addPropertyValue(\"configuration\", defaultAttributes);\n\t\t\t\tBeanDefinition beanDefinition = builder.getBeanDefinition();\n\t\t\t\tregistry.registerBeanDefinition(name, beanDefinition);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthrow new IllegalArgumentException(\"name is required\");\n\t\t\t}\n\t\t}\n\t\tMap<String, Object> clients = (Map<String, Object>) attributes.get(\"value\");\n\t\tif (clients != null) {\n\t\t\tfor (Map.Entry<String, Object> entry : clients.entrySet()) {\n\t\t\t\tString name = entry.getKey();\n\t\t\t\tMap<String, Object> configuration = (Map<String, Object>) entry.getValue();\n\t\t\t\tif (configuration != null) {\n\t\t\t\t\tBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(RibbonClientConfiguration.class);\n\t\t\t\t\tbuilder.addPropertyValue(\"name\", name);\n\t\t\t\t\tbuilder.addPropertyValue(\"configuration\", configuration);\n\t\t\t\t\tBeanDefinition beanDefinition = builder.getBeanDefinition();\n\t\t\t\t\tregistry.registerBeanDefinition(name, beanDefinition);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tthrow new IllegalArgumentException(\"configuration is required\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 41.4033881151536}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n\tif (attributes != null) {\n\t\tString[] value = (String[]) attributes.get(\"value\");\n\t\tString[] defaultConfiguration = (String[]) attributes.get(\"defaultConfiguration\");\n\t\tif (value.length > 0) {\n\t\t\tfor (String name : value) {\n\t\t\t\tregisterBeanDefinitions(name, registry);\n\t\t\t}\n\t\t}\n\t\tif (defaultConfiguration.length > 0) {\n\t\t\tregisterBeanDefinitions(defaultConfiguration[0], registry);\n\t\t}\n\t}\n}", "CodeBleu_score": 46.520671969091644}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n\tif (attributes != null) {\n\t\tMap<String, Object> defaultAttributes = (Map<String, Object>) attributes.get(\"defaultConfiguration\");\n\t\tif (defaultAttributes != null) {\n\t\t\tString name = (String) defaultAttributes.get(\"name\");\n\t\t\tif (StringUtils.hasText(name)) {\n\t\t\t\tBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(RibbonClientConfiguration.class);\n\t\t\t\tbuilder.addPropertyValue(\"name\", name);\n\t\t\t\tbuilder.addPropertyValue(\"configuration\", defaultAttributes);\n\t\t\t\tAbstractBeanDefinition definition = builder.getBeanDefinition();\n\t\t\t\tregistry.registerBeanDefinition(name, definition);\n\t\t\t}\n\t\t}\n\t\tMap<String, Object> clients = (Map<String, Object>) attributes.get(\"clients\");\n\t\tif (clients != null) {\n\t\t\tfor (Map.Entry<String, Object> entry : clients.entrySet()) {\n\t\t\t\tString name = entry.getKey();\n\t\t\t\tif (StringUtils.hasText(name)) {\n\t\t\t\t\tBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(RibbonClientConfiguration.class);\n\t\t\t\t\tbuilder.addPropertyValue(\"name\", name);\n\t\t\t\t\tbuilder.addPropertyValue(\"configuration\", entry.getValue());\n\t\t\t\t\tAbstractBeanDefinition definition = builder.getBeanDefinition();\n\t\t\t\t\tregistry.registerBeanDefinition(name, definition);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 42.08164422397809}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\tif (serviceId == null) {\n\t\tthrow new IllegalArgumentException(\"serviceId must not be null\");\n\t}\n\tif (request == null) {\n\t\tthrow new IllegalArgumentException(\"request must not be null\");\n\t}\n\treturn choose(serviceId, request.getContext());\n}", "CodeBleu_score": 25.04185702521579}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\t// TODO: implement this function\n\t// return null;\n}", "CodeBleu_score": 10.113816973284147}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\treturn choose(serviceId, request, null);\n}", "CodeBleu_score": 12.420362692234196}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\n}", "CodeBleu_score": 3.9894377123445492}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tif (server == null || original == null) {\n\t\tthrow new IllegalArgumentException(\"server and original must not be null\");\n\t}\n\n\tString originalScheme = original.getScheme();\n\tString originalHost = original.getHost();\n\tint originalPort = original.getPort();\n\tString originalPath = original.getPath();\n\tString originalQuery = original.getRawQuery();\n\n\tString scheme = originalScheme;\n\tString host = originalHost;\n\tint port = originalPort;\n\tString path = originalPath;\n\tString query = originalQuery;\n\n\tif (server.isSecure()) {\n\t\tscheme = \"https\";\n\t}\n\telse {\n\t\tscheme = \"http\";\n\t}\n\n\thost = server.getHost();\n\tport = server.getPort();\n\n\tif (port == 80 && scheme.equals(\"http\")) {\n\t\tport = -1;\n\t}\n\telse if (port == 443 && scheme.equals(\"https\")) {\n\t\tport = -1;\n\t}\n\n\tif (originalPath == null || originalPath.length() == 0) {\n\t\tpath = \"/\";\n\t}\n\n\tif (originalQuery != null && originalQuery.length() > 0) {\n\t\tquery = originalQuery;\n\t}\n\n\ttry {\n\t\treturn new URI(scheme, null, host, port, path, query, null);\n\t}\n\tcatch (URISyntaxException e) {\n\t\tthrow new RuntimeException(\"Failed to reconstruct URI for server \" + server.getServiceId() + \" and original URI \" + original, e);\n\t}\n}", "CodeBleu_score": 34.6811007554526}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tif (server == null) {\n\t\tthrow new IllegalArgumentException(\"server must not be null\");\n\t}\n\tif (original == null) {\n\t\tthrow new IllegalArgumentException(\"original must not be null\");\n\t}\n\tString originalUri = original.toString();\n\tint colonIndex = originalUri.indexOf(':');\n\tint slashIndex = originalUri.indexOf('/');\n\tString scheme = originalUri.substring(0, colonIndex);\n\tString host = server.getHost();\n\tint port = server.getPort();\n\tStringBuilder sb = new StringBuilder();\n\tsb.append(scheme).append(\"://\").append(host).append(\":\").append(port);\n\tif (slashIndex > 0) {\n\t\tsb.append(originalUri.substring(slashIndex));\n\t}\n\tString query = original.getRawQuery();\n\tif (query != null) {\n\t\tsb.append(\"?\").append(query);\n\t}\n\treturn URI.create(sb.toString());\n}", "CodeBleu_score": 42.72364750734797}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t\tList<TutuServer> servers = new ArrayList<TutuServer>();\n\tString serviceName = \"Tutu\";\n\tString serverAddr = getServerAddr();\n\tString url = serverAddr + \"/list?serviceName=\" + serviceName;\n\tString json = get(url);\n\tif (json != null) {\n\t\ttry {\n\t\t\tJSONArray array = (JSONArray) parseArray(json);\n\t\t\tfor (int i = 0; i < array.length(); i++) {\n\t\t\t\tJSONObject obj = (JSONObject) array.get(i);\n\t\t\t\tString ip = obj.getString(\"ip\");\n\t\t\t\tint port = obj.getInt(\"port\");\n\t\t\t\tservers.add(new TutuServer(ip, port));\n\t\t\t}\n\t\t} catch (JSONException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\treturn servers;\n}", "CodeBleu_score": 32.966719684176105}, {"code": "private List<TutuServer> getServer(){\n\t\t// Get the server address from the discovery service\n\tString serverAddr = getServerAddr();\n\n\t// Construct the URL string\n\tString url = serverAddr + \"/list\";\n\tif (serviceName != null) {\n\t\turl += \"?serviceName=\" + serviceName;\n\t}\n\n\t// Send the HTTP request\n\tString response = get(url);\n\n\t// Parse the response into a list of TutuServer objects\n\treturn parseArray(response, TutuServer.class);\n}", "CodeBleu_score": 14.532612946517617}, {"code": "private List<TutuServer> getServer(){\n\t\t// Construct a URL object from the server address, service name, and port\n\tString url = getServerAddr() + \"/\" + serviceName + \"/\" + port;\n\n\t// Construct a list of parameters\n\tList<NameValuePair> params = new ArrayList<NameValuePair>();\n\tparams.add(new BasicNameValuePair(\"serviceName\", serviceName));\n\tparams.add(new BasicNameValuePair(\"port\", port));\n\n\t// Construct a URL object from the server address and port\n\tURL obj = null;\n\ttry {\n\t\tobj = new URL(url);\n\t} catch (MalformedURLException e) {\n\t\te.printStackTrace();\n\t}\n\n\t// Create a new HTTP client\n\tHttpClient client = HttpClients.createDefault();\n\n\t// Send a request to the server and receive a response\n\ttry {\n\t\tHttpResponse response = client.execute(new HttpGet(obj));\n\n\t\t// If the response code is not 200, return an empty list\n\t\tif (response.getStatusLine().getStatusCode() != 200) {\n\t\t\treturn new ArrayList<TutuServer>();\n\t\t}\n\n\t\t// Get the response entity\n\t\tHttpEntity entity = response.getEntity();\n\n\t\t// If the response entity is null, return an empty list\n\t\tif (entity == null) {\n\t\t\treturn new ArrayList<TutuServer>();\n\t\t}\n\n\t\t// Parse the JSON array into a list of TutuServer objects\n\t\treturn parseArray(EntityUtils.toString(entity));\n\t} catch (ClientProtocolException e) {\n\t\te.printStackTrace();\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n\n\t// Return an empty list if there is an error\n\treturn new ArrayList<TutuServer>();\n}", "CodeBleu_score": 30.395115181469162}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t\tfor (Map.Entry<String, ZuulRoute> entry : routes.entrySet()) {\n\t\tString pattern = entry.getValue().getPath();\n\t\tif (pathMatcher.match(pattern, path)) {\n\t\t\tString targetPath = pathMatcher.extractPath(pattern, path);\n\t\t\treturn new Route(targetPath, entry.getValue().getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 45.33245136331002}, {"code": "public Route getMatchingRoute(String path){\n\t\tif (path == null) {\n\t\treturn null;\n\t}\n\tfor (Map.Entry<String, ZuulRoute> entry : this.routes.entrySet()) {\n\t\tString pattern = entry.getValue().getPath();\n\t\tif (this.pathMatcher.match(pattern, path)) {\n\t\t\tString routePath = path.substring(path.indexOf(pattern) + pattern.length());\n\t\t\treturn new Route(routePath, entry.getValue().getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 44.23584262481138}, {"code": "public Route getMatchingRoute(String path){\n\t\tif (path == null) {\n\t\treturn null;\n\t}\n\tfor (Route route : this.getRoutes()) {\n\t\tif (route.getLocation() == null) {\n\t\t\tcontinue;\n\t\t}\n\t\tString routePath = route.getLocation();\n\t\tif (routePath.startsWith(\"http:\") || routePath.startsWith(\"https:\") || routePath.startsWith(\"socket:\")) {\n\t\t\tcontinue;\n\t\t}\n\t\tif (routePath.startsWith(\"/\")) {\n\t\t\troutePath = routePath.substring(1);\n\t\t}\n\t\tif (routePath.endsWith(\"/\")) {\n\t\t\troutePath = routePath.substring(0, routePath.length() - 1);\n\t\t}\n\t\tif (this.pathMatcher.match(routePath, path)) {\n\t\t\tString targetPath = this.pathMatcher.extractPathWithinPattern(routePath, path);\n\t\t\tString serviceId = route.getServiceId();\n\t\t\treturn new Route(targetPath, serviceId);\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 37.26522310229267}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = importingClassMetadata.getAnnotationAttributes(FeignClient.class.getName());\n\tif (attributes == null) {\n\t\treturn;\n\t}\n\tString contextId = (String) attributes.get(\"contextId\");\n\tString type = (String) attributes.get(\"type\");\n\tClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(false, this.environment);\n\tscanner.addIncludeFilter(new AnnotationTypeFilter(FeignClient.class));\n\tSet<BeanDefinition> candidates = new LinkedHashSet<>();\n\tfor (BeanDefinition candidate : scanner.findCandidateComponents(attributes.get(\"basePackage\").toString())) {\n\t\tcandidates.add(candidate);\n\t}\n\tfor (BeanDefinition candidate : candidates) {\n\t\tBeanDefinitionBuilder definitionBuilder = BeanDefinitionBuilder.genericBeanDefinition(FeignClientFactoryBean.class);\n\t\tdefinitionBuilder.addPropertyValue(\"type\", type);\n\t\tdefinitionBuilder.addPropertyValue(\"contextId\", contextId);\n\t\tdefinitionBuilder.addPropertyValue(\"feignClass\", candidate.getBeanClassName());\n\t\tdefinitionBuilder.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);\n\t\tregistry.registerBeanDefinition(candidate.getBeanClassName(), definitionBuilder.getBeanDefinition());\n\t}\n}", "CodeBleu_score": 34.54176749946924}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = importingClassMetadata.getAnnotationAttributes(FeignClients.class.getName());\n\tif (attributes == null) {\n\t\treturn;\n\t}\n\tregisterBeanDefinitions(attributes, registry);\n}", "CodeBleu_score": 12.311667179681342}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> annotationAttributes = importingClassMetadata.getAnnotationAttributes(EnableFeignClients.class.getName());\n\tif (annotationAttributes != null) {\n\t\tregisterBeanDefinitions((String[]) annotationAttributes.get(\"value\"), registry);\n\t}\n\telse {\n\t\tregisterBeanDefinitions(null, registry);\n\t}\n}", "CodeBleu_score": 14.051630310827823}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}]}
