{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    loop_wait = self.loop_wait - 2\n    if loop_wait < 2:\n        loop_wait = 2\n    wait_time = loop_wait * 1000\n    return wait_time, self._orig_kazoo_connect(*args)\n\n", "CodeBleu_score": 48.291744353299414}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    return (max(2000, (self.loop_wait - 2) * 1000), self._orig_kazoo_connect(*args))\n\n", "CodeBleu_score": 47.50417975072767}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    # The following line calls the original method with any given arguments.\n    return_value = self._orig_kazoo_connect(*args)\n    # The following line calculates the wait time in milliseconds by subtracting 2 from the loop_wait attribute, ensuring it does not go below 2, and then multiplying by 1000.\n    wait_time = (self.loop_wait - 2) * 1000\n    # The following line returns a tuple. The tuple consists of the wait time in milliseconds and the second element of the original method's return value.\n    return wait_time, return_value[1]\n\n", "CodeBleu_score": 46.43604614622045}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if not isinstance(config, dict):\n        config = config.data\n\n    if 'retry_timeout' in config:\n        self.set_retry_timeout(config['retry_timeout'])\n\n    if 'loop_wait' in config:\n        self.set_loop_wait(config['loop_wait'])\n\n    if 'ttl' in config:\n        try:\n            self.set_ttl(config['ttl'])\n        except socket.error:\n            if self.loop_wait != config['loop_wait']:\n                self.close()\n\n", "CodeBleu_score": 34.97086103423144}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n\n    if isinstance(config, dict):\n        config = Config(config)\n\n    if self.retry_timeout != config.retry_timeout:\n        self.set_retry_timeout(config.retry_timeout)\n\n    if self.loop_wait_time != config.loop_wait_time:\n        if isinstance(self.handler, PatroniSequentialThreadingHandler):\n            self.handler.set_connect_timeout(config.loop_wait_time)\n        self.loop_wait_time = config.loop_wait_time\n\n    if self.ttl != config.ttl:\n        try:\n            self.set_ttl(config.ttl)\n        except socket.error:\n            if self.loop_wait_time != config.loop_wait_time:\n                self.close()\n            raise\n\n", "CodeBleu_score": 37.05493087326107}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n\n    if not isinstance(config, dict):\n        config = config.get_config_dict()\n    self.set_retry_timeout(config.get('retry_timeout', self.retry_timeout))\n    self.set_ttl(config.get('ttl', self.ttl))\n    if self.loop_wait_time != config.get('loop_wait', self.loop_wait_time):\n        self.loop_wait_time = config.get('loop_wait', self.loop_wait_time)\n        if isinstance(self.handler, PatroniSequentialThreadingHandler):\n            self.handler.set_connect_timeout(self.loop_wait_time)\n        try:\n            self.set_ttl(config.get('ttl', self.ttl))\n        except Exception:\n            self.close()\n            raise\n\n", "CodeBleu_score": 39.19046058963947}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n\n    # Check if the specified path is a valid cluster directory.\n    if not os.path.isdir(path):\n        raise ValueError(f\"{path} is not a valid directory.\")\n\n    # Check if the specified path contains a cluster configuration file.\n    if not os.path.isfile(os.path.join(path, \"postgresql.conf\")):\n        raise ValueError(f\"{path} does not contain a cluster configuration file.\")\n\n    # Check if the specified path contains a PostgreSQL cluster.\n    if not os.path.isfile(os.path.join(path, \"PG_VERSION\")):\n        raise ValueError(f\"{path} does not contain a PostgreSQL cluster.\")\n\n    # Check if the specified path contains a timeline history file.\n    if not os.path.isfile(os.path.join(path, \"timeline.history\")):\n        raise ValueError(f\"{path} does not contain a timeline history file.\")\n\n    # Check if the specified path contains a synchronization state file.\n    if not os.path.isfile(os.path.join(path, \"recovery.conf\")):\n        raise ValueError(f\"{path} does not contain a synchronization state file.\")\n\n    # Check if the specified path contains a members file.\n    if not os.path.isfile(os.path.join(path, \"members\")):\n        raise ValueError(f\"{path} does not contain a members file.\")\n\n    # Check if the specified path contains a leader PID file.\n    if not os.path.isfile(os.path.join(path, \"postmaster.pid\")):\n        raise ValueError(f\"{path} does not contain a leader PID file.\")\n\n    # Check if the specified path contains a status file.\n    if not os.path.isfile(os.path.join(path, \"status\")):\n        raise ValueError(f\"{path} does not contain a status file.\")\n\n    # Check if the specified path contains a failover file.\n    if not os.path.isfile(os.path.join(path, \"failover\")):\n        raise ValueError(f\"{path} does", "CodeBleu_score": 12.206516066327497}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    # Check if the path exists\n    if not os.path.exists(path):\n        raise FileNotFoundError(f\"Path {path} does not exist.\")\n\n    # Check if the path is a directory\n    if not os.path.isdir(path):\n        raise NotADirectoryError(f\"Path {path} is not a directory.\")\n\n    # Check if the path contains a cluster configuration file\n    if not os.path.isfile(os.path.join(path, \"postgresql.conf\")):\n        raise FileNotFoundError(f\"Path {path} does not contain a cluster configuration file.\")\n\n    # Check if the path contains a timeline history file\n    if not os.path.isfile(os.path.join(path, \"timeline.json\")):\n        raise FileNotFoundError(f\"Path {path} does not contain a timeline history file.\")\n\n    # Check if the path contains a synchronization state file\n    if not os.path.isfile(os.path.join(path, \"state.json\")):\n        raise FileNotFoundError(f\"Path {path} does not contain a synchronization state file.\")\n\n    # Check if the path contains a members file\n    if not os.path.isfile(os.path.join(path, \"members.json\")):\n        raise FileNotFoundError(f\"Path {path} does not contain a members file.\")\n\n    # Check if the path contains a leader file\n    if not os.path.isfile(os.path.join(path, \"leader.json\")):\n        raise FileNotFoundError(f\"Path {path} does not contain a leader file.\")\n\n    # Check if the path contains a cluster status file\n    if not os.path.isfile(os.path.join(path, \"status.json\")):\n        raise FileNotFoundError(f\"Path {path} does not contain a cluster status file.\")\n\n    # Check if the path contains a failover state file\n    if not os.path.isfile(os.path.join(path, \"failover.json\")):\n        raise FileNotFoundError(f\"Path {path} does not contain a failover state file.\")\n\n    # Check if the path contains a failsafe configuration", "CodeBleu_score": 12.71671785074946}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    # Check if the path exists and is a directory\n    if not os.path.isdir(path):\n        raise Exception(f\"The specified path {path} does not exist or is not a directory.\")\n\n    # Retrieve the initialization state\n    init_state = InitState.from_node(path)\n\n    # Retrieve the configuration\n    config = ClusterConfig.from_node(path)\n\n    # Retrieve the timeline history\n    timeline_history = TimelineHistory.from_node(path)\n\n    # Retrieve the synchronization state\n    sync_state = SyncState.from_node(path)\n\n    # Retrieve the members\n    members = self.load_members(path)\n\n    # Retrieve the leader information\n    leader = Leader.from_node(path)\n\n    # Retrieve the cluster status\n    status = self.get_status(path)\n\n    # Retrieve the failover state\n    failover = Failover.from_node(path)\n\n    # Retrieve the failsafe configuration\n    failsafe_config = FailsafeConfig.from_node(path)\n\n    # Return a Cluster object containing all the gathered information\n    return Cluster(\n        init_state,\n        config,\n        timeline_history,\n        sync_state,\n        members,\n        leader,\n        status,\n        failover,\n        failsafe_config,\n    )\n\n", "CodeBleu_score": 14.079243176148779}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    if self.zk_client is None:\n        self.zk_client = KazooClient(\n            hosts=self.zookeeper_hosts,\n            timeout=self.zookeeper_timeout,\n            logger=logger,\n        )\n        self.zk_client.start()\n    try:\n        self.zk_client.create(\n            self.zk_path,\n            ephemeral=True,\n            makepath=True,\n        )\n        return True\n    except KazooException as e:\n        if isinstance(e, (KazooConnectionLossError, KazooSessionExpiredError)):\n            raise ZooKeeperError(\n                f\"Failed to connect to ZooKeeper at {self.zookeeper_hosts} \"\n                \"within timeout {self.zookeeper_timeout}.\"\n            )\n        if isinstance(e, NodeExistsError):\n            logger.info(\n                \"Another instance of this service has the leader lock.\"\n            )\n            return False\n        logger.error(\n            \"Failed to acquire the leader lock. \"\n            f\"Exception: {e.__class__.__name__}: {e}\"\n        )\n        return False\n\n", "CodeBleu_score": 37.45137150759451}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.lock_path,\n                       makepath=True,\n                       ephemeral=True,\n                       sequence=True)\n    except (ConnectionClosedError, SessionExpiredError):\n        raise ZooKeeperError(\n            'ZooKeeper connection closed or session expired while attempting to acquire leader lock.'\n        )\n    except (ConnectionLossError, SessionTimeoutError):\n        logger.error('ZooKeeper connection lost while attempting to acquire leader lock.')\n        return False\n    except NodeExistsError:\n        logger.info('Leader lock already acquired.')\n        return False\n    except Exception as e:\n        logger.error('Unexpected error while attempting to acquire leader lock: %s', e)\n        return False\n\n    return True\n\n", "CodeBleu_score": 40.414416470199285}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.path, makepath=True)\n        return True\n    except (ZooKeeperError, ConnectionLoss) as e:\n        raise e\n    except Exception as e:\n        if isinstance(e, NodeExistsError):\n            logger.info(\"Another instance has the leader lock.\")\n            return False\n        else:\n            logger.error(f\"Could not acquire leader lock: {e}\")\n            return False\n\n", "CodeBleu_score": 42.138211712826475}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n\n    # Check if the current client ID matches the leader's session.\n    if leader.client_id != self.client_id:\n        # Log a warning.\n        self.logger.warning(\n            f\"The current client ID {self.client_id} does not match the leader's session {leader.client_id}. Attempting to delete the existing leader ZNode.\"\n        )\n\n        # Delete the existing leader ZNode.\n        try:\n            self.zk.delete(self.leader_path)\n        except NoNodeError:\n            # Ignore the error.\n            pass\n        except ConnectionClosedError:\n            # Raise a ZooKeeperError.\n            raise ZooKeeperError(\n                \"The connection to the ZooKeeper server has been closed.\"\n            )\n        except RetryFailedError:\n            # Raise a ZooKeeperError.\n            raise ZooKeeperError(\n                \"The maximum number of retries has been exceeded while attempting to delete the leader ZNode.\"\n            )\n        except Exception as e:\n            # Log the error.\n            self.logger.error(\n                f\"An unexpected error occurred while attempting to delete the leader ZNode: {e}\"\n            )\n\n        # Return False.\n        return False\n\n    # Try to create a new leader ZNode.\n    try:\n        # Create the leader ZNode with the current client's name encoded in UTF-8.\n        self.zk.create(\n            self.leader_path,\n            self.client_id.encode(\"utf-8\"),\n            acl=self.acl,\n            ephemeral=True,\n            sequence=True,\n        )\n    except NodeExistsError:\n        # Log the error.\n        self.logger.error(\n            f\"The leader ZNode already exists. This should not happen since the leader's session should have been deleted.\"\n        )\n    except ConnectionClosedError:\n        # Raise a ZooKeeperError.\n        raise ZooKeeperError(\n            \"The connection to the ZooKeeper server has been closed.\"\n        )\n    except RetryFailedError:\n       ", "CodeBleu_score": 38.478941713812844}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    # Check if the current client ID matches the leader's session.\n    if leader.client_id != self.client_id:\n        logger.warning(\n            \"Leader session does not match the current client ID. Deleting the leader ZNode.\"\n        )\n\n        # Delete the existing leader ZNode.\n        try:\n            self.delete(leader.znode_path)\n        except NoNodeError:\n            # The leader ZNode has already been deleted.\n            pass\n        except ConnectionClosedError:\n            # The connection has been closed.\n            pass\n        except RetryFailedError:\n            # Retry failed.\n            raise ZooKeeperError(\n                \"Failed to delete the leader ZNode. Retry failed.\"\n            ) from None\n        else:\n            # Delete successful.\n            pass\n\n        # Create a new leader ZNode.\n        try:\n            self.create(\n                leader.znode_path,\n                encode(leader.client_id),\n                acl=leader.acl,\n                ephemeral=True,\n            )\n        except ConnectionClosedError:\n            # The connection has been closed.\n            pass\n        except RetryFailedError:\n            # Retry failed.\n            raise ZooKeeperError(\n                \"Failed to create a new leader ZNode. Retry failed.\"\n            ) from None\n        except Exception:\n            # Other errors.\n            logger.error(\n                \"Failed to create a new leader ZNode. Error: %s\",\n                traceback.format_exc(),\n            )\n        else:\n            # Creation successful.\n            return True\n    else:\n        # The current client ID matches the leader's session.\n        return True\n\n    # Creation failed.\n    return False\n\n", "CodeBleu_score": 35.71184399481653}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.session_id != self.client_id:\n        self.logger.warning(\n            \"Leader's session id does not match the current client id.\"\n        )\n        try:\n            self.zk.delete(leader.path)\n        except (\n            NoNodeError,\n            ConnectionClosedError,\n            RetryFailedError,\n        ) as e:\n            self.logger.error(\n                \"Could not delete leader ZNode. Error: {}\".format(e)\n            )\n            return False\n\n    try:\n        self.zk.create(\n            self.leader_path,\n            self.client_id.encode(),\n            acl=self.acl,\n            ephemeral=True,\n        )\n    except (\n        NoNodeError,\n        ConnectionClosedError,\n        RetryFailedError,\n    ) as e:\n        self.logger.error(\n            \"Could not create leader ZNode. Error: {}\".format(e)\n        )\n        return False\n\n    return True\n\n", "CodeBleu_score": 41.472320725056576}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    if time.time() - self._last_poll_time > self._poll_interval:\n        exhibitors = self._query_exhibitors()\n        if exhibitors:\n            exhibitors_sorted = sorted(exhibitors)\n            exhibitors_joined = \",\".join(exhibitors_sorted)\n            if self._exhibitors != exhibitors_sorted:\n                self._exhibitors = exhibitors_sorted\n                self._exhibitors_joined = exhibitors_joined\n                self._exhibitors_changed = True\n                logger.info(\"Exhibitors changed: %s\", exhibitors_joined)\n            else:\n                self._exhibitors_changed = False\n            return True\n    return False\n\n", "CodeBleu_score": 30.090145816681336}, {"code": "def poll(self) -> bool\n\t\n    if time.time() - self._last_poll_time < self._poll_interval:\n        return False\n\n    self._last_poll_time = time.time()\n\n    exhibitors = self._query_exhibitors()\n    if not exhibitors:\n        return False\n\n    exhibitors = sorted(exhibitors, key=lambda x: x.get(\"server\", \"\"))\n    exhibitors = sorted(exhibitors, key=lambda x: x.get(\"port\", 0))\n\n    exhibitors_str = \", \".join(\n        [\n            \"%s:%s\" % (exhibitor.get(\"server\", \"\"), exhibitor.get(\"port\", 0))\n            for exhibitor in exhibitors\n        ]\n    )\n\n    if exhibitors_str != self._exhibitors_str:\n        self._exhibitors_str = exhibitors_str\n        self._zk_hosts = \",\".join(\n            [\n                \"%s:%s\" % (exhibitor.get(\"server\", \"\"), exhibitor.get(\"port\", 0))\n                for exhibitor in exhibitors\n            ]\n        )\n\n        logger.info(\"Updating ZooKeeper hosts to %s\", self._zk_hosts)\n\n        return True\n\n    return False\n\n", "CodeBleu_score": 37.55513344575022}, {"code": "def poll(self) -> bool\n\t\n    logger.info('Polling for exhibitors')\n    exhibitors = self._query_exhibitors()\n    if not exhibitors:\n        return False\n    exhibitors = sorted(exhibitors)\n    if self._exhibitors == exhibitors:\n        return False\n    self._exhibitors = exhibitors\n    self._last_poll = time.time()\n    self._update_zookeeper_connection_string(exhibitors)\n    return True\n\n", "CodeBleu_score": 21.257690016303183}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider:\n        self.hosts = self._ensemble_provider.hosts\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 59.21014363992274}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    # Load the cluster configuration\n    cluster = loader(path)\n\n    # If the cluster is a dictionary, then we need to update the hosts\n    if isinstance(cluster, dict):\n        # Update the hosts for each cluster\n        for cluster_id, cluster_config in cluster.items():\n            # Update the hosts for the cluster\n            self._update_hosts(cluster_config)\n\n    # Otherwise, we just need to update the hosts\n    else:\n        # Update the hosts for the cluster\n        self._update_hosts(cluster)\n\n    # Return the cluster\n    return cluster\n\n", "CodeBleu_score": 50.07515336653272}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self.ensemble_provider is not None:\n        hosts = self.ensemble_provider.get_hosts()\n        if hosts is not None:\n            self.hosts = hosts\n    return super(self.__class__, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 58.47064259604144}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 81.45633845775137}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t    if (zookeeperListener == null) {\n        return;\n    }\n    String group = getGroup();\n    String dataId = getDataId();\n    logUnsubscribeStarted(group, dataId);\n    try {\n        zookeeperListener.unsubscribe(group, dataId);\n        logUnsubscribeSucceed(group, dataId);\n    } catch (NacosException e) {\n        logUnsubscribeFailed(group, dataId, e);\n    }\n}", "CodeBleu_score": 74.71368533514422}, {"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = getGroup();\n\tString dataId = getDataId();\n\tlogUnsubscribeStarted(group, dataId);\n\ttry {\n\t\tzookeeperListener.unsubscribe(group, dataId);\n\t\tlogUnsubscribeSucceeded(group, dataId);\n\t} catch (NacosException e) {\n\t\tlogUnsubscribeFailed(group, dataId, e);\n\t}\n}", "CodeBleu_score": 71.84659151836279}, {"code": "public void destroy(){\n\t    if (zookeeperListener == null) {\n        return;\n    }\n    String group = getGroup();\n    String dataId = getDataId();\n    logUnsubscribeStarted(group, dataId);\n    try {\n        zookeeperListener.unsubscribe(group, dataId);\n    } catch (NacosException e) {\n        logUnsubscribeFailed(group, dataId, e);\n    }\n}", "CodeBleu_score": 77.3118588300971}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zkServer = (ZookeeperServer) server;\n        return zkServer.getPayload();\n    } else {\n        return new HashMap<String, String>();\n    }\n}", "CodeBleu_score": 59.66391396016807}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t    Map<String, String> metadata = new HashMap<String, String>();\n\n    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zkServer = (ZookeeperServer) server;\n        String payload = zkServer.getPayload();\n        if (payload != null) {\n            String[] parts = payload.split(\";\");\n            for (String part : parts) {\n                String[] kv = part.split(\":\");\n                if (kv.length == 2) {\n                    metadata.put(kv[0], kv[1]);\n                }\n            }\n        }\n    }\n\n    return metadata;\n}", "CodeBleu_score": 46.894751410705744}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t  Map<String, String> metadata = new HashMap<>();\n  if (server instanceof ZookeeperServer) {\n    ZookeeperServer zkServer = (ZookeeperServer) server;\n    String payload = zkServer.getPayload();\n    if (payload != null) {\n      String[] parts = payload.split(\"\\\\|\");\n      if (parts.length > 1) {\n        metadata.put(\"zk_version\", parts[0]);\n        metadata.put(\"zk_config_version\", parts[1]);\n      }\n    }\n  }\n  return metadata;\n}", "CodeBleu_score": 46.48199736246509}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t    String path = ZKPaths.makePath(ZKPaths.makePath(ZKPaths.makePath(root, group), serviceId), CONFIG_NODE_NAME);\n    NodeCache nodeCache = new NodeCache(client, path, false);\n    NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception {\n            if (nodeCache.getCurrentData() != null) {\n                String config = new String(nodeCache.getCurrentData().getData());\n                if (config != null && !config.isEmpty()) {\n                    try {\n                        zookeeperSubscribeCallback.callback(convertConfig(config));\n                    } catch (Exception e) {\n                        logger.error(\"Error converting config\", e);\n                    }\n                }\n            }\n        }\n    };\n    nodeCache.getListenable().addListener(nodeCacheListener);\n    nodeCache.start();\n    ZookeeperListener zookeeperListener = new ZookeeperListener(client, path, nodeCache, nodeCacheListener);\n    zookeeperListener.addListener();\n    return zookeeperListener;\n}", "CodeBleu_score": 56.00648275367477}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t    String path = ZookeeperPathUtils.getGroupServiceConfigPath(group, serviceId);\n    NodeCache nodeCache = new NodeCache(client, path);\n    nodeCache.getListenable().addListener(new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception {\n            try {\n                String config = new String(nodeCache.getCurrentData().getData(), \"UTF-8\");\n                // \u5c06\u914d\u7f6e\u8f6c\u6362\u4e3a\u5bf9\u8c61\n                Config configObj = convertConfig(config);\n                zookeeperSubscribeCallback.callback(configObj);\n            } catch (Exception e) {\n                logger.error(\"[subscribeConfig]\", e);\n            }\n        }\n    });\n    nodeCache.start();\n    ZookeeperListener zookeeperListener = new ZookeeperListener();\n    zookeeperListener.setNodeCache(nodeCache);\n    zookeeperListener.setZookeeperSubscribeCallback(zookeeperSubscribeCallback);\n    return zookeeperListener;\n}", "CodeBleu_score": 59.969248917536646}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t    String path = getPath(group, serviceId);\n    NodeCache nodeCache = new NodeCache(zkClient, path);\n    NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception {\n            try {\n                byte[] data = nodeCache.getCurrentData().getData();\n                String config = new String(data, \"UTF-8\");\n                convertConfig(group, serviceId, config, zookeeperSubscribeCallback);\n            } catch (Exception e) {\n                log.error(\"nodeChanged\", e);\n            }\n        }\n    };\n    nodeCache.getListenable().addListener(nodeCacheListener);\n    nodeCache.start();\n    ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n    zookeeperListeners.put(group + \":\" + serviceId, zookeeperListener);\n    return zookeeperListener;\n}", "CodeBleu_score": 66.75309909871336}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    ZookeeperServerList serverList = new ZookeeperServerList(serviceDiscovery);\n    serverList.initWithNiwsConfig(config);\n    serverList.setLoadBalanceListenerExecutor(config.getLoadBalancerRequestExecutorService());\n    serverList.setServiceId(getClientName(config));\n    return serverList;\n}", "CodeBleu_score": 66.31978250690861}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    RibbonServerList serverList = new RibbonServerList(serviceDiscovery);\n    serverList.initWithNiwsConfig(config);\n    serverList.setLoadBalanceListenerExecutor(config.get(CommonClientConfigKey.LoadBalancerExecutor));\n    serverList.setServiceId(getClientName(config));\n    return serverList;\n}", "CodeBleu_score": 60.03070829183097}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    ZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery);\n    serverList.initWithNiwsConfig(config);\n    serverList.setLoadBalanceListenerExecutor(config.getClientName());\n    serverList.setServiceId(getClientName(config));\n    return serverList;\n}", "CodeBleu_score": 78.93435977787048}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor executor = (RegisterListenerExecutor) this.applicationContext.getBean(\"registerListenerExecutor\");\n\t\texecutor.onRegister(registration);\n\t}\n\tcatch (BeansException ex) {\n\t\tlogger.warn(\"No RegisterListenerExecutor bean found in application context.  Skipping registration listener execution.\");\n\t}\n\tfinally {\n\t\tthis.serviceRegistry.register(registration);\n\t}\n}", "CodeBleu_score": 49.41913517048416}, {"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        if (logger.isDebugEnabled()) {\n            logger.debug(\"Registering: \" + registration.getServiceId());\n        }\n        RegisterListenerExecutor executor = (RegisterListenerExecutor) applicationContext.getBean(RegisterListenerExecutor.class);\n        executor.onRegister(registration);\n    } catch (BeansException e) {\n        logger.warn(\"No RegisterListenerExecutor bean found in application context.  Service will be registered without invoking the RegisterListenerExecutor.onRegister method.\");\n    }\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 57.24686971638591}, {"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onRegister(registration);\n    } catch (BeansException e) {\n        // ignore\n    }\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 91.46133830544045}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = (RegisterListenerExecutor) applicationContext.getBean(\"registerListenerExecutor\");\n        registerListenerExecutor.onDeregister(registration);\n    } catch (BeansException e) {\n        logger.info(\"No RegisterListenerExecutor bean found in application context\");\n    }\n    serviceRegistry.remove(registration);\n}", "CodeBleu_score": 66.77579835808211}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor executor = (RegisterListenerExecutor) applicationContext.getBean(RegisterListenerExecutor.class);\n        executor.onDeregister(registration);\n    } catch (BeansException e) {\n        // ignore\n    }\n    serviceRegistry.remove(registration);\n}", "CodeBleu_score": 68.52362949631902}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = (RegisterListenerExecutor) applicationContext.getBean(\"registerListenerExecutor\");\n        registerListenerExecutor.onDeregister(registration);\n    } catch (BeansException e) {\n        LOG.debug(\"No RegisterListenerExecutor found in application context\");\n    }\n    serviceRegistry.remove(registration);\n}", "CodeBleu_score": 67.13099056738841}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\t    try {\n        RegisterListenerExecutor rle = (RegisterListenerExecutor)\n            getBean(\"RegisterListenerExecutor\");\n        rle.onClose();\n    } catch (BeansException be) {\n        logger.warn(\"Could not retrieve RegisterListenerExecutor bean\", be);\n    } finally {\n        serviceRegistry.close();\n    }\n}", "CodeBleu_score": 50.83510597281068}, {"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor executor = getBean(RegisterListenerExecutor.class);\n\t\texecutor.onClose();\n\t}\n\tcatch (BeansException ex) {\n\t\tlogger.debug(\"Could not retrieve RegisterListenerExecutor bean\", ex);\n\t}\n\tfinally {\n\t\ttry {\n\t\t\tthis.serviceRegistry.close();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tlogger.error(\"Error closing ServiceRegistry\", ex);\n\t\t}\n\t}\n}", "CodeBleu_score": 48.31922399623302}, {"code": "public void close(){\n\t\tif (logger.isDebugEnabled()) {\n\t\tlogger.debug(\"Closing \" + this);\n\t}\n\ttry {\n\t\tif (beanFactory != null) {\n\t\t\tObject listener = beanFactory.getBean(listenerBeanName);\n\t\t\tif (listener instanceof RegisterListenerExecutor) {\n\t\t\t\t((RegisterListenerExecutor) listener).onClose();\n\t\t\t}\n\t\t}\n\t}\n\tcatch (BeansException ex) {\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Ignoring BeansException on close\", ex);\n\t\t}\n\t}\n\tfinally {\n\t\tif (serviceRegistry != null) {\n\t\t\tserviceRegistry.close();\n\t\t}\n\t}\n}", "CodeBleu_score": 42.56410328718423}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = null;\n    String dataId = null;\n\n    if (globalConfig) {\n        group = this.getGlobalConfig().getGroup();\n        dataId = this.getGlobalConfig().getDataId();\n    } else {\n        group = this.getConfig().getGroup();\n        dataId = this.getConfig().getDataId();\n    }\n\n    String key = group + \".\" + dataId;\n\n    logger.info(\"Subscribing to configuration for \" + key);\n\n    ZookeeperListener listener = null;\n\n    try {\n        listener = zookeeperOperation.subscribe(group, dataId, new ZookeeperListener() {\n            @Override\n            public void process(WatchedEvent watchedEvent) {\n                logger.info(\"Configuration update received for \" + key);\n                callbackConfig(globalConfig);\n            }\n        });\n    } catch (Exception e) {\n        logger.error(\"Exception subscribing to configuration for \" + key, e);\n    }\n\n    return listener;\n}", "CodeBleu_score": 43.5607589695761}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = getGroup();\n    String dataId = getDataId();\n    logger.info(\"subscribeConfig group: {}, dataId: {}\", group, dataId);\n\n    // \u521b\u5efaZookeeperListener\uff0c\u5e76\u6ce8\u518c\u56de\u8c03\u51fd\u6570\n    ZookeeperListener listener = new ZookeeperListener(dataId, group, this);\n    try {\n        // \u5c1d\u8bd5\u8ba2\u9605\u914d\u7f6e\n        zookeeperOperation.subscribeConfig(dataId, group, listener);\n    } catch (NacosException e) {\n        logger.error(\"[subscribe-error] {}\", e);\n        return null;\n    }\n\n    // \u521b\u5efa\u56de\u8c03\u51fd\u6570\n    listener.setListener(new Listener() {\n        @Override\n        public void receiveConfigInfo(String configInfo) {\n            // \u56de\u8c03\u51fd\u6570\uff0c\u5904\u7406\u914d\u7f6e\u66f4\u65b0\n            receiveConfigInfo(configInfo, globalConfig);\n        }\n    });\n\n    return listener;\n}", "CodeBleu_score": 51.89580846602271}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = null;\n    String dataId = null;\n    try {\n        if (globalConfig) {\n            group = getGlobalConfig().getGroup();\n            dataId = getGlobalConfig().getDataId();\n        } else {\n            group = getConfig().getGroup();\n            dataId = getConfig().getDataId();\n        }\n        if (group == null || group.isEmpty()) {\n            LOGGER.warn(\"Unable to subscribe to configuration. Group is null or empty.\");\n            return null;\n        }\n        if (dataId == null || dataId.isEmpty()) {\n            LOGGER.warn(\"Unable to subscribe to configuration. DataId is null or empty.\");\n            return null;\n        }\n        LOGGER.info(\"Subscribing to configuration: \" + group + \":\" + dataId);\n        ZookeeperListener listener = zookeeperOperation.subscribe(group, dataId, callbackConfig);\n        return listener;\n    } catch (Exception e) {\n        LOGGER.error(\"Unable to subscribe to configuration: \" + group + \":\" + dataId, e);\n        return null;\n    }\n}", "CodeBleu_score": 33.265305728716726}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t    if (isEmpty(connectString)) {\n        throw new DiscoveryException(\"Zookeeper connection string is empty.\");\n    }\n    RetryPolicy retryPolicy = new ExponentialBackoffRetry(retryCount, sleepTime);\n    CuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n            .connectString(connectString)\n            .retryPolicy(retryPolicy)\n            .build();\n    curatorFramework.start();\n    return curatorFramework;\n}", "CodeBleu_score": 27.147076477897723}, {"code": "public CuratorFramework curatorFramework(){\n\t\tString connectString = getProperty(ZOOKEEPER_CONNECT_STRING);\n\tif (isEmpty(connectString)) {\n\t\tthrow new DiscoveryException(\"Zookeeper connection string is empty.\");\n\t}\n\tint retryCount = Integer.parseInt(getProperty(ZOOKEEPER_RETRY_COUNT, \"3\"));\n\tint retrySleepTime = Integer.parseInt(getProperty(ZOOKEEPER_RETRY_SLEEP_TIME, \"1000\"));\n\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(retrySleepTime, retryCount);\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(connectString)\n\t\t\t.retryPolicy(retryPolicy)\n\t\t\t.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 44.08634036290607}, {"code": "public CuratorFramework curatorFramework(){\n\t    String connectString = getProperty(ZOOKEEPER_CONNECTION_STRING);\n    if (isEmpty(connectString)) {\n        throw new DiscoveryException(\"Zookeeper connection string is empty.\");\n    }\n    CuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder();\n    builder.connectString(connectString);\n    builder.retryPolicy(new ExponentialBackoffRetry(getProperty(ZOOKEEPER_RETRY_COUNT), getProperty(ZOOKEEPER_SLEEP_TIME)));\n    CuratorFramework curatorFramework = builder.build();\n    curatorFramework.start();\n    return curatorFramework;\n}", "CodeBleu_score": 29.29549700911655}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n\t/**\n\t * The bean method returns a new instance of GatewayStrategyRouteZookeeperProcessor.\n\t *\n\t * @return a new instance of GatewayStrategyRouteZookeeperProcessor\n\t */\n\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n\n\t/**\n\t * The bean method returns a new instance of GatewayStrategyRouteZookeeperLocator.\n\t *\n\t * @return a new instance of GatewayStrategyRouteZookeeperLocator\n\t */\n\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperLocator gatewayStrategyRouteZookeeperLocator() {\n\t\treturn new GatewayStrategyRouteZookeeperLocator();\n\t}\n\n\t/**\n\t * The bean method returns a new instance of GatewayStrategyRouteZookeeperRouteDefinitionLocator.\n\t *\n\t * @return a new instance of GatewayStrategyRouteZookeeperRouteDefinitionLocator\n\t */\n\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperRouteDefinitionLocator gatewayStrategyRouteZookeeperRouteDefinitionLocator() {\n\t\treturn new GatewayStrategyRouteZookeeperRouteDefinitionLocator();\n\t}\n\n\t/**\n\t * The bean method returns a new instance of GatewayStrategyRouteZookeeperRouteLocator.\n\t *\n\t * @return a new instance of GatewayStrategyRouteZookeeperRouteLocator\n\t */\n\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperRouteLocator gateway", "CodeBleu_score": 34.051085616737694}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n\t@Bean\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n\n}", "CodeBleu_score": 64.91734404115697}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n\t/**\n\t * The bean method that returns a new instance of GatewayStrategyRouteZookeeperProcessor.\n\t * @return\n\t */\n\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n\n}", "CodeBleu_score": 68.48906389591397}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t  java.util.Properties props = new java.util.Properties()\n  props.put(org.apache.curator.framework.imps.Constants.ZOOKEEPER_SASL_CLIENT, \"true\")\n  props.put(org.apache.curator.framework.imps.Constants.ZOOKEEPER_SESSION_TIMEOUT, sessionTimeoutMs)\n  props.put(org.apache.curator.framework.imps.Constants.ZOOKEEPER_CONNECTION_TIMEOUT, sessionTimeoutMs)\n  props.put(org.apache.curator.framework.imps.Constants.ZOOKEEPER_CONNECTION_STRING, connectString)\n  props.put(org.apache.curator.framework.imps.Constants.ZOOKEEPER_NAMESPACE, namespace)\n  org.apache.curator.framework.CuratorFrameworkFactory.builder()\n    .namespace(namespace)\n    .connectString(connectString)\n    .retryPolicy(retryPolicy)\n    .sessionTimeoutMs(sessionTimeoutMs)\n    .connectionTimeoutMs(sessionTimeoutMs)\n    .canBeReadOnly(true)\n    .build()\n}", "CodeBleu_score": 34.18847725108136}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t  synchronized (this) {\n    if (curatorFramework != null) {\n      return curatorFramework\n    }\n    val client = CuratorFrameworkFactory.builder()\n      .connectString(getZkHosts)\n      .sessionTimeoutMs(sessionTimeoutMs)\n      .retryPolicy(retryPolicy)\n      .namespace(namespace)\n      .build()\n    client.start()\n    curatorFramework = client\n    return curatorFramework\n  }\n}", "CodeBleu_score": 41.356552149086646}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t  java.lang.String namespace = getNamespace ()  ;\n  org.apache.curator.RetryPolicy retryPolicy = getRetryPolicy ()  ;\n  org.apache.curator.framework.CuratorFramework framework = org.apache.curator.framework.CuratorFrameworkFactory.builder ().namespace (namespace).retryPolicy (retryPolicy).connectString (getZkHosts ()).sessionTimeoutMs (getSessionTimeout ()).build ()  ;\n  framework.start () ;\n  return framework ;\n}", "CodeBleu_score": 41.864644168098216}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\t    InterProcessMutex lock = locksMap.get(path);\n    if (lock == null) {\n        try {\n            lock = new InterProcessMutex(getZkClient(), path);\n            lock.acquire();\n            locksMap.put(path, lock);\n        } catch (Exception e) {\n            throw new DistributedLockException(\"Error acquiring lock for path: \" + path, e);\n        }\n    } else {\n        try {\n            lock.acquire();\n        } catch (Exception e) {\n            throw new DistributedLockException(\"Error re-acquiring lock for path: \" + path, e);\n        }\n    }\n}", "CodeBleu_score": 43.41480976687247}, {"code": "public void lock(String path) throws DistributedLockException{\n\t    if (locksMap.containsKey(path)) {\n        InterProcessMutex lock = locksMap.get(path);\n        try {\n            lock.acquire();\n        } catch (Exception e) {\n            throw new DistributedLockException(\"Error acquiring lock for path: \" + path, e);\n        }\n    } else {\n        try {\n            InterProcessMutex lock = new InterProcessMutex(zkClient, path);\n            lock.acquire();\n            locksMap.put(path, lock);\n        } catch (Exception e) {\n            throw new DistributedLockException(\"Error acquiring lock for path: \" + path, e);\n        }\n    }\n}", "CodeBleu_score": 38.66164475688703}, {"code": "public void lock(String path) throws DistributedLockException{\n\t  if (locksMap.containsKey(path)) {\n    InterProcessMutex lock = locksMap.get(path);\n    try {\n      lock.acquire();\n    } catch (Exception e) {\n      throw new DistributedLockException(e);\n    }\n  } else {\n    InterProcessMutex lock = new InterProcessMutex(getZkClient(), path);\n    try {\n      lock.acquire();\n      locksMap.put(path, lock);\n    } catch (Exception e) {\n      throw new DistributedLockException(e);\n    }\n  }\n}", "CodeBleu_score": 33.32868144515033}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    // 1. \u83b7\u53d6curatorFramework\n    CuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n    // 2. \u83b7\u53d6zookeeper\n    String zookeeper = getZookeeper(dtpProperties);\n    // 3. \u83b7\u53d6\u503c\n    String value = getValue(curatorFramework, dtpProperties);\n    // 4. \u83b7\u53d6\u914d\u7f6e\u7c7b\u578b\n    String configType = dtpProperties.getConfigType();\n    // 5. \u5224\u65ad\u914d\u7f6e\u7c7b\u578b\n    if (configType.equalsIgnoreCase(ConfigConstant.PROPERTIES)) {\n        // 5.1 \u5982\u679c\u662fproperties\uff0c\u5219\u751f\u6210properties\u7c7b\u578b\u7684map\n        return genPropertiesTypeMap(value);\n    } else if (configType.equalsIgnoreCase(ConfigConstant.JSON)) {\n        // 5.2 \u5982\u679c\u662fjson\uff0c\u5219\u6784\u9020\u8282\u70b9\u8def\u5f84\uff0c\u83b7\u53d6\u503c\uff0c\u5e76\u89e3\u6790\u4e3amap\n        String configKey = dtpProperties.getConfigKey();\n        return parseConfig(curatorFramework, zookeeper, configKey, value);\n    }\n    // 6. \u8fd4\u56de\u7a7amap\n    return newHashMap();\n}", "CodeBleu_score": 40.49265788423851}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    CuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n    String nodePath = getZookeeper(dtpProperties);\n    String value = getValue(curatorFramework, nodePath);\n    Map<Object, Object> propertiesMap = newHashMap();\n    if (dtpProperties.getConfigType().equalsIgnoreCase(ConfigType.PROPERTIES.getType())) {\n        propertiesMap = genPropertiesTypeMap(value);\n    } else if (dtpProperties.getConfigType().equalsIgnoreCase(ConfigType.JSON.getType())) {\n        String configKey = getConfigKey(dtpProperties);\n        String val = getVal(value, configKey);\n        propertiesMap = ConfigHandler.getInstance().parseConfig(val, dtpProperties.getConfigType());\n    }\n    return propertiesMap;\n}", "CodeBleu_score": 55.47583335508095}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    CuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n    String nodePath = getZookeeper(dtpProperties);\n    String value = getValue(curatorFramework, nodePath);\n    Map<Object, Object> propertiesMap = newHashMap();\n    if (dtpProperties.getConfigType().equalsIgnoreCase(DtpProperties.CONFIG_TYPE_PROPERTIES)) {\n        propertiesMap = genPropertiesTypeMap(value);\n    } else if (dtpProperties.getConfigType().equalsIgnoreCase(DtpProperties.CONFIG_TYPE_JSON)) {\n        propertiesMap = ConfigHandler.parseConfig(value);\n    }\n    return propertiesMap;\n}", "CodeBleu_score": 46.320130018366456}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t    // 1. \u83b7\u53d6 DtpProperties\n    DtpProperties dtpProperties = bindDtpProperties(environment);\n    // 2. \u68c0\u67e5\u5c5e\u6027\u662f\u5426\u5b58\u5728\n    checkPropertyExist(environment, dtpProperties);\n    // 3. \u751f\u6210\u5c5e\u6027\u6620\u5c04\n    Map<String, Object> propertiesMap = genPropertiesMap(dtpProperties);\n    // 4. \u521b\u5efa Zookeeper \u5c5e\u6027\u6e90\n    createZkPropertySource(environment, propertiesMap);\n}", "CodeBleu_score": 44.866950569025036}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t    DtpProperties dtpProperties = bindDtpProperties(environment);\n    checkPropertyExist(environment, dtpProperties);\n    genPropertiesMap(dtpProperties);\n    createZkPropertySource(environment, dtpProperties);\n}", "CodeBleu_score": 38.26444801820155}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = bindDtpProperties(environment);\n\tcheckPropertyExist(dtpProperties);\n\tMap<String, Object> propertiesMap = genPropertiesMap(dtpProperties);\n\tif (!environment.containsProperty(DtpProperties.DTP_ZOOKEEPER_CONNECTION_STRING)) {\n\t\tcreateZkPropertySource(environment, propertiesMap);\n\t}\n}", "CodeBleu_score": 46.59985094958723}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    builder.Register(provider =>\n    {\n        var logger = provider.GetRequiredService<ILogger<ZooKeeperServiceRouteManager>>();\n        var serializer = provider.GetRequiredService<ISerializer<byte[]>>();\n        var factory = provider.GetRequiredService<IServiceRouteFactory>();\n        var stringSerializer = provider.GetRequiredService<ISerializer<string>>();\n        var clientProvider = provider.GetRequiredService<IZookeeperClientProvider>();\n        return new ZooKeeperServiceRouteManager(logger, configInfo, serializer, factory, stringSerializer, clientProvider);\n    }).As<IServiceRouteManager>().SingleInstance();\n    return this;\n}", "CodeBleu_score": 47.80939409558541}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    builder.Register(provider =>\n    {\n        var logger = provider.GetRequiredService<ILogger<ZooKeeperServiceRouteManager>>();\n        var serializer = provider.GetRequiredService<ISerializer<byte[]>>();\n        var factory = provider.GetRequiredService<IServiceRouteFactory>();\n        var jsonSerializer = provider.GetRequiredService<ISerializer<string>>();\n        var clientProvider = provider.GetRequiredService<IZookeeperClientProvider>();\n        var manager = new ZooKeeperServiceRouteManager(configInfo.RoutePath, logger, serializer, factory, jsonSerializer, clientProvider);\n        return manager;\n    }).As<IServiceRouteManager>().SingleInstance();\n    return this;\n}", "CodeBleu_score": 39.1105262429214}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    builder.RegisterInstance(configInfo)\n        .As<ConfigInfo>()\n        .SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteManager>()\n        .As<IServiceRouteManager>()\n        .As<IStartupTask>()\n        .SingleInstance();\n    builder.RegisterType<DefaultServiceRouteFactory>()\n        .As<IServiceRouteFactory>()\n        .SingleInstance();\n    builder.RegisterType<JsonSerializer>()\n        .As<ISerializer<byte[]>>()\n        .SingleInstance();\n    builder.RegisterType<JsonStringSerializer>()\n        .As<ISerializer<string>>()\n        .SingleInstance();\n    builder.RegisterType<ZookeeperClientProvider>()\n        .As<IZookeeperClientProvider>()\n        .SingleInstance();\n    builder.RegisterType<NullLogger<ZooKeeperServiceRouteManager>>()\n        .As<ILogger<ZooKeeperServiceRouteManager>>()\n        .SingleInstance();\n    return this;\n}", "CodeBleu_score": 50.058094265481365}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t        builder.Register(provider => new ZookeeperServiceCommandManager(provider.Resolve<ILogger<ZookeeperServiceCommandManager>>(),\n            provider.Resolve<ISerializer<byte[]>>(),\n            provider.Resolve<ISerializer<string>>(),\n            provider.Resolve<IServiceEntryManager>(),\n            provider.Resolve<IServiceRouteManager>(),\n            provider.Resolve<IZookeeperClientProvider>(),\n            configInfo))\n            .As<IServiceCommandManager>()\n            .SingleInstance();\n        return this;\n    }", "CodeBleu_score": 58.71643838022052}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t            if (builder == null) {\n                throw new ArgumentNullException(nameof(builder));\n            }\n            if (configInfo == null) {\n                throw new ArgumentNullException(nameof(configInfo));\n            }\n            builder.Register<IServiceEntryManager, ServiceEntryManager>(Lifetime.Singleton)\n                .Register<ISerializer<byte[]>, JsonSerializer<byte[]>>(Lifetime.Singleton)\n                .Register<ISerializer<string>, JsonSerializer<string>>(Lifetime.Singleton)\n                .Register<IZookeeperClientProvider>(provider => new DefaultZookeeperClientProvider(configInfo.ConnectionString), Lifetime.Singleton)\n                .Register<IServiceRouteManager, ServiceRouteManager>(Lifetime.Singleton)\n                .Register<IServiceCommandManager, ZookeeperServiceCommandManager>(Lifetime.Singleton)\n                .Register<IServiceSubscriber, ZookeeperServiceSubscriber>(Lifetime.Singleton)\n                .Register<IServicePublisher, ZookeeperServicePublisher>(Lifetime.Singleton)\n                .Register<IServiceDiscovery, ZookeeperServiceDiscovery>(Lifetime.Singleton)\n                .Register<IServiceSubscriberFactory, ZookeeperServiceSubscriberFactory>(Lifetime.Singleton)\n                .Register<IServicePublisherFactory, ZookeeperServicePublisherFactory>(Lifetime.Singleton)\n                .Register<IServiceDiscoveryFactory, ZookeeperServiceDiscoveryFactory>(Lifetime.Singleton)\n                .Register<IServiceSubscriberManager, ServiceSubscriberManager>(Lifetime.Singleton)\n                .Register<IServicePublisherManager, ServicePublisherManager>(Lifetime.Singleton)\n                .Register<IServiceDiscoveryManager, ServiceDiscoveryManager>(Lifetime.Singleton)\n                .Register<IServiceSubscriberFactoryManager, ServiceSubscriberFactoryManager>(Lifetime.Singleton)\n                .Register<IServicePublisherFactoryManager, ServicePublisherFactoryManager>(Lifetime.Singleton)\n                .Register<IServiceDiscoveryFactoryManager, ServiceDiscoveryFactoryManager>(L", "CodeBleu_score": 34.69897266411447}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    builder.Register<IServiceEntryManager, ZookeeperServiceEntryManager>(ServiceLifetime.Singleton);\n    builder.Register<ISerializer<byte[]>, JsonUtf8Serializer>(ServiceLifetime.Singleton);\n    builder.Register<ISerializer<string>, JsonStringSerializer>(ServiceLifetime.Singleton);\n    builder.Register<ILogger<ZookeeperServiceCommandManager>>(ServiceLifetime.Singleton, p => p.GetRequiredService<ILoggerFactory>().CreateLogger<ZookeeperServiceCommandManager>());\n    builder.Register<IServiceRouteManager, ZookeeperServiceRouteManager>(ServiceLifetime.Singleton);\n    builder.Register<IZookeeperClientProvider>(ServiceLifetime.Singleton, p => new DefaultZookeeperClientProvider(configInfo.ZookeeperConnectionString, configInfo.RoutePath, configInfo.RoutePath, configInfo.RoutePath));\n    builder.Register<IServiceCommandManager, ZookeeperServiceCommandManager>(ServiceLifetime.Singleton);\n    return this;\n}", "CodeBleu_score": 44.78959760082903}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    Check.NotNull(builder, nameof(builder));\n    Check.CheckCondition(string.IsNullOrEmpty(path), nameof(path), \"path is null or empty\");\n\n    if (provider == null && !Path.IsPathRooted(path)) {\n        throw new ArgumentException(\"A non-rooted path requires a provider.\");\n    }\n\n    var physicalProvider = provider as PhysicalFileProvider;\n    if (physicalProvider == null && provider != null) {\n        throw new ArgumentException(\"The file provider must be of type PhysicalFileProvider.\");\n    }\n\n    var source = new ZookeeperConfigurationSource() {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange,\n        ReloadDelay = TimeSpan.FromSeconds(1)\n    };\n\n    builder.Add(source);\n\n    return builder;\n}", "CodeBleu_score": 53.24718098395772}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    Check.NotNull(builder, nameof(builder));\n    Check.CheckCondition(string.IsNullOrEmpty(path), nameof(path));\n    Check.CheckCondition(Path.IsPathRooted(path), nameof(path));\n    Check.NotNull(provider, nameof(provider));\n    Check.CheckCondition(Path.IsPathRooted(path), nameof(path));\n    Check.CheckCondition(Path.GetFileName(path).EndsWith(\".json\", StringComparison.OrdinalIgnoreCase), nameof(path));\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    };\n    builder.Add(source);\n    return builder;\n}", "CodeBleu_score": 57.58281942604222}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    if (builder == null) {\n        throw new ArgumentNullException(nameof(builder));\n    }\n    if (string.IsNullOrEmpty(path)) {\n        throw new ArgumentNullException(nameof(path));\n    }\n    if (provider == null && !Path.IsPathRooted(path)) {\n        throw new ArgumentException(Resources.Error_InvalidFilePath, nameof(path));\n    }\n    Check.NotNull(builder, nameof(builder));\n    Check.CheckCondition(string.IsNullOrEmpty(path), \"path\");\n    Check.CheckCondition(provider == null && !Path.IsPathRooted(path), \"path\");\n    if (provider == null) {\n        provider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n    }\n    builder.Add(new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = Path.GetFileName(path),\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    });\n    return builder;\n}", "CodeBleu_score": 59.33033908649491}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t    var routes = await GetRoutesAsync();\n    foreach (var route in routes) {\n        route.Address.Except(Address);\n    }\n    await base.SetRoutesAsync(routes);\n}", "CodeBleu_score": 64.32727013306877}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t    var routes = await GetRoutesAsync();\n    var newRoutes = new List<RouteModel>();\n    foreach (var route in routes) {\n        var newRoute = route.Clone();\n        newRoute.Addresses.RemoveAll(a => Address.Any(a.Equals));\n        newRoutes.Add(newRoute);\n    }\n    await base.SetRoutesAsync(newRoutes);\n}", "CodeBleu_score": 49.07256058442264}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t    var routes = await GetRoutesAsync();\n    foreach (var route in routes) {\n        var addresses = route.Address.Except(Address);\n        route.Address = addresses;\n    }\n    await base.SetRoutesAsync(routes);\n}", "CodeBleu_score": 66.59399710058726}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = _routePath + \"/\" + hostAddr.ToString();\n    var zooKeeperClients = await _zookeeperClientProvider.GetZooKeepers();\n    foreach (var zooKeeper in zooKeeperClients) {\n        var oldRoutes = await zooKeeper.Item2.getChildrenAsync(routePath);\n        var oldRouteIds = oldRoutes.Select(p => p.Replace(\"_\", string.Empty)).ToArray();\n        var newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n        var deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n        foreach (var deletedRouteId in deletedRouteIds) {\n            var path = routePath + \"/\" + deletedRouteId;\n            var addresses = await zooKeeper.Item2.getChildrenAsync(path);\n            if (addresses.Contains(hostAddr.ToString())) {\n                await zooKeeper.Item2.deleteAsync(path + \"/\" + hostAddr.ToString());\n            }\n        }\n    }\n}", "CodeBleu_score": 51.76939616100535}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var path = $\"{_options.RoutePath}/{hostAddr.ToString()}\";\n    var zooKeeperClients = _zookeeperClientProvider.GetZooKeepers();\n    foreach (var zooKeeper in zooKeeperClients) {\n        var oldRoutes = await zooKeeper.Item2.getChildrenAsync(path);\n        var oldRouteIds = oldRoutes.Select(i => i.Utf8String).ToArray();\n        var newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n        var deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n        foreach (var deletedRouteId in deletedRouteIds) {\n            var addresses = _routes.Where(p => p.ServiceDescriptor.Id == deletedRouteId).Select(p => p.Address).FirstOrDefault();\n            if (addresses.Contains(hostAddr)) {\n                await zooKeeper.Item2.deleteAsync(path + \"/\" + deletedRouteId);\n            }\n        }\n    }\n}", "CodeBleu_score": 57.7903610201046}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var oldRouteIds = _routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n    var newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n    var deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n\n    foreach (var zooKeeper in _zookeeperClientProvider.GetZooKeepers()) {\n        var addresses = await zooKeeper.Item2.getChildrenAsync(zooKeeper.Item1);\n        var deletedRouteIdsOnZk = addresses.Except(newRouteIds).ToArray();\n        foreach (var deletedRouteId in deletedRouteIdsOnZk) {\n            var path = $\"{zooKeeper.Item1}/{deletedRouteId}\";\n            if (path.EndsWith(hostAddr.ToString())) {\n                await zooKeeper.Item2.deleteAsync(path);\n            }\n        }\n    }\n}", "CodeBleu_score": 47.56256650131434}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (_logger.IsEnabled(LogLevel.Debug))\n        _logger.LogDebug($\"Deserializing route data: {data.ToUTF8String()}\");\n\n    if (data == null)\n        return null;\n\n    var descriptor = await DeserializeAsync<ServiceRouteDescriptor>(data);\n    return (await CreateServiceRoutesAsync(new[] { descriptor })).First();\n}", "CodeBleu_score": 51.39807559759534}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (_logger.IsEnabled(LogLevel.Debug)) {\n        _logger.LogDebug($\"Deserializing route data: {Encoding.UTF8.GetString(data)}\u3002\");\n    }\n\n    if (data == null) {\n        return null;\n    }\n\n    var descriptor = await _serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\n    return (await CreateServiceRoutesAsync(new[] { descriptor })).First();\n}", "CodeBleu_score": 50.23458246905565}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (_logger.IsEnabled(LogLevel.Debug))\n        _logger.LogDebug($\"Deserializing route from data: {(data == null ? \"null\" : BitConverter.ToString(data))}.\");\n\n    if (data == null)\n        return null;\n\n    var descriptor = await _serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\n    return (await CreateServiceRoutesAsync(new[] { descriptor })).First();\n}", "CodeBleu_score": 54.48530339230525}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    if (DataEquals(oldData, newData)) {\n        return;\n    }\n\n    var newRoute = await GetRoute(newData);\n    lock (_routesLock) {\n        _routes = _routes.Where(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id)\n            .Concat(new[] { newRoute }).ToArray();\n    }\n\n    OnChanged(newRoute, GetRoute(oldData));\n}", "CodeBleu_score": 63.31931987661488}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    if (oldData.DataEquals(newData)) {\n        return;\n    }\n\n    var newRoute = new Route(newData);\n    lock (_routes) {\n        var oldRoute = _routes.FirstOrDefault(i =>\n            i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id);\n        _routes = _routes.Where(i =>\n                i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id)\n            .Concat(new[] { newRoute }).ToArray();\n    }\n\n    // Trigger the route changed event.\n    OnChanged(newRoute, oldRoute);\n}", "CodeBleu_score": 67.04618778797821}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    if (DataEquals(oldData, newData)) {\n        return;\n    }\n\n    var newRoute = GetRoute(newData);\n    if (newRoute == null) {\n        throw new Exception(\"invalid newData\");\n    }\n\n    Route oldRoute = null;\n    lock (_routes) {\n        oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id);\n        if (oldRoute == null) {\n            throw new Exception(\"invalid oldData\");\n        }\n\n        _routes = _routes.Where(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id)\n            .Concat(new[] { newRoute }).ToArray();\n    }\n\n    // trigger the OnChanged event.\n    await OnChanged(newRoute, oldRoute);\n}", "CodeBleu_score": 68.59283294805718}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    var serviceSubscribers = await base.GetSubscribersAsync();\n    var updatedSubscribers = new List<ServiceSubscriber>();\n    foreach (var subscriber in subscribers) {\n        var existingSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n        if (existingSubscriber != null) {\n            existingSubscriber.Address = existingSubscriber.Address.Concat(subscriber.Address).Except(existingSubscriber.Address);\n            updatedSubscribers.Add(existingSubscriber);\n        } else {\n            updatedSubscribers.Add(subscriber);\n        }\n    }\n    await base.SetSubscribersAsync(updatedSubscribers);\n}", "CodeBleu_score": 64.18091380627106}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    var serviceSubscribers = await GetSubscribersAsync();\n    foreach (var subscriber in subscribers) {\n        var existingSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n        if (existingSubscriber != null) {\n            existingSubscriber.Address = existingSubscriber.Address.Concat(subscriber.Address).Except(existingSubscriber.Address);\n        }\n    }\n    await base.SetSubscribersAsync(serviceSubscribers);\n}", "CodeBleu_score": 66.6050904370081}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t\tvar serviceSubscribers = await GetSubscribersAsync();\n\tforeach (var subscriber in subscribers) {\n\t\tvar existingSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n\t\tif (existingSubscriber != null) {\n\t\t\texistingSubscriber.Address = subscriber.Address.Concat(existingSubscriber.Address.Except(subscriber.Address)).ToList();\n\t\t}\n\t}\n\tawait base.SetSubscribersAsync(serviceSubscribers);\n}", "CodeBleu_score": 66.00252593391616}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t            var subscribers = new List<ServiceSubscriber>();\n            var rootPath = _configuration.GetValue<string>(\"SubscriberPath\");\n  ", "CodeBleu_score": 9.782338735138326}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t            var subscribers = new List<ServiceSubscriber>();\n            var rootPath = _options.GetRootPath();\n            _logger.LogDebug(\"Getting subscribers for children: {0}\", childrens.Count());\n            foreach (var child in childrens) {\n                var nodePath = Path.Combine(rootPath, child);\n                _logger.LogDebug(\"Getting subscribers for node: {0}\", nodePath);\n                var subscriber = await _options.GetSubscriber(nodePath);\n                subscribers.Add(subscriber);\n            }\n            return subscribers.ToArray();\n        }", "CodeBleu_score": 45.3855376879925}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t    var subscribers = new List<ServiceSubscriber>();\n    var rootPath = $\"{_options.RootPath}/{_options.SubscriberPath}\";\n    _logger.LogDebug($\"Getting subscribers for children {string.Join(\", \", childrens)}\");\n    foreach (var child in childrens) {\n        var nodePath = $\"{rootPath}/{child}\";\n        _logger.LogDebug($\"Getting subscribers for child {nodePath}\");\n        var subscriber = await GetSubscriber(nodePath);\n        if (subscriber != null) {\n            subscribers.Add(subscriber);\n        }\n    }\n    return subscribers.ToArray();\n}", "CodeBleu_score": 52.86392589966046}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null) {\n        return;\n    }\n    var zooKeeper = await GetZooKeeper();\n    if (zooKeeper.Item2.existsAsync(SubscribersPath).GetAwaiter().GetResult() != null) {\n        var result = await zooKeeper.Item2.getChildrenAsync(SubscribersPath);\n        _subscribers = result.Children.ToArray();\n    } else {\n        _logger.LogWarning(\"Subscribers path does not exist\");\n        _subscribers = Array.Empty<string>();\n    }\n}", "CodeBleu_score": 47.70831183963911}, {"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null) {\n        return;\n    }\n    var zooKeeper = await GetZooKeeper();\n    var result = await zooKeeper.Item2.existsAsync(SubscribersPath);\n    if (result.Children.ToArray().Length > 0) {\n        _subscribers = await zooKeeper.Item2.getChildrenAsync(SubscribersPath);\n    } else {\n        _logger.LogWarning(\"No subscribers found at {path}\", SubscribersPath);\n        _subscribers = new string[0];\n    }\n}", "CodeBleu_score": 45.601501061940056}, {"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null)\n        return;\n\n    var zooKeeper = await GetZooKeeper();\n    var result = await zooKeeper.Item2.existsAsync(SubscriberPath);\n    if (result.Stat != null) {\n        var children = (await zooKeeper.Item2.getChildrenAsync(SubscriberPath)).Children.ToArray();\n        var subscribers = new List<Subscriber>(children.Length);\n        foreach (var child in children) {\n            var subscriber = await GetSubscriber(child);\n            if (subscriber != null)\n                subscribers.Add(subscriber);\n        }\n        _subscribers = subscribers.ToArray();\n    }\n    else {\n        _logger.LogWarning(\"The subscriber path does not exist: {path}\", SubscriberPath);\n        _subscribers = Array.Empty<Subscriber>();\n    }\n}", "CodeBleu_score": 58.02225296198984}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t    // If the data has changed, get the new service command.\n    if (!DataEquals(oldData, newData)) {\n        var newCommand = GetServiceCommand(newData);\n        // Update the service commands list by replacing the old command with the new one for the same service ID.\n        _serviceCommands = _serviceCommands\n            .Where(i => i.ServiceId != newCommand.ServiceId)\n            .Concat(new[] { newCommand }).ToArray();\n    }\n    // Trigger the OnChanged event with the new and old commands.\n    OnChanged(new CommandChangedEventArgs(_serviceCommands.FirstOrDefault(i => i.ServiceId == newCommand.ServiceId), newCommand));\n}", "CodeBleu_score": 68.2035389004362}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t    // If the data is null, return.\n    if (oldData == null || newData == null) {\n        return;\n    }\n\n    // If the data is not equal, get the new command.\n    if (!DataEquals(oldData, newData)) {\n        // Get the new command.\n        ServiceCommand newCommand = GetServiceCommand(newData);\n\n        // If the new command is null, return.\n        if (newCommand == null) {\n            return;\n        }\n\n        // Update the service commands list by replacing the old command with the new one for the same service ID.\n        ServiceCommands = ServiceCommands.Where(i => i.ServiceId != newCommand.ServiceId)\n            .Concat(new[] { newCommand }).ToArray();\n    }\n    // Trigger the OnChanged event with the new and old commands.\n    OnChanged(new ServiceCommandChangedEventArgs(GetServiceCommand(oldData), GetServiceCommand(newData)));\n}", "CodeBleu_score": 62.44466911993034}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t    if (DataEquals(oldData, newData)) {\n        return;\n    }\n    var newCommand = GetServiceCommand(newData);\n    if (newCommand == null) {\n        return;\n    }\n    lock (_lock) {\n        if (_serviceCommands == null) {\n            _serviceCommands = new[] { newCommand };\n        } else {\n            _serviceCommands = _serviceCommands.FirstOrDefault(i => i.ServiceId == newCommand.ServiceId)\n                .Concat(new[] { newCommand }).ToArray();\n        }\n    }\n    //\u89e6\u53d1\u670d\u52a1\u547d\u4ee4\u53d8\u66f4\u4e8b\u4ef6\u3002\n    \n }", "CodeBleu_score": 64.96246499841494}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    if (watchedEvent.get_Type() == EventType.NodeDataChanged) {\n        var zooKeeper = _zooKeeperCall();\n        if (zooKeeper != null) {\n            var data = await zooKeeper.Item2.getDataAsync(_path);\n            if (data != null) {\n                var action = _action;\n                if (action != null) {\n                    action(data.get_Data(), data.get_Stat());\n                }\n                _watcher.SetCurrentData(data.get_Data());\n            }\n        }\n    }\n}", "CodeBleu_score": 57.133311651152184}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    if (watchedEvent.get_Type() == Event.EventType.NodeDataChanged) {\n        var zooKeeper = _zooKeeperCall.GetZooKeeper();\n        var data = await zooKeeper.Item2.getDataAsync(watchedEvent.get_Path());\n        var newData = Encoding.UTF8.GetString(data.get_Data());\n        var currentData = _watcher.GetCurrentData();\n        var action = _action;\n        if (action != null) {\n            await action(currentData, newData);\n        }\n        _watcher.SetCurrentData(newData);\n    }\n}", "CodeBleu_score": 36.050149049159394}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    if (watchedEvent.get_Type() == Event.EventType.NodeDataChanged) {\n        var zooKeeper = this.zooKeeperCall();\n        var newData = await zooKeeper.Item2.getDataAsync(watchedEvent.get_Path());\n        var action = this.action;\n        action(this.watcher.GetCurrentData(), newData);\n        this.watcher.SetCurrentData(newData);\n    }\n}", "CodeBleu_score": 51.52163964259275}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    builder.Services.Register(provider =>\n        new DefaultZookeeperClientProvider(\n            GetConfigInfo(configInfo),\n            provider.Resolve<IHealthCheckService>(),\n            provider.Resolve<IZookeeperAddressSelector>(),\n            provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance;\n    return builder;\n}", "CodeBleu_score": 68.19621835597654}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    builder.Services.Register(provider =>\n        new DefaultZookeeperClientProvider(\n            GetConfigInfo(configInfo),\n            provider.Resolve<IHealthCheckService>(),\n            provider.Resolve<IZookeeperAddressSelector>(),\n            provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance;\n    return builder;\n}", "CodeBleu_score": 68.19621835597654}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    builder.Services.Register(provider =>\n       new DefaultZookeeperClientProvider(\n           GetConfigInfo(configInfo),\n        provider.Resolve<IHealthCheckService>(),\n          provider.Resolve<IZookeeperAddressSelector>(),\n          provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance;\n\n    return builder;\n}", "CodeBleu_score": 68.77248215881002}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t    _logger.LogInformation(\"Setting MQTT routes...\");\n    var zooKeeper = await _zooKeeperProvider.GetZooKeeper();\n    if (zooKeeper == null) {\n        _logger.LogInformation(\"ZooKeeper is not available. Skipping MQTT route setup.\");\n        return;\n    }\n    var serviceRoute = $\"{_conf.ZooKeeperRoot}/{_conf.ZooKeeperServiceRoutePath}\";\n    if (!await zooKeeper.ExistsAsync(serviceRoute)) {\n        _logger.LogInformation(\"Creating MQTT route subdirectory...\");\n        await zooKeeper.CreateAsync(serviceRoute, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n    }\n    foreach (var route in routes) {\n        var nodePath = $\"{serviceRoute}/{route.ServiceId}\";\n        if (!await zooKeeper.ExistsAsync(nodePath)) {\n            _logger.LogInformation(\"Creating MQTT route node...\");\n            await zooKeeper.CreateAsync(nodePath, Serialize(route), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n        } else {\n            _logger.LogInformation(\"Updating MQTT route node...\");\n            await zooKeeper.SetDataAsync(nodePath, Serialize(route));\n        }\n    }\n    _logger.LogInformation(\"MQTT routes set.\");\n}", "CodeBleu_score": 48.65741548296997}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t    if (routes == null) throw new ArgumentNullException(nameof(routes));\n    if (!routes.Any()) return;\n\n    _logger.LogInformation(\"Setting MQTT routes...\");\n    var zooKeeper = await _zooKeeperProvider.GetZooKeeper();\n\n    foreach (var client in _conf.Clients) {\n        var clientPath = $\"{_conf.RouteRoot}/{client.Name}\";\n        await zooKeeper.CreateRecursiveAsync(clientPath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\n        foreach (var route in routes) {\n            var routePath = $\"{clientPath}/{route.Name}\";\n            var data = Encoding.UTF8.GetBytes(JsonConvert.SerializeObject(route));\n            var stat = await zooKeeper.ExistsAsync(routePath);\n\n            if (stat == null) {\n                _logger.LogDebug(\"Creating route node: {routePath}\", routePath);\n                await zooKeeper.CreateAsync(routePath, data, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            } else {\n                _logger.LogDebug(\"Updating route node: {routePath}\", routePath);\n                await zooKeeper.SetDataAsync(routePath, data);\n            }\n        }\n    }\n\n    _logger.LogInformation(\"MQTT routes set.\");\n}", "CodeBleu_score": 46.04989100353131}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t    _logger.LogInformation(\"Setting MQTT routes\");\n\n    var zooKeeper = await _zooKeeperProvider.GetZooKeeper();\n\n    if (zooKeeper == null) {\n        _logger.LogWarning(\"No ZooKeeper clients available\");\n        return;\n    }\n\n    foreach (var client in _zooKeeperProvider.GetZooKeepers()) {\n        var nodePath = $\"{_conf.ZooKeeper.Root}/{_conf.ZooKeeper.RoutePath}\";\n\n        if (!await zooKeeper.ExistsAsync(nodePath)) {\n            _logger.LogInformation(\"Creating MQTT route path: {nodePath}\", nodePath);\n\n            await zooKeeper.CreateAsync(nodePath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n        }\n\n        foreach (var serviceRoute in routes) {\n            var node = $\"{nodePath}/{serviceRoute.ServiceDescriptor.Id}\";\n\n            if (!await zooKeeper.ExistsAsync(node)) {\n                _logger.LogInformation(\"Creating MQTT route node: {node}\", node);\n\n                await zooKeeper.CreateAsync(node, Data, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            } else {\n                _logger.LogInformation(\"Updating MQTT route node: {node}\", node);\n\n                await zooKeeper.setDataAsync(node, Data);\n            }\n        }\n    }\n\n    _logger.LogInformation(\"MQTT routes set\");\n}", "CodeBleu_score": 53.11761558053385}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    var oldRouteTopics = _routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\n    if (!deletedRouteTopics.Any()) return;\n    var zooKeeper = await _zookeeperClientProvider.GetZooKeepers();\n    foreach (var zooKeeper in zooKeeper) {\n        var addresses = await zooKeeper.Item2.getChildrenAsync(zooKeeper.Item1.RoutePath);\n        var deletedRouteEndpoints = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopics).Select(p => p.MqttEndpoint).FirstOrDefault();\n        if (deletedRouteEndpoints.Any() && addresses.Contains(hostAddr.Address)) {\n            await zooKeeper.Item2.deleteAsync(zooKeeper.Item1.RoutePath + \"/\" + deletedRouteTopics);\n        }\n    }\n}", "CodeBleu_score": 59.03328037116048}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = $\"{_options.RoutePath}/{hostAddr.ToString()}\";\n    var zooKeeperClients = await _zookeeperClientProvider.GetZooKeepers();\n    var oldRouteTopics = zooKeeperClients.SelectMany(i => i.Item2.getChildrenAsync(routePath).Result).ToArray();\n    var newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\n    foreach (var zooKeeper in zooKeeperClients) {\n        var addresses = zooKeeper.Item2.getChildrenAsync(routePath).Result.ToArray();\n        var deletedRouteAddresses = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopics[0]).Select(p => p.MqttEndpoint).FirstOrDefault();\n        if (addresses.Contains(deletedRouteAddresses.ToString())) {\n            await zooKeeper.Item2.deleteAsync(routePath + \"/\" + deletedRouteAddresses.ToString());\n        }\n    }\n}", "CodeBleu_score": 52.73192842539236}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t  var routePath = $\"{_options.Value.RoutePath}/{hostAddr.ToString()}\";\n  var zooKeeperClients = await _zookeeperClientProvider.GetZooKeepers();\n  foreach (var zooKeeper in zooKeeperClients) {\n    var oldRouteTopics = await zooKeeper.Item2.getChildrenAsync(routePath);\n    var newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\n    foreach (var deletedRouteTopic in deletedRouteTopics) {\n      var addresses = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\n      if (addresses.Contains(hostAddr)) {\n        await zooKeeper.Item2.deleteAsync(routePath + \"/\" + deletedRouteTopic);\n      }\n    }\n  }\n}", "CodeBleu_score": 59.95225360848515}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t    _logger.LogInformation(\"Setting service caches in Zookeeper\");\n    string cachePath = $\"{_config.ZooKeeperRootPath}/{_config.CachePath}\";\n    var zooKeeperClients = await _zooKeeperClientProvider.GetZooKeepers();\n    foreach (var zooKeeper in zooKeeperClients) {\n        await zooKeeper.EnsureExistsAsync(cachePath);\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            string nodePath = $\"{cachePath}/{cacheDescriptor.ServiceDescriptor.Id}\";\n            if (await zooKeeper.ExistsAsync(nodePath) == null) {\n                await zooKeeper.CreateAsync(nodePath, cacheDescriptor.Serialize());\n            }\n            else {\n                if (!DataEquals(cacheDescriptor.Serialize(), await zooKeeper.GetDataAsync(nodePath))) {\n                    await zooKeeper.SetDataAsync(nodePath, cacheDescriptor.Serialize());\n                }\n            }\n        }\n    }\n    _logger.LogInformation(\"Service caches set in Zookeeper\");\n}", "CodeBleu_score": 36.8807070258226}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t    if (cacheDescriptors == null) {\n        throw new ArgumentNullException(nameof(cacheDescriptors));\n    }\n\n    _logger.LogInformation(\"Setting service caches...\");\n\n    var cachePath = GetCachePath();\n    var zooKeeperClients = await _zooKeeperProvider.GetZooKeepers();\n\n    foreach (var zooKeeper in zooKeeperClients) {\n        await zooKeeper.EnsureExistsAsync(cachePath);\n\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var cacheDescriptorPath = GetCacheDescriptorPath(cacheDescriptor.Name);\n            var cacheDescriptorData = Encoding.UTF8.GetBytes(JsonConvert.SerializeObject(cacheDescriptor));\n\n            if (!await zooKeeper.ExistsAsync(cacheDescriptorPath)) {\n                await zooKeeper.CreateAsync(cacheDescriptorPath, cacheDescriptorData);\n            } else {\n                var zooKeeperCacheDescriptorData = await zooKeeper.GetDataAsync(cacheDescriptorPath);\n\n                if (!DataEquals(cacheDescriptorData, zooKeeperCacheDescriptorData)) {\n                    await zooKeeper.SetDataAsync(cacheDescriptorPath, cacheDescriptorData);\n                }\n            }\n        }\n    }\n\n    _logger.LogInformation(\"Service caches set.\");\n}", "CodeBleu_score": 39.13073914770911}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t    _logger.LogInformation(\"Setting service caches in Zookeeper...\");\n    var cachePath = _configProvider.GetZooKeeperCachePath();\n    var zooKeepers = _configProvider.GetZooKeepers();\n    foreach (var zooKeeper in zooKeepers) {\n        await zooKeeper.EnsurePathExistsAsync(cachePath);\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var nodePath = GetCacheNodePath(cacheDescriptor.ServiceId);\n            var data = JsonConvert.SerializeObject(cacheDescriptor);\n            if (!await zooKeeper.ExistsAsync(nodePath)) {\n                await zooKeeper.CreateAsync(nodePath, data, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n            } else {\n                var zooKeeperData = await zooKeeper.GetDataAsync(nodePath);\n                if (!DataEquals(zooKeeperData, data)) {\n                    await zooKeeper.SetDataAsync(nodePath, data);\n                }\n            }\n        }\n    }\n    _logger.LogInformation(\"Service caches have been successfully added in Zookeeper.\");\n}", "CodeBleu_score": 42.761199099946246}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    _logger.LogInformation(\"Creating subdirectory: {0}\", path);\n    zooKeeper.Item2.createAsync(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT).Wait();\n    _logger.LogInformation(\"Created subdirectory: {0}\", path);\n}", "CodeBleu_score": 26.297628133043517}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    _logger.LogInformation($\"Waiting for manual reset event to be set before creating Zookeeper node path {path}\");\n    zooKeeper.Item1.WaitOne();\n    _logger.LogInformation($\"Manual reset event is set, proceeding to create Zookeeper node path {path}\");\n    if (await zooKeeper.Item2.existsAsync(path) == null) {\n        _logger.LogInformation($\"Zookeeper node path {path} does not exist, creating it\");\n        var subpaths = path.Split(\"/\", StringSplitOptions.RemoveEmptyEntries);\n        var subpath = \"\";\n        foreach (var subdirectory in subpaths) {\n            subpath = string.IsNullOrEmpty(subpath) ? subdirectory : $\"{subpath}/{subdirectory}\";\n            if (await zooKeeper.Item2.existsAsync(subpath) == null) {\n                await zooKeeper.Item2.createAsync(subpath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n                _logger.LogInformation($\"Created Zookeeper node path {subpath}\");\n            }\n        }\n    }\n    _logger.LogInformation($\"Zookeeper node path {path} exists, no need to create it\");\n}", "CodeBleu_score": 53.787263286794754}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    _logger.LogInformation($\"Waiting for manual reset event\");\n    zooKeeper.Item1.WaitOne();\n    _logger.LogInformation($\"Manual reset event received\");\n    if (zooKeeper.Item2.existsAsync(path).GetAwaiter().GetResult() == null) {\n        _logger.LogInformation($\"Creating Zookeeper node {path}\");\n        zooKeeper.Item2.createAsync(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT).GetAwaiter().GetResult();\n        _logger.LogInformation($\"Created Zookeeper node {path}\");\n    }\n    else {\n        _logger.LogInformation($\"Zookeeper node {path} already exists\");\n    }\n    string[] directories = path.Split('/');\n    string subdirectory = string.Empty;\n    for (int i = 1; i < directories.Length; i++) {\n        subdirectory = string.Join(\"/\", directories.Take(i));\n        if (zooKeeper.Item2.existsAsync(subdirectory).GetAwaiter().GetResult() == null) {\n            _logger.LogInformation($\"Creating Zookeeper node {subdirectory}\");\n            zooKeeper.Item2.createAsync(subdirectory, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT).GetAwaiter().GetResult();\n            _logger.LogInformation($\"Created Zookeeper node {subdirectory}\");\n        }\n        else {\n            _logger.LogInformation($\"Zookeeper node {subdirectory} already exists\");\n        }\n    }\n}", "CodeBleu_score": 46.736503317697064}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new List<(ManualResetEvent, ZooKeeper)>();\n    foreach (var address in _config.Addresses) {\n        var healthy = await _healthCheckService.IsHealth(address).ConfigureAwait(false);\n        if (healthy) {\n            var zooKeeper = CreateZooKeeper(address);\n            var manualResetEvent = new ManualResetEvent(false);\n            result.Add((manualResetEvent, zooKeeper));\n        }\n    }\n    return result;\n}", "CodeBleu_score": 72.71949515427427}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new List<(ManualResetEvent, ZooKeeper)>();\n    foreach (var address in _addresses) {\n        if (await _healthCheckService.IsHealth(address)) {\n            result.Add((new ManualResetEvent(false), CreateZooKeeper(address)));\n        }\n    }\n    return result;\n}", "CodeBleu_score": 75.13691029647218}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new List<(ManualResetEvent, ZooKeeper)>();\n\n    foreach (var address in _zooKeeperAddresses) {\n        if (await _healthCheckService.IsHealth(address)) {\n            result.Add((new ManualResetEvent(false), new ZooKeeper(address)));\n        }\n    }\n\n    return result;\n}", "CodeBleu_score": 73.96439079181184}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\t    synchronized (this) {\n        if (zk == null) {\n            zk = newZooKeeper(getConnectionString());\n        }\n        return zk;\n    }\n}", "CodeBleu_score": 21.80574271444023}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t    synchronized (this) {\n        if (zk == null) {\n            zk = newZooKeeper();\n        }\n        return zk;\n    }\n}", "CodeBleu_score": 17.96793118857101}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t  synchronized (this) {\n    if (zk == null) {\n      zk = newZooKeeper();\n    }\n    return zk;\n  }\n}", "CodeBleu_score": 16.602629864291337}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t    try {\n        if (zk != null) {\n            if (waitForShutdownTimeoutMs > 0) {\n                try {\n                    zk.register(new Watcher() {\n                        @Override\n                        public void process(WatchedEvent event) {\n                            // Do nothing\n                        }\n                    });\n                    zk.close(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n                } catch (InterruptedException e) {\n                    Thread.currentThread().interrupt();\n                    throw e;\n                }\n            } else {\n                zk.close();\n            }\n        }\n    } finally {\n        zk = null;\n    }\n}", "CodeBleu_score": 44.758414940108224}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t    if (this.zk != null) {\n        // We register a dummy watcher to clear the default watcher, preventing new events from being processed\n        this.zk.register(new Watcher() {\n            @Override\n            public void process(WatchedEvent event) {\n                // Nothing to do\n            }\n        });\n\n        if (waitForShutdownTimeoutMs > 0) {\n            // Wait for the specified timeout\n            this.zk.close(waitForShutdownTimeoutMs);\n        } else {\n            // Close immediately\n            this.zk.close();\n        }\n\n        this.zk = null;\n    }\n}", "CodeBleu_score": 25.305694481725876}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t    ZooKeeper zk = helper.getZooKeeper();\n    if (zk != null) {\n        try {\n            if (waitForShutdownTimeoutMs > 0) {\n                zk.register(new Watcher() {\n                    @Override\n                    public void process(WatchedEvent event) {\n                    }\n                });\n                zk.close(waitForShutdownTimeoutMs);\n            } else {\n                zk.close();\n            }\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            throw e;\n        }\n    }\n}", "CodeBleu_score": 46.85260190310661}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    startAdvancedTracer();\n    try {\n        if (isConnected()) {\n            return true;\n        }\n        internalBlockUntilConnectedOrTimedOut();\n        return true;\n    } catch (Exception e) {\n        return false;\n    } finally {\n        endAdvancedTracer();\n    }\n}", "CodeBleu_score": 16.485587512569357}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    startAdvancedTracer(\"blockUntilConnectedOrTimedOut\");\n    boolean connected = false;\n    if (isConnected()) {\n        connected = true;\n    } else {\n        try {\n            internalBlockUntilConnectedOrTimedOut();\n            connected = true;\n        } catch (Exception e) {\n            log.warn(\"blockUntilConnectedOrTimedOut exception: \" + e.getMessage());\n        }\n    }\n    debug(\"blockUntilConnectedOrTimedOut done\");\n    return connected;\n}", "CodeBleu_score": 36.07995134130015}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\treturn blockUntilConnectedOrTimedOut(10000);\n}", "CodeBleu_score": 5.2412900037997}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t    if (!started) {\n        return;\n    }\n    started = false;\n    log.info(\"Closing service.\");\n    try {\n        state.close(waitForShutdownTimeoutMs);\n    } catch (IOException e) {\n        if (Thread.currentThread().isInterrupted()) {\n            log.error(\"Interrupted while closing service.  This is likely due to a shutdown request.\");\n        } else {\n            log.error(\"Error while closing service.\", e);\n        }\n    }\n}", "CodeBleu_score": 49.718832930755056}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t    if (isStarted()) {\n        try {\n            logger.log(Level.FINE, \"Shutting down service\");\n            setStarted(false);\n            if (waitForShutdownTimeoutMs > 0) {\n                close(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n            }\n        } catch (IOException e) {\n            checkInterrupted(e);\n            logger.log(Level.SEVERE, \"Error shutting down service\", e);\n        }\n    }\n}", "CodeBleu_score": 46.75196016623314}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\ttry {\n\t\tlogger.info(\"Shutting down service\");\n\t\tsetStarted(false);\n\t\tif (!close(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS)) {\n\t\t\tlogger.info(\"Service did not shutdown in the specified time\");\n\t\t}\n\t} catch (IOException e) {\n\t\tcheckInterrupted(e);\n\t\tlogger.error(\"Error shutting down service\", e);\n\t}\n}", "CodeBleu_score": 54.534159668060035}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t  long remainingWaitTime = connectionTimeout;\n  long startTime = System.currentTimeMillis();\n  while (state != State.CONNECTED && remainingWaitTime > 0) {\n    CountDownLatch countDownLatch = new CountDownLatch(1);\n    ConnectionStateListener watcher = new ConnectionStateListener() {\n      @Override\n      public void onConnectionStateChange(State newState) {\n        if (newState == State.CONNECTED) {\n          countDownLatch.countDown();\n        }\n      }\n    };\n    addConnectionStateListener(watcher);\n    countDownLatch.await(remainingWaitTime, TimeUnit.MILLISECONDS);\n    removeConnectionStateListener(watcher);\n    remainingWaitTime = connectionTimeout - (System.currentTimeMillis() - startTime);\n  }\n}", "CodeBleu_score": 37.063197904947565}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tlong remainingWaitTime = connectionTimeout;\n\twhile (true) {\n\t\tif (state == State.CONNECTED) {\n\t\t\treturn;\n\t\t}\n\t\tif (state == State.CLOSED) {\n\t\t\tthrow new InterruptedException(\"The client is closed\");\n\t\t}\n\t\tif (remainingWaitTime <= 0) {\n\t\t\tthrow new InterruptedException(\"Timed out waiting for connection\");\n\t\t}\n\t\tCountDownLatch latch = new CountDownLatch(1);\n\t\ttry {\n\t\t\tWatcher watcher = new Watcher() {\n\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t\tif (event.getState() == KeeperState.SyncConnected) {\n\t\t\t\t\t\tlatch.countDown();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tzooKeeper.register(watcher);\n\t\t\tlatch.await(remainingWaitTime, TimeUnit.MILLISECONDS);\n\t\t\tzooKeeper.removeWatcher(watcher);\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow e;\n\t\t} catch (Exception e) {\n\t\t\t// ignore\n\t\t}\n\t\tremainingWaitTime = connectionTimeout - (System.currentTimeMillis() - startTime);\n\t}\n}", "CodeBleu_score": 40.36055785978859}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t  long start = System.currentTimeMillis();\n  long remaining = connectionTimeout;\n  while (true) {\n    if (state == State.CONNECTED) {\n      return;\n    }\n    if (state == State.DISCONNECTED) {\n      throw new MqttException(MqttException.REASON_CODE_CLIENT_NOT_CONNECTED);\n    }\n    if (remaining <= 0) {\n      throw new MqttException(MqttException.REASON_CODE_CLIENT_TIMEOUT);\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    MqttWatcher watcher = new MqttWatcher() {\n      public void processEvent(MqttEvent event) {\n        if (event.getEvent() == MqttEvent.CONNECTED) {\n          latch.countDown();\n        }\n      }\n    };\n    watchers.add(watcher);\n    latch.await(remaining, TimeUnit.MILLISECONDS);\n    watchers.remove(watcher);\n    remaining = connectionTimeout - (System.currentTimeMillis() - start);\n  }\n}", "CodeBleu_score": 41.90510690789955}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t    if (createMode == CreateMode.EPHEMERAL) {\n        if (client.getZooKeeper().getSessionId() != client.getSessionId()) {\n            client.getFailedDeleteManager().delete(foundNode, -1);\n            client.getZooKeeper().getSessionId();\n            client.info(\"Ephemeral node [\" + foundNode + \"] deleted due to session ID change\");\n        }\n    }\n    return foundNode;\n}", "CodeBleu_score": 26.526792029152308}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t    if (isEphemeral(createMode)) {\n        String sessionId = getSessionId(client);\n        if (getFailedDeleteManager().isFailedDelete(foundNode)) {\n            getFailedDeleteManager().delete(client, foundNode);\n        }\n        if (!sessionId.equals(getSessionId(client))) {\n            info(\"Session ID has changed, old session: \" + sessionId + \", new session: \" + getSessionId(client));\n            getFailedDeleteManager().delete(client, foundNode);\n            setSessionId(client);\n        }\n    }\n    return foundNode;\n}", "CodeBleu_score": 33.62053932912675}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t    if (isEphemeral(createMode)) {\n        if (getSessionId(client) != info.getSessionId()) {\n            log.warn(\"The sessionId has changed, deleting the old node: \" + foundNode);\n            getFailedDeleteManager().delete(client, foundNode);\n            info.setSessionId(getSessionId(client));\n        }\n    }\n    return foundNode;\n}", "CodeBleu_score": 26.67831798139059}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t    final String traceName = \"pathInForeground\";\n    final ZooKeeperTracer tracer = getZooKeeperTracer();\n    final ZooKeeper zooKeeper = getZooKeeper();\n    final String pathToSet = path;\n    final List<ACL> aclListToSet = aclList;\n    final ZooKeeperOperationTracker operationTracker = new ZooKeeperOperationTracker(tracer, traceName, pathToSet, aclListToSet);\n    tracer.startAdvancedTrace(operationTracker);\n    try {\n        final int maxAttempts = 10;\n        final long retryInterval = 1000;\n        final RetryLoop<Object> retryLoop = new RetryLoop<Object>(retryInterval, maxAttempts, tracer);\n        Stat stat = retryLoop.callWithRetry(new Callable<Stat>() {\n            public Stat call() throws Exception {\n                final String traceName = \"pathInForeground-call\";\n                final ZooKeeperTracer tracer = getZooKeeperTracer();\n                final ZooKeeper zooKeeper = getZooKeeper();\n                final String pathToSet = pathToSet;\n                final List<ACL> aclListToSet = aclListToSet;\n                final ZooKeeperOperationTracker operationTracker = new ZooKeeperOperationTracker(tracer, traceName, pathToSet, aclListToSet);\n                tracer.startAdvancedTrace(operationTracker);\n                try {\n                    Stat stat = zooKeeper.setACL(pathToSet, aclListToSet, -1);\n                    tracer.commitAdvancedTrace(operationTracker, stat);\n                    return stat;\n                } catch (Exception e) {\n                    tracer.abortAdvancedTrace(operationTracker, e);\n                    throw e;\n                } finally {\n                    tracer.stopAdvancedTrace(operationTracker);\n                }\n            }\n        });\n        tracer.commitAdvancedTrace(operationTracker, stat", "CodeBleu_score": 39.80406390180198}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t    final String traceName = \"setACL-\" + path;\n    final Trace trace = getTracer().startAdvancedTrace(traceName);\n    trace.record(\"path\", path);\n    trace.record(\"acl\", aclList);\n    try {\n        Stat stat = null;\n        for (int i = 0; i < 10; i++) {\n            try {\n                stat = getZooKeeper().setACL(path, aclList, -1);\n                trace.record(\"status\", \"success\");\n                break;\n            } catch (KeeperException e) {\n                trace.record(\"status\", \"exception\");\n                trace.record(e);\n                if (e.code() == Code.NONODE) {\n                    break;\n                }\n            }\n            Thread.sleep(1000);\n        }\n        return stat;\n    } finally {\n        trace.commit();\n    }\n}", "CodeBleu_score": 31.680325543377364}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t  final ZooKeeper zk = getZooKeeper();\n  final String method = \"pathInForeground\";\n  final String traceName = \"path-in-foreground\";\n  final String traceDescription = \"Set ACL for path \" + path;\n  final TraceScope scope = Trace.startSpan(traceName, SamplingFlags.SAMPLED);\n  try {\n    scope.getSpan().setTag(\"path\", path);\n    scope.getSpan().setTag(\"acl\", aclList);\n    final RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n    final Callable<Stat> callable = new Callable<Stat>() {\n      public Stat call() throws Exception {\n        return zk.setACL(path, aclList, -1);\n      }\n    };\n    final RetryCallback<Stat> callback = new RetryCallback<Stat>() {\n      public Stat doWithRetry(RetryContext context) throws Exception {\n        return callable.call();\n      }\n    };\n    final Stat stat = retryTemplate.execute(retryPolicy, callback);\n    scope.getSpan().setTag(\"status\", \"success\");\n    scope.close();\n    return stat;\n  } catch (Exception e) {\n    scope.getSpan().setTag(\"status\", \"failure\");\n    scope.close();\n    throw e;\n  }\n}", "CodeBleu_score": 41.974199096504414}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t    checkNotNull(client, \"client cannot be null\");\n    checkNotNull(membershipPath, \"membershipPath cannot be null\");\n    checkNotNull(thisId, \"thisId cannot be null\");\n    checkNotNull(payload, \"payload cannot be null\");\n\n    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.payload = payload;\n\n    try {\n        this.cache = CuratorCache.build(client, membershipPath);\n    } catch (Exception e) {\n        throw new IllegalStateException(\"Could not create cache for path: \" + membershipPath, e);\n    }\n\n    try {\n        this.memberNode = new PersistentNode(client, makePath(membershipPath, thisId), CreateMode.EPHEMERAL, payload);\n        this.memberNode.start();\n    } catch (Exception e) {\n        throw new IllegalStateException(\"Could not create persistent node for path: \" + makePath(membershipPath, thisId), e);\n    }\n}", "CodeBleu_score": 45.98838366349565}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tcheckNotNull(client, \"client cannot be null\");\n\tcheckNotNull(membershipPath, \"membershipPath cannot be null\");\n\tcheckNotNull(thisId, \"thisId cannot be null\");\n\tcheckNotNull(payload, \"payload cannot be null\");\n\n\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\n\tcheckMemberId(thisId);\n\n\tthis.cache = CuratorCache.build(client, membershipPath);\n\tthis.cache.start();\n\n\ttry {\n\t\tthis.node = PersistentNode.builder(client, makePath(thisId)).ephemeral().data(payload).build();\n\t\tthis.node.start();\n\t} catch (Exception e) {\n\t\tthrow new IllegalStateException(\"Could not create PersistentNode for member \" + thisId, e);\n\t}\n}", "CodeBleu_score": 47.72890324211101}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tcheckNotNull(client, \"client cannot be null\");\n\tcheckNotNull(membershipPath, \"membershipPath cannot be null\");\n\tcheckNotNull(thisId, \"thisId cannot be null\");\n\tcheckNotNull(payload, \"payload cannot be null\");\n\n\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\n\tcheckArgument(thisId.matches(VALID_ID_REGEX), \"thisId must match regex \" + VALID_ID_REGEX);\n\n\tthis.cache = CuratorCache.build(client, membershipPath);\n\tthis.cache.start();\n\n\tthis.memberNode = PersistentNode.builder(client, makePath(membershipPath, thisId), payload).ephemeral().build();\n\tthis.memberNode.start();\n}", "CodeBleu_score": 46.93138981892222}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    try {\n        client.create().forPath(path);\n        System.out.println(\"Path created: \" + path);\n        client.getData().usingWatcher(new MyWatcher()).forPath(path);\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}", "CodeBleu_score": 30.814784654279254}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    try {\n        client.create().forPath(path);\n        System.out.println(\"Node \" + path + \" created\");\n        client.getData().usingWatcher(new MyWatcher()).forPath(path);\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}", "CodeBleu_score": 30.939761523879604}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    try {\n        client.create().forPath(path);\n        System.out.println(\"Created \" + path);\n        client.getData().usingWatcher(new MyWatcher()).forPath(path);\n        System.out.println(\"Set watcher on \" + path);\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}", "CodeBleu_score": 35.34684379024039}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t    List<OpResult> results = zk.multi(ops);\n    if (results.get(0).getErr() != 0) {\n        throw KeeperException.create(KeeperException.Code.get(results.get(0).getErr()));\n    }\n    return results;\n}", "CodeBleu_score": 17.095197916586866}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t  List<OpResult> results = client.multi(ops);\n  if (results.size() > 0) {\n    OpResult first = results.get(0);\n    if (first instanceof ErrorResult) {\n      throw KeeperException.create(((ErrorResult) first).getErr());\n    }\n  }\n  return results;\n}", "CodeBleu_score": 26.09448572468191}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t    List<OpResult> results = null;\n    int count = 0;\n    while (true) {\n        try {\n            results = getZooKeeper().multi(ops);\n            break;\n        } catch (KeeperException.ConnectionLossException e) {\n            if (count++ == maxRetries) {\n                throw e;\n            }\n        }\n    }\n    if (results == null) {\n        return null;\n    }\n    if (results.size() == 0) {\n        return results;\n    }\n    OpResult first = results.get(0);\n    if (first.getType() == OpResult.ERROR) {\n        int code = getErrorCode(first.getErr());\n        throw KeeperException.create(KeeperException.Code.get(code),\n                \"Multi transaction failed, results: \" + results);\n    }\n    return results;\n}", "CodeBleu_score": 41.90399536787098}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    // Query for all service names.\n    List<String> serviceNames = serviceDiscovery.queryForNames();\n\n    // Query for all instances of each service name.\n    for (String serviceName : serviceNames) {\n        List<InstanceDetails> instances = serviceDiscovery.queryForInstances(serviceName);\n\n        // Print the service name and its instances.\n        System.out.println(serviceName + \": \" + instances);\n    }\n\n    // Close the ServiceDiscovery instance quietly.\n    serviceDiscovery.closeQuietly();\n}", "CodeBleu_score": 32.49017850455091}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    // Query for all service names\n    List<String> serviceNames = serviceDiscovery.queryForNames();\n    // For each service name\n    for (String serviceName : serviceNames) {\n        // Query for all instances of the service\n        List<InstanceDetails> instances = serviceDiscovery.queryForInstances(serviceName);\n        // If there are instances\n        if (instances.size() > 0) {\n            // For each instance\n            for (InstanceDetails instance : instances) {\n                // Print the instance\n                outputInstance(instance);\n            }\n        }\n        // Otherwise\n        else {\n            // Catch the NoNodeException and print an error message\n            System.out.println(\"No instances found for service \" + serviceName);\n        }\n    }\n    // Close the ServiceDiscovery instance quietly\n    serviceDiscovery.closeQuietly();\n}", "CodeBleu_score": 47.759305546511364}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    // Query for all service names\n    List<String> serviceNames = serviceDiscovery.queryForNames();\n\n    // Iterate through the service names\n    for (String serviceName : serviceNames) {\n        // Query for all instances of the service name\n        List<InstanceDetails> serviceInstances = serviceDiscovery.queryForInstances(serviceName);\n\n        // Print the service name\n        System.out.println(\"Service name: \" + serviceName);\n\n        // Print the instances of the service name\n        for (InstanceDetails serviceInstance : serviceInstances) {\n            System.out.println(\"Service instance: \" + serviceInstance);\n        }\n    }\n\n    // Close the ServiceDiscovery instance quietly\n    serviceDiscovery.closeQuietly();\n}", "CodeBleu_score": 39.98064242893066}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t  List<String> filteredChildren = children.findAll { it != READY_NODE }\n  return filteredChildren.sort()\n}", "CodeBleu_score": 12.529327249342812}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t    return children.findAll { it != READY_NODE }.sort()\n}", "CodeBleu_score": 9.146609653854949}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t  return children.findAll { !it.equals(READY_NODE) }.sort()\n}", "CodeBleu_score": 13.496380525458834}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t    if (zk != null) {\n        zk.close();\n    }\n    zk = new ZooKeeper(newHost, 30000, this);\n    zk.register(this);\n}", "CodeBleu_score": 24.28535764757653}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\t// Close the existing connection, if any.\n\tif (zk != null) {\n\t\tzk.close();\n\t}\n\t// Create a new connection.\n\tzk = new ZooKeeper(newHost, 3000, this);\n\t// Wait until we're connected to the new host.\n\twhile (true) {\n\t\tif (zk.getState() == States.CONNECTED) {\n\t\t\tbreak;\n\t\t}\n\t\tThread.sleep(1000);\n\t}\n\t// Set the read-only mode if the -readonly command-line option is set.\n\tif (readOnly) {\n\t\tzk.setReadOnly();\n\t}\n}", "CodeBleu_score": 28.030363185677555}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t    if (zk != null && zk.getState() != ZooKeeper.States.CLOSED) {\n        zk.close();\n    }\n    zk = new ZooKeeper(newHost, CONNECTION_TIMEOUT, this);\n    while (zk.getState() != ZooKeeper.States.CONNECTED) {\n        Thread.sleep(1000);\n    }\n    if (readOnly) {\n        zk.setReadOnly();\n    }\n}", "CodeBleu_score": 37.96970529763916}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> acls = new ArrayList<ACL>();\n    for (String acl : aclString.split(\",\")) {\n        try {\n            ACL aclObj = new ACL();\n            int firstColon = acl.indexOf(\":\");\n            int lastColon = acl.lastIndexOf(\":\");\n            if (firstColon == -1 || lastColon == -1 || firstColon == lastColon) {\n                throw new IOException(\"Invalid ACL found: \" + acl);\n            }\n            aclObj.setPerms(getPermFromString(acl.substring(lastColon + 1)));\n            aclObj.setId(new Id(acl.substring(0, firstColon), acl.substring(firstColon + 1, lastColon)));\n            acls.add(aclObj);\n        } catch (IOException e) {\n            LOG.warn(\"Invalid ACL found: \" + acl);\n        }\n    }\n    return acls;\n}", "CodeBleu_score": 58.381530119106586}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> aclList = new ArrayList<ACL>();\n    String[] aclArray = aclString.split(\",\");\n    for (String acl : aclArray) {\n        try {\n            ACL aclObj = new ACL();\n            String[] idPerm = acl.split(\":\");\n            if (idPerm.length != 3) {\n                throw new IOException(\"Invalid ACL string: \" + acl);\n            }\n            aclObj.setPerms(getPermFromString(idPerm[2]));\n            aclObj.setId(new Id(idPerm[0], idPerm[1]));\n            aclList.add(aclObj);\n        } catch (IOException e) {\n            LOG.error(\"Invalid ACL string: \" + acl);\n        }\n    }\n    return aclList;\n}", "CodeBleu_score": 32.457531716646464}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> aclList = new ArrayList<ACL>();\n    if (aclString != null && !aclString.isEmpty()) {\n        String[] aclArray = aclString.split(\",\");\n        for (String acl : aclArray) {\n            try {\n                ACL aclObj = new ACL();\n                int firstColon = acl.indexOf(':');\n                int lastColon = acl.lastIndexOf(':');\n                if (firstColon == -1 || lastColon == -1 || firstColon == lastColon) {\n                    throw new IOException(\"Invalid ACL string: \" + acl);\n                }\n                aclObj.setPerms(getPermFromString(acl.substring(lastColon + 1)));\n                aclObj.setId(new Id(acl.substring(0, firstColon), acl.substring(firstColon + 1, lastColon)));\n                aclList.add(aclObj);\n            } catch (Exception e) {\n                LOG.error(\"Invalid ACL string: \" + acl + \" -- exception: \" + e);\n            }\n        }\n    }\n    return aclList;\n}", "CodeBleu_score": 55.60160742199576}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    requireNonNull(pathList, \"pathList is null\");\n    assertZookeeperExists(serverId);\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            delete(serverId, path);\n        }\n    }\n    else {\n        List<CompletableFuture<Void>> futures = new ArrayList<>(pathList.size());\n        for (String path : pathList) {\n            futures.add(deleteAsync(serverId, path));\n        }\n        CompletableFuture.allOf(futures.toArray(new CompletableFuture<?>[0])).join();\n    }\n}", "CodeBleu_score": 55.72497210051396}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t\trequireNonNull(pathList, \"The path list must not be null.\");\n\tassertZookeeperExists(serverId);\n\n\tif (pathList.size() < 20) {\n\t\tfor (String path : pathList) {\n\t\t\tdeleteAsync(serverId, path).get();\n\t\t}\n\t} else {\n\t\tList<CompletableFuture<Void>> futures = new ArrayList<>();\n\t\tfor (String path : pathList) {\n\t\t\tfutures.add(deleteAsync(serverId, path));\n\t\t}\n\n\t\tfor (CompletableFuture<Void> future : futures) {\n\t\t\tfuture.get();\n\t\t}\n\t}\n}", "CodeBleu_score": 54.26782195664305}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t  requireNonNull(pathList, \"pathList is null\");\n  assertZookeeperExists(serverId);\n  if (pathList.size() < 20) {\n    for (String path : pathList) {\n      delete(serverId, path);\n    }\n  } else {\n    deleteAsync(serverId, pathList);\n  }\n}", "CodeBleu_score": 61.01566217666016}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t    writer.write(\"Connecting to \" + url + \"...\");\n    writer.flush();\n    ZookeeperClientFactory factory = new CuratorZookeeperConnectionFactory();\n    ZookeeperClient connection = factory.connect(url);\n    writer.write(\"Successfully connected to \" + url + \".\n\");\n    ZooKeeperMain main = new ZooKeeperMain(connection);\n    return new Terminal(id, url, connection, main);\n}", "CodeBleu_score": 42.0371909876974}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t    writer.write(\"Connecting to Zookeeper at \" + url + \" ...\");\n    writer.flush();\n    ZookeeperFactory.ZookeeperConnection connection = ZookeeperFactory.createConnection(url);\n    connection.start();\n    writer.write(\"Successfully connected to Zookeeper at \" + url + \".\n\");\n    writer.flush();\n    ZooKeeperMain zkMain = new ZooKeeperMain();\n    zkMain.setZookeeperConnection(connection);\n    return new Terminal(id, url, connection, zkMain);\n}", "CodeBleu_score": 40.884290980273434}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t\n    writer.write(\"Connecting to \" + url + \" ... \");\n    writer.flush();\n\n    CuratorFramework curator = CuratorZookeeperConnectionFactory.create(url, 10000, 10000);\n\n    writer.write(\"Success!\n\");\n    writer.flush();\n\n    ZooKeeperMain zk = new ZooKeeperMain(curator);\n\n    return new Terminal(id, url, curator, zk);\n}", "CodeBleu_score": 32.74582792686107}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\t\tint retryCount = 0;\n\twhile (retryCount < 6) {\n\t\ttry {\n\t\t\tif (isConnected()) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tretryCount++;\n\t\t\t\tsleep(1000);\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tclose();\n\t\t\tthrow new IllegalStateException(\"Failed to establish SSH connection after \" + retryCount + \" retries.\", e);\n\t\t}\n\t}\n\tclose();\n\tthrow new IllegalStateException(\"Failed to establish SSH connection after \" + retryCount + \" retries.\");\n}", "CodeBleu_score": 38.66052632318382}, {"code": "public void blockUntilConnected(){\n\t  try {\n    int retries = 0;\n    while (!isConnected()) {\n      try {\n        info(\"Attempting to connect...\");\n        connect();\n      } catch (Exception e) {\n        if (retries++ > 5) {\n          throw new IllegalStateException(\"Failed to connect after \" + retries + \" attempts\", e);\n        }\n        info(\"Failed to connect: \" + e.getMessage());\n        sleep(1000);\n      }\n    }\n  } catch (Exception e) {\n    close();\n    throw new IllegalStateException(\"Failed to connect\", e);\n  }\n}", "CodeBleu_score": 47.375207728635026}, {"code": "public void blockUntilConnected(){\n\t    int retries = 0;\n    while (retries < 6) {\n        try {\n            if (isConnected()) {\n                return;\n            }\n            connect();\n            return;\n        } catch (Exception e) {\n            close();\n            retries++;\n            if (retries < 6) {\n                log.info(\"Failed to connect to SSH server.  Retrying in 1 second.\");\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e1) {\n                    // Ignore\n                }\n            }\n        }\n    }\n    throw new IllegalStateException(\"Unable to connect to SSH server.\");\n}", "CodeBleu_score": 47.54704095335796}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        logger.error(\"Exception while deleting nodes from Zookeeper: \" + e.getMessage());\n        throw new IllegalStateException(\"Error while deleting nodes from Zookeeper.\");\n    }\n}", "CodeBleu_score": 57.39102720818258}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tLOG.error(\"Error deleting node from Zookeeper: \" + e.getMessage());\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 65.04787152012479}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tLOG.error(\"Error deleting node from Zookeeper: \" + e.getMessage());\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 65.04787152012479}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\t    if (id == null) {\n        return;\n    }\n    Task<Void> task = new Task<Void>() {\n        @Override\n        protected Void call() throws Exception {\n            ServerConfiguration serverConfiguration = getById(id);\n            if (serverConfiguration != null) {\n                serverConfiguration.disconnect();\n                remove(serverConfiguration);\n            }\n            return null;\n        }\n    };\n    runLater(task);\n}", "CodeBleu_score": 40.235580538303886}, {"code": "public void disconnect(String id){\n\t    Task<Server> task = new Task<Server>() {\n        @Override\n        protected Server call() throws Exception {\n            Server server = serverTreeItemCache.getById(id);\n            if (server != null) {\n                server.disconnect();\n            }\n            return server;\n        }\n    };\n    task.setOnSucceeded(event -> {\n        Server server = task.getValue();\n        if (server != null) {\n            serverTreeItemCache.remove(server.getId());\n        }\n    });\n    task.setOnFailed(event -> {\n        Server server = task.getValue();\n        if (server != null) {\n            serverTreeItemCache.remove(server.getId());\n        }\n    });\n    new Thread(task).start();\n}", "CodeBleu_score": 34.23189313971024}, {"code": "public void disconnect(String id){\n\t    if (id == null) {\n        return;\n    }\n\n    // get the server configuration from the cache\n    ServerConfiguration server = getById(id);\n\n    // if the server is null, return\n    if (server == null) {\n        return;\n    }\n\n    // run the task on the JavaFX application thread\n    Platform.runLater(() -> {\n        // disconnect from Zookeeper\n        try {\n            ZookeeperClient.getInstance().disconnect(server.getId());\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n\n        // remove the server from the cache\n        remove(id);\n    });\n}", "CodeBleu_score": 33.36627623724989}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    Server server = getServerById(serverId);\n    String url = getUrl(server);\n    zookeeperDomainService.startTerminal(serverId, url, stream);\n}", "CodeBleu_score": 17.799720981282025}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    Server server = getServerById(serverId);\n    String host = getHost(server);\n    int port = getPort(server);\n    boolean sshTunnelEnabled = getSshTunnelEnabled(server);\n    String connectionUrl = getConnectionUrl(host, port, sshTunnelEnabled);\n    zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 33.38290197505355}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    Server server = serverService.getById(serverId)\n        .orElseThrow(() -> new RuntimeException(\"Server with ID \" + serverId + \" not found\"));\n    String host = server.getHost();\n    int port = server.getPort();\n    boolean sshTunnelEnabled = server.getSshTunnelEnabled();\n    String url = sshTunnelEnabled ? \"localhost:\" + port : host + \":\" + port;\n    zookeeperDomainService.startTerminal(serverId, url, stream);\n}", "CodeBleu_score": 44.638976523959535}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t  try {\n    String response = Zookeeper.executeCommand(id, command);\n    if (response != null) {\n      println(response);\n    }\n  } catch (Exception e) {\n    println(\"Error executing command on server \" + id + \":\n\" + command + \"\n\" + e.getMessage());\n  }\n}", "CodeBleu_score": 49.287520595338876}, {"code": "public void executeCommand(String id, String command){\n\t    try {\n        ZooKeeper zk = new ZooKeeper(id, 3000, this);\n        zk.create(\"/test\", \"test\".getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n        System.out.println(\"Successfully executed command on server \" + id);\n    } catch (Exception e) {\n        System.out.println(\"Error executing command on server \" + id + \": \" + e);\n        e.printStackTrace();\n        System.out.println(\"Error executing command on server \" + id + \": \" + e);\n        displayErrorMessage(\"Error executing command on server \" + id + \": \" + e);\n    }\n}", "CodeBleu_score": 38.93708257784721}, {"code": "public void executeCommand(String id, String command){\n\t    try {\n        CommandResult result = execute(id, command);\n        if (result.getCode() != 0) {\n            log.error(\"Command failed: \" + command + \" with code: \" + result.getCode());\n            throw new RuntimeException(\"Command execution failed. Please retry.\");\n        }\n    } catch (Exception e) {\n        log.error(\"Command failed: \" + command + \" with exception: \" + e.getMessage());\n        throw new RuntimeException(\"Command execution failed. Please retry.\");\n    }\n}", "CodeBleu_score": 41.27307224724947}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\t  Properties props = new Properties();\n  String zookeeperPropertiesFilePath = System.getProperty(ZOOKEEPER_PROPERTIES_FILE_PATH_PROPERTY);\n  if (zookeeperPropertiesFilePath != null) {\n    File zookeeperPropertiesFile = new File(zookeeperPropertiesFilePath);\n    if (zookeeperPropertiesFile.exists()) {\n      try {\n        props.load(new FileInputStream(zookeeperPropertiesFile));\n        log.info(\"Loaded Zookeeper system properties from {}\", zookeeperPropertiesFile.getAbsolutePath());\n      } catch (IOException e) {\n        log.error(\"Unable to load Zookeeper system properties from {}\", zookeeperPropertiesFile.getAbsolutePath(), e);\n      }\n    } else {\n      log.warn(\"Unable to load Zookeeper system properties from {}. File does not exist.\", zookeeperPropertiesFile.getAbsolutePath());\n    }\n  } else {\n    log.warn(\"Unable to load Zookeeper system properties. {} system property is not set.\", ZOOKEEPER_PROPERTIES_FILE_PATH_PROPERTY);\n  }\n  return props;\n}", "CodeBleu_score": 40.49944596074001}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t    Properties properties = new Properties();\n    try {\n        String zookeeperPropertiesFile = System.getProperty(ZOOKEEPER_PROPERTIES_FILE);\n        if (zookeeperPropertiesFile == null) {\n            zookeeperPropertiesFile = ZOOKEEPER_PROPERTIES_FILE_DEFAULT;\n        }\n        if (exists(zookeeperPropertiesFile)) {\n            InputStream is = new FileInputStream(zookeeperPropertiesFile);\n            properties.load(is);\n            is.close();\n            log.info(\"Zookeeper system properties loaded from: \" + zookeeperPropertiesFile);\n        } else {\n            log.info(\"Zookeeper system properties file does not exist: \" + zookeeperPropertiesFile);\n        }\n    } catch (IOException e) {\n        log.error(\"Error loading Zookeeper system properties file: \" + e.getMessage());\n    }\n    return properties;\n}", "CodeBleu_score": 40.131219185116315}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t    Properties props = new Properties();\n    String filePath = System.getProperty(ZOOKEEPER_PROPERTIES_FILE_PATH_KEY);\n    if (filePath == null || filePath.isEmpty()) {\n        log.info(\"No system properties file path specified. Skipping loading system properties.\");\n        return props;\n    }\n    File file = new File(filePath);\n    if (!file.exists()) {\n        log.info(\"System properties file does not exist. Skipping loading system properties.\");\n        return props;\n    }\n    try {\n        props.load(new FileInputStream(file));\n        log.info(\"Loaded system properties: \" + props);\n    } catch (IOException e) {\n        log.error(\"Error loading system properties file \" + filePath, e);\n    }\n    return props;\n}", "CodeBleu_score": 43.30429209427519}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\t    try {\n        Properties props = new Properties();\n        props.load(new StringReader(content));\n        FileOutputStream out = new FileOutputStream(SYS_PROP_PATH);\n        props.store(out, \"Zookeeper system properties\");\n        out.close();\n    } catch (IOException e) {\n        log.error(\"Failed to save Zookeeper system properties\", e);\n        showNotification(\"Failed to save Zookeeper system properties\", e.getMessage(), NotificationType.ERROR_MESSAGE);\n    }\n}", "CodeBleu_score": 28.44440386391985}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\ttry {\n\t\tProperties properties = new Properties();\n\t\tproperties.load(new StringReader(content));\n\t\tFileOutputStream fileOutputStream = new FileOutputStream(SYS_PROP_PATH);\n\t\tproperties.store(fileOutputStream, \"Zookeeper system properties\");\n\t\tfileOutputStream.close();\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error saving Zookeeper system properties\", e);\n\t\tshowNotification(\"Error saving Zookeeper system properties\", e.getMessage(), NotificationType.ERROR_MESSAGE);\n\t}\n}", "CodeBleu_score": 27.409175987364858}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t    Properties props = new Properties();\n    try {\n        props.load(new StringReader(content));\n    } catch (IOException e) {\n        log.error(\"Failed to load properties from content\", e);\n        Notification.show(\"Failed to load properties from content\", e.getMessage(), Notification.Type.ERROR_MESSAGE);\n        return;\n    }\n    FileOutputStream fos = null;\n    try {\n        fos = new FileOutputStream(SYS_PROP_PATH);\n        props.store(fos, \"Zookeeper system properties\");\n    } catch (FileNotFoundException e) {\n        log.error(\"Failed to open file for writing\", e);\n        Notification.show(\"Failed to open file for writing\", e.getMessage(), Notification.Type.ERROR_MESSAGE);\n    } catch (IOException e) {\n        log.error(\"Failed to write to file\", e);\n        Notification.show(\"Failed to write to file\", e.getMessage(), Notification.Type.ERROR_MESSAGE);\n    } finally {\n        if (fos != null) {\n            try {\n                fos.close();\n            } catch (IOException e) {\n                log.error(\"Failed to close file\", e);\n            }\n        }\n    }\n}", "CodeBleu_score": 39.81401038902943}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\t    try {\n        BufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n        StringBuilder response = new StringBuilder();\n        String inputLine;\n        while ((inputLine = in.readLine()) != null) {\n            response.append(inputLine);\n        }\n        in.close();\n        client.close();\n        return response.toString();\n    } catch (IOException e) {\n        throw new IllegalStateException(\"Error reading from client\", e);\n    }\n}", "CodeBleu_score": 52.61799181842982}, {"code": "private String response(Socket client){\n\t    try {\n        StringBuilder response = new StringBuilder();\n        BufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n        String inputLine;\n        while ((inputLine = in.readLine()) != null) {\n            response.append(inputLine);\n        }\n        in.close();\n        client.close();\n        return response.toString();\n    } catch (IOException e) {\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 58.16830175069485}, {"code": "private String response(Socket client){\n\t    try {\n        InputStream is = client.getInputStream();\n        BufferedReader reader = new BufferedReader(new InputStreamReader(is));\n        StringBuilder response = new StringBuilder();\n        String line;\n        while ((line = reader.readLine()) != null) {\n            response.append(line);\n            response.append('\n');\n        }\n        return response.toString();\n    } catch (Exception e) {\n        throw new IllegalStateException(e);\n    } finally {\n        try {\n            client.close();\n        } catch (IOException e) {\n            throw new IllegalStateException(e);\n        }\n    }\n}", "CodeBleu_score": 55.31346642036505}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t    CuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(params.getZookeeperConnectString(), params.getSessionTimeoutMs(), params.getConnectionTimeoutMs(), new ExponentialBackoffRetry(params.getBaseSleepTimeMs(), params.getMaxRetries()));\n    curatorFramework.start();\n    try {\n        blockUntilConnected(curatorFramework, params.getConnectionTimeoutMs());\n    } catch (Exception e) {\n        curatorFramework.close();\n        throw new RuntimeException(e);\n    }\n    return new CuratorZookeeperConnection(params, curatorFramework);\n}", "CodeBleu_score": 40.26619785481945}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t  CuratorFramework curatorFramework = null;\n  try {\n    curatorFramework = CuratorFrameworkFactory.builder()\n      .connectString(params.getConnectString())\n      .retryPolicy(new ExponentialBackoffRetry(params.getBaseSleepTimeMs(), params.getMaxRetries()))\n      .build();\n    curatorFramework.start();\n    if (!curatorFramework.blockUntilConnected(params.getConnectionTimeoutMs(), TimeUnit.MILLISECONDS)) {\n      throw new RuntimeException(\"Unable to connect to Zookeeper within \" + params.getConnectionTimeoutMs() + \" ms\");\n    }\n    return new CuratorZookeeperConnection(curatorFramework);\n  } catch (Exception e) {\n    if (curatorFramework != null) {\n      curatorFramework.close();\n    }\n    throw new RuntimeException(e);\n  }\n}", "CodeBleu_score": 37.17264473039389}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t  CuratorFramework client = createCuratorFramework(params);\n  start(client);\n  waitUntilConnected(client);\n  return new CuratorZookeeperConnection(client, params);\n}", "CodeBleu_score": 28.924992815033328}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t    String connectionString = getZookeeperClient().getCurrentConnectionString();\n    if (connectionString == null) {\n        throw new IllegalStateException(\"Zookeeper client connection string is null\");\n    }\n    if (getListenable().isSynchronizing()) {\n        info(\"Synchronization already in progress\");\n        return;\n    }\n    debug(\"Starting synchronization\");\n    CuratorTreeCacheListener curatorTreeCacheListener = new CuratorTreeCacheListener(getId(), listeners);\n    getListenable().setSynchronizing(true);\n    try {\n        getTreeCache().getListenable().addListener(curatorTreeCacheListener);\n        getTreeCache().start();\n        getListenable().setSynchronizing(false);\n        debug(\"Synchronization complete\");\n    } catch (Exception e) {\n        getListenable().setSynchronizing(false);\n        error(\"Error synchronizing\", e);\n        close();\n    }\n}", "CodeBleu_score": 39.632180955639576}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t  if (isSynchronizing.compareAndSet(false, true)) {\n    try {\n      info(\"Starting synchronization of Zookeeper nodes\");\n      addListener(listeners);\n      start();\n    } catch (Exception e) {\n      error(\"An error occurred while synchronizing Zookeeper nodes\", e);\n      close();\n    }\n  } else {\n    info(\"Synchronization of Zookeeper nodes already in progress\");\n  }\n}", "CodeBleu_score": 25.20973697817871}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t  if (isSyncing()) {\n    logger.info(\"Synchronization already in progress.\");\n    return;\n  }\n  logger.debug(\"Starting synchronization.\");\n  String connectionString = getZookeeperClient().getCurrentConnectionString();\n  if (connectionString == null) {\n    logger.error(\"Could not retrieve current Zookeeper connection string.\");\n    return;\n  }\n  setSyncing(true);\n  CuratorTreeCacheListener treeCacheListener = new CuratorTreeCacheListener(listeners);\n  try {\n    getListenable().addListener(treeCacheListener);\n    get().start();\n  } catch (Exception e) {\n    logger.error(\"Error starting TreeCache.\", e);\n    close();\n  }\n}", "CodeBleu_score": 43.574281385980285}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache cache = new PathChildrenCache(zkClient, path, true);\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    cache.getListenable().addListener(listener);\n}", "CodeBleu_score": 63.281917989010154}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache childrenCache = new PathChildrenCache(zk, path, true);\n    childrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    childrenCache.getListenable().addListener(listener);\n}", "CodeBleu_score": 65.3100363599804}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    // Create a PathChildrenCache for the given path.\n    PathChildrenCache cache = new PathChildrenCache(zkConnection, path, true);\n    // Start the cache in BUILD_INITIAL_CACHE mode.\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    // Add a listener to handle child node events.\n    cache.getListenable().addListener(listener);\n}", "CodeBleu_score": 63.22230240506227}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t    try {\n        logger.info(\"Starting unregistration process\");\n        for (String path : paths) {\n            try {\n                client.delete().forPath(path);\n            } catch (Exception e) {\n                logger.error(e.getMessage());\n            }\n        }\n        logger.info(\"Unregistration process complete\");\n    } catch (Exception e) {\n        logger.error(e.getMessage());\n    } finally {\n        try {\n            client.close();\n        } catch (Exception e) {\n            logger.error(e.getMessage());\n        }\n    }\n}", "CodeBleu_score": 42.83694733696997}, {"code": "public void unregisterService(){\n\t\tlogger.info(\"Unregistering all services\");\n\tfor (String path : paths) {\n\t\ttry {\n\t\t\tclient.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Error deleting \" + path + \" from Zookeeper\", e);\n\t\t}\n\t}\n\ttry {\n\t\tclient.close();\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error closing Curator client\", e);\n\t}\n}", "CodeBleu_score": 48.9824515182604}, {"code": "public void unregisterService(){\n\t    LOGGER.info(\"Unregistering services...\");\n    for (String path : paths) {\n        try {\n            curator.delete().forPath(path);\n            LOGGER.info(\"Deleted {}\", path);\n        } catch (Exception e) {\n            LOGGER.error(\"Error unregistering service: {}\", e.getMessage());\n        }\n    }\n    LOGGER.info(\"Unregistered services\");\n    try {\n        curator.close();\n        LOGGER.info(\"Closed Curator client\");\n    } catch (Exception e) {\n        LOGGER.error(\"Error closing Curator client: {}\", e.getMessage());\n    }\n}", "CodeBleu_score": 43.27227082721147}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\t    CompletableFuture<Void> future = new CompletableFuture<>();\n    future.whenComplete(this::subscribeStateChanges);\n    future.whenComplete(this::makeClientReady);\n    future.complete(null);\n}", "CodeBleu_score": 26.052598038612846}, {"code": "public void addListener(IZkStateListener listener){\n\t    try {\n        makeClientReady().thenAccept(x -> subscribeStateChanges(listener));\n    } catch (Exception e) {\n        throw new ZkClientException(\"Failed to add listener\", e);\n    }\n}", "CodeBleu_score": 25.80008987696466}, {"code": "public void addListener(IZkStateListener listener){\n\t    try {\n        makeClientReady().thenAccept(v -> {\n            subscribeStateChanges(listener);\n        });\n    } catch (Exception e) {\n        throw new RuntimeException(\"Failed to add listener\", e);\n    }\n}", "CodeBleu_score": 28.851683268149674}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t  this(serverAddr, authority, new ExponentialBackoffRetry(1000, 3));\n}", "CodeBleu_score": 3.6881796198560273}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t  this(serverAddr, authority, null, null, null, null, null, null, null, null, null, null, null, null, null);\n}", "CodeBleu_score": 3.801306855821408}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t  this(serverAddr, authority, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null, null", "CodeBleu_score": 4.629182383930094}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t    if (path == null) {\n        throw new NullPointerException(\"Path must not be null\");\n    }\n    if (listener == null) {\n        throw new NullPointerException(\"Listener must not be null\");\n    }\n    if (listeners.containsKey(path)) {\n        listeners.get(path).remove(listener);\n        if (listeners.get(path).isEmpty()) {\n            listeners.remove(path);\n            try {\n                zooKeeper.getChildren(path, true);\n            } catch (KeeperException e) {\n                e.printStackTrace();\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}", "CodeBleu_score": 34.85154591799272}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t    if (listener == null) {\n        throw new NullPointerException(\"listener must not be null\");\n    }\n    if (path == null) {\n        throw new NullPointerException(\"path must not be null\");\n    }\n    if (path.length() == 0) {\n        throw new IllegalArgumentException(\"path must not be empty\");\n    }\n    if (!path.startsWith(\"/\")) {\n        throw new IllegalArgumentException(\"path must start with / character\");\n    }\n    try {\n        retryUntilConnected(new Callable<Void>() {\n            @Override\n            public Void call() throws Exception {\n                getConnection().removeChildListener(path, listener);\n                return null;\n            }\n        });\n    } catch (Exception e) {\n        throw new ZooKeeperClientException(\"Error while removing child listener\", e);\n    }\n}", "CodeBleu_score": 24.11549414392847}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t    if (path == null) {\n        throw new NullPointerException(\"Path must not be null\");\n    }\n    if (listener == null) {\n        throw new NullPointerException(\"Listener must not be null\");\n    }\n    try {\n        retryUntilConnected(new Callable<Void>() {\n            @Override\n            public Void call() throws Exception {\n                getConnection().removeChildListener(path, listener);\n                return null;\n            }\n        });\n    } catch (Exception e) {\n        throw ZooKeeperClientException.create(e);\n    }\n}", "CodeBleu_score": 28.36960419892819}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t  if (zh == NULL) {\n    return -1;\n  }\n\n  char *idc_host = lock_ht_find(zh);\n  if (idc_host == NULL) {\n    return -1;\n  }\n  lock_ht_delete(zh);\n\n  char *idc_str = NULL;\n  char *host_str = NULL;\n  deserialize_from_idc_host(idc_host, &idc_str, &host_str);\n  free(idc_host);\n\n  if (idc_str == NULL || host_str == NULL) {\n    return -1;\n  }\n\n  zookeeper_close(zh);\n  zh = zookeeper_init(host_str, watcher_zk_completion, 10000, 0, 0, 0);\n  if (zh == NULL) {\n    LOG_ERR(\"Failed to reconnect to zookeeper host %s\", host_str);\n    return -1;\n  }\n\n  init_env_for_zk(zh, idc_str);\n  reset_table_watcher(zh);\n  return 0;\n}", "CodeBleu_score": 24.49334501461669}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t    char *idc_host_str;\n    char *idc_host_deserialized;\n    char *host_deserialized;\n    int idc_host_len;\n    int host_len;\n    int rc;\n\n    if (zh == NULL) {\n        return ZOOKEEPER_ERROR;\n    }\n\n    idc_host_str = lock_ht_find(zookeeper_idc_host_table, zh);\n    if (idc_host_str == NULL) {\n        return ZOOKEEPER_ERROR;\n    }\n\n    lock_ht_delete(zookeeper_idc_host_table, zh);\n\n    idc_host_len = deserialize_from_idc_host(idc_host_str, &idc_host_deserialized);\n    if (idc_host_len == 0) {\n        return ZOOKEEPER_ERROR;\n    }\n\n    host_len = deserialize_from_idc_host(idc_host_deserialized, &host_deserialized);\n    if (host_len == 0) {\n        return ZOOKEEPER_ERROR;\n    }\n\n    rc = zookeeper_close(zh);\n    if (rc != ZOK) {\n        LOG_ERR(\"Failed to close old ZooKeeper handle\");\n        return ZOOKEEPER_ERROR;\n    }\n\n    zh = zookeeper_init(host_deserialized, watcher_global_watcher, 10000, 0, 0, 0);\n    if (zh == NULL) {\n        return ZOOKEEPER_ERROR;\n    }\n\n    init_env_for_zk(zh, idc_host_deserialized, idc_host_len);\n    rc = zoo_w_table_watcher(zh);\n    if (rc != ZOK) {\n        return ZOOKEEPER_ERROR;\n    }\n\n    return ZOK;\n}", "CodeBleu_score": 43.76546354004985}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t    if (zh == NULL) {\n        LOG_ERR(\"ZooKeeper handle is NULL\");\n        return -1;\n    }\n\n    char *idc_host_info = NULL;\n    idc_host_info = lock_ht_find(zh);\n    if (idc_host_info == NULL) {\n        LOG_ERR(\"IDC host info is NULL\");\n        return -1;\n    }\n\n    lock_ht_delete(zh);\n    zookeeper_close(zh);\n\n    struct zookeeper_idc_host *idc_host = deserialize_from_idc_host(idc_host_info);\n    if (idc_host == NULL) {\n        LOG_ERR(\"Deserialized IDC host is NULL\");\n        return -1;\n    }\n\n    zh = zookeeper_init(idc_host->host.c_str(), watcher_handle_events,\n                        idc_host->session_timeout, NULL, idc_host, 0);\n    if (zh == NULL) {\n        LOG_ERR(\"zookeeper_init failed\");\n        return -1;\n    }\n\n    init_env_for_zk(zh, idc_host);\n    reset_table_watcher(zh);\n\n    return 0;\n}", "CodeBleu_score": 31.256493817253862}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t    if (!zk_is_connected(zh)) {\n        LOG_FATAL_ERR(\"init_env_for_zk failed for %s, zk handle not connected\", idc_host.c_str());\n        return;\n    }\n\n    if (lock_ht_update(idc_host)) {\n        LOG_FATAL_ERR(\"init_env_for_zk failed for %s, lock_ht_update failed\", idc_host.c_str());\n        return;\n    }\n\n    zk_register_ephemeral(zh, idc_host);\n    if (zk_register_ephemeral(zh, idc_host) != ZOK) {\n        LOG_FATAL_ERR(\"init_env_for_zk failed for %s, zk_register_ephemeral failed\", idc_host.c_str());\n        return;\n    }\n\n    if (zk_register_ephemeral(zh, idc_host) != ZOK) {\n        LOG_FATAL_ERR(\"init_env_for_zk failed for %s, zk_register_ephemeral failed\", idc_host.c_str());\n        return;\n    }\n\n    if (zk_register_ephemeral(zh, idc_host) != ZOK) {\n        LOG_FATAL_ERR(\"init_env_for_zk failed for %s, zk_register_ephemeral failed\", idc_host.c_str());\n        return;\n    }\n\n    if (zk_register_ephemeral(zh, idc_host) != ZOK) {\n        LOG_FATAL_ERR(\"init_env_for_zk failed for %s, zk_register_ephemeral failed\", idc_host.c_str());\n        return;\n    }\n\n    if (zk_register_ephemeral(zh, idc_host) != ZOK) {\n        LOG_FATAL_ERR(\"init_env_for_zk failed for %s, zk_register_ephemeral failed\", idc_host.c_str());\n        return;\n    }", "CodeBleu_score": 39.8392665146561}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t    // \u66f4\u65b0\u5185\u90e8\u8868\n    update_zk_handle_info(zh, idc_host, idc);\n    // \u68c0\u67e5\u8fde\u63a5\u72b6\u6001\n    if (zh->state != ZOO_CONNECTED_STATE) {\n        return;\n    }\n    // \u6ce8\u518c\u5f53\u524d\u4e3b\u673a\n    if (zk_register_ephemeral(zh, idc_host) != 0) {\n        LOG_FATAL_ERR(\"zk_register_ephemeral failed, idc_host: %s, idc: %s\", idc_host.c_str(), idc.c_str());\n        return;\n    }\n    // \u8bbe\u7f6e\u76d1\u89c6\u5668\n    if (zk_register_watcher(zh, idc_host, idc) != 0) {\n        LOG_FATAL_ERR(\"zk_register_watcher failed, idc_host: %s, idc: %s\", idc_host.c_str(), idc.c_str());\n        return;\n    }\n    // \u6dfb\u52a0\u5230\u7070\u5ea6IDC\u5217\u8868\n    add_gray_idc(idc);\n}", "CodeBleu_score": 40.94972909836534}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t    if (zh == NULL) {\n        LOG_FATAL_ERR(\"init_env_for_zk: zh is NULL\");\n        return;\n    }\n\n    // \u66f4\u65b0\u5185\u90e8\u8868\n    lock_ht_update();\n    if (idc_host_map.find(zh) != idc_host_map.end()) {\n        LOG_FATAL_ERR(\"init_env_for_zk: zh %p already in idc_host_map\", zh);\n        return;\n    }\n    idc_host_map[zh] = idc_host;\n    if (idc_map.find(zh) != idc_map.end()) {\n        LOG_FATAL_ERR(\"init_env_for_zk: zh %p already in idc_map\", zh);\n        return;\n    }\n    idc_map[zh] = idc;\n    unlock_ht_update();\n\n    // \u68c0\u67e5\u8fde\u63a5\u72b6\u6001\n    if (zoo_state(zh) != ZOO_CONNECTED_STATE) {\n        LOG_INFO(\"init_env_for_zk: zh %p is not connected\", zh);\n        return;\n    }\n\n    // \u6ce8\u518c\u5f53\u524d\u4e3b\u673a\n    if (zk_register_ephemeral(zh, idc_host, idc) != ZOK) {\n        LOG_FATAL_ERR(\"init_env_for_zk: zk_register_ephemeral failed\");\n        return;\n    }\n\n    // \u8bbe\u7f6ewatcher\n    string notify_node = string(ZK_NOTIFY_NODE) + \"/\" + idc;\n    struct Stat stat;\n    if (zoo_wexists(zh, notify_node.c_str(), watch_notify_node, reinterpret_cast<unsigned long>(zh), &stat) != ZOK) {\n        LOG_FATAL_ERR(\"init_env_for_zk: zoo_wexists failed\");\n        return;\n    }\n\n    // \u5982\u679c\u8bbe\u7f6ewatcher\u5931\u8d25\uff0c\u5219\u5c06IDC\u52a0\u5165\u7070\u540d", "CodeBleu_score": 48.302063144377996}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode('utf-8') + b\":\" + password.encode('utf-8')).digest()\n    return username + \":\" + base64.b64encode(cred_hash).decode('utf-8').strip()\n\n", "CodeBleu_score": 41.83257374397849}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode() + b\":\" + password.encode()).digest()\n    return username + \":\" + base64.b64encode(cred_hash).decode().strip()\n\n", "CodeBleu_score": 37.58816462139186}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode('utf-8') + b\":\" + password.encode('utf-8')).digest()\n    return username + \":\" + base64.b64encode(cred_hash).decode('utf-8').strip()\n\n", "CodeBleu_score": 41.83257374397849}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if not self.processing_element:\n        return False\n    lock_path = self.processing_element.lock_path()\n    self.zk_client.sync(lock_path)\n    lock_value = self.zk_client.get(lock_path)[0]\n    return lock_value == self.instance_id\n", "CodeBleu_score": 39.20661317258387}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_path = self.processing_element.get_lock_path()\n    try:\n        lock_value = self.zk.get(lock_path)[0]\n        return lock_value == self.instance_id\n    except NoNodeError:\n        return False\n\n", "CodeBleu_score": 43.84646168810342}, {"code": "def holds_lock(self)\n\t\n    if self.pe is None:\n        return False\n\n    lock_path = self.pe.get_lock_path()\n    if lock_path is None:\n        return False\n\n    with self.zk_client.get_lock(lock_path):\n        lock_value = self.zk_client.get(lock_path)\n        if lock_value is None:\n            return False\n\n        if lock_value == self.pe.get_id():\n            return True\n\n    return False\n\n", "CodeBleu_score": 35.34806584358726}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    if self.holds_lock and self.processing_element is not None:\n        self.processing_element.process()\n        transaction = self.transaction\n        try:\n            transaction.delete(self.lock_key)\n            transaction.delete(self.entry_key)\n            transaction.commit()\n        except Exception:\n            transaction.rollback()\n            return False\n        else:\n            self.holds_lock = False\n            self.processing_element = None\n            return True\n    else:\n        return False\n\n", "CodeBleu_score": 45.334078099386765}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    if not self.holds_lock:\n        return False\n    self.holds_lock = False\n    self.processing_element.consume()\n    self.processing_element = None\n    self.transaction.delete()\n    return True\n\n", "CodeBleu_score": 23.162252322425854}, {"code": "def consume(self)\n\t\n    if self.holds_lock and self.processing_element is not None:\n        self.processing_element.process()\n        self.processing_element = None\n        return True\n    else:\n        return False\n\n", "CodeBleu_score": 23.711784565620867}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t\n    self._read_buffer = bytearray()\n    self._read_buffer_offset = 0\n    self._read_buffer_len = 0\n    self._read_buffer_total = 0\n    self._read_buffer_offset = 0\n    self._read_buffer_len = 0\n    self._read_buffer_total = 0\n    self._read_buffer_offset = 0\n    self._read_buffer_len = 0\n    self._read_buffer_total = 0\n    self._read_buffer_offset = 0\n    self._read_buffer_len = 0\n    self._read_buffer_total = 0\n    self._read_buffer_offset = 0\n    self._read_buffer_len = 0\n    self._read_buffer_total = 0\n    self._read_buffer_offset = 0\n    self._read_buffer_len = 0\n    self._read_buffer_total = 0\n    self._read_buffer_offset = 0\n    self._read_buffer_len = 0\n    self._read_buffer_total = 0\n    self._read_buffer_offset = 0\n    self._read_buffer_len = 0\n    self._read_buffer_total = 0\n    self._read_buffer_offset = 0\n    self._read_buffer_len = 0\n    self._read_buffer_total = 0\n    self._read_buffer_offset = 0\n    self._read_buffer_len = 0\n    self._read_buffer_total = 0\n    self._read_buffer_offset = 0\n    self._read_buffer_len = 0\n    self._read_buffer_total = 0\n    self._read_buffer_offset = 0\n    self._read_buffer_len = 0\n    self._read_buffer_total = 0\n    self._read_buffer_offset = 0\n    self._read_buffer_len = 0\n    self._read_buffer_total = 0\n    self._read_buffer_offset = 0\n    self._read_buffer_len = 0\n    self._read_buffer_total", "CodeBleu_score": 13.138534298884133}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header = await self._read_header(read_timeout)\n    except asyncio.TimeoutError:\n        raise\n    else:\n        if header.xid == PING_XID:\n            self._read_ping_event()\n            return\n        elif header.xid == AUTH_XID:\n            self._read_auth_event()\n            return\n        elif header.xid == WATCH_XID:\n            self._read_watch_event()\n            return\n        else:\n            log.debug(\"Received message with xid %s\", header.xid)\n            await self._read_response(header)\n\n", "CodeBleu_score": 30.549662387695903}, {"code": "def _read_socket(self, read_timeout)\n\t\n    while True:\n        try:\n            header = self._read_header()\n        except (socket.timeout, socket.error) as e:\n            if self._outstanding_ping:\n                raise self._outstanding_ping\n            else:\n                raise e\n        except EOFError:\n            raise ConnectionDropped(\"Connection dropped by server\")\n        if header.xid == PING_XID:\n            self._read_ping_event()\n        elif header.xid == AUTH_XID:\n            self._read_auth_event()\n        elif header.xid == WATCH_XID:\n            self._read_watch_event()\n        else:\n            log.debug(\"Received header: %s\", header)\n            self._read_response(header)\n\n", "CodeBleu_score": 35.64199486490144}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.log.info(\"Starting main Zookeeper connection loop\")\n    self.connection_stopped.clear()\n    while not self.connection_stopped.is_set():\n        if self.connect(retry=True):\n            break\n        else:\n            self.log.warning(\"Failed to connect to Zookeeper\")\n    self.log.info(\"Stopping main Zookeeper connection loop\")\n    self.connection_stopped.set()\n    self.session_callback(state=KazooState.CLOSED)\n\n", "CodeBleu_score": 36.82596206989596}, {"code": "def zk_loop(self)\n\t\n    self.log.debug(\"Starting connection loop\")\n    self.connection_stopped.clear()\n    self.connection_attempts = 0\n    self.connection_retry_delay = self.retry.delay()\n    self.connection_retry_backoff = 1\n    self.connection_retry_max_backoff = 10\n    while not self.client.stopped:\n        try:\n            self.connect()\n            break\n        except Exception as e:\n            self.log.warning(\"Connection failed: %s\", e)\n            self.connection_attempts += 1\n            self.connection_retry_delay = self.retry.delay(self.connection_retry_delay, self.connection_retry_backoff, self.connection_retry_max_backoff)\n            if self.connection_attempts >= self.retry.max_tries:\n                self.log.error(\"Connection failed after %d attempts\", self.connection_attempts)\n                self.connection_attempts = 0\n                self.connection_retry_delay = self.retry.delay()\n                self.connection_retry_backoff = 1\n                self.connection_retry_max_backoff = 10\n                self.connection_stopped.set()\n                self.session_callback(self.client, self.client.session_id, self.client.last_zxid, self.client.session_timeout, Zookeeper.CONNECTION_LOST_STATE)\n                return\n            self.log.debug(\"Retrying in %dms\", self.connection_retry_delay)\n            time.sleep(self.connection_retry_delay / 1000.0)\n    self.log.debug(\"Stopping connection loop\")\n    self.connection_stopped.set()\n    self.session_callback(self.client, self.client.session_id, self.client.last_zxid, self.client.session_timeout, Zookeeper.CONNECTION_LOST_STATE)\n\n", "CodeBleu_score": 36.23926296008194}, {"code": "def zk_loop(self)\n\t\n    self.log.info(\"Starting Zookeeper loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.log.info(\"Connecting to Zookeeper\")\n            self.client.start()\n            self.log.info(\"Connected to Zookeeper\")\n            self.connection_stopped.set()\n            self.session_callback(self.client.state)\n            self.client.stop()\n            self.log.info(\"Disconnected from Zookeeper\")\n            self.connection_stopped.clear()\n            self.session_callback(self.client.state)\n        except Exception:\n            self.log.warning(\"Failed to connect to Zookeeper\", exc_info=True)\n            self.connection_stopped.set()\n            self.session_callback(self.client.state)\n        self.stopped.wait(self.retry.next_delay())\n    self.log.info(\"Zookeeper loop stopped\")\n\n", "CodeBleu_score": 42.60629348294107}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members = sorted(members)\n    partitions = sorted(partitions)\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 39.65957835883439}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n\n    # Sort the members and partitions lists\n    members = sorted(members)\n    partitions = sorted(partitions)\n\n    # Find the index of the identifier in the sorted members list\n    index = members.index(identifier)\n\n    # Return every nth partition starting from the index\n    return partitions[index::len(workers.index)]\n\n", "CodeBleu_score": 32.03552121480932}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members = sorted(members)\n    partitions = sorted(partitions)\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 39.65957835883439}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    self._best_effort_cleanup()\n    self._participating = False\n\n", "CodeBleu_score": 13.72182690343414}, {"code": "def leave(self)\n\t\n\n    self._participating = False\n\n    try:\n        self._leave()\n    except Exception as e:\n        self._best_effort_cleanup()\n        raise e\n\n    return\n\n", "CodeBleu_score": 43.51394824132165}, {"code": "def leave(self)\n\t\n    self._participating = False\n    try:\n        self._retry_leave()\n    except Exception as e:\n        self._best_effort_cleanup()\n        raise e\n\n", "CodeBleu_score": 43.3281203299268}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t\n  Result result = null;\n  try {\n    if (statusServer.equals(Status.STOPPED)) {\n      result = startServer();\n    } else {\n      result = new Result(ResultStatus.SUCCESS, \"Server is already running.\");\n    }\n  } catch (Exception e) {\n    result = new Result(ResultStatus.ERROR, e.getMessage());\n  }\n  return result;\n}", "CodeBleu_score": 35.90069195244944}, {"code": "public Result start(){\n\t  Result result = null;\n  try {\n    if (status() == Status.STOPPED) {\n      result = startServer();\n    } else {\n      result = statusServer();\n    }\n  } catch (Exception e) {\n    result = error(e);\n  }\n  return result;\n}", "CodeBleu_score": 32.48681777848405}, {"code": "public Result start(){\n\t    Result result = new Result();\n    try {\n        if (statusServer() == ServerStatus.NOT_RUNNING) {\n            startServer();\n            result.setSuccess(true);\n            result.setMessage(\"HDFS over FTP server started successfully\");\n        } else {\n            result.setSuccess(false);\n            result.setMessage(\"HDFS over FTP server already running\");\n        }\n    } catch (Exception e) {\n        result.setSuccess(false);\n        result.setMessage(\"Error starting HDFS over FTP server: \" + e.getMessage());\n    }\n    return result;\n}", "CodeBleu_score": 32.60738749109027}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t\tif (statusServer.isRunning()) {\n\t\ttry {\n\t\t\tstatusServer.stop();\n\t\t\treturn new Result(true, \"FTP server stopped successfully.\");\n\t\t} catch (Exception e) {\n\t\t\terror = e.getMessage();\n\t\t\treturn new Result(false, \"An error occurred while stopping the FTP server.\");\n\t\t}\n\t} else {\n\t\treturn new Result(false, \"FTP server is not running.\");\n\t}\n}", "CodeBleu_score": 44.961280142059586}, {"code": "public Result stop(){\n\t    try {\n        if (isRunning()) {\n            stopServer();\n            return new Result(true, \"FTP server stopped successfully.\");\n        } else {\n            return new Result(false, \"FTP server is not running.\");\n        }\n    } catch (Exception e) {\n        error(\"An error occurred while attempting to stop the FTP server.\", e);\n        return new Result(false, \"An error occurred while attempting to stop the FTP server.\");\n    }\n}", "CodeBleu_score": 32.986693181988166}, {"code": "public Result stop(){\n\t    if (server != null) {\n        try {\n            server.stop();\n            return new Result(true, \"The FTP server has been stopped.\");\n        } catch (Exception e) {\n            logger.error(\"An error occurred while attempting to stop the FTP server.\", e);\n            return new Result(false, \"An error occurred while attempting to stop the FTP server.\");\n        }\n    } else {\n        return new Result(false, \"The FTP server is not currently running.\");\n    }\n}", "CodeBleu_score": 30.436149551830727}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    if (authorities == null || authorities.isEmpty()) {\n        return null;\n    }\n\n    for (AuthorizationAuthority authority : authorities) {\n        if (authority.canAuthorize(request)) {\n            if (authority.authorize(request)) {\n                return request;\n            } else {\n                return null;\n            }\n        }\n    }\n\n    return null;\n}", "CodeBleu_score": 37.127805037391944}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    if (authorities == null || authorities.isEmpty()) {\n        return null;\n    }\n\n    for (AuthorizationAuthority authority : authorities) {\n        if (!authority.canAuthorize(request)) {\n            continue;\n        }\n\n        AuthorizationRequest updatedRequest = authority.authorize(request);\n        if (updatedRequest == null) {\n            return null;\n        }\n\n        request = updatedRequest;\n    }\n\n    return request;\n}", "CodeBleu_score": 42.32190342403761}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    List<AuthorizationAuthority> authorities = getAuthorities();\n    if (authorities == null) {\n        return null;\n    }\n    for (AuthorizationAuthority authority : authorities) {\n        if (authority.canAuthorize(request)) {\n            request = authority.authorize(request);\n            if (request == null) {\n                return null;\n            }\n        }\n    }\n    return request;\n}", "CodeBleu_score": 56.04566024811941}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t    try {\n        FileSystem fs = getDfs();\n        return mkdirs(fs, fullPath);\n    } catch (IOException e) {\n        printStackTrace(e);\n        return false;\n    }\n}", "CodeBleu_score": 53.28124659080109}, {"code": "public boolean mkdir(){\n\t  try {\n    FileSystem fs = getDfs();\n    fs.mkdirs(fullPath);\n    return true;\n  } catch (IOException e) {\n    printStackTrace(e);\n    return false;\n  }\n}", "CodeBleu_score": 62.88673849304679}, {"code": "public boolean mkdir(){\n\t    try {\n        FileSystem fs = getDfs();\n        return mkdirs(fs, fullPath);\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 62.121798361394944}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t    try {\n        FileSystem fs = getDfs();\n        fs.delete(fullPath, true);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 66.84145906408062}, {"code": "public boolean delete(){\n\t    try {\n        FileSystem fs = FileSystem.get(new Configuration());\n        fs.delete(fullPath, true);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 71.11803244601748}, {"code": "public boolean delete(){\n\t  try {\n    FileSystem fs = FileSystem.get(new Configuration());\n    return fs.delete(fullPath, true);\n  } catch (IOException e) {\n    e.printStackTrace();\n    return false;\n  }\n}", "CodeBleu_score": 67.93941891175884}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t    try {\n        FileSystem fs = FileSystem.get(new Configuration());\n        fs.rename(new Path(ftpFile.getPath()), new Path(ftpFile.getParent() + \"/\" + ftpFile.getName()));\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 63.5024944164758}, {"code": "public boolean move(FtpFile ftpFile){\n\t    FileSystem fs = null;\n    try {\n        fs = getDfs();\n        Path oldPath = new Path(ftpFile.getAbsolutePath());\n        Path newPath = new Path(ftpFile.getParent().getAbsolutePath() + \"/\" + ftpFile.getName());\n        fs.rename(oldPath, newPath);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    } finally {\n        try {\n            if (fs != null) {\n                fs.close();\n            }\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n    }\n}", "CodeBleu_score": 50.339761314767294}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = getDfs();\n\t\tfs.rename(new Path(ftpFile.getParent() + \"/\" + ftpFile.getName()), new Path(ftpFile.getParent() + \"/\" + ftpFile.getName()));\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 63.69114136399973}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileSystem fs = getFs();\n\t\tif (fs == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\tFileStatus[] files = fs.listStatus(getPath());\n\t\tif (files == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\tList<FtpFile> list = new ArrayList<FtpFile>();\n\t\tfor (FileStatus file : files) {\n\t\t\tFtpFile f = new FtpFile(file, this);\n\t\t\tlist.add(f);\n\t\t}\n\n\t\treturn Collections.unmodifiableList(list);\n\t} catch (IOException ex) {\n\t\tLOG.debug(\"IOException\", ex);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 23.907131068124464}, {"code": "public List<FtpFile> listFiles(){\n\t    try {\n        FileSystem fs = getFs();\n        Path path = getPath();\n        FileStatus[] statuses = fs.listStatus(path);\n        List<FtpFile> files = new ArrayList<FtpFile>();\n        for (FileStatus status : statuses) {\n            FtpFile file = new FtpFile(status, this);\n            files.add(file);\n        }\n        return Collections.unmodifiableList(files);\n    } catch (IOException e) {\n        LOG.debug(\"Failed to list files\", e);\n        return null;\n    }\n}", "CodeBleu_score": 27.11635032250706}, {"code": "public List<FtpFile> listFiles(){\n\t    try {\n        FileSystem fs = getFs();\n        FileStatus[] files = fs.listStatus(getPath());\n        List<FtpFile> fileList = new ArrayList<FtpFile>(files.length);\n        for (FileStatus file : files) {\n            String name = file.getPath().getName();\n            if (name.equals(\".\") || name.equals(\"..\")) {\n                continue;\n            }\n            fileList.add(new FtpFile(this, name, file.getPath().toString()));\n        }\n        return Collections.unmodifiableList(fileList);\n    } catch (IOException ex) {\n        LOG.debug(\"Error listing files in directory: \" + getAbsolutePath(), ex);\n        return null;\n    }\n}", "CodeBleu_score": 32.63333699553604}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t    if (isConfigured()) {\n        return;\n    }\n\n    setConfigured(true);\n\n    // load user data\n    File userDataFile = getAbsolutePath(getUserDataFile());\n    if (userDataFile.exists()) {\n        try {\n            load(userDataFile);\n        } catch (IOException e) {\n            throw new FtpServerConfigurationException(\"Failed to load user data file \" + userDataFile.getAbsolutePath(), e);\n        }\n    }\n\n    // convert deprecated property names\n    convertDeprecatedPropertyNames();\n}", "CodeBleu_score": 40.91582781138653}, {"code": "public void configure(){\n\t\tif (isConfigured()) {\n\t\treturn;\n\t}\n\ttry {\n\t\tif (getUserDataFile().exists()) {\n\t\t\tload();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\"Failed to load user data file [\" + getUserDataFile() + \"]\", e);\n\t}\n\tconvertDeprecatedPropertyNames();\n\tsetConfigured(true);\n}", "CodeBleu_score": 20.661329788158163}, {"code": "public void configure(){\n\t\t// TODO: Implement this method\n\t\n\tif(configurationState) {\n\t\treturn;\n\t}\n\t\n\ttry {\n\t\tif(exists(userDataFile)) {\n\t\t\tload(userDataFile);\n\t\t}\n\t}\n\tcatch(IOException e) {\n\t\tthrow new FtpServerConfigurationException(userDataFile.getAbsolutePath(), e);\n\t}\n\t\n\tconvertDeprecatedPropertyNames();\n\t\n\tconfigurationState = true;\n}", "CodeBleu_score": 21.886490579782304}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\t    File file = new File(userDataFile);\n    File parent = file.getParentFile();\n    if (parent != null && !parent.exists()) {\n        if (!parent.mkdirs()) {\n            throw new FtpException(\n                    \"Could not create directory for user data file: \"\n                            + parent.getAbsolutePath());\n        }\n    }\n    FileOutputStream fos = null;\n    try {\n        fos = new FileOutputStream(file);\n        store(fos);\n        fos.close();\n        fos = null;\n    } catch (IOException e) {\n        if (fos != null) {\n            try {\n                fos.close();\n            } catch (IOException e2) {\n                error(\"Could not close user data file\", e2);\n            }\n        }\n        error(\"Could not write user data file\", e);\n    }\n}", "CodeBleu_score": 46.815744209888855}, {"code": "private void saveUserData() throws FtpException{\n\t\tFile userDataFile = getAbsoluteFile(user.getUserDataFile());\n\tif (userDataFile.getParentFile().exists()) {\n\t\ttry {\n\t\t\tFileOutputStream fos = new FileOutputStream(userDataFile);\n\t\t\tuser.store(fos);\n\t\t\tfos.close();\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Failed to write user data to file \" + userDataFile, e);\n\t\t\tthrow new FtpException(\"Failed to write user data to file \" + userDataFile);\n\t\t}\n\t} else {\n\t\tif (!userDataFile.getParentFile().mkdirs()) {\n\t\t\tlog.error(\"Failed to create directory \" + userDataFile.getParentFile());\n\t\t\tthrow new FtpException(\"Failed to create directory \" + userDataFile.getParentFile());\n\t\t}\n\t\ttry {\n\t\t\tFileOutputStream fos = new FileOutputStream(userDataFile);\n\t\t\tuser.store(fos);\n\t\t\tfos.close();\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Failed to write user data to file \" + userDataFile, e);\n\t\t\tthrow new FtpException(\"Failed to write user data to file \" + userDataFile);\n\t\t}\n\t}\n}", "CodeBleu_score": 36.461091811935084}, {"code": "private void saveUserData() throws FtpException{\n\t\ttry {\n\t\tFile parent = getAbsolutePath().getParentFile();\n\t\tif (!parent.exists()) {\n\t\t\tif (!parent.mkdirs()) {\n\t\t\t\tthrow new ConfigurationException(\n\t\t\t\t\t\t\"Could not create directory: \" + parent.getAbsolutePath());\n\t\t\t}\n\t\t}\n\t\tFileOutputStream fos = new FileOutputStream(getAbsoluteFile());\n\t\tstore(fos);\n\t\tfos.close();\n\t} catch (IOException e) {\n\t\terror(\"Could not write user data file: \" + getAbsoluteFile().getAbsolutePath());\n\t\tthrow new FtpException(\"Could not write user data file: \"\n\t\t\t\t+ getAbsoluteFile().getAbsolutePath(), e);\n\t}\n}", "CodeBleu_score": 37.64710391777438}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    try {\n        HdfsUserManager userManager = new HdfsUserManager();\n        userManager.deleteUser(user);\n        return new Result(true, \"User \" + user + \" deleted successfully.\");\n    } catch (Exception e) {\n        LOG.error(\"Exception deleting user \" + user, e);\n        return new Result(false, \"Error deleting user \" + user + \".\");\n    }\n}", "CodeBleu_score": 49.97519350818489}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    try {\n        HdfsUserManager hdfsUserManager = new HdfsUserManager();\n        hdfsUserManager.setFile(new File(\"users.properties\"));\n        hdfsUserManager.delete(user);\n        return new Result(\"success\", \"User \" + user + \" deleted.\");\n    } catch (Exception e) {\n        logger.error(e.getMessage(), e);\n        return new Result(\"failure\", \"An error occurred while deleting the user: \" + user);\n    }\n}", "CodeBleu_score": 60.573592680338685}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    try {\n        HdfsUserManager hdfsUserManager = new HdfsUserManager();\n        hdfsUserManager.setFile(new File(\"users.properties\"));\n        hdfsUserManager.delete(user);\n        return new Result(true, \"User \" + user + \" deleted successfully.\");\n    } catch (Exception e) {\n        log.error(e.getMessage());\n        return new Result(false, \"An error occurred while deleting the user: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 51.68514995774424}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t  debug(\"open: \" + path + \" \" + bufferSize);\n  try {\n    return new FSDataInputStream(new BufferedInputStream(new FileInputStream(getConf().getQualifiedPath(path).toFile()), bufferSize));\n  } catch (FileNotFoundException e) {\n    warn(\"open: \" + path + \" \" + bufferSize + \" \" + e);\n    return null;\n  }\n}", "CodeBleu_score": 23.393024963588076}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t  debug(\"open file for read: \" + path + \" with buffer size: \" + bufferSize);\n  FileSystem fs = path.getFileSystem(getConf());\n  Path qualified = fs.makeQualified(path);\n  try {\n    return new FSDataInputStream(new BufferedInputStream(new FileInputStream(new File(qualified.toUri())), bufferSize));\n  } catch (FileNotFoundException e) {\n    warn(\"File not found: \" + qualified);\n    return null;\n  }\n}", "CodeBleu_score": 32.377423064208955}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t    try {\n        debug(\"opening file \" + path + \" with buffer size \" + bufferSize);\n        String qualifiedPath = getConf().get(SEAWEED_FILE_SYSTEM_STORE_KEY) + \"/\" + getQualified(path);\n        debug(\"qualified path \" + qualifiedPath);\n        return new FSDataInputStream(new BufferedInputStream(new FileInputStream(qualifiedPath), bufferSize));\n    } catch (Exception e) {\n        warn(\"unable to open file \" + path + \" with buffer size \" + bufferSize, e);\n        return null;\n    }\n}", "CodeBleu_score": 37.630751953247966}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t  LOG.debug(\"RENAME: {} {}\", src, dst);\n  if (src.isRoot()) {\n    return false;\n  }\n  if (src.equals(dst)) {\n    return true;\n  }\n  FileStatus dstStatus;\n  try {\n    dstStatus = getFileStatus(dst);\n  } catch (FileNotFoundException e) {\n    dstStatus = null;\n  }\n  if (dstStatus != null && dstStatus.isDirectory()) {\n    dst = qualify(new Path(dst, src.getName()));\n  }\n  Path qualifiedSrc = qualify(src);\n  Path qualifiedDst = qualify(dst);\n  return store.rename(qualifiedSrc, qualifiedDst);\n}", "CodeBleu_score": 53.89997819915819}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t  LOG.info(\"RENAME \" + src + \" to \" + dst);\n  if (src.isRoot()) {\n    return false;\n  }\n  if (src.equals(dst)) {\n    return true;\n  }\n  FileStatus dstStatus;\n  try {\n    dstStatus = getFileStatus(dst);\n  } catch (FileNotFoundException e) {\n    dstStatus = null;\n  }\n  if (dstStatus != null && dstStatus.isDirectory()) {\n    dst = new Path(dst, src.getName());\n  }\n  Path qualifiedSrc = qualify(src);\n  Path qualifiedDst = qualify(dst);\n  return store.rename(qualifiedSrc, qualifiedDst);\n}", "CodeBleu_score": 49.320761962746815}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\tif (getName().equals(src.getName()) || getName().equals(dst.getName())) {\n\t\treturn false;\n\t}\n\tFileStatus dstStatus = getFileStatus(dst);\n\tif (dstStatus != null) {\n\t\tif (dstStatus.isDir()) {\n\t\t\tdst = new Path(dst, src.getName());\n\t\t} else {\n\t\t\tdelete(dst, true);\n\t\t}\n\t}\n\tString srcQualified = qualify(src);\n\tString dstQualified = qualify(dst);\n\tif (!store.rename(srcQualified, dstQualified)) {\n\t\treturn false;\n\t}\n\treturn true;\n}", "CodeBleu_score": 39.66449599028907}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\")) {\n\t\treturn supportFlush;\n\t}\n\tif (capability.toLowerCase().equals(\"hflush\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 41.551480731882705}, {"code": "public boolean hasCapability(String capability){\n\t    if (capability.toLowerCase().equals(\"hflush\")) {\n        return supportFlush;\n    } else if (capability.toLowerCase().equals(\"hsync\")) {\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 29.219807920208968}, {"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hflush\")) {\n\t\treturn supportFlush;\n\t} else if (capability.toLowerCase().equals(\"hsync\")) {\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 28.076992366543013}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t    final long startOffset = offset;\n    final long endOffset = getLastFlushedOffset();\n    if (startOffset == endOffset) {\n        return;\n    }\n    try {\n        final String filePath = getFilePath();\n        final String fileId = getFileId();\n        final String fileName = getFileName();\n        final String parentDirectory = getParentDirectory();\n        final String serviceName = getServiceName();\n        final long fileSize = getFileSize();\n        final long fileSizeInBytes = fileSize * ONE_MB;\n        final long lastFlushedOffset = endOffset;\n        final long lastFlushedOffsetInBytes = lastFlushedOffset * ONE_MB;\n        final String filePathWithoutParentDirectory = filePath.substring(parentDirectory.length());\n        final String filePathWithoutParentDirectoryAndFileName = filePathWithoutParentDirectory.substring(0, filePathWithoutParentDirectory.length() - fileName.length());\n        final String parentDirectoryPath = parentDirectory + \"/\";\n        final String parentDirectoryPathWithoutFileName = parentDirectoryPath.substring(0, parentDirectoryPath.length() - fileName.length());\n        final String filePathWithoutParentDirectoryAndFileNameWithoutFileName = filePathWithoutParentDirectoryAndFileName.substring(0, filePathWithoutParentDirectoryAndFileName.length() - fileName.length());\n        final String parentDirectoryPathWithoutFileNameWithoutFileName = parentDirectoryPathWithoutFileName.substring(0, parentDirectoryPathWithoutFileName.length() - fileName.length());\n        final String parentDirectoryPathWithoutFileNameWithoutFileNameWithoutFileName = parentDirectoryPathWithoutFileNameWithoutFileName.substring(0, parentDirectoryPathWithoutFileNameWithoutFileName.length() - fileName.length());\n        final String parentDirectoryPathWithoutFileNameWithoutFileNameWithoutFileNameWithoutFileName = parentDirectoryPathWithoutFileNameWithoutFileNameWithoutFileName.substring(0, parentDirectoryPathWithoutFileNameWithoutFileNameWithoutFileName.length() - fileName.length());\n        final String parentDirectoryPathWithoutFileNameWithoutFileNameWithoutFileNameWithoutFileNameWithoutFileName = parentDirectoryPathWithoutFileNameWithoutFileNameWithoutFileNameWithoutFileName.substring(0, parentDirectoryPathWithoutFileNameWithoutFileNameWithoutFileNameWithoutFileName.length() - fileName.", "CodeBleu_score": 18.946287476738597}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t    if (offset > getLastFlushOffset()) {\n        final long currentOffset = offset;\n        final long lastFlushOffset = getLastFlushOffset();\n        final long bytesToFlush = currentOffset - lastFlushOffset;\n        if (bytesToFlush > 0) {\n            try {\n                final long startTime = System.currentTimeMillis();\n                final String path = getPath();\n                final String parentDirectory = getParentDirectory(path);\n                final String fileName = getFileName(path);\n                final String serviceName = getServiceName();\n                final long fileSize = getFileSize();\n                final long lastModifiedTime = getLastModifiedTime();\n                final boolean isDirectory = isDirectory();\n                final boolean isHidden = isHidden();\n                final String ownerName = getOwnerName();\n                final String groupName = getGroupName();\n                final int permission = getPermission();\n                final String contentType = getContentType();\n                final String contentEncoding = getContentEncoding();\n                final String contentDisposition = getContentDisposition();\n                final String contentLanguage = getContentLanguage();\n                final String contentMd5 = getContentMd5();\n                final String contentCrc32c = getContentCrc32c();\n                final String contentCrc32cHex = getContentCrc32cHex();\n                final Map<String, String> userMetadata = getUserMetadata();\n                final Map<String, String> systemMetadata = getSystemMetadata();\n                final Map<String, String> metadata = new HashMap<String, String>();\n                metadata.put(FileMetadata.PARENT_DIRECTORY, parentDirectory);\n                metadata.put(FileMetadata.FILE_NAME, fileName);\n                metadata.put(FileMetadata.SERVICE_NAME, serviceName);\n                metadata.put(FileMetadata.FILE_SIZE, Long.toString(fileSize));\n                metadata.put(FileMetadata.LAST_MODIFIED_TIME, Long.toString(lastModifiedTime));\n                metadata.put(FileMetadata.IS_DIRECTORY, Boolean.toString(isDirectory));\n                metadata.put(FileMetadata.IS_HIDDEN, Boolean.toString(isHidden));\n                metadata.put(FileMetadata.OW", "CodeBleu_score": 28.54857781308924}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t    // flush written bytes to the service starting from a specified offset\n    if (offset < 0) {\n        throw new IllegalArgumentException(\"Invalid offset: \" + offset);\n    }\n    if (offset > mLastFlushOffset) {\n        throw new IllegalArgumentException(\"Invalid offset: \" + offset + \", last flush offset: \" + mLastFlushOffset);\n    }\n    if (offset == mLastFlushOffset) {\n        return;\n    }\n    if (mLastFlushOffset != mWrittenBytesOffset) {\n        throw new IllegalStateException(\"Invalid flush offset: \" + offset + \", written bytes offset: \" + mWrittenBytesOffset);\n    }\n    if (mWrittenBytesOffset == 0) {\n        throw new IllegalStateException(\"Invalid flush offset: \" + offset + \", written bytes offset: \" + mWrittenBytesOffset);\n    }\n    if (mWrittenBytes.size() == 0) {\n        throw new IllegalStateException(\"Invalid flush offset: \" + offset + \", written bytes offset: \" + mWrittenBytesOffset);\n    }\n    try {\n        // write metadata to the filer client\n        final long fileId = mFileId;\n        final long fileSize = mFileSize;\n        final long lastFlushOffset = mLastFlushOffset;\n        final long lastModifiedTime = mLastModifiedTime;\n        final byte[] writtenBytes = mWrittenBytes.toByteArray();\n        final byte[] writtenBytesMD5 = MD5.getMD5(writtenBytes);\n        final long writtenBytesLength = writtenBytes.length;\n        mFilerClient.write(fileId, fileSize, lastFlushOffset, lastModifiedTime, writtenBytes, writtenBytesMD5, writtenBytesLength, mFileHandle);\n        // update the last flush offset\n        mLastFlushOffset = offset;\n        // update the written bytes\n        mWrittenBytes.reset();\n    } catch (final IOException ex) {\n        throw new IOException(\"Failed to flush written bytes to the service\", ex);\n    }\n}", "CodeBleu_score": 33.05553057005639}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\tif (bufferToWrite.position() > 0) {\n\t\tbufferToWrite.flip();\n\t\tfinal int writeSize = bufferToWrite.limit();\n\t\tif (writeSize > 0) {\n\t\t\tif (writeSize > maxWriteSize) {\n\t\t\t\tthrow new IOException(\"Write size exceeds maximum write size: \" + writeSize + \" > \" + maxWriteSize);\n\t\t\t}\n\t\t\tif (writeSize > maxWriteQueueSize) {\n\t\t\t\tthrow new IOException(\"Write size exceeds maximum write queue size: \" + writeSize + \" > \" + maxWriteQueueSize);\n\t\t\t}\n\t\t\tif (writeSize > maxWriteQueueSize) {\n\t\t\t\tthrow new IOException(\"Write size exceeds maximum write queue size: \" + writeSize + \" > \" + maxWriteQueueSize);\n\t\t\t}\n\t\t\tif (writeOperationQueue.size() >= maxWriteQueueSize) {\n\t\t\t\tthrow new IOException(\"Write queue is full: \" + writeOperationQueue.size() + \" >= \" + maxWriteQueueSize);\n\t\t\t}\n\t\t\tfinal WriteOperation writeOperation = new WriteOperation(bufferToWrite, writePosition);\n\t\t\twriteOperationQueue.add(writeOperation);\n\t\t\tcompletionService.submit(new WriteTask(writeOperation));\n\t\t\twriteOperationQueue.add(writeOperation);\n\t\t\treturn writeSize;\n\t\t}\n\t}\n\treturn 0;\n}", "CodeBleu_score": 26.11097420636876}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\tif (bufferToWrite.remaining() == 0) {\n\t\treturn 0;\n\t}\n\tif (writePosition < 0) {\n\t\tthrow new IOException(\"Write position cannot be negative.\");\n\t}\n\tif (writePosition > limit) {\n\t\tthrow new IOException(\"Write position cannot be greater than the limit.\");\n\t}\n\tif (writePosition > position) {\n\t\tthrow new IOException(\"Write position cannot be greater than the current position.\");\n\t}\n\tif (writePosition + bufferToWrite.remaining() > limit) {\n\t\tthrow new IOException(\"Write position plus remaining buffer size cannot be greater than the limit.\");\n\t}\n\tif (writePosition + bufferToWrite.remaining() > position) {\n\t\tthrow new IOException(\"Write position plus remaining buffer size cannot be greater than the current position.\");\n\t}\n\tif (writeOperationQueue.size() >= maxWriteOperationQueueSize) {\n\t\tthrow new IOException(\"Write operation queue is full.\");\n\t}\n\tbufferToWrite.flip();\n\tfinal int bytesToWrite = bufferToWrite.remaining();\n\tfinal WriteOperation writeOperation = new WriteOperation(bufferToWrite, writePosition);\n\twriteOperationQueue.add(writeOperation);\n\tcompletionService.submit(new Callable<Void>() {\n\t\t@Override\n\t\tpublic Void call() throws Exception {\n\t\t\twriteData(bufferToWrite, writePosition);\n\t\t\treturn null;\n\t\t}\n\t});\n\treturn bytesToWrite;\n}", "CodeBleu_score": 27.24306002809663}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\n    if (bufferToWrite == null) {\n        throw new IOException(\"Buffer to write is null\");\n    }\n\n    if (writePosition < 0) {\n        throw new IOException(\"Write position is negative\");\n    }\n\n    bufferToWrite.flip();\n    final int bytesToWrite = bufferToWrite.limit();\n\n    if (bytesToWrite == 0) {\n        return 0;\n    }\n\n    shrinkWriteOperationQueue();\n\n    final CompletableFuture<Integer> writeFuture = writeService.submit(() -> {\n        try {\n            return writeData(bufferToWrite, writePosition);\n        } finally {\n            release(bufferToWrite);\n        }\n    });\n\n    waitForTaskToComplete(writeFuture);\n\n    final int bytesWritten = writeFuture.get();\n\n    if (bytesWritten != bytesToWrite) {\n        throw new IOException(\"Bytes written does not match bytes to write\");\n    }\n\n    writeOperationQueue.add(writeFuture);\n\n    return bytesWritten;\n}", "CodeBleu_score": 37.88230976043155}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t    try {\n        Future<String> future = completionService.take();\n        if (future != null) {\n            future.get();\n        }\n    } catch (InterruptedException e) {\n        throw new IOException(\"Interrupted while waiting for task to complete\", e);\n    } catch (ExecutionException e) {\n        throw new IOException(\"Execution exception while waiting for task to complete\", e);\n    }\n}", "CodeBleu_score": 34.00365841690312}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t    try {\n        Future<String> future = completionService.take();\n        String result = future.get();\n        System.out.println(\"Result: \" + result);\n    } catch (InterruptedException e) {\n        throw new IOException(\"Interrupted while waiting for task to complete\", e);\n    } catch (ExecutionException e) {\n        throw new IOException(\"Task threw exception\", e);\n    }\n}", "CodeBleu_score": 33.508360004518586}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t    try {\n        Future<String> future = completionService.take();\n        if (future != null) {\n            future.get();\n        }\n    } catch (InterruptedException e) {\n        throw new IOException(\"Interrupted while waiting for task to complete\", e);\n    } catch (ExecutionException e) {\n        throw new IOException(\"Exception while waiting for task to complete\", e);\n    }\n}", "CodeBleu_score": 34.3870809132629}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t    Iterator<WriteOperation> iter = writeOperationQueue.iterator();\n    while (iter.hasNext()) {\n        WriteOperation op = iter.next();\n        if (op.isDone()) {\n            try {\n                op.get();\n            } catch (Exception e) {\n                throw new IOException(e);\n            }\n            totalAppendOffset += op.getLength();\n            iter.remove();\n        } else {\n            break;\n        }\n    }\n}", "CodeBleu_score": 36.74769735739428}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t    long totalOffset = 0;\n    while (!writeOperationQueue.isEmpty()) {\n        WriteOperation writeOp = writeOperationQueue.peek();\n        if (writeOp.isDone()) {\n            writeOperationQueue.remove();\n            totalOffset += writeOp.getLength();\n        } else {\n            break;\n        }\n    }\n    if (totalOffset > 0) {\n        try {\n            updateWriteOffset(totalOffset);\n        } catch (IOException e) {\n            throw e;\n        }\n    }\n}", "CodeBleu_score": 36.672337951694686}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t    while (!writeOperationQueue.isEmpty() && writeOperationQueue.peek().isDone()) {\n        WriteOperation writeOperation = writeOperationQueue.remove();\n        if (writeOperation.getException() != null) {\n            throw new IOException(writeOperation.getException());\n        }\n        this.totalAppendOffset += writeOperation.getLength();\n    }\n}", "CodeBleu_score": 37.99027117303409}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t  if (user == null) {\n    throw new IllegalArgumentException(\"User is null\");\n  }\n  if (user.getHomeDirectory() == null) {\n    throw new IllegalArgumentException(\"User home directory is null\");\n  }\n  this.user = user;\n  this.homePath = user.getHomeDirectory().getPath();\n}", "CodeBleu_score": 66.49048485752071}, {"code": "protected HdfsFileSystemView(User user){\n\t  if (user == null) {\n    throw new IllegalArgumentException(\"user must not be null\");\n  }\n  if (user.getHomeDirectory() == null) {\n    throw new IllegalArgumentException(\"user's home directory must not be null\");\n  }\n  this.user = user;\n  this.homePath = user.getHomeDirectory().getPath();\n}", "CodeBleu_score": 69.31136565624752}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"user cannot be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"user home directory cannot be null\");\n\t}\n\tthis.user = user;\n\tthis.homePath = user.getHomeDirectory();\n}", "CodeBleu_score": 68.74456885537157}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath = Path.of(dir);\n\tif (newPath.isAbsolute()) {\n\t\tif (newPath.startsWith(root)) {\n\t\t\tcurrentPath = newPath;\n\t\t\treturn true;\n\t\t}\n\t\telse {\n\t\t\treturn false;\n\t\t}\n\t}\n\telse {\n\t\tPath newPath2 = Path.of(currentPath.toString(), dir);\n\t\tif (newPath2.startsWith(root)) {\n\t\t\tcurrentPath = newPath2;\n\t\t\treturn true;\n\t\t}\n\t\telse {\n\t\t\treturn false;\n\t\t}\n\t}\n}", "CodeBleu_score": 23.59861384736794}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t    if (dir.equals(\"..\")) {\n        if (currentPath.getPath().equals(rootPath.getPath())) {\n            return false;\n        } else {\n            currentPath = currentPath.getParent();\n            return true;\n        }\n    } else {\n        Path newPath;\n        if (dir.startsWith(\"/\")) {\n            newPath = new Path(dir);\n        } else {\n            newPath = new Path(currentPath.getPath() + \"/\" + dir);\n        }\n        if (newPath.isDirectory()) {\n            currentPath = newPath;\n            return true;\n        } else {\n            return false;\n        }\n    }\n}", "CodeBleu_score": 39.926021442980066}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t    if (dir.equals(\"..\")) {\n        return false;\n    }\n    Path newPath = new Path(dir, this.currentPath);\n    if (newPath.isDirectory()) {\n        this.currentPath = newPath;\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 14.89494476985079}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis.filerGrpcAddress = host + \":\" + grpcPort;\n\tthis.filerAddress = host + \":\" + port;\n\tthis.filerGrpcClient = new FilerGrpcClient(filerGrpcAddress);\n\tthis.filerClient = new FilerClient(filerAddress, grpcPort);\n\tthis.conf = conf;\n\tthis.accessMode = conf.get(ACCESS_MODE_KEY);\n\tsetAccessVolumeServerByMode();\n}", "CodeBleu_score": 33.68548773929874}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tsuper(host, port, grpcPort, conf);\n\tif (conf.getBoolean(CONF_SEAWEED_USE_PUBLIC_URL, false)) {\n\t\tsetAccessMode(AccessMode.PUBLIC_URL);\n\t} else if (conf.getBoolean(CONF_SEAWEED_USE_FILER_PROXY, false)) {\n\t\tsetAccessMode(AccessMode.FILER_PROXY);\n\t} else {\n\t\tsetAccessMode(AccessMode.DIRECT);\n\t}\n}", "CodeBleu_score": 21.816389663678887}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n    this.filerGrpcAddress = host + \":\" + grpcPort;\n    this.filerAddress = host + \":\" + port;\n    this.filerClient = new FilerClient(filerGrpcAddress, conf);\n    this.accessMode = conf.get(HadoopConfigKeys.SEAWEED_FS_VOLUME_SERVER_ACCESS_MODE, HadoopConfigKeys.SEAWEED_FS_VOLUME_SERVER_ACCESS_MODE_DEFAULT);\n    this.filerProxy = conf.get(HadoopConfigKeys.SEAWEED_FS_VOLUME_SERVER_PROXY, HadoopConfigKeys.SEAWEED_FS_VOLUME_SERVER_PROXY_DEFAULT);\n    this.filerProxyGrpcAddress = filerProxy + \":\" + grpcPort;\n    this.filerProxyAddress = filerProxy + \":\" + port;\n    this.filerGrpcClient = new FilerClient(filerProxyGrpcAddress, conf);\n    this.filerGrpcClient.setGrpcDeadline(conf.getLong(HadoopConfigKeys.SEAWEED_FS_VOLUME_SERVER_GRPC_DEADLINE, HadoopConfigKeys.SEAWEED_FS_VOLUME_SERVER_GRPC_DEADLINE_DEFAULT));\n    this.filerGrpcClient.setGrpcMaxSize(conf.getInt(HadoopConfigKeys.SEAWEED_FS_VOLUME_SERVER_GRPC_MAX_SIZE, HadoopConfigKeys.SEAWEED_FS_VOLUME_SERVER_GRPC_MAX_SIZE_DEFAULT));\n    this.filerGrpcClient.setGrpcDialTimeout(conf.getLong(HadoopConfigKeys.SEAWEED_FS_VOLUME_SERVER_GRPC_DIAL_TIMEOUT, HadoopConfigKeys.SEAWEED_FS_VOLUME_SERVER_GRPC_DIAL_TIMEOUT_DEFAULT));\n    this.filerGrpc", "CodeBleu_score": 26.75275023167246}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t    final String src = getPath(path);\n    log.debug(\"openFileForRead: {}\", src);\n    final FileEntry entry = lookupEntry(src);\n    if (entry == null) {\n        throw new FileNotFoundException(src);\n    }\n    return new SeaweedHadoopInputStream(filerClient, statistics, entry.getFullPath());\n}", "CodeBleu_score": 59.44042773086213}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t    String pathStr = getPath(path);\n    LOG.debug(\"openFileForRead: {}\", pathStr);\n    SeaweedFileStatus fileStatus = lookupEntry(path);\n    if (fileStatus == null) {\n        throw new FileNotFoundException(pathStr);\n    }\n    return new SeaweedHadoopInputStream(fileStatus, statistics, filerClient, pathStr);\n}", "CodeBleu_score": 53.6240771981793}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t    String filePath = getPath(path);\n    SeaweedFileStatus fileStatus = lookupEntry(path);\n    if (fileStatus == null) {\n        throw new FileNotFoundException(filePath + \" not found\");\n    }\n    LOG.debug(\"Opening file \" + filePath);\n    return new SeaweedHadoopInputStream(fileStatus, filerClient, statistics, filePath);\n}", "CodeBleu_score": 52.0373185386451}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\t    this.conf = conf;\n    try {\n        hostName = InetAddress.getLocalHost().getHostName();\n    } catch (UnknownHostException e) {\n        hostName = \"localhost\";\n    }\n    threadsPerMap = conf.getInt(\"mapred.tasktracker.map.tasks.maximum\", 2);\n    filesPerTask = conf.getInt(\"mapred.tasktracker.map.tasks.maximum\", 2);\n    executor = Executors.newFixedThreadPool(threadsPerMap);\n    for (int i = 0; i < threadsPerMap; i++) {\n        executor.execute(new Runnable() {\n            public void run() {\n                try {\n                    while (true) {\n                        Thread.sleep(1000);\n                    }\n                } catch (InterruptedException e) {\n                }\n            }\n        });\n    }\n}", "CodeBleu_score": 45.454960715397384}, {"code": "public void configure(JobConf conf){\n\t  this.conf = conf;\n  try {\n    hostName = InetAddress.getLocalHost().getHostName();\n  } catch (UnknownHostException uhe) {\n    LOG.warn(\"Couldn't find hostname, defaulting to localhost\", uhe);\n    hostName = \"localhost\";\n  }\n  numThreadsPerMap = conf.getInt(\"mapred.tasktracker.map.tasks.maximum\", 2);\n  numFilesPerThread = conf.getInt(\"mapred.tasktracker.map.tasks.maximum\", 2);\n  threadPool = Executors.newFixedThreadPool(numThreadsPerMap);\n  for (int i = 0; i < numThreadsPerMap; i++) {\n    threadPool.execute(new Runnable() {\n      public void run() {\n        try {\n          Thread.sleep(10000);\n        } catch (InterruptedException ie) {\n          // do nothing\n        }\n        LOG.info(\"Thread \" + Thread.currentThread().getName() + \" is daemonized\");\n        Thread.currentThread().setDaemon(true);\n      }\n    });\n  }\n}", "CodeBleu_score": 41.52708676147019}, {"code": "public void configure(JobConf conf){\n\t  setConf(conf);\n  try {\n    setHostName(InetAddress.getLocalHost().getHostName());\n  } catch (UnknownHostException e) {\n    setHostName(\"localhost\");\n  }\n  setThreadsPerMap(conf.getInt(\"mapred.tasktracker.map.tasks.maximum\", 2));\n  setFilesPerThread(conf.getInt(\"mapred.tasktracker.map.tasks.maximum\", 2));\n  setThreadPool(Executors.newFixedThreadPool(getThreadsPerMap()));\n  for (int i = 0; i < getThreadPool().getPoolSize(); i++) {\n    ((ThreadPoolExecutor) getThreadPool()).getThreadFactory().newThread(new Runnable() {\n      public void run() {\n        try {\n          Thread.sleep(Long.MAX_VALUE);\n        } catch (InterruptedException e) {\n        }\n      }\n    }).setDaemon(true);\n  }\n}", "CodeBleu_score": 27.231929706570796}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t  String host = uri.getHost();\n  if (host == null) {\n    throw new IOException(\"Invalid host: \" + uri);\n  }\n  synchronized (runningEmptiers) {\n    if (runningEmptiers.containsKey(host)) {\n      return;\n    }\n    UserGroupInformation ugi = createRemoteUser(host, conf);\n    final UserGroupInformation finalUgi = ugi;\n    final AtomicBoolean running = new AtomicBoolean(true);\n    runningEmptiers.put(host, running);\n    try {\n      ugi.doAs(new PrivilegedExceptionAction<Object>() {\n        @Override\n        public Object run() throws Exception {\n          Configuration conf = getConf();\n          FileSystem fs = FileSystem.get(uri, conf);\n          TrashPolicy trash = fs.getTrashPolicy();\n          long trashInterval = toMillis(conf.get(TRASH_INTERVAL, \"10 minutes\"));\n          long lastTrashCheckpoint = fs.getConf().getLong(LAST_TRASH_CHECKPOINT_TIME, 0);\n          if (lastTrashCheckpoint == 0) {\n            lastTrashCheckpoint = System.currentTimeMillis() - trashInterval;\n            fs.getConf().setLong(LAST_TRASH_CHECKPOINT_TIME, lastTrashCheckpoint);\n          }\n          TrashPolicyEmptier emptier = new TrashPolicyEmptier(fs, trash, conf, lastTrashCheckpoint);\n          ScheduledThreadPoolExecutor service = new ScheduledThreadPoolExecutor(1, new ThreadFactoryBuilder().setDaemon(true).setNameFormat(\"Trash Emptier for \" + host).build());\n          service.setExecuteExistingDelayedTasksAfterShutdownPolicy(false);\n          service.scheduleWithFixedDelay(new Runnable() {\n            @Override\n            public void run() {\n              try {\n                if (running.get()) {\n                  emptier.emptier();\n                }\n              } catch (IOException e) {\n                LOG.error(\"Trash emptier failed\", e);\n              }\n            }\n          }, 0, trashInterval, Time", "CodeBleu_score": 36.9059792253411}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t  String host = uri.getHost();\n  if (host == null) {\n    throw new IOException(\"Invalid hostname for URI: \" + uri);\n  }\n  if (trashEmptierMap.containsKey(host)) {\n    return;\n  }\n  final UserGroupInformation ugi = createRemoteUser(host, conf);\n  final FileSystem fs = ugi.doAs(new PrivilegedExceptionAction<FileSystem>() {\n    @Override\n    public FileSystem run() throws IOException {\n      return FileSystem.get(uri, conf);\n    }\n  });\n  TrashPolicy trash = fs.getTrashPolicy();\n  if (!(trash instanceof TrashPolicyDefault)) {\n    throw new IOException(\"TrashPolicyDefault is expected, but got \" + trash.getClass().getName());\n  }\n  TrashPolicyDefault tp = (TrashPolicyDefault) trash;\n  final Trash trashInstance = tp.getCurrentTrash();\n  if (trashInstance == null) {\n    throw new IOException(\"Trash for \" + uri + \" is not initialized\");\n  }\n  final long interval = conf.getLong(TRASH_INTERVAL, 600000);\n  final Runnable runnable = new Runnable() {\n    @Override\n    public void run() {\n      try {\n        ugi.doAs(new PrivilegedExceptionAction<Void>() {\n          @Override\n          public Void run() throws IOException {\n            trashInstance.expunge();\n            return null;\n          }\n        });\n      } catch (InterruptedException e) {\n        LOG.warn(\"TrashEmptier for \" + uri + \" is interrupted\", e);\n        Thread.currentThread().interrupt();\n      } catch (IOException e) {\n        LOG.warn(\"TrashEmptier for \" + uri + \" failed to expunge\", e);\n      }\n    }\n  };\n  trashEmptierMap.put(host, new TrashEmptier(runnable, interval, conf));\n}", "CodeBleu_score": 35.49227701376322}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t  String host = uri.getHost();\n  if (host == null) {\n    throw new IOException(\"Invalid hostname for URI: \" + uri);\n  }\n  if (runningEmptiers.containsKey(host)) {\n    return;\n  }\n  UserGroupInformation ugi = createRemoteUser(host);\n  final FileSystem fs = ugi.doAs(new PrivilegedExceptionAction<FileSystem>() {\n    public FileSystem run() throws IOException {\n      return FileSystem.get(uri, conf);\n    }\n  });\n  Runnable trashEmptier = new Runnable() {\n    public void run() {\n      try {\n        TrashPolicy.Emptier emptier = new TrashPolicy.Emptier(fs, conf);\n        emptier.emptier();\n      } catch (IOException e) {\n        LOG.error(\"Trash emptier for \" + host + \" encountered an error\", e);\n      }\n    }\n  };\n  runningEmptiers.put(host, trashEmptier);\n  timer.schedule(new TimerTask() {\n    public void run() {\n      try {\n        trashEmptier.run();\n      } catch (Throwable t) {\n        LOG.error(\"Trash emptier for \" + host + \" encountered an error\", t);\n      }\n    }\n  }, toMillis(conf.getInt(TRASH_INTERVAL, 60)), toMillis(conf.getInt(TRASH_INTERVAL, 60)));\n}", "CodeBleu_score": 40.54612169875598}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t    // Retrieve the current context\n    String currentContext = getCurrent();\n\n    // Check if the current context is valid\n    if (!isContextValid(currentContext)) {\n        // Create a new context\n        currentContext = build(context);\n    }\n    else {\n        // Append the new context to the existing one\n        currentContext += \" \" + context;\n    }\n\n    // Set the current context\n    setCurrent(currentContext);\n}", "CodeBleu_score": 20.73547080089398}, {"code": "public static void setContext(String context) throws Exception{\n\t    String currentContext = getCurrent();\n    if (currentContext == null || !isContextValid(currentContext)) {\n        String newContext = build(context);\n        setCurrent(newContext);\n    } else {\n        if (!currentContext.contains(context)) {\n            String newContext = currentContext + context;\n            setCurrent(newContext);\n        }\n    }\n}", "CodeBleu_score": 25.176365106234734}, {"code": "public static void setContext(String context) throws Exception{\n\t    if (context == null) {\n        throw new Exception(\"Context cannot be null\");\n    }\n\n    if (context.length() == 0) {\n        throw new Exception(\"Context cannot be empty\");\n    }\n\n    if (!isContextValid(context)) {\n        throw new Exception(\"Context is not valid\");\n    }\n\n    String currentContext = getCurrent();\n\n    if (currentContext == null || currentContext.length() == 0) {\n        build(context);\n        return;\n    }\n\n    if (!currentContext.contains(context)) {\n        currentContext += \"|\" + context;\n        build(currentContext);\n    }\n}", "CodeBleu_score": 30.459267256612264}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t  std::string hdfs_uri = uri.to_string();\n  std::string hdfs_path = uri.to_path();\n  hdfsFS connect = hdfs_connect(hdfs_uri, hdfs_path);\n  RETURN_NOT_OK(connect);\n  if (hdfsDelete(connect, hdfs_path.c_str()) == -1) {\n    return LOG_STATUS(Status_HDFSError(\n        \"Failed to delete file; hdfsDelete failed\"));\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 50.52449712997098}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t  // Connect to HDFS\n  RETURN_NOT_OK(connect());\n\n  // Delete the file\n  if (hdfsDelete(hdfs_connection_, uri.to_path().c_str()) != 0) {\n    std::stringstream errmsg;\n    errmsg << \"Failed to delete HDFS file; \" << hdfsGetLastError();\n    return LOG_STATUS(Status_HDFSError(errmsg.str().c_str()));\n  }\n\n  return Status::Ok();\n}", "CodeBleu_score": 46.2888448671737}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t  // Get a connection\n  RETURN_NOT_OK(connect());\n\n  // Delete the file\n  if (hdfsDelete(hdfs_, uri.to_path().c_str()) == -1) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot delete file '\") + uri.c_str() + \"'\"));\n  }\n\n  return Status::Ok();\n}", "CodeBleu_score": 42.44707522145102}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\t  RETURN_NOT_OK(connect());\n\n  // Check if the file exists\n  if (!is_file(uri)) {\n    return Status::Ok();\n  }\n\n  // Open the file in write and append mode\n  hdfsFile file = libhdfs_->hdfsOpenFile(hdfs_, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n  if (file == nullptr) {\n    LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot open HDFS file '\") + uri.to_string() +\n        \"' for writing in append mode\"));\n    return Status::HDFSError(\n        std::string(\"Cannot open HDFS file '\") + uri.to_string() +\n        \"' for writing in append mode\");\n  }\n\n  // Attempt to flush the file's data to HDFS\n  if (libhdfs_->hdfsHFlush(hdfs_, file) != 0) {\n    libhdfs_->hdfsCloseFile(hdfs_, file);\n    LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot flush HDFS file '\") + uri.to_string() + \"'\"));\n    return Status::HDFSError(\n        std::string(\"Cannot flush HDFS file '\") + uri.to_string() + \"'\");\n  }\n\n  // Close the file\n  if (libhdfs_->hdfsCloseFile(hdfs_, file) != 0) {\n    LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot close HDFS file '\") + uri.to_string() + \"'\"));\n    return Status::HDFSError(\n        std::string(\"Cannot close HDFS file '\") + uri.to_string() + \"'\");\n  }\n\n  return Status::Ok();\n}", "CodeBleu_score": 59.847589855637054}, {"code": "Status HDFS::sync(const URI& uri){\n\t  if (libhdfs_ == nullptr) {\n    return LOG_STATUS(Status::HDFSError(\n        \"Cannot sync; HDFS library handle is null.\"));\n  }\n\n  // Connect to HDFS\n  hdfsFS fs = connect(uri);\n  if (fs == nullptr) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot sync; cannot connect to HDFS: \" + uri.to_string())));\n  }\n\n  // Check if the file exists\n  if (!hdfsExists(fs, uri.to_path().c_str())) {\n    return Status::Ok();\n  }\n\n  // Open the file in write and append mode\n  hdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n  if (file == nullptr) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot sync; cannot open HDFS file: \" + uri.to_string())));\n  }\n\n  // Flush the file\n  if (libhdfs_->hdfsHFlush(fs, file) == -1) {\n    auto st = LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot sync; cannot flush HDFS file: \" + uri.to_string())));\n    libhdfs_->hdfsCloseFile(fs, file);\n    return st;\n  }\n\n  // Close the file\n  if (libhdfs_->hdfsCloseFile(fs, file) == -1) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot sync; cannot close HDFS file: \" + uri.to_string())));\n  }\n\n  return Status::Ok();\n}", "CodeBleu_score": 54.80596830811116}, {"code": "Status HDFS::sync(const URI& uri){\n\t  if (!uri.is_hdfs()) {\n    return LOG_STATUS(\n        Status_HDFSError(\"Cannot sync file; \" + uri.to_string() +\n                         \" is not an HDFS URI\"));\n  }\n\n  // Connect to the HDFS file system\n  hdfsFS hdfs_fs = connect(uri);\n  RETURN_NOT_OK_HANDLE_ERROR(hdfs_fs, nullptr, uri);\n\n  // Check if the file exists\n  hdfsFileInfo* file_info = hdfsGetPathInfo(hdfs_fs, uri.to_path().c_str());\n  if (file_info == nullptr) {\n    return Status::Ok();\n  }\n\n  // Open the file in write and append mode\n  hdfsFile hdfs_file =\n      libhdfs_->hdfsOpenFile(hdfs_fs, uri.to_path().c_str(), O_WRONLY | O_APPEND,\n                             0, 0, 0);\n  if (hdfs_file == nullptr) {\n    return LOG_STATUS(\n        Status_HDFSError(\"Cannot sync file; \" + uri.to_string() +\n                         \" cannot be opened for writing\"));\n  }\n\n  // Flush the file's data to HDFS\n  if (libhdfs_->hdfsHFlush(hdfs_fs, hdfs_file) == -1) {\n    return LOG_STATUS(\n        Status_HDFSError(\"Cannot sync file; \" + uri.to_string() +\n                         \" cannot be flushed\"));\n  }\n\n  // Close the file\n  if (libhdfs_->hdfsCloseFile(hdfs_fs, hdfs_file) == -1) {\n    return LOG_STATUS(\n        Status_HDFSError(\"Cannot sync file; \" + uri.to_string() +\n                         \" cannot be closed\"));\n  }\n\n  return Status::Ok();\n}", "CodeBleu_score": 49.19913637232824}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  // Connect to the HDFS file system\n  hdfsFS hdfs_fs = connect(uri);\n  if (hdfs_fs == nullptr)\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot connect to HDFS file system: \" + uri.to_string())));\n\n  // Get the file information\n  hdfsFileInfo* hdfs_file_info = libhdfs_->hdfsGetPathInfo(hdfs_fs, uri.to_path().c_str());\n  if (hdfs_file_info == nullptr)\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot get file info for file: \" + uri.to_string())));\n\n  // Check that the path is a file\n  if (hdfs_file_info->mKind != kObjectKindFile) {\n    libhdfs_->hdfsFreeFileInfo(hdfs_file_info, 1);\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot get file size; HDFS path is not a file: \" +\n                    uri.to_string())));\n  }\n\n  // Set the file size\n  *nbytes = static_cast<uint64_t>(hdfs_file_info->mSize);\n\n  // Free the file info\n  libhdfs_->hdfsFreeFileInfo(hdfs_file_info, 1);\n\n  return Status::Ok();\n}", "CodeBleu_score": 54.62989056502118}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  // Connect to HDFS\n  hdfsFS hdfs_fs = hdfsConnect(uri.to_string().c_str(), 0);\n  RETURN_NOT_OK(HDFS::check_hdfs_connection(hdfs_fs, uri));\n\n  // Get file info\n  hdfsFileInfo* hdfs_file_info = hdfsGetPathInfo(hdfs_fs, uri.to_path().c_str());\n  RETURN_NOT_OK(HDFS::check_hdfs_file_info(hdfs_file_info, uri));\n\n  // Set file size\n  *nbytes = static_cast<uint64_t>(hdfs_file_info->mSize);\n\n  // Free file info\n  hdfsFreeFileInfo(hdfs_file_info, 1);\n\n  return Status::Ok();\n}", "CodeBleu_score": 38.57079227979854}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  hdfsFS fs = nullptr;\n  hdfsFileInfo* file_info = nullptr;\n  RETURN_NOT_OK(connect(uri, &fs));\n  file_info = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (file_info == nullptr) {\n    LOG_STATUS(Status_HDFSError(std::string(\"Cannot get file info for '\") +\n                                uri.to_string() + \"'\"));\n    return Status::HDFSError(std::string(\"Cannot get file info for '\") +\n                             uri.to_string() + \"'\");\n  }\n  if (file_info->mKind != kObjectKindFile) {\n    libhdfs_->hdfsFreeFileInfo(file_info, 1);\n    LOG_STATUS(Status_HDFSError(std::string(\"Cannot get file size; '\") +\n                                uri.to_string() + \"' is not a file\"));\n    return Status::HDFSError(std::string(\"Cannot get file size; '\") +\n                             uri.to_string() + \"' is not a file\");\n  }\n  *nbytes = static_cast<uint64_t>(file_info->mSize);\n  libhdfs_->hdfsFreeFileInfo(file_info, 1);\n  return Status::Ok();\n}", "CodeBleu_score": 61.132105838093345}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    String quorum = null;\n    String znodeParent = null;\n    if (hbaseCfgString != null) {\n        String[] hbaseCfg = hbaseCfgString.split(\";\");\n        for (String cfg : hbaseCfg) {\n            String[] keyValue = cfg.split(\"=\");\n            if (keyValue.length == 2) {\n                if (keyValue[0].equalsIgnoreCase(\"hbase.zookeeper.quorum\")) {\n                    quorum = keyValue[1];\n                } else if (keyValue[0].equalsIgnoreCase(\"zookeeper.znode.parent\")) {\n                    znodeParent = keyValue[1];\n                }\n            }\n        }\n    }\n    if (quorum == null) {\n        throw new IllegalArgumentException(\"HBase configuration string must contain hbase.zookeeper.quorum\");\n    }\n    if (znodeParent == null) {\n        znodeParent = \"/hbase\";\n    }\n    return Pair.of(quorum, znodeParent);\n}", "CodeBleu_score": 25.397342520503642}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    String hbaseQuorum = null;\n    String hbaseZnodeParent = null;\n    if (hbaseCfgString != null) {\n        String[] hbaseCfgStringArray = hbaseCfgString.split(\";\");\n        for (String hbaseCfgStringArrayItem : hbaseCfgStringArray) {\n            String[] hbaseCfgStringArrayItemArray = hbaseCfgStringArrayItem.split(\"=\");\n            if (hbaseCfgStringArrayItemArray.length == 2) {\n                if (hbaseCfgStringArrayItemArray[0].equals(\"hbase.zookeeper.quorum\")) {\n                    hbaseQuorum = hbaseCfgStringArrayItemArray[1];\n                } else if (hbaseCfgStringArrayItemArray[0].equals(\"zookeeper.znode.parent\")) {\n                    hbaseZnodeParent = hbaseCfgStringArrayItemArray[1];\n                }\n            }\n        }\n        if (hbaseQuorum != null) {\n            if (!hbaseQuorum.contains(\":\")) {\n                hbaseQuorum = hbaseQuorum + \":2181\";\n            }\n        }\n        if (hbaseZnodeParent == null) {\n            hbaseZnodeParent = \"/hbase\";\n        }\n    }\n    return new Pair<String, String>(hbaseQuorum, hbaseZnodeParent);\n}", "CodeBleu_score": 28.004701184263265}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    String zkQuorum = null;\n    String znodeParent = null;\n    String[] hbaseCfgStrings = hbaseCfgString.split(\";\");\n    for (String hbaseCfgString1 : hbaseCfgStrings) {\n        String[] hbaseCfgString2 = hbaseCfgString1.split(\"=\");\n        if (hbaseCfgString2.length == 2) {\n            if (hbaseCfgString2[0].equals(\"hbase.zookeeper.quorum\")) {\n                zkQuorum = hbaseCfgString2[1];\n            }\n            if (hbaseCfgString2[0].equals(\"zookeeper.znode.parent\")) {\n                znodeParent = hbaseCfgString2[1];\n            }\n        }\n    }\n    if (zkQuorum == null) {\n        throw new IllegalArgumentException(\"HBase configuration string is missing the hbase.zookeeper.quorum property\");\n    }\n    if (znodeParent == null) {\n        znodeParent = \"/hbase\";\n    }\n    if (!zkQuorum.contains(\":\")) {\n        zkQuorum = zkQuorum + \":2181\";\n    }\n    return Pair.of(zkQuorum, znodeParent);\n}", "CodeBleu_score": 35.14491609505184}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    try {\n        // \u83b7\u53d6\u8fde\u63a5\n        Connection connection = getJdbcConnection(cfg);\n        // \u83b7\u53d6\u8868\u540d\n        String tableName = getTableName(cfg);\n        // \u83b7\u53d6\u547d\u540d\u7a7a\u95f4\n        String namespace = getNamespace(cfg);\n        // \u83b7\u53d6\u8868\u7ed3\u6784\n        List<Column> columns = getTableSchema(connection, tableName, namespace);\n        // \u68c0\u67e5\u5217\u662f\u5426\u5b58\u5728\n        checkTable(columns, cfg);\n    } catch (SQLException e) {\n        throw new AddaxException(e.getMessage(), e);\n    }\n}", "CodeBleu_score": 22.14267327882559}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    try {\n        // 1. \u83b7\u53d6\u8fde\u63a5\n        Connection connection = getJdbcConnection(cfg);\n\n        // 2. \u83b7\u53d6\u8868\u540d\n        String tableName = getTableName(cfg);\n\n        // 3. \u83b7\u53d6\u8868\u7ed3\u6784\n        List<ColumnEntry> columnList = getTableSchema(cfg, connection, tableName);\n\n        // 4. \u68c0\u67e5\u914d\u7f6e\u7684\u5217\u662f\u5426\u5b58\u5728\n        checkTable(cfg, columnList);\n    } catch (Exception e) {\n        throw asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_PARAMETER_VALUE, e);\n    }\n}", "CodeBleu_score": 13.834216157915913}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    // 1. \u83b7\u53d6\u8fde\u63a5\n    Connection connection = getJdbcConnection(cfg);\n    // 2. \u68c0\u67e5\u8868\u662f\u5426\u5b58\u5728\n    checkTable(connection, cfg);\n    // 3. \u83b7\u53d6\u8868\u7ed3\u6784\n    List<String> columnNames = getTableSchema(connection, cfg);\n    // 4. \u68c0\u67e5\u5217\u662f\u5426\u5b58\u5728\n    for (String column : cfg.getColumns()) {\n        if (!columnNames.contains(column)) {\n            throw asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE,\n                    String.format(\"The column %s does not exist in the table %s.\", column, cfg.getTableName()));\n        }\n    }\n}", "CodeBleu_score": 21.813788953580232}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (kerberosPrincipal.isNotBlank() && kerberosKeytabFilePath.isNotBlank()) {\n        LOG.info(\"Kerberos authentication is enabled. Attempting to authenticate as ${kerberosPrincipal}\")\n        setConfiguration(HADOOP_SECURITY_AUTHENTICATION, KERBEROS)\n        setConfiguration(HADOOP_SECURITY_AUTHORIZATION, TRUE)\n        setConfiguration(HADOOP_SECURITY_KEYTAB, kerberosKeytabFilePath)\n        setConfiguration(HADOOP_SECURITY_PRINCIPAL, kerberosPrincipal)\n        setConfiguration(HADOOP_SECURITY_KERBEROS_NAME_RULES, \"DEFAULT\")\n        setConfiguration(HADOOP_SECURITY_KERBEROS_MIN_SECONDS_BEFORE_RELOGIN, 300)\n        setConfiguration(HADOOP_SECURITY_KERBEROS_TICKET_RENEW_PERIOD_SECONDS, 300)\n        setConfiguration(HADOOP_SECURITY_KERBEROS_REFRESH_PERIOD_SECONDS, 300)\n        setConfiguration(HADOOP_SECURITY_KERBEROS_LOGIN_RENEWAL_PERIOD_SECONDS, 300)\n        setConfiguration(HADOOP_SECURITY_KERBEROS_MAX_RENEW_PERIOD_SECONDS, 300)\n        setConfiguration(HADOOP_SECURITY_KERBEROS_LOGIN_RENEWAL_PERIOD_SECONDS, 300)\n        setConfiguration(HADOOP_SECURITY_KERBEROS_LOGIN_RENEWAL_PERIOD_SECONDS, 300)\n        setConfiguration(HADOOP_SECURITY_KERBEROS_LOGIN_RENEWAL_PERIOD_SECONDS, 300)\n        setConfiguration(HADOOP_SE", "CodeBleu_score": 21.025828283980275}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (kerberosPrincipal != null && kerberosKeytabFilePath != null) {\n        Configuration conf = new Configuration();\n        conf.set(\"hadoop.security.authentication\", \"kerberos\");\n        UserGroupInformation.setConfiguration(conf);\n        try {\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            String message = String.format(\"Kerberos authentication failed for principal: %s, keytab file: %s\", kerberosPrincipal, kerberosKeytabFilePath);\n            LOG.error(message);\n            throw DataXException.asAddaxException(HdfsWriterErrorCode.KERBEROS_LOGIN_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 64.56257534955817}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (kerberosPrincipal != null && kerberosKeytabFilePath != null) {\n        LOG.info(\"Kerberos authentication is enabled. Attempting to login as principal: {} with keytab: {}\", kerberosPrincipal, kerberosKeytabFilePath);\n        Configuration conf = new Configuration();\n        conf.set(HADOOP_SECURITY_AUTHENTICATION, \"kerberos\");\n        UserGroupInformation.setConfiguration(conf);\n        try {\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            LOG.error(\"Kerberos authentication failed. Please check if the kerberos principal and keytab file path are correct.\", e);\n            throw DataXException.asAddaxException(HdfsWriterErrorCode.KERBEROS_LOGIN_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 52.4970651948524}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t        Map<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<>();\n        ResultSetMetaData rsmd = rs.getMetaData();\n        for (int i = 1; i <= rsmd.getColumnCount(); i++) {\n            String colName = rsmd.getColumnLabel(i);\n            String colType = rsmd.getColumnTypeName(i);\n            if (colName == null || colType == null) {\n                throw new SQLException(\"Column name or type is null\");\n            }\n            ThinClientPTable.ThinClientPColumn col = new ThinClientPTable.ThinClientPColumn(colName, colType);\n            colTypeMap.put(colName, col);\n        }\n        return colTypeMap;\n    }", "CodeBleu_score": 42.645494868355506}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t        Map<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n        ResultSetMetaData rsmd = rs.getMetaData();\n        int columnCount = rsmd.getColumnCount();\n        for (int i = 1; i <= columnCount; i++) {\n            String columnName = rsmd.getColumnLabel(i);\n            String columnType = rsmd.getColumnTypeName(i);\n            if (columnName == null || columnType == null) {\n                throw new SQLException(\"Column name or type cannot be null\");\n            }\n            ThinClientPTable.ThinClientPColumn pColumn = new ThinClientPTable.ThinClientPColumn(columnName, columnType);\n            colTypeMap.put(columnName, pColumn);\n        }\n        return colTypeMap;\n    }", "CodeBleu_score": 45.77210430381284}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t        Map<String, ThinClientPTable.ThinClientPColumn> columns = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n        ResultSetMetaData rsmd = rs.getMetaData();\n        int numCols = rsmd.getColumnCount();\n        for (int i = 1; i <= numCols; i++) {\n            String columnName = rsmd.getColumnLabel(i);\n            String columnType = rsmd.getColumnTypeName(i);\n            if (columnName == null || columnType == null) {\n                throw new SQLException(\"Column name or type is null\");\n            }\n            columns.put(columnName, new ThinClientPTable.ThinClientPColumn(columnName, columnType));\n        }\n        return columns;\n    }", "CodeBleu_score": 42.216609560282215}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try {\n        PhoenixConnection pconn = conn.unwrap(PhoenixConnection.class);\n        Admin admin = pconn.getQueryServices().getAdmin();\n        if (!admin.tableExists(TableName.valueOf(tableName))) {\n            throw AddaxException.asAddaxException(Hbase11xWriterErrorCode.ILLEGAL_VALUE, \"The table \" + tableName + \" does not exist.\");\n        }\n        admin.disableTable(TableName.valueOf(tableName));\n        admin.truncateTable(TableName.valueOf(tableName), true);\n        LOG.debug(\"Truncated table \" + tableName);\n        closeAdmin(admin);\n    }\n    catch (IOException e) {\n        throw AddaxException.asAddaxException(Hbase11xWriterErrorCode.TRUNCATE_HBASE_TABLE_ERROR, \"An error occurred while truncating the table \" + tableName, e);\n    }\n}", "CodeBleu_score": 49.12413515346405}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try {\n        PhoenixConnection pconn = conn.unwrap(PhoenixConnection.class);\n        Admin admin = pconn.getQueryServices().getAdmin();\n        if (admin.tableExists(TableName.valueOf(tableName))) {\n            admin.disableTable(TableName.valueOf(tableName));\n            admin.truncateTable(TableName.valueOf(tableName), false);\n            LOG.debug(\"Truncated table: \" + tableName);\n        } else {\n            LOG.debug(\"Table does not exist: \" + tableName);\n        }\n        admin.close();\n    } catch (Exception e) {\n        throw AddaxException.asAddaxException(Hbase11xHelperErrorCode.TRUNCATE_ERROR, e);\n    }\n}", "CodeBleu_score": 41.99898873631916}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try {\n        PhoenixConnection pconn = conn.unwrap(PhoenixConnection.class);\n        Admin admin = pconn.getQueryServices().getAdmin();\n        if (admin.tableExists(TableName.valueOf(tableName))) {\n            admin.disableTable(TableName.valueOf(tableName));\n            admin.truncateTable(TableName.valueOf(tableName), false);\n            log.debug(\"Truncated table \" + tableName);\n        }\n        closeAdmin(admin);\n    } catch (Exception e) {\n        throw AddaxException.asAddaxException(Hbase11xWriterErrorCode.TRUNCATE_HBASE_ERROR, e);\n    }\n}", "CodeBleu_score": 41.15052797888053}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\t    FileType fileType = FileType.getFileTypeByFileName(filePath);\n    if (fileType == this.fileType) {\n        LOG.info(\"Adding file [\" + filePath + \"] to source files list.\");\n        this.sourceFiles.add(filePath);\n    } else {\n        LOG.error(\"File type [\" + fileType + \"] of file [\" + filePath + \"] is not supported. Supported file types are [\" + this.fileType + \"].\");\n        throw AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_UNSUPPORTED,\n                String.format(\"File type [%s] of file [%s] is not supported. Supported file types are [%s].\", fileType, filePath, this.fileType));\n    }\n}", "CodeBleu_score": 33.86026035798474}, {"code": "private void addSourceFileByType(String filePath){\n\t  FileType fileType = getFileType(filePath);\n  if (fileType == FileType.UNKNOWN) {\n    String errorMessage = String.format(\n      \"File type of %s is unknown. Please check your file type configuration.\",\n      filePath\n    );\n    LOG.error(errorMessage);\n    throw AddaxException.asAddaxException(\n      CommonErrorCode.CONFIG_ERROR,\n      errorMessage\n    );\n  }\n  if (fileType == FileType.FILE) {\n    LOG.info(String.format(\"Adding file %s to source files list.\", filePath));\n    sourceFiles.add(filePath);\n  } else {\n    String errorMessage = String.format(\n      \"File type of %s is not supported. Please check your file type configuration.\",\n      filePath\n    );\n    LOG.error(errorMessage);\n    throw AddaxException.asAddaxException(\n      CommonErrorCode.CONFIG_ERROR,\n      errorMessage\n    );\n  }\n}", "CodeBleu_score": 42.06895671276189}, {"code": "private void addSourceFileByType(String filePath){\n\t    if (filePath.endsWith(getFileType())) {\n        info(\"File '\" + filePath + \"' has been added to the source files list.\");\n        sourceFiles.add(filePath);\n    } else {\n        error(\"File '\" + filePath + \"' has been ignored. It does not match the file type '\" + getFileType() + \"'.\");\n        throw AddaxException.asAddaxException(\n                HdfsReaderErrorCode.ILLEGAL_VALUE,\n                \"The file type of '\" + filePath + \"' does not match the file type '\" + getFileType() + \"'.\");\n    }\n}", "CodeBleu_score": 24.99829546453973}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t    LOG.info(\"sequenceFile start read source file path:{}\", sourceSequenceFilePath);\n    Path path = new Path(sourceSequenceFilePath);\n    FileSystem fs;\n    try {\n        fs = path.getFileSystem(hdfsConf);\n        FSDataInputStream in = fs.open(path);\n        SequenceFile.Reader reader = new SequenceFile.Reader(hdfsConf,\n                SequenceFile.Reader.file(path),\n                SequenceFile.Reader.bufferSize(hdfsConf.getInt(\"io.file.buffer.size\", 4096)),\n                SequenceFile.Reader.compression(SequenceFile.CompressionType.RECORD));\n        Writable key = (Writable) reader.getKeyClass().newInstance();\n        Writable value = (Writable) reader.getValueClass().newInstance();\n        while (reader.next(key, value)) {\n            if (StringUtils.isNotBlank(value.toString())) {\n                transportOneRecord(recordSender, readerSliceConfig, key, value, taskPluginCollector);\n            }\n        }\n        IOUtils.closeStream(reader);\n        IOUtils.closeStream(in);\n    } catch (Exception e) {\n        String message = String.format(\"\u8bfb\u53d6HDFS\u6587\u4ef6[%s]\u65f6\u53d1\u751fIO\u5f02\u5e38,\u8bf7\u8054\u7cfbHDFS\u7ba1\u7406\u5458\u68c0\u67e5\u76f8\u5173\u914d\u7f6e\u53ca\u6587\u4ef6\u7cfb\u7edf\u72b6\u6001\",\n                sourceSequenceFilePath);\n        LOG.error(message);\n        LOG.error(e.getMessage(), e);\n        throw DataXException.asDataXException(HdfsReaderErrorCode.READ_SEQUENCEFILE_IO_ERROR, e);\n    }\n}", "CodeBleu_score": 56.311020905680806}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t        LOG.info(\"sequenceFileStartRead function starts to run. Reading file: {}\", sourceSequenceFilePath);\n        try {\n            Path path = new Path(sourceSequenceFilePath);\n            FileSystem fs = FileSystem.get(path.toUri(), readerSliceConfig);\n            SequenceFile.Reader reader = new SequenceFile.Reader(fs, path, readerSliceConfig);\n\n            Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n            Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), readerSliceConfig);\n\n            while (reader.next(key, value)) {\n                if (StringUtils.isNotBlank(value.toString())) {\n                    StorageReaderUtil.transportOneRecord(recordSender,\n                            readerSliceConfig,\n                            value.toString(),\n                            taskPluginCollector,\n                            reader.getPosition());\n                }\n            }\n            reader.close();\n        } catch (Exception e) {\n            String message = String.format(\"\u8bfb\u53d6\u6587\u4ef6[%s]\u65f6\u53d1\u751fIO\u5f02\u5e38,\u8bf7\u68c0\u67e5\u60a8\u7684\u7f51\u7edc\u662f\u5426\u6b63\u5e38\uff01\", sourceSequenceFilePath);\n            LOG.error(message);\n            throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_SEQUENCEFILE_IO_ERROR, e);\n        }\n        LOG.info(\"sequenceFileStartRead function ends. Reading file: {}\", sourceSequenceFilePath);\n    }", "CodeBleu_score": 55.092403531249246}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t        LOG.info(\"start read sequence file, source path = [{}]\", sourceSequenceFilePath);\n        Path path = new Path(sourceSequenceFilePath);\n        FileSystem fs;\n        try {\n            fs = FileSystem.get(path.toUri(), readerSliceConfig);\n            FSDataInputStream inputStream = fs.open(path);\n            SequenceFile.Reader reader = new SequenceFile.Reader(fs, inputStream, readerSliceConfig);\n            Writable key = (Writable) reader.getKeyClass().newInstance();\n            Writable value = (Writable) reader.getValueClass().newInstance();\n            while (reader.next(key, value)) {\n                if (StringUtils.isNotBlank(value.toString())) {\n                    StorageReaderUtil.transportOneRecord(recordSender,\n                            readerSliceConfig,\n                            value.toString(),\n                            taskPluginCollector,\n                            this.getClass().getSimpleName());\n                }\n            }\n            reader.close();\n        } catch (Exception e) {\n            String message = String.format(\"read sequence file [%s] exception\", sourceSequenceFilePath);\n            LOG.error(message, e);\n            throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_SEQUENCEFILE_ERROR, e);\n        }\n    }", "CodeBleu_score": 55.386313416057654}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    FileSystem fs = null;\n    try {\n        fs = FileSystem.get(new URI(filepath), new Configuration());\n        if (fs.isFile(new Path(filepath))) {\n            String fileType = getFileType(fs, filepath);\n            if (specifiedFileType.equalsIgnoreCase(fileType)) {\n                return true;\n            } else {\n                return false;\n            }\n        } else {\n            return false;\n        }\n    } catch (Exception e) {\n        LOG.error(\"Exception while checking file type: \" + e.getMessage());\n        throw DataXException.asAddaxException(\n                HdfsReaderErrorCode.READ_FILE_ERROR, \"Exception while checking file type: \" + e.getMessage());\n    } finally {\n        IOUtils.closeStream(fs);\n    }\n}", "CodeBleu_score": 34.683353414175286}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    try {\n        FileSystem fs = FileSystem.get(new URI(filepath), conf);\n        Path path = new Path(filepath);\n        if (fs.exists(path)) {\n            if (specifiedFileType.equalsIgnoreCase(\"orc\")) {\n                return isORCFile(fs, path);\n            } else if (specifiedFileType.equalsIgnoreCase(\"rc\")) {\n                return isRCFile(fs, path);\n            } else if (specifiedFileType.equalsIgnoreCase(\"sequence\")) {\n                return isSequenceFile(fs, path);\n            } else if (specifiedFileType.equalsIgnoreCase(\"parquet\")) {\n                return isParquetFile(fs, path);\n            } else if (specifiedFileType.equalsIgnoreCase(\"csv\")) {\n                return isCSVFile(fs, path);\n            } else if (specifiedFileType.equalsIgnoreCase(\"text\")) {\n                return isTextFile(fs, path);\n            } else {\n                return false;\n            }\n        } else {\n            throw AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_NOT_EXISTS, \"\");\n        }\n    } catch (Exception e) {\n        LOG.error(\"Check file type failed: \" + e.getMessage());\n        throw AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_ERROR, \"\");\n    }\n}", "CodeBleu_score": 43.39558277092163}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    try {\n        FileSystem fs = FileFactory.getFileSystem(filepath);\n        if (fs.isFile(filepath)) {\n            String fileType = getFileType(fs, filepath);\n            if (fileType.equalsIgnoreCase(specifiedFileType)) {\n                return true;\n            }\n        }\n    } catch (Exception e) {\n        LOG.error(\"An error occurred while checking the file type for file \" + filepath + \".\", e);\n        throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, e);\n    }\n    return false;\n}", "CodeBleu_score": 25.89837797515343}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t    try {\n        if (hConnection != null) {\n            hConnection.close();\n        }\n    } catch (IOException e) {\n        throw new AddaxException(HBaseWriterErrorCode.CLOSE_HBASE_CONNECTION_ERROR, e);\n    }\n}", "CodeBleu_score": 58.980800892776486}, {"code": "public static void closeConnection(Connection hConnection){\n\t    if (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new AddaxException(AddaxException.HBASE_16, e);\n        }\n    }\n}", "CodeBleu_score": 51.939445742812}, {"code": "public static void closeConnection(Connection hConnection){\n\t    if (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new AddaxException(AddaxException.HBASE_14, e.getMessage());\n        }\n    }\n}", "CodeBleu_score": 46.7407586729801}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t    if (admin != null) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw new AddaxException(AddaxException.ADMIN_CLOSE_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 53.171850246590466}, {"code": "public static void closeAdmin(Admin admin){\n\t    if (admin != null) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw new AddaxException(Hbase11xHelper.class.getSimpleName() + \" close admin error: \" + e.getMessage(), e);\n        }\n    }\n}", "CodeBleu_score": 48.238606093360424}, {"code": "public static void closeAdmin(Admin admin){\n\t    if (admin != null) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw new AddaxException(HBaseWriterErrorCode.CLOSE_ADMIN_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 54.06662042624129}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\n        // Extract the row key, timestamp, column family, qualifier, and value from the cell\n        String rowKey = Bytes.toString(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength());\n        long timestamp = cell.getTimestamp();\n        String family = Bytes.toString(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength());\n        String qualifier = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());\n        String value = Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());\n\n        // Determine the type and format for the row key\n        String rowKeyType = getByTypeName(rowKeyTypeName);\n        String rowKeyFormat = getByTypeName(rowKeyFormatName);\n\n        // Determine the type and format for the column value\n        String columnValueType = getByTypeName(columnValueTypeName);\n        String columnValueFormat = getByTypeName(columnValueFormatName);\n\n        // Convert the extracted data to the appropriate types and add them as columns to the record\n        record.setStringField(rowKeyColumnName, rowKey);\n        record.setStringField(familyColumnName, family);\n        record.setStringField(qualifierColumnName, qualifier);\n        record.setLongField(timestampColumnName, timestamp);\n        record.setField(rowKeyColumnName, convertBytesToAssignType(rowKey, rowKeyType, rowKeyFormat));\n        record.setField(columnValueColumnName, convertBytesToAssignType(value, columnValueType, columnValueFormat));\n    }", "CodeBleu_score": 35.7266744634755}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t        String rowKey = Bytes.toString(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength());\n        String family = Bytes.toString(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength());\n        String qualifier = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());\n        String value = Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());\n        String timestamp = Bytes.toString(cell.getTimestampArray(), cell.getTimestampOffset(), cell.getTimestampLength());\n        String rowKeyType = getRowKeyType(family);\n        String columnType = getColumnType(family, qualifier);\n        String columnFormat = getColumnFormat(family, qualifier);\n        String columnName = getColumnName(family, qualifier);\n        String rowKeyFormat = getRowKeyFormat(family);\n        String timestampFormat = getTimestampFormat(family);\n        String rowKeyName = getRowKeyName(family);\n        String timestampName = getTimestampName(family);\n        String rowKeyValue = convertBytesToAssignType(rowKey, rowKeyType, rowKeyFormat, rowKeyName);\n        String columnValue = convertBytesToAssignType(value, columnType, columnFormat, columnName);\n        String timestampValue = convertBytesToAssignType(timestamp, \"long\", timestampFormat, timestampName);\n        if (rowKeyValue != null) {\n            record.add(rowKeyValue);\n        }\n        if (columnValue != null) {\n            record.add(columnValue);\n        }\n        if (timestampValue != null) {\n            record.add(timestampValue);\n        }\n    }", "CodeBleu_score": 30.84262513831768}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t        String rowKey = Bytes.toString(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength());\n        String family = Bytes.toString(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength());\n        String qualifier = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());\n        String value = Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());\n        Long timestamp = cell.getTimestamp();\n\n        // Add the row key to the record\n        record.setStringField(ROW_KEY, rowKey);\n\n        // Add the column family to the record\n        record.setStringField(COLUMN_FAMILY, family);\n\n        // Add the column qualifier to the record\n        record.setStringField(COLUMN_QUALIFIER, qualifier);\n\n        // Add the timestamp to the record\n        record.setLongField(TIMESTAMP, timestamp);\n\n        // Get the column value type and format\n        String valueType = getByTypeName(family, qualifier);\n\n        // Add the column value to the record\n        add(record, value, valueType);\n    }", "CodeBleu_score": 22.93761481532077}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t  String startRowkey = configuration.get(START_ROW_KEY);\n  if (isBlank(startRowkey)) {\n    return new byte[0];\n  }\n  return stringToBytes(startRowkey, configuration.get(BINARY_ROW_KEYS));\n}", "CodeBleu_score": 28.876594038546987}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t  String userStartRowKey = configuration.get(TableInputFormat.START_ROW);\n  if (isBlank(userStartRowKey)) {\n    return new byte[0];\n  }\n  if (isBinaryRowkey(configuration)) {\n    return stringToBytes(userStartRowKey);\n  }\n  return Bytes.toBytesBinary(userStartRowKey);\n}", "CodeBleu_score": 37.8732233741129}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t  String startRowkey = configuration.get(TableInputFormat.SCAN_START_ROW, \"\");\n  if (isBlank(startRowkey)) {\n    return new byte[0];\n  }\n  if (isBinaryRowkey(configuration)) {\n    return stringToBytes(startRowkey);\n  } else {\n    return Bytes.toBytesBinary(startRowkey);\n  }\n}", "CodeBleu_score": 40.71832803975617}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t  String startRowKey = configuration.getString(HBASE_INNER_START_ROWKEY);\n  if (StringUtils.isBlank(startRowKey)) {\n    return new byte[0];\n  } else {\n    return startRowKey.getBytes(StandardCharsets.UTF_8);\n  }\n}", "CodeBleu_score": 45.66721593588075}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowKey = configuration.getString(INNER_START_ROWKEY, \"\");\n\tif (isBlank(startRowKey)) {\n\t\treturn new byte[] {};\n\t}\n\treturn startRowKey.toBytesBinary();\n}", "CodeBleu_score": 37.982304414928436}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.getString(Constants.INNER_START_ROWKEY);\n\tif (StringUtils.isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t}\n\treturn startRowkey.toBytesBinary();\n}", "CodeBleu_score": 59.83730278564307}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.headers = new TbQueueMsgHeaders(record.headers());\n    this.data = record.value();\n}", "CodeBleu_score": 43.38814105979103}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.headers = new TbQueueMsgHeaders(record.headers());\n    this.value = record.value();\n}", "CodeBleu_score": 41.68596210596541}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.headers = new TbQueueMsgHeaders(record.headers());\n    this.value = record.value();\n}", "CodeBleu_score": 41.68596210596541}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    return createProducer(getNotificationsTopic(), getServiceId(), settings, admin);\n}", "CodeBleu_score": 10.958396894277907}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    return new TbKafkaProducerTemplate<>(getProducerConfig(), getNotificationsTopic(),\n            msg -> new TbProtoQueueMsg<>(msg.getKey(), ToTransportMsg.parseFrom(msg.getData()), msg.getHeaders()));\n}", "CodeBleu_score": 18.22838135072442}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    return createProducer(getNotificationsTopic(),\n            getServiceId(),\n            getSettings().getTransportNotificationsTopic(),\n            ToTransportMsg.class);\n}", "CodeBleu_score": 11.481390171358774}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    TbKafkaConsumerTemplate.TbKafkaConsumerTemplateBuilder<TbProtoQueueMsg<ToCoreNotificationMsg>> builder = TbKafkaConsumerTemplate.builder();\n    builder.settings(getSettings());\n    builder.topic(getTopic());\n    builder.clientId(getClientId());\n    builder.groupId(getGroupId());\n    builder.decoder(decoder);\n    builder.admin(admin);\n    builder.statisticsService(statsService);\n    return builder.build();\n}", "CodeBleu_score": 36.814184831695364}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    return build(getFullTopicName(ToCoreNotificationMsg.class),\n            new TbKafkaDecoder<>(getDataDecoder(), getHeadersDecoder()),\n            getConsumerProperties(getTopic(ToCoreNotificationMsg.class), getConsumerGroup()));\n}", "CodeBleu_score": 8.640436052901677}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    return createConsumer(getFullTopicName(ToCoreNotificationMsg.class),\n            getConsumerProperties(ToCoreNotificationMsg.class),\n            msg -> new TbProtoQueueMsg<>(msg.getKey(), ToCoreNotificationMsg.parseFrom(msg.getData()), msg.getHeaders()));\n}", "CodeBleu_score": 19.18127434760298}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (topicNames.isEmpty()) {\n        log.info(\"No topics provided. Unsubscribing from all topics\");\n        consumer.unsubscribe();\n        return;\n    }\n\n    for (String topicName : topicNames) {\n        if (!topicExists(topicName)) {\n            log.info(\"Topic {} does not exist. Creating it\", topicName);\n            createTopic(topicName);\n        }\n    }\n\n    log.info(\"Subscribing to topics: {}\", topicNames);\n    consumer.subscribe(topicNames);\n}", "CodeBleu_score": 51.74990436981377}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (topicNames.isEmpty()) {\n        LOG.info(\"{} is unsubscribed.\", consumerId);\n        unsubscribe();\n    } else {\n        LOG.info(\"{} is subscribed to {}\", consumerId, topicNames);\n        for (String topicName : topicNames) {\n            subscribe(topicName);\n        }\n    }\n}", "CodeBleu_score": 52.31966845796998}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (topicNames.isEmpty()) {\n        logger.info(\"Consumer {} is unsubscribed from all topics\", this);\n        consumer.unsubscribe();\n    } else {\n        logger.info(\"Consumer {} is subscribed to topics {}\", this, topicNames);\n        consumer.subscribe(topicNames);\n    }\n}", "CodeBleu_score": 56.29879453519146}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t    Stopwatch stopwatch = Stopwatch.createStarted();\n    logger.info(\"Polling for {}ms from topic {}\", durationInMillis, topic);\n    List<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n    ConsumerRecords<String, byte[]> consumerRecords = consumer.poll(Duration.ofMillis(durationInMillis));\n    stopwatch.stop();\n    logger.info(\"Polled for {}ms from topic {}\", stopwatch.elapsed(TimeUnit.MILLISECONDS), topic);\n    if (!consumerRecords.isEmpty()) {\n        for (ConsumerRecord<String, byte[]> record : consumerRecords) {\n            records.add(record);\n        }\n    }\n    return records;\n}", "CodeBleu_score": 52.08578556534172}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t    Stopwatch stopwatch = Stopwatch.createStarted();\n    logger.trace(\"Polling for {} ms\", durationInMillis);\n    List<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n    ConsumerRecords<String, byte[]> consumerRecords = consumer.poll(Duration.ofMillis(durationInMillis));\n    stopwatch.stop();\n    logger.trace(\"Polled for {} ms, found {} records\", stopwatch.elapsed(TimeUnit.MILLISECONDS), consumerRecords.count());\n    if (consumerRecords.count() == 0) {\n        return Collections.emptyList();\n    }\n    consumerRecords.forEach(records::add);\n    return records;\n}", "CodeBleu_score": 55.85635511448119}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t    Stopwatch stopwatch = Stopwatch.createStarted();\n    log.trace(\"Polling for {} ms\", durationInMillis);\n    List<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n    try {\n        ConsumerRecords<String, byte[]> consumerRecords = consumer.poll(Duration.ofMillis(durationInMillis));\n        stopwatch.stop();\n        log.trace(\"Polled {} records in {} ms\", consumerRecords.count(), stopwatch.elapsed(TimeUnit.MILLISECONDS));\n        if (consumerRecords.count() == 0) {\n            return emptyList();\n        }\n        consumerRecords.forEach(records::add);\n        return records;\n    } catch (Exception e) {\n        stopwatch.stop();\n        log.error(\"Failed to poll records in {} ms\", stopwatch.elapsed(TimeUnit.MILLISECONDS), e);\n        throw new KafkaPollException(e);\n    }\n}", "CodeBleu_score": 51.000046850050396}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    if (initError) {\n        log.error(\"[{}] Failed to initialize Kafka producer. See previous error messages for details\", ctx.getSelfId());\n        ctx.tellFailure(msg, initError);\n        return;\n    }\n    String topic = getTopicPattern(msg);\n    String key = getKeyPattern(msg);\n    try {\n        executeAsync(ctx, msg, topic, key);\n    } catch (Exception e) {\n        log.error(\"[{}] Failed to publish message to Kafka topic: {}\", ctx.getSelfId(), topic, e);\n        ctx.tellFailure(msg, e);\n    }\n}", "CodeBleu_score": 28.98932712123114}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    if (initError != null) {\n        log.error(\"[{}] Failed to initialize Kafka producer: {}\", ctx.getSelfId(), initError.getMessage());\n        ctx.tellFailure(msg, initError);\n        return;\n    }\n    String topicPattern = getTopicPattern(msg);\n    String keyPattern = getKeyPattern(msg);\n    if (topicPattern == null || keyPattern == null) {\n        log.error(\"[{}] Failed to determine topic or key pattern\", ctx.getSelfId());\n        ctx.tellFailure(msg, new IllegalArgumentException(\"Failed to determine topic or key pattern\"));\n        return;\n    }\n    try {\n        String topic = processPattern(topicPattern, msg);\n        String key = processPattern(keyPattern, msg);\n        if (topic == null || key == null) {\n            log.error(\"[{}] Failed to process topic or key pattern\", ctx.getSelfId());\n            ctx.tellFailure(msg, new IllegalArgumentException(\"Failed to process topic or key pattern\"));\n            return;\n        }\n        log.debug(\"[{}] Publishing message to topic {} with key {}\", ctx.getSelfId(), topic, key);\n        publish(ctx, msg, topic, key);\n    } catch (Exception e) {\n        log.error(\"[{}] Failed to publish message to topic\", ctx.getSelfId(), e);\n        ctx.tellFailure(msg, e);\n    }\n}", "CodeBleu_score": 44.78729187494438}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    if (msg.getMetaData().getValue(\"topic\") == null) {\n        ctx.tellFailure(msg, new IllegalArgumentException(\"Topic is not specified! Use msg.getMetaData().putValue(\\\"topic\\\", \\\"myTopic\\\") to specify topic.\"));\n        return;\n    }\n    String topic = getTopicPattern(msg);\n    String key = getKeyPattern(msg);\n    if (topic == null) {\n        ctx.tellFailure(msg, new IllegalArgumentException(\"Failed to evaluate topic pattern!\"));\n        return;\n    }\n    if (key == null) {\n        ctx.tellFailure(msg, new IllegalArgumentException(\"Failed to evaluate key pattern!\"));\n        return;\n    }\n    if (topic.isEmpty()) {\n        ctx.tellFailure(msg, new IllegalArgumentException(\"Topic pattern resulted with empty topic name!\"));\n        return;\n    }\n    try {\n        publish(ctx, msg, topic, key);\n    } catch (Exception e) {\n        ctx.tellFailure(msg, e);\n    }\n}", "CodeBleu_score": 35.70256171772044}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t    if (ctx.getSelfId().isPresent()) {\n        String selfId = ctx.getSelfId().get();\n        if (metadata.containsKey(selfId)) {\n            Map<String, String> metadataMap = metadata.get(selfId);\n            Map<String, String> headers = new HashMap<>();\n            for (String key : metadataMap.keySet()) {\n                headers.put(key, metadataMap.get(key));\n            }\n            ctx.send(msg, topic, key, headers, this::processRecord);\n        } else {\n            ctx.send(msg, topic, key, this::processRecord);\n        }\n    } else {\n        ctx.log().debug(msg, \"Failed to publish message to topic '{}' with key '{}' due to missing selfId\", topic, key);\n    }\n}", "CodeBleu_score": 36.862140151808724}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t  // Create a producer record\n  ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, msg.getData());\n  // Check if metadata should be added as headers\n  if (ctx.getMetaDataAddToMessage()) {\n    // Add metadata as headers\n    Map<String, String> metaData = ctx.getMetaDataValues(msg);\n    metaData.forEach(record::header);\n  }\n  // Send the record\n  try {\n    ctx.send(record);\n  } catch (Exception e) {\n    ctx.log().debug(ctx.getSelfId(), \"Failed to send message to topic \" + topic + \" with key \" + key, e);\n  }\n}", "CodeBleu_score": 29.345922578049553}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t    try {\n        if (msg.getMetaData().getData().size() > 0) {\n            ProducerRecord<String, byte[]> record = new ProducerRecord<>(topic, key, getBytes(msg));\n            msg.getMetaData().getData().forEach((k, v) -> record.headers().add(new RecordHeader(k, v.getBytes())));\n            processRecord(ctx, msg, record);\n        } else {\n            processRecord(ctx, msg, new ProducerRecord<>(topic, key, getBytes(msg)));\n        }\n    } catch (Exception e) {\n        ctx.tellFailure(msg, e);\n        ctx.log().debug(ctx.getSelfId(), \"Failed to send message to topic: \" + topic + \" with key: \" + key, e);\n    }\n}", "CodeBleu_score": 45.64202828540049}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\t    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            logger.error(\"Failed to close producer\", e);\n        }\n    }\n}", "CodeBleu_score": 68.28802047924664}, {"code": "public void destroy(){\n\t  if (producer != null) {\n    try {\n      producer.close();\n    } catch (Exception e) {\n      logger.error(\"Failed to close producer\", e);\n    }\n  }\n}", "CodeBleu_score": 64.20211838852671}, {"code": "public void destroy(){\n\t    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            logger.error(\"Failed to close Kafka producer\", e);\n        }\n    }\n}", "CodeBleu_score": 68.291721355429}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    log.info(\"Creating rule engine msg producer\");\n    String clientId = getServiceId();\n    TbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>, ToRuleEngineMsg> builder = TbKafkaProducerTemplate.builder();\n    builder.settings(settings);\n    builder.clientId(clientId);\n    builder.defaultTopic(defaultTopic);\n    builder.admin(admin);\n    return new TbKafkaProducerTemplate<>(builder.build());\n}", "CodeBleu_score": 45.98772379001304}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    return createTopicProducer(settings.getTopic());\n}", "CodeBleu_score": 11.53960446789276}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    return new TbKafkaProducerTemplate<>(createBuilder(), defaultTopic);\n}", "CodeBleu_score": 8.614550059464014}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\t    final long kafkaResponseTimeoutMs = getKafkaResponseTimeoutMs();\n    final long printIntervalMs = getPrintIntervalMs();\n    final boolean statsPrintRequired = isStatsPrintRequired();\n\n    if (statsPrintRequired) {\n        log.info(\"Scheduling periodic Kafka consumer group statistics logging every {}ms\", printIntervalMs);\n        final ScheduledFuture<?> future = scheduler.scheduleWithFixedDelay(new Runnable() {\n            @Override\n            public void run() {\n                try {\n                    if (statsPrintRequired) {\n                        getTopicsStatsWithLag().ifPresent(this::logStats);\n                    }\n                } catch (final Exception e) {\n                    log.warn(\"Exception while retrieving consumer group statistics: {}\", e.getMessage(), e);\n                }\n            }\n\n            private void logStats(final Map<String, TopicStats> topicStats) {\n                for (final Map.Entry<String, TopicStats> entry : topicStats.entrySet()) {\n                    final String groupId = entry.getKey();\n                    final TopicStats topicStat = entry.getValue();\n\n                    if (topicStat.hasLag()) {\n                        log.warn(\"Consumer group {} has lagging topics: {}\", groupId, topicStat);\n                    }\n                }\n            }\n        }, 0, printIntervalMs, TimeUnit.MILLISECONDS);\n\n        if (future.getDelay(TimeUnit.MILLISECONDS) > kafkaResponseTimeoutMs) {\n            log.warn(\"Kafka consumer group statistics logging task is scheduled with a delay longer than the Kafka response timeout. This may cause the task to fail.\");\n        }\n    }\n}", "CodeBleu_score": 37.592917312469154}, {"code": "private void startLogScheduling(){\n\t  final long printIntervalMs = getPrintIntervalMs();\n  if (printIntervalMs > 0) {\n    final ScheduledExecutorService scheduledExecutorService = Executors.newSingleThreadScheduledExecutor();\n    final Runnable task = () -> {\n      if (isStatsPrintRequired()) {\n        try {\n          getTopicsStatsWithLag().forEach((group, topicsStatsWithLag) -> {\n            if (!topicsStatsWithLag.isEmpty()) {\n              log.info(getMessage(\"monitor.log.group.stats.with.lag\", group, topicsStatsWithLag));\n            }\n          });\n        } catch (final Exception e) {\n          log.warn(getMessage(\"monitor.log.group.stats.with.lag.error\", group), e);\n        }\n      }\n    };\n    scheduledExecutorService.scheduleWithFixedDelay(task, printIntervalMs, printIntervalMs, TimeUnit.MILLISECONDS);\n  }\n}", "CodeBleu_score": 23.67626705916887}, {"code": "private void startLogScheduling(){\n\t    Duration kafkaResponseTimeout = Duration.ofMillis(getKafkaResponseTimeoutMs());\n    getScheduler().scheduleWithFixedDelay(\n        () -> {\n            if (isStatsPrintRequired()) {\n                getTopicsStatsWithLag().forEach((groupId, topicStats) -> {\n                    if (!topicStats.isEmpty()) {\n                        try {\n                            getLogger().info(\n                                \"Consumer group {} has {} topic(s) with lag: {}\",\n                                groupId,\n                                topicStats.size(),\n                                topicStats.toString()\n                            );\n                        } catch (Exception e) {\n                            getLogger().warn(\n                                \"Error while printing consumer group {} lag statistics: {}\",\n                                groupId,\n                                e.getMessage(),\n                                e\n                            );\n                        }\n                    }\n                });\n            }\n        },\n        kafkaResponseTimeout,\n        kafkaResponseTimeout\n    );\n}", "CodeBleu_score": 24.870365774045045}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\t    Properties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers());\n    props.put(AdminClientConfig.RETRIES_CONFIG, retries());\n    return props;\n}", "CodeBleu_score": 73.63853636708627}, {"code": "protected Properties toAdminProps(){\n\t  Properties props = toProps();\n  props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n  props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n  return props;\n}", "CodeBleu_score": 91.50543425528835}, {"code": "protected Properties toAdminProps(){\n\t    Properties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers());\n    props.put(AdminClientConfig.RETRIES_CONFIG, retries());\n    return props;\n}", "CodeBleu_score": 73.63853636708627}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\t// Create a MetricEvent with a scoped name and tags derived from the metric name and group\n\tMetricEvent event = new MetricEvent(\n\t\t\tmetric.getMetricIdentifier().withMetricGroup(group),\n\t\t\tmetric.getMetricIdentifier().getTagsFromMetricKey(),\n\t\t\tmetric.getScopeComponents());\n\n\t// Depending on the type of the metric (Counter, Gauge, Histogram, or Meter), it adds the metric and its event to the corresponding collection\n\tif (metric instanceof Counter) {\n\t\tCounter counter = (Counter) metric;\n\t\tcounterMetrics.put(event, counter);\n\t\tcounterEvents.add(event);\n\t} else if (metric instanceof Gauge) {\n\t\tGauge<?> gauge = (Gauge<?>) metric;\n\t\tgaugeMetrics.put(event, gauge);\n\t\tgaugeEvents.add(event);\n\t} else if (metric instanceof Histogram) {\n\t\tHistogram histogram = (Histogram) metric;\n\t\thistogramMetrics.put(event, histogram);\n\t\thistogramEvents.add(event);\n\t} else if (metric instanceof Meter) {\n\t\tMeter meter = (Meter) metric;\n\t\tmeterMetrics.put(event, meter);\n\t\tmeterEvents.add(event);\n\t} else {\n\t\tLOG.warn(\"Unknown metric type: {}\", metric.getClass().getName());\n\t}\n}", "CodeBleu_score": 47.569497947713145}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t    String scopedName = getScopedName(metricName, group);\n    Map<String, String> tags = getTags(metricName, group);\n    Class<? extends Metric> clazz = metric.getClass();\n    if (clazz == Counter.class) {\n        counters.put(scopedName, (Counter) metric);\n        put(metric, scopedName, tags, CounterEvent.class);\n    } else if (clazz == Gauge.class) {\n        gauges.put(scopedName, (Gauge<?>) metric);\n        put(metric, scopedName, tags, GaugeEvent.class);\n    } else if (clazz == Histogram.class) {\n        histograms.put(scopedName, (Histogram) metric);\n        put(metric, scopedName, tags, HistogramEvent.class);\n    } else if (clazz == Meter.class) {\n        meters.put(scopedName, (Meter) metric);\n        put(metric, scopedName, tags, MeterEvent.class);\n    } else {\n        warn(\"Unknown metric type: \" + clazz.getName() + \" for metric \" + metricName);\n    }\n}", "CodeBleu_score": 39.628900162888996}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t    final String scopedName = getScopedName(group, metricName);\n    final Map<String, String> tags = getTags(group, metricName);\n    final String className = getClass(metric);\n    final MetricEvent event = new MetricEvent(metric, scopedName, tags, className);\n\n    if (metric instanceof Counter) {\n        counters.put(scopedName, event);\n        counterEvents.add(event);\n    } else if (metric instanceof Gauge) {\n        gauges.put(scopedName, event);\n        gaugeEvents.add(event);\n    } else if (metric instanceof Histogram) {\n        histograms.put(scopedName, event);\n        histogramEvents.add(event);\n    } else if (metric instanceof Meter) {\n        meters.put(scopedName, event);\n        meterEvents.add(event);\n    } else {\n        warn(\n            \"Metric type {} is not supported. \" +\n                \"The metric {} will not be reported.\",\n            metric.getClass().getName(),\n            metricName\n        );\n    }\n}", "CodeBleu_score": 45.536974379334794}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t    if (metricEvent.getFields() == null) {\n        Map<String, Object> fields = new HashMap<>();\n        fields.put(field, getValue(gauge));\n        metricEvent.setFields(fields);\n    } else {\n        Map<String, Object> fields = metricEvent.getFields();\n        fields.put(field, getValue(gauge));\n    }\n    return metricEvent;\n}", "CodeBleu_score": 40.09405441450508}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t    Object value = gauge.getValue();\n    Map<String, Object> fields = metricEvent.getFields();\n    if (fields == null) {\n        fields = new HashMap<>();\n    }\n    if (value instanceof Number) {\n        fields.put(field, (Number) value);\n    } else if (value instanceof Boolean) {\n        fields.put(field, (Boolean) value ? 1 : 0);\n    } else if (value instanceof String) {\n        fields.put(field, (String) value);\n    } else {\n        fields.put(field, String.valueOf(value));\n    }\n    metricEvent.setFields(fields);\n    return metricEvent;\n}", "CodeBleu_score": 66.36730892434714}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t    Object value = gauge.getValue();\n    Map<String, Object> fields = metricEvent.getFields();\n    if (fields == null) {\n        fields = new HashMap<String, Object>();\n    }\n    fields.put(field, value);\n    metricEvent.setFields(fields);\n    return metricEvent;\n}", "CodeBleu_score": 38.97063800938993}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t    Map<String, Object> fields = metricEvent.getFields();\n    Map<String, Object> kafkaLagTimes = (Map<String, Object>) fields.get(KAFKA_LAG_TIMES);\n    if (kafkaLagTimes == null) {\n        kafkaLagTimes = new HashMap<>();\n        fields.put(KAFKA_LAG_TIMES, kafkaLagTimes);\n    }\n\n    Map<String, Object> kafkaLagMetrics = (Map<String, Object>) gauge.getValue();\n    Map<String, Object> kafkaLagMetricFields = new HashMap<>();\n    for (Map.Entry<String, Object> entry : kafkaLagMetrics.entrySet()) {\n        String metricName = entry.getKey();\n        Object metricValue = entry.getValue();\n        if (metricValue instanceof Number) {\n            kafkaLagMetricFields.put(metricName, metricValue);\n        }\n    }\n\n    if (kafkaLagMetricFields.size() > 0) {\n        // Check for changes in the Kafka lag metrics\n        Map<String, Object> previousKafkaLagMetricFields = (Map<String, Object>) kafkaLagTimes.get(timestamp);\n        if (previousKafkaLagMetricFields == null || !previousKafkaLagMetricFields.equals(kafkaLagMetricFields)) {\n            // Update the kafkaLagTimes map with the current Kafka lag metrics\n            kafkaLagTimes.put(timestamp, kafkaLagMetricFields);\n            // Set the event's timestamp to the current data timestamp\n            metricEvent.setTimestamp(timestamp);\n        }\n    }\n    return metricEvent;\n}", "CodeBleu_score": 31.404645939170877}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t    String metricName = gauge.getId().getName();\n    String[] metricNameParts = metricName.split(\"\\\\.\");\n    String metricNamePrefix = metricNameParts[0];\n    String metricNameSuffix = metricNameParts[metricNameParts.length - 1];\n    String metricNameTopic = metricNameParts[metricNameParts.length - 2];\n    String metricNameGroup = metricNameParts[metricNameParts.length - 3];\n    String metricNameClient = metricNameParts[metricNameParts.length - 4];\n    String metricNameBroker = metricNameParts[metricNameParts.length - 5];\n    String metricNameCluster = metricNameParts[metricNameParts.length - 6];\n    String metricNamePartition = metricNameParts[metricNameParts.length - 7];\n    String metricNameOffset = metricNameParts[metricNameParts.length - 8];\n    String metricNameLag = metricNameParts[metricNameParts.length - 9];\n    String metricNameType = metricNameParts[metricNameParts.length - 10];\n    String metricNameKey = metricNameCluster + \".\" + metricNameBroker + \".\" + metricNameGroup + \".\" + metricNameTopic + \".\" + metricNamePartition + \".\" + metricNameOffset;\n    String metricNameLagKey = metricNameCluster + \".\" + metricNameBroker + \".\" + metricNameGroup + \".\" + metricNameTopic + \".\" + metricNamePartition + \".\" + metricNameLag;\n    Long metricValue = (Long) gauge.getValue();\n    Long metricValueLag = (Long) kafkaLagTimes.get(metricNameLagKey);\n    Long metricValueOffset = (Long) kafkaLagTimes.get(metricNameKey);\n    Long metricValueTimestamp = (Long) kafkaLagTimes.get(metricNameLagKey + \".timestamp\");\n    if (metricValueOffset != null && metricValueOffset.equals(metricValue)) {\n        return null;\n    }\n    kafkaLagTimes.put(metricNameKey, metricValue);\n    kafkaLagTimes", "CodeBleu_score": 32.18777852224118}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t  Map<String, Object> fields = new HashMap<>();\n  Map<String, Object> tags = new HashMap<>();\n  String metricName = gauge.id().name();\n  String[] metricNameSplit = metricName.split(\"\\\\.\");\n  String topic = metricNameSplit[metricNameSplit.length - 1];\n  String consumerGroup = metricNameSplit[metricNameSplit.length - 2];\n  Long currentOffset = (Long) gauge.value();\n  Long committedOffset = (Long) kafkaLagTimes.get(consumerGroup + \".\" + topic);\n  if (currentOffset != committedOffset) {\n    kafkaLagTimes.put(consumerGroup + \".\" + topic, currentOffset);\n    fields.put(\"currentOffset\", currentOffset);\n    fields.put(\"committedOffset\", committedOffset);\n    fields.put(\"lag\", currentOffset - committedOffset);\n    tags.put(\"topic\", topic);\n    tags.put(\"consumerGroup\", consumerGroup);\n    metricEvent.setFields(fields);\n    metricEvent.setTags(tags);\n    metricEvent.setTimestamp(timestamp);\n  }\n  return metricEvent;\n}", "CodeBleu_score": 39.59886040809117}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\t\t\n\t\t// Get global job parameters\n\t\tProperties globalProperties = getConfig(env);\n\t\t\n\t\t// Get start from specific offsets\n\t\tMap<KafkaTopicPartition, Long> specificOffsets = getGlobalJobParameters(env, globalProperties, time);\n\t\t\n\t\t// Build Kafka properties\n\t\tProperties kafkaProps = buildKafkaProps(globalProperties);\n\t\t\n\t\t// Create Kafka consumer\n\t\tFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(\n\t\t\t\ttopic,\n\t\t\t\tnew MetricEventSchema(),\n\t\t\t\tkafkaProps);\n\t\t\n\t\t// Set start from specific offsets\n\t\tsetStartFromSpecificOffsets(consumer, specificOffsets);\n\t\t\n\t\t// Add the consumer to the StreamExecutionEnvironment\n\t\tDataStreamSource<MetricEvent> source = env.addSource(consumer);\n\t\t\n\t\treturn source;\n\t}", "CodeBleu_score": 55.50758053314435}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t    Map<String, Object> globalParams = getGlobalJobParameters(env);\n    Properties props = buildKafkaProps(globalParams);\n    FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), props);\n    if (time != null) {\n        setStartFromSpecificOffsets(consumer, time);\n    }\n    return env.addSource(consumer);\n}", "CodeBleu_score": 47.81591006184146}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t    // Get global job parameters\n    ParameterTool parameterTool = getConfig(env);\n\n    // Build Kafka properties\n    Properties props = buildKafkaProps(parameterTool);\n\n    // Create Kafka consumer\n    FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(\n            topic,\n            new MetricEventSchema(),\n            props);\n\n    // If a specific start time is provided, set consumer to start from specific offsets\n    if (time != null) {\n        Map<KafkaTopicPartition, Long> specificStartOffsets = buildOffsetByTime(consumer, time);\n        consumer.setStartFromSpecificOffsets(specificStartOffsets);\n    }\n\n    // Add Kafka consumer as source to the StreamExecutionEnvironment\n    DataStreamSource<MetricEvent> source = env.addSource(consumer);\n    return source;\n}", "CodeBleu_score": 66.75051338806301}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t    String topic = parameterTool.getRequired(\"topic\");\n    String groupId = parameterTool.getRequired(\"groupid\");\n    props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);\n\n    KafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(props);\n    Map<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\n\n    // Get the partitions for the topic\n    List<PartitionInfo> partitionInfoList = consumer.partitionsFor(topic);\n\n    // Create a map of partitions to the timestamp\n    Map<KafkaTopicPartition, Long> topicPartitionTimestamps = new HashMap<>();\n    for (PartitionInfo partitionInfo : partitionInfoList) {\n        topicPartitionTimestamps.put(new KafkaTopicPartition(topic, partitionInfo.partition()), time);\n    }\n\n    // Get the offsets for the partitions\n    Map<KafkaTopicPartition, OffsetAndTimestamp> partitionOffsetsByTimes = consumer.offsetsForTimes(topicPartitionTimestamps);\n\n    // Create a map of partitions to offsets\n    for (Map.Entry<KafkaTopicPartition, OffsetAndTimestamp> entry : partitionOffsetsByTimes.entrySet()) {\n        OffsetAndTimestamp offsetAndTimestamp = entry.getValue();\n        if (offsetAndTimestamp != null) {\n            partitionOffsets.put(entry.getKey(), offsetAndTimestamp.offset());\n        }\n    }\n\n    consumer.close();\n    return partitionOffsets;\n}", "CodeBleu_score": 48.86278235935359}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t    String topic = parameterTool.get(\"topic\");\n    String groupId = parameterTool.get(\"group.id\");\n    props.setProperty(\"group.id\", groupId);\n    KafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(props);\n    Map<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\n    Map<TopicPartition, Long> times = new HashMap<>();\n    List<PartitionInfo> partitions = consumer.partitionsFor(topic);\n    for (PartitionInfo partition : partitions) {\n        KafkaTopicPartition kafkaTopicPartition = new KafkaTopicPartition(topic, partition.partition());\n        partitionOffsets.put(kafkaTopicPartition, 0L);\n        times.put(new TopicPartition(topic, partition.partition()), time);\n    }\n    Map<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(times);\n    for (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : offsets.entrySet()) {\n        if (entry.getValue() != null) {\n            partitionOffsets.put(new KafkaTopicPartition(entry.getKey().topic(), entry.getKey().partition()), entry.getValue().offset());\n        }\n    }\n    consumer.close();\n    return partitionOffsets;\n}", "CodeBleu_score": 46.0611245191901}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t    final String groupId = parameterTool.getRequired(\"groupId\");\n    final String topic = parameterTool.getRequired(\"topic\");\n    final String offset = parameterTool.get(\"offset\", \"earliest\");\n\n    props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);\n    props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, offset);\n    props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringDeserializer\");\n    props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, \"org.apache.kafka.common.serialization.StringDeserializer\");\n\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n    Map<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\n\n    try {\n        List<PartitionInfo> partitionInfos = consumer.partitionsFor(topic);\n        List<KafkaTopicPartition> topicPartitions = new ArrayList<>();\n\n        for (PartitionInfo partitionInfo : partitionInfos) {\n            topicPartitions.add(new KafkaTopicPartition(partitionInfo.topic(), partitionInfo.partition()));\n        }\n\n        Map<KafkaTopicPartition, Long> timestampsToSearch = new HashMap<>();\n        for (KafkaTopicPartition topicPartition : topicPartitions) {\n            timestampsToSearch.put(topicPartition, time);\n        }\n\n        Map<KafkaTopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(timestampsToSearch);\n\n        for (Map.Entry<KafkaTopicPartition, OffsetAndTimestamp> entry : offsets.entrySet()) {\n            OffsetAndTimestamp offsetAndTimestamp = entry.getValue();\n            if (offsetAndTimestamp != null) {\n                partitionOffsets.put(entry.getKey(), offsetAndTimestamp.offset());\n            }\n        }\n    } finally {\n        consumer.close();\n    }\n\n    return partitionOffsets;\n}", "CodeBleu_score": 43.011093884466554}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"acks\", \"all\");\n    props.put(\"retries\", 0);\n    props.put(\"batch.size\", 16384);\n    props.put(\"linger.ms\", 1);\n    props.put(\"buffer.memory\", 33554432);\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    MetricEvent event = new MetricEvent();\n    event.setName(\"metric.name\");\n    event.setTimestamp(currentTimeMillis());\n    event.setTags(ImmutableMap.of(\"tag1\", \"value1\", \"tag2\", \"value2\"));\n    event.setFields(ImmutableMap.of(\"field1\", 1, \"field2\", 2));\n\n    ProducerRecord<String, String> record = new ProducerRecord<>(\n        \"topic\",\n        event.getName(),\n        event.toJson()\n    );\n\n    producer.send(record);\n\n    producer.flush();\n    println(\"Sent: \" + event.toJson());\n}", "CodeBleu_score": 52.07469355276368}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t    // Create producer properties\n    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n    // Create producer\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    // Create MetricEvent\n    MetricEvent event = new MetricEvent();\n    event.setName(\"jvm.memory.used\");\n    event.setTags(new HashMap<String, String>() {{\n        put(\"host\", \"localhost\");\n        put(\"region\", \"us-west\");\n    }});\n    event.setTimestamp(System.currentTimeMillis());\n    event.setFields(new HashMap<String, Object>() {{\n        put(\"value\", 1234567890);\n    }});\n\n    // Create ProducerRecord\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"telegraf\", event.toJson());\n\n    // Send data\n    producer.send(record);\n    producer.flush();\n    System.out.println(\"Sent: \" + event.toJson());\n}", "CodeBleu_score": 49.430013787671584}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t    // Create properties for Kafka producer\n    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"acks\", \"all\");\n    props.put(\"retries\", 0);\n    props.put(\"batch.size\", 16384);\n    props.put(\"linger.ms\", 1);\n    props.put(\"buffer.memory\", 33554432);\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    // Create a Kafka producer\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n    // Create a MetricEvent\n    MetricEvent event = new MetricEvent();\n    // Set the name, tags, and timestamp\n    event.setName(\"test\");\n    event.setTags(new HashMap<String, String>() {{\n        put(\"host\", \"localhost\");\n        put(\"region\", \"us-west\");\n    }});\n    event.setTimestamp(System.currentTimeMillis());\n    // Create a ProducerRecord\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"test\", event.toJson());\n    // Send the record to the topic\n    producer.send(record);\n    // Print the sent data\n    System.out.println(\"Sent: \" + event.toJson());\n    // Flush the producer to ensure all data is sent\n    producer.flush();\n}", "CodeBleu_score": 51.52437735312352}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    if (event.getLevel().isMoreSpecificThan(getLevel()) && !event.getLoggerName().contains(\"xxx\")) {\n        try {\n            producer.send(new ProducerRecord<String, String>(topic, event.getMessage().getFormattedMessage()));\n        } catch (Exception e) {\n            event.getLogger().warn(\"Unable to send event to Kafka topic \" + topic, e);\n        }\n    }\n}", "CodeBleu_score": 51.80240212148881}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    if (isLevelEnabled(event.getLevel()) && !event.getLoggerName().contains(\"xxx\")) {\n        try {\n            producer.send(new ProducerRecord<String, String>(topic, event.getLevel().toString(), event.getMessage().getFormattedMessage()));\n        } catch (Exception e) {\n            logger.warn(\"Failed to send log event to Kafka topic {}\", topic, e);\n        }\n    }\n}", "CodeBleu_score": 59.704452768442096}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    if (event.getLevel().isMoreSpecificThan(getLevel()) && !event.getLoggerName().contains(\"xxx\")) {\n        try {\n            producer.send(new ProducerRecord<String, String>(topic, event.getMessage().getFormattedMessage()));\n        } catch (Exception e) {\n            logger.warn(\"Failed to send event to Kafka topic {}\", topic, e);\n        }\n    }\n}", "CodeBleu_score": 46.19640788411159}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tvalidMethods := []string{\n\t\t\"random\",\n\t\t\"uuid\",\n\t\t\"timestamp\",\n\t}\n\tfor _, m := range validMethods {\n\t\tif m == method {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 72.610880903859}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tvalidTopicSuffixMethods := []string{\n\t\t\"\",\n\t\t\"first\",\n\t\t\"last\",\n\t\t\"all\",\n\t}\n\n\tfor _, validTopicSuffixMethod := range validTopicSuffixMethods {\n\t\tif method == validTopicSuffixMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 72.60495252305134}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 89.40480295903943}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \"\" {\n\t\tif v, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn v, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 57.412037867450785}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \"\" {\n\t\tif v, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn v, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\tu, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn u.String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 86.92270400846459}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \"\" {\n\t\tif v, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn v, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\tu, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn u.String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 86.92270400846459}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.topicRegexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tr, err := regexp.Compile(topicRegexp)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile topic regexp %s: %w\", topicRegexp, err)\n\t\t}\n\t\tk.topicRegexps[i] = r\n\t}\n\treturn nil\n}", "CodeBleu_score": 57.69628940832783}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tif len(k.TopicRegexps) == 0 {\n\t\treturn nil\n\t}\n\n\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tregexp, err := regexp.Compile(topicRegexp)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regexp %q: %w\", topicRegexp, err)\n\t\t}\n\t\tk.regexps[i] = regexp\n\t}\n\n\treturn nil\n}", "CodeBleu_score": 55.26330005256555}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.topicRegexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, regex := range k.TopicRegexps {\n\t\tre, err := regexp.Compile(regex)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regex %q: %w\", regex, err)\n\t\t}\n\t\tk.topicRegexps[i] = re\n\t}\n\treturn nil\n}", "CodeBleu_score": 60.69280344073156}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif !ok {\n\t\th.mu.Unlock()\n\t\treturn\n\t}\n\tdelete(h.undelivered, track.ID)\n\th.mu.Unlock()\n\n\tif msg.session != nil {\n\t\tmsg.session.MarkMessage(msg, \"\")\n\t}\n\n\tif track.State == telegraf.Delivered {\n\t\tmsg.Delivered()\n\t} else {\n\t\tmsg.Undelivered(fmt.Errorf(\"delivery state: %s\", track.State))\n\t}\n\n\th.sem <- struct{}{}\n}", "CodeBleu_score": 56.773841273526884}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif ok {\n\t\tdelete(h.undelivered, track.ID)\n\t\th.sem <- struct{}{}\n\t}\n\th.mu.Unlock()\n\n\tif ok {\n\t\tmsg.session.MarkMessage(msg.message, \"\")\n\t\tmsg.Delivered()\n\t}\n}", "CodeBleu_score": 56.28203350441241}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.ID]\n\tif !ok {\n\t\treturn\n\t}\n\tdelete(h.undelivered, track.ID)\n\n\tif !msg.Delivered() {\n\t\tmsg.MarkDelivered()\n\t\th.session.MarkMessage(msg, \"\")\n\t}\n\n\th.sem <- struct{}{}\n}", "CodeBleu_score": 55.5015976300695}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase <-claim.Messages():\n\t\t\tif err := h.Handle(ctx, session, claim); err != nil {\n\t\t\t\th.acc.AddError(err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 51.20694190066962}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := h.Context(session.Context())\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.Handle(ctx, msg); err != nil {\n\t\t\t\th.acc.AddError(err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 63.14279732416491}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := h.Context(session)\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg := <-claim.Messages():\n\t\t\tif err := h.Reserve(ctx, msg); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err := h.Handle(ctx, msg); err != nil {\n\t\t\t\th.acc.AddError(err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 71.8725529520905}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\t  if (logkafka_id.isEmpty)\n    throw new IllegalArgumentException(\"The Logkafka ID cannot be empty\")\n  else if (logkafka_id == \".\")\n    throw new IllegalArgumentException(\"The Logkafka ID cannot be \\\".\\\"\")\n  else if (logkafka_id == \"..\")\n    throw new IllegalArgumentException(\"The Logkafka ID cannot be \\\"..\\\"\")\n  else if (logkafka_id.length > 255)\n    throw new IllegalArgumentException(\"The Logkafka ID cannot exceed 255 characters\")\n  else if (!rgx.findFirstIn(logkafka_id).equals(logkafka_id))\n    throw new IllegalArgumentException(\"The Logkafka ID contains invalid characters\")\n}", "CodeBleu_score": 27.240361505897205}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t  val rgx = \"\"\"^[a-zA-Z0-9\\-_]+$\"\"\".r\n  val t = rgx.findFirstIn(logkafka_id)\n  t match {\n    case Some(x) =>\n      if (logkafka_id.equals(\".\")) {\n        throw new IllegalArgumentException(s\"Logkafka ID cannot be '.'\")\n      } else if (logkafka_id.equals(\"..\")) {\n        throw new IllegalArgumentException(s\"Logkafka ID cannot be '..'\")\n      } else if (logkafka_id.length > 255) {\n        throw new IllegalArgumentException(s\"Logkafka ID cannot be longer than 255 characters\")\n      } else if (logkafka_id.isEmpty) {\n        throw new IllegalArgumentException(s\"Logkafka ID cannot be empty\")\n      } else {\n        logkafka_id\n      }\n    case None =>\n      throw new IllegalArgumentException(s\"Logkafka ID contains invalid characters\")\n  }\n}", "CodeBleu_score": 23.42744697716211}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t  // Check that the Logkafka ID is not empty\n  if (logkafka_id.equals(\"\")) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be empty.\")\n  }\n\n  // Check that the Logkafka ID is not equal to \".\" or \"..\"\n  if (logkafka_id.equals(\".\") || logkafka_id.equals(\"..\")) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be \\\".\\\" or \\\"..\\\".\")\n  }\n\n  // Check that the Logkafka ID does not exceed the maximum allowed length\n  if (logkafka_id.length > 255) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot exceed 255 characters in length.\")\n  }\n\n  // Check that the Logkafka ID contains only valid characters\n  val rgx = \"\"\"^[a-zA-Z0-9\\._\\-]+$\"\"\".r\n  if (!rgx.findFirstIn(logkafka_id).isDefined) {\n    throw new IllegalCharacterInLogkafkaId(\"Logkafka ID contains invalid characters.\")\n  }\n}", "CodeBleu_score": 29.882176018208305}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse => \n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) => \n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover\n  }", "CodeBleu_score": 67.62408264969089}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse => \n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) => \n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover\n    {\n      case t: Throwable =>\n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 81.33626965385426}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse => \n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) => \n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover {\n      case t: Throwable => \n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 81.44723901834882}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case t: Throwable => -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 75.0306295608407}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case t: Throwable => -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 75.0306295608407}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case t: Throwable => -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 75.0306295608407}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val kmCommand = KMClusterCommandRequest(clusterName, KMClusterCommandRequest.RunPreferredLeaderElection(topics))\n    sendCommand(kmCommand)\n  }", "CodeBleu_score": 17.99947082203111}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val command = KMClusterCommandRequest(\n      clusterName,\n      PreferredLeaderElection(topics)\n    )\n    sendCommand(command)\n  }", "CodeBleu_score": 20.22983883860668}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val command = KMCommandRequest(KMCommandRequest.RunPreferredLeaderElection,\n      KMRunPreferredLeaderElectionRequest(clusterName, topics))\n    runCommand(command)\n  }", "CodeBleu_score": 19.421287603634113}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t  getTopicList(clusterName).flatMap {\n    case Right(topicList) => runPreferredLeaderElection(clusterName, topicList)\n    case Left(error) => Future.successful(Left(error))\n  }\n}", "CodeBleu_score": 21.029156673489567}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t  implicit val ec = ExecutionContext.global\n  getTopicList(clusterName).flatMap {\n    errorOrTopicList =>\n      errorOrTopicList.fold(\n        error => Future.failed(error),\n        topicList => runPreferredLeaderElection(clusterName, topicList)\n      )\n  }\n}", "CodeBleu_score": 37.7105078759887}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t  getTopicList(clusterName).flatMap {\n    topicList =>\n      runPreferredLeaderElection(topicList, clusterName)\n  }\n}", "CodeBleu_score": 14.04026941404251}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t  val results = tryWithKafkaManagerActor(\n    KMClusterCommandRequest(\n      clusterName,\n      CMManualPartitionAssignments(assignments)\n    )\n  )\n  results.map {\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg))\n    case \\/-(-\\/(e)) => -\\/(ApiError(e.msg", "CodeBleu_score": 21.865737188866756}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t  val results = tryWithKafkaManagerActor(\n    KMClusterCommandRequest(\n      clusterName,\n      CMManualPartitionAssignments(assignments)\n    )\n  )\n  results.map(_.result).collect{\n    case \\/-(ApiError(e)) => e\n  }\n}", "CodeBleu_score": 22.20814173283176}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t  tryWithKafkaManagerActor(\n      KMClusterCommandRequest (\n        clusterName,\n        CMManualPartitionAssignments(assignments)\n      )\n    ) map {\n      case Right(r) =>\n        r.result.collect {\n          case KMCommandResult.Success => true\n          case KMCommandResult.Error(e) => e\n        }\n      case Left(e) =>\n        Seq(ApiError(e.msg))\n    }\n}", "CodeBleu_score": 31.486575911506186}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t  // Retrieve the nodes\n  final Collection<Node> nodes = describeCluster(admin, 10000);\n  // If no nodes are available, throw an exception\n  if (nodes.isEmpty()) {\n    throw new ConnectException(\"No nodes found in cluster.\");\n  }\n  // Select the first node's ID\n  final int nodeId = nodes.iterator().next().id();\n  // Request the configuration of the node\n  final Config config = get(admin, nodeId, 10000);\n  // If no configuration is received, throw an exception\n  if (config.entries().isEmpty()) {\n    throw new ConnectException(\"No configuration found for node \" + nodeId);\n  }\n  return config;\n}", "CodeBleu_score": 39.35293534774659}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    log.debug(\"Getting Kafka broker configuration\");\n    DescribeClusterResult clusterResult = admin.describeCluster(getTimeout());\n    Collection<Node> nodes = clusterResult.nodes().get(getTimeout().toMillis(), TimeUnit.MILLISECONDS);\n    if (nodes.isEmpty()) {\n        throw new ConnectException(\"No Kafka brokers available\");\n    }\n    Config brokerConfig = admin.describeConfigs(Collections.singleton(nodes.iterator().next().idString())).all().get(getTimeout().toMillis(), TimeUnit.MILLISECONDS).get(nodes.iterator().next().idString());\n    if (brokerConfig.entries().isEmpty()) {\n        throw new ConnectException(\"No configuration received\");\n    }\n    log.debug(\"Kafka broker configuration received\");\n    return brokerConfig;\n}", "CodeBleu_score": 57.36612557418468}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    Config config = null;\n    try {\n        DescribeClusterResult result = admin.describeCluster(new DescribeClusterOptions().timeoutMs(10000));\n        Collection<Node> nodes = result.nodes().get();\n        if (nodes.size() == 0) {\n            throw new ConnectException(\"No Kafka nodes found\");\n        }\n        Node node = nodes.iterator().next();\n        ConfigResource resource = new ConfigResource(ConfigResource.Type.BROKER, Integer.toString(node.id()));\n        DescribeConfigsResult configs = admin.describeConfigs(Collections.singleton(resource));\n        Map<ConfigResource, Config> configMap = configs.all().get();\n        config = configMap.get(resource);\n        if (config == null) {\n            throw new ConnectException(\"No configurations found for Kafka node \" + node.id());\n        }\n    } catch (Exception e) {\n        throw new ConnectException(\"Failed to get Kafka broker config\", e);\n    }\n    return config;\n}", "CodeBleu_score": 50.795910151958644}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t  return new Validator() {\n    @Override\n    public void ensureValid(final String name, final Object value) {\n      if (SchemaHistory.Kafka.equals(SchemaHistory.of(value))) {\n        validator.ensureValid(name, value);\n      }\n    }\n\n    @Override\n    public String toString() {\n      return validator.toString();\n    }\n  };\n}", "CodeBleu_score": 30.69295305325661}, {"code": "private static Validator forKafka(final Validator validator){\n\t    return (name, value) -> {\n        if (SchemaHistory.Kafka.equals(SchemaHistory.forValue(value))) {\n            return validator.validate(name, value);\n        }\n        return 0;\n    };\n}", "CodeBleu_score": 25.146125411871743}, {"code": "private static Validator forKafka(final Validator validator){\n\t    return new Validator() {\n        @Override\n        public ValidationResult validate(final Configuration config) {\n            final String schemaHistory = config.getString(SchemaRegistryClientConfig.SCHEMA_REGISTRY_SCHEMA_HISTORY_LEVEL_CONFIG);\n            if (schemaHistory.equals(SchemaRegistryClientConfig.SchemaRegistrySchemaHistory.KAFKA.name)) {\n                return validator.validate(config);\n            }\n            return new ValidationResult();\n        }\n    };\n}", "CodeBleu_score": 34.89927054141716}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t    if (config == null) {\n        return false\n    }\n\n    if (config.containsKey(\"topic.creation.enable\")) {\n        return config.get(\"topic.creation.enable\").toString().toBoolean()\n    }\n\n    return true\n}", "CodeBleu_score": 15.833548768352316}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t    if (version == null) {\n        version = parseVersion(get(config, \"version\", \"2.4.0\"))\n    }\n    if (version == null) {\n        return true\n    }\n    if (version.compareTo(parseVersion(\"2.4.0\")) < 0) {\n        return true\n    }\n    return getBoolean(config, \"topic.creation.enable\", true)\n}", "CodeBleu_score": 28.46926433884398}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t  def version = getVersion(config)\n  def enabled = parseBoolean(config.getOrDefault(\"topic.creation.enable\", \"true\"))\n  def kafkaVersion = parseVersion(version)\n  def minVersion = parseVersion(\"2.0.0\")\n  return kafkaVersion >= minVersion && enabled\n}", "CodeBleu_score": 33.28216929794533}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t  String clientId = config.getOrDefault(\"client.id\", \"spark-kafka-offset-backing-store\");\n  Properties adminProperties = new Properties();\n  adminProperties.put(\"bootstrap.servers\", config.get(\"bootstrap.servers\"));\n  adminProperties.put(\"client.id\", clientId);\n  adminProperties.put(\"group.id\", config.get(\"group.id\"));\n  adminProperties.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n  adminProperties.put(\"value.serializer\", \"org.apache.kafka.common.serialization.ByteArraySerializer\");\n  adminProperties.put(\"enable.auto.commit\", \"false\");\n  adminProperties.put(\"auto.offset.reset\", \"earliest\");\n  adminProperties.put(\"max.poll.interval.ms\", \"300000\");\n  adminProperties.put(\"max.poll.records\", \"1000\");\n  adminProperties.put(\"session.timeout.ms\", \"30000\");\n  adminProperties.put(\"request.timeout.ms\", \"30000\");\n  SharedTopicAdmin admin = new SharedTopicAdmin(adminProperties);\n  return new KafkaOffsetBackingStore(admin, clientId, converterForOffsetStore(config));\n}", "CodeBleu_score": 30.044248035133624}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t    String clientId = config.getOrDefault(\"client.id\", \"kafka-offset-backing-store\");\n    Properties adminProperties = new Properties();\n    adminProperties.put(\"bootstrap.servers\", config.get(\"bootstrap.servers\"));\n    adminProperties.put(\"client.id\", clientId);\n    adminProperties.put(\"group.id\", clientId);\n    adminProperties.put(\"enable.auto.commit\", \"false\");\n    adminProperties.put(\"auto.offset.reset\", \"earliest\");\n    adminProperties.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    adminProperties.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    SharedTopicAdmin admin = new SharedTopicAdmin(adminProperties);\n    String offsetStoreName = config.getOrDefault(\"offset.store.name\", \"__consumer_offsets\");\n    String offsetStoreReplicationFactor = config.getOrDefault(\"offset.store.replication.factor\", \"1\");\n    String offsetStorePartitions = config.getOrDefault(\"offset.store.partitions\", \"1\");\n    String offsetStoreRetentionMs = config.getOrDefault(\"offset.store.retention.ms\", \"-1\");\n    String offsetStoreRetentionBytes = config.getOrDefault(\"offset.store.retention.bytes\", \"-1\");\n    String offsetStoreCleanupPolicy = config.getOrDefault(\"offset.store.cleanup.policy\", \"delete\");\n    String offsetStoreCompressionType = config.getOrDefault(\"offset.store.compression.type\", \"producer\");\n    String offsetStoreSegmentBytes = config.getOrDefault(\"offset.store.segment.bytes\", \"1048576\");\n    String offsetStoreSegmentIndexBytes = config.getOrDefault(\"offset.store.segment.index.bytes\", \"1048576\");\n    String offsetStoreSegmentJitterMs = config.getOrDefault(\"offset.store.segment.jitter.ms\", \"0\");\n    String offsetStoreMinInsyncReplicas = config.getOrDefault(\"offset.store.min.insync.replicas\", \"1\");\n   ", "CodeBleu_score": 26.754064740231975}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t  Objects.requireNonNull(config, \"config can not be null\");\n  String clientId = config.getOrDefault(\"client.id\", \"kafka-offset-backing-store\");\n  String offsetTopic = config.getOrDefault(\"offset.topic\", \"__consumer_offsets\");\n  String offsetTopicReplicationFactor = config.getOrDefault(\"offset.topic.replication.factor\", \"1\");\n  String offsetTopicPartitions = config.getOrDefault(\"offset.topic.partitions\", \"50\");\n  String offsetTopicConfigs = config.getOrDefault(\"offset.topic.configs\", \"\");\n  String offsetStoreConverterClass = config.getOrDefault(\"offset.store.converter.class\", \"com.lightbend.kafka.scala.offsetstore.OffsetStoreConverter\");\n  String offsetStoreConverterConfigs = config.getOrDefault(\"offset.store.converter.configs\", \"\");\n  String adminClientConfigs = config.getOrDefault(\"admin.client.configs\", \"\");\n  Properties adminProperties = new Properties();\n  adminProperties.put(\"bootstrap.servers\", config.get(\"bootstrap.servers\"));\n  adminProperties.put(\"client.id\", clientId);\n  adminProperties.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n  adminProperties.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n  adminProperties.putAll(parseProperties(adminClientConfigs));\n  SharedTopicAdmin admin = new SharedTopicAdmin(adminProperties);\n  try {\n    admin.createTopic(offsetTopic, Integer.parseInt(offsetTopicPartitions), Integer.parseInt(offsetTopicReplicationFactor), parseProperties(offsetTopicConfigs));\n  } catch (Exception e) {\n    log.warn(\"Unable to create offset topic \" + offsetTopic + \" with \" + offsetTopicPartitions + \" partitions and \" + offsetTopicReplicationFactor + \" replication factor\", e);\n  }\n  OffsetStoreConverter converter = (OffsetStoreConverter) Class.forName(offsetStoreConverterClass).getDeclaredConstructor().newInstance();\n  converter.", "CodeBleu_score": 28.264644979335568}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\t  if (!node.isObject()) {\n    throw new IOException(\"Key is not an object\");\n  }\n  JsonNode payloadNode = node.get(PAYLOAD_FIELD);\n  if (payloadNode != null) {\n    node = payloadNode;\n  }\n  Iterator<String> fieldNames = node.fieldNames();\n  if (!fieldNames.hasNext()) {\n    throw new IOException(\"Key has no fields\");\n  }\n  String fieldName = fieldNames.next();\n  if (!fieldNames.hasNext()) {\n    return readValue(node.get(fieldName));\n  }\n  // If there are multiple fields, the key is composite.\n  Map<String, T> map = new HashMap<>();\n  map.put(fieldName, readValue(node.get(fieldName)));\n  while (fieldNames.hasNext()) {\n    fieldName = fieldNames.next();\n    map.put(fieldName, readValue(node.get(fieldName)));\n  }\n  return (T) map;\n}", "CodeBleu_score": 45.022846123751634}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t    if (!node.isObject()) {\n        throw new IOException(\"Expected object node\");\n    }\n\n    JsonNode payloadNode = node.get(payloadFieldName);\n    if (payloadNode != null) {\n        node = payloadNode;\n    }\n\n    Iterator<String> fieldNames = node.fieldNames();\n    if (!fieldNames.hasNext()) {\n        throw new IOException(\"Expected at least one field\");\n    }\n\n    String fieldName = fieldNames.next();\n    if (!fieldNames.hasNext()) {\n        return readValue(node, fieldName);\n    }\n\n    Map<String, Object> compositeKey = new LinkedHashMap<>();\n    compositeKey.put(fieldName, readValue(node, fieldName));\n    while (fieldNames.hasNext()) {\n        fieldName = fieldNames.next();\n        compositeKey.put(fieldName, readValue(node, fieldName));\n    }\n\n    return (T) compositeKey;\n}", "CodeBleu_score": 43.861290412472286}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t  if (!node.isObject()) {\n    throw new IOException(\"Invalid key: expected an object, got \" + node.getNodeType());\n  }\n  JsonNode payload = node.get(\"payload\");\n  if (payload != null) {\n    node = payload;\n  }\n  Iterator<String> fieldNames = node.getFieldNames();\n  if (!fieldNames.hasNext()) {\n    throw new IOException(\"Invalid key: object has no fields\");\n  }\n  String fieldName = fieldNames.next();\n  if (!fieldNames.hasNext()) {\n    return readValue(node.get(fieldName));\n  }\n  return readValue(node);\n}", "CodeBleu_score": 45.16030254995794}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t  String topicName = topicNameFor(id, prefix, delimiter);\n  boolean sanitized = false;\n  StringBuilder sb = new StringBuilder();\n  for (int i = 0; i < topicName.length(); i++) {\n    char c = topicName.charAt(i);\n    if (isValidTopicNameCharacter(c)) {\n      sb.append(c);\n    } else {\n      sb.append(REPLACEMENT_CHARACTER);\n      sanitized = true;\n    }\n  }\n  if (sanitized) {\n    warn(\"Sanitized topic name: \" + topicName + \" -> \" + sb.toString());\n  }\n  return sb.toString();\n}", "CodeBleu_score": 46.73707310305307}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t    String topicName = delegate.topicNameFor(id, prefix, delimiter);\n    StringBuilder sanitizedTopicName = new StringBuilder();\n    boolean anyReplacements = false;\n    for (int i = 0; i < topicName.length(); i++) {\n        char c = topicName.charAt(i);\n        if (isValidTopicNameCharacter(c)) {\n            sanitizedTopicName.append(c);\n        } else {\n            sanitizedTopicName.append(REPLACEMENT_CHARACTER);\n            anyReplacements = true;\n        }\n    }\n    if (anyReplacements) {\n        log.warn(\"Sanitized topic name '{}'\", sanitizedTopicName);\n    }\n    return sanitizedTopicName.toString();\n}", "CodeBleu_score": 55.35299598369554}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t\tString topicName = delegate.topicNameFor(id, prefix, delimiter);\n\tStringBuilder sanitizedTopicName = new StringBuilder();\n\tfor (int i = 0; i < topicName.length(); i++) {\n\t\tchar c = topicName.charAt(i);\n\t\tif (isValidTopicNameCharacter(c)) {\n\t\t\tsanitizedTopicName.append(c);\n\t\t} else {\n\t\t\tsanitizedTopicName.append(REPLACEMENT_CHARACTER);\n\t\t\twarn(\"Invalid topic name character: \" + c + \" in \" + topicName);\n\t\t}\n\t}\n\tif (sanitizedTopicName.length() != topicName.length()) {\n\t\twarn(\"Sanitized topic name: \" + sanitizedTopicName + \" for \" + topicName);\n\t}\n\treturn sanitizedTopicName.toString();\n}", "CodeBleu_score": 46.87421331537263}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t    this.connectorType = connectorType;\n    this.connectorConfig = connectorConfig;\n    this.queue = queue;\n    this.maxRetries = getMaxRetriesOnError(connectorConfig, replacedErrorHandler);\n    this.retries = replacedErrorHandler != null ? replacedErrorHandler.retries : 0;\n}", "CodeBleu_score": 43.88471402735252}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t    this.connectorType = connectorType;\n    this.connectorConfig = connectorConfig;\n    this.queue = queue;\n    this.producerThrowable = replacedErrorHandler != null ? replacedErrorHandler.producerThrowable : new AtomicReference<>();\n    this.maxRetries = getMaxRetriesOnError(replacedErrorHandler);\n    this.retries = replacedErrorHandler != null ? replacedErrorHandler.retries : 0;\n}", "CodeBleu_score": 53.12723761062125}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t    this.connectorType = connectorType;\n    this.connectorConfig = connectorConfig;\n    this.queue = queue;\n    this.replacedErrorHandler = replacedErrorHandler;\n    this.producerThrowable = new AtomicReference<>();\n\n    if (replacedErrorHandler != null) {\n        this.maxRetries = replacedErrorHandler.getMaxRetriesOnError();\n        this.retries = replacedErrorHandler.getRetries();\n    }\n    else {\n        this.maxRetries = connectorConfig.getMaxRetries();\n        this.retries = 0;\n    }\n}", "CodeBleu_score": 67.35304073334405}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\n    Map<String, ValidationResult> results = configuration.validate(fields);\n\n    for (Map.Entry<String, ValidationResult> result : results.entrySet()) {\n        if (result.getValue().hasErrors()) {\n            throw new ConfigException(result.getValue().getErrors().get(0));\n        }\n    }\n}", "CodeBleu_score": 43.97092488316972}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t    if (configuration.validate(fields).hasErrors()) {\n        throw new ConfigException(configuration.validate(fields).errorMessages().get(0));\n    }\n}", "CodeBleu_score": 18.234898064968082}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t  for (Field field : fields) {\n    String name = field.getName();\n    Field.ValidationResult result = configuration.validate(field);\n    if (!result.getMessages().isEmpty()) {\n      throw new ConfigException(\n        \"Invalid value for '\" + name + \"': \" + result.getMessages().get(0));\n    }\n  }\n}", "CodeBleu_score": 37.34723816970086}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t    if (oldSchema.isPrimitive()) {\n        return oldSchema\n    }\n    SchemaBuilder newSchemaBuilder = SchemaBuilder.builder().struct()\n    if (oldSchema.getType() == Schema.Type.STRUCT) {\n        for (Schema.Field oldField : oldSchema.fields()) {\n            String oldFieldName = oldField.name()\n            Schema oldFieldSchema = oldField.schema()\n            if (oldFieldName == fieldName) {\n                continue\n            }\n            if (oldFieldName in headerToProcess) {\n                Header header = headerToProcess.remove(oldFieldName)\n                newSchemaBuilder.field(header.name, header.schema)\n                log.debug(\"${\"  \" * level}Added field ${header.name} of type ${header.schema}\")\n            } else {\n                if (oldFieldSchema.type == Schema.Type.STRUCT) {\n                    newSchemaBuilder.field(oldFieldName, buildNewSchema(oldFieldName, oldFieldSchema, headerToProcess, nestedFields, level + 1))\n                    log.debug(\"${\"  \" * level}Copied field ${oldFieldName} of type ${oldFieldSchema}\")\n                } else {\n                    newSchemaBuilder.field(oldFieldName, oldFieldSchema)\n                    log.debug(\"${\"  \" * level}Copied field ${oldFieldName} of type ${oldFieldSchema}\")\n                }\n            }\n        }\n    } else if (oldSchema.type == Schema.Type.MAP) {\n        newSchemaBuilder.map(oldSchema.valueSchema())\n        log.debug(\"${\"  \" * level}Copied field ${fieldName} of type ${oldSchema}\")\n    }\n    if (headerToProcess) {\n        for (Header header : headerToProcess.values()) {\n            newSchemaBuilder.field(header.name, header.schema)\n            log.debug(\"${\"  \" * level}Added field ${header.name} of type ${header.schema}\")\n        }\n    }\n    return newSchemaBuilder.build()\n}", "CodeBleu_score": 34.95774560013983}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t  SchemaBuilder builder = SchemaBuilder.struct()\n  builder.field(fieldName, oldSchema)\n  if (oldSchema.type.isPrimitive()) {\n    return oldSchema\n  }\n  if (oldSchema.type.equals(Schema.Type.STRUCT)) {\n    oldSchema.fields.each {\n      if (it.name.startsWith(\"__\")) {\n        builder.field(it.name, it.schema)\n      } else {\n        buildNewSchema(it.name, it.schema, headerToProcess, nestedFields, level + 1)\n      }\n    }\n  } else if (oldSchema.type.equals(Schema.Type.MAP)) {\n    Schema valueSchema = oldSchema.valueSchema()\n    if (valueSchema.type.isPrimitive()) {\n      builder.field(fieldName, oldSchema)\n    } else {\n      buildNewSchema(fieldName, valueSchema, headerToProcess, nestedFields, level + 1)\n    }\n  } else if (oldSchema.type.equals(Schema.Type.ARRAY)) {\n    Schema valueSchema = oldSchema.valueSchema()\n    if (valueSchema.type.isPrimitive()) {\n      builder.field(fieldName, oldSchema)\n    } else {\n      buildNewSchema(fieldName, valueSchema, headerToProcess, nestedFields, level + 1)\n    }\n  }\n  if (headerToProcess.containsKey(fieldName)) {\n    Header header = headerToProcess.get(fieldName)\n    Schema newSchema = header.schema()\n    if (newSchema.type.equals(Schema.Type.STRUCT)) {\n      newSchema.fields.each {\n        if (it.name.startsWith(\"__\")) {\n          builder.field(it.name, it.schema)\n        } else {\n          buildNewSchema(it.name, it.schema, headerToProcess, nestedFields, level + 1)\n        }\n      }\n    } else if (newSchema.type.equals(Schema.Type.MAP)) {\n      Schema valueSchema = newSchema.valueSchema()\n      if (valueSchema.type.isPrimitive()) {\n        builder.field", "CodeBleu_score": 37.30325209799601}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t    Schema newSchema = null;\n    if (isPrimitive(oldSchema)) {\n        newSchema = oldSchema;\n        log.debug(\"Primitive schema found for field ${fieldName}.  Returning schema: ${newSchema}\");\n    } else {\n        SchemaBuilder builder = SchemaBuilder.struct();\n        builder.name(oldSchema.name());\n        builder.doc(oldSchema.doc());\n        if (oldSchema.isOptional()) {\n            builder.optional();\n        }\n        for (Field field : oldSchema.fields()) {\n            String fieldNameToProcess = field.name();\n            if (nestedFields.contains(fieldNameToProcess)) {\n                fieldNameToProcess = fieldName + \".\" + fieldNameToProcess;\n            }\n            if (headerToProcess.containsKey(fieldNameToProcess)) {\n                Header header = headerToProcess.get(fieldNameToProcess);\n                if (header.type == Header.Type.STRING) {\n                    builder.field(fieldNameToProcess, Schema.STRING_SCHEMA);\n                } else if (header.type == Header.Type.INT) {\n                    builder.field(fieldNameToProcess, Schema.INT32_SCHEMA);\n                } else if (header.type == Header.Type.LONG) {\n                    builder.field(fieldNameToProcess, Schema.INT64_SCHEMA);\n                } else if (header.type == Header.Type.FLOAT) {\n                    builder.field(fieldNameToProcess, Schema.FLOAT32_SCHEMA);\n                } else if (header.type == Header.Type.DOUBLE) {\n                    builder.field(fieldNameToProcess, Schema.FLOAT64_SCHEMA);\n                } else if (header.type == Header.Type.BOOLEAN) {\n                    builder.field(fieldNameToProcess, Schema.BOOLEAN_SCHEMA);\n                } else {\n                    throw new IllegalArgumentException(\"Unsupported header type ${header.type} for field ${fieldNameToProcess}\");\n                }\n                log.debug(\"Added header field ${fieldNameToProcess} to", "CodeBleu_score": 28.778530480670835}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\t    if (source.schema().field(SNAPSHOT_KEY) == null) {\n        return null;\n    }\n\n    String snapshotString = source.getString(SNAPSHOT_KEY);\n    if (snapshotString == null) {\n        return null;\n    }\n\n    return SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 33.022743973387925}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t  if (source == null) {\n    return null;\n  }\n  Schema schema = source.schema();\n  if (schema.field(SNAPSHOT_KEY) == null) {\n    return null;\n  }\n  String snapshotString = source.getString(SNAPSHOT_KEY);\n  if (snapshotString == null) {\n    return null;\n  }\n  return SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 38.881683336133996}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t  if (source.schema().field(SNAPSHOT_KEY) == null) {\n    return null;\n  }\n\n  Object snapshotString = source.get(SNAPSHOT_KEY);\n  if (snapshotString == null) {\n    return null;\n  }\n\n  return valueOf(snapshotString.toString().toUpperCase());\n}", "CodeBleu_score": 27.748552566769686}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t    Optional<Float> result = Optional.empty();\n    try {\n        String[] parts = version.split(\"\\\\.\");\n        if (parts.length > 2) {\n            parts = Arrays.copyOfRange(parts, 0, 2);\n        }\n        String[] subParts = parts[0].split(\"-\");\n        result = Optional.of(Float.parseFloat(subParts[0]));\n    } catch (Exception e) {\n        return Optional.empty();\n    }\n    return result;\n}", "CodeBleu_score": 58.716458126868666}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null) {\n\t\treturn Optional.empty();\n\t}\n\n\tString[] versionSplit = version.split(\"\\\\.\");\n\tif (versionSplit.length > 2) {\n\t\tversionSplit = Arrays.copyOf(versionSplit, 2);\n\t}\n\n\tString versionParts = versionSplit[0];\n\tif (versionSplit.length > 1) {\n\t\tversionParts += \".\" + versionSplit[1];\n\t}\n\n\tString[] versionPartsSplit = versionParts.split(\"-\");\n\tif (versionPartsSplit.length > 1) {\n\t\tversionParts = versionPartsSplit[0];\n\t}\n\n\treturn Optional.of(Float.parseFloat(versionParts));\n}", "CodeBleu_score": 45.604346775299355}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t    Optional<Float> parsedVersion = Optional.empty();\n    String[] versionParts = version.split(\"\\\\.\");\n    if (versionParts.length >= 2) {\n        String[] versionParts2 = versionParts[0].split(\"-\");\n        try {\n            parsedVersion = Optional.of(Float.parseFloat(versionParts2[0]));\n        } catch (NumberFormatException e) {\n            parsedVersion = Optional.empty();\n        }\n    }\n    return parsedVersion;\n}", "CodeBleu_score": 45.043746179993526}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t    return accessContextService.createContext(exchange, operationName, clusterName, connectName, connector)\n            .flatMap(context -> accessValidationService.validateAccess(context, ValidationPolicy.CREATE_CONNECTOR))\n            .flatMap(context -> kafkaConnectService.createConnector(context, connector))\n            .flatMap(response -> {\n                auditService.audit(context, AuditSignal.CREATE_CONNECTOR);\n                return Mono.just(ResponseEntity.ok(response));\n            })\n            .onErrorMap(KafkaConnectAccessDeniedException.class, error -> new ResponseStatusException(HttpStatus.FORBIDDEN, error.getMessage()))\n            .onErrorMap(KafkaConnectException.class, error -> new ResponseStatusException(HttpStatus.INTERNAL_SERVER_ERROR, error.getMessage()));\n}", "CodeBleu_score": 31.915486111895063}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t    return audit(exchange, operationName,\n            () -> validateAccess(exchange,\n                    ctx -> ctx.add(AuditContext.CLUSTER_NAME, clusterName)\n                            .add(AuditContext.CONNECT_NAME, connectName)\n                            .add(AuditContext.CONNECTOR_NAME, connector.map(NewConnectorDTO::getName).block()),\n                    this::createConnector)\n            .map(ResponseEntity::ok));\n}", "CodeBleu_score": 29.78625527321661}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t    return accessService.accessContext(AccessOperation.CREATE,\n            AccessTarget.Connector(clusterName, connectName, connector.map(NewConnectorDTO::getName).block()),\n            exchange)\n            .flatMap(accessContext -> {\n                if (accessContext.hasAccess()) {\n                    return kafkaConnectService.createConnector(clusterName, connectName, connector)\n                            .map(connectorDTO -> ResponseEntity.ok()\n                                    .eTag(connectorDTO.getVersion())\n                                    .body(connectorDTO));\n                } else {\n                    return Mono.just(new ResponseEntity<>(HttpStatus.FORBIDDEN));\n                }\n            })\n            .doOnEach(ReactorUtil.onComplete(\n                    () -> auditService.createAudit(AuditContext.builder()\n                            .type(AuditType.KAFKA_CONNECT)\n                            .operation(AccessOperation.CREATE)\n                            .resource(AccessTarget.Connector(clusterName, connectName, connector.map(NewConnectorDTO::getName).block()))\n                            .user(accessContext.getAuditUser())\n                            .build()),\n                    error -> auditService.createAudit(AuditContext.builder()\n                            .type(AuditType.KAFKA_CONNECT)\n                            .operation(AccessOperation.CREATE)\n                            .resource(AccessTarget.Connector(clusterName, connectName, connector.map(NewConnectorDTO::getName).block()))\n                            .user(accessContext.getAuditUser())\n                            .exception(error)\n                            .build())\n            ));\n}", "CodeBleu_score": 35.859894744584665}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\n    AccessContext accessContext = AccessContext.builder()\n            .clusterName(clusterName)\n            .connectName(connectName)\n            .operationParams(OperationParams.builder()\n                    .operationName(OperationName.DELETE_CONNECTOR)\n                    .connectName(connectName)\n                    .connectorName(connectorName)\n                    .build())\n            .build();\n\n    return validateAccess(accessContext, exchange)\n            .flatMap(accessValidationResult -> {\n                if (accessValidationResult.isSuccess()) {\n                    return kafkaConnectService.deleteConnector(clusterName, connectName, connectorName)\n                            .doOnEach(ReactorUtils.deferContext())\n                            .contextWrite(context -> context.put(AUTH_CONTEXT_KEY, accessValidationResult))\n                            .then(Mono.just(ResponseEntity.ok().build()));\n                } else {\n                    return Mono.just(new ResponseEntity<>(accessValidationResult.getMessage(),\n                            accessValidationResult.getStatusCode()));\n                }\n            })\n            .doOnEach(ReactorUtils.onError(throwable -> {\n                if (throwable.getCause() instanceof ConnectNotFoundException) {\n                    audit(exchange, accessContext, throwable.getCause().getMessage(),\n                            AuditService.UNKNOWN_RESOURCE_ID, AuditService.UNKNOWN_RESOURCE_ID, AuditService.UNKNOWN_RESOURCE_ID,\n                            AuditService.UNKNOWN_RESOURCE_ID, AuditService.UNKNOWN_RESOURCE_ID, AuditService.UNKNOWN_RESOURCE_ID);\n                } else {\n                    audit(exchange, accessContext, AuditService.UNKNOWN_RESOURCE_ID,\n                            AuditService.UNKNOWN_RESOURCE_ID, AuditService.UNKNOWN_RESOURCE_ID,\n                            AuditService.UNKNOWN_RESOURCE_ID, AuditService.UNKNOWN_RESOURCE_ID, AuditService.UNKNOWN_RESOURCE_", "CodeBleu_score": 41.60101575015884}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t    return getCluster(clusterName)\n        .map(Optional::get)\n        .flatMap(cluster -> {\n            AccessContext accessContext = AccessContext.builder()\n                .clusterName(clusterName)\n                .connectName(connectName)\n                .connectCluster(cluster)\n                .operation(Operation.DELETE_CONNECTOR)\n                .build();\n\n            return validateAccess(accessContext, exchange)\n                .flatMap(accessValidation -> {\n                    if (accessValidation.isHasAccess()) {\n                        return kafkaConnectService.deleteConnector(cluster, connectName, connectorName);\n                    } else {\n                        return Mono.error(new ValidationException(\"Access denied\"));\n                    }\n                });\n        })\n        .flatMap(response -> {\n            if (response.getStatusCode().is2xxSuccessful()) {\n                return Mono.just(ResponseEntity.ok().build());\n            } else {\n                return Mono.error(new RuntimeException(\"Failed to delete connector\"));\n            }\n        })\n        .doOnEach(ReactorUtil.onComplete(\n            () -> audit(exchange,\n                AuditContext.builder()\n                    .clusterName(clusterName)\n                    .connectName(connectName)\n                    .connectorName(connectorName)\n                    .operation(Operation.DELETE_CONNECTOR)\n                    .build(),\n                \"Delete connector\"))\n        );\n}", "CodeBleu_score": 41.56926376634913}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t    return Mono.just(new AccessContext.Builder())\n            .map(builder -> builder.withClusterName(clusterName))\n            .map(builder -> builder.withConnectName(connectName))\n            .map(builder -> builder.withOperation(Operation.DELETE_CONNECTOR))\n            .map(builder -> builder.withParams(Map.of(\n                    \"connectorName\", connectorName\n            )))\n            .map(AccessContext.Builder::build)\n            .flatMap(accessContext -> validateAccess(accessContext, exchange))\n            .map(accessValidation -> accessValidation.getAccessContext())\n            .flatMap(accessContext -> kafkaConnectService.deleteConnector(accessContext.getClusterName(),\n                    accessContext.getConnectName(), connectorName))\n            .doOnEach(ReactorExt.audit(this.audit))\n            .map(ResponseEntity::ok)\n            .onErrorResume(error -> Mono.just(ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build()));\n}", "CodeBleu_score": 29.295484300605036}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\n    return Mono.zip(\n            Mono.just(clusterName),\n            Mono.just(connectName),\n            Mono.just(connectorName),\n            Mono.just(action),\n            Mono.just(exchange)\n    )\n            .map(t -> {\n                String clusterName = t.getT1();\n                String connectName = t.getT2();\n                String connectorName = t.getT3();\n                ConnectorActionDTO action = t.getT4();\n                ServerWebExchange exchange = t.getT5();\n\n                return new Tuple4<>(clusterName, connectName, connectorName, action);\n            })\n            .flatMap(t -> {\n                String clusterName = t.getT1();\n                String connectName = t.getT2();\n                String connectorName = t.getT3();\n                ConnectorActionDTO action = t.getT4();\n\n                return Mono.zip(\n                        Mono.just(clusterName),\n                        Mono.just(connectName),\n                        Mono.just(connectorName),\n                        Mono.just(action),\n                        kafkaConnectService.getConnect(clusterName, connectName),\n                        kafkaConnectService.getConnector(clusterName, connectName, connectorName)\n                );\n            })\n            .flatMap(t -> {\n                String clusterName = t.getT1();\n                String connectName = t.getT2();\n                String connectorName = t.getT3();\n                ConnectorActionDTO action = t.getT4();\n                KafkaConnect kafkaConnect = t.getT5();\n                KafkaConnector kafkaConnector = t.getT6();\n\n                return Mono.zip(\n                        Mono.just(clusterName),\n                        Mono.just(connectName),\n                        Mono.just(connectorName),\n                        Mono.just(action),\n                        Mono.just(kafkaConnect),\n                        Mono.just(kafkaConnector),\n                        kafkaConnectService.getConnectors(clusterName, connectName),\n                        k", "CodeBleu_score": 27.213324921099897}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t    return Mono.zip(\n        getCluster(clusterName),\n        getConnect(clusterName, connectName),\n        getConnector(clusterName, connectName, connectorName))\n        .flatMap(t -> {\n            Cluster cluster = t.getT1();\n            Connect connect = t.getT2();\n            Connector connector = t.getT3();\n\n            Map<String, String> operationParams = new HashMap<>();\n            operationParams.put(CONNECTOR_NAME, connector.getName());\n            operationParams.put(CONNECT_NAME, connect.getName());\n            operationParams.put(CLUSTER_NAME, cluster.getName());\n\n            ConnectAction connectAction = ConnectAction.valueOf(action.getAction());\n            String operationName = \"updateConnectorState\";\n\n            return Mono.just(new AuditContext(cluster, connect, connector, operationName, connectAction, operationParams));\n        })\n        .flatMap(auditContext -> {\n            validateAccess(auditContext);\n            return kafkaConnectService.updateConnectorState(auditContext.getCluster(), auditContext.getConnect(), auditContext.getConnector(), auditContext.getConnectAction());\n        })\n        .flatMap(response -> {\n            if (response.getStatusCode() == HttpStatus.OK) {\n                return Mono.just(ResponseEntity.ok().build());\n            } else {\n                return Mono.just(ResponseEntity.status(response.getStatusCode()).build());\n            }\n        })\n        .doOnEach(ReactorUtils.onComplete(\n            signal -> auditService.createEntry(signal.get(), exchange)\n        ));\n}", "CodeBleu_score": 35.28953542580964}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t    return Mono.just(new AuditContext(exchange,\n                                      \"updateConnectorState\",\n                                      ImmutableMap.of(\"clusterName\", clusterName,\n                                                      \"connectName\", connectName,\n                                                      \"connectorName\", connectorName)))\n               .map(this::build)\n               .map(auditContext -> auditContext.toBuilder()\n                                                 .operationParams(ImmutableMap.of(\"action\", action))\n                                                 .build())\n               .flatMap(this::validateAccess)\n               .flatMap(auditContext -> kafkaConnectService.updateConnectorState(clusterName,\n                                                                                 connectName,\n                                                                                 connectorName,\n                                                                                 action))\n               .doOnEach(this::audit)\n               .map(ResponseEntity::ok);\n}", "CodeBleu_score": 20.740493760957495}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t    @PathVariable String clusterName,\n    @PathVariable String connectName,\n    @PathVariable String pluginName,\n    @RequestBody Map<String, String> requestBody\n}", "CodeBleu_score": 35.22907495390474}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t    @Parameter(description = \"The Kafka Connect cluster name\", required = true)\n    @PathVariable(\"clusterName\")\n    String clusterName,\n    @Parameter(description = \"The Kafka Connect name\", required = true)\n    @PathVariable(\"connectName\")\n    String connectName,\n    @Parameter(description = \"The connector plugin name\", required = true)\n    @PathVariable(\"pluginName\")\n    String pluginName,\n    @Parameter(description = \"The connector plugin configuration\", required = true)\n    @Valid\n    @RequestBody\n    Map<String, String> request) {\n    return kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, request)\n        .map(response -> ResponseEntity.ok(new ConnectorPluginConfigValidationResponseDTO(response.getConfig(), response.getMessages())));\n}\n\n", "CodeBleu_score": 39.509409186613276}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\n    return kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, requestBody)\n        .map(this::map)\n        .map(ResponseEntity::ok);\n}", "CodeBleu_score": 32.179766112991274}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    SpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n    builder.initializers(new DynamicConfigPropertiesInitializer());\n    return builder.run(args);\n}", "CodeBleu_score": 45.22206797006011}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    SpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n    builder.initializers(new DynamicConfigPropertiesInitializer());\n    return builder.run(args);\n}", "CodeBleu_score": 45.22206797006011}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t\t.initializers(dynamicConfigPropertiesInitializer())\n\t\t\t.run(args);\n}", "CodeBleu_score": 40.474157817515355}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\tif (search == null) {\n\t\treturn c -> true;\n\t}\n\treturn c -> {\n\t\tfinal String[] strings = getStringsForSearch(c);\n\t\tfor (final String s : strings) {\n\t\t\tif (s.containsIgnoreCase(search)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t};\n}", "CodeBleu_score": 59.67946676900402}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t    if (search == null) {\n        return x -> true;\n    }\n\n    return x -> {\n        final String[] strings = getStringsForSearch(x);\n        return Arrays.stream(strings).anyMatch(s -> s.containsIgnoreCase(search));\n    };\n}", "CodeBleu_score": 58.9413419778134}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t    if (search == null) {\n        return (connector) -> true;\n    } else {\n        return (connector) -> anyMatch(getStringsForSearch(connector), containsIgnoreCase(search));\n    }\n}", "CodeBleu_score": 56.47122724782441}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    Map<String, Object> flattenedMap = new HashMap<>();\n\n    if (propertiesMap != null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = entry.getKey();\n        Object value = entry.getValue();\n\n        if (value instanceof Map) {\n          flattenedMap.putAll(flattenClusterProperties(prefix != null ? prefix + \".\" + key : key, (Map<String, Object>) value));\n        } else {\n          flattenedMap.put(prefix != null ? prefix + \".\" + key : key, value);\n        }\n      }\n    }\n\n    return flattenedMap;\n  }", "CodeBleu_score": 48.4415059842951}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    Map<String, Object> flattened = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattened;\n    }\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      Object value = entry.getValue();\n      String newKey = prefix == null ? key : prefix + \".\" + key;\n      if (value instanceof Map) {\n        flattened.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n      } else {\n        flattened.put(newKey, value);\n      }\n    }\n    return flattened;\n  }", "CodeBleu_score": 57.10885562595068}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    Map<String, Object> flattenedProperties = new HashMap<>();\n    if (propertiesMap != null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = entry.getKey();\n        Object value = entry.getValue();\n        String newKey = prefix == null ? key : prefix + \".\" + key;\n        if (value instanceof Map) {\n          flattenedProperties.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n        } else {\n          flattenedProperties.put(newKey, value);\n        }\n      }\n    }\n    return flattenedProperties;\n  }", "CodeBleu_score": 55.14963047949241}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t    ConfigDef configDef = new ConfigDef()\n    configDef.define(SslConfigs.SSL_KEY_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.HIGH, SslConfigs.SSL_KEY_PASSWORD_DOC)\n    configDef.define(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.HIGH, SslConfigs.SSL_KEYSTORE_PASSWORD_DOC)\n    configDef.define(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.HIGH, SslConfigs.SSL_TRUSTSTORE_PASSWORD_DOC)\n    configDef.define(SaslConfigs.SASL_JAAS_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.HIGH, SaslConfigs.SASL_JAAS_CONFIG_DOC)\n    configDef.define(SaslConfigs.SASL_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.HIGH, SaslConfigs.SASL_PASSWORD_DOC)\n    configDef.define(SaslConfigs.SASL_KERBEROS_KINIT_CMD, ConfigDef.Type.PASSWORD, ConfigDef.Importance.HIGH, SaslConfigs.SASL_KERBEROS_KINIT_CMD_DOC)\n    configDef.define(SaslConfigs.SASL_KERBEROS_TICKET_RENEW_WINDOW_FACTOR_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.HIGH, SaslConfigs.SASL_KERBEROS_TICKET_RENEW_WINDOW_FACTOR_DOC)\n    configDef.define(SaslConfigs.SASL_KERBEROS_TICKET_RENEW_JITTER_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance", "CodeBleu_score": 37.162642937410254}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t  ConfigDef configDef = new ConfigDef();\n  configDef.define(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG,\n                  ConfigDef.Type.STRING,\n                  CommonClientConfigs.DEFAULT_SECURITY_PROTOCOL,\n                  ConfigDef.Importance.MEDIUM,\n                  CommonClientConfigs.SECURITY_PROTOCOL_DOC);\n  configDef.define(SslConfigs.SSL_KEY_PASSWORD_CONFIG,\n                  ConfigDef.Type.PASSWORD,\n                  ConfigDef.Importance.MEDIUM,\n                  SslConfigs.SSL_KEY_PASSWORD_DOC);\n  configDef.define(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG,\n                  ConfigDef.Type.PASSWORD,\n                  ConfigDef.Importance.MEDIUM,\n                  SslConfigs.SSL_KEYSTORE_PASSWORD_DOC);\n  configDef.define(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG,\n                  ConfigDef.Type.PASSWORD,\n                  ConfigDef.Importance.MEDIUM,\n                  SslConfigs.SSL_TRUSTSTORE_PASSWORD_DOC);\n  configDef.define(SaslConfigs.SASL_JAAS_CONFIG,\n                  ConfigDef.Type.PASSWORD,\n                  ConfigDef.Importance.MEDIUM,\n                  SaslConfigs.SASL_JAAS_CONFIG_DOC);\n  return configDef.configKeys().stream()\n                  .filter(configKey -> configKey.type() == ConfigDef.Type.PASSWORD)\n                  .map(ConfigDef.ConfigKey::name)\n                  .collect(Collectors.toSet());\n}", "CodeBleu_score": 50.76362299163129}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t    final ConfigDef configDef = new ConfigDef();\n    addClientSslSupport(configDef);\n    addClientSaslSupport(configDef);\n    return configDef.configKeys().entrySet().stream()\n        .filter(entry -> entry.getValue().type() == ConfigDef.Type.PASSWORD)\n        .map(Map.Entry::getKey)\n        .collect(Collectors.toSet());\n  }", "CodeBleu_score": 78.21660936568632}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return Mono.just(clusterDescription)\n        .flatMap(cd -> {\n            if (cd.getAuthorizedOperations().contains(AclOperation.ALL) ||\n                cd.getAuthorizedOperations().contains(AclOperation.ALTER)) {\n                return adminClient.describeCluster()\n                    .map(describedCluster -> {\n                        if (describedCluster.aclViewEnabled()) {\n                            return ClusterFeature.KAFKA_ACL_EDIT;\n                        }\n                        return null;\n                    });\n            }\n            return Mono.empty();\n        });\n}", "CodeBleu_score": 27.546302898208612}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return adminClient.describeAcls(new AclBindingFilter(ResourcePatternFilter.ANY, AccessControlEntryFilter.ANY))\n        .map(aclDescription -> {\n            if (aclDescription.authorizedOperations().contains(AclOperation.ALTER) && aclDescription.authorizedOperations().contains(AclOperation.ALL)) {\n                return aclViewEnabled(clusterDescription) ? ClusterFeature.KAFKA_ACL_EDIT : ClusterFeature.KAFKA_ACL_VIEW;\n            } else {\n                return ClusterFeature.KAFKA_ACL_VIEW;\n            }\n        })\n        .onErrorReturn(ClusterFeature.KAFKA_ACL_VIEW);\n}", "CodeBleu_score": 27.36143605243242}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return adminClient.describeAcls(new AclBindingFilter(new ResourcePatternFilter(ResourceType.CLUSTER, null, PatternType.LITERAL), AccessControlEntryFilter.ANY))\n        .map(aclDescription -> aclDescription.acls())\n        .map(acls -> acls.stream().map(acl -> acl.operation()).collect(Collectors.toList()))\n        .map(authorizedOperations -> {\n            boolean aclViewEnabled = authorizedOperations.contains(AclOperation.DESCRIBE_CONFIGS);\n            boolean canEdit = authorizedOperations.contains(AclOperation.ALTER) || authorizedOperations.contains(AclOperation.ALTER_CONFIGS);\n            return new ClusterFeature(clusterDescription.clusterId(), ClusterFeature.FeatureType.KAFKA_ACL_EDIT, canEdit, aclViewEnabled);\n        })\n        .onErrorReturn(new ClusterFeature(clusterDescription.clusterId(), ClusterFeature.FeatureType.KAFKA_ACL_EDIT, false, false));\n}", "CodeBleu_score": 35.80536038549696}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    // Initialize the range to read from based on the previous range or the offsets from seek operations\n    TreeMap<TopicPartition, FromToOffset> range = new TreeMap<>();\n    for (Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\n        range.put(entry.getKey(), entry.getValue());\n    }\n    for (Entry<TopicPartition, FromToOffset> entry : seekOperations.getOffsetsForSeek().entrySet()) {\n        range.put(entry.getKey(), entry.getValue());\n    }\n\n    // Calculate the number of messages to poll per partition\n    int numMessagesPerPartition = (int) Math.ceil((double) getMaxPollRecords() / range.size());\n\n    // For each topic partition, determine the start offset and adjust it based on the number of messages to poll\n    for (Entry<TopicPartition, FromToOffset> entry : range.entrySet()) {\n        TopicPartition topicPartition = entry.getKey();\n        FromToOffset fromToOffset = entry.getValue();\n        long startOffset = fromToOffset.getFrom();\n        long endOffset = fromToOffset.getTo();\n        long adjustedStartOffset = Math.max(startOffset, endOffset - numMessagesPerPartition + 1);\n        range.put(topicPartition, new FromToOffset(adjustedStartOffset, endOffset));\n    }\n\n    return range;\n}", "CodeBleu_score": 39.10709303856632}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    TreeMap<TopicPartition, FromToOffset> range = new TreeMap<>();\n    // Initialize the range based on the previous range or the offsets from seek operations\n    // if the previous range is empty.\n    if (prevRange.isEmpty()) {\n        range.putAll(seekOperations.getBeginOffsets());\n    } else {\n        range.putAll(prevRange);\n    }\n    // Calculate the number of messages to poll per partition.\n    int numMessagesPerPartition = (int) Math.ceil(\n        (double) getMaxPollRecords() / range.size());\n    // For each topic partition, determine the start offset and adjust it based on the number of messages to poll,\n    // ensuring it does not go below the beginning offset.\n    for (Map.Entry<TopicPartition, FromToOffset> entry : range.entrySet()) {\n        TopicPartition topicPartition = entry.getKey();\n        FromToOffset fromToOffset = entry.getValue();\n        long startOffset = fromToOffset.getFrom();\n        long endOffset = fromToOffset.getTo();\n        long adjustedStartOffset = Math.min(startOffset + numMessagesPerPartition, endOffset);\n        range.put(topicPartition, new FromToOffset(startOffset, adjustedStartOffset));\n    }\n    return range;\n}", "CodeBleu_score": 39.97117772351676}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t  TreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<TopicPartition, FromToOffset>();\n  // If the previous range is empty, initialize it with the offsets from the seek operations\n  if (prevRange.isEmpty()) {\n    for (TopicPartition topicPartition : seekOperations.getTopicPartitions()) {\n      long offset = seekOperations.getOffset(topicPartition);\n      nextRange.put(topicPartition, new FromToOffset(offset, offset));\n    }\n  } else {\n    nextRange.putAll(prevRange);\n  }\n  // Calculate the number of messages to poll per partition\n  int numMessagesToPollPerPartition = Math.min(numMessagesToPoll, nextRange.size());\n  // For each topic partition, calculate the start offset and adjust it based on the number of messages to poll\n  for (TopicPartition topicPartition : nextRange.keySet()) {\n    FromToOffset fromToOffset = nextRange.get(topicPartition);\n    long startOffset = fromToOffset.getFrom();\n    long endOffset = fromToOffset.getTo();\n    long numMessages = endOffset - startOffset;\n    // If the number of messages to poll is greater than the number of messages in the current range, poll the entire range\n    if (numMessagesToPollPerPartition > numMessages) {\n      nextRange.put(topicPartition, new FromToOffset(startOffset, endOffset));\n    } else {\n      // If the number of messages to poll is less than or equal to the number of messages in the current range,\n      // poll the last numMessagesToPollPerPartition messages\n      long newStartOffset = Math.max(startOffset, endOffset - numMessagesToPollPerPartition + 1);\n      nextRange.put(topicPartition, new FromToOffset(newStartOffset, endOffset));\n    }\n  }\n  return nextRange;\n}", "CodeBleu_score": 34.739645956690694}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 2.3542208163979508}, {"code": "public void doLaunch(final MessageInput input){\n\t  // This is a hack to support legacy mode.\n  // TODO: Remove this in a future version\n  if (getBoolean(LEGACY_MODE_CONFIG).get()) {\n    doLaunchLegacy(input);\n  } else {\n    doLaunchConsumer(input);\n  }\n}", "CodeBleu_score": 8.622698778575424}, {"code": "public void doLaunch(final MessageInput input){\n\t  if (input.getBoolean(CONF_LEGACY_MODE)) {\n    final String zkConnect = input.getString(CONF_ZOOKEEPER_CONNECT);\n    final String groupId = input.getString(CONF_GROUP_ID);\n    final String topic = input.getString(CONF_TOPIC);\n    if (zkConnect == null || zkConnect.isEmpty()) {\n      throw new IllegalArgumentException(\"ZooKeeper connect string must be set when legacy mode is enabled\");\n    }\n    if (groupId == null || groupId.isEmpty()) {\n      throw new IllegalArgumentException(\"Group ID must be set when legacy mode is enabled\");\n    }\n    if (topic == null || topic.isEmpty()) {\n      throw new IllegalArgumentException(\"Topic must be set when legacy mode is enabled\");\n    }\n    doLaunchLegacy(input, zkConnect, groupId, topic);\n  } else {\n    final String bootstrapServers = input.getString(CONF_BOOTSTRAP_SERVERS);\n    final String groupId = input.getString(CONF_GROUP_ID);\n    final String topic = input.getString(CONF_TOPIC);\n    if (bootstrapServers == null || bootstrapServers.isEmpty()) {\n      throw new IllegalArgumentException(\"Bootstrap servers must be set when legacy mode is disabled\");\n    }\n    if (groupId == null || groupId.isEmpty()) {\n      throw new IllegalArgumentException(\"Group ID must be set when legacy mode is disabled\");\n    }\n    if (topic == null || topic.isEmpty()) {\n      throw new IllegalArgumentException(\"Topic must be set when legacy mode is disabled\");\n    }\n    doLaunchConsumer(input, bootstrapServers, groupId, topic);\n  }\n  input.awaitRunning();\n  input.register(new LifecycleListener() {\n    @Override\n    public void start() {\n      lifecycleStateChange(input, LifecycleState.START);\n    }\n\n    @Override\n    public void stop() {\n      lifecycleStateChange(input, LifecycleState.STOP);\n    }\n\n    @Override\n    public void pause() {\n      lifecycleStateChange(input", "CodeBleu_score": 41.27012465642538}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t    try {\n        // load the configuration string into a Properties object\n        Properties customProps = new Properties();\n        customProps.load(new StringReader(getConfigurationString()));\n\n        // merge the custom properties with the existing properties\n        props.putAll(customProps);\n    } catch (IOException e) {\n        // log an error message if an IOException occurs\n        logError(\"Failed to load custom properties: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 37.278025150631976}, {"code": "private void insertCustomProperties(Properties props){\n\t\tString customProps = props.getProperty(\"customProperties\");\n\tif (customProps != null) {\n\t\ttry {\n\t\t\tProperties customPropsObj = new Properties();\n\t\t\tcustomPropsObj.load(new StringReader(customProps));\n\t\t\tprops.putAll(customPropsObj);\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Failed to load custom properties: \" + customProps, e);\n\t\t}\n\t}\n}", "CodeBleu_score": 40.712351516114104}, {"code": "private void insertCustomProperties(Properties props){\n\t    try {\n        Properties customProps = new Properties();\n        customProps.load(new StringReader(getCustomProperties()));\n        props.putAll(customProps);\n    } catch (IOException e) {\n        logError(e.getMessage());\n    }\n}", "CodeBleu_score": 33.43253206690785}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t    long start = System.nanoTime();\n    int size = entries.size();\n    if (size == 0) {\n        return;\n    }\n    // Filter out null entries\n    List<RawMessageEvent> filtered = entries.stream().filter(Objects::nonNull).collect(Collectors.toList());\n    if (filtered.size() == 0) {\n        return;\n    }\n    // Map each event to a journal entry\n    List<JournalEntry> journalEntries = filtered.stream().map(this::map).collect(Collectors.toList());\n    // Calculate the total message bytes\n    int totalMessageBytes = journalEntries.stream().mapToInt(JournalEntry::getMessageBytes).sum();\n    // Attempt to write the entries to the journal\n    try {\n        journal.writeToJournal(journalEntries);\n    } catch (JournalException e) {\n        // Retry using an exponential back-off strategy\n        int retry = 1;\n        while (retry <= maxRetry) {\n            try {\n                Thread.sleep(retry * 1000);\n                journal.writeToJournal(journalEntries);\n                break;\n            } catch (Exception e2) {\n                retry++;\n            }\n        }\n    }\n    // Update the written messages and bytes metrics\n    writtenMessages.addAndGet(filtered.size());\n    writtenBytes.addAndGet(totalMessageBytes);\n    long end = System.nanoTime();\n    writeDuration.addAndGet((end - start) / 1000000);\n}", "CodeBleu_score": 45.36954394801542}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t  if (entries == null || entries.size() == 0) {\n    return;\n  }\n\n  // filter out null entries\n  entries = entries.stream().filter(Objects::nonNull).collect(Collectors.toList());\n\n  // map each entry to a journal entry while calculating the total message bytes\n  final List<JournalEntry> journalEntries = entries.stream().map(entry -> {\n    final int messageBytes = entry.getMessageBytes();\n    final int messageIdBytes = entry.getMessageIdBytes();\n    final byte[] rawMessage = entry.getEncodedRawMessage();\n    final long timestamp = entry.getTimestamp();\n    return new JournalEntry(messageIdBytes, messageBytes, rawMessage, timestamp);\n  }).collect(Collectors.toList());\n\n  // attempt to write the entries to the journal\n  final int retryCount = 10;\n  final long retryDelay = 1000;\n  final long retryMaxDelay = 30000;\n  final double retryDelayFactor = 2.0;\n  final double retryDelayJitter = 0.1;\n  final RetryPolicy retryPolicy = new RetryPolicy(retryCount, retryDelay, retryMaxDelay, retryDelayFactor, retryDelayJitter);\n  final long startTime = System.currentTimeMillis();\n  final long totalMessageBytes = journalEntries.stream().mapToLong(JournalEntry::getMessageBytes).sum();\n  final long totalMessageIdBytes = journalEntries.stream().mapToLong(JournalEntry::getMessageIdBytes).sum();\n  final int totalMessages = journalEntries.size();\n  try {\n    retryPolicy.execute(() -> {\n      try {\n        journal.writeToJournal(journalEntries);\n        return null;\n      } catch (JournalException e) {\n        throw new RetryableException(e);\n      }\n    });\n  } catch (RetryException e) {\n    throw new MessageQueueException(\"Failed to write entries to the journal\", e);\n  }\n\n  // update the written messages and bytes metrics\n  final long endTime = System.currentTimeMillis();\n  final long writeTime =", "CodeBleu_score": 40.91073829535702}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t    long totalMessageBytes = 0;\n    List<JournalEntry> journalEntries = new ArrayList<>(entries.size());\n    for (RawMessageEvent entry : entries) {\n        if (entry == null) {\n            continue;\n        }\n        totalMessageBytes += entry.getMessageBytes().length;\n        journalEntries.add(entry.getEncodedRawMessage());\n    }\n    if (journalEntries.isEmpty()) {\n        return;\n    }\n    try {\n        journal.writeToJournal(journalEntries);\n    } catch (JournalException e) {\n        throw new MessageQueueException(\"Failed to write to journal\", e);\n    }\n    writeMetrics.mark(journalEntries.size(), totalMessageBytes);\n}", "CodeBleu_score": 29.912544035954575}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\t    if (messages.isEmpty()) {\n        return;\n    }\n\n    int max = messages.stream()\n            .map(Message::getQueueId)\n            .max(Integer::compareTo)\n            .orElse(0);\n\n    if (max > 0) {\n        queue.acknowledge(max);\n    }\n\n    acknowledgedMessages.mark(messages.size());\n}", "CodeBleu_score": 42.75513159344324}, {"code": "public void acknowledge(List<Message> messages){\n\t    if (messages.isEmpty()) {\n        return;\n    }\n    int max = messages.stream().map(Message::getQueueId).max(Integer::compareTo).get();\n    if (max > 0) {\n        queue.acknowledge(max);\n    }\n    if (metrics != null) {\n        metrics.acknowledgedMessages.mark(messages.size());\n    }\n}", "CodeBleu_score": 39.89392732930535}, {"code": "public void acknowledge(List<Message> messages){\n\t\n    if (messages.isEmpty()) {\n        return;\n    }\n\n    int maxMessageId = messages.stream()\n            .map(Message::getMessageId)\n            .filter(Objects::nonNull)\n            .max(Integer::compareTo)\n            .orElse(0);\n\n    if (maxMessageId > 0) {\n        acknowledge(maxMessageId);\n    }\n\n    acknowledgedMessages.mark(messages.size());\n}", "CodeBleu_score": 49.244909680228545}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\t    try {\n        metricRegistry.getMetrics().entrySet().stream().filter(e -> e.getKey().startsWith(getClass().getName())).forEach(e -> {\n            String legacyMetricName = e.getKey().replace(getClass().getName(), \"akka.persistence.kafka.journal\");\n            try {\n                metricRegistry.register(legacyMetricName, e.getValue());\n            } catch (IllegalArgumentException ex) {\n                log.warn(\"Failed to register legacy metric [{}] with value [{}]\", legacyMetricName, e.getValue());\n            }\n        });\n    } catch (Exception ex) {\n        log.warn(\"Failed to register legacy metrics\", ex);\n    }\n}", "CodeBleu_score": 49.89090826212994}, {"code": "private void registerLegacyMetrics(){\n\t  getMetrics().entrySet().stream().filter(entry -> entry.getKey().startsWith(getClass().getName())).forEach(entry -> {\n    String legacyName = entry.getKey().replace(getClass().getName(), \"akka.persistence.kafka.journal.LocalKafkaJournal\");\n    try {\n      getMetrics().register(legacyName, entry.getValue());\n    } catch (IllegalArgumentException e) {\n      getLogger().warn(\"Unable to register legacy metric [{}] with name [{}]\", entry.getKey(), legacyName);\n    }\n  });\n}", "CodeBleu_score": 50.27005705021932}, {"code": "private void registerLegacyMetrics(){\n\t  registry.getMetrics().stream()\n      .filter(metric -> metric.getName().startsWith(getClass().getName()))\n      .forEach(metric -> {\n        String legacyName = getLegacyMetricName(metric.getName());\n        try {\n          registry.register(legacyName, metric);\n        } catch (IllegalArgumentException e) {\n          logger.warn(\"Unable to register legacy metric name: \" + legacyName\n              + \" for metric: \" + metric.getName(), e);\n        }\n      });\n}", "CodeBleu_score": 39.354106014066275}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t    try {\n        return metricRegistry.timer(metricName);\n    } catch (IllegalArgumentException e) {\n        return metricRegistry.getTimers().get(metricName);\n    }\n}", "CodeBleu_score": 21.97987496955459}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t    try {\n        return metricRegistry.timer(metricName);\n    } catch (IllegalArgumentException e) {\n        return metricRegistry.getTimers().get(metricName);\n    }\n}", "CodeBleu_score": 21.97987496955459}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t  try {\n    return metricRegistry.timer(metricName);\n  } catch (IllegalArgumentException e) {\n    return metricRegistry.getTimers().get(metricName);\n  }\n}", "CodeBleu_score": 20.59664230058331}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t  try {\n    metricRegistry.register(name, new Gauge<Long>() {\n      @Override\n      public Long getValue() {\n        long uncommitted = 0;\n        long logEndOffset = getLogEndOffset();\n        long logStartOffset = getLogStartOffset();\n        long size = getSize();\n        if (size > 0) {\n          long committed = get();\n          if (committed == 0) {\n            uncommitted = logEndOffset - logStartOffset;\n          } else {\n            uncommitted = logEndOffset - committed;\n          }\n        }\n        return uncommitted;\n      }\n    });\n  } catch (IllegalArgumentException e) {\n    // Ignore the exception\n  }\n}", "CodeBleu_score": 43.245510224639276}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t  try {\n    metricRegistry.register(name, new Gauge<Integer>() {\n      @Override\n      public Integer getValue() {\n        if (size() == 0) {\n          return 0;\n        } else if (committedOffset == DEFAULT_OFFSET) {\n          return (int) (getLogEndOffset() - getLogStartOffset());\n        } else {\n          return (int) (getLogEndOffset() - committedOffset);\n        }\n      }\n    });\n  } catch (IllegalArgumentException e) {\n    // Ignore the exception\n  }\n}", "CodeBleu_score": 50.86654087056816}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t  try {\n    metricRegistry.register(name, new Gauge<Number>() {\n      @Override\n      public Number getValue() {\n        long uncommitted = 0;\n        if (size() == 0) {\n          return 0;\n        }\n        if (committedOffset == null) {\n          uncommitted = getLogEndOffset() - getLogStartOffset();\n        } else {\n          uncommitted = getLogEndOffset() - committedOffset;\n        }\n        return uncommitted;\n      }\n    });\n  } catch (IllegalArgumentException e) {\n    // ignore\n  }\n}", "CodeBleu_score": 52.14223508932303}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t    if (messages.isEmpty()) {\n        if (isDebugEnabled) {\n            debug(\"Flushing \" + messages.size() + \" messages with payload size \" + payloadSize + \" bytes to \" + name + \" with empty message set.\");\n        }\n    } else {\n        ByteBufferMessageSet messageSet = ByteBufferMessageSet.create(messages);\n        if (isDebugEnabled) {\n            debug(\"Flushing \" + messages.size() + \" messages with payload size \" + payloadSize + \" bytes to \" + name + \" with message set of \" + messageSet.sizeInBytes + \" bytes.\");\n        }\n        long start = time.nanoseconds();\n        long lastOffset = log.append(messageSet);\n        long end = time.nanoseconds();\n        double elapsed = (end - start) / (double) time.nanosecondsPerSecond;\n        debug(\"Flush of \" + messages.size() + \" messages with payload size \" + payloadSize + \" bytes to \" + name + \" with message set of \" + messageSet.sizeInBytes + \" bytes took \" + elapsed + \" seconds.\");\n        markFlattenedMessages(messages.size());\n        return lastOffset;\n    }\n    return log.logEndOffset();\n}", "CodeBleu_score": 44.511625959566324}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t    if (messages.isEmpty()) {\n        logger.debug(\"Flushing {} messages.\", messages.size());\n    } else {\n        ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages.toArray(new Message[0]));\n        logger.debug(\"Flushing {} messages of {} bytes.\", messages.size(), messageSet.sizeInBytes());\n        long lastOffset = log.append(messageSet);\n        logger.debug(\"Flushed messages to offset {}.\", lastOffset);\n        numMessages += messages.size();\n        return lastOffset;\n    }\n    return -1;\n}", "CodeBleu_score": 40.219320483323905}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t    if (messages.isEmpty()) {\n        debug(\"Attempt to flushMessages with no messages.\");\n    } else {\n        ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages.iterator());\n        debug(\"Flushing \" + messageSet.sizeInBytes + \" bytes to log '\" + name + \"'\");\n        long start = time.nanoseconds();\n        long logOffset = log.append(messageSet);\n        long end = time.nanoseconds();\n        double elapsed = (end - start) / (double) time.nanosecondsPerSecond;\n        double mbps = payloadSize / elapsed / 1024 / 1024;\n        debug(\"Log append time: \" + elapsed + \" ms\" + \" (\" + mbps + \" MB/sec)\");\n        numMessages.add(messages.size());\n        numBytes.add(payloadSize);\n        lastFlushTime.set(time.milliseconds());\n    }\n    return log.logEndOffset();\n}", "CodeBleu_score": 45.06672477413984}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    // lock the client map to ensure thread safety\n    synchronized (this.kafkaAdminClientMap) {\n        // retrieve the list of AdminClient instances for the specified cluster ID\n        List<AdminClient> adminClientList = this.kafkaAdminClientMap.get(clusterPhyId);\n        // if no clients are found, the function returns\n        if (adminClientList == null) {\n            return;\n        }\n        // log the start of the closing process\n        log.info(\"Closing Kafka AdminClient instances for cluster \" + clusterPhyId);\n        // attempt to close all AdminClient instances in the list\n        for (AdminClient adminClient : adminClientList) {\n            try {\n                adminClient.close();\n            } catch (Exception e) {\n                // log an error message if any closure fails\n                log.error(\"Error closing Kafka AdminClient instance for cluster \" + clusterPhyId, e);\n            }\n        }\n        // log a success message if all clients are closed successfully, or an error message if any closure fails\n        if (adminClientList.isEmpty()) {\n            log.info(\"Successfully closed Kafka AdminClient instances for cluster \" + clusterPhyId);\n        } else {\n            log.error(\"Failed to close Kafka AdminClient instances for cluster \" + clusterPhyId);\n        }\n    }\n}", "CodeBleu_score": 46.36073404116839}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    try {\n        LOG.info(\"Starting to close Kafka AdminClient instances for cluster ID {}\", clusterPhyId);\n        List<AdminClient> adminClientList = adminClientMap.get(clusterPhyId);\n        if (adminClientList == null) {\n            LOG.info(\"No AdminClient instances to close for cluster ID {}\", clusterPhyId);\n            return;\n        }\n        for (AdminClient adminClient : adminClientList) {\n            try {\n                adminClient.close();\n            } catch (Exception e) {\n                LOG.error(\"Error closing AdminClient instance for cluster ID {}\", clusterPhyId, e);\n            }\n        }\n        LOG.info(\"Successfully closed all AdminClient instances for cluster ID {}\", clusterPhyId);\n    } catch (Exception e) {\n        LOG.error(\"Error closing AdminClient instances for cluster ID {}\", clusterPhyId, e);\n    } finally {\n        lock.unlock();\n    }\n}", "CodeBleu_score": 50.65393544439492}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    if (clusterPhyId == null) {\n        return;\n    }\n    List<AdminClient> clients = new ArrayList<>();\n    synchronized (adminClientMap) {\n        clients = adminClientMap.remove(clusterPhyId);\n    }\n    if (clients == null || clients.isEmpty()) {\n        return;\n    }\n    log.info(\"Closing Kafka AdminClient instances for cluster {}\", clusterPhyId);\n    for (AdminClient client : clients) {\n        try {\n            client.close();\n        } catch (Exception e) {\n            log.error(\"Error closing Kafka AdminClient instance for cluster {}\", clusterPhyId, e);\n        }\n    }\n    log.info(\"Successfully closed Kafka AdminClient instances for cluster {}\", clusterPhyId);\n}", "CodeBleu_score": 49.68080230071249}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t  if (adminClientList == null) {\n    return true\n  }\n\n  boolean success = true\n  for (AdminClient adminClient : adminClientList) {\n    try {\n      adminClient.close(ofSeconds(30))\n    } catch (Exception e) {\n      logger.error(\"Failed to close AdminClient for cluster {}\", clusterPhyId, e)\n      success = false\n    }\n  }\n  return success\n}", "CodeBleu_score": 52.18214753692551}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    boolean success = true;\n    if (adminClientList != null) {\n        for (AdminClient adminClient : adminClientList) {\n            try {\n                adminClient.close(30, TimeUnit.SECONDS);\n            } catch (Exception e) {\n                LOGGER.error(\"Error closing AdminClient for cluster {}\", clusterPhyId, e);\n                success = false;\n            }\n        }\n    }\n    return success;\n}", "CodeBleu_score": 64.34018604903716}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    boolean success = true;\n    if (adminClientList != null) {\n        for (AdminClient adminClient : adminClientList) {\n            try {\n                adminClient.close(Duration.ofSeconds(30));\n            } catch (Exception e) {\n                success = false;\n                LOG.error(\"Failed to close AdminClient for cluster {}\", clusterPhyId, e);\n            }\n        }\n    }\n    return success;\n}", "CodeBleu_score": 66.31490932692448}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\t\tif (app != null) {\n\t\tapp.stop();\n\t\tint attempts = 0;\n\t\twhile (app != null && attempts < 5) {\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(\"Interrupted while waiting for application to stop\");\n\t\t\t}\n\t\t\tattempts++;\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 54.31970751877112}, {"code": "public void stop() {\n\t  if (isRunning()) {\n    try {\n      app.stop();\n      int attempts = 0;\n      while (isRunning() && attempts < 5) {\n        attempts++;\n        sleep(1000);\n      }\n      if (isRunning()) {\n        throw new IllegalStateException(\"Failed to stop application\");\n      }\n    } finally {\n      app = null;\n    }\n  }\n}", "CodeBleu_score": 38.79035365378519}, {"code": "public void stop() {\n\t  if (isRunning()) {\n    app.stop();\n    int count = 0;\n    while (isRunning() && count < 5) {\n      try {\n        sleep(1000);\n        count++;\n      } catch (InterruptedException e) {\n        throw new IllegalStateException(\"Interrupted while waiting for app to stop\");\n      }\n    }\n    app = null;\n  }\n}", "CodeBleu_score": 44.61531408057979}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner runner = new EurekaServerRunner(config)\n    runner.enableTls()\n    runner.setKeyStore(keyStore, keyStorePassword)\n    runner.setTrustStore(trustStore, trustStorePassword)\n    runner.start()\n    return runner\n}", "CodeBleu_score": 40.13864351401504}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner server = new EurekaServerRunner(config)\n    server.enableTls()\n    setTrustStore(server)\n    setKeyStore(server)\n    server.start()\n    server\n}", "CodeBleu_score": 41.14395907765365}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner runner = new EurekaServerRunner(config)\n    runner.enableTls(true)\n    runner.setKeyStore(keyStore, keyStorePassword)\n    runner.setTrustStore(trustStore, trustStorePassword)\n    runner.start()\n    return runner\n}", "CodeBleu_score": 40.0768710709547}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t    def runner = new EurekaClientRunner(\n            \"testservice\",\n            config,\n            server.getServiceUrl(),\n            false,\n            true\n    )\n    runner.start()\n    return runner\n}", "CodeBleu_score": 34.90174960613511}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t    def runner = new EurekaClientRunner(\n            \"testservice\",\n            config,\n            server.getServiceUrl(),\n            server.getApplicationInfoManager().getInfo()\n    )\n    runner.enableTlsClient()\n    runner.start()\n    return runner\n}", "CodeBleu_score": 36.39764011881442}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t    EurekaClientRunner runner = new EurekaClientRunner(\n            server.getServiceUrl(),\n            \"testservice\",\n            config,\n            true,\n            true\n    )\n    runner.start()\n    return runner\n}", "CodeBleu_score": 35.99008816884742}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t\t// create a keytool instance\n\tKeyTool keyTool = new KeyTool(KEYTOOL_PATH, KEYTOOL_PASSWORD);\n\t\n\t// create a CA certificate and sign it\n\tkeyTool.createCA(CA_ALIAS, CA_CN, CA_O, CA_OU, CA_L, CA_S, CA_C, CA_KEY_PASSWORD, CA_CERT_PASSWORD, CA_VALIDITY);\n\tkeyTool.saveCert(CA_ALIAS, CA_CERT_FILE);\n\t\n\t// create a server certificate and sign it with the CA\n\tkeyTool.createCert(SERVER_ALIAS, SERVER_CN, SERVER_O, SERVER_OU, SERVER_L, SERVER_S, SERVER_C, SERVER_KEY_PASSWORD, SERVER_CERT_PASSWORD, SERVER_VALIDITY, CA_ALIAS, CA_CERT_FILE);\n\tkeyTool.saveCert(SERVER_ALIAS, SERVER_CERT_FILE);\n\t\n\t// create a client certificate and sign it with the CA\n\tkeyTool.createCert(CLIENT_ALIAS, CLIENT_CN, CLIENT_O, CLIENT_OU, CLIENT_L, CLIENT_S, CLIENT_C, CLIENT_KEY_PASSWORD, CLIENT_CERT_PASSWORD, CLIENT_VALIDITY, CA_ALIAS, CA_CERT_FILE);\n\tkeyTool.saveCert(CLIENT_ALIAS, CLIENT_CERT_FILE);\n\t\n\t// create a second CA certificate and sign it\n\tkeyTool.createCA(CA2_ALIAS, CA2_CN, CA2_O, CA2_OU, CA2_L, CA2_S, CA2_C, CA2_KEY_PASSWORD, CA2_CERT_PASSWORD, CA2_VALIDITY);\n\tkeyTool.saveCert(CA2_ALIAS, CA2_CERT_FILE);\n\t\n\t// create a client certificate and sign it with the second CA\n\tkeyTool.createCert(CLIENT2_ALIAS, CLIENT2_CN, CLIENT2_O, CLIENT2_OU,", "CodeBleu_score": 19.639390099027338}, {"code": "static void createCertificates() throws Exception{\n\t    // Create a CA certificate\n    KeyTool caKeyTool = new KeyTool(\"CN=ca,OU=CA,O=MyOrg,L=London,C=GB\", \"ca\", \"ca\", \"ca\");\n    X509Certificate caCert = caKeyTool.generateSelfSignedCertificate();\n    saveCert(caCert, \"ca.cer\");\n\n    // Create a server certificate\n    KeyTool serverKeyTool = new KeyTool(\"CN=server,OU=Server,O=MyOrg,L=London,C=GB\", \"server\", \"server\", \"server\");\n    X509Certificate serverCert = serverKeyTool.generateCertificate(caKeyTool);\n    saveCert(serverCert, \"server.cer\");\n\n    // Create a client certificate\n    KeyTool clientKeyTool = new KeyTool(\"CN=client,OU=Client,O=MyOrg,L=London,C=GB\", \"client\", \"client\", \"client\");\n    X509Certificate clientCert = clientKeyTool.generateCertificate(caKeyTool);\n    saveCert(clientCert, \"client.cer\");\n\n    // Create a second CA certificate\n    KeyTool caKeyTool2 = new KeyTool(\"CN=ca2,OU=CA,O=MyOrg,L=London,C=GB\", \"ca2\", \"ca2\", \"ca2\");\n    X509Certificate caCert2 = caKeyTool2.generateSelfSignedCertificate();\n    saveCert(caCert2, \"ca2.cer\");\n\n    // Create a second client certificate\n    KeyTool clientKeyTool2 = new KeyTool(\"CN=client2,OU=Client,O=MyOrg,L=London,C=GB\", \"client2\", \"client2\", \"client2\");\n    X509Certificate clientCert2 = clientKeyTool2.generateCertificate(caKeyTool2);\n    saveCert(clientCert2, \"client2.cer\");\n\n    // Save the CA certificate and key\n    saveKeyAndCert(caKeyTool, caCert, \"ca\");\n\n    // Save the server certificate and key\n    saveKeyAndCert(serverKeyTool, serverCert, \"server\");\n", "CodeBleu_score": 23.618854354845677}, {"code": "static void createCertificates() throws Exception{\n\t\tKeyTool keyTool = new KeyTool(new File(KEY_STORE_FILE));\n\n\t// Create CA certificate\n\tkeyTool.createKey(CA_ALIAS, CA_KEY_PASSWORD, KeyTool.KEY_ALGORITHM, KeyTool.KEY_SIZE, KeyTool.KEY_VALIDITY, CA_SUBJECT, CA_SIGN_ALGORITHM);\n\tX509Certificate caCert = keyTool.createSelfSignedCert(CA_ALIAS, CA_KEY_PASSWORD, CA_SUBJECT, CA_SIGN_ALGORITHM, CA_VALIDITY);\n\tsaveCert(caCert, CA_CERT_FILE);\n\n\t// Create server certificate\n\tkeyTool.createKey(SERVER_ALIAS, SERVER_KEY_PASSWORD, KeyTool.KEY_ALGORITHM, KeyTool.KEY_SIZE, KeyTool.KEY_VALIDITY, SERVER_SUBJECT, KeyTool.SIGN_ALGORITHM);\n\tX509Certificate serverCert = keyTool.createCert(SERVER_ALIAS, SERVER_KEY_PASSWORD, SERVER_SUBJECT, KeyTool.SIGN_ALGORITHM, SERVER_VALIDITY, caCert, CA_ALIAS, CA_KEY_PASSWORD);\n\tsaveCert(serverCert, SERVER_CERT_FILE);\n\n\t// Create client certificate\n\tkeyTool.createKey(CLIENT_ALIAS, CLIENT_KEY_PASSWORD, KeyTool.KEY_ALGORITHM, KeyTool.KEY_SIZE, KeyTool.KEY_VALIDITY, CLIENT_SUBJECT, KeyTool.SIGN_ALGORITHM);\n\tX509Certificate clientCert = keyTool.createCert(CLIENT_ALIAS, CLIENT_KEY_PASSWORD, CLIENT_SUBJECT, KeyTool.SIGN_ALGORITHM, CLIENT_VALIDITY, caCert, CA_ALIAS, CA_KEY_PASSWORD);\n\tsaveCert(clientCert, CLIENT_CERT_FILE);\n\n\t// Create second CA certificate\n\tkeyTool.createKey(CA2_ALIAS, CA2_KEY_PASSWORD", "CodeBleu_score": 22.799856446338225}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long startTime = System.currentTimeMillis();\n    long timeLimit = startTime + (seconds * 1000);\n    while (System.currentTimeMillis() < timeLimit) {\n        if (assertion.getAsBoolean()) {\n            return;\n        }\n        try {\n            Thread.sleep(500);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n    throw new RuntimeException(\"Assertion not met in \" + seconds + \" seconds\");\n}", "CodeBleu_score": 43.377673698604575}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long startTime = System.currentTimeMillis();\n    long endTime = startTime + seconds * 1000;\n    while (System.currentTimeMillis() < endTime) {\n        if (assertion.getAsBoolean()) {\n            return;\n        }\n        try {\n            Thread.sleep(100);\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(e);\n        }\n    }\n    throw new RuntimeException(\"Assertion not met in \" + seconds + \" seconds\");\n}", "CodeBleu_score": 43.48089303004081}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long startTime = System.currentTimeMillis();\n    long endTime = startTime + (seconds * 1000);\n    while (System.currentTimeMillis() < endTime) {\n        if (assertion.getAsBoolean()) {\n            return;\n        }\n        try {\n            Thread.sleep(100);\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        }\n    }\n    throw new RuntimeException(\"Assertion not met within \" + seconds + \" seconds\");\n}", "CodeBleu_score": 42.243016213370574}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t    // Create a certificate builder using the public key and CA information\n    X509CertificateBuilder certBuilder = X509CertificateBuilder.fromKeypair(\n            keyPair.getPublic(),\n            keyPair.getPrivate(),\n            new X500Principal(ca),\n            new Date(),\n            new Date(System.currentTimeMillis() + 3600000 * 24 * 365)\n    );\n\n    // Add key usage and basic constraints extensions to the certificate\n    certBuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment | KeyUsage.keyCertSign));\n    certBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(true));\n\n    // Sign the certificate with the private key and return the signed X509 certificate\n    return certBuilder.build(keyPair.getPrivate());\n}", "CodeBleu_score": 41.959605981366636}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\n    // Create a certificate builder\n    CertificateBuilder certBuilder = this.certBuilder();\n\n    // Get the public key from the key pair\n    PublicKey publicKey = keyPair.getPublic();\n\n    // Get the private key from the key pair\n    PrivateKey privateKey = keyPair.getPrivate();\n\n    // Set the public key in the certificate builder\n    certBuilder.setPublicKey(publicKey);\n\n    // Set the CA information in the certificate builder\n    certBuilder.setIssuerDN(ca);\n\n    // Set the certificate validity period\n    certBuilder.setNotBefore(new Date(System.currentTimeMillis() - 10000));\n    certBuilder.setNotAfter(new Date(System.currentTimeMillis() + 1000000000));\n\n    // Set the subject key identifier extension\n    certBuilder.addExtension(Extension.subjectKeyIdentifier, false, new SubjectKeyIdentifier(publicKey));\n\n    // Set the key usage extension\n    certBuilder.addExtension(Extension.keyUsage, false, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment));\n\n    // Set the basic constraints extension\n    certBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\n    // Sign the certificate with the private key\n    X509Certificate cert = certBuilder.build(privateKey);\n\n    return cert;\n}", "CodeBleu_score": 36.127135260550574}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t    // Create the certificate builder\n    X509CertificateBuilder certBuilder = this.certBuilder(keyPair, ca);\n\n    // Add the key usage extension\n    certBuilder = this.addExtension(certBuilder, \"2.5.29.15\", false, new DEROctetString(new DERSequence(new ASN1Encodable[] { new DERBoolean(true), new DERBoolean(true), new DERBoolean(true) })));\n\n    // Add the basic constraints extension\n    certBuilder = this.addExtension(certBuilder, \"2.5.29.19\", false, new DEROctetString(new DERSequence(new ASN1Encodable[] { new DERBoolean(true), new DERInteger(2) })));\n\n    // Sign the certificate\n    return this.signCert(certBuilder, keyPair.getPrivate());\n}", "CodeBleu_score": 37.941865313633826}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (eurekaHttpClient == null) {\n        try {\n            Field registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n            registrationClientField.setAccessible(true);\n            eurekaHttpClient = (EurekaHttpClient) registrationClientField.get(eurekaTransport);\n        } catch (NoSuchFieldException | IllegalAccessException e) {\n            logger.error(\"Unable to retrieve EurekaHttpClient from EurekaTransport object\", e);\n        }\n    }\n    return eurekaHttpClient;\n}", "CodeBleu_score": 47.651811805689945}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (eurekaHttpClient == null) {\n        try {\n            Field registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n            registrationClientField.setAccessible(true);\n            eurekaHttpClient = (EurekaHttpClient) registrationClientField.get(eurekaTransport);\n        } catch (IllegalAccessException e) {\n            log.error(\"Error accessing registrationClient field\", e);\n        } catch (NoSuchFieldException e) {\n            log.error(\"No registrationClient field\", e);\n        }\n    }\n    return eurekaHttpClient;\n}", "CodeBleu_score": 51.808834330095486}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (eurekaHttpClient == null) {\n        try {\n            eurekaHttpClient = (EurekaHttpClient) getFieldValue(registrationClient, \"eurekaHttpClient\");\n        } catch (IllegalAccessException e) {\n            logger.error(\"Error accessing eurekaHttpClient\", e);\n        }\n    }\n    return eurekaHttpClient;\n}", "CodeBleu_score": 30.842940774607854}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t    List<String> services = new ArrayList<String>();\n    List<Application> apps = getApplications();\n    if (apps == null || apps.size() == 0) {\n        return services;\n    }\n    for (Application app : apps) {\n        if (app.getInstances() != null && app.getInstances().size() > 0) {\n            services.add(app.getName().toLowerCase());\n        }\n    }\n    return services;\n}", "CodeBleu_score": 41.03047100476602}, {"code": "public List<String> getServices(){\n\t    List<String> services = new ArrayList<>();\n    List<Application> applications = getApplications();\n    if (applications.isEmpty()) {\n        return services;\n    }\n    for (Application application : applications) {\n        if (!application.getInstances().isEmpty()) {\n            services.add(application.getName().toLowerCase());\n        }\n    }\n    return services;\n}", "CodeBleu_score": 41.200300475564156}, {"code": "public List<String> getServices(){\n\t\tList<String> serviceNames = new ArrayList<>();\n\tList<Application> applications = getApplications();\n\tif (applications.size() == 0) {\n\t\treturn serviceNames;\n\t}\n\tfor (Application app : applications) {\n\t\tif (app.getInstances().size() != 0) {\n\t\t\tserviceNames.add(app.getName().toLowerCase());\n\t\t}\n\t}\n\treturn serviceNames;\n}", "CodeBleu_score": 40.62836052179831}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    healthContributors.entrySet().forEach(entry -> {\n        if (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor contributor = (DiscoveryCompositeHealthContributor) entry.getValue();\n            contributor.getIndicators().forEach(indicator -> {\n                if (!(indicator.getValue() instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(entry.getKey() + \".\" + indicator.getKey(), indicator.getValue());\n                }\n            });\n        } else {\n            healthContributors.put(entry.getKey(), entry.getValue());\n        }\n    });\n}", "CodeBleu_score": 36.64212355612551}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    healthContributors.entrySet().forEach { entry ->\n        if (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor contributor = entry.getValue()\n            contributor.indicators.entrySet().forEach { indicatorEntry ->\n                if (!(indicatorEntry.getValue() instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(indicatorEntry.getKey(), indicatorEntry.getValue())\n                }\n            }\n        } else {\n            healthContributors.put(entry.getKey(), entry.getValue())\n        }\n    }\n}", "CodeBleu_score": 35.66220308757693}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    healthContributors.entrySet().forEach(entry -> {\n        if (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor dchc = (DiscoveryCompositeHealthContributor) entry.getValue();\n            dchc.getIndicators().entrySet().forEach(indicator -> {\n                if (!(indicator.getValue() instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(indicator.getKey(), indicator.getValue());\n                }\n            });\n        }\n    });\n}", "CodeBleu_score": 35.119900623966686}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t\n    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No instances found for provider-application\");\n    }\n    String uri = instances.get(0).getUri().toString();\n    RestTemplate restTemplate = new RestTemplate();\n    String response = restTemplate.postForObject(uri + \"/echo\", \"Hello\", String.class);\n    return response;\n}", "CodeBleu_score": 57.423014802265726}, {"code": "public String hello(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No service instance found for provider-application\");\n    }\n    ServiceInstance instance = instances.get(0);\n    String url = String.format(\"%s/echo\", instance.getUri());\n    RestTemplate restTemplate = new RestTemplate();\n    return restTemplate.postForObject(url, \"Hello World\", String.class);\n}", "CodeBleu_score": 56.6993232656839}, {"code": "public String hello(){\n\t    List<ServiceInstance> instances = this.discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No instances available for provider-application\");\n    }\n    ServiceInstance instance = instances.get(0);\n    String uri = instance.getUri().toString() + \"/echo\";\n    return this.restTemplate.postForObject(uri, \"Hello\", String.class);\n}", "CodeBleu_score": 46.173596428021156}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t\n\t// Get an instance of the load balancer client\n\tLoadBalancerClient loadBalancer = context.getBean(LoadBalancerClient.class);\n\n\t// Try to get the service instance with the name \"provider-application\"\n\tServiceInstance instance = loadBalancer.choose(\"provider-application\");\n\n\t// If no such service is found, throw an exception\n\tif (instance == null) {\n\t\tthrow new RuntimeException(\"No service with name provider-application\");\n\t}\n\n\t// Construct a URI for the service instance\n\tURI uri = getUri(instance);\n\n\t// Use a RestTemplate to send a POST request to the \"/echo\" endpoint\n\treturn postForObject(uri, \"Hello World!\", String.class);\n}", "CodeBleu_score": 42.3123760839428}, {"code": "public String world(){\n\t    String serviceInstance = loadBalancerClient.choose(\"provider-application\");\n    if (serviceInstance == null) {\n        throw new RuntimeException(\"No service instance found for provider-application\");\n    }\n    String uri = \"http://\" + serviceInstance + \"/echo\";\n    RestTemplate restTemplate = new RestTemplate();\n    return restTemplate.postForObject(uri, \"World\", String.class);\n}", "CodeBleu_score": 49.04236457673984}, {"code": "public String world(){\n\t    LoadBalancerClient loadBalancer = context.getBean(LoadBalancerClient.class);\n    ServiceInstance instance = loadBalancer.choose(\"provider-application\");\n    String url = String.format(\"http://%s:%s/echo\", instance.getHost(), instance.getPort());\n    RestTemplate restTemplate = new RestTemplate();\n    return restTemplate.postForObject(url, \"hello\", String.class);\n}", "CodeBleu_score": 46.12523695177628}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    logger.info(\"Registering \" + serviceName + \" with ip \" + ip + \" and port \" + port);\n    if (serverMap.containsKey(serviceName)) {\n        synchronized (serverMap.get(serviceName)) {\n            return serverMap.get(serviceName).add(new Server(ip, port));\n        }\n    } else {\n        Set<Server> set = Collections.synchronizedSet(new HashSet<Server>());\n        set.add(new Server(ip, port));\n        serverMap.put(serviceName, set);\n        return true;\n    }\n}", "CodeBleu_score": 50.440661299368074}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\n    Server server = new Server(ip, port);\n\n    if (serverMap.containsKey(serviceName)) {\n        Set<Server> servers = serverMap.get(serviceName);\n        servers.add(server);\n        serverMap.put(serviceName, servers);\n        logger.info(\"Registered service: \" + serviceName + \" with IP: \" + ip + \" and port: \" + port);\n        return true;\n    } else {\n        Set<Server> servers = Collections.synchronizedSet(new HashSet<>());\n        servers.add(server);\n        serverMap.put(serviceName, servers);\n        logger.info(\"Registered service: \" + serviceName + \" with IP: \" + ip + \" and port: \" + port);\n        return true;\n    }\n}", "CodeBleu_score": 53.632923820854515}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    log.info(\"Registering service \" + serviceName + \" with IP \" + ip + \" and port \" + port);\n\n    if (!serverMap.containsKey(serviceName)) {\n        serverMap.putIfAbsent(serviceName, Collections.synchronizedSet(new HashSet<>()));\n    }\n\n    Server server = new Server(ip, port);\n    return serverMap.get(serviceName).add(server);\n}", "CodeBleu_score": 61.56319170584542}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\t// TODO: Implement this method\n\tServer server = new Server(ip, port);\n\tServerMap serverMap = serverMapMap.get(serviceName);\n\tif (serverMap == null) {\n\t\treturn false;\n\t}\n\tif (serverMap.getServerSet().contains(server)) {\n\t\tserverMap.getServerSet().remove(server);\n\t\tlog.info(\"Deregistered server \" + server + \" from service \" + serviceName);\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 52.30455145064825}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    Server server = new Server(serviceName, ip, port);\n    boolean deregistered = serverMap.get(serviceName).remove(server);\n    if (deregistered) {\n        LOGGER.info(\"Deregistered server: \" + server.toString());\n    }\n    return deregistered;\n}", "CodeBleu_score": 49.89345270250629}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    if (serverMap.containsKey(serviceName)) {\n        if (serverMap.get(serviceName).contains(new Server(ip, port))) {\n            logger.info(\"Deregistered \" + ip + \":\" + port + \" from \" + serviceName);\n            serverMap.get(serviceName).remove(new Server(ip, port));\n            return true;\n        }\n        else {\n            logger.info(\"Server \" + ip + \":\" + port + \" not found in \" + serviceName);\n            return false;\n        }\n    }\n    else {\n        logger.info(\"Service \" + serviceName + \" not found\");\n        return false;\n    }\n}", "CodeBleu_score": 36.396971304078725}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName(), true);\n    if (attributes == null) {\n        return;\n    }\n    Object[] clients = (Object[]) attributes.get(\"value\");\n    if (clients == null) {\n        return;\n    }\n    for (Object client : clients) {\n        if (client instanceof AnnotationMetadata) {\n            registerClientConfiguration((AnnotationMetadata) client, registry);\n        }\n    }\n}", "CodeBleu_score": 53.415636990856285}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attributes != null) {\n        registerClientConfigurations(attributes, registry);\n    }\n}", "CodeBleu_score": 33.808556538962534}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attributes != null) {\n        List<String> basePackages = new ArrayList<String>();\n        for (String pkg : (String[]) attributes.get(\"value\")) {\n            if (StringUtils.hasText(pkg)) {\n                basePackages.add(pkg);\n            }\n        }\n        for (String pkg : (String[]) attributes.get(\"basePackages\")) {\n            if (StringUtils.hasText(pkg)) {\n                basePackages.add(pkg);\n            }\n        }\n        for (Class<?> clazz : (Class[]) attributes.get(\"basePackageClasses\")) {\n            basePackages.add(ClassUtils.getPackageName(clazz));\n        }\n        if (basePackages.isEmpty()) {\n            basePackages.add(ClassUtils.getPackageName(metadata.getClassName()));\n        }\n        registerClientConfigurations(attributes, basePackages, registry);\n    }\n}", "CodeBleu_score": 39.70004624740982}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    ServiceInstance instance = chooseServer(serviceId, request);\n    if (instance == null) {\n        return null;\n    }\n    return new TutuServiceInstance(instance.getServiceId(), instance.getHost(), instance.getPort());\n}", "CodeBleu_score": 37.145197498431706}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    return choose(serviceId, request, null);\n}", "CodeBleu_score": 12.469394230308437}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    return choose(serviceId, request, null);\n}", "CodeBleu_score": 12.469394230308437}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    String host = server.getHost();\n    int port = server.getPort();\n    String scheme = original.getScheme();\n    String query = original.getRawQuery();\n    String path = original.getRawPath();\n    try {\n        StringBuilder sb = new StringBuilder();\n        sb.append(scheme).append(\"://\").append(host).append(\":\").append(port).append(path);\n        if (query != null) {\n            sb.append(\"?\").append(query);\n        }\n        return new URI(sb.toString());\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 56.34905581977814}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t  URI reconstructed = null;\n  try {\n    String scheme = original.getScheme();\n    String host = original.getHost();\n    String port = original.getPort() == -1 ? null : original.getPort()+\"\";\n    String path = original.getPath();\n    String query = original.getRawQuery();\n    String fragment = original.getFragment();\n\n    // Reconstruct the path\n    StringBuilder sb = new StringBuilder();\n    sb.append(\"/\");\n    sb.append(server.getServiceId());\n    sb.append(\"/\");\n    sb.append(server.getHost());\n    sb.append(\":\");\n    sb.append(server.getPort());\n    sb.append(path);\n\n    // Reconstruct the query string\n    if (query != null && !query.isEmpty()) {\n      sb.append(\"?\");\n      sb.append(query);\n    }\n\n    reconstructed = new URI(scheme, host, port, sb.toString(), fragment);\n  } catch (URISyntaxException e) {\n    throw new RuntimeException(e);\n  }\n\n  return reconstructed;\n}", "CodeBleu_score": 53.45576283429602}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    String host = server.getHost();\n    int port = server.getPort();\n    String scheme = original.getScheme();\n    String query = original.getRawQuery();\n    try {\n        // Note that we use a URI builder here to ensure that we don't\n        // inadvertently change the meaning of the URI.\n        // For example, if the original URI contains a path that ends with \"/\",\n        // we don't want to lose that information when we call toString() on the URI\n        // object.\n        return new URIBuilder()\n            .setScheme(scheme)\n            .setHost(host)\n            .setPort(port)\n            .setPath(original.getRawPath())\n            .setCustomQuery(query)\n            .build();\n    }\n    catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 44.16838452513626}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t    def http = new HTTPBuilder(getServerAddr())\n    def response = http.request(Method.GET, ContentType.JSON) {\n        uri.path = \"/list\"\n        uri.query = [\n                serviceName: serviceName\n        ]\n        response.success = { resp, json ->\n            return json\n        }\n        response.failure = { resp, json ->\n            return null\n        }\n    }\n    return response\n}", "CodeBleu_score": 23.39110390368174}, {"code": "private List<TutuServer> getServer(){\n\t    //TODO: Implement this function\n    String serviceName = \"TutuServer\";\n    String serverAddr = getServerAddr();\n    String url = serverAddr + \"/list\";\n    String response = getString(url);\n    List<TutuServer> serverList = parseArray(response);\n    return serverList;\n}", "CodeBleu_score": 17.96449538148164}, {"code": "private List<TutuServer> getServer(){\n\t    String serviceName = getString(SERVICE_NAME)\n    String serverAddr = getServerAddr()\n\n    String url = serverAddr + \"/list\"\n    String response = get(url)\n    return parseArray(response)\n}", "CodeBleu_score": 15.357222479565442}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t    for (Map.Entry<String, ZuulRoute> entry : this.getRoutes().entrySet()) {\n        String pattern = entry.getKey();\n        ZuulRoute zuulRoute = entry.getValue();\n        if (this.pathMatcher.match(pattern, path)) {\n            String target = this.pathMatcher.extractPathWithinPattern(pattern, path);\n            return new Route(target, zuulRoute.getServiceId());\n        }\n    }\n    return null;\n}", "CodeBleu_score": 49.43669480186923}, {"code": "public Route getMatchingRoute(String path){\n\t    Route matchedRoute = null;\n    String matchedPath = null;\n    for (Route route : this.routes) {\n        // If the route matches the path, get the target path and service ID\n        if (pathMatcher.match(route.getPath(), path)) {\n            matchedPath = pathMatcher.extractPathWithinPattern(route.getPath(), path);\n            matchedRoute = new Route(route.getId(), matchedPath, route.getServiceId());\n            break;\n        }\n    }\n    return matchedRoute;\n}", "CodeBleu_score": 28.768649372736867}, {"code": "public Route getMatchingRoute(String path){\n\t    Route route = null;\n    if (path != null) {\n        for (ZuulRoute zuulRoute : this.getRoutes()) {\n            if (zuulRoute.getPath().equalsIgnoreCase(path)) {\n                route = new Route(path, zuulRoute.getId());\n                break;\n            } else if (this.pathMatcher.match(zuulRoute.getPath(), path)) {\n                String targetPath = this.pathMatcher.extractPathWithinPattern(zuulRoute.getPath(), path);\n                route = new Route(targetPath, zuulRoute.getId());\n                break;\n            }\n        }\n    }\n    return route;\n}", "CodeBleu_score": 32.81101627820999}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attributes = importingClassMetadata.getAnnotationAttributes(EnableFeignClients.class.getName());\n    String[] basePackages = (String[]) attributes.get(\"value\");\n    if (basePackages == null || basePackages.length == 0) {\n        basePackages = new String[] {\n                ClassUtils.getPackageName(importingClassMetadata.getClassName())\n        };\n    }\n    for (String basePackage : basePackages) {\n        if (StringUtils.hasText(basePackage)) {\n            ClassPathScanningCandidateComponentProvider scanner = getScanner();\n            scanner.setResourceLoader(this.resourceLoader);\n            AnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(FeignClient.class);\n            scanner.addIncludeFilter(annotationTypeFilter);\n            for (BeanDefinition candidate : scanner.findCandidateComponents(basePackage)) {\n                if (candidate instanceof AnnotatedBeanDefinition) {\n                    AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidate;\n                    AnnotationMetadata annotationMetadata = beanDefinition.getMetadata();\n                    Assert.isTrue(annotationMetadata.isInterface(),\n                            \"@FeignClient can only be specified on an interface\");\n                    Map<String, Object> attributesMap = annotationMetadata\n                            .getAnnotationAttributes(FeignClient.class.getCanonicalName());\n                    registerFeignClient(registry, annotationMetadata, attributesMap);\n                }\n            }\n        }\n    }\n}", "CodeBleu_score": 35.29235913331078}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    registerFeignClient(importingClassMetadata, registry);\n}", "CodeBleu_score": 3.692754934017686}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attributes = importingClassMetadata.getAnnotationAttributes(EnableFeignClients.class.getName());\n    Object[] clients = (Object[]) attributes.get(\"clients\");\n    if (clients.length == 0) {\n        clients = new String[] { AnnotationUtils.getNestedAnnotationAttribute(importingClassMetadata, EnableFeignClients.class.getName(), \"clients\") };\n    }\n    for (Object client : clients) {\n        String className = client.toString();\n        BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(FeignClientFactoryBean.class);\n        builder.addPropertyValue(\"type\", className);\n        builder.addPropertyValue(\"name\", className);\n        AbstractBeanDefinition beanDefinition = builder.getBeanDefinition();\n        if (beanDefinition instanceof AbstractBeanDefinition) {\n            try {\n                String beanClassName = ClassUtils.forName(className, EnableFeignClients.class.getClassLoader()).getName();\n                AbstractBeanDefinition tempBeanDefinition = BeanDefinitionBuilder.genericBeanDefinition(beanClassName).getBeanDefinition();\n                ((AbstractBeanDefinition) beanDefinition).overrideFrom(tempBeanDefinition);\n            } catch (ClassNotFoundException e) {\n                throw new IllegalStateException(\"Unable to resolve bean class for type \" + className, e);\n            }\n        }\n        registry.registerBeanDefinition(className, beanDefinition);\n    }\n}", "CodeBleu_score": 38.53454298482274}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}]}
