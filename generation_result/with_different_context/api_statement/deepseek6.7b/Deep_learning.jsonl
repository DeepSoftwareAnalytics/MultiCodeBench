{"instance_id": "1f9f4d85e825", "generation_result": [{"code": "def load_model_from_config(self, half_attention)\n\t\n    if self.cache_models:\n        if self.model_path.endswith(\".safetensors\"):\n            model_path = self.model_path\n        else:\n            model_path = os.path.join(self.model_path, \"pytorch_model.bin\")\n        model_cache_path = os.path.join(self.cache_dir, f\"{model_path.split('/')[-1]}.pt\")\n        if os.path.exists(model_cache_path):\n            model = torch.load(model_cache_path)\n            if model is not None:\n                self.logger.info(f\"Loaded model from cache: {model_cache_path}\")\n                return model\n    else:\n        model_path = self.model_path\n    self.logger.info(f\"Loading model from: {model_path}\")\n    if model_path.endswith(\".safetensors\"):\n        model = safetensors.torch.load_file(model_path, device=\"cpu\")\n    else:\n        model = torch.load(model_path, map_location=\"cpu\")\n    if \"state_dict\" in model:\n        model = model[\"state_dict\"]\n    model = self.load_model_from_config_dict(model)\n    model.eval()\n    if half_attention:\n        model.half()\n    if self.memory_format_optimization:\n        model.to(memory_format=torch.channels_last)\n    if self.device == \"cuda\":\n        model.to(device=\"cuda\")\n    self.logger.info(\"Model loaded\")\n    if self.cache_models:\n        torch.save(model, model_cache_path)\n        self.logger.info(f\"Cached model: {model_cache_path}\")\n    return model\n\n", "CodeBleu_score": 38.967476502770474}, {"code": "def load_model_from_config(self, half_attention)\n\t\n    if self.config.get(\"cache_model\"):\n        cache_path = self.config.get(\"cache_model_path\")\n        if cache_path is None:\n            cache_path = os.path.join(self.config.get(\"cache_dir\"), \"model.pt\")\n        if os.path.exists(cache_path):\n            try:\n                model = torch.load(cache_path, map_location=\"cpu\")\n                if model.get(\"half_attention\"):\n                    model.half()\n                model.eval()\n                model.to(self.device)\n                return model\n            except Exception as e:\n                logger.warning(f\"Failed to load cached model: {e}\")\n\n    model_path = self.config.get(\"model_path\")\n    if model_path is None:\n        raise ValueError(\"No model path specified in config\")\n    if os.path.exists(model_path):\n        try:\n            model = torch.load(model_path, map_location=\"cpu\")\n            if model.get(\"half_attention\"):\n                model.half()\n            model.eval()\n            model.to(self.device)\n            if self.config.get(\"cache_model\"):\n                torch.save(model, cache_path)\n            return model\n        except Exception as e:\n            logger.warning(f\"Failed to load model from path: {e}\")\n\n    if model_path.endswith(\".safetensors\"):\n        try:\n            model = load_file(model_path)\n            if model.get(\"half_attention\"):\n                model.half()\n            model.eval()\n            model.to(self.device)\n            if self.config.get(\"cache_model\"):\n                torch.save(model, cache_path)\n            return model\n        except Exception as e:\n            logger.warning(f\"Failed to load model from path: {e}\")\n\n    if model_path.endswith(\".ckpt\"):\n        try:\n            model = torch.load(model_path, map_location=\"cpu\")\n            if model.get(\"half_attention\"", "CodeBleu_score": 32.49923650526762}, {"code": "def load_model_from_config(self, half_attention)\n\t\n    if self.cache_path is not None:\n        if os.path.exists(self.cache_path) and os.path.isfile(self.cache_path):\n            try:\n                model = torch.load(self.cache_path)\n                if self.model_name in model:\n                    model = model[self.model_name]\n                else:\n                    model = None\n            except Exception as e:\n                print(f\"Error loading cached model: {e}\")\n                model = None\n            if model is not None:\n                print(f\"Loaded model from cache: {self.cache_path}\")\n                return model\n\n    model_path = self.model_path\n    if model_path is None:\n        raise ValueError(\"No model path specified\")\n\n    if not os.path.exists(model_path):\n        raise FileNotFoundError(f\"Model not found at {model_path}\")\n\n    if model_path.endswith(\".safetensors\"):\n        model = load_file(model_path)\n    else:\n        model = torch.load(model_path, map_location=\"cpu\")\n\n    if self.model_name in model:\n        model = model[self.model_name]\n    else:\n        model = model\n\n    if hasattr(model, \"load_state_dict\"):\n        model.load_state_dict(model.state_dict())\n\n    model.eval()\n    model.half() if half_attention else model.float()\n    model.to(self.device)\n\n    if self.optimize_memory:\n        model.half()\n        model.to(memory_format=torch.channels_last)\n\n    print(f\"Loaded model from {model_path}\")\n\n    if self.cache_path is not None:\n        torch.save({self.model_name: model}, self.cache_path)\n        print(f\"Cached model at {self.cache_path}\")\n\n    return model\n\n", "CodeBleu_score": 36.98592939685212}]}
{"instance_id": "8dc955007aa2", "generation_result": [{"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n    # Initialize the DDIM sampler\n    sampler = DDIMSampler(model)\n\n    # Extract the batch size from the shape parameter\n    batch_size = shape[0]\n\n    # Print the eta and steps values\n    print(f\"sampling steps: {steps}\")\n    print(f\"eta: {eta}\")\n\n    # Call the sample method of the DDIMSampler instance\n    samples, intermediates = sampler.sample(steps, batch_size, shape, cond, eta=eta, callback=callback,\n                                            normals_sequence=normals_sequence, mask=mask, x0=x0,\n                                            quantize_x0=quantize_x0, temperature=temperature,\n                                            score_corrector=score_corrector,\n                                            corrector_kwargs=corrector_kwargs, x_t=x_t)\n\n    # Return the generated samples and intermediate values\n    return samples, intermediates\n\n", "CodeBleu_score": 58.173377816165626}, {"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n    model_wrap = ModelWrapper(model)\n    batch_size = shape[0]\n    print(f\"sampling steps: {steps}\")\n    print(f\"eta: {eta}\")\n    if callback:\n        callback(0)\n    sampler = DDIMSampler(model_wrap)\n    return sampler.sample(\n        S=steps,\n        batch_size=batch_size,\n        shape=shape,\n        conditioning=cond,\n        eta=eta,\n        callback=callback,\n        normals_sequence=normals_sequence,\n        mask=mask,\n        x0=x0,\n        quantize_x0=quantize_x0,\n        temperature=temperature,\n        score_corrector=score_corrector,\n        corrector_kwargs=corrector_kwargs,\n        x_T=x_t,\n    )", "CodeBleu_score": 43.84996577396921}, {"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n    batch_size = shape[0]\n    print(f'sampling steps: {steps}')\n    print(f'eta: {eta}')\n    model.to(cond.device)\n    model.eval()\n    shape = [batch_size, *shape[1:]]\n    if mask is not None:\n        mask = mask.to(cond.device)\n    if x0 is not None:\n        x0 = x0.to(cond.device)\n    if x_t is not None:\n        x_t = x_t.to(cond.device)\n\n    shape = [batch_size, *shape[1:]]\n    if mask is not None:\n        mask = mask.to(cond.device)\n    if x0 is not None:\n        x0 = x0.to(cond.device)\n    if x_t is not None:\n        x_t = x_t.to(cond.device)\n\n    sampler = DDIMSampler(model)\n    samples, intermediates = sampler.sample(\n        S=steps,\n        conditioning=cond,\n        batch_size=batch_size,\n        shape=shape,\n        verbose=False,\n        eta=eta,\n        callback=callback,\n        normals_sequence=normals_sequence,\n        mask=mask,\n        x0=x0,\n        quantize_x0=quantize_x0,\n        temperature=temperature,\n        score_corrector=score_corrector,\n        corrector_kwargs=corrector_kwargs,\n        x_T=x_t,\n    )\n    return samples, intermediates", "CodeBleu_score": 54.08561592009838}]}
{"instance_id": "9bdcd9081480", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    with tf.name_scope(self.name):\n        if context:\n            print(f\"", "CodeBleu_score": 6.327636858557723}, {"code": "def ema_scope(self, context=None)\n\t\n    if not self.ema_enabled:\n        return\n    if context is not None:\n        context.print(f\"Using EMA weights for {self.name}\")\n    self.ema_enabled = False\n    self.ema_weights = self.weights\n    self.weights = self.ema_weights\n    if context is not None:\n        context.print(f\"Switched to EMA weights for {self.name}\")\n    yield\n    self.ema_enabled = True\n    self.weights = self.ema_weights\n    if context is not None:\n        context.print(f\"Restored original weights for {self.name}\")\n\n", "CodeBleu_score": 40.248922804902044}, {"code": "def ema_scope(self, context=None)\n\t\n    if self.ema_enabled:\n        self.ema_enabled = False\n        if context:\n            context.print_log(\"EMA weights are being used. Restoring original weights.\")\n        self.ema_weights = self.model.get_weights()\n        self.model.set_weights(self.ema_weights)\n        if context:\n            context.print_log(\"EMA weights have been restored.\")\n\n", "CodeBleu_score": 31.863934278064598}]}
{"instance_id": "14ab009e1c5c", "generation_result": [{"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    sd = torch.load(path, map_location=\"cpu\")[\"state_dict\"]\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"model.\")}\n    if ignore_keys:\n        sd = {k: v for k, v in sd.items() if not any([k.startswith(ignore_key) for ignore_key in ignore_keys])}\n    self.load_state_dict(sd, strict=False)\n    missing, unexpected = [], []\n    for name, param in self.named_parameters():\n        if name not in sd:\n            missing.append(name)\n        elif sd[name].shape != param.shape:\n            unexpected.append(name)\n    if missing:\n        print(f\"Missing key(s) in state_dict: {missing}\")\n    if unexpected:\n        print(f\"Unexpected key(s) in state_dict: {unexpected}\")\n\n", "CodeBleu_score": 42.616214535916214}, {"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    sd = torch.load(path, map_location=\"cpu\")[\"state_dict\"]\n    keys = list(sd.keys())\n    for k in keys:\n        if k.startswith(\"module.\"):\n            sd[k[7:]] = sd[k]\n            del sd[k]\n    missing, unexpected = self.load_state_dict(sd, strict=False)\n    if len(missing) > 0:\n        print(\"missing keys:\")\n        print(\"", "CodeBleu_score": 34.084849544564214}, {"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    sd = torch.load(path, map_location=\"cpu\")[\"state_dict\"]\n    keys = list(sd.keys())\n    if ignore_keys is not None:\n        for k in keys:\n            if k.startswith(\"model.\"):\n                sd.pop(k)\n            elif k.startswith(\"model_ema.\"):\n                sd.pop(k)\n            elif k.startswith(\"model_ema_copy.\"):\n                sd.pop(k)\n            elif k.startswith(\"model_ema_copy_2.\"):\n                sd.pop(k)\n    missing_keys = []\n    unexpected_keys = []\n    error_msgs = []\n    # copy state_dict so _load_from_state_dict can modify it\n    metadata = getattr(state_dict, \"_metadata\", None)\n    state_dict = state_dict.copy()\n    if metadata is not None:\n        state_dict._metadata = metadata\n    # load state dict\n    self.load_state_dict(state_dict, strict=False)\n    # save to the fixed checkpoint keys are stripped of \"model.\" prefix\n    structure = {}\n    for name, module in self.named_modules():\n        structure[name] = module\n    for name, module in structure.items():\n        try:\n            module._load_from_state_dict(\n                state_dict, prefix=name + \".\", local_metadata=metadata\n            )\n        except Exception as e:\n            print(e)\n            error_msgs.append(\n                \"Warning: Error(s) in loading {} from checkpoint:", "CodeBleu_score": 30.267504314019323}]}
{"instance_id": "754176e27b81", "generation_result": [{"code": "def forward(self, input, return_pred_indices=False)\n\t\n    # Encoding\n    encoded = self.encode(input)\n\n    # Decoding\n    decoded = self.decode(encoded)\n\n    # Returning the decoded output and the difference metric\n    return decoded, self.difference_metric(input, decoded)\n\n", "CodeBleu_score": 19.908294184001015}, {"code": "def forward(self, input, return_pred_indices=False)\n\t\n    input_shape = input.shape\n    input = input.view(-1, input.shape[-1])\n    input = self.encode(input)\n    input = self.decode(input)\n    input = input.view(input_shape)\n    if return_pred_indices:\n        return input, torch.argmax(input, dim=-1)\n    else:\n        return input\n\n", "CodeBleu_score": 31.65478002406587}, {"code": "def forward(self, input, return_pred_indices=False)\n\t\n    self.encode(input)\n    decoded_output = self.decode()\n    if return_pred_indices:\n        return decoded_output, self.pred_indices\n    return decoded_output\n\n", "CodeBleu_score": 29.312651148609252}]}
{"instance_id": "443df6fdaf0d", "generation_result": [{"code": "def get_input(self, batch, k)\n\t\n    x = batch[k]\n    if len(x.shape) == 3:\n        x = x.unsqueeze(1)\n    x = x.permute(0, 3, 1, 2).contiguous().float()\n    if self.batch_resize:\n        x = F.interpolate(x, size=(self.batch_resize_height, self.batch_resize_width), mode='bicubic')\n    x = x.detach()\n    return x\n\n", "CodeBleu_score": 33.57825449328652}, {"code": "def get_input(self, batch, k)\n\t\n    x = batch[k]\n    if x.dim() == 2:\n        x = x.unsqueeze(0)\n    if x.dim() == 3:\n        x = x.unsqueeze(0)\n    if x.dim() == 4:\n        x = x.permute(0, 3, 1, 2)\n    x = F.interpolate(x, size=(self.height, self.width), mode='bicubic', align_corners=True)\n    x = x.contiguous().float()\n    if self.batch_resize:\n        scale = np.linspace(self.batch_min, self.batch_max, self.batch_steps)\n        scale = scale[self.step % self.batch_steps]\n        x = F.interpolate(x, scale_factor=scale, mode='bicubic', align_corners=True)\n    x = x.detach()\n    return x\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 46.838049011917185}, {"code": "def get_input(self, batch, k)\n\t\n    x = batch[k]\n    if len(x.shape) == 3:\n        x = x.unsqueeze(1)\n    if x.shape[2] != self.img_size or x.shape[3] != self.img_size:\n        if self.resize_data:\n            x = F.interpolate(x, size=(self.img_size, self.img_size), mode='bicubic')\n        else:\n            raise Exception('Image size mismatch')\n    x = x.permute(0, 3, 1, 2).contiguous().float()\n    if self.resize_data:\n        x = x[np.arange(x.shape[0]), :, int(self.img_size * self.train_step / self.max_steps):int(self.img_size * (self.train_step + 1) / self.max_steps), int(self.img_size * self.train_step / self.max_steps):int(self.img_size * (self.train_step + 1) / self.max_steps)]\n    x = x.detach()\n    return x", "CodeBleu_score": 48.83356805408664}]}
{"instance_id": "953a2632fc15", "generation_result": [{"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t\n    x, y = batch\n    y_hat = self(x)\n    if optimizer_idx == 0:\n        loss = self.loss(y_hat, y)\n        self.log(\"autoencoder_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n    elif optimizer_idx == 1:\n        disc_loss = self.disc_loss(y_hat, y)\n        self.log(\"discriminator_loss\", disc_loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n    return loss\n\n", "CodeBleu_score": 13.588173343944627}, {"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t\n    # Retrieve the input data and predictions\n    x, y = batch\n    y_hat = self(x)\n\n    # Compute the autoencoding loss\n    if optimizer_idx == 0:\n        loss = self.loss(y_hat, y)\n        self.log(\"train_loss\", loss, on_step=True, on_epoch=True)\n        return loss\n\n    # Compute the discriminator loss\n    if optimizer_idx == 1:\n        # Get the last layer of the generator\n        last_layer = self.get_last_layer(y_hat)\n        # Compute the discriminator loss\n        loss = self.loss(last_layer, y)\n        self.log(\"disc_loss\", loss, on_step=True, on_epoch=True)\n        return loss\n\n", "CodeBleu_score": 14.7839858497712}, {"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t\n    x, y = batch\n    y_hat = self(x)\n    if optimizer_idx == 0:\n        loss = self.loss(y_hat, y)\n        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n        return loss\n    elif optimizer_idx == 1:\n        loss = self.disc_loss(y_hat, y)\n        self.log(\"disc_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n        return loss\n\n", "CodeBleu_score": 12.770572309720016}]}
{"instance_id": "b449b5e8b77f", "generation_result": [{"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t\n    x, y = batch\n    if self.ema_scope is not None:\n        with tf.variable_scope(self.ema_scope, reuse=True):\n            x_ema = self.ema_ema(x)\n    else:\n        x_ema = x\n    if not only_inputs:\n        y_hat = self.sample(x)\n        y_hat_ema = self.sample(x_ema)\n        x = self.get_input(x)\n        x_ema = self.get_input(x_ema)\n        y = self.get_input(y)\n        y_hat = self.get_input(y_hat)\n        y_hat_ema = self.get_input(y_hat_ema)\n        if self.to_rgb:\n            x = tf.image.grayscale_to_rgb(x)\n            x_ema = tf.image.grayscale_to_rgb(x_ema)\n            y = tf.image.grayscale_to_rgb(y)\n            y_hat = tf.image.grayscale_to_rgb(y_hat)\n            y_hat_ema = tf.image.grayscale_to_rgb(y_hat_ema)\n        self.logger.log_images(x, 'inputs', **kwargs)\n        self.logger.log_images(y, 'ground_truth', **kwargs)\n        self.logger.log_images(y_hat, 'reconstructions', **kwargs)\n        if plot_ema:\n            self.logger.log_images(y_hat_ema, 'reconstructions_ema', **kwargs)\n    else:\n        x = self.get_input(x)\n        x_ema = self.get_input(x_ema)\n        if self.to_rgb:\n            x = tf.image.grayscale_to_rgb(x)\n            x_ema = tf.image.grayscale_to_rgb(x_ema)\n        self.logger.log_images(x, 'inputs', **kwargs)\n        self.logger.log_images", "CodeBleu_score": 30.096075829324185}, {"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t\n    x, y = batch\n    batch_size = x.shape[0]\n    if self.ema_scope is not None:\n        self.ema_scope.model.eval()\n        with torch.no_grad():\n            if self.ema_scope.ema_model is not None:\n                ema_model = self.ema_scope.ema_model\n            else:\n                ema_model = self.ema_scope.model\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)\n            ema_model.eval()\n            ema_model.to(self.device)", "CodeBleu_score": 15.817785502818701}, {"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t\n    x, y = batch\n    batch_size = x.shape[0]\n    if plot_ema:\n        x_recon = self.ema_recon(x)\n    else:\n        x_recon = self.recon(x)\n    x = self.get_input(x)\n    x_recon = self.get_input(x_recon)\n    if self.to_rgb:\n        x = x.permute(0, 2, 3, 1)\n        x_recon = x_recon.permute(0, 2, 3, 1)\n    if self.ema_scope is not None:\n        self.ema_scope.update(self.ema_model, self)\n    if only_inputs:\n        self.logger.experiment.add_images(\"inputs\", x, self.global_step)\n    else:\n        self.logger.experiment.add_images(\"inputs\", x, self.global_step)\n        self.logger.experiment.add_images(\"reconstructions\", x_recon, self.global_step)\n\n", "CodeBleu_score": 32.063337014021116}]}
{"instance_id": "540d089e3481", "generation_result": [{"code": "def get_loss(self, pred, target, mean=True)\n\t\n    loss_type = self.loss_type\n    if loss_type == \"l1\":\n        if mean:\n            return torch.mean(torch.abs(pred - target))\n        else:\n            return torch.abs(pred - target)\n    elif loss_type == \"l2\":\n        if mean:\n            return torch.mean(torch.pow(pred - target, 2))\n        else:\n            return torch.pow(pred - target, 2)\n    else:\n        raise NotImplementedError(f\"Unknown loss type: {loss_type}\")\n\n", "CodeBleu_score": 27.60492524263371}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == \"l1\":\n        return torch.mean(torch.abs(pred - target))\n    elif self.loss_type == \"l2\":\n        return torch.mean((pred - target) ** 2) if mean else (pred - target) ** 2\n    else:\n        raise NotImplementedError(\"Unknown loss type: {}\".format(self.loss_type))\n\n", "CodeBleu_score": 24.97652492061809}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        if mean:\n            return torch.mean(torch.abs(pred - target))\n        else:\n            return torch.abs(pred - target)\n    elif self.loss_type == 'l2':\n        if mean:\n            return torch.mean((pred - target) ** 2)\n        else:\n            return (pred - target) ** 2\n    else:\n        raise NotImplementedError(f'Loss type {self.loss_type} not implemented')\n\n", "CodeBleu_score": 34.485792790724815}]}
{"instance_id": "63a08283666f", "generation_result": [{"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    if self.learned_conditioning:\n        c = self.get_learned_conditioning(c)\n    x = self.get_time_embedding(x)\n    if self.learned_conditioning:\n        x = torch.cat([x, c], dim=1)\n    if self.use_timesteps:\n        t = torch.randint(0, self.num_timesteps, (x.shape[0],), device=x.device)\n        x = self.q_sample(x, t, *args, **kwargs)\n    else:\n        x = self.q_sample(x, *args, **kwargs)\n    x_start = self.q_sample(x, torch.tensor([0], device=x.device), *args, **kwargs)\n    x_end = self.q_sample(x, torch.tensor([self.num_timesteps - 1], device=x.device), *args, **kwargs)\n    return self.p_losses(x, x_start, x_end, c, *args, **kwargs)\n\n", "CodeBleu_score": 48.38456396364039}, {"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    # Select time steps\n    t = self.select_time_step(x)\n    # Apply learned conditioning\n    if self.learned_conditioning:\n        c = self.get_learned_conditioning(c, t)\n    # Process inputs\n    x = self.process_inputs(x, t)\n    # Compute loss\n    loss = self.compute_loss(x, c, t)\n    return loss\n\n", "CodeBleu_score": 9.574207893160175}, {"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    # Select time steps\n    if self.training:\n        # self.q_sample = torch.randint(0, self.num_timesteps, (x.shape[0],), device=x.device)\n        self.q_sample = torch.randint(0, self.num_timesteps, (x.shape[0],), device=x.device).long()\n    else:\n        self.q_sample = torch.full((x.shape[0],), self.num_timesteps - 1, device=x.device, dtype=torch.long)\n    # Get learned conditioning\n    c = self.get_learned_conditioning(c, self.q_sample)\n    # Process inputs\n    x = self.process_inputs(x, c, self.q_sample)\n    # Compute loss\n    loss = self.compute_loss(x, c, self.q_sample)\n    return loss\n\n", "CodeBleu_score": 41.87396141235116}]}
{"instance_id": "4627e1e8ed62", "generation_result": [{"code": "def get_codebook_entry(self, indices, shape)\n\t\n    indices = indices.view(-1)\n    z_q = self.embedding(indices)\n    if self.unmap_to_all:\n        z_q = z_q.reshape(indices.shape[0], shape[1], shape[2], shape[3])\n    else:\n        z_q = z_q.view(indices.shape[0], shape[1], shape[2], shape[3])\n    return z_q\n\n", "CodeBleu_score": 21.568637978124272}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    indices = indices.view(-1)\n    if self.remap_to_all:\n        indices = self.remap_indices(indices)\n    z_q = self.embedding(indices)\n    z_q = z_q.view(shape)\n    z_q = z_q.permute(0, 3, 1, 2)\n    return z_q\n\n", "CodeBleu_score": 40.99845277569371}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    z_q = self.embedding(indices)\n    if self.remap_to_all:\n        z_q = z_q.view(indices.shape[0], self.num_codebooks, self.num_codebook_vectors, *shape)\n        z_q = z_q.permute(0, 2, 1, 3)\n        z_q = z_q.reshape(indices.shape[0], self.num_codebooks * self.num_codebook_vectors, *shape)\n    else:\n        z_q = z_q.view(indices.shape[0], self.num_codebook_vectors, *shape)\n    return z_q\n\n", "CodeBleu_score": 38.874665174647184}]}
{"instance_id": "c55d014827ef", "generation_result": [{"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor > 0 and dimension % factor == 0:\n        return factor, dimension // factor\n    if factor < 0:\n        m = n = int(math.sqrt(dimension))\n        while m * n > dimension:\n            n -= 1\n            m = dimension // n\n        return m, n\n    raise ValueError(f\"Invalid factor: {factor}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 31.76926400790478}, {"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor > 0 and dimension % factor == 0:\n        return factor, dimension // factor\n    else:\n        m, n = 1, dimension\n        while m <= n and (factor < 0 or n <= factor):\n            m += 1\n            n = dimension // m\n        return m, n\n\n\n", "CodeBleu_score": 31.101008024986186}, {"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor > 0 and dimension % factor == 0:\n        return factor, dimension // factor\n    if factor <= 0:\n        factors = []\n        for i in range(1, int(dimension**0.5)+1):\n            if dimension % i == 0:\n                factors.append(i)\n                factors.append(dimension // i)\n        factors = sorted(factors)\n        for i in range(len(factors)-1):\n            if factors[i] <= factor and factors[i+1] >= factor:\n                return factors[i], factors[i+1]\n    return -1, -1\n\n\n", "CodeBleu_score": 30.235024307965762}]}
{"instance_id": "5d613ec26036", "generation_result": [{"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    if updown.device != orig_weight.device:\n        updown = updown.to(orig_weight.device)\n    if updown.dtype != orig_weight.dtype:\n        updown = updown.to(orig_weight.dtype)\n    if updown.shape != orig_weight.shape:\n        updown = updown.reshape(orig_weight.shape)\n    if updown.shape != orig_weight.shape:\n        updown = updown.transpose(orig_weight.shape)\n    if updown.shape != orig_weight.shape:\n        updown = updown.reshape(orig_weight.shape)\n    if updown.shape != orig_weight.shape:\n        updown = updown.transpose(orig_weight.shape)\n    if updown.shape != orig_weight.shape:\n        updown = updown.reshape(orig_weight.shape)\n    if updown.shape != orig_weight.shape:\n        updown = updown.transpose(orig_weight.shape)\n    if updown.shape != orig_weight.shape:\n        updown = updown.reshape(orig_weight.shape)\n    if updown.shape != orig_weight.shape:\n        updown = updown.transpose(orig_weight.shape)\n    if updown.shape != orig_weight.shape:\n        updown = updown.reshape(orig_weight.shape)\n    if updown.shape != orig_weight.shape:\n        updown = updown.transpose(orig_weight.shape)\n    if updown.shape != orig_weight.shape:\n        updown = updown.reshape(orig_weight.shape)\n    if updown.shape != orig_weight.shape:\n        updown = updown.transpose(orig_weight.shape)\n    if updown.shape != orig_weight.shape:\n        updown = updown.reshape(orig_weight.shape)\n    if updown.shape != orig_weight.shape:\n        updown = updown.transpose(orig_weight.shape", "CodeBleu_score": 19.921991349773627}, {"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    # Ensure tensors are on the same device and have the same data type\n    updown = updown.to(orig_weight.device).to(orig_weight.dtype)\n    orig_weight = orig_weight.to(updown.device).to(updown.dtype)\n\n    # Combine the input weight and original weight\n    combined_weight = updown + orig_weight\n\n    # Normalize the combined weight\n    norm = torch.norm(combined_weight)\n    normalized_weight = combined_weight / norm\n\n    # Scale the normalized weight using the predefined scale factor\n    scaled_weight = self.scale_factor * normalized_weight\n\n    # Calculate the final adjusted weight\n    adjusted_weight = scaled_weight - orig_weight\n\n    return adjusted_weight\n\n", "CodeBleu_score": 24.14106273718922}, {"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    updown = updown.to(orig_weight.device)\n    orig_weight = orig_weight.to(updown.device)\n    updown = updown.transpose(0, 1)\n    orig_weight = orig_weight.transpose(0, 1)\n    updown = updown.reshape(orig_weight.shape)\n    merged_scale1 = torch.cat((updown, orig_weight), dim=0)\n    merged_scale1 = merged_scale1.transpose(0, 1)\n    norm = torch.norm(merged_scale1, p=2, dim=0)\n    norm = torch.max(norm, torch.tensor(1e-6).to(norm.device))\n    norm = norm.reshape((1, -1))\n    merged_scale1 = merged_scale1 / norm\n    merged_scale1 = merged_scale1.transpose(0, 1)\n    merged_scale1 = merged_scale1.reshape(orig_weight.shape)\n    merged_scale1 = merged_scale1.to(torch.float32)\n    merged_scale1 = merged_scale1.to(orig_weight.device)\n    merged_scale1 = merged_scale1.transpose(0, 1)\n    merged_scale1 = merged_scale1.reshape(orig_weight.shape)\n    merged_scale1 = merged_scale1.to(torch.float32)\n    merged_scale1 = merged_scale1.to(orig_weight.device)\n    merged_scale1 = merged_scale1.transpose(0, 1)\n    merged_scale1 = merged_scale1.reshape(orig_weight.shape)\n    merged_scale1 = merged_scale1.to(torch.float32)\n    merged_scale1 = merged_scale1.to(orig_weight.device)\n    merged_scale1 = merged_scale1.transpose(0, 1)\n    merged_scale1 = merged_scale1.reshape(orig_weight.shape)\n    merged_scale1 = merged_scale1.to(torch.float32)", "CodeBleu_score": 21.64643278170081}]}
{"instance_id": "c73d0d1cd3e5", "generation_result": [{"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t\n    if ex_bias is not None:\n        updown = updown + ex_bias\n    if orig_weight.size == updown.size:\n        updown = updown.reshape(orig_weight.size())\n    else:\n        updown = updown.reshape(output_shape)\n    if self.multiplier is not None:\n        updown = updown * self.multiplier\n    if self.apply_weight_decompose:\n        updown = self.calc_scale(updown)\n    return updown, updown * self.multiplier\n\n", "CodeBleu_score": 41.96835702911106}, {"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t\n    if ex_bias is not None:\n        ex_bias = ex_bias.to(updown)\n        if ex_bias.numel() == orig_weight.numel():\n            ex_bias = ex_bias.reshape(orig_weight.shape)\n        elif ex_bias.numel() == updown.numel():\n            ex_bias = ex_bias.reshape(updown.shape)\n        else:\n            raise ValueError(\"Bias tensor must have the same number of elements as the original weight or the updown tensor.\")\n        updown = updown + ex_bias\n    if updown.numel() == orig_weight.numel():\n        updown = updown.reshape(orig_weight.shape)\n    elif updown.numel() == output_shape.numel():\n        updown = updown.reshape(output_shape)\n    else:\n        raise ValueError(\"Upscaled tensor must have the same number of elements as the original weight or the output shape.\")\n    if self.multiplier is not None:\n        updown = self.multiplier * updown\n    if self.apply_weight_decompose:\n        updown = self.calc_scale(updown, orig_weight)\n    return updown, ex_bias\n\n", "CodeBleu_score": 48.72945568217837}, {"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t\n    if ex_bias is not None:\n        updown = updown + ex_bias\n    if orig_weight.size() == updown.size():\n        updown = updown.reshape(output_shape)\n    else:\n        updown = updown.reshape(orig_weight.size())\n        updown = updown.reshape(output_shape)\n    if self.multiplier is not None:\n        updown = updown * self.multiplier\n    if self.apply_weight_decompose:\n        updown = self.calc_scale(updown)\n    if ex_bias is not None:\n        ex_bias = ex_bias * self.multiplier\n    return updown, ex_bias\n\n", "CodeBleu_score": 50.97265690597184}]}
{"instance_id": "c6a41665c62c", "generation_result": [{"code": "def calc_updown(self, orig_weight)\n\t\n    self.weight = self.weight.to(orig_weight.device)\n    if self.bias is not None:\n        self.bias = self.bias.to(orig_weight.device)\n    self.finalize_updown(orig_weight)\n    return self.weight\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.508635956434645}, {"code": "def calc_updown(self, orig_weight)\n\t\n    orig_weight = orig_weight.to(self.weight.device)\n    if self.bias is not None:\n        self.bias = self.bias.to(self.weight.device)\n    self.finalize_updown(orig_weight)\n    return self.weight\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.48626769899641}, {"code": "def calc_updown(self, orig_weight)\n\t\n    self.weight = self.weight.to(orig_weight.device)\n    self.bias = self.bias.to(orig_weight.device)\n    self.finalize_updown(orig_weight)\n    return self.weight\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 17.20948084836907}]}
{"instance_id": "1bb9e5d94af8", "generation_result": [{"code": "def purge_networks_from_memory()\n\t\n    networks_in_memory = devices.torch_gc.by_type(\"Network\")\n    if len(networks_in_memory) > devices.torch_gc.max_networks:\n        networks_to_remove = len(networks_in_memory) - devices.torch_gc.max_networks\n        for network in iter(networks_in_memory.values()):\n            if networks_to_remove == 0:\n                break\n            networks_in_memory.pop(network.id)\n            networks_to_remove -= 1\n        del networks_in_memory\n        gc.collect()\n\n", "CodeBleu_score": 37.00759840265699}, {"code": "def purge_networks_from_memory()\n\t\n    networks_in_memory = devices.torch_gc.by_type('Network')\n    len_networks_in_memory = len(networks_in_memory)\n    if len_networks_in_memory > devices.torch_gc.max_networks_in_memory:\n        for network in iter(networks_in_memory):\n            networks_in_memory.pop(network)\n            devices.torch_gc.collect()\n            if len(networks_in_memory) <= devices.torch_gc.max_networks_in_memory:\n                break\n    return", "CodeBleu_score": 37.56070267947349}, {"code": "def purge_networks_from_memory()\n\t\n    networks_in_memory = networks_in_memory.copy()\n    if len(networks_in_memory) > devices.torch_gc:\n        for network in iter(networks_in_memory):\n            networks_in_memory.pop(network)\n            if len(networks_in_memory) <= devices.torch_gc:\n                break\n        gc.collect()\n    return networks_in_memory", "CodeBleu_score": 35.39492507602454}]}
{"instance_id": "42b48ebf4d07", "generation_result": [{"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n    if hasattr(self, \"backup_weights\"):\n        self.weight.data = self.backup_weights.weight.data\n    if hasattr(self, \"backup_biases\"):\n        self.bias.data = self.backup_biases.bias.data\n    if isinstance(self, torch.nn.MultiheadAttention):\n        if hasattr(self, \"backup_projection_weights\"):\n            self.q_proj.weight.data = self.backup_projection_weights.q_proj.weight.data\n            self.k_proj.weight.data = self.backup_projection_weights.k_proj.weight.data\n            self.v_proj.weight.data = self.backup_projection_weights.v_proj.weight.data\n        if hasattr(self, \"backup_projection_biases\"):\n            self.q_proj.bias.data = self.backup_projection_biases.q_proj.bias.data\n            self.k_proj.bias.data = self.backup_projection_biases.k_proj.bias.data\n            self.v_proj.bias.data = self.backup_projection_biases.v_proj.bias.data\n    if hasattr(self, \"backup_bias\") and self.backup_bias is None:\n        self.bias = None\n\n", "CodeBleu_score": 39.3369209380438}, {"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n    if hasattr(self, \"weight_backup\"):\n        self.weight.data = self.weight_backup.data\n    if hasattr(self, \"bias_backup\"):\n        self.bias.data = self.bias_backup.data\n    if isinstance(self, torch.nn.MultiheadAttention):\n        if hasattr(self, \"projection_backup\"):\n            self.projection.weight.data = self.projection_backup.weight.data\n            self.projection.bias.data = self.projection_backup.bias.data\n        if hasattr(self, \"projection_backup_bias\"):\n            self.projection.bias.data = self.projection_backup_bias.data\n    return self\n\n", "CodeBleu_score": 33.55063532945735}, {"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n    if hasattr(self, \"backup_weights\"):\n        self.weight.data = copy_.deepcopy(self.backup_weights)\n        if hasattr(self, \"backup_bias\"):\n            self.bias.data = copy_.deepcopy(self.backup_bias)\n        elif hasattr(self, \"backup_bias\") and self.backup_bias is None:\n            self.bias = None\n    if isinstance(self, torch.nn.MultiheadAttention) and hasattr(self, \"backup_projection_weights\"):\n        self.k_proj.weight.data = copy_.deepcopy(self.backup_projection_weights)\n        self.v_proj.weight.data = copy_.deepcopy(self.backup_projection_weights)\n        self.q_proj.weight.data = copy_.deepcopy(self.backup_projection_weights)\n        if hasattr(self, \"backup_projection_bias\"):\n            self.k_proj.bias.data = copy_.deepcopy(self.backup_projection_bias)\n            self.v_proj.bias.data = copy_.deepcopy(self.backup_projection_bias)\n            self.q_proj.bias.data = copy_.deepcopy(self.backup_projection_bias)\n        elif hasattr(self, \"backup_projection_bias\") and self.backup_projection_bias is None:\n            self.k_proj.bias = None\n            self.v_proj.bias = None\n            self.q_proj.bias = None\n    return self", "CodeBleu_score": 36.645788158723455}]}
{"instance_id": "c8fcd357131a", "generation_result": [{"code": "def network_forward(org_module, input, original_forward)\n\t\n    if not hasattr(org_module, \"loaded_networks\"):\n        return original_forward(input)\n    if not hasattr(org_module, \"backup_weights\"):\n        org_module.backup_weights()\n    if not hasattr(org_module, \"cached_weight\"):\n        org_module.cached_weight = org_module.weight\n    if not hasattr(org_module, \"cached_bias\"):\n        org_module.cached_bias = org_module.bias\n    if not hasattr(org_module, \"cached_weight_grad\"):\n        org_module.cached_weight_grad = org_module.weight.grad\n    if not hasattr(org_module, \"cached_bias_grad\"):\n        org_module.cached_bias_grad = org_module.bias.grad\n    if not hasattr(org_module, \"cached_weight_grad_frozen\"):\n        org_module.cached_weight_grad_frozen = org_module.weight_grad_frozen\n    if not hasattr(org_module, \"cached_bias_grad_frozen\"):\n        org_module.cached_bias_grad_frozen = org_module.bias_grad_frozen\n    if not hasattr(org_module, \"cached_weight_frozen\"):\n        org_module.cached_weight_frozen = org_module.weight_frozen\n    if not hasattr(org_module, \"cached_bias_frozen\"):\n        org_module.cached_bias_frozen = org_module.bias_frozen\n    if not hasattr(org_module, \"cached_weight_cond\"):\n        org_module.cached_weight_cond = org_module.weight_cond\n    if not hasattr(org_module, \"cached_bias_cond\"):\n        org_module.cached_bias_cond = org_module.bias_cond\n    if not hasattr(org_module, \"cached_weight_", "CodeBleu_score": 22.347474524269224}, {"code": "def network_forward(org_module, input, original_forward)\n\t\n    # Check if any additional networks are loaded\n    if len(networks) == 0:\n        # If not, use the original forward method\n        return original_forward(input)\n    # Cast input to the appropriate device\n    input = devices.cond_cast_unet(input)\n    # Restore weights from backup and reset cached weight\n    network_restore_weights_from_backup()\n    network_reset_cached_weight()\n    # Call the original forward method\n    output = original_forward(input)\n    # Iterate over each loaded network\n    for network in networks:\n        # Check if the current layer matches the loaded network\n        if network.layer == org_module.layer:\n            # If it does, apply the network to the output\n            output = network.apply(output)\n    # Return the final output\n    return output\n\n\n", "CodeBleu_score": 29.224997471496067}, {"code": "def network_forward(org_module, input, original_forward)\n\t\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return original_forward(org_module, input)\n    if not hasattr(org_module, 'networks'):\n        return", "CodeBleu_score": 17.10601359603377}]}
{"instance_id": "1070211f5c11", "generation_result": [{"code": "def trainables(self)\n\t\n    trainables = []\n    for layer in self.layers:\n        if isinstance(layer, torch.nn.Linear) or isinstance(layer, torch.nn.LayerNorm):\n            trainables.extend(layer.parameters())\n    return trainables\n", "CodeBleu_score": 38.539893447997024}, {"code": "def trainables(self)\n\t\n    return [\n        param\n        for layer in self.layers\n        for name, param in layer.named_parameters()\n        if param.requires_grad\n    ]\n\n", "CodeBleu_score": 17.75766075121087}, {"code": "def trainables(self)\n\t\n    return [p for p in self.parameters() if p.requires_grad]", "CodeBleu_score": 6.452447410697191}]}
{"instance_id": "0c3ba62c96a7", "generation_result": [{"code": "def load_hypernetworks(names, multipliers=None)\n\t\n    already_loaded = load_hypernetworks_already_loaded()\n    clear_hypernetworks()\n    for i, name in enumerate(names):\n        if name in already_loaded:\n            hypernetwork = already_loaded[name]\n        else:\n            hypernetwork = load_hypernetwork(name)\n        if multipliers:\n            hypernetwork.set_multiplier(multipliers[i])\n        hypernetworks.append(hypernetwork)\n    return hypernetworks\n\n", "CodeBleu_score": 29.238304297199193}, {"code": "def load_hypernetworks(names, multipliers=None)\n\t\n    already_loaded = get_loaded_hypernetworks()\n    clear_loaded_hypernetworks()\n    for name, multiplier in zip(names, multipliers or [None] * len(names)):\n        hypernetwork = load_hypernetwork(name)\n        if multiplier is not None:\n            hypernetwork.set_multiplier(multiplier)\n        already_loaded.append(hypernetwork)\n    return already_loaded\n\n", "CodeBleu_score": 22.490542303269223}, {"code": "def load_hypernetworks(names, multipliers=None)\n\t\n    already_loaded = load_hypernetworks.already_loaded\n    already_loaded.get\n    hypernetwork.set_multiplier\n    enumerate\n\n", "CodeBleu_score": 2.5813810884134445}]}
{"instance_id": "bea3772ed532", "generation_result": [{"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k = context\n    context_v = context\n    for hypernetwork in hypernetworks:\n        context_k, context_v = apply_single_hypernetwork(hypernetwork, context_k, context_v, layer)\n    return context_k, context_v\n\n\n", "CodeBleu_score": 77.04946886953897}, {"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k = context\n    context_v = context\n    for hypernetwork in hypernetworks:\n        context_k, context_v = apply_single_hypernetwork(hypernetwork, context_k, context_v, layer)\n    return context_k, context_v", "CodeBleu_score": 77.04946886953897}, {"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k = context\n    context_v = context\n    for hypernetwork in hypernetworks:\n        context_k, context_v = apply_single_hypernetwork(hypernetwork, context_k, context_v, layer)\n    return context_k, context_v", "CodeBleu_score": 77.04946886953897}]}
{"instance_id": "922efa3e092f", "generation_result": [{"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    if context is None:\n        context = x\n    query = self.to_q(x)\n    key = self.to_k(context)\n    value = self.to_v(context)\n    context = self.apply_hypernetworks(context)\n    query = self.apply_hypernetworks(query)\n    query = query.reshape(query.shape[0], query.shape[1], self.heads, self.dim_head)\n    key = key.reshape(key.shape[0], key.shape[1], self.heads, self.dim_head)\n    value = value.reshape(value.shape[0], value.shape[1], self.heads, self.dim_head)\n    sim = torch.einsum('... i d, ... j d -> ... i j', query, key)\n    sim = sim * self.scale\n    if mask is not None:\n        sim = sim.masked_fill(mask == 0, -torch.finfo(sim.dtype).max)\n    attn = sim.softmax(dim=-1)\n    out = torch.einsum('... i j, ... j d -> ... i d', attn, value)\n    out = out.reshape(out.shape[0], out.shape[1], self.dim_head * self.heads)\n    out = self.to_out(out)\n    return out\n\n", "CodeBleu_score": 45.987056931338245}, {"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    if context is None:\n        context = x\n    query, key, value = self.to_q(x), self.to_k(context), self.to_v(context)\n    if self.context_dim is not None:\n        context = self.apply_hypernetworks(context)\n    query, key, value = map(lambda t: rearrange(t, \"b n (h d) -> b h n d\", h=self.heads), (query, key, value))\n    sim = einsum(\"b h i d, b h j d -> b h i j\", query, key) * self.scale\n    if mask is not None:\n        mask = rearrange(mask, \"b ... -> b 1 1 ...\")\n        sim = sim.masked_fill_(~mask, -torch.finfo(sim.dtype).max)\n    attn = sim.softmax(dim=-1)\n    out = einsum(\"b h i j, b h j d -> b h i d\", attn, value)\n    out = rearrange(out, \"b h n d -> b n (h d)\")\n    return self.to_out(out)\n\n", "CodeBleu_score": 53.44326541889121}, {"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    if context is None:\n        context = x\n    if self.to_q is not None:\n        query = self.to_q(x)\n    else:\n        query = x\n    if self.to_k is not None:\n        key = self.to_k(context)\n    else:\n        key = context\n    if self.to_v is not None:\n        value = self.to_v(context)\n    else:\n        value = context\n    if self.to_out is not None:\n        query = self.to_out(query)\n    if self.to_out is not None:\n        key = self.to_out(key)\n    if self.to_out is not None:\n        value = self.to_out(value)\n    if self.apply_hypernetworks:\n        query = self.apply_hypernetworks(query, 'query')\n        key = self.apply_hypernetworks(key, 'key')\n        value = self.apply_hypernetworks(value, 'value')\n    query = self.reshape_heads_to_batch_dim(query)\n    key = self.reshape_heads_to_batch_dim(key)\n    value = self.reshape_heads_to_batch_dim(value)\n    if mask is not None:\n        mask = mask.view(self.num_heads, -1, 1)\n    attention_scores = sim.einsum('bhqd,bhkd->bhqk', query, key)\n    attention_scores = attention_scores / math.sqrt(self.dim_heads)\n    if mask is not None:\n        attention_scores = sim.masked_fill_(attention_scores, mask, -1e9)\n    attention_probs = sim.softmax(attention_scores, dim=-1)\n    context = sim.einsum('bhal,bhlv->bhav', attention_probs, value)\n    context = self.reshape_batch_dim_to_heads(context)\n    if self.to_out is not None:\n        context = self.", "CodeBleu_score": 35.10019076735681}]}
{"instance_id": "8b7455a03a0e", "generation_result": [{"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t\n    original_attributes = {}\n    for attr in hypernetwork.__dict__:\n        if attr not in ['model', 'state_dict', 'checkpoint', 'checkpoint_dir', 'checkpoint_name', 'checkpoint_path', 'checkpoint_url', 'checkpoint_id', 'checkpoint_revision', 'checkpoint_branch', 'checkpoint_commit', 'checkpoint_message', 'checkpoint_author', 'checkpoint_date', 'checkpoint_author_email', 'checkpoint_author_url', 'checkpoint_committer', 'checkpoint_committer_email', 'checkpoint_committer_url', 'checkpoint_tree', 'checkpoint_distinct_size', 'checkpoint_size', 'checkpoint_submodule_count', 'checkpoint_file_count', 'checkpoint_commit_date', 'checkpoint_commit_time', 'checkpoint_commit_local_time', 'checkpoint_commit_timezone', 'checkpoint_commit_summary', 'checkpoint_commit_message', 'checkpoint_commit_message_full', 'checkpoint_commit_encoding', 'checkpoint_commit_author_name', 'checkpoint_commit_author_email', 'checkpoint_commit_author_date', 'checkpoint_commit_author_time', 'checkpoint_commit_author_timezone', 'checkpoint_commit_committer_name', 'checkpoint_commit_committer_email', 'checkpoint_commit_committer_date', 'checkpoint_commit_committer_time', 'checkpoint_commit_committer_timezone', 'checkpoint_commit_tree_id', 'checkpoint_commit_parent_ids', 'checkpoint_commit_trailers', 'checkpoint_commit_trailers_parsed', 'checkpoint_commit_trailers_raw', 'checkpoint_commit_gpgsig', 'checkpoint_commit_gpgsig_raw', 'checkpoint_commit_gpgsig_payload', 'checkpoint_commit_gpgsig_signature', 'checkpoint_commit_gpgsig_valid', 'checkpoint_commit_gpgsig_key_id', 'checkpoint_commit_gpgsig_is_valid', 'checkpoint_commit_gpgsig_is_", "CodeBleu_score": 15.478252557521358}, {"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t\n    original_attributes = {}\n    for attr in hypernetwork.state_dict():\n        original_attributes[attr] = getattr(hypernetwork, attr)\n\n    hypernetwork.load_state_dict(checkpoint[\"hypernetwork\"])\n    hypernetwork.name = hypernetwork_name\n\n    try:\n        torch.save(hypernetwork.state_dict(), filename)\n    except Exception as e:\n        for attr, value in original_attributes.items():\n            setattr(hypernetwork, attr, value)\n        raise e\n\n    for attr, value in original_attributes.items():\n        setattr(hypernetwork, attr, value)\n\n", "CodeBleu_score": 30.814420738679054}, {"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t\n    try:\n        original_checkpoint = hypernetwork.checkpoint\n        original_hypernetwork_name = hypernetwork.name\n        hypernetwork.checkpoint = checkpoint\n        hypernetwork.name = hypernetwork_name\n        hypernetwork.save(filename)\n    except Exception as e:\n        hypernetwork.checkpoint = original_checkpoint\n        hypernetwork.name = original_hypernetwork_name\n        raise e\n\n", "CodeBleu_score": 35.13890743045175}]}
{"instance_id": "3175f835140f", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if not self.ema_enabled:\n        return\n    if context is None:\n        context = {}\n    context['ema_enabled'] = True\n    self.store_parameters()\n    self.copy_ema_to_model()\n    if self.ema_log_switch:\n        self.logger.info('Switched to EMA weights.')\n    yield\n    self.restore_parameters()\n    if self.ema_log_switch:\n        self.logger.info('Restored model weights.')\n\n", "CodeBleu_score": 33.92035290006329}, {"code": "def ema_scope(self, context=None)\n\t\n    pass\n\n", "CodeBleu_score": 3.051106025934401}, {"code": "def ema_scope(self, context=None)\n\t\n    # pylint: disable=line-too-long\n    if context is None:\n        context = {}\n    if self.ema is None:\n        return\n    if self.ema.enabled:\n        self.ema.store()\n        self.ema.copy_to(self.model)\n        if self.ema.log_weights:\n            self.logger.log_weights(self.model, self.ema.name)\n    try:\n        yield\n    finally:\n        if self.ema.enabled:\n            self.ema.restore()\n            if self.ema.log_weights:\n                self.logger.log_weights(self.model, self.ema.name)\n\n", "CodeBleu_score": 45.03054640750143}]}
{"instance_id": "a7b5d5cd519a", "generation_result": [{"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    model_output = self.model(x, t)\n    assert model_output.shape == x.shape\n    if clip_denoised:\n        x_recon = x.clamp(-1., 1.)\n    else:\n        x_recon = self.x_recon(model_output, t)\n    assert x_recon.shape == x.shape\n\n    posterior_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n    assert posterior_mean.shape == x.shape\n    assert posterior_variance.shape == x.shape\n    assert posterior_log_variance.shape == x.shape\n    return posterior_mean, posterior_variance, posterior_log_variance\n\n", "CodeBleu_score": 49.79846182121168}, {"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    model_output = self.model(x, t)\n    if self.model_var_type in [\"learned\", \"learned_range\"]:\n        model_var, model_log_var = self.model_var(x, t, model_output)\n    else:\n        model_var, model_log_var = (\n            self.fixed_variance,\n            torch.zeros_like(x),\n        )\n    if self.predict_start_from_noise:\n        posterior_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n            x, t, model_output, model_var, model_log_var\n        )\n    else:\n        if self.x_recon_type == \"pred_x0\":\n            posterior_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n                x, t, model_output, model_var, model_log_var\n            )\n        elif self.x_recon_type == \"model_output\":\n            posterior_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n                model_output, t, model_output, model_var, model_log_var\n            )\n        elif self.x_recon_type == \"model_output_x0\":\n            posterior_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n                x, t, model_output, model_var, model_log_var\n            )\n        elif self.x_recon_type == \"model_output_x0_variance\":\n            posterior_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n                x, t, model_output, model_var, model_log_var\n            )\n        elif self.x_recon_type == \"model_output_x0_variance_clip\":\n            posterior_mean, posterior_variance, posterior_log_variance = self.q_posterior(\n                x, t, model_output, model_var, model_log_var\n            )\n        elif self.", "CodeBleu_score": 29.052464516652055}, {"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    B, C, H, W = x.shape\n    model_mean, _, model_var, _ = self.q_posterior(x, t)\n    model_var = model_var.reshape(B, C, H, W)\n    model_mean = model_mean.reshape(B, C, H, W)\n    model_var = model_var.reshape(B, C, H, W)\n    model_log_var = model_var.log()\n\n    if self.predict_start_from_noise:\n        noise = self.predict_start_from_noise(x, t)\n        x_recon = model_mean + noise\n    else:\n        x_recon = model_mean\n\n    if clip_denoised:\n        x_recon = x_recon.clamp(-1, 1)\n\n    return model_mean, model_var, model_log_var, x_recon\n\n", "CodeBleu_score": 28.48809522864013}]}
{"instance_id": "a8652fa78473", "generation_result": [{"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        if mean:\n            return torch.mean(torch.abs(pred - target))\n        else:\n            return torch.abs(pred - target)\n    elif self.loss_type == 'l2':\n        if mean:\n            return torch.mean((pred - target) ** 2)\n        else:\n            return (pred - target) ** 2\n    else:\n        raise NotImplementedError\n\n", "CodeBleu_score": 33.16912388958236}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='none')\n        if mean:\n            return torch.mean(loss)\n        else:\n            return loss\n    elif self.loss_type == 'l2':\n        return F.mse_loss(pred, target, reduction='none')\n    else:\n        raise NotImplementedError(f'{self.loss_type} loss not implemented')", "CodeBleu_score": 39.970381711044354}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == \"l1\":\n        if mean:\n            return torch.mean(torch.abs(pred - target))\n        else:\n            return torch.abs(pred - target)\n    elif self.loss_type == \"l2\":\n        if mean:\n            return torch.mean((pred - target) ** 2)\n        else:\n            return (pred - target) ** 2\n    else:\n        raise NotImplementedError(\"Unknown loss type: {}\".format(self.loss_type))\n\n", "CodeBleu_score": 30.939622174621324}]}
{"instance_id": "d68e4f061349", "generation_result": [{"code": "def _prior_bpd(self, x_start)\n\t\n    batch_size = x_start.shape[0]\n    t = torch.ones(batch_size, dtype=torch.long, device=x_start.device) * (self.num_timesteps - 1)\n    t = t.view(-1)\n    model_output = self.q_mean_variance(x_start, t)\n    mean, log_variance = model_output[:2]\n    bpd = normal_kl(mean, log_variance).sum(-1)\n    return bpd\n\n", "CodeBleu_score": 30.8033400554538}, {"code": "def _prior_bpd(self, x_start)\n\t\n    batch_size = x_start.shape[0]\n    t = torch.ones(batch_size, dtype=torch.long, device=x_start.device) * (self.num_timesteps - 1)\n    t = t.view(-1)\n    model_output = self.q_mean_variance(x_start, t)\n    mean, log_variance = model_output[:2]\n    bpd = normal_kl(mean, log_variance)\n    bpd *= self.num_timesteps\n    bpd /= np.log(2)\n    bpd /= x_start.shape[-1]\n    return bpd\n\n", "CodeBleu_score": 29.970798970554068}, {"code": "def _prior_bpd(self, x_start)\n\t\n    batch_size = x_start.shape[0]\n    t = torch.ones(batch_size, dtype=torch.long, device=x_start.device) * (self.num_timesteps - 1)\n    t = t.view(-1)\n    mean, log_variance = self.q_mean_variance(x_start, t)\n    mean_flat = mean.view(mean.shape[0], -1)\n    normal = Normal(0, 1)\n    log_prob = normal.log_prob(mean_flat).view(mean.shape[0], -1).sum(dim=-1)\n    log_prob = log_prob * self.num_dims\n    kl = log_prob - log_variance.sum(dim=-1)\n    bpd = -1.0 * kl / np.log(2.0)\n    return bpd\n\n", "CodeBleu_score": 33.70272767012529}]}
{"instance_id": "c695d93fdf2d", "generation_result": [{"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    cache_path = Path(CACHE_DIR) / subsection\n    cache_path.mkdir(parents=True, exist_ok=True)\n    cache = diskcache.Cache(\n        cache_path,\n        size_limit=4e9,\n        eviction_policy=\"least-recently-used\",\n        disk_min_file_size=256e3,\n    )\n    return cache\n\n", "CodeBleu_score": 44.76608325530431}, {"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    return diskcache.Cache(\n        path=os.path.join(CACHE_DIR, subsection),\n        size_limit=4e9,\n        eviction_policy=\"least-recently-used\",\n        eviction_ttl=120,\n        disk_min_file_size=256e3,\n    )", "CodeBleu_score": 53.039720384987966}, {"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    cache_dir = Path(f'{Path.home()}/.cache/pypi-cache/{subsection}')\n    cache_dir.mkdir(parents=True, exist_ok=True)\n    cache = diskcache.Cache(cache_dir, size_limit=4e9,\n                            disk_min_file_size=256e3)\n    return cache\n\n", "CodeBleu_score": 45.808236345297246}]}
{"instance_id": "ed4c543f0d38", "generation_result": [{"code": "def cache(subsection)\n\t\n    if subsection in caches:\n        return caches[subsection]\n    with cache_lock:\n        if subsection in caches:\n            return caches[subsection]\n        if not isdir(cache_dir):\n            os.makedirs(cache_dir)\n        if not isfile(cache_filename):\n            convert_old_cached_data()\n        caches[subsection] = make_cache(subsection)\n        return caches[subsection]\n\n", "CodeBleu_score": 39.84710579369401}, {"code": "def cache(subsection)\n\t\n    # First, try to get the cache object from the global caches dictionary\n    cache = caches.get(subsection)\n    if cache is not None:\n        return cache\n\n    # If the cache object is not found in the global caches dictionary, acquire a lock to ensure thread-safety\n    with cache_lock:\n        # Re-check the caches dictionary to ensure that another thread did not create the cache object in the meantime\n        cache = caches.get(subsection)\n        if cache is not None:\n            return cache\n\n        # If the cache object is still not found, create a new cache object and store it in the caches dictionary\n        cache = make_cache(subsection)\n        caches[subsection] = cache\n\n    return cache\n\n", "CodeBleu_score": 41.459975954049874}, {"code": "def cache(subsection)\n\t\n    global caches\n    global cache_lock\n    if subsection in caches:\n        return caches[subsection]\n    with cache_lock:\n        if subsection in caches:\n            return caches[subsection]\n        cache_dir = os.path.join(get_cache_dir(), subsection)\n        if not os.path.exists(cache_dir):\n            os.makedirs(cache_dir)\n        cache_filename = os.path.join(cache_dir, 'cache.json')\n        if not os.path.isfile(cache_filename):\n            convert_old_cached_data()\n        if subsection not in caches:\n            caches[subsection] = make_cache(subsection)\n        return caches[subsection]\n\n", "CodeBleu_score": 43.06008225651047}]}
{"instance_id": "ccf5ea2d9fc1", "generation_result": [{"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n    existing_cache = cache(subsection)\n    mtime = getmtime(filename)\n    if entry := existing_cache.get(title):\n        if entry.get(\"mtime\") < mtime:\n            existing_cache.pop(title)\n            existing_cache[title] = {\"mtime\": mtime, \"data\": func()}\n            dump_cache(existing_cache)\n        else:\n            return entry.get(\"data\")\n    else:\n        existing_cache[title] = {\"mtime\": mtime, \"data\": func()}\n        dump_cache(existing_cache)\n    return existing_cache[title].get(\"data\")", "CodeBleu_score": 32.461500578452714}, {"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n    existing_cache = cache(subsection)\n    mtime = getmtime(filename)\n    if existing_cache.has_key(title):\n        entry = existing_cache[title]\n        if entry.get('mtime') < mtime:\n            del existing_cache[title]\n    if not existing_cache.has_key(title):\n        data = func()\n        existing_cache[title] = {'mtime': mtime, 'data': data}\n        dump_cache(subsection, existing_cache)\n    return existing_cache[title]['data']\n\n", "CodeBleu_score": 33.36909816939658}, {"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n    cache = cache(subsection)\n    mtime = getmtime(filename)\n    entry = cache.get(title)\n    if entry:\n        if entry.get('mtime') < mtime:\n            cache.invalidate(title)\n            entry = None\n    if entry is None:\n        data = func()\n        cache[title] = {'data': data, 'mtime': mtime}\n        dump_cache(cache)\n    else:\n        data = entry['data']\n    return data", "CodeBleu_score": 37.424764738802224}]}
{"instance_id": "e01a2d4f0ac2", "generation_result": [{"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n    print(message.splitlines(), file=sys.stderr)\n    if exc_info:\n        print(textwrap.indent(traceback.format_exc(), \"    \"), file=sys.stderr)\n        print(\"---\", file=sys.stderr)", "CodeBleu_score": 60.783908885035984}, {"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n    for line in message.splitlines():\n        print(f\"*** {line}\", file=sys.stderr)\n    if exc_info:\n        print(textwrap.indent(traceback.format_exc(), \"    \"), file=sys.stderr)\n        print(\"---\", file=sys.stderr)", "CodeBleu_score": 70.73041784590174}, {"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n    for line in message.splitlines():\n        print(\"***\", line, file=sys.stderr)\n    if exc_info:\n        traceback.print_exc()\n        print(\"---\", file=sys.stderr)\n\n", "CodeBleu_score": 61.882585566291745}]}
{"instance_id": "125fb9d2320b", "generation_result": [{"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n    if style.prompt == \"\" and style.negative_prompt == \"\":\n        return False, prompt, negative_prompt\n\n    positive_prompt, negative_prompt = extract_style_text_from_prompt(\n        style, prompt, negative_prompt\n    )\n    if positive_prompt is None or negative_prompt is None:\n        return False, prompt, negative_prompt\n    return True, positive_prompt, negative_prompt\n\n", "CodeBleu_score": 45.24006725437274}, {"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n    if style.prompt == \"\" and style.negative_prompt == \"\":\n        return False, prompt, negative_prompt\n\n    positive_prompt, negative_prompt = extract_style_text(\n        style, prompt, negative_prompt\n    )\n\n    if positive_prompt is None or negative_prompt is None:\n        return False, prompt, negative_prompt\n\n    return True, positive_prompt, negative_prompt\n\n", "CodeBleu_score": 44.621706079316006}, {"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n    if style.prompt == \"\" and style.negative_prompt == \"\":\n        return False, prompt, negative_prompt\n\n    positive_prompt = extract_style_text_from_prompt(style.prompt, prompt)\n    if positive_prompt is False:\n        return False, prompt, negative_prompt\n\n    negative_prompt = extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n    if negative_prompt is False:\n        return False, prompt, negative_prompt\n\n    return True, positive_prompt, negative_prompt\n\n", "CodeBleu_score": 59.17710053299334}]}
{"instance_id": "0c5f729fbce2", "generation_result": [{"code": "def random_partial(self, count, n_frames)\n\t\n    if not self.utterances:\n        self._load_utterances()\n    utterances = self.utterance_cycler.sample(count)\n    return [(u, u.random_partial(n_frames)) for u in utterances]", "CodeBleu_score": 55.89879214825755}, {"code": "def random_partial(self, count, n_frames)\n\t\n    if not self._utterances:\n        self._load_utterances()\n    utterances = self.utterance_cycler.sample(count)\n    return [(u, u.random_partial(n_frames)) for u in utterances]\n\n\n", "CodeBleu_score": 55.7089248940014}, {"code": "def random_partial(self, count, n_frames)\n\t\n    if not self.utterances:\n        self._load_utterances()\n    utterances = self.utterance_cycler.sample(count)\n    return [(u, u.random_partial(n_frames)) for u in utterances]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 55.89879214825755}]}
{"instance_id": "31e8b27b8f94", "generation_result": [{"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"Both increase_only and decrease_only cannot be set to True.\")\n    if np.mean(wav) == 0:\n        return wav\n    rms = np.sqrt(np.mean(wav**2))\n    dBFS = 20 * np.log10(rms)\n    dB_change = target_dBFS - dBFS\n    if dB_change > 0 and increase_only:\n        return wav\n    if dB_change < 0 and decrease_only:\n        return wav\n    return wav * 10**(dB_change / 20)\n\n", "CodeBleu_score": 56.447927771068315}, {"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"Both increase_only and decrease_only cannot be True\")\n    dBFS_change = target_dBFS - 10 * np.log10(np.mean(wav ** 2))\n    if (dBFS_change < 0 and increase_only) or (dBFS_change > 0 and decrease_only):\n        return wav\n    return wav * 10 ** (dBFS_change / 20)\n\n", "CodeBleu_score": 86.51094668032061}, {"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"Both increase_only and decrease_only cannot be True.\")\n    if np.all(wav == 0):\n        return wav\n    rms = np.sqrt(np.mean(wav**2))\n    dBFS = 20 * np.log10(rms)\n    dBFS_change = target_dBFS - dBFS\n    if (dBFS_change < 0 and increase_only) or (dBFS_change > 0 and decrease_only):\n        return wav\n    return wav * 10**(dBFS_change / 20)\n\n", "CodeBleu_score": 67.69028566989368}]}
{"instance_id": "2353831e9033", "generation_result": [{"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    global _model\n    if device is None:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    _model = SpeakerEncoder(device=device)\n    _model.load_state_dict(torch.load(weights_fpath)[\"model_state\"])\n    _model.eval()\n    print(\"Loaded encoder \\\"{}\\\" trained to step {}\".format(weights_fpath.name, _model._step))\n\n", "CodeBleu_score": 45.44149546476825}, {"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    if device is None:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    _model = SpeakerEncoder(device=device)\n    _model.load_state_dict(torch.load(weights_fpath)[\"model_state\"])\n    _model.eval()\n    print(\"Loaded encoder \\\"{}\\\" trained to step {}\".format(weights_fpath.name, _model._step))\n    return _model\n\n", "CodeBleu_score": 44.60224223812041}, {"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    if device is None:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    _model = SpeakerEncoder(device=device)\n    _model.load_state_dict(torch.load(weights_fpath)[\"model_state\"])\n    _model.eval()\n    print(\"Loaded encoder \\\"{}\\\" trained to step {}\".format(\n        weights_fpath.name, _model._step))\n\n", "CodeBleu_score": 44.363295470093796}]}
{"instance_id": "3231ad480199", "generation_result": [{"code": "def embed_frames_batch(frames_batch)\n\t\n    if _model is None:\n        raise Exception(\"Model is not loaded\")\n    frames_batch = torch.from_numpy(frames_batch).to(_device)\n    embeddings = _model.forward(frames_batch).detach().cpu().numpy()\n    return embeddings\n\n", "CodeBleu_score": 69.92692359995954}, {"code": "def embed_frames_batch(frames_batch)\n\t\n    if _model is None:\n        raise Exception(\"Model not loaded\")\n    frames_batch = torch.from_numpy(frames_batch).to(_device)\n    embeddings = _model.forward(frames_batch)\n    embeddings = embeddings.detach().cpu().numpy()\n    return embeddings\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 65.19032465739761}, {"code": "def embed_frames_batch(frames_batch)\n\t\n    if _model is None:\n        raise Exception(\"Model not loaded\")\n    frames_batch = torch.from_numpy(frames_batch).to(_device)\n    embeddings = _model.forward(frames_batch).detach().cpu().numpy()\n    return embeddings\n\n", "CodeBleu_score": 69.77480336620489}]}
{"instance_id": "117a41716c8d", "generation_result": [{"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    assert 0 <= overlap < 1, 'Invalid value for overlap'\n    assert 0 <= min_pad_coverage < 1, 'Invalid value for min_pad_coverage'\n    assert partial_utterance_n_frames > 0, 'Invalid value for partial_utterance_n_frames'\n\n    # Compute how many frames will result in `partial_utterance_n_frames`\n    # when we frame signal with `frame_length` frames and `overlap` overlap\n    frame_length = int(np.ceil((n_samples - partial_utterance_n_frames) / (partial_utterance_n_frames * (1 - overlap))))\n    frame_step = int(frame_length * (1 - overlap))\n    n_frames_total = frame_length\n\n    # Padding to ensure we have at least `partial_utterance_n_frames`\n    # coverage\n    # TODO(Yifan): This can be removed when we get min_pad_coverage from\n    # config\n    pad_signal_length = int(\n        ((partial_utterance_n_frames - 1) * frame_step + frame_length)\n    )\n    z = np.zeros((pad_signal_length - n_samples,))\n\n    # Pad signal with zeros\n    pad_signal = np.append(raw_audio, z)\n    indices = np.tile(np.arange(0, frame_length),\n                      int(np.ceil(pad_signal_length / frame_length)))[:pad_signal_length]\n    pad_signal *= np.less(np.arange(pad_signal_length),\n                          indices).astype(np.float32)\n    pad_signal *= np.greater_equal(np.arange(pad_signal_length),\n                                   indices - n_frames_total).astype(np.float32)\n\n    # Compute frames\n    indices = np.reshape(np.arange(0, frame_length), [frame_length, 1])\n    indices_ = np.reshape(np.arange(0, n_frames_total), [1, n_frames_total])\n    frames", "CodeBleu_score": 31.80596814869437}, {"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    # Compute how many frames will result in `partial_utterance_n_frames` if we\n    # start at the beginning of the utterance.\n    start_frame = 0\n    first_slice_frames = partial_utterance_n_frames\n    first_slice_end_frame = start_frame + first_slice_frames\n    first_slice_end_sample = first_slice_end_frame * frame_step\n\n    # Padding needed if we end at the end of the utterance.\n    end_padding = max(0, first_slice_end_sample + frame_step - n_samples)\n\n    # Restrict padding to the range between 0 and `min_pad_coverage`.\n    end_padding = min(end_padding, n_samples * (1 - min_pad_coverage))\n\n    # Compute how many frames will result in `partial_utterance_n_frames` if we\n    # end at the end of the utterance.\n    end_frame = np.ceil(\n        (n_samples + end_padding) / frame_step).astype(np.int64)\n    last_slice_end_frame = end_frame\n    last_slice_frames = last_slice_end_frame - end_frame + partial_utterance_n_frames\n    last_slice_start_frame = last_slice_end_frame - last_slice_frames\n    last_slice_start_sample = last_slice_start_frame * frame_step\n\n    # Padding needed if we start at the beginning of the utterance.\n    start_padding = max(0, first_slice_start_sample)\n\n    # Restrict padding to the range between 0 and `min_pad_coverage`.\n    start_padding = min(start_padding, n_samples * (1 - min_pad_coverage))\n\n    # If necessary, add silence to the utterance at the beginning and end.\n    if start_padding != 0 or end_padding != 0:\n        silence_frames_count = np.ceil(start_padding / frame_step).astype(np.int64)\n        assert silence_frames_count + last_", "CodeBleu_score": 27.359215149343218}, {"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    assert 0 <= overlap < 1, 'Specify a valid overlap to compute {}% partial slices'.format(overlap * 100)\n    assert 0 <= min_pad_coverage < 1, 'Specify a valid min pad coverage to compute {}% partial slices'.format(min_pad_coverage * 100)\n\n    # Compute how many frames will be affected by the overlap\n    n_overlap_frames = int(np.ceil(overlap * partial_utterance_n_frames))\n\n    # Compute how many frames will be present in each partial utterance\n    frames_per_step = partial_utterance_n_frames - n_overlap_frames\n\n    # Compute how many steps will be needed for the computation\n    n_steps = int(np.ceil(len(wav) / frames_per_step))\n\n    # Compute the start and stop frames for each step\n    start_frames = np.tile(np.arange(0, frames_per_step * n_steps, frames_per_step),\n                           n_samples).astype(np.int)\n    stop_frames = start_frames + partial_utterance_n_frames\n    stop_frames[stop_frames > len(wav)] = len(wav)\n\n    # Compute the start and stop samples for each slice\n    start_samples = np.tile(np.arange(0, len(wav), frames_per_step),\n                            n_samples).astype(np.int)\n    stop_samples = start_samples + partial_utterance_n_frames * sr\n    stop_samples[stop_samples > len(wav)] = len(wav)\n\n    # Slice the wav and mel\n    wav_slices = [wav[start:stop] for start, stop in zip(start_samples, stop_samples)]\n    mel_slices = [mel[start:stop, :] for start, stop in zip(start_frames, stop_frames)]\n\n    # Check if we need to repeat the last partial utterance multiple times\n    # to cover the entire sample\n    n_pad_frames", "CodeBleu_score": 32.07466367825576}]}
{"instance_id": "34fe5c864f1c", "generation_result": [{"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n    if shape is None:\n        shape = (int(np.sqrt(len(embed))), int(np.sqrt(len(embed))))\n    embed = embed.reshape(shape)\n    im = ax.imshow(embed, cmap=\"RdBu\", vmin=color_range[0], vmax=color_range[1])\n    ax.set_title(title)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    plt.colorbar(im)\n    return im\n\n", "CodeBleu_score": 51.382477088763814}, {"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n    if shape is None:\n        shape = (int(np.sqrt(len(embed))), int(np.sqrt(len(embed))))\n    embed = embed.reshape(shape)\n    ax.imshow(embed, cmap=cm.get_cmap(\"hot\", 10))\n    sm = plt.cm.ScalarMappable(cmap=cm.get_cmap(\"hot\", 10), norm=plt.Normalize(vmin=color_range[0], vmax=color_range[1]))\n    sm.set_array([])\n    plt.colorbar(sm)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(title)\n\n", "CodeBleu_score": 58.441277336717626}, {"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n    if shape is None:\n        shape = (int(np.sqrt(len(embed))), int(np.sqrt(len(embed))))\n    assert len(embed) == shape[0] * shape[1]\n    reshaped_embed = embed.reshape(shape)\n    im = ax.imshow(reshaped_embed, cmap=cm.get_cmap('jet', 100))\n    plt.colorbar(im, ax=ax)\n    im.set_clim(color_range[0], color_range[1])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(title)\n    return ax\n\n", "CodeBleu_score": 50.59449058039465}]}
{"instance_id": "92e93d50b62b", "generation_result": [{"code": "def similarity_matrix(self, embeds)\n\t\n    num_speakers, num_utts = embeds.shape[0], embeds.shape[1]\n    centroids_incl = torch.zeros(num_speakers, self.dim_embed, device=self.device)\n    centroids_excl = torch.zeros(num_speakers, self.dim_embed, device=self.device)\n    mask = torch.eye(num_speakers, device=self.device)\n    sim_matrix = torch.zeros(num_speakers, num_speakers, device=self.device)\n    for speaker_idx in range(num_speakers):\n        centroids_incl[speaker_idx] = torch.mean(embeds[speaker_idx], dim=0)\n        centroids_excl[speaker_idx] = torch.mean(torch.cat((embeds[speaker_idx][:speaker_idx], embeds[speaker_idx][speaker_idx+1:]), dim=0), dim=0)\n    for speaker_idx in range(num_speakers):\n        sim_matrix[speaker_idx] = torch.norm(centroids_incl[speaker_idx] - centroids_excl, dim=1)\n    sim_matrix = sim_matrix * self.scale + self.bias\n    sim_matrix = sim_matrix * (1 - mask)\n    return sim_matrix\n\n", "CodeBleu_score": 30.016596012131973}, {"code": "def similarity_matrix(self, embeds)\n\t\n    num_speakers = embeds.shape[0]\n    num_utts = embeds.shape[1]\n    centroids_incl = torch.zeros(num_speakers, embeds.shape[2], device=self.device)\n    centroids_excl = torch.zeros(num_speakers, embeds.shape[2], device=self.device)\n    mask = torch.eye(num_speakers, device=self.device)\n    sim_mat = torch.zeros(num_speakers, num_speakers, device=self.device)\n    for i in range(num_speakers):\n        centroids_incl[i] = torch.mean(embeds[i], dim=0)\n        centroids_incl[i] /= torch.norm(centroids_incl[i])\n        centroids_excl[i] = torch.mean(embeds[~mask[i]], dim=0)\n        centroids_excl[i] /= torch.norm(centroids_excl[i])\n        sim_mat[i] = torch.norm(centroids_incl[i] - centroids_excl[i], dim=0)\n    sim_mat = sim_mat / torch.max(sim_mat)\n    sim_mat = sim_mat * 2 - 1\n    return sim_mat\n\n", "CodeBleu_score": 27.796745376125433}, {"code": "def similarity_matrix(self, embeds)\n\t\n    batch_size, num_speakers, num_utterances, _ = embeds.shape\n    num_speakers_per_batch = torch.tensor([num_speakers], device=embeds.device)\n    num_utterances_per_speaker = torch.tensor([num_utterances], device=embeds.device)\n    centroids_incl = torch.zeros((batch_size, num_speakers, embeds.shape[-1]), device=embeds.device)\n    centroids_excl = torch.zeros((batch_size, num_speakers, embeds.shape[-1]), device=embeds.device)\n    mask = torch.eye(num_speakers, device=embeds.device)\n    for i in range(num_speakers):\n        centroids_incl[:, i, :] = torch.mean(embeds[:, i, :, :], dim=1)\n        centroids_incl[:, i, :] /= torch.norm(centroids_incl[:, i, :], dim=1, keepdim=True)\n        centroids_excl[:, i, :] = torch.mean(embeds[:, torch.where(mask[:, i] == 0)[0], :, :], dim=1)\n        centroids_excl[:, i, :] /= torch.norm(centroids_excl[:, i, :], dim=1, keepdim=True)\n    similarity_matrix = torch.zeros((batch_size, num_speakers, num_speakers), device=embeds.device)\n    for i in range(num_speakers):\n        similarity_matrix[:, i, :] = torch.sum(embeds[:, i, :, :] * centroids_incl[:, i, :].unsqueeze(1), dim=2)\n        similarity_matrix[:, i, :] /= torch.norm(embeds[:, i, :, :], dim=2)\n        similarity_matrix[:, i, :] /= torch.norm(centroids_incl[:, i, :].unsqueeze", "CodeBleu_score": 29.133324837791925}]}
{"instance_id": "a6eba54108a1", "generation_result": [{"code": "def loss(self, embeds)\n\t\n\n    # Get the number of speakers and utterances per speaker from the shape of the input embeddings\n    num_speakers, num_utts_per_speaker = embeds.shape[0], embeds.shape[1]\n\n    # Compute the similarity matrix\n    sim_matrix = self.similarity_matrix(embeds)\n\n    # Reshape the similarity matrix to a 2D tensor\n    sim_matrix = sim_matrix.reshape(num_speakers, num_utts_per_speaker, -1)\n\n    # Compute the ground truth labels\n    labels = torch.from_numpy(\n        np.repeat(np.eye(num_utts_per_speaker), num_speakers, axis=0)\n    )\n\n    # Compute the loss\n    loss = self.loss_fn(sim_matrix, labels)\n\n    # Compute the EER\n    with torch.no_grad():\n        # Compute the predicted labels\n        preds = torch.argmax(sim_matrix, dim=2)\n        preds = preds.flatten()\n\n        # Compute the true labels\n        labels = labels.flatten()\n\n        # Compute the ROC curve\n        fpr, tpr, thresholds = roc_curve(labels.cpu().numpy(), preds.cpu().numpy())\n\n        # Find the threshold where the false positive rate equals the false negative rate\n        eer = brentq(lambda x: 1.0 - x - interp1d(fpr, tpr)(x), 0.0, 1.0)\n\n    return loss, eer\n\n", "CodeBleu_score": 41.06501124407084}, {"code": "def loss(self, embeds)\n\t\n    num_speakers, num_utts_per_speaker = embeds.shape[0], embeds.shape[1]\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape((-1, num_speakers))\n    labels = torch.from_numpy(\n        np.repeat(np.arange(num_speakers), num_utts_per_speaker)\n    ).long()\n    if torch.cuda.is_available():\n        labels = labels.cuda()\n    with torch.no_grad():\n        preds = torch.argmax(sim_matrix, dim=1)\n        preds = inv_argmax(preds)\n        labels = inv_argmax(labels)\n        fpr, tpr, thresholds = roc_curve(labels, preds, pos_label=1)\n        eer = brentq(lambda x: 1.0 - x - interp1d(fpr, tpr)(x), 0.0, 1.0)\n    loss = self.loss_fn(sim_matrix, labels)\n    return loss, eer\n\n", "CodeBleu_score": 42.11473579824761}, {"code": "def loss(self, embeds)\n\t\n    num_speakers = embeds.shape[0]\n    num_utterances = embeds.shape[1]\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape(num_speakers, num_utterances, -1)\n    sim_matrix = sim_matrix.detach().cpu().numpy()\n    labels = np.repeat(np.arange(num_speakers), num_utterances)\n    labels = torch.from_numpy(labels).long().to(self.device)\n    labels = labels.flatten()\n    with torch.no_grad():\n        loss = self.loss_fn(sim_matrix, labels)\n        preds = inv_argmax(sim_matrix)\n        preds = preds.flatten()\n        fpr, tpr, thresholds = roc_curve(labels.cpu(), preds.cpu(), pos_label=1)\n        eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n    return loss, eer\n\n", "CodeBleu_score": 45.189669730342715}]}
{"instance_id": "ac7b74b9d1b1", "generation_result": [{"code": "def log_params(self)\n\t\n    if self.log_params:\n        from prettytable import PrettyTable\n        from IPython.display import display\n        model_params = PrettyTable()\n        model_params.field_names = [\"Name\", \"Value\"]\n        model_params.align = \"l\"\n        model_params.title = \"Model Parameters\"\n        for name, value in self.model.named_parameters():\n            model_params.add_row([name, value])\n        display(model_params)\n        data_params = PrettyTable()\n        data_params.field_names = [\"Name\", \"Value\"]\n        data_params.align = \"l\"\n        data_params.title = \"Data Parameters\"\n        for name, value in self.data.named_parameters():\n            data_params.add_row([name, value])\n        display(data_params)\n\n", "CodeBleu_score": 26.543334492007975}, {"code": "def log_params(self)\n\t\n    if not self.disable_params:\n        params = {}\n        params[\"model\"] = {}\n        params[\"data\"] = {}\n        params[\"model\"][\"name\"] = self.model.name\n        params[\"model\"][\"params\"] = {}\n        params[\"data\"][\"name\"] = self.data.name\n        params[\"data\"][\"params\"] = {}\n        for name, param in self.model.named_parameters():\n            params[\"model\"][\"params\"][name] = param.data.cpu().numpy().tolist()\n        for name, param in self.data.named_parameters():\n            params[\"data\"][\"params\"][name] = param.data.cpu().numpy().tolist()\n        params_str = json.dumps(params, indent=4)\n        print(params_str)\n        print(f\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 23.16869486380205}, {"code": "def log_params(self)\n\t\n    import inspect\n    import textwrap\n    import os\n    import logging\n    import sys\n\n    logger = logging.getLogger(__name__)\n    logger.setLevel(logging.INFO)\n\n    # create a file handler\n    handler = logging.FileHandler('parameters.log')\n    handler.setLevel(logging.INFO)\n\n    # create a logging format\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler.setFormatter(formatter)\n\n    # add the handler to the logger\n    logger.addHandler(handler)\n\n    # import parameter configurations\n    import config\n\n    # iterate through model and data parameters\n    for param_name, param_value in inspect.getmembers(config.model_params):\n        if not param_name.startswith('__'):\n            logger.info(f\"{param_name}: {param_value}\")\n\n    for param_name, param_value in inspect.getmembers(config.data_params):\n        if not param_name.startswith('__'):\n            logger.info(f\"{param_name}: {param_value}\")\n\n    logger.info(\"Parameters logged successfully.\")\n\n", "CodeBleu_score": 26.004366131157102}]}
{"instance_id": "4726b7864386", "generation_result": [{"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    if len(embeds) > max_speakers:\n        embeds = embeds[:max_speakers]\n    embeds = np.concatenate(embeds, axis=0)\n    embeds = np.repeat(embeds, utterances_per_speaker, axis=0)\n    speaker_ids = np.repeat(np.arange(len(embeds) // utterances_per_speaker), utterances_per_speaker)\n    reducer = umap.UMAP(random_state=42)\n    projections = reducer.fit_transform(embeds)\n    plt.clf()\n    plt.scatter(projections[:, 0], projections[:, 1], c=speaker_ids, cmap=\"hsv\")\n    plt.gca().set_aspect(\"equal\", \"datalim\")\n    plt.title(f\"Speaker projections at step {step}\")\n    plt.colorbar(boundaries=np.arange(len(embeds) + 1) - 0.5).set_ticks(np.arange(len(embeds)))\n    if out_fpath is not None:\n        plt.savefig(out_fpath)\n    else:\n        plt.show(block=False)\n\n", "CodeBleu_score": 45.55831488076403}, {"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    if embeds.shape[0] > max_speakers:\n        embeds = embeds[:max_speakers]\n    embeds = embeds.reshape(embeds.shape[0] * embeds.shape[1], embeds.shape[2])\n    labels = np.repeat(np.arange(embeds.shape[0]), utterances_per_speaker)\n    reducer = umap.UMAP(n_components=2, random_state=0)\n    projections = reducer.fit_transform(embeds)\n    plt.scatter(projections[:, 0], projections[:, 1], c=labels, cmap=\"Spectral\", s=5)\n    plt.gca().set_aspect(\"equal\", \"datalim\")\n    plt.title(f\"Speaker embeddings at step {step}\")\n    if out_fpath:\n        plt.savefig(out_fpath)\n        plt.clf()\n    else:\n        plt.show(block=False)\n        plt.pause(0.01)\n        plt.clf()\n\n", "CodeBleu_score": 30.913594177144283}, {"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    if self.speaker_embedding_visualization_disabled:\n        return\n    if len(embeds) > max_speakers:\n        embeds = embeds[:max_speakers]\n    embeds = np.repeat(embeds, utterances_per_speaker, axis=0)\n    embeds = reducer.fit_transform(embeds)\n    plt.clf()\n    plt.scatter(embeds[:, 0], embeds[:, 1], c=np.arange(len(embeds)), cmap='hsv')\n    plt.gca().set_aspect('equal', 'datalim')\n    plt.title(f'Speaker embeddings projection at step {step}')\n    if out_fpath:\n        plt.savefig(out_fpath)\n    else:\n        plt.show()\n\n", "CodeBleu_score": 32.91350776106386}]}
{"instance_id": "274fa50985c0", "generation_result": [{"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    # Save the dimensions of the input tensor as human-readable names\n    x_size = x.size()\n    speaker_embedding_size = speaker_embedding.size()\n\n    # Determine the appropriate dimension index for the speaker embedding\n    if len(x_size) == 3:\n        speaker_embedding_dim = 2\n    elif len(x_size) == 4:\n        speaker_embedding_dim = 3\n    else:\n        raise ValueError(\"Invalid input tensor shape\")\n\n    # Repeat the speaker embedding to match the length of the input text\n    speaker_embedding = speaker_embedding.repeat_interleave(x_size[speaker_embedding_dim], dim=speaker_embedding_dim)\n\n    # Reshape and transpose the speaker embedding\n    speaker_embedding = speaker_embedding.reshape(x_size[0], x_size[1], -1)\n    speaker_embedding = speaker_embedding.transpose(1, speaker_embedding_dim)\n\n    # Concatenate the speaker embedding with the input tensor\n    x = torch.cat([x, speaker_embedding], dim=-1)\n\n    return x\n\n", "CodeBleu_score": 32.761841946612186}, {"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    x_size = x.size()\n    speaker_embedding_dim = speaker_embedding.size()[-1]\n    speaker_embedding_index = x_size.index(speaker_embedding_dim)\n    speaker_embedding = speaker_embedding.repeat_interleave(x_size[speaker_embedding_index], dim=speaker_embedding_index)\n    speaker_embedding = speaker_embedding.reshape(*x_size[:speaker_embedding_index], *x_size[speaker_embedding_index + 1:], -1)\n    speaker_embedding = speaker_embedding.transpose(speaker_embedding_index, -1)\n    return torch.cat([x, speaker_embedding], dim=-1)\n\n", "CodeBleu_score": 15.70414544474494}, {"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    original_shape = x.size()\n    speaker_embedding_dim = speaker_embedding.size(-1)\n    speaker_embedding = speaker_embedding.repeat_interleave(original_shape[speaker_embedding.dim], dim=speaker_embedding.dim)\n    speaker_embedding = speaker_embedding.reshape(*original_shape[:-1], speaker_embedding_dim)\n    speaker_embedding = speaker_embedding.transpose(speaker_embedding.dim, -1)\n    return torch.cat([x, speaker_embedding], dim=-1)", "CodeBleu_score": 20.140239313329978}]}
{"instance_id": "e6742ea0fe5e", "generation_result": [{"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = next(self.parameters()).device\n    batch_size, seq_len, _ = encoder_seq_proj.size()\n    self.cum_attn = torch.zeros(batch_size, seq_len, device=device)\n    self.attn = torch.zeros(batch_size, seq_len, device=device)\n\n", "CodeBleu_score": 24.39409957346545}, {"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = self.parameters.device\n    batch_size, seq_len = encoder_seq_proj.size()\n    self.cum_attn = torch.zeros(batch_size, seq_len, device=device)\n    self.attn = torch.zeros(batch_size, seq_len, device=device)\n\n", "CodeBleu_score": 22.488937734896567}, {"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = self.parameters().device\n    batch_size, seq_len, _ = encoder_seq_proj.size()\n    self.cum_attn = torch.zeros(batch_size, seq_len, device=device)\n    self.attn = torch.zeros(batch_size, seq_len, device=device)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 22.882643082191017}]}
{"instance_id": "4e1fc1ed0ed7", "generation_result": [{"code": "def load(self, path, optimizer=None)\n\t\n    device = self.parameters().device\n    checkpoint = torch.load(path, map_location=device)\n    self.load_state_dict(checkpoint[\"model_state\"])\n    if optimizer is not None and \"optimizer_state\" in checkpoint:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n\n", "CodeBleu_score": 40.30745704686687}, {"code": "def load(self, path, optimizer=None)\n\t\n    self.to(self.parameters().device)\n    checkpoint = torch.load(path, map_location=self.parameters().device)\n    self.load_state_dict(checkpoint[\"model_state_dict\"])\n    if optimizer is not None and \"optimizer_state_dict\" in checkpoint:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n\n", "CodeBleu_score": 47.00568246850464}, {"code": "def load(self, path, optimizer=None)\n\t\n    self.to(self.device)\n    checkpoint = torch.load(path, map_location=self.device)\n    self.load_state_dict(checkpoint[\"state_dict\"])\n    if optimizer is not None and \"optimizer\" in checkpoint:\n        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n\n", "CodeBleu_score": 42.077435570679796}]}
{"instance_id": "178e6aa16c0f", "generation_result": [{"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer:\n        torch.save({\n            'model_state_dict': self.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict()\n        }, path)\n    else:\n        torch.save(self.state_dict(), path)\n\n", "CodeBleu_score": 55.26145593616825}, {"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is not None:\n        torch.save({\n            'model_state_dict': self.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict()\n        }, path)\n    else:\n        torch.save(self.state_dict(), path)\n\n", "CodeBleu_score": 63.81618480133533}, {"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is None:\n        torch.save(self.state_dict(), path)\n    else:\n        torch.save({\n            'model_state_dict': self.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict()\n        }, path)\n\n", "CodeBleu_score": 57.651555886258265}]}
{"instance_id": "6528fd80e87b", "generation_result": [{"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n\n", "CodeBleu_score": 55.88611500274403}, {"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n\n", "CodeBleu_score": 55.88611500274403}, {"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n\n", "CodeBleu_score": 55.88611500274403}]}
{"instance_id": "8a4fe08e0985", "generation_result": [{"code": "def text_to_sequence(text, cleaner_names)\n\t\n    sequence = []\n    for cleaner_name in cleaner_names:\n        if cleaner_name == 'english_cleaners':\n            sequence += _clean_text(text, _curly_re, _cleaners)\n        elif cleaner_name == 'transliteration_cleaners':\n            sequence += _clean_text(text, _curly_re, _trans_cleaners)\n        elif cleaner_name == 'korean_cleaners':\n            sequence += _clean_text(text, _curly_re, _kor_cleaners)\n        elif cleaner_name == 'basic_cleaners':\n            sequence += _clean_text(text, _curly_re, _basic_cleaners)\n        else:\n            raise Exception('Unknown cleaner: %s' % cleaner_name)\n    sequence = _arpabet_to_sequence(sequence)\n    sequence = _symbols_to_sequence(sequence)\n    sequence.append(_eos_id)\n    return sequence\n\n", "CodeBleu_score": 25.797550515537885}, {"code": "def text_to_sequence(text, cleaner_names)\n\t\n    sequence = []\n\n    # Check for curly braces and treat their contents as ARPAbet:\n    while len(text):\n        m = _curly_re.match(text)\n        if not m:\n            sequence += _clean_text(text, cleaner_names)\n            break\n        sequence += _clean_text(m.group(1), cleaner_names)\n        sequence += _arpabet_to_sequence(m.group(2))\n        text = m.group(3)\n\n    # Append EOS token\n    sequence.append(_symbols_to_sequence(\"<EOS>\"))\n    return sequence\n", "CodeBleu_score": 61.851710679471296}, {"code": "def text_to_sequence(text, cleaner_names)\n\t\n    sequence = []\n    for cleaner_name in cleaner_names:\n        sequence.extend(cleaners[cleaner_name](text))\n    sequence.append(symbols.eos_id)\n    return sequence\n\n", "CodeBleu_score": 12.691617552690715}]}
{"instance_id": "e1c25a37af1f", "generation_result": [{"code": "def sequence_to_text(sequence)\n\t\n    result = []\n    for symbol_id in sequence:\n        if symbol_id in _arpabet:\n            result.append(\"{%s}\" % _arpabet[symbol_id])\n        else:\n            result.append(_symbol_to_id[symbol_id])\n    result = \" \".join(result)\n    result = result.replace(\"}{\", \" \")\n    return result\n\n", "CodeBleu_score": 42.397505435502524}, {"code": "def sequence_to_text(sequence)\n\t\n    result = ''\n    for symbol_id in sequence:\n        if symbol_id in _arpabet:\n            result += _arpabet[symbol_id] + ' '\n        else:\n            result += symbol_id + ' '\n    result = result.strip()\n    return result\n\n", "CodeBleu_score": 32.73472599300341}, {"code": "def sequence_to_text(sequence)\n\t\n    result = ''\n    for symbol_id in sequence:\n        if symbol_id in _symbol_to_id:\n            s = _symbol_to_id[symbol_id]\n            # Enclose ARPAbet symbols in curly braces\n            if len(s) > 1 and s[0] == '@':\n                s = '{%s}' % s[1:]\n            result += s + ' '\n    return result.strip()\n\n", "CodeBleu_score": 57.92824468542205}]}
{"instance_id": "7807cad4b05d", "generation_result": [{"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded:\n        encoder.load_model(encoder_model_fpath)\n\n    wav_fpath = fpaths[0]\n    wav = encoder.preprocess_wav(wav_fpath)\n    embed = encoder.embed_utterance(wav)\n    np.save(fpaths[1], embed)\n\n", "CodeBleu_score": 48.82457614416186}, {"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    wav_fpath = fpaths[0]\n    wav = encoder.preprocess_wav(wav_fpath)\n    embed = encoder.embed_utterance(wav)\n    np.save(fpaths[1], embed)\n\n", "CodeBleu_score": 54.31808253273586}, {"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded:\n        encoder.load_model(encoder_model_fpath)\n    wav_fpaths = [fpath for fpath in fpaths if \".wav\" in fpath]\n    if len(wav_fpaths) == 0:\n        raise Exception(\"No wav file found for the given fpaths: {}\".format(fpaths))\n    wav_fpath = wav_fpaths[0]\n    wav = encoder.preprocess_wav(wav_fpath)\n    embed = encoder.embed_utterance(wav)\n    return embed\n\n", "CodeBleu_score": 44.47556669633757}]}
{"instance_id": "9f860273a325", "generation_result": [{"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    # Check that encoder model is provided\n    if not encoder_model_fpath.exists():\n        raise Exception(\"Encoder model not found\")\n\n    # Check that input directories exist\n    if not synthesizer_root.exists():\n        raise Exception(\"Synthesizer root directory does not exist\")\n\n    # Get the list of audio files\n    wav_dir = synthesizer_root.joinpath(\"wavs\")\n    if not wav_dir.exists():\n        raise Exception(\"wav files not found in {}\".format(wav_dir))\n    wav_fpaths = list(wav_dir.glob((\"*.wav\")))\n    if len(wav_fpaths) == 0:\n        raise Exception(\"no wav files found in {}\".format(wav_dir))\n\n    # Create the embedding output directory if it doesn't exist\n    embed_dir = synthesizer_root.joinpath(\"embeds\")\n    if not embed_dir.exists():\n        embed_dir.mkdir(parents=True)\n\n    # Create a metadata file\n    metadata_fpath = synthesizer_root.joinpath(\"train.txt\")\n    if not metadata_fpath.exists():\n        write_metadata(metadata_fpath, wav_fpaths)\n\n    # We use ProcessPoolExecutor to parallelize across all CPUs\n    executor = ProcessPoolExecutor(max_workers=n_processes)\n    futures = []\n    index = 1\n\n    # Process the group of files that are currently being read from the disk\n    # This is a generator - it reads the audio files on the fly\n    def embed_utterance(wav_fpath):\n        return compute_embedding(wav_fpath, encoder_model_fpath)\n\n    for wav_fpath in wav_fpaths:\n        futures.append(executor.submit(embed_utterance, wav_fpath))\n        index += 1\n\n    # Wait for the jobs to complete. This is a blocking operation.\n    # noinspection PyUnusedLocal\n    for future in tqdm(as_completed(futures), total=len(futures), unit=", "CodeBleu_score": 38.59479281022004}, {"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    # Check if input directories and files exist\n    if not encoder_model_fpath.exists():\n        raise Exception(\"Encoder model not found\")\n    if not synthesizer_root.exists():\n        raise Exception(\"synthesizer root not found\")\n    if not synthesizer_root.joinpath(\"train.txt\").exists():\n        raise Exception(\"train.txt not found\")\n    if not synthesizer_root.joinpath(\"valid.txt\").exists():\n        raise Exception(\"valid.txt not found\")\n    if not synthesizer_root.joinpath(\"test.txt\").exists():\n        raise Exception(\"test.txt not found\")\n    if not synthesizer_root.joinpath(\"wavs\").exists():\n        raise Exception(\"wavs not found\")\n\n    # Get the paths to the audio files\n    wav_dir = synthesizer_root.joinpath(\"wavs\")\n    wav_fpaths = list(wav_dir.glob(\"**/*.wav\"))\n    if len(wav_fpaths) == 0:\n        raise Exception(\"No wav files found in {}\".format(wav_dir))\n\n    # Create output directory for embeddings\n    embed_dir = synthesizer_root.joinpath(\"embeds\")\n    embed_dir.mkdir(exist_ok=True)\n\n    # Create a pool of workers to process the audio files\n    pool = Pool(n_processes)\n\n    # Iterate over the audio files and generate embeddings for each one\n    for wav_fpath in tqdm(wav_fpaths):\n        # Get the corresponding embedding file path\n        embed_fpath = embed_dir.joinpath(wav_fpath.name.replace(\".wav\", \".npy\"))\n\n        # If the embedding file already exists, skip it\n        if embed_fpath.exists():\n            continue\n\n        # Load the audio file\n        wav = load_wav(wav_fpath)\n\n        # Generate the embedding using the encoder model\n        embed = encoder.embed_utterance(wav)\n\n        # Save the embedding to the corresponding file path\n        np.save(embed_fpath, embed,", "CodeBleu_score": 34.21079796772218}, {"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    # Check if encoder model file exists\n    if not encoder_model_fpath.exists():\n        raise Exception(\n            \"Encoder model file does not exist at path: {}\".format(encoder_model_fpath))\n\n    # Check if wav directory exists\n    wav_dir = synthesizer_root.joinpath(\"wavs\")\n    if not wav_dir.exists():\n        raise Exception(\n            \"Directory of wav files does not exist at path: {}\".format(wav_dir))\n\n    # Check if embeddings directory exists\n    embed_dir = synthesizer_root.joinpath(\"embeds\")\n    if not embed_dir.exists():\n        embed_dir.mkdir(parents=True)\n\n    # Get list of audio file names\n    wav_fnames = [fname for fname in wav_dir.listdir() if fname.endswith(\".wav\")]\n\n    # Create a multiprocessing pool and process each audio file\n    # in the wav directory with the encoder\n    with Pool(n_processes) as pool:\n        list(tqdm(pool.imap(partial(_process_wav, encoder_model_fpath=encoder_model_fpath,\n                                    embed_dir=embed_dir), wav_fnames), total=len(wav_fnames), file=sys.stdout))\n\n", "CodeBleu_score": 36.860405363925466}]}
{"instance_id": "9eb0abda14a9", "generation_result": [{"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n    attention_plot = attention.cpu().data.numpy()\n    mel_prediction = mel_prediction.cpu().data.numpy()\n    target_spectrogram = target_spectrogram.cpu().data.numpy()\n\n    # Save attention plot\n    plot_attention(attention_plot, plot_dir, step, sample_num)\n\n    # Save predicted mel spectrogram\n    np.save(mel_output_dir.joinpath(\n        f\"step_{step}_sample_{sample_num}_mel_prediction.npy\"), mel_prediction)\n\n    # Reconstruct waveform\n    audio.inv_mel_spectrogram(mel_prediction, hparams)\n\n    # Save reconstructed waveform\n    audio.save_wav(mel_prediction, wav_dir.joinpath(\n        f\"step_{step}_sample_{sample_num}_mel_prediction.wav\"), hparams)\n\n    # Plot predicted and target mel spectrograms\n    plot_spectrogram(mel_prediction, target_spectrogram,\n                     f\"step_{step}_sample_{sample_num}_mel_prediction.png\", plot_dir)\n\n    # Print input sequence\n    print(sequence_to_text(input_seq))\n\n    # Print loss\n    print(f\"Loss: {loss.item()}\")\n\n    # Print current time\n    print(f\"Current time: {time_string()}\")\n\n    # Print model type\n    print(f\"Model type: {hparams.model_type}\")\n\n    # Print step number\n    print(f\"Step number: {step}\")\n\n    # Print sample number\n    print(f\"Sample number: {sample_num}\")\n\n    # Print loss\n    print(f\"Loss: {loss.item()}\")\n\n    # Print current time\n    print(f\"Current time: {time_string()}\")\n\n    # Print model type\n    print(f\"Model type: {hparams.model_type}\")\n\n    # Print step number\n    print(f\"Step number: {step}\")\n\n    # Print sample number\n    print(f", "CodeBleu_score": 29.79212462087063}, {"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n    # Save attention plot\n    plot_attention(attention, step, plot_dir)\n\n    # Save predicted mel spectrogram\n    mel_prediction = mel_prediction.squeeze().cpu().numpy()\n    np.save(mel_output_dir.joinpath(f\"mel_prediction_{sample_num}.npy\"), mel_prediction)\n\n    # Save reconstructed waveform\n    audio.save_wav(mel_prediction, wav_dir.joinpath(f\"mel_prediction_{sample_num}.wav\"))\n\n    # Generate and save plot comparing predicted and target mel spectrograms\n    plot_spectrogram(target_spectrogram, mel_prediction, step, plot_dir,\n                     f\"{hparams.model_type}_step_{step}_loss_{loss:.4f}\")\n\n    # Print input sequence\n    print(f\"Input sequence at step {step}: {sequence_to_text(input_seq)}\")\n\n", "CodeBleu_score": 18.57986064607366}, {"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n    # Save attention plot\n    attention = attention.cpu().data.numpy()\n    plot_attention(attention, step, sample_num, plot_dir)\n\n    # Save predicted mel spectrogram\n    mel_prediction = mel_prediction.cpu().data.numpy()\n    np.save(mel_output_dir.joinpath(f\"{sample_num}-{step}-predicted-mel-spectrogram.npy\"), mel_prediction)\n\n    # Save reconstructed waveform\n    target_spectrogram = target_spectrogram.cpu().data.numpy()\n    audio.inv_mel_spectrogram(mel_prediction, hparams.outputs_per_step,\n                              hparams.output_sample_rate,\n                              hparams.mel_spectrogram_config.mel_fmin,\n                              hparams.mel_spectrogram_config.mel_fmax,\n                              hparams.output_sample_rate,\n                              hparams.output_sample_rate / hparams.hop_length,\n                              hparams.mel_spectrogram_config.num_mels,\n                              hparams.output_sample_rate / hparams.hop_length,\n                              hparams.output_sample_rate / hparams.hop_length)\n    audio.save_wav(mel_prediction, hparams.output_sample_rate,\n                   wav_dir.joinpath(f\"{sample_num}-{step}-predicted-waveform.wav\"))\n\n    # Generate and save a plot comparing the predicted and target mel spectrograms\n    plot_spectrogram(mel_prediction, step, sample_num, plot_dir,\n                     hparams.mel_spectrogram_config.mel_fmin,\n                     hparams.mel_spectrogram_config.mel_fmax,\n                     hparams.mel_spectrogram_config.num_mels,\n                     hparams.output_sample_rate,\n                     hparams.mel_spectrogram_config.num_mels,\n                     hparams.output_sample_rate / hparams.hop_length,\n                     hparams.output_sample_rate / hparams.hop_length,\n                    ", "CodeBleu_score": 25.382917958386646}]}
{"instance_id": "6bad4f500286", "generation_result": [{"code": "def num_params(self)\n\t\n    total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n    print(f\"{total_params/1000000:1.3f}M\")\n\n", "CodeBleu_score": 11.064092228916007}, {"code": "def num_params(self)\n\t\n    num_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n    print(f\"The model has {num_params/1e6:.3f}M trainable parameters\")", "CodeBleu_score": 13.79102780220851}, {"code": "def num_params(self)\n\t\n    num_trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n    print(f\"Number of trainable parameters: {np.round(num_trainable_params/1e6, 3)} M\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 14.972169919540585}]}
{"instance_id": "78b876054bd4", "generation_result": [{"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if side == 'both':\n        new_size = x.size(0) + pad * 2\n    elif side == 'after':\n        new_size = x.size(0) + pad\n    elif side == 'before':\n        new_size = x.size(0) + pad\n    else:\n        raise ValueError('Invalid side argument: {}'.format(side))\n\n    if x.is_cuda:\n        x_padded = torch.zeros(new_size, x.size(1), x.size(2)).cuda()\n    else:\n        x_padded = torch.zeros(new_size, x.size(1), x.size(2))\n\n    if side == 'both':\n        x_padded[pad:-pad, :, :] = x\n    elif side == 'after':\n        x_padded[:x.size(0), :, :] = x\n    elif side == 'before':\n        x_padded[pad:, :, :] = x\n\n    return x_padded\n\n", "CodeBleu_score": 43.21717610980341}, {"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if side == 'both':\n        pad_size = x.size(0) + pad\n    elif side == 'before':\n        pad_size = x.size(0) + pad\n    elif side == 'after':\n        pad_size = x.size(0) + pad\n    else:\n        raise ValueError(\"Side must be one of 'before', 'after', or 'both'.\")\n    if x.is_cuda:\n        x_padded = torch.zeros(pad_size, x.size(1), x.size(2)).cuda()\n    else:\n        x_padded = torch.zeros(pad_size, x.size(1), x.size(2))\n    if side == 'both':\n        x_padded[:x.size(0), :, :] = x\n        x_padded[x.size(0) + pad:, :, :] = x\n    elif side == 'before':\n        x_padded[pad:, :, :] = x\n    elif side == 'after':\n        x_padded[:-pad, :, :] = x\n    return x_padded\n\n", "CodeBleu_score": 36.0344770183524}, {"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if side == 'both':\n        pad_size = pad * 2\n    elif side == 'before':\n        pad_size = pad\n    elif side == 'after':\n        pad_size = pad\n    else:\n        raise ValueError(\"side must be one of 'before', 'after', or 'both'\")\n    new_size = x.size(0) + pad_size\n    new_tensor = torch.zeros(new_size, x.size(1), x.size(2)).type_as(x)\n    new_tensor[:, :, :] = x\n    if side == 'both':\n        new_tensor = new_tensor[pad:-pad, :, :]\n    elif side == 'before':\n        new_tensor = new_tensor[pad:, :, :]\n    elif side == 'after':\n        new_tensor = new_tensor[:-pad, :, :]\n    return new_tensor\n\n", "CodeBleu_score": 29.196022055687553}]}
{"instance_id": "a7ed1715a3df", "generation_result": [{"code": "def save_attention(attn, path)\n\t\n    plt.close()\n    fig = plt.figure(figsize=(10, 10))\n    plt.imshow(attn, cmap='Reds', interpolation='nearest')\n    plt.savefig(path)\n    plt.close()", "CodeBleu_score": 35.800348608523095}, {"code": "def save_attention(attn, path)\n\t\n    plt.close()\n    fig = plt.figure(figsize=(10, 10))\n    plt.imshow(attn, cmap='Reds', interpolation='nearest')\n    plt.savefig(path)\n    plt.close()\n\n", "CodeBleu_score": 35.800348608523095}, {"code": "def save_attention(attn, path)\n\t\n    plt.close()\n    fig = plt.figure(figsize=(12, 12))\n    plt.imshow(attn, cmap='Reds')\n    plt.savefig(path + '.png')\n    plt.close()\n\n", "CodeBleu_score": 37.673763679475925}]}
{"instance_id": "19375c9f44a2", "generation_result": [{"code": "def plot(array)\n\t\n    fig = plt.figure(figsize=(10, 6))\n    ax = fig.add_subplot(111)\n    ax.tick_params(labelsize=12, labelcolor='black',\n                   bottom=True, top=True, left=True, right=True)\n    ax.set_xlabel('x', fontsize=14, color='black')\n    ax.set_ylabel('y', fontsize=14, color='black')\n    plt.plot(array)\n\n", "CodeBleu_score": 24.514344494421028}, {"code": "def plot(array)\n\t\n    fig = plt.figure(figsize=(10, 5))\n    ax = fig.add_subplot(111)\n    ax.tick_params(axis='x', labelsize=12, labelcolor='black')\n    ax.tick_params(axis='y', labelsize=12, labelcolor='black')\n    ax.plot(array)\n    plt.show()", "CodeBleu_score": 24.191092335294176}, {"code": "def plot(array)\n\t\n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot(111)\n    ax.tick_params(axis='both', which='major', labelsize=10, color='black')\n    ax.tick_params(axis='both', which='minor', labelsize=8, color='black')\n    ax.set_xlabel('X', fontsize=12, color='black')\n    ax.set_ylabel('Y', fontsize=12, color='black')\n    plt.plot(array)\n    plt.show()\n\n", "CodeBleu_score": 28.196650946380885}]}
{"instance_id": "ff94c425920c", "generation_result": [{"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    data = {'image': image_name, 'prediction': prediction, 'confidence': confidence}\n    with open('predictions.csv', 'a', newline='') as csv_file:\n        fieldnames = ['image', 'prediction', 'confidence']\n        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n        if not csv_file.is_file():\n            writer.writeheader()\n        writer.writerow(data)\n\n", "CodeBleu_score": 50.66505890132339}, {"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    data = {\"image_name\": image_name, \"prediction\": prediction, \"confidence\": confidence}\n    with open(\"predictions.csv\", \"a\", newline=\"\") as csv_file:\n        fieldnames = [\"image_name\", \"prediction\", \"confidence\"]\n        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n        if not csv_path.is_file():\n            writer.writeheader()\n        writer.writerow(data)", "CodeBleu_score": 56.55796167926792}, {"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    data = {\"image\": image_name, \"prediction\": prediction, \"confidence\": confidence}\n    with open(\"predictions.csv\", \"a\") as csv_file:\n        writer = csv.DictWriter(csv_file, fieldnames=data.keys())\n        if not csv_path.is_file():\n            writer.writeheader()\n        writer.writerow(data)", "CodeBleu_score": 62.65592535779487}]}
{"instance_id": "436161602009", "generation_result": [{"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    LOGGER.info(f\"{prefix} Exporting {file}\")  # print to console\n    t = time.time()  # start time\n    with torch.no_grad():\n        model.eval()\n        jit_model = torch.jit.trace(model, im)\n    LOGGER.info(f\"{prefix} Export complete ({time.time() - t:.2f}s)\")\n    if optimize:\n        LOGGER.info(f\"{prefix} Optimizing for mobile...\")\n        jit_model = optimize_for_mobile(jit_model)\n        LOGGER.info(f\"{prefix} Optimized for mobile ({time.time() - t:.2f}s)\")\n    ts.save(jit_model, file)  # save TorchScript model\n    LOGGER.info(f\"{prefix} Optimized model saved {file} ({time.time() - t:.2f}s)", "CodeBleu_score": 33.80373819374552}, {"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    LOGGER.info(f\"{prefix} exporting {file} with TorchScript\")\n    with torch.no_grad():\n        model.eval()\n        if hasattr(model, \"model\"):\n            model = model.model\n        for k, m in model.named_modules():\n            m._non_persistent_buffers_set = set()  # pytorch 1.6.0 compatibility\n        if hasattr(model, \"forward_export\"):\n            model = model.forward_export\n        if hasattr(model, \"fuse\"):\n            model.fuse()\n        if isinstance(im, torch.Tensor):\n            im = [im]\n        traced_script_module = torch.jit.trace(model, im)\n        file = Path(file)\n        file.parent.mkdir(parents=True, exist_ok=True)\n        torch.jit.save(traced_script_module, file)  # pytorch 1.6.0 compatibility\n        if optimize:\n            _save_for_lite_interpreter(file, im, prefix)\n        else:\n            ts.save(traced_script_module, file.with_suffix(\".torchscript\"))\n    return file", "CodeBleu_score": 35.88604352190694}, {"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    LOGGER.info(f\"{prefix} Exporting {file}\")  # print to console\n    with torch.no_grad():\n        torch.onnx.export(\n            model,\n            im,\n            file,\n            verbose=False,\n            opset_version=11,\n            do_constant_folding=True,\n            input_names=[\"images\"],\n            output_names=[\"classes\", \"boxes\"],\n        )\n    if optimize:\n        try:  # update yolov5 PyTorch model\n            _ = model(im)\n            if model.model[-1].export:\n                _ = [\n                    torch.jit.trace(\n                        model.model[-1].export,\n                        im,\n                        strict=False,\n                    )\n                ]\n        except Exception:\n            pass\n        model.model[-1].export = None  # remove final export\n        LOGGER.info(f\"{prefix} Optimizing for mobile use with torch.jit.trace()...\")\n        file = file.with_suffix(\".torchscript.pt\")  # filename\n        ts = torch.jit.trace(model, im)  # torchscript module\n        ts.save(file)  # export torchscript\n        _ = _save_for_lite_interpreter(ts, file)  # export for lite interpreter\n        return file\n    else:\n        LOGGER.info(f\"{prefix} Export complete ({file})\")\n        return file\n\n", "CodeBleu_score": 38.971272387334096}]}
{"instance_id": "78335487ac1c", "generation_result": [{"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t\n    # Check for coremltools requirement\n    check_requirements(requirements=[\"coremltools\"], extra=\"To use export_coreml(), please pip install coremltools.\")\n    # Log start of export\n    LOGGER.info(f\"{prefix} Exporting {file}\")\n    # Set file suffix to .mlmodel\n    file = file.with_suffix(\".mlmodel\")\n    # Wrap model with iOSModel for NMS support\n    if nms:\n        model = iOSModel(model)\n    # Trace model\n    im = im.to(next(model.parameters()).device)\n    traced_model = torch.jit.trace(model, im)\n    # Convert to CoreML\n    ct_model = ct.convert(traced_model, inputs=[ct.ImageType(shape=im.shape)])\n    # Apply quantization if needed and supported\n    if int8 or half:\n        ct_model = ct.quantize(ct_model)\n    if half:\n        ct_model = ct.convert(ct_model, convert_to=\"float16\")\n    # Save CoreML model\n    ct_model.save(file)\n    # Return file path and CoreML model\n    return file, ct_model\n\n", "CodeBleu_score": 37.58390971844533}, {"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t\n    # Check requirements\n    check_requirements(requirements=(\"coremltools\",))\n    # Log start\n    LOGGER.info(f\"{prefix} Exporting {file}\")\n    # Set file suffix\n    file = file.with_suffix(\".mlmodel\")\n    # Wrap model with iOSModel for NMS support\n    if nms:\n        model = iOSModel(model)\n    # Trace model\n    im = im.to(next(model.parameters()).device)\n    traced_model = torch.jit.trace(model, im)\n    # Convert to CoreML\n    ct_model = ct.convert(traced_model, inputs=[ct.ImageType()])\n    # Apply quantization\n    if int8:\n        ct_model = ct_model.convert(convert_to=\"INT8\")\n    elif half:\n        ct_model = ct_model.convert(convert_to=\"FP16\")\n    # Save model\n    ct_model.save(file)\n    # Return file path and CoreML model\n    return file, ct_model\n\n", "CodeBleu_score": 33.990034260875746}, {"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t\n    # Check requirements\n    check_requirements(requirements=(\"coremltools\", \"torchvision\"), log=False)\n    # Log export start\n    LOGGER.info(f\"{prefix} Exporting {file}\")\n    # Set file suffix to .mlmodel\n    file = file.with_suffix(\".mlmodel\")\n    # Wrap model with iOSModel for NMS support\n    if nms:\n        model = iOSModel(model)\n    # Trace model\n    model = trace(model, im)\n    # Convert to CoreML\n    ct_model = ct.convert(model, inputs=[ct.ImageType(name=\"input\", shape=im.shape, scale=1 / 255)])\n    # Apply quantization if needed and supported\n    if int8:\n        ct_model.convert_image_input_dtype(\"INT8\")\n        ct_model.convert_model_dtype(\"INT8\")\n    elif half:\n        ct_model.convert_model_dtype(\"FP16\")\n    # Save CoreML model\n    ct_model.save(file)\n    # Return file path and CoreML model\n    return file, ct_model\n\n", "CodeBleu_score": 33.137999684139515}]}
{"instance_id": "80233cf71580", "generation_result": [{"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for _ in range(individual_length):\n        individual.append(random.uniform(*input_ranges))\n    return individual\n\n", "CodeBleu_score": 38.14759799230568}, {"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for _ in range(individual_length):\n        individual.append(random.uniform(input_ranges[0], input_ranges[1]))\n    return individual\n\n", "CodeBleu_score": 39.41234669340793}, {"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for _ in range(individual_length):\n        individual.append(random.uniform(*input_ranges))\n    return individual\n\n", "CodeBleu_score": 38.14759799230568}]}
{"instance_id": "5ea979cb4a8e", "generation_result": [{"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule == 'discrete':\n        return torch.log(self.alphas[t])\n    elif self.schedule == 'linear':\n        return self.interpolate_fn(t)\n    elif self.schedule == 'cosine':\n        return self.log_alpha_fn(t)\n\n", "CodeBleu_score": 23.740650324106273}, {"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule_type == \"discrete\":\n        return torch.log(\n            torch.tensor(\n                [\n                    self.alpha_discrete_fn(t)\n                    for t in range(self.num_timesteps)\n                ]\n            )\n        )\n    elif self.schedule_type == \"linear\":\n        return torch.log(\n            torch.tensor(\n                [\n                    self.alpha_linear_fn(t)\n                    for t in range(self.num_timesteps)\n                ]\n            )\n        )\n    elif self.schedule_type == \"cosine\":\n        return torch.log(\n            torch.tensor(\n                [\n                    self.alpha_cosine_fn(t)\n                    for t in range(self.num_timesteps)\n                ]\n            )\n        )\n    else:\n        raise NotImplementedError(\n            f\"Schedule type {self.schedule_type} not implemented.\"\n        )\n\n", "CodeBleu_score": 26.992364325969927}, {"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule_type == 'discrete':\n        return torch.log(self.alpha_bar[t]) - torch.log(self.alpha_bar[0])\n    elif self.schedule_type == 'linear':\n        return self.log_alpha_fn(t, self.num_timesteps)\n    elif self.schedule_type == 'cosine':\n        return self.log_alpha_fn(t, self.num_timesteps)\n    else:\n        raise ValueError(f'Unsupported schedule type: {self.schedule_type}')\n\n", "CodeBleu_score": 30.941203882251873}]}
{"instance_id": "7da4fae5a278", "generation_result": [{"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == 'linear':\n        t = (1 - torch.exp(-lamb * self.beta)) / self.beta\n        t_fn = t\n    elif self.schedule == 'quadratic':\n        t = (1 - torch.exp(-lamb * self.beta)) / self.beta\n        t_fn = t\n    elif self.schedule == 'sigmoid':\n        t = (1 - torch.exp(-lamb * self.beta)) / self.beta\n        t_fn = t\n    elif self.schedule == 'discrete':\n        log_alpha = self.log_alpha\n        t = (log_alpha - lamb).argmax(dim=-1)\n        t_fn = t\n    else:\n        log_alpha = self.log_alpha\n        t = torch.arccos(torch.exp(lamb - log_alpha)) / self.beta\n        t_fn = t\n\n    return t, t_fn\n\n", "CodeBleu_score": 28.127065401692654}, {"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == 'linear':\n        # calculate t using beta values and a temporary variable\n        t = torch.sum(1 - torch.exp(-lamb * self.beta), dim=1)\n    elif self.schedule == 'quadratic':\n        # calculate t using beta values and a temporary variable\n        t = torch.sum(1 - torch.exp(-lamb * self.beta), dim=1)\n    elif self.schedule == 'rq':\n        # calculate t using beta values and a temporary variable\n        t = torch.sum(1 - torch.exp(-lamb * self.beta), dim=1)\n    elif self.schedule == 'discrete':\n        # interpolate log_alpha to find t\n        t = self.interpolate_fn(lamb, self.log_alpha)\n    else:\n        # calculate log_alpha and use an arccos function to derive t\n        log_alpha = self.log_alpha\n        log_alpha = log_alpha.reshape(log_alpha.shape[0], -1)\n        t = torch.arccos(torch.exp(log_alpha - lamb)) / (2 * np.pi)\n\n    return t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.186686043042783}, {"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == \"linear\":\n        # For linear schedules, we can use a simple formula to calculate t\n        t = self.beta0 * (1 - torch.exp(-lamb))\n        return t\n    elif self.schedule == \"discrete\":\n        # For discrete schedules, we need to interpolate log_alpha\n        log_alpha = torch.log(self.alpha)\n        t = interpolate_fn(log_alpha, lamb)\n        return t\n    elif self.schedule == \"cosine\":\n        # For cosine schedules, we need to use an arccos function\n        log_alpha = torch.log(self.alpha)\n        t = torch.arccos(torch.exp(lamb - log_alpha)) / np.pi\n        return t\n    else:\n        raise ValueError(f\"Unknown schedule: {self.schedule}\")\n\n", "CodeBleu_score": 21.657536471274124}]}
{"instance_id": "a519c853a2b2", "generation_result": [{"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\t\n    t_continuous = expand_dims(t_continuous, 0)\n    x = expand_dims(x, 0)\n    if cond is not None:\n        cond = expand_dims(cond, 0)\n        x = model(x, t_continuous, cond=cond)\n    else:\n        x = model(x, t_continuous)\n    x = x.squeeze(0)\n    return x\n\n", "CodeBleu_score": 12.043041450783283}, {"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\t\n    t_continuous = expand_dims(t_continuous, 0)\n    if model.type == \"ddpm\":\n        t_continuous = t_continuous.expand(x.shape[0])\n        x_t = x\n    elif model.type == \"ddim\":\n        t_continuous = t_continuous.expand(x.shape[0])\n        x_t = x * noise_schedule.marginal_alpha(t_continuous) ** 0.5\n    elif model.type == \"vqvae\":\n        t_continuous = t_continuous.expand(x.shape[0])\n        x_t = x\n    elif model.type == \"vqvae_ddpm\":\n        t_continuous = t_continuous.expand(x.shape[0])\n        x_t = x\n    elif model.type == \"vqvae_ddim\":\n        t_continuous = t_continuous.expand(x.shape[0])\n        x_t = x * noise_schedule.marginal_alpha(t_continuous) ** 0.5\n    elif model.type == \"vqvae_ddpm_ddim\":\n        t_continuous = t_continuous.expand(x.shape[0])\n        x_t = x * noise_schedule.marginal_alpha(t_continuous) ** 0.5\n    else:\n        raise ValueError(f\"Unknown model type: {model.type}\")\n    if cond is not None:\n        x_t = torch.cat([x_t, cond], dim=1)\n    noise_pred = model(x_t, t_continuous)\n    if model.type == \"ddim\":\n        noise_pred = noise_pred * noise_schedule.marginal_std(t_continuous)\n    return noise_pred\n\n", "CodeBleu_score": 33.54445673690865}, {"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\t\n    t_continuous = expand_dims(t_continuous, axis=0)\n    x_t = x\n    if model.model_type == \"ddpm\":\n        noise_pred = model(x_t, t_continuous)\n    elif model.model_type == \"ddim\":\n        noise_pred = model(x_t, t_continuous, cond)\n    elif model.model_type == \"vqvae\":\n        noise_pred = model(x_t, t_continuous, cond)\n    elif model.model_type == \"vqvae_ddpm\":\n        noise_pred = model(x_t, t_continuous)\n    elif model.model_type == \"vqvae_ddim\":\n        noise_pred = model(x_t, t_continuous, cond)\n    else:\n        raise ValueError(f\"Unknown model type: {model.model_type}\")\n\n    if model.model_type == \"ddim\":\n        noise_pred = noise_pred[0]\n\n    if noise_schedule.marginal_alpha is not None:\n        noise_pred = noise_pred * noise_schedule.marginal_std + noise_schedule.marginal_alpha\n\n    return noise_pred\n\n", "CodeBleu_score": 24.30920496986395}]}
{"instance_id": "96a9b7d54823", "generation_result": [{"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t\n    x0 = x0.reshape(-1)\n    x0_abs = torch.abs(x0)\n    q = torch.quantile(x0_abs, self.q)\n    if q == 0.0:\n        q = 1e-6\n    scale = self.scale / q\n    x0 = torch.clamp(x0, -scale, scale)\n    x0 = x0 * scale\n    x0 = x0.reshape(x00.shape)\n    return x0\n\n", "CodeBleu_score": 17.523116351103745}, {"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t\n    x0 = x0.reshape(-1)\n    x0_abs = torch.abs(x0)\n    q = torch.quantile(x0_abs, q=0.95, dim=-1, keepdim=True)\n    scaling_factor = torch.maximum(torch.ones_like(q), q / 0.95)\n    x0 = torch.clamp(x0, -scaling_factor, scaling_factor)\n    x0 = x0.reshape(x00.shape)\n    return x0\n\n", "CodeBleu_score": 20.759842483164984}, {"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t\n    if t is None:\n        t = 0.9999999999999999\n    x0 = x0.reshape((x0.shape[0], -1))\n    x0_quantile = torch.quantile(torch.abs(x0), t, dim=1)\n    x0_quantile = x0_quantile.unsqueeze(1)\n    x0_quantile = torch.maximum(x0_quantile, torch.ones_like(x0_quantile))\n    x0 = x0 / x0_quantile\n    x0 = torch.clamp(x0, min=-1, max=1)\n    x0 = x0 * x0_quantile\n    x0 = x0.reshape(x0.shape[0], *x0.shape[1:])\n    return x0\n\n", "CodeBleu_score": 41.62223583052626}]}
{"instance_id": "59c6ec6d7a6a", "generation_result": [{"code": "def data_prediction_fn(self, x, t)\n\t\n    x0_threshold = self.dynamic_thresholding_ratio * self.max_threshold_value\n    x0_clamped = torch.clamp(x, -x0_threshold, x0_threshold)\n    x0_normalized = x0_clamped / x0_threshold\n    return x0_normalized\n\n", "CodeBleu_score": 11.21680650645988}, {"code": "def data_prediction_fn(self, x, t)\n\t\n    x0_dynamic_thresholding = x - t * self.dynamic_thresholding_ratio * torch.max(torch.abs(x), self.max_dynamic_thresholding_value)\n    x0_dynamic_thresholding = torch.clamp(x0_dynamic_thresholding, -self.max_dynamic_thresholding_value, self.max_dynamic_thresholding_value)\n    return x0_dynamic_thresholding / (1 - t * self.dynamic_thresholding_ratio)\n\n", "CodeBleu_score": 15.943876867170244}, {"code": "def data_prediction_fn(self, x, t)\n\t\n    x_t = self.noise_prediction_fn(x, t)\n    max_threshold = self.max_threshold(x_t)\n    dynamic_threshold = self.dynamic_threshold(x_t, max_threshold)\n    x_t = torch.clamp(x_t, -dynamic_threshold, dynamic_threshold)\n    x_t = x_t / dynamic_threshold\n    return x_t\n\n", "CodeBleu_score": 8.38226716312851}]}
{"instance_id": "65e3618468a2", "generation_result": [{"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = sigma_in.view(input.shape)\n    input = input / sigma_in\n    pred = model(input, **kwargs)\n    pred = pred * sigma_in\n    return pred\n\n", "CodeBleu_score": 22.522105136838576}, {"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = sigma_in.view(sigma_in.size(0), -1)\n    input = input.view(input.size(0), -1)\n    input = input / torch.norm(input, dim=1).view(-1, 1)\n    input = input * sigma_in.view(-1, 1)\n    output = model(input)\n    return output\n\n", "CodeBleu_score": 22.82384526881739}, {"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma = sigma_in.view(sigma_in.shape[0], -1)\n    scaled_input = input * sigma\n    output = model(scaled_input, **kwargs)\n    return output * sigma\n\n", "CodeBleu_score": 25.552473102502727}]}
{"instance_id": "b35846dfbc66", "generation_result": [{"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.enable_grad():\n        taus = taus.clone().requires_grad_(True)\n        alpha = torch.exp(beta_0 - beta_1 * taus)\n        log_alpha = torch.log(alpha)\n        alpha.backward(torch.ones_like(alpha))\n        t2alpha_fn = taus.grad\n        taus.requires_grad_(False)\n        return t2alpha_fn * alpha, log_alpha.sum()\n\n", "CodeBleu_score": 36.9224335284278}, {"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.enable_grad():\n        taus = taus.clone()\n        taus.requires_grad_(True)\n        alpha = torch.exp(beta_0 - beta_1 * taus)\n        log_alpha = torch.log(alpha)\n        backward()\n        t2alpha_fn = taus.grad\n        return t2alpha_fn * alpha\n\n", "CodeBleu_score": 35.67980651372717}, {"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.enable_grad():\n        taus = taus.clone()\n        taus.requires_grad_()\n        alpha = beta_0.log() - beta_1.log() - taus\n        log_alpha = alpha.log()\n        backward()\n        t2alpha_fn = taus.grad\n        return t2alpha_fn * log_alpha\n\n", "CodeBleu_score": 31.815918511825153}]}
{"instance_id": "5f3667566a10", "generation_result": [{"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = model.default_noise_sampler\n    if callback is None:\n        callback = lambda x, i: None\n    x_t = x.new_ones(x.shape)\n    for i in trange(len(sigmas) - 1, disable=disable):\n        sigma_i = sigmas[i]\n        sigma_ip1 = sigmas[i + 1]\n        # Calculate the ancestral step\n        ancestral_step = get_ancestral_step(x_t, sigma_ip1, sigma_i, model, extra_args)\n        # Update the input using the Euler method\n        x_t = x_t + ancestral_step\n        # Add noise\n        x_t = x_t + s_noise * to_d(noise_sampler(x_t.shape, device=x.device), x_t.device)\n        # Call the callback function\n        callback(x_t, i)\n    return x_t\n\n", "CodeBleu_score": 37.20593638208894}, {"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = get_ancestral_step(model, x, sigmas, extra_args=extra_args, eta=eta)\n    x_t = x\n    for i in trange(len(sigmas) - 1, disable=disable):\n        if callback is not None:\n            callback({'x_t': x_t, **extra_args})\n        if s_noise != 1:\n            x_t = x_t + s_noise * to_d(noise_sampler(x_t, sigmas[i]), x_t)\n        x_t = x_t + eta * to_d(noise_sampler(x_t, sigmas[i + 1]), x_t)\n    if callback is not None:\n        callback({'x_t': x_t, **extra_args})\n    if s_noise != 1:\n        x_t = x_t + s_noise * to_d(noise_sampler(x_t, sigmas[-1]), x_t)\n    return x_t\n\n", "CodeBleu_score": 35.76054519981538}, {"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    if callback is None:\n        callback = get_ancestral_step\n    eta = to_d(eta)\n    s_noise = to_d(s_noise)\n    x = x.clone()\n    x_shape = x.shape\n    x_flat = x.reshape([-1, x_shape[-1]])\n    x_flat = x_flat.to(model.device)\n    sigmas = sigmas.to(model.device)\n    extra_args = {k: v.to(model.device) for k, v in extra_args.items()}\n    for i in trange(len(sigmas) - 1, disable=disable):\n        sigma_i = sigmas[i]\n        sigma_ip1 = sigmas[i + 1]\n        if sigma_ip1 > sigma_i:\n            eta_i = eta * (sigma_ip1 ** 2 / sigma_i ** 2) ** 0.5\n        else:\n            eta_i = eta\n        noise = s_noise * (sigma_ip1 ** 2 - sigma_i ** 2) ** 0.5 * noise_sampler(x_flat, extra_args)\n        x_flat = callback(model, x_flat, sigma_i, sigma_ip1, eta_i, noise, extra_args)\n    x = x_flat.reshape(x_shape)\n    return x\n\n", "CodeBleu_score": 35.92334565651088}]}
{"instance_id": "6261ded88df2", "generation_result": [{"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    if order > 1:\n        if j == i:\n            return 1\n        elif j == i + 1:\n            return -1\n        else:\n            return 0\n    else:\n        raise ValueError(\"Order must be at least 2\")\n\n", "CodeBleu_score": 16.061958381573874}, {"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    def prod(k, i, j):\n        if k == j:\n            return 1\n        elif k < j:\n            return (t[i+1] - t[i-k]) * prod(k+1, i, j)\n        else:\n            return (t[i+1] - t[i-k+1]) * prod(k+1, i, j)\n    if order > i:\n        raise ValueError(\"Order too high for step index.\")\n    return prod(1, i, j) / prod(1, i, order)\n\n", "CodeBleu_score": 29.280645152543343}, {"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    if order == 1:\n        if i == 0:\n            return 1\n        elif i == 1:\n            return -1\n        else:\n            raise ValueError(\"Order 1 method is not defined for step index greater than 1.\")\n    elif order == 2:\n        if i == 0:\n            return 1\n        elif i == 1:\n            return -2\n        elif i == 2:\n            return 1\n        else:\n            raise ValueError(\"Order 2 method is not defined for step index greater than 2.\")\n    elif order == 3:\n        if i == 0:\n            return 1\n        elif i == 1:\n            return -3\n        elif i == 2:\n            return 3\n        elif i == 3:\n            return -1\n        else:\n            raise ValueError(\"Order 3 method is not defined for step index greater than 3.\")\n    elif order == 4:\n        if i == 0:\n            return 1\n        elif i == 1:\n            return -4\n        elif i == 2:\n            return 6\n        elif i == 3:\n            return -4\n        elif i == 4:\n            return 1\n        else:\n            raise ValueError(\"Order 4 method is not defined for step index greater than 4.\")\n    else:\n        raise ValueError(\"Invalid order.\")\n\n    def product(j):\n        result = 1\n        for k in range(order):\n            if k != j:\n                result *= (t[i] - t[i - k - 1]) / (t[i - j] - t[i - k - 1])\n        return result\n\n    return sum(product(j) for j in range(order))\n\n", "CodeBleu_score": 30.169463231586175}]}
{"instance_id": "4ee025e33ab1", "generation_result": [{"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    if noise_sampler is None:\n        noise_sampler = model.default_noise_sampler\n    if extra_args is None:\n        extra_args = {}\n    if x.ndim == 1:\n        x = x.unsqueeze(0)\n    if sigmas.ndim == 0:\n        sigmas = sigmas.unsqueeze(0)\n    x = x.to(model.device)\n    sigmas = sigmas.to(model.device)\n    extra_args['x'] = x\n    extra_args['sigmas'] = sigmas\n    if callback is not None:\n        callback(extra_args)\n    for i in trange(len(sigmas) - 1, disable=disable):\n        sigma_i = sigmas[i].item()\n        sigma_next = sigmas[i + 1].item()\n        if sigma_next > 0:\n            noise_scaling = (sigma_next ** 2 / sigma_i ** 2).sqrt()\n        else:\n            noise_scaling = 1\n        noise = noise_sampler(x.shape, device=x.device)\n        x_in = x + (noise_scaling * sigma_i) * noise\n        x_in = x_in.to(model.device)\n        x = model(x_in, sigma_i, **extra_args)\n        if callback is not None:\n            callback(extra_args)\n    return x\n\n", "CodeBleu_score": 42.053920769961074}, {"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    if callback is None:\n        callback = lambda x: None\n    if disable is None:\n        disable = False\n    model.first_invocation = True\n    x_t = x.clone()\n    for i in trange(len(sigmas) - 1):\n        sigma = sigmas[i]\n        noise = noise_sampler(x_t, sigmas[i])\n        x_t_plus_one = model(x_t, sigma, **extra_args) + noise\n        if sigmas[i + 1] > 0:\n            x_t = noise_scaling(x_t_plus_one, x_t, sigmas[i + 1], sigmas[i])\n        else:\n            x_t = x_t_plus_one\n        callback(x_t)\n    return x_t\n\n", "CodeBleu_score": 40.876152532515405}, {"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    if sigmas[0] != 0:\n        raise ValueError(\"sigmas[0] should be the null image sigma\")\n    if len(sigmas) == 1:\n        return x\n    x_t = x.clone()\n    for i in trange(len(sigmas) - 1, disable=disable):\n        sigma_t = sigmas[i]\n        sigma_s = sigmas[i + 1]\n        if sigma_s > 0:\n            noise = noise_sampler(x_t, sigma_t)\n            x_t.data.add_(noise)\n            x_t.data.mul_(1 / (sigma_t ** 2)).add_(x).mul_(sigma_t ** 2)\n        x_t = model(x_t, sigma_t, **extra_args)\n        if callback:\n            callback(i, x_t)\n    return x_t\n\n", "CodeBleu_score": 41.19291795369}]}
{"instance_id": "cb51f91da606", "generation_result": [{"code": "def append_dims(x, target_dims)\n\t\n    current_dims = len(x.shape)\n    if current_dims > target_dims:\n        raise ValueError(\n            f\"Cannot append dimensions to a tensor with {current_dims} dimensions, which is greater than the target dimensions of {target_dims}.\"\n        )\n    num_dims_to_append = target_dims - current_dims\n    expanded = x.unsqueeze(-1)\n    for _ in range(num_dims_to_append):\n        expanded = expanded.unsqueeze(-1)\n    if x.device.type == \"mps\":\n        return expanded.detach().clone()\n    else:\n        return expanded", "CodeBleu_score": 36.66539411005638}, {"code": "def append_dims(x, target_dims)\n\t\n    current_dims = x.dim()\n    if current_dims >= target_dims:\n        raise ValueError(f\"The current number of dimensions ({current_dims}) is greater than or equal to the target number of dimensions ({target_dims}).\")\n    num_dims_to_append = target_dims - current_dims\n    x = x.unsqueeze(-1)\n    for _ in range(num_dims_to_append - 1):\n        x = x.unsqueeze(-1)\n    if x.device.type == \"mps\":\n        x = x.detach().clone()\n    return x\n\n", "CodeBleu_score": 34.70789946190912}, {"code": "def append_dims(x, target_dims)\n\t\n    num_dims_to_append = target_dims - x.ndim\n    if num_dims_to_append < 0:\n        raise ValueError(f\"Target dimensions ({target_dims}) must be at least {x.ndim}\")\n    for _ in range(num_dims_to_append):\n        x = x.unsqueeze(-1)\n    return x.detach() if x.device.type == \"mps\" else x", "CodeBleu_score": 37.17681356614225}]}
{"instance_id": "9fac874a3bc7", "generation_result": [{"code": "def download_file(path, url, digest=None)\n\t\n    if not path.exists():\n        path.parent.mkdir(parents=True, exist_ok=True)\n        with urlopen(url) as response:\n            with open(path, 'wb') as f:\n                shutil.copyfileobj(response, f)\n    if digest is not None:\n        with open(path, 'rb') as f:\n            if hashlib.sha256(f.read()).hexdigest() != digest:\n                raise OSError('File hash does not match expected value')\n    return path", "CodeBleu_score": 49.45361625068843}, {"code": "def download_file(path, url, digest=None)\n\t\n    if not path.exists():\n        path.parent.mkdir(parents=True, exist_ok=True)\n        with urlopen(url) as response:\n            with path.open('wb') as f:\n                shutil.copyfileobj(response, f)\n    if digest is not None:\n        with path.open('rb') as f:\n            if hashlib.sha256(f.read()).hexdigest() != digest:\n                raise OSError('file {} has incorrect hash'.format(path))\n    return path\n\n", "CodeBleu_score": 42.053673171046064}, {"code": "def download_file(path, url, digest=None)\n\t\n    if not os.path.exists(path):\n        os.makedirs(os.path.dirname(path), exist_ok=True)\n        with urllib.request.urlopen(url) as response, open(path, 'wb') as out_file:\n            shutil.copyfileobj(response, out_file)\n    if digest:\n        with open(path, 'rb') as file:\n            file_hash = hashlib.sha256(file.read()).hexdigest()\n            if file_hash != digest:\n                raise OSError('Hash mismatch for file: {}'.format(path))\n    return path\n\n", "CodeBleu_score": 56.08927988513751}]}
{"instance_id": "f23165e897ce", "generation_result": [{"code": "def train_mode(model, mode=True)\n\t\n    model_train_modes = [module.training for module in model.modules()]\n    if mode:\n        model.train()\n    else:\n        model.eval()\n    yield model\n    for module, mode in zip(model.modules(), model_train_modes):\n        module.train(mode)", "CodeBleu_score": 42.98030587272306}, {"code": "def train_mode(model, mode=True)\n\t\n    training_modes = [module.training for module in model.modules()]\n    try:\n        for module in model.modules():\n            module.train(mode)\n        yield model\n    finally:\n        for module, mode in zip(model.modules(), training_modes):\n            module.train(mode)\n\n", "CodeBleu_score": 45.42029676893778}, {"code": "def train_mode(model, mode=True)\n\t\n    train_modes = [m.train for m in model.modules()]\n    for m in model.modules():\n        m.train = mode\n    yield model\n    for m, tm in zip(model.modules(), train_modes):\n        m.train = tm\n\n", "CodeBleu_score": 33.289645897150734}]}
{"instance_id": "c6d59c6cb8e1", "generation_result": [{"code": "def ema_update(model, averaged_model, decay)\n\t\n    # Ensure both models have the same parameters and buffers\n    model_params = model.named_parameters()\n    averaged_params = averaged_model.named_parameters()\n    model_buffers = model.named_buffers()\n    averaged_buffers = averaged_model.named_buffers()\n\n    # Iterate over all parameters and buffers\n    for (name, param), (_, averaged_param) in zip(model_params, averaged_params):\n        # Update the averaged parameter using a weighted average\n        averaged_param.data.mul_(decay).add_(param.data, alpha=1 - decay)\n\n    for (name, buffer), (_, averaged_buffer) in zip(model_buffers, averaged_buffers):\n        # Copy the current model's buffers to the averaged model\n        averaged_buffer.data.copy_(buffer.data)\n\n    return averaged_model\n\n", "CodeBleu_score": 33.09524523294358}, {"code": "def ema_update(model, averaged_model, decay)\n\t\n    # Update the parameters of the averaged model\n    for param, averaged_param in zip(model.parameters(), averaged_model.parameters()):\n        averaged_param.data = decay * averaged_param.data + (1 - decay) * param.data\n\n    # Update the buffers of the averaged model\n    for buffer, averaged_buffer in zip(model.buffers(), averaged_model.buffers()):\n        averaged_buffer.data = decay * averaged_buffer.data + (1 - decay) * buffer.data\n\n    # Copy the current model's buffers to the averaged model\n    averaged_model.load_state_dict(model.state_dict())\n\n", "CodeBleu_score": 33.99589950214761}, {"code": "def ema_update(model, averaged_model, decay)\n\t\n    # Get the model parameters and buffers\n    model_params = model.named_parameters()\n    model_buffers = model.named_buffers()\n\n    # Get the averaged model parameters and buffers\n    averaged_params = averaged_model.named_parameters()\n    averaged_buffers = averaged_model.named_buffers()\n\n    # Ensure both models have the same parameters and buffers\n    for (name, param), (_, averaged_param) in zip(model_params, averaged_params):\n        assert name == averaged_param.name\n        averaged_param.data.copy_(averaged_param.data * decay + param.data * (1 - decay))\n\n    for (name, buffer), (_, averaged_buffer) in zip(model_buffers, averaged_buffers):\n        assert name == averaged_buffer.name\n        averaged_buffer.data.copy_(averaged_buffer.data * decay + buffer.data * (1 - decay))\n\n    # Copy the current model's buffers to the averaged model\n    for (name, buffer), (_, averaged_buffer) in zip(model_buffers, averaged_buffers):\n        assert name == averaged_buffer.name\n        averaged_buffer.data.copy_(buffer.data)\n\n", "CodeBleu_score": 26.71513253470267}]}
{"instance_id": "600c39a30798", "generation_result": [{"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, dtype=dtype, device=device)\n    max_value = torch.as_tensor(max_value, dtype=dtype, device=device)\n    u = torch.rand(shape, device=device, dtype=dtype)\n    u = torch.log(u) - torch.log(1 - u)\n    u = (u - loc) / scale\n    u = torch.sigmoid(u)\n    u = min_value.log() + u * (max_value.log() - min_value.log())\n    return u.exp()\n\n", "CodeBleu_score": 34.47099319338475}, {"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, device=device, dtype=dtype)\n    max_value = torch.as_tensor(max_value, device=device, dtype=dtype)\n    u = torch.rand(shape, device=device, dtype=dtype)\n    if min_value.numel() > 0:\n        min_value = min_value.logit()\n    if max_value.numel() > 0:\n        max_value = max_value.logit()\n    return loc + scale * torch.log(torch.exp(min_value - u) / torch.exp(max_value - u))\n\n", "CodeBleu_score": 41.203618152984916}, {"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, device=device, dtype=dtype)\n    max_value = torch.as_tensor(max_value, device=device, dtype=dtype)\n    u = torch.rand(shape, device=device, dtype=dtype)\n    u = torch.where(min_value.log() < max_value.log(), u, torch.zeros_like(u))\n    u = torch.where(min_value.log() > max_value.log(), u, torch.ones_like(u))\n    u = (u - min_value.log()) / (max_value.log() - min_value.log())\n    u = torch.logit(u)\n    u = u * scale + loc\n    u = u.exp()\n    return u\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.09617761434745}]}
{"instance_id": "75e2def2467f", "generation_result": [{"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return Activation1d(nn.ELU())\n    elif activation == \"snake\":\n        return Activation1d(SnakeBeta(channels))\n    elif activation == \"none\":\n        return Identity()\n    else:\n        raise ValueError(f\"Unknown activation type: {activation}\")", "CodeBleu_score": 44.51390467604621}, {"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return nn.ELU(inplace=True)\n    elif activation == \"snake\":\n        return SnakeBeta(channels)\n    elif activation == \"none\":\n        return nn.Identity()\n    else:\n        raise ValueError(f\"Invalid activation type: {activation}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.78412116496468}, {"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return Activation1d(nn.ELU(), antialias=antialias)\n    elif activation == \"snake\":\n        assert channels is not None, \"Channels must be specified for SnakeBeta activation\"\n        return Activation1d(SnakeBeta(channels), antialias=antialias)\n    elif activation == \"none\":\n        return Activation1d(Identity(), antialias=antialias)\n    else:\n        raise ValueError(f\"Invalid activation type: {activation}\")", "CodeBleu_score": 40.243962679605616}]}
{"instance_id": "ef1714c79e51", "generation_result": [{"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t\n    if t.dtype == torch.bfloat16:\n        t = t.float()\n    if freqs.dtype == torch.bfloat16:\n        freqs = freqs.float()\n    t_shape = t.shape\n    t_unrotated = t[..., :t_shape[-1] // 2]\n    t_rotated = t[..., t_shape[-1] // 2:]\n    t_rotated = t_rotated.view(*t_rotated.shape[:-1], -1, 2)\n    t_rotated = t_rotated.float()\n    t_rotated = t_rotated * freqs.view(*freqs.shape[:-1], -1, 1)\n    t_rotated = t_rotated.view(*t_rotated.shape[:-2], -1)\n    t_rotated = torch.stack((-t_rotated[..., 1::2], t_rotated[..., ::2]), dim=-1)\n    t_rotated = t_rotated.contiguous()\n    t_rotated = t_rotated.view(*t_rotated.shape[:-1], -1)\n    t_rotated = t_rotated.type_as(t)\n    t_rotated = scale * t_rotated\n    t = torch.cat((t_unrotated, t_rotated), dim=-1)\n    return t\n\n", "CodeBleu_score": 36.37573373263937}, {"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t\n    t = t.to(dtype=torch.float32)\n    t_unrotated = t[:, :, :t.shape[-1] // 2]\n    t_rotated = t[:, :, t.shape[-1] // 2:]\n    t_rotated = t_rotated * freqs.sin() * scale\n    t_rotated = t_rotated @ freqs.cos() * scale\n    t = torch.cat([t_unrotated, t_rotated], dim=-1)\n    return t\n\n", "CodeBleu_score": 17.025262574307764}, {"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t\n    t_unrotated = t[:, :, :, :t.shape[-1] // 2]\n    t_rotated = t[:, :, :, t.shape[-1] // 2:]\n    t_rotated = t_rotated.to(torch.float32)\n    t_rotated = t_rotated * scale\n    t_rotated = t_rotated.to(torch.float64)\n    t_rotated = t_rotated * freqs.sin()\n    t_rotated = t_rotated.to(torch.float32)\n    t_rotated = t_rotated + freqs.cos()\n    t_rotated = t_rotated.to(torch.float64)\n    t_rotated = t_rotated.view(*t_rotated.shape[:3], -1)\n    t = torch.cat([t_unrotated, t_rotated], dim = -1)\n    return t\n\n", "CodeBleu_score": 29.860825771537762}]}
{"instance_id": "a7a5f178c6f6", "generation_result": [{"code": "def idx2vq(self, idx, dim=-1)\n\t\n    codebook = self.codebook\n    idx = idx.long()\n    embeddings = codebook[idx]\n    if dim is not None:\n        embeddings = embeddings.movedim(-1, dim)\n    return embeddings\n\n", "CodeBleu_score": 25.332083786762897}, {"code": "def idx2vq(self, idx, dim=-1)\n\t\n    # Retrieve embeddings corresponding to the given indices\n    vq_emb = self.codebook[idx]\n    # Move the last dimension to the given dimension\n    if dim != -1:\n        vq_emb = vq_emb.movedim(-1, dim)\n    # Return the resulting embeddings\n    return vq_emb\n\n", "CodeBleu_score": 37.08465210457558}, {"code": "def idx2vq(self, idx, dim=-1)\n\t\n    # 1. Retrieve embeddings corresponding to the given indices\n    vq_embeddings = self.codebook[idx]\n    # 2. Move the last dimension to the given dimension\n    if dim != -1:\n        vq_embeddings = vq_embeddings.movedim(-1, dim)\n    # 3. Return the resulting embeddings\n    return vq_embeddings\n\n", "CodeBleu_score": 33.71407254268347}]}
{"instance_id": "4104c041fb20", "generation_result": [{"code": "def encode(self, x, quantize=False)\n\t\n    self.in_block.set_input(x)\n    self.in_block.forward()\n    x = self.in_block.get_output()\n\n    for block in self.down_blocks:\n        block.set_input(x)\n        block.forward()\n        x = block.get_output()\n\n    if quantize:\n        quantized, encoding, indices, loss = self.quantizer.quantize(x)\n        return quantized, encoding, indices, loss\n    else:\n        return x\n", "CodeBleu_score": 25.665195735131434}, {"code": "def encode(self, x, quantize=False)\n\t\n    x = self.in_block(x)\n    quant_loss = 0\n    quant_indices = []\n    quant_encodings = []\n    for block in self.down_blocks:\n        x, quant_loss_block, quant_indices_block, quant_encoding_block = block(x, quantize=quantize)\n        quant_loss += quant_loss_block\n        quant_indices.append(quant_indices_block)\n        quant_encodings.append(quant_encoding_block)\n\n    if quantize:\n        return x, quant_loss, quant_indices, quant_encodings\n    else:\n        return x\n\n", "CodeBleu_score": 27.810121714818802}, {"code": "def encode(self, x, quantize=False)\n\t\n    x = self.in_block(x)\n    if quantize:\n        z, z_q, indices, loss = self.down_blocks(x)\n        return z_q, z, indices, loss\n    else:\n        z = self.down_blocks(x)\n        return z\n", "CodeBleu_score": 27.53299472773303}]}
{"instance_id": "403c52ba2d3b", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if not self.ema:\n        return\n    if context is None:\n        self.parameters.copy_(self.ema_parameters)\n        return\n    self.ema_parameters.copy_(self.parameters)\n    self.parameters.copy_(self.ema.parameters)\n    logpy.info(f\"Switching to EMA weights for {context}\")\n\n    def restore():\n        self.parameters.copy_(self.ema_parameters)\n        logpy.info(f\"Restoring original weights for {context}\")\n    return restore\n\n", "CodeBleu_score": 49.51948595918167}, {"code": "def ema_scope(self, context=None)\n\t\n    if context is None:\n        context = self.ema_context\n    if context is None:\n        return\n    with context:\n        self.store()\n        self.copy_to(self.ema_parameters)\n        self.ema_parameters.requires_grad = False\n        logpy.info(f\"Using EMA weights for {self.name}.\")\n        yield\n    self.copy_to(self.parameters)\n    self.ema_parameters.requires_grad = True\n    logpy.info(f\"Restoring original weights for {self.name}.\")\n\n", "CodeBleu_score": 44.50170597198784}, {"code": "def ema_scope(self, context=None)\n\t\n    if not self.ema_enabled:\n        return context\n\n    if context is None:\n        context = Context()\n\n    context.ema_enabled = True\n    context.ema_parameters = copy.deepcopy(self.parameters)\n    self.parameters = copy.deepcopy(self.ema_parameters)\n    logpy.info(\"EMA weights loaded.\")\n\n    return context\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.89597808081563}]}
{"instance_id": "94b7467f98e4", "generation_result": [{"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    x = x + attn @ self.norm1(gate_msa)\n    x = self.norm2(x)\n    x = x * modulate(shift_mlp)\n    x = x + gate_mlp(x)\n    return x\n\n", "CodeBleu_score": 35.9417810471968}, {"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    x = x + gate_msa * attn\n    x = self.norm1(x)\n    x = x + gate_mlp * self.mlp(self.norm2(x))\n    x = self.norm3(x)\n    return x", "CodeBleu_score": 39.15398146588086}, {"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    x = x + attn * gate_msa\n    x = self.norm1(x)\n    x = x + self.modulate(shift_mlp(x), scale_mlp(x)) * gate_mlp.unsqueeze(0)\n    x = self.norm2(x)\n    return x\n\n", "CodeBleu_score": 49.69996899163899}]}
{"instance_id": "d9fdc05542a2", "generation_result": [{"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    qkv_context = context_block.pre_attention(context, c)\n    qkv_x = x_block.pre_attention(x, c)\n    qkv = torch.cat((qkv_context, qkv_x), dim=1)\n    attention = optimized_attention(qkv)\n    attention_context, attention_x = torch.split(attention, [context.shape[1], x.shape[1]], dim=1)\n    context = context_block.post_attention(attention_context, c)\n    x = x_block.post_attention(attention_x, c)\n    return context, x\n\n", "CodeBleu_score": 18.79493501122263}, {"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    qkv_context = context_block.pre_attention(context)\n    qkv_x = x_block.pre_attention(x)\n    qkv = torch.cat((qkv_context, qkv_x), dim=1)\n    attention = optimized_attention(qkv, c)\n    context_out, x_out = torch.split(attention, (c, c), dim=1)\n    context_out = context_block.post_attention(context_out)\n    x_out = x_block.post_attention(x_out)\n    return context_out, x_out\n\n", "CodeBleu_score": 12.76849477898248}, {"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    # Pre-attention\n    context_q, context_k, context_v, context_intermediate = context_block.pre_attention(context)\n    x_q, x_k, x_v, x_intermediate = x_block.pre_attention(x)\n\n    # Concatenate qkv tensors\n    qkv = torch.cat([context_q, x_q], dim=0)\n    kv = torch.cat([context_k, x_k], dim=0)\n    v = torch.cat([context_v, x_v], dim=0)\n\n    # Apply optimized attention\n    context_attention, x_attention = optimized_attention(qkv, kv, v, c)\n\n    # Split attention results back into context and x parts\n    context_attention, x_attention = torch.split(context_attention, [context.shape[0], x.shape[0]], dim=0)\n\n    # Post-attention\n    context = context_block.post_attention(context_attention, context_intermediate)\n    x = x_block.post_attention(x_attention, x_intermediate)\n\n    return context, x\n\n", "CodeBleu_score": 25.479644312213463}]}
{"instance_id": "b219bce30160", "generation_result": [{"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    assert len(timesteps.shape) == 1, 'Timesteps input to get_timestep_embedding() must be a 1-dimensional tensor'\n    half_dim = embedding_dim // 2\n    emb = math.log(10000) / (half_dim - 1)\n    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n    emb = timesteps[:, None].float() * emb[None, :]\n    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n    if embedding_dim % 2 == 1:\n        emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=-1)\n    return emb\n\n", "CodeBleu_score": 68.44801193072173}, {"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    assert len(timesteps.shape) == 1, \"Timesteps must be a one-dimensional tensor\"\n    half_dim = embedding_dim // 2\n    emb = math.log(10000) / (half_dim - 1)\n    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n    emb = timesteps[:, None] * emb[None, :]\n    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n    if embedding_dim % 2 == 1:\n        emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=-1)\n    return emb\n\n", "CodeBleu_score": 68.54439225751453}, {"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    assert len(timesteps.shape) == 1, 'Timesteps input to get_timestep_embedding() must be a 1-dimensional tensor'\n    if embedding_dim % 2 == 0:\n        max_embeddings = embedding_dim // 2\n    else:\n        max_embeddings = embedding_dim // 2 + 1\n    if max_embeddings < timesteps.max().item() + 1:\n        raise ValueError(f'timestep values must be < {max_embeddings}, but received {timesteps.max().item() + 1}')\n    half_dim = embedding_dim // 2\n    emb = math.log(10000) / (half_dim - 1)\n    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n    emb = timesteps.float()[:, None] * emb[None, :]\n    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n    if embedding_dim % 2 == 1:\n        emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=1)\n    return emb\n\n", "CodeBleu_score": 68.08727565360006}]}
{"instance_id": "6ae8453c86be", "generation_result": [{"code": "def pytorch_attention(q, k, v)\n\t\n    try:\n        q = q.view(*q.shape[:-1], -1)\n        k = k.view(*k.shape[:-1], -1)\n        v = v.view(*v.shape[:-1], -1)\n        q = q.transpose(0, 1)\n        k = k.transpose(0, 1)\n        v = v.transpose(0, 1)\n        out = torch.nn.functional.softmax(q @ k.transpose(-1, -2) / math.sqrt(k.shape[-1]), dim=-1)\n        out = out @ v\n        out = out.transpose(0, 1)\n        out = out.reshape(*out.shape[:-1], -1)\n        return out\n    except RuntimeError as e:\n        if \"out of memory\" in str(e):\n            logging.warning(\"OOM exception occurred, switching to slice attention as a fallback\")\n            return slice_attention(q, k, v)\n        else:\n            raise e\n\n", "CodeBleu_score": 34.3435635648731}, {"code": "def pytorch_attention(q, k, v)\n\t\n    try:\n        q = q.reshape(q.shape[0], q.shape[1], q.shape[2] * q.shape[3]).transpose(1, 2)\n        k = k.reshape(k.shape[0], k.shape[1], k.shape[2] * k.shape[3]).transpose(1, 2)\n        v = v.reshape(v.shape[0], v.shape[1], v.shape[2] * v.shape[3]).transpose(1, 2)\n        return scaled_dot_product_attention(q, k, v).reshape(q.shape[0], q.shape[1], q.shape[2], q.shape[3]).transpose(1, 2)\n    except RuntimeError as e:\n        logging.warning(e)\n        return slice_attention(q, k, v)\n\n", "CodeBleu_score": 24.670669759660456}, {"code": "def pytorch_attention(q, k, v)\n\t\n    try:\n        q = q.view(q.shape[0], -1, q.shape[-1])\n        k = k.view(k.shape[0], -1, k.shape[-1])\n        v = v.view(v.shape[0], -1, v.shape[-1])\n        q = q.transpose(1, 2)\n        k = k.transpose(1, 2)\n        v = v.transpose(1, 2)\n        t = torch.bmm(q, k.transpose(1, 2))\n        t = t / math.sqrt(k.shape[-1])\n        t = torch.softmax(t, dim=-1)\n        t = torch.bmm(t, v)\n        t = t.transpose(1, 2)\n        t = t.reshape(q.shape[0], -1, t.shape[-1])\n        return t\n    except RuntimeError as e:\n        if 'out of memory' in str(e):\n            logging.warning('OOM exception occurred. Switching to slice attention as a fallback.')\n            return slice_attention(q, k, v)\n        else:\n            raise e\n\n", "CodeBleu_score": 32.012990410971845}]}
{"instance_id": "fe4433c987ad", "generation_result": [{"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        if control in h.controls:\n            h.controls.pop(control)\n            try:\n                h.add_control(control, name)\n            except Exception:\n                logging.warning(\"Failed to add control {} to {}\".format(control, name))\n    return h\n\n", "CodeBleu_score": 35.118674777924426}, {"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        if name in control:\n            control.pop(name)\n            if not h.add(name):\n                logging.warning(\"Could not apply control adjustment for {}\".format(name))\n    return h\n\n", "CodeBleu_score": 29.10416410788056}, {"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        if name in control:\n            c = control.pop(name)\n            try:\n                h[name] = c\n            except Exception:\n                logging.warning(\"Could not apply control '%s' to %s\", c, name)\n    return h\n\n", "CodeBleu_score": 38.066113523052934}]}
{"instance_id": "56da4547c101", "generation_result": [{"code": "def get_codebook_entry(self, indices, shape)\n\t\n    z_q = torch.zeros(indices.shape[0], self.n_e, device=self.device)\n    z_q.scatter_(1, indices.unsqueeze(1), 1)\n    z_q = z_q * self.w_q\n    if shape is not None:\n        z_q = z_q.view(z_q.shape[0], *shape)\n        z_q = z_q.permute(0, 2, 3, 1)\n    return z_q\n\n", "CodeBleu_score": 41.9847415683651}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    min_encodings = torch.zeros(indices.shape[0], self.num_codebook_vectors, device=indices.device)\n    min_encodings.scatter_(1, indices.unsqueeze(1), 1)\n    min_encodings = min_encodings.view(*indices.shape, -1)\n    z_q = torch.matmul(min_encodings, self.embedding.weight)\n    if shape is not None:\n        z_q = z_q.view(shape)\n        z_q = z_q.permute(0, 3, 1, 2)\n    return z_q\n\n", "CodeBleu_score": 50.18550298800438}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # shape specifying (C, H, W)\n    # indices specifying (N, H, W)\n    min_encodings = torch.zeros(indices.shape[0], self.num_codebooks, device=self.device)\n    min_encodings.scatter_(1, indices, 1)\n    min_encodings = min_encodings.view(indices.shape[0], self.num_codebooks, -1)\n    min_encodings = min_encodings.permute(0, 2, 1)\n    min_encodings = min_encodings.contiguous().view(-1, self.num_codebooks)\n    z_q = torch.matmul(min_encodings, self.embedding.weight)\n    z_q = z_q.view(indices.shape[0], *shape, self.dim)\n    return z_q\n\n", "CodeBleu_score": 20.670915413074447}]}
{"instance_id": "548f8a1fb37d", "generation_result": [{"code": "def make_noise(self)\n\t\n    noise = torch.randn(4, 4).to(self.device)\n    noises = [noise]\n    for i in range(3, self.log_size + 3):\n        factor = 2 ** (i - 2)\n        for _ in range(2):\n            noise = torch.nn.functional.interpolate(noise, scale_factor=2, mode=\"nearest\")\n            noise = noise.to(self.device)\n            noises.append(noise)\n    return noises", "CodeBleu_score": 30.681379763877935}, {"code": "def make_noise(self)\n\t\n    self.noise = []\n    self.noise.append(torch.randn(4, 4, device=self.device))\n    for i in range(3, self.log_size + 3):\n        self.noise.append(\n            torch.randn(2**i, 2**i, device=self.device)\n        )  # 2**i is the same as 2^i\n        self.noise.append(\n            torch.randn(2**i, 2**i, device=self.device)\n        )  # 2**i is the same as 2^i\n    return self.noise", "CodeBleu_score": 28.081390033592967}, {"code": "def make_noise(self)\n\t\n    self.noise = []\n    self.noise.append(torch.randn(4, 4, device=self.device))\n    for i in range(self.log_size - 3):\n        self.noise.append(torch.randn(2 ** (i + 3), 2 ** (i + 3), device=self.device))\n        self.noise.append(torch.randn(2 ** (i + 3), 2 ** (i + 3), device=self.device))\n    return self.noise\n\n", "CodeBleu_score": 24.402858139800554}]}
{"instance_id": "42fd805563c6", "generation_result": [{"code": "def mean_latent(self, num_latent)\n\t\n    # Generate random latent inputs\n    z = torch.randn((num_latent, self.latent_dim), device=self.device)\n\n    # Process the latent inputs through the style MLP\n    z = self.style_mlp(z)\n\n    # Compute the mean of the processed latents along the first dimension\n    mean_z = torch.mean(z, dim=0)\n\n    return mean_z\n\n", "CodeBleu_score": 25.47528009841953}, {"code": "def mean_latent(self, num_latent)\n\t\n    mean = torch.randn(num_latent, self.style_dim, device=self.device)\n    mean = self.style_mlp(mean)\n    mean = mean.mean(dim=0)\n    return mean\n\n", "CodeBleu_score": 24.855392104049088}, {"code": "def mean_latent(self, num_latent)\n\t\n    mean = torch.randn(num_latent)\n    mean = self.style_mlp(mean)\n    mean = mean.mean(0)\n    return mean\n\n", "CodeBleu_score": 11.286926772114366}]}
{"instance_id": "2f485fd924af", "generation_result": [{"code": "def color_jitter(img, shift)\n\t\n    jitter = np.random.uniform(-shift, shift, size=img.shape)\n    img = img + jitter\n    img = np.clip(img, 0, 1)\n    return img\n\n", "CodeBleu_score": 55.8841710261472}, {"code": "def color_jitter(img, shift)\n\t\n    jitter = np.random.uniform(-shift, shift, size=img.shape)\n    img = img + jitter\n    img = np.clip(img, 0, 1)\n    return img\n\n", "CodeBleu_score": 55.8841710261472}, {"code": "def color_jitter(img, shift)\n\t\n    jitter = np.random.uniform(-shift, shift, size=img.shape)\n    jitter = jitter.astype(img.dtype)\n    jittered_img = img + jitter\n    jittered_img = np.clip(jittered_img, 0, 1)\n    return jittered_img", "CodeBleu_score": 44.47226692809877}]}
{"instance_id": "c87ccf1fbf48", "generation_result": [{"code": "def feed_data(self, data)\n\t\n    self.lq = data['lq']\n    if 'gt' in data:\n        self.gt = data['gt']\n    if 'l_eye' in data:\n        self.l_eye = data['l_eye']\n    if 'r_eye' in data:\n        self.r_eye = data['r_eye']\n    if 'mouth' in data:\n        self.mouth = data['mouth']\n\n", "CodeBleu_score": 43.5686635004068}, {"code": "def feed_data(self, data)\n\t\n    self.lq = data['lq']\n    if 'gt' in data:\n        self.gt = data['gt']\n    if 'l_eye' in data:\n        self.l_eye = data['l_eye']\n        self.r_eye = data['r_eye']\n        self.mouth = data['mouth']", "CodeBleu_score": 42.90189828846784}, {"code": "def feed_data(self, data)\n\t\n    self.lq = data['lq']\n    if 'gt' in data:\n        self.gt = data['gt']\n    if 'l_eye' in data:\n        self.l_eye = data['l_eye']\n    if 'r_eye' in data:\n        self.r_eye = data['r_eye']\n    if 'mouth' in data:\n        self.mouth = data['mouth']\n\n", "CodeBleu_score": 43.5686635004068}]}
{"instance_id": "8f8c7cb13037", "generation_result": [{"code": "def construct_img_pyramid(self)\n\t\n    img_pyramid = [self.gt_img]\n    for i in range(self.num_scales - 1):\n        img_pyramid.insert(0, F.interpolate(img_pyramid[0], scale_factor=0.5, mode='bilinear', align_corners=True))\n    return img_pyramid\n\n", "CodeBleu_score": 24.4544630856044}, {"code": "def construct_img_pyramid(self)\n\t\n    img_pyramid = []\n    img_pyramid.insert(0, self.gt_img)\n    for i in range(self.num_scales - 1):\n        img_pyramid.insert(0, F.interpolate(img_pyramid[0], scale_factor=0.5, mode='bilinear'))\n    return img_pyramid", "CodeBleu_score": 27.322773636326904}, {"code": "def construct_img_pyramid(self)\n\t\n    pyramid_gt = []\n    pyramid_gt.insert(0, self.img_gt)\n    for i in range(self.num_scales - 1):\n        pyramid_gt.insert(0, F.interpolate(pyramid_gt[0], scale_factor=0.5, mode='bilinear', align_corners=False))\n    return pyramid_gt\n\n", "CodeBleu_score": 31.817557967503372}]}
{"instance_id": "51247274d40c", "generation_result": [{"code": "def save(self, epoch, current_iter)\n\t\n    self.save_network(epoch, current_iter)\n    self.save_training_state(epoch, current_iter)\n\n", "CodeBleu_score": 11.730051474060335}, {"code": "def save(self, epoch, current_iter)\n\t\n    self.save_network(epoch, current_iter)\n    self.save_training_state(epoch, current_iter)\n\n", "CodeBleu_score": 11.730051474060335}, {"code": "def save(self, epoch, current_iter)\n\t\n    self.save_network(epoch, current_iter)\n    self.save_training_state(epoch, current_iter)\n\n", "CodeBleu_score": 11.730051474060335}]}
{"instance_id": "afa0dc8128c1", "generation_result": [{"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        try:\n            if os.path.isfile(item_path):\n                os.unlink(item_path)\n            elif os.path.islink(item_path):\n                os.unlink(item_path)\n            elif os.path.isdir(item_path):\n                shutil.rmtree(item_path)\n        except Exception as e:\n            print(f\"Error deleting {item_path}: {e}\")\n\n", "CodeBleu_score": 51.31080674140933}, {"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        try:\n            if os.path.isfile(item_path):\n                os.unlink(item_path)\n            elif os.path.islink(item_path):\n                os.unlink(item_path)\n            elif os.path.isdir(item_path):\n                shutil.rmtree(item_path)\n        except Exception as e:\n            print(f\"Error deleting {item_path}: {e}\")\n\n", "CodeBleu_score": 51.31080674140933}, {"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        try:\n            if os.path.isfile(item_path):\n                os.unlink(item_path)\n            elif os.path.islink(item_path):\n                os.unlink(item_path)\n            elif os.path.isdir(item_path):\n                shutil.rmtree(item_path)\n        except Exception as e:\n            print(f\"Error deleting {item_path}: {e}\")\n\n", "CodeBleu_score": 51.31080674140933}]}
{"instance_id": "53588b481bdd", "generation_result": [{"code": "def next_batch(self, sample_size=1)\n\t\n    if len(self.buffer) < sample_size:\n        sample_size = len(self.buffer)\n    samples = random.sample(self.buffer, sample_size)\n    self.buffer = [e for e in self.buffer if e not in samples]\n    return samples\n\n", "CodeBleu_score": 52.627829498764086}, {"code": "def next_batch(self, sample_size=1)\n\t\n    if sample_size > len(self.memory):\n        sample_size = len(self.memory)\n    return random.sample(self.memory, sample_size)\n\n", "CodeBleu_score": 32.782246025742744}, {"code": "def next_batch(self, sample_size=1)\n\t\n    if sample_size > len(self.buffer):\n        sample_size = len(self.buffer)\n    return random.sample(self.buffer, sample_size)\n\n", "CodeBleu_score": 32.797839059628124}]}
{"instance_id": "6bfa6a4e621c", "generation_result": [{"code": "def find_estimated_top_configs(self)\n\t\n    flattened_ds_config = {}\n    for config, value in self.all_configs.items():\n        flattened_config = self.flatten(config)\n        flattened_ds_config[flattened_config] = value\n    flattened_config_list = list(flattened_ds_config.keys())\n    flattened_config_val_list = list(flattened_ds_config.values())\n    flattened_config_val_list = [\n        self.feature_val[self.configs.index(config)]\n        for config in flattened_config_list\n    ]\n    flattened_config_val_array = np.array(flattened_config_val_list)\n    flattened_config_val_array = flattened_config_val_array.astype(float)\n    flattened_config_val_array = flattened_config_val_array.reshape(\n        len(flattened_config_val_array), 1\n    )\n    predicted_cost = self.predict(flattened_config_val_array)\n    predicted_cost = predicted_cost.reshape(len(predicted_cost), 1)\n    predicted_cost = predicted_cost.flatten()\n    predicted_cost = predicted_cost.tolist()\n    if self.metric == \"cost\":\n        top_configs = np.argsort(predicted_cost)\n    elif self.metric == \"quality\":\n        top_configs = np.argsort(flattened_config_val_array)\n    else:\n        raise ValueError(\"Invalid metric specified.\")\n    return top_configs\n\n", "CodeBleu_score": 33.31923786762485}, {"code": "def find_estimated_top_configs(self)\n\t\n    flattened_ds_config = self.flatten_ds_config()\n    configs = []\n    feature_val = []\n    for config in self.all_configs:\n        configs.append(flattened_ds_config.items())\n        feature_val.append(config.flatten())\n    feature_val = np.array(feature_val)\n    if isinstance(self.cost_model, str):\n        if self.cost_model == \"random\":\n            cost = np.random.rand(len(self.all_configs))\n        else:\n            raise ValueError(\n                \"The cost model should be a string and one of the following: 'random'.\"\n            )\n    else:\n        cost = self.cost_model.predict(feature_val)\n    if self.metric == \"cost\":\n        top_configs_idx = np.argsort(cost)[::-1]\n    elif self.metric == \"accuracy\":\n        top_configs_idx = np.argsort(cost)[::-1]\n    elif self.metric == \"runtime\":\n        top_configs_idx = np.argsort(cost)[::-1]\n    else:\n        raise ValueError(\n            \"The metric should be a string and one of the following: 'cost', 'accuracy', 'runtime'.\"\n        )\n    return top_configs_idx", "CodeBleu_score": 26.50499532065745}, {"code": "def find_estimated_top_configs(self)\n\t\n    flattened_ds_config = flatten(self.all_configs)\n    feature_val = []\n    for k, v in flattened_ds_config.items():\n        if isinstance(v, int) or isinstance(v, float):\n            feature_val.append(v)\n    feature_val = np.array(feature_val)\n    predict = self.cost_model.predict(feature_val)\n    sorted_index = np.argsort(predict)\n    return sorted_index[: self.top_configs_num]", "CodeBleu_score": 28.63962333652233}]}
{"instance_id": "d4cf48413a57", "generation_result": [{"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, dict):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)", "CodeBleu_score": 74.04759388199203}, {"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, dict):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 74.04759388199203}, {"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, dict):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 74.04759388199203}]}
{"instance_id": "c2a514249c25", "generation_result": [{"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd:\n        logger.info(f\"Running command after tuning: {self.optimal_cmd}\")\n        result = subprocess.Popen(self.optimal_cmd, shell=True)\n        result.wait()\n        logger.info(\"Command after tuning completed successfully.\")\n    else:\n        logger.info(\"Autotuning did not find an optimal configuration.\")", "CodeBleu_score": 55.86950458553419}, {"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd:\n        logger.info(f\"Running command after tuning: {self.optimal_cmd}\")\n        subprocess.Popen(self.optimal_cmd, shell=True)\n        result = subprocess.run(self.optimal_cmd, shell=True)\n        result.wait()\n        logger.info(\"Command run successfully\")\n    else:\n        logger.info(\"Autotuning did not find an optimal configuration\")", "CodeBleu_score": 54.73048042791384}, {"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd is not None:\n        logger.info(\"Running command after tuning\")\n        result = subprocess.Popen(self.optimal_cmd, shell=True)\n        result.wait()\n        logger.info(\"Command after tuning executed successfully\")\n    else:\n        logger.info(\"No optimal command found after tuning\")", "CodeBleu_score": 50.82686276851746}]}
{"instance_id": "61802de52df0", "generation_result": [{"code": "def run_job(self, exp: dict, reservations)\n\t\n    self.logger.info(f\"Running experiment {exp['name']}\")\n    exp[\"master_port\"] = self.get_port()\n    exp[\"result_dir\"] = self.get_result_dir(exp[\"name\"])\n    user_args = []\n    for arg in exp[\"args\"]:\n        if arg[\"type\"] == \"reservation\":\n            arg[\"value\"] = reservations[arg[\"reservation\"]]\n        user_args.append(arg[\"value\"])\n    t = threading.Thread(target=self.run_experiment, args=(exp[\"script\"], user_args))\n    t.start()\n    self.running_experiments[exp[\"name\"]] = {\"thread\": t, \"timestamp\": time.time()}\n\n", "CodeBleu_score": 26.037108764001438}, {"code": "def run_job(self, exp: dict, reservations)\n\t\n    exp['master_port'] = self.master_port\n    exp['result_dir'] = self.result_dir\n    if 'args' in exp:\n        args = exp['args']\n        if 'mappings' in exp:\n            mappings = exp['mappings']\n            for mapping in mappings:\n                if mapping['type'] == 'arg':\n                    arg_index = args.index(mapping['arg'])\n                    args[arg_index] = get_val_by_key(mapping['mapping'], reservations)\n        exp['args'] = args\n    self.running_experiments[exp['name']] = time.time()\n    t = threading.Thread(target=self.run_experiment, args=(exp,))\n    t.start()\n\n", "CodeBleu_score": 27.6779518699536}, {"code": "def run_job(self, exp: dict, reservations)\n\t\n    self.exp = exp\n    self.reservations = reservations\n    self.exp[\"master_port\"] = self.get_free_port()\n    self.exp[\"result_dir\"] = self.get_result_dir()\n    self.update_user_args()\n    self.exp[\"user_args\"] = self.user_args\n    self.running_experiments[self.exp[\"name\"]] = {\"start_time\": time.time(), \"exp\": self.exp}\n    t = threading.Thread(target=self.run_experiment, args=(self.exp[\"script\"], self.user_args))\n    t.start()\n\n", "CodeBleu_score": 20.517281563705293}]}
{"instance_id": "4884e2e9665c", "generation_result": [{"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if dist.is_initialized():\n        if ranks is None:\n            ranks = [dist.get_rank()]\n        if ranks[0] == 0:\n            message = f'[Rank {ranks[0]}] {message}'\n    else:\n        ranks = [0]\n    if ranks[0] == 0:\n        if path is None:\n            path = self.args.log_file\n        with open(path, 'a') as outfile:\n            json.dump(message, outfile)\n            outfile.write('", "CodeBleu_score": 35.883177758820935}, {"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if dist.is_initialized():\n        message = f\"Rank {dist.get_rank()}: {message}\"\n    if self.log_to_file:\n        with open(self.log_file, \"a\") as outfile:\n            json.dump({\"message\": message}, outfile)\n            outfile.write(\"", "CodeBleu_score": 17.592897964063667}, {"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if dist.is_initialized():\n        if ranks is None:\n            ranks = [0]\n        if dist.get_rank() in ranks:\n            if path is None:\n                path = self.exp_results_path\n            with open(path, 'a') as outfile:\n                json.dump(message, outfile)\n                outfile.write('", "CodeBleu_score": 29.87619237621858}]}
{"instance_id": "0429344c3c4d", "generation_result": [{"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    # Check if there are any layer files\n    if not self.layer_files:\n        raise ValueError(\"No layer files found.\")\n\n    # Verify the layer index\n    if layer_index < 0 or layer_index >= len(self.layer_files):\n        raise ValueError(\"Invalid layer index.\")\n\n    # Get the prefix for the layer files\n    prefix = self.layer_files[layer_index]\n\n    # Get the files with the specified prefix\n    files = get_files_with_prefix(prefix)\n\n    # Partition the files into tp_degree partitions\n    partitioned_files = partition_data(files, self.tp_degree)\n\n    # Create a dictionary mapping partition indices to their corresponding file lists\n    tp_other_layer_map = {\n        i: partitioned_files[i] for i in range(len(partitioned_files))\n    }\n\n    return tp_other_layer_map\n\n", "CodeBleu_score": 44.26666021210246}, {"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    layer_files = self._get_layer_files(layer_index)\n    if not layer_files:\n        raise ValueError(f\"No layer files found for layer {layer_index}\")\n    if layer_index >= len(layer_files):\n        raise ValueError(f\"Invalid layer index {layer_index}\")\n    layer_files = layer_files[layer_index]\n    tp_degree = self.tp_degree\n    tp_other_layer_map = {}\n    for i, file_list in enumerate(partition_data(layer_files, tp_degree)):\n        tp_other_layer_map[i] = file_list\n    return tp_other_layer_map\n\n", "CodeBleu_score": 33.32555406920471}, {"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    if self.layer_files is None:\n        raise ValueError(\"Layer files not found.\")\n    if layer_index >= len(self.layer_files):\n        raise ValueError(f\"Layer index {layer_index} is out of bounds.\")\n    layer_files = self.layer_files[layer_index]\n    prefix = self._get_layer_prefix(layer_index)\n    partition_files = self._partition_data(layer_files, prefix, self.tp_degree)\n    tp_other_layer_map = {i: partition_files[i] for i in range(self.tp_degree)}\n    return tp_other_layer_map\n\n", "CodeBleu_score": 40.08253238791687}]}
{"instance_id": "1b65ecb9be93", "generation_result": [{"code": "def system_info()\n\t\n    system_info = {\n        \"Operating System\": platform.system(),\n        \"Architecture\": platform.architecture(),\n        \"Version\": platform.version(),\n        \"Processor\": platform.processor(),\n        \"Python Version\": platform.python_version(),\n    }\n    return system_info\n\n", "CodeBleu_score": 52.055468047033095}, {"code": "def system_info()\n\t\n    return {\n        \"os\": platform.system(),\n        \"architecture\": platform.architecture(),\n        \"version\": platform.version(),\n        \"processor\": platform.processor(),\n        \"python_version\": platform.python_version(),\n    }", "CodeBleu_score": 83.71932669032101}, {"code": "def system_info()\n\t\n    return {\n        \"operating_system\": platform.system(),\n        \"architecture\": platform.architecture(),\n        \"version\": platform.version(),\n        \"processor\": platform.processor(),\n        \"python_version\": platform.python_version()\n    }", "CodeBleu_score": 81.56623209309042}]}
{"instance_id": "969bcc5cf3b5", "generation_result": [{"code": "def cuda_info()\n\t\n    device_count = torch.cuda.device_count()\n    if device_count == 0:\n        print(\"No CUDA device found. Please check your CUDA setup.\")\n        return\n\n    print(\"CUDA device count:\", device_count)\n\n    for i in range(device_count):\n        device_name = torch.cuda.get_device_name(i)\n        print(\"CUDA device {}: {}\".format(i, device_name))\n\n    print(\"CUDA available:\", torch.cuda.is_available())\n    print(\"CUDA version:\", torch.version.cuda)\n\n", "CodeBleu_score": 41.3234528949208}, {"code": "def cuda_info()\n\t\n    print(\"CUDA version:\", torch.version.cuda)\n    print(\"CUDA device count:\", torch.cuda.device_count())\n    print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n    print(\"CUDA availability:\", torch.cuda.is_available())\n\n", "CodeBleu_score": 36.47358097265306}, {"code": "def cuda_info()\n\t\n    if torch.cuda.is_available():\n        print(f\"CUDA is available. There are {torch.cuda.device_count()} GPUs available.\")\n        print(f\"The current device is {torch.cuda.get_device_name()}.\")\n        print(f\"The current CUDA version is {torch.version.cuda}.\")\n    else:\n        print(\"CUDA is not available.\")\n\n", "CodeBleu_score": 29.764222087948205}]}
{"instance_id": "a2ba908a4c70", "generation_result": [{"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_name_key = encoder_manager.config.class_name_key\n    class_id_to_class_name_mapping = encoder_manager.config.class_id_to_class_name_mapping\n    class_acc_dict = {}\n    for item in tqdm(dataset_items):\n        audio_file = item[class_name_key]\n        embedding = encoder_manager.compute_embedding_from_clip(audio_file)\n        if class_id_to_class_name_mapping:\n            class_id = item[\"class_id\"]\n            class_name = class_id_to_class_name_mapping[class_id]\n        else:\n            class_name = item[class_name_key]\n        if class_name not in class_acc_dict:\n            class_acc_dict[class_name] = {\"total\": 0, \"correct\": 0}\n        class_acc_dict[class_name][\"total\"] += 1\n        if embedding.cuda.is_available():\n            embedding = embedding.cuda()\n        inference = encoder_manager.inference(embedding)\n        if class_name == inference:\n            class_acc_dict[class_name][\"correct\"] += 1\n    for class_name, class_acc in class_acc_dict.items():\n        print(f\"{class_name}: {class_acc['correct'] / class_acc['total'] * 100:.2f}%\")\n    print(f\"Average accuracy: {sum([class_acc['correct'] for class_acc in class_acc_dict.values()]) / sum([class_acc['total'] for class_acc in class_acc_dict.values()]) * 100:.2f}%\")\n\n", "CodeBleu_score": 33.927944904845006}, {"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_name_key = encoder_manager.config.class_name_key\n    class_id_to_class_name_mapping = encoder_manager.config.class_id_to_class_name_mapping\n    class_acc_dict = {}\n    for item in tqdm(dataset_items):\n        audio_file = item[class_name_key]\n        embedding = encoder_manager.compute_embedding_from_clip(audio_file)\n        if embedding is not None:\n            if class_id_to_class_name_mapping is not None:\n                class_id = item.get(\"class_id\")\n                if class_id is not None:\n                    class_name = class_id_to_class_name_mapping[class_id]\n                else:\n                    class_name = item.get(\"class_name\")\n                if class_name is not None:\n                    class_acc_dict[class_name] = class_acc_dict.get(class_name, 0) + 1\n            else:\n                class_name = item.get(\"class_name\")\n                if class_name is not None:\n                    class_acc_dict[class_name] = class_acc_dict.get(class_name, 0) + 1\n    if len(class_acc_dict) > 0:\n        total_acc = sum(class_acc_dict.values())\n        for class_name, acc in class_acc_dict.items():\n            print(f\"{class_name}: {acc / total_acc * 100:.2f}%\")\n        print(f\"Average accuracy: {total_acc / len(dataset_items) * 100:.2f}%\")\n\n\n\n", "CodeBleu_score": 34.28914623157346}, {"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_name_key = encoder_manager.config.class_name_key\n    class_id_to_class_name_mapping = encoder_manager.config.class_id_to_class_name_mapping\n    class_acc_dict = {}\n    for item in tqdm(dataset_items):\n        audio_file = item[class_name_key]\n        embedding = encoder_manager.compute_embedding_from_clip(audio_file)\n        if class_id_to_class_name_mapping is not None:\n            class_id = item[\"class_id\"]\n            class_name = class_id_to_class_name_mapping[class_id]\n            if class_name not in class_acc_dict:\n                class_acc_dict[class_name] = {\"total\": 0, \"correct\": 0}\n            class_acc_dict[class_name][\"total\"] += 1\n            if embedding is not None:\n                class_acc_dict[class_name][\"correct\"] += 1\n    for class_name, class_acc in class_acc_dict.items():\n        accuracy = class_acc[\"correct\"] / class_acc[\"total\"]\n        print(f\"Accuracy for class {class_name}: {accuracy:.4f}\")\n    if len(class_acc_dict) > 0:\n        total_correct = sum([class_acc[\"correct\"] for class_acc in class_acc_dict.values()])\n        total_total = sum([class_acc[\"total\"] for class_acc in class_acc_dict.values()])\n        average_accuracy = total_correct / total_total\n        print(f\"Average accuracy: {average_accuracy:.4f}\")\n\n", "CodeBleu_score": 33.57849294665316}]}
{"instance_id": "e01ec69ad58a", "generation_result": [{"code": "def adjust_path_and_remove_silence(audio_path)\n\t\n    output_path = audio_path.replace(input_dir, output_dir)\n    if not force and output_path.exists():\n        return output_path, False\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n    speech_detected = remove_silence(audio_path, output_path,\n                                     silence_threshold=silence_threshold,\n                                     keep_silence=keep_silence,\n                                     min_silence_len=min_silence_len)\n    return output_path, speech_detected\n\n", "CodeBleu_score": 34.442146766545505}, {"code": "def adjust_path_and_remove_silence(audio_path)\n\t\n    # Replace input directory path with output directory path to determine the new file location\n    output_path = audio_path.replace(input_dir, output_dir)\n\n    # Check if the file already exists and if force is not specified\n    if output_path.exists() and not force:\n        # Return the output path and a False flag\n        return output_path, False\n\n    # Create the necessary directory structure\n    output_path.parent.mkdir(parents=True, exist_ok=True)\n\n    # Load the audio file\n    audio, _ = librosa.load(audio_path, sr=sr)\n\n    # Remove silence from the audio using specified parameters\n    audio, _ = librosa.effects.trim(audio, top_db=top_db, frame_length=frame_length, hop_length=hop_length)\n\n    # Save the processed audio\n    librosa.output.write_wav(output_path, audio, sr)\n\n    # Check if speech was detected\n    speech_detected = librosa.feature.rms(audio, frame_length=frame_length, hop_length=hop_length).max() > threshold\n\n    # Return the output path and a flag indicating if speech was detected\n    return output_path, speech_detected\n\n", "CodeBleu_score": 42.58392968343826}, {"code": "def adjust_path_and_remove_silence(audio_path)\n\t\n    # Replace the input directory path with the output directory path to determine the new file location\n    output_path = audio_path.replace(input_dir, output_dir)\n    # Check if the file already exists\n    if os.path.exists(output_path) and not force:\n        # If force is not specified and the file already exists, return the output path and a False flag\n        return output_path, False\n    # Create the necessary directory structure\n    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n    # Remove silence from the audio using specified parameters\n    speech_detected = remove_silence(audio_path, output_path, silence_threshold, silence_duration)\n    # Return the output path and a flag indicating if speech was detected\n    return output_path, speech_detected\n\n", "CodeBleu_score": 32.54819030289377}]}
{"instance_id": "7e0bdb0feff8", "generation_result": [{"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir is None:\n        output_dir = input_dir\n\n    # Copy input directory to output directory\n    copytree(input_dir, output_dir)\n\n    # Find all audio files with the specified extension\n    audio_files = glob.glob(os.path.join(output_dir, \"**\", f\"*.{file_ext}\"), recursive=True)\n\n    # Resample audio files in parallel using a specified number of jobs\n    with Pool(n_jobs) as p:\n        with tqdm(total=len(audio_files)) as pbar:\n            for _ in p.imap_unordered(partial(resample_file, output_sr=output_sr), audio_files):\n                pbar.update()\n\n    # Print completion message\n    print(f\"Resampling completed. {len(audio_files)} audio files resampled.\")\n\n", "CodeBleu_score": 47.836257043206984}, {"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if not output_dir:\n        output_dir = input_dir\n    if not os.path.exists(output_dir):\n        shutil.copytree(input_dir, output_dir)\n    files = glob.glob(os.path.join(output_dir, \"**\", f\"*.{file_ext}\"), recursive=True)\n    pbar = tqdm(total=len(files))\n\n    def process_file(file):\n        output_file = file.replace(output_dir, output_dir + \"_resampled\")\n        if not os.path.exists(os.path.dirname(output_file)):\n            os.makedirs(os.path.dirname(output_file))\n        sound, sr = librosa.load(file, sr=None)\n        sound = librosa.resample(sound, sr, output_sr)\n        librosa.output.write_wav(output_file, sound, output_sr)\n        pbar.update()\n\n    with Pool(n_jobs) as p:\n        list(tqdm(p.imap_unordered(process_file, files), total=len(files)))\n    pbar.close()\n    print(f\"", "CodeBleu_score": 42.25165427734328}, {"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir is None:\n        output_dir = input_dir\n    else:\n        copytree(input_dir, output_dir)\n    files = glob.glob(f\"{output_dir}/**/*.{file_ext}\", recursive=True)\n    with Pool(n_jobs) as p:\n        with tqdm(total=len(files)) as pbar:\n            for _ in p.imap_unordered(partial(resample_file, output_sr=output_sr), files):\n                pbar.update()\n    print(f\"Completed resampling {len(files)} files to {output_sr}Hz.\")\n\n", "CodeBleu_score": 33.6145949429753}]}
{"instance_id": "a1351834ca57", "generation_result": [{"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    avg_loss = 0\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(data_loader):\n            inputs = inputs.view(inputs.shape[0], -1)\n            if torch.cuda.is_available():\n                inputs = inputs.cuda()\n                labels = labels.cuda()\n            outputs = model(inputs)\n            outputs = outputs.view(outputs.shape[0], -1)\n            labels = labels.view(labels.shape[0], -1)\n            loss = criterion(outputs, labels)\n            avg_loss += loss.item()\n            if i == len(data_loader) - 1:\n                labels = labels.view(labels.shape[0], -1)\n                labels = labels.cpu().numpy()\n                labels = labels.reshape((labels.shape[0] * labels.shape[1], 1))\n                labels = np.argmax(labels, axis=1)\n                inputs = inputs.view(inputs.shape[0], -1)\n                inputs = inputs.cpu().numpy()\n                inputs = inputs.reshape((inputs.shape[0] * inputs.shape[1], 1))\n                embeddings = inputs\n                embeddings = embeddings.reshape((embeddings.shape[0], -1))\n                embeddings = embeddings.reshape((embeddings.shape[0], -1))\n                embeddings = embeddings.reshape((embeddings.shape[0], -1))\n                embeddings = embeddings.reshape((embeddings.shape[0], -1))\n                embeddings = embeddings.reshape((embeddings.shape[0], -1))\n                embeddings = embeddings.reshape((embeddings.shape[0], -1))\n                embeddings = embeddings.reshape((embeddings.shape[0], -1))\n                embeddings = embeddings.reshape((embeddings.shape[0], -1))\n                embeddings = embeddings.reshape((embeddings.shape[0], -1))\n                embeddings = embeddings.reshape((embeddings.shape[0], -", "CodeBleu_score": 32.1135571039705}, {"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    eval_loss = 0\n    for i, (inputs, labels) in enumerate(data_loader):\n        inputs = inputs.view(inputs.shape[0], -1)\n        labels = labels.view(labels.shape[0])\n        if torch.cuda.is_available():\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n        with torch.no_grad():\n            outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        eval_loss += loss.item()\n        if i == len(data_loader) - 1:\n            embeddings = outputs.detach().cpu().numpy()\n            labels = labels.cpu().numpy()\n            plot_embeddings(embeddings, labels, global_step)\n    eval_loss /= len(data_loader)\n    dashboard_logger.eval_stats(eval_loss, global_step)\n    return eval_loss\n\n", "CodeBleu_score": 33.94256762655843}, {"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    eval_loss = 0\n    for batch_idx, (inputs, labels) in enumerate(data_loader):\n        inputs = inputs.view(-1, 28 * 28)\n        labels = labels.view(-1)\n        inputs, labels = inputs.cuda(), labels.cuda()\n        with torch.no_grad():\n            outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        eval_loss += loss.item()\n        if batch_idx == len(data_loader) - 1:\n            embeddings = outputs.detach().cpu().numpy()\n            labels = labels.detach().cpu().numpy()\n            plot_embeddings(embeddings, labels, global_step)\n    eval_loss /= len(data_loader)\n    dashboard_logger.eval_stats(eval_loss, global_step)\n    return eval_loss\n\n", "CodeBleu_score": 30.948321766413155}]}
{"instance_id": "565f8ed09916", "generation_result": [{"code": "def register_config(model_name: str) -> Coqpit\n\t\n    config_class_name = f\"{model_name}_config\"\n    if model_name == \"xtts\":\n        from .xtts_config import XTTSConfig\n        return XTTSConfig\n    else:\n        try:\n            from .config import Coqpit\n            from .config import Config\n            config_class = Config.get_config_class(config_class_name)\n            return config_class\n        except ModuleNotFoundError as e:\n            raise ModuleNotFoundError(f\"Configuration class {config_class_name} not found for model {model_name}\") from e\n\n", "CodeBleu_score": 32.85121763001091}, {"code": "def register_config(model_name: str) -> Coqpit\n\t\n    config_name = model_name.title() + 'Config'\n    try:\n        if model_name == 'xtts':\n            from espnet2.bin.tts_inference import XTTSConfig\n            return XTTSConfig\n        else:\n            from espnet2.bin.tts_inference import TTSConfig\n            return TTSConfig\n    except ModuleNotFoundError as e:\n        raise ModuleNotFoundError(f'Failed to find configuration class for {model_name}') from e\n\n", "CodeBleu_score": 25.74202020597271}, {"code": "def register_config(model_name: str) -> Coqpit\n\t\n    config_name = model_name + \"Config\"\n    if model_name == \"xtts\":\n        try:\n            from xtts.config import XTTSConfig\n        except ModuleNotFoundError:\n            raise ModuleNotFoundError(\n                f\"Could not find the configuration class for model {model_name}.\"\n            )\n        return XTTSConfig\n    for path in [\n        \"models\",\n        \"models.tts\",\n        \"models.tts.hifigan\",\n        \"models.tts.fastspeech\",\n        \"models.tts.fastspeech.config\",\n        \"models.tts.fastspeech.config.v1\",\n        \"models.tts.fastspeech.config.v2\",\n        \"models.tts.fastspeech.config.v2.baker\",\n        \"models.tts.fastspeech.config.v2.baker.baker_v2_char\",\n        \"models.tts.fastspeech.config.v2.baker.baker_v2_word\",\n        \"models.tts.fastspeech.config.v2.baker.baker_v2_word.baker_v2_word_char\",\n        \"models.tts.fastspeech.config.v2.baker.baker_v2_word.baker_v2_word_phoneme\",\n        \"models.tts.fastspeech.config.v2.baker.baker_v2_word.baker_v2_word_pinyin\",\n        \"models.tts.fastspeech.config.v2.baker.baker_v2_word.baker_v2_word_pinyin_char\",\n        \"models.tts.fastspeech.config.v2.baker.baker_v2_word.baker_v2_word_pinyin_phoneme\",\n        \"models.tts.fastspeech.config.v2.baker.baker_v2_word.baker_v2_word_pinyin_phoneme_char\",\n        \"models.tts.fastspeech.", "CodeBleu_score": 26.2849012717214}]}
{"instance_id": "0ea7862506a7", "generation_result": [{"code": "def load_config(config_path: str) -> Coqpit\n\t\n    _, ext = splitext(config_path)\n    if ext == \".yaml\":\n        config_dict = yaml.safe_load(fsspec.open(config_path))\n    elif ext == \".json\":\n        config_dict = read_json_with_comments(config_path)\n    else:\n        raise TypeError(f\"Unknown config type: {ext}\")\n    model_name = _process_model_name(config_dict)\n    register_config(model_name)\n    config_class = config_registry.get(model_name)\n    config = config_class()\n    config.from_dict(config_dict)\n    return config", "CodeBleu_score": 41.99501611324447}, {"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = read_json_with_comments(config_path)\n    model_name = _process_model_name(config_dict)\n    register_config(model_name, config_class)\n    config = config_class()\n    config.from_dict(config_dict)\n    return config", "CodeBleu_score": 10.359569439607087}, {"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = read_json_with_comments(config_path)\n    model_name = _process_model_name(config_dict)\n    register_config(model_name)\n    config_class = config_dict.pop(\"_config_class\", model_name)\n    config = config_class()\n    config.from_dict(config_dict)\n    return config\n\n", "CodeBleu_score": 14.04082322126663}]}
{"instance_id": "e0db68b63143", "generation_result": [{"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n\n    # loop over the directory structure\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        # loop over the filenames in the current directory\n        for filename in filenames:\n            # if the contains string is not none and the filename does not contain\n            # the supplied string, then ignore the file\n            if contains is not None and filename.find(contains) == -1:\n                continue\n\n            # determine the file extension of the current file\n            ext = filename[filename.rfind(\".\"):].lower()\n\n            # check to see if the file is an image and should be processed\n            if validExts is None or ext.endswith(validExts):\n                # construct the path to the image and yield it\n                imagePath = os.path.join(rootDir, filename)\n                yield imagePath\n\n", "CodeBleu_score": 77.01394656986473}, {"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n\n    # loop over the directory structure\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        # loop over the filenames in the current directory\n        for filename in filenames:\n            # if the contains string is not none and the filename does not contain\n            # the supplied string, then ignore the file\n            if contains is not None and filename.find(contains) == -1:\n                continue\n\n            # determine the file extension of the current file\n            ext = filename[filename.rfind(\".\"):].lower()\n\n            # check to see if the file is an image and should be processed\n            if validExts is None or ext.endswith(validExts):\n                # construct the path to the image and yield it\n                imagePath = os.path.join(rootDir, filename)\n                yield imagePath\n\n", "CodeBleu_score": 77.01394656986473}, {"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        for filename in filenames:\n            if contains is not None and filename.find(contains) == -1:\n                continue\n            if validExts is None or filename.endswith(validExts):\n                yield os.path.join(rootDir, filename)\n\n", "CodeBleu_score": 55.21038111615264}]}
{"instance_id": "b836fcaf0a27", "generation_result": [{"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    clear_gpu_cache()\n    if xtts_checkpoint is None:\n        return \"XTTS checkpoint path is not provided\"\n    if xtts_config is None:\n        return \"XTTS config path is not provided\"\n    if xtts_vocab is None:\n        return \"XTTS vocab path is not provided\"\n    config = XttsConfig.load_json(xtts_config)\n    model = Xtts.init_from_config(config)\n    model.load_checkpoint(xtts_checkpoint, xtts_vocab)\n    if torch.cuda.is_available():\n        model.cuda()\n    print(\"Loaded XTTS model from checkpoint: {}\".format(xtts_checkpoint))\n    return \"Successfully loaded XTTS model from checkpoint: {}\".format(xtts_checkpoint)\n\n", "CodeBleu_score": 48.46824228735843}, {"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    clear_gpu_cache()\n    if xtts_checkpoint is None or xtts_config is None or xtts_vocab is None:\n        return \"Error: Please provide all the required paths for XTTS model.\"\n    config = XttsConfig.load_json(xtts_config)\n    xtts_model = Xtts.init_from_config(config, xtts_vocab)\n    xtts_model.load_checkpoint(xtts_checkpoint)\n    if torch.cuda.is_available():\n        xtts_model.cuda()\n    print(\"XTTS model loaded successfully.\")\n    return \"XTTS model loaded successfully.\"\n\n", "CodeBleu_score": 47.54710460245081}, {"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    clear_gpu_cache()\n    if xtts_checkpoint is None or xtts_config is None or xtts_vocab is None:\n        return \"Error: Please provide all required paths.\"\n    config = XttsConfig.load_json(xtts_config)\n    model = Xtts.init_from_config(config)\n    model.load_checkpoint(xtts_checkpoint, xtts_vocab)\n    if torch.cuda.is_available():\n        model = model.cuda()\n    print(\"Model loaded successfully.\")\n    return \"Model loaded successfully.\"\n\n", "CodeBleu_score": 45.09341517529841}]}
{"instance_id": "c5d63aa0df26", "generation_result": [{"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    # Adjust number of frames based on hop length\n    if self.hop_length is not None:\n        num_frames = int(num_frames * self.hop_length / self.sample_rate)\n    # Ensure number of frames does not exceed input length\n    num_frames = min(num_frames, x.shape[0])\n    # Calculate offset positions for evaluation\n    offsets = np.linspace(0, num_frames - 1, num_eval)\n    # Extract frames at these offsets\n    frames_batch = []\n    for offset in offsets:\n        frames_batch.append(x[int(offset):int(offset + num_frames)])\n    # Concatenate frames into a batch\n    frames_batch = torch.cat(frames_batch, dim=0)\n    # Perform inference to obtain embeddings\n    embeddings = self.inference(frames_batch)\n    # Compute the mean of the embeddings\n    if return_mean:\n        embeddings = torch.mean(embeddings, dim=0)\n    # Normalize embeddings with L2 norm\n    if l2_norm:\n        embeddings = F.normalize(embeddings, dim=-1)\n    return embeddings\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 50.51536834920386}, {"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    # Adjust number of frames based on hop length\n    num_frames = int(num_frames / self.hop_length)\n    # Compute offsets for evaluation\n    offsets = np.linspace(0, x.shape[0] - self.sample_rate * num_frames, num_eval)\n    # Extract frames at these offsets\n    frames_batch = []\n    for offset in offsets:\n        frames = x[int(offset) : int(offset + self.sample_rate * num_frames)]\n        frames_batch.append(frames)\n    # Concatenate frames into a batch\n    frames_batch = torch.cat(frames_batch, dim=0)\n    # Perform inference to obtain embeddings\n    embeddings = self.inference(frames_batch)\n    # Compute mean of embeddings and return result\n    if return_mean:\n        embeddings = torch.mean(embeddings, dim=0)\n        if l2_norm:\n            embeddings = F.normalize(embeddings, p=2, dim=-1)\n    return embeddings\n\n", "CodeBleu_score": 43.96766713678439}, {"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    hop_length = self.hop_length\n    if hop_length is not None:\n        num_frames = num_frames // hop_length\n    num_frames = min(num_frames, x.shape[1] // hop_length)\n    num_eval = min(num_eval, num_frames)\n    offsets = np.linspace(0, num_frames - 1, num_eval, dtype=np.int64) * hop_length\n    frames_batch = []\n    for i in range(num_eval):\n        frames = x[:, offsets[i]:offsets[i] + self.frame_length]\n        frames_batch.append(frames)\n    frames_batch = torch.cat(frames_batch, dim=0)\n    embeddings = self.inference(frames_batch)\n    if l2_norm:\n        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1)\n    if return_mean:\n        embeddings = torch.mean(embeddings, dim=0)\n    return embeddings\n\n", "CodeBleu_score": 49.9706297706513}]}
{"instance_id": "06f5b0335b26", "generation_result": [{"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(\n                self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False\n            ),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n    return nn.Sequential(*layers)\n\n", "CodeBleu_score": 83.24884053744397}, {"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n", "CodeBleu_score": 85.18641475692186}, {"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(\n                self.inplanes,\n                planes * block.expansion,\n                kernel_size=1,\n                stride=stride,\n                bias=False,\n            ),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n    return nn.Sequential(*layers)\n\n", "CodeBleu_score": 80.60103986256841}]}
{"instance_id": "9ac60597b633", "generation_result": [{"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    num_classes = len(embeddings)\n    num_utterances_per_class = [len(embeddings[i]) for i in range(num_classes)]\n    num_utterances_per_class = np.array(num_utterances_per_class)\n    num_utterances_per_class_sorted = np.sort(num_utterances_per_class)[::-1]\n    num_utterances_per_class_sorted_cumsum = np.cumsum(num_utterances_per_class_sorted)\n    num_classes_to_plot = np.sum(num_utterances_per_class_sorted_cumsum < num_classes_in_batch)\n    if num_classes_to_plot > 10:\n        num_utterances_per_class_sorted_cumsum = np.cumsum(num_utterances_per_class_sorted[:10])\n        num_classes_to_plot = 10\n    embeddings_to_plot = [embeddings[i] for i in range(num_classes) if num_utterances_per_class[i] in num_utterances_per_class_sorted_cumsum[:num_classes_to_plot]]\n    embeddings_to_plot = np.concatenate(embeddings_to_plot, axis=0)\n    embeddings_to_plot = np.repeat(embeddings_to_plot, num_utterances_per_class[:num_classes_to_plot], axis=0)\n    embeddings_to_plot = np.array(embeddings_to_plot)\n    embeddings_to_plot = embeddings_to_plot.reshape(-1, embeddings_to_plot.shape[-1])\n    embeddings_to_plot = umap.UMAP().fit_transform(embeddings_to_plot)\n    fig, ax = plt.subplots()\n    ax.scatter(embeddings_to_plot[:, 0], embeddings_to_plot[:, 1], c=np.arange(num_classes)[:num_classes_to_plot], cmap='jet')\n    ax.set", "CodeBleu_score": 37.39984915045117}, {"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    num_utterances_per_class = np.repeat(np.bincount(num_classes_in_batch), np.bincount(num_classes_in_batch))\n    num_classes = len(num_utterances_per_class)\n    if num_classes > 10:\n        num_utterances_per_class = num_utterances_per_class[:10]\n        num_classes = 10\n    model = umap.UMAP(n_components=2, min_dist=0.0, metric='correlation')\n    embeddings = model.fit_transform(embeddings)\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(embeddings[:, 0], embeddings[:, 1], c=num_classes_in_batch, cmap='Spectral', s=num_utterances_per_class,\n               edgecolor='none')\n    ax.set_title('UMAP projection')\n    ax.set_aspect('equal')\n    plt.tight_layout()\n    plt.savefig('umap.png')\n    return fig\n\n", "CodeBleu_score": 40.70101167519863}, {"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    # Calculate the number of utterances per class\n    num_utterances_per_class = np.repeat(embeddings.shape[0] // num_classes_in_batch, num_classes_in_batch)\n    # Limit the number of classes to 10 if necessary\n    num_classes_in_batch = min(num_classes_in_batch, 10)\n    # UMAP transforms the embeddings\n    reducer = umap.UMAP()\n    embeddings_umap = reducer.fit_transform(embeddings)\n    # Create a scatter plot with colors representing different classes\n    fig = plt.figure(figsize=(10, 10))\n    ax = plt.gca()\n    ax.scatter(embeddings_umap[:, 0], embeddings_umap[:, 1], c=np.repeat(np.arange(num_classes_in_batch), num_utterances_per_class))\n    plt.title(\"UMAP projection\")\n    set_aspect(\"equal\", \"datalim\")\n    plt.tight_layout()\n    plt.savefig(\"umap.png\")\n    return fig\n\n", "CodeBleu_score": 33.779852328159244}]}
{"instance_id": "19c2b4af256d", "generation_result": [{"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cos_sim_matrix = []\n    for i, (speaker, utterances) in enumerate(dvecs.items()):\n        new_centroids = self.calc_new_centroids(centroids, utterances)\n        for j, utterance in enumerate(utterances):\n            cs_row = []\n            for k, centroid in enumerate(new_centroids):\n                cos_sim = torch.mm(centroid, utterance) / (torch.norm(centroid) * torch.norm(utterance))\n                cos_sim = torch.clamp(cos_sim, min=0.0)\n                cs_row.append(cos_sim)\n            cs_row = torch.stack(cs_row)\n            cos_sim_matrix.append(cs_row)\n    cos_sim_matrix = torch.cat(cos_sim_matrix)\n    return cos_sim_matrix\n\n", "CodeBleu_score": 37.34000964790875}, {"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cos_sim_matrix = []\n    for speaker_id, speaker_dvecs in enumerate(dvecs):\n        new_centroids = self.calc_new_centroids(speaker_dvecs, centroids)\n        for i, (dvec, centroid) in enumerate(zip(speaker_dvecs, new_centroids.transpose(0, 1))):\n            cs_row = []\n            for j, new_centroid in enumerate(new_centroids):\n                if i == j:\n                    cs_row.append(1.0)\n                else:\n                    cos_sim = torch.mm(dvec.unsqueeze(0), new_centroid.unsqueeze(1)) / (torch.norm(dvec) * torch.norm(new_centroid))\n                    cs_row.append(cos_sim.item())\n            cos_sim_matrix.append(cs_row)\n    cos_sim_matrix = torch.stack(cos_sim_matrix)\n    cos_sim_matrix = torch.clamp(cos_sim_matrix, min=1e-6)\n    return cos_sim_matrix\n\n", "CodeBleu_score": 40.115940627305676}, {"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cos_sim_matrix = []\n    for i, (spk_id, spk_dvecs) in enumerate(dvecs.items()):\n        new_centroids = self.calc_new_centroids(spk_dvecs, centroids)\n        for j, (utt_id, dvec) in enumerate(spk_dvecs.items()):\n            cs_row = []\n            for new_centroid in new_centroids:\n                cos_sim = torch.mm(dvec.unsqueeze(0), new_centroid.transpose(0, 1)) / (\n                    torch.norm(dvec, dim=0) * torch.norm(new_centroid, dim=0)\n                )\n                cos_sim = torch.clamp(cos_sim, min=-1.0, max=1.0)\n                cs_row.append(cos_sim)\n            cos_sim_matrix.append(torch.cat(cs_row))\n    cos_sim_matrix = torch.stack(cos_sim_matrix)\n    return cos_sim_matrix\n\n", "CodeBleu_score": 41.63626202504773}]}
{"instance_id": "c525b411a1e7", "generation_result": [{"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    losses = []\n    for dvec in dvecs:\n        dvec_losses = -F.log_softmax(cos_sim_matrix[dvec], dim=0)\n        losses.append(dvec_losses)\n    return torch.stack(losses)\n\n\n def embed_loss_softmax_batch(self, dvecs, cos_sim_matrix):\n    \"\"\"The function calculates the embedding loss using softmax.", "CodeBleu_score": 27.069727613774642}, {"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    losses = []\n    for i in range(len(dvecs)):\n        loss = F.log_softmax(cos_sim_matrix[i], dim=0)\n        losses.append(loss)\n    return torch.stack(losses)\n\n\n def embed_loss_mse(self, dvecs, cos_sim_matrix):\n    \"\"\"The function calculates the embedding loss using MSE.", "CodeBleu_score": 34.28594921283252}, {"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    losses = []\n    for i in range(dvecs.shape[0]):\n        losses.append(F.log_softmax(cos_sim_matrix[i], dim=0))\n    return torch.stack(losses)\n\n\n def embed_loss_cross_entropy(self, dvecs, cos_sim_matrix):\n    \"\"\"The function calculates the embedding loss using cross entropy.", "CodeBleu_score": 29.348225956972907}]}
{"instance_id": "25ac3945da2e", "generation_result": [{"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    L_row = []\n    for i, dvec in enumerate(dvecs):\n        dvec_cos_sim_matrix = cos_sim_matrix[i]\n        dvec_cos_sim_matrix[i] = -100\n        dvec_sigmoid = torch.sigmoid(dvec_cos_sim_matrix)\n        dvec_contrast_loss = torch.sum(dvec_sigmoid)\n        L_row.append(dvec_contrast_loss)\n    L = torch.stack(L_row)\n    return L\n\n", "CodeBleu_score": 27.055793203102724}, {"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    losses_row = []\n    for i in range(len(dvecs)):\n        dvec = dvecs[i]\n        cos_sim_matrix_i = cos_sim_matrix[i]\n        cos_sim_matrix_i[i] = -100\n        sigmoid_cos_sim_matrix_i = torch.sigmoid(cos_sim_matrix_i)\n        contrast_loss = -torch.log(sigmoid_cos_sim_matrix_i)\n        contrast_loss = torch.mean(contrast_loss)\n        losses_row.append(contrast_loss)\n    losses = torch.stack(losses_row)\n    return losses\n\n", "CodeBleu_score": 31.02210041449711}, {"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    L_row = []\n    for i in range(len(dvecs)):\n        dvec = dvecs[i]\n        cos_sim_matrix_i = cos_sim_matrix[i]\n        cos_sim_matrix_i_exclude_current_centroid = cos_sim_matrix_i[\n            torch.arange(len(dvecs)), torch.arange(len(dvecs)) != i\n        ]\n        sigmoid_cos_sim_matrix_i_exclude_current_centroid = torch.sigmoid(\n            cos_sim_matrix_i_exclude_current_centroid\n        )\n        contrast_loss = torch.mean(\n            torch.log(1 + torch.exp(sigmoid_cos_sim_matrix_i_exclude_current_centroid))\n        )\n        L_row.append(contrast_loss)\n    return torch.stack(L_row)\n\n", "CodeBleu_score": 31.36267938420784}]}
{"instance_id": "878d14ffabd2", "generation_result": [{"code": "def forward(self, x, _label=None)\n\t\n    assert x.size(1) >= 2, \"The input must have at least two utterances per speaker.\"\n    num_speakers = x.size(0)\n    num_utts_per_speaker = x.size(1)\n    dvec_feats = x.size(2)\n    x = x.view(-1, dvec_feats)\n    x = self.embed(x)\n    x = x.view(num_speakers, num_utts_per_speaker, -1)\n    centroids = torch.mean(x, dim=1)\n    sim_matrix = self.calc_cosine_sim(x, centroids)\n    sim_matrix = self.scale * sim_matrix + self.shift\n    sim_matrix = torch.clamp(sim_matrix, min=0.0, max=1.0)\n    sim_matrix = sim_matrix.view(-1)\n    label = torch.LongTensor(range(num_speakers)).to(x.device)\n    loss = self.embed_loss(sim_matrix, label)\n    return loss\n\n", "CodeBleu_score": 38.06998143347427}, {"code": "def forward(self, x, _label=None)\n\t\n    # Check input dimensions\n    assert x.size(1) >= 2, \"GE2E loss requires at least two utterances per speaker\"\n    # Compute centroids\n    centroids = x.mean(dim=1)\n    # Compute similarity matrix\n    sim_matrix = self.calc_cosine_sim(x, centroids)\n    # Scale and shift similarity matrix\n    sim_matrix = self.scale_and_shift(sim_matrix)\n    # Compute embedding loss\n    loss = self.embed_loss(sim_matrix, _label)\n    return loss\n\n", "CodeBleu_score": 43.72657075748606}, {"code": "def forward(self, x, _label=None)\n\t\n    x = x.view(-1, x.size(2))\n    x = self.embed(x)\n    x = x.view(self.num_speakers, -1, x.size(1))\n    centroids = x.mean(dim=1, keepdim=True)\n    sim_mat = self.calc_cosine_sim(x, centroids)\n    sim_mat = torch.clamp(sim_mat, min=-1, max=1)\n    sim_mat = self.scale * sim_mat + self.shift\n    sim_mat = torch.exp(sim_mat)\n    sim_mat = sim_mat / torch.sum(sim_mat, dim=1, keepdim=True)\n    self.embed_loss = -torch.log(sim_mat[:, 0]).mean()\n    return self.embed_loss\n\n", "CodeBleu_score": 41.93102733194015}]}
{"instance_id": "86a364c72caa", "generation_result": [{"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\t\n    voices = {}\n    for voice_dir in [\"./voices\"] + extra_voice_dirs:\n        for dirpath, dirnames, filenames in os.walk(voice_dir):\n            if len(filenames) == 0:\n                continue\n            if dirpath not in voices:\n                voices[dirpath] = []\n            for filename in filenames:\n                if filename.endswith(\".npz\"):\n                    voices[dirpath].append(os.path.join(dirpath, filename))\n                elif filename.endswith(\".wav\") or filename.endswith(\".mp3\"):\n                    voices[dirpath].append(os.path.join(dirpath, filename))\n    return voices\n\n", "CodeBleu_score": 28.375888974363384}, {"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\t\n    voices = {}\n    for dir_name in [\"voices\", \"voices_extra\"] + extra_voice_dirs:\n        for root, dirs, files in os.walk(dir_name):\n            if len(files) > 0:\n                voices[root] = [os.path.join(root, file) for file in files]\n    return voices\n\n", "CodeBleu_score": 21.8374589516204}, {"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\t\n    extra_voice_dirs = [os.path.abspath(extra_voice_dir) for extra_voice_dir in extra_voice_dirs]\n    extra_voice_dirs = [extra_voice_dir for extra_voice_dir in extra_voice_dirs if os.path.isdir(extra_voice_dir)]\n    extra_voice_dirs = [extra_voice_dir for extra_voice_dir in extra_voice_dirs if len(os.listdir(extra_voice_dir)) > 0]\n\n    voice_dirs = [os.path.abspath(voice_dir) for voice_dir in voice_dirs]\n    voice_dirs = [voice_dir for voice_dir in voice_dirs if os.path.isdir(voice_dir)]\n    voice_dirs = [voice_dir for voice_dir in voice_dirs if len(os.listdir(voice_dir)) > 0]\n\n    voice_dirs.extend(extra_voice_dirs)\n    voice_dirs = [voice_dir for voice_dir in voice_dirs if len(os.listdir(voice_dir)) > 0]\n\n    voice_files = {}\n    for voice_dir in voice_dirs:\n        voice_files[voice_dir] = []\n        for root, dirs, files in os.walk(voice_dir):\n            for file in files:\n                if file.endswith(\".npz\") or file.endswith(\".wav\") or file.endswith(\".mp3\"):\n                    voice_files[voice_dir].append(os.path.join(root, file))\n        if len(voice_files[voice_dir]) == 0:\n            for root, dirs, files in os.walk(voice_dir):\n                for file in files:\n                    if file.endswith(\".wav\") or file.endswith(\".mp3\"):\n                        voice_files[voice_dir].append(os.path.join(root, file))\n\n    return voice_files\n\n", "CodeBleu_score": 28.75520030072809}]}
{"instance_id": "02f20c8917e6", "generation_result": [{"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t\n    # Get the voice paths\n    voice_paths = get_voices(model, voice, extra_voice_dirs)\n\n    # If the voice is \"random\", return None for all values\n    if voice == \"random\":\n        return None, None, None, None\n\n    # If there are multiple voice paths, raise an error\n    if len(voice_paths) > 1:\n        raise ValueError(\n            f\"Multiple voices found for model {model} and voice {voice}. Please specify the voice path explicitly.\"\n        )\n\n    # If there are no voice paths, raise an error\n    if len(voice_paths) == 0:\n        raise ValueError(\n            f\"No voices found for model {model} and voice {voice}. Please specify the voice path explicitly or add the voice to the model's directory.\"\n        )\n\n    # Get the voice path\n    voice_path = voice_paths[0]\n\n    # Check if the voice path ends with \".npz\"\n    if voice_path.endswith(\".npz\"):\n        # Load the voice data from the .npz file\n        voice_data = load_npz(voice_path)\n    else:\n        # Generate a .npz file for the voice and recursively load the voice\n        voice_data = generate_voice(model, voice_path)\n\n    # Return the loaded voice data\n    return voice_data\n\n", "CodeBleu_score": 41.375884631396815}, {"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t\n    if voice == \"random\":\n        return None\n    voice_paths = get_voices(model, voice, extra_voice_dirs)\n    if len(voice_paths) == 0:\n        raise KeyError(f\"Voice {voice} not found for model {model}\")\n    if len(voice_paths) > 1:\n        raise ValueError(f\"Multiple voices found for model {model} and voice {voice}: {voice_paths}\")\n    voice_path = voice_paths[0]\n    if voice_path.endswith(\".npz\"):\n        return load_npz(voice_path)\n    else:\n        npz_path = generate_voice(model, voice, voice_path)\n        return load_npz(npz_path)\n\n", "CodeBleu_score": 41.99560658421297}, {"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t\n    voice_paths = get_voices(model, voice, extra_voice_dirs)\n    if voice == \"random\":\n        return None, None, None, None\n    if len(voice_paths) > 1:\n        raise KeyError(f\"Multiple voices found for {voice}\")\n    if len(voice_paths) == 0:\n        raise KeyError(f\"No voice found for {voice}\")\n    voice_path = voice_paths[0]\n    if voice_path.endswith(\".npz\"):\n        return load_npz(voice_path)\n    else:\n        voice_path_npz = voice_path.replace(splitext(voice_path)[1], \".npz\")\n        generate_voice(voice_path, voice_path_npz)\n        return load_voice(model, voice_path_npz)\n\n", "CodeBleu_score": 44.19189678389716}]}
{"instance_id": "9458e981389f", "generation_result": [{"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, num_heads, seq_len, _ = pos_score.size()\n    zeros = torch.zeros((batch_size, num_heads, seq_len, 1), device=pos_score.device)\n    padded_pos_score = torch.cat([zeros, pos_score], dim=-1)\n    padded_pos_score = padded_pos_score.view(batch_size, num_heads, seq_len + 1, seq_len)\n    pos_score = padded_pos_score[:, :, :seq_len, :seq_len]\n    return pos_score\n\n", "CodeBleu_score": 50.02876304464103}, {"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, num_heads, seq_length, _ = pos_score.size()\n    zeros = torch.zeros((batch_size, num_heads, seq_length, 1), device=pos_score.device)\n    padded_pos_score = torch.cat([pos_score, zeros], dim=-1)\n    padded_pos_score = padded_pos_score.view(batch_size, num_heads, seq_length + 1, seq_length)\n    pos_score = padded_pos_score[:, :, :seq_length, :seq_length]\n    return pos_score\n\n", "CodeBleu_score": 49.020651190523594}, {"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, num_heads, seq_length = pos_score.size()\n    zeros = torch.zeros((batch_size, num_heads, 1), device=pos_score.device)\n    padded_pos_score = torch.cat([pos_score, zeros], dim=-1)\n    padded_pos_score = padded_pos_score.view(batch_size, num_heads, seq_length + 1, 2)\n    pos_score = padded_pos_score[:, :, :, 1:].view_as(pos_score)\n    return pos_score", "CodeBleu_score": 47.22459326513429}]}
{"instance_id": "c046d4f00e80", "generation_result": [{"code": "def run_padded_sequence(self, context, lens)\n\t\n    context_embedded = []\n    for i in range(len(context)):\n        context_embedded.append(self.embedding(context[i]))\n    context_embedded = pad_sequence(context_embedded, batch_first=True)\n    context_embedded = context_embedded[:, :, :self.size]\n    context_embedded = self.dropout(context_embedded)\n    for conv in self.convs:\n        context_embedded = F.relu(conv(context_embedded))\n        context_embedded = self.dropout(context_embedded)\n    context_embedded = pad_sequence(\n        [context_embedded[i, :lens[i], :] for i in range(len(context))], batch_first=True)\n    return context_embedded", "CodeBleu_score": 37.95426078079976}, {"code": "def run_padded_sequence(self, context, lens)\n\t\n    # Process each batch element in the padded sequence\n    for i in range(context.size(0)):\n        # Extract the context up to the specified length\n        context_embedded = context[i, :lens[i]]\n        # Apply the convolutional layers with ReLU activation and dropout\n        context_embedded = self.dropout(F.relu(self.conv(context_embedded)))\n        # Store the results\n        self.context_embedded.append(context_embedded)\n    # Pad the processed contexts to create a consistent batch size\n    context_embedded = pad_sequence(self.context_embedded, batch_first=True)\n    # Clear the context_embedded list for the next batch\n    self.context_embedded = []\n    # Return the padded sequence\n    return context_embedded", "CodeBleu_score": 29.518526986743694}, {"code": "def run_padded_sequence(self, context, lens)\n\t\n    context_embedded = []\n    for i in range(len(context)):\n        context_embedded.append(self.embed(context[i][:lens[i]]))\n    context_embedded = torch.nn.utils.rnn.pad_sequence(context_embedded, batch_first=True)\n    context_embedded = context_embedded.transpose(1, 2)\n    context_embedded = self.dropout(context_embedded)\n    for conv in self.convs:\n        context_embedded = F.relu(conv(context_embedded))\n    return context_embedded\n\n", "CodeBleu_score": 39.87063528660444}]}
{"instance_id": "db2644f3c681", "generation_result": [{"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    lens_sorted, lens_indices = torch.sort(lens, descending=True)\n    context = context[lens_indices]\n    context = pack_padded_sequence(context, lens_sorted.long(), batch_first=True)\n    context = fn(context)\n    context, _ = pad_packed_sequence(context, batch_first=True)\n    context = context[range(len(lens)), lens_indices]\n    return context", "CodeBleu_score": 18.631145218241567}, {"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    lens_sorted, indices = torch.sort(lens, descending=True)\n    packed_context = pack_padded_sequence(context[indices], lens_sorted, batch_first=True)\n    packed_result = fn(packed_context)\n    result, _ = pad_packed_sequence(packed_result, batch_first=True)\n    return result[torch.argsort(indices)]\n\n", "CodeBleu_score": 13.120624872185022}, {"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    # Sort the lengths in descending order\n    lens_sorted, lens_idx = torch.sort(lens, descending=True)\n    # Pack the context sequences based on the sorted lengths\n    context_sorted = torch.nn.utils.rnn.pack_padded_sequence(context[lens_idx], lens_sorted, batch_first=True)\n    # Apply the function on the sorted context\n    output = fn(context_sorted)\n    # Unpack the sequences and map the results back to the original order\n    output_sorted, _ = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n    output_sorted = output_sorted[torch.argsort(lens_idx)]\n    return output_sorted", "CodeBleu_score": 18.27446323149661}]}
{"instance_id": "ced082bffc63", "generation_result": [{"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    self.convt_pre.remove_parametrizations()\n    for block in self.conv_blocks:\n        block.remove_parametrizations()\n\n", "CodeBleu_score": 36.39504072468004}, {"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    self.convt_pre.remove_parametrizations()\n    for conv_block in self.conv_blocks:\n        conv_block.remove_parametrizations()\n\n", "CodeBleu_score": 30.370495563205314}, {"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    self.convt_pre.remove_parametrizations()\n    for block in self.conv_blocks:\n        block.remove_parametrizations()\n\n", "CodeBleu_score": 36.39504072468004}]}
{"instance_id": "b5a39fd97061", "generation_result": [{"code": "def map_mx_to_torch_model(mx_name)\n\t\n    torch_name = mx_name.lower()\n    if torch_name.startswith('se_'):\n        torch_name = torch_name.replace('se_', '')\n    if torch_name.startswith('senet_'):\n        torch_name = torch_name.replace('senet_', '')\n    if torch_name.startswith('inceptionv3'):\n        torch_name = torch_name.replace('inceptionv3', 'inception_v3')\n    torch_name = 'gluon_' + torch_name\n    return torch_name", "CodeBleu_score": 71.604002349494}, {"code": "def map_mx_to_torch_model(mx_name)\n\t\n    torch_name = mx_name.lower()\n    if torch_name.startswith('se_'):\n        torch_name = torch_name[3:]\n    elif torch_name.startswith('senet_'):\n        torch_name = torch_name[6:]\n    elif torch_name == 'inceptionv3':\n        torch_name = 'inception_v3'\n    return 'gluon_' + torch_name\n\n", "CodeBleu_score": 43.884299498444804}, {"code": "def map_mx_to_torch_model(mx_name)\n\t\n    torch_name = mx_name.lower()\n    torch_name = torch_name.replace('se_', 'se-')\n    torch_name = torch_name.replace('senet_', 'se-')\n    torch_name = torch_name.replace('inceptionv3', 'inception-v3')\n    torch_name = 'gluon_' + torch_name\n    return torch_name\n\n", "CodeBleu_score": 46.25347070075858}]}
{"instance_id": "7eee5efdbf67", "generation_result": [{"code": "def _num_samples_per_worker(self)\n\t\n    num_samples = self._num_samples\n    if self.repeats > 0:\n        num_samples = num_samples * self.repeats\n    if self.num_workers > 0:\n        num_samples = int(math.ceil(num_samples / self.num_workers))\n    if self.batch_size is not None:\n        num_samples = int(math.ceil(num_samples / self.batch_size)) * self.batch_size\n    return num_samples\n\n", "CodeBleu_score": 37.83399480621991}, {"code": "def _num_samples_per_worker(self)\n\t\n    if self.repeats is None:\n        return math.ceil(self.total / self.num_workers)\n    else:\n        return math.ceil((self.repeats * self.total) / self.num_workers)\n\n", "CodeBleu_score": 12.455765387504673}, {"code": "def _num_samples_per_worker(self)\n\t\n    num_samples = self.repeats * self.total_samples\n    if self.num_workers > 0:\n        num_samples = math.ceil(num_samples / self.num_workers)\n    if self.batch_size is not None:\n        num_samples = max(num_samples, self.batch_size)\n    return int(num_samples)", "CodeBleu_score": 34.351312990564516}]}
{"instance_id": "a698d65ae190", "generation_result": [{"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    if class_to_idx is None:\n        unique_labels = set()\n        labels = []\n        filenames = []\n        for root, subdirs, files in os.walk(folder, topdown=True):\n            rel_path = os.path.relpath(root, folder) if (\n                leaf_name_only) else root\n            rel_path = rel_path.replace(os.path.sep, '/')\n            for f in files:\n                base, ext = os.path.splitext(f)\n                if types is not None:\n                    ext = ext.lower()\n                    if ext not in types:\n                        continue\n                labels.append(rel_path)\n                filenames.append(os.path.join(root, f))\n                unique_labels.add(rel_path)\n\n        # assign an (arbitrary) ordering to object classes\n        if class_to_idx is None:\n            # Here, we assign the idx (starting from 0) to the classes in the dataset\n            # according to the lexicographic order of the classes\n            # [IMPORTANT]\n            # In the case you train a model which will be used in a different dataset, for example,\n            # your model will be trained on Imagenet dataset and you will use it to predict dog images\n            # on your custom dataset. In this case, the mapping between the current dataset\n            # and Imagenet will be changed. Therefore, we can use the mapping that we've prepared in advance and\n            # load it from a file\n            # unique_labels must be sorted before assigning indices (for stability)\n            idx2class = {idx: class_name for idx,\n                         class_name in enumerate(sorted(unique_labels))}\n            class_to_idx = {class_name: idx for idx,\n                            class_name in idx2class.items()}\n        elif sort:\n            # sort by indices if given mapping is not in order\n            labels, filenames = zip(*sorted(\n                zip(labels, filenames), key=lambda k: class_to_idx[k[0]]))\n    else:\n        # check that the fold exists\n        dirs = set(", "CodeBleu_score": 49.83420622841476}, {"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n\n    if class_to_idx is None:\n        unique_labels = set()\n        labels = []\n        filenames = []\n        for root, subdirs, files in os.walk(folder, topdown=True):\n            rel_path = os.path.relpath(root, folder) if (\n                (leaf_name_only) and (rel_path := os.path.relpath(root, folder))\n            ) else rel_path\n            for f in files:\n                base, ext = os.path.splitext(f)\n                if types is not None:\n                    ext = ext.lower()\n                    if ext not in types:\n                        continue\n                labels.append(rel_path)\n                filenames.append(os.path.join(rel_path, f))\n                unique_labels.add(rel_path)\n\n        # assign an (arbitrary) integer to each unique label (and thus class)\n        classes = list(sorted(unique_labels))\n        class_to_idx = {cls_name: idx\n                        for idx, cls_name in enumerate(classes)}\n\n    elif class_to_idx is not None:\n        labels = []\n        filenames = []\n        for root, subdirs, files in os.walk(folder, topdown=True):\n            rel_path = os.path.relpath(root, folder) if (\n                (leaf_name_only) and (rel_path := os.path.relpath(root, folder))\n            ) else rel_path\n            for f in files:\n                base, ext = os.path.splitext(f)\n                if types is not None:\n                    ext = ext.lower()\n                    if ext not in types:\n                        continue\n                labels.append(class_to_idx[rel_path])\n                filenames.append(os.path.join(rel_path, f))\n\n    if sort:\n        filenames, labels = zip(\n            *sorted(zip(filenames, labels), key=lambda fn_lbl: fn_lbl[0]))\n\n    return filenames, labels, class_to_idx\n\n", "CodeBleu_score": 45.08129216916824}, {"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    if class_to_idx is None:\n        unique_labels = set()\n        labels = []\n        filenames = []\n        for root, subdirs, files in os.walk(folder):\n            for filename in files:\n                file_path = os.path.join(root, filename)\n                if leaf_name_only:\n                    file_path = os.path.relpath(file_path, folder)\n                if types is not None:\n                    ext = splitext(filename)[1].lower()\n                    if ext not in types:\n                        continue\n                filenames.append(file_path)\n                label = basename(root)\n                if label not in unique_labels:\n                    unique_labels.add(label)\n                    labels.append(label)\n        labels.sort()\n        class_to_idx = {cls_label: idx for idx, cls_label in enumerate(labels)}\n    elif class_to_idx is not None:\n        if not isinstance(class_to_idx, dict):\n            raise TypeError(\"class_to_idx must be a dictionary\")\n        labels = [class_to_idx[i] for i in class_to_idx]\n    else:\n        raise ValueError(\"class_to_idx must be a dictionary mapping class names to class indices\")\n\n    img_paths = []\n    for root, _, files in os.walk(folder):\n        for filename in files:\n            file_path = os.path.join(root, filename)\n            if leaf_name_only:\n                file_path = os.path.relpath(file_path, folder)\n            if types is not None:\n                ext = splitext(filename)[1].lower()\n                if ext not in types:\n                    continue\n            img_paths.append(file_path)\n\n    if sort:\n        img_paths.sort(key=natural_key)\n\n    img_targets = [class_to_idx[basename(path)] for path in img_paths]\n\n    return img_paths, img_targets, class_to_idx\n\n", "CodeBleu_score": 39.449189115448895}]}
{"instance_id": "e7fe43bdecdc", "generation_result": [{"code": "def pytorch_worker_seed()\n\t\n    worker_info = get_worker_info()\n    if worker_info is not None:\n        seed = worker_info.seed\n    else:\n        seed = (torch.initial_seed() % 2 ** 32) - 1\n    return seed\n\n", "CodeBleu_score": 53.20959597997573}, {"code": "def pytorch_worker_seed()\n\t\n    worker_info = get_worker_info()\n    if worker_info is not None:\n        seed = worker_info.seed\n    else:\n        seed = get_wds_rank()\n    return seed\n\n", "CodeBleu_score": 56.27282949609004}, {"code": "def pytorch_worker_seed()\n\t\n    worker_info = get_worker_info()\n    if worker_info is not None:\n        seed = worker_info.seed\n    else:\n        seed = torch.initial_seed() % 2 ** 32\n        seed = (seed + torch.cuda.current_device()) % 2 ** 32\n        seed = (seed + torch.distributed.get_rank()) % 2 ** 32\n    return seed", "CodeBleu_score": 49.69435067903715}]}
{"instance_id": "0ffc7e7ded25", "generation_result": [{"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    img = img.convert(\"L\")\n    lut = []\n    for i in range(256):\n        lut.append(min(255, i + add) if i < thresh else i)\n    img.point(lut, \"L\")\n    return img\n\n", "CodeBleu_score": 35.42264854832654}, {"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    lut = [0] * 256\n    for i in range(256):\n        lut[i] = 255 if i < thresh else i + add\n    return img.point(lut)\n\n", "CodeBleu_score": 21.016457841287945}, {"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    lut = [i + add if i < thresh else i for i in range(256)]\n    return img.point(lut)\n\n", "CodeBleu_score": 10.437853308879575}]}
{"instance_id": "5a0d29577a21", "generation_result": [{"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    transform_names, transform_weights = zip(*transforms.items())\n    transform_weights = np.array(transform_weights) / np.sum(transform_weights)\n    return transform_names, transform_weights\n\n", "CodeBleu_score": 27.06064657505982}, {"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    transforms_list = list(transforms.items())\n    transform_names, transform_probs = zip(*transforms_list)\n    transform_probs = np.array(transform_probs) / np.sum(transform_probs)\n    return transform_names, transform_probs\n\n", "CodeBleu_score": 21.032602298754473}, {"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    transform_names, transform_probs = zip(*transforms.items())\n    transform_probs = np.array(transform_probs) / np.sum(transform_probs)\n    return transform_names, transform_probs\n\n", "CodeBleu_score": 30.110471671460658}]}
{"instance_id": "84bc5658c135", "generation_result": [{"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros(img.size)\n    for i, weight in enumerate(mixing_weights):\n        mixed += weight * _apply_ops(self, img, m)\n    mixed = np.clip(mixed, 0, 255)\n    mixed = mixed.astype(np.uint8)\n    mixed = Image.fromarray(mixed)\n    return Image.blend(img, mixed, m)\n\n", "CodeBleu_score": 23.044521632834076}, {"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros(img.size)\n    for i in range(len(mixing_weights)):\n        mixed += mixing_weights[i] * np.asarray(\n            img.getbands()[randint(0, len(img.getbands()) - 1)]\n        ) * m(img)\n    mixed = np.clip(mixed, 0, 255)\n    mixed = mixed.astype(np.uint8)\n    mixed = Image.fromarray(mixed)\n    return Image.blend(img, mixed, 0.5)\n\n", "CodeBleu_score": 28.71219465594219}, {"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros((img.size[1], img.size[0], 3))\n    for w in mixing_weights:\n        ops = []\n        for i in range(m):\n            ops.append(self.operations[randint(0, len(self.operations) - 1)])\n        for op in ops:\n            img = op(img)\n        mixed += w * np.asarray(img)\n    mixed = np.clip(mixed, 0, 255)\n    mixed = mixed.astype(np.uint8)\n    mixed = Image.fromarray(mixed)\n    return Image.blend(img, mixed, m)\n\n", "CodeBleu_score": 34.37090793862897}]}
{"instance_id": "84b5b752ff04", "generation_result": [{"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance(x, (tuple, list)):\n        x = tuple(repeat(x, n))\n    elif len(x) != n:\n        _logger.warning(f\"x has {len(x)} channels, but n is {n}. Using mean of x.\")\n        x = tuple(repeat(np.mean(x), n))\n    assert len(x) == n\n    return x", "CodeBleu_score": 51.30821468956732}, {"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance(x, (tuple, list)):\n        x = repeat(x, n)\n    elif len(x) != n:\n        _logger.warning(f\"The length of x ({len(x)}) does not match the required number of channels ({n}). Calculating the mean of x and repeating it {n} times.\")\n        x = repeat(np.mean(x), n)\n    assert len(x) == n\n    return x\n\n", "CodeBleu_score": 41.529108290976936}, {"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance(x, (tuple, list)):\n        x = repeat(x, n)\n    elif len(x) != n:\n        _logger.warning(f\"Expected {n} channels, got {len(x)}. Calculating mean.\")\n        x = repeat(np.mean(x), n)\n    assert len(x) == n, f\"Expected {n} channels, got {len(x)}\"\n    return x\n\n", "CodeBleu_score": 41.32338709762519}]}
{"instance_id": "54754b6ba394", "generation_result": [{"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    worker_info = get_worker_info()\n    assert worker_info is not None\n    assert isinstance(worker_info.seed, int)\n    assert isinstance(worker_id, int)\n    if worker_seeding == 'all':\n        seed = worker_info.seed\n        random.seed(seed)\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n    elif callable(worker_seeding):\n        seed = worker_seeding(worker_id)\n        random.seed(seed)\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n    else:\n        raise ValueError(f'worker_seeding must be a string or callable, got {worker_seeding}')\n\n", "CodeBleu_score": 42.72222720082869}, {"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    worker_info = get_worker_info()\n    if worker_info is None:\n        return\n    worker_id = worker_info.id\n    if worker_seeding == 'all':\n        worker_seed = worker_info.seed\n        numpy.random.seed(worker_seed)\n        torch.manual_seed(worker_seed)\n        random.seed(worker_seed)\n    elif isinstance(worker_seeding, Callable):\n        worker_seed = worker_seeding(worker_id)\n        numpy.random.seed(worker_seed)\n        torch.manual_seed(worker_seed)\n        random.seed(worker_seed)\n    elif isinstance(worker_seeding, str):\n        worker_seed = seed(worker_id)\n        numpy.random.seed(worker_seed)\n    else:\n        raise ValueError('worker_seeding must be a callable, a string, or None')\n\n", "CodeBleu_score": 46.10291807627275}, {"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    worker_info = get_worker_info()\n    if worker_info is None:\n        return\n    if worker_seeding == 'all':\n        seed = worker_info.seed\n        random.seed(seed)\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n    elif isinstance(worker_seeding, str):\n        seed = worker_info.seed\n        np.random.seed(seed)\n    elif isinstance(worker_seeding, callable):\n        worker_seeding(worker_id)\n    else:\n        raise ValueError(f'Invalid worker_seeding: {worker_seeding}')\n\n", "CodeBleu_score": 43.42674560639935}]}
{"instance_id": "81dfdce940db", "generation_result": [{"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    shape = extract_jpeg_shape(image_bytes)\n    padded_center_crop_size = tf.cast(\n        ((image_size / (shape[0] / tf.cast(shape[1], tf.float32))) + 3) / 4 * 4, tf.int32\n    )\n    offset_height = ((shape[0] - padded_center_crop_size) + 1) // 2\n    offset_width = ((shape[1] - padded_center_crop_size) + 1) // 2\n    crop_window = tf.stack([offset_height, offset_width, padded_center_crop_size, padded_center_crop_size])\n    image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n    image = resize(image, image_size, resize_method)\n    return image\n\n", "CodeBleu_score": 44.21199478899428}, {"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    shape = extract_jpeg_shape(image_bytes)\n    padded_center_crop_size = tf.cast(\n        ((image_size / (shape[0] + image_size)) / 2) * tf.cast(shape, tf.float32), tf.int32)\n    offset_height = ((shape[0] - padded_center_crop_size) + 1) // 2\n    offset_width = ((shape[1] - padded_center_crop_size) + 1) // 2\n    crop_window = tf.stack([offset_height, offset_width, padded_center_crop_size, padded_center_crop_size])\n    image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n    return resize(image, image_size, resize_method)\n", "CodeBleu_score": 43.11533389833738}, {"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    image_shape = extract_jpeg_shape(image_bytes)\n    padded_center_crop_size = tf.cast(\n        ((image_size / (image_size + PADDING)) *\n         tf.cast(tf.minimum(image_shape[0], image_shape[1]), tf.float32)),\n        tf.int32)\n    offset_height = ((image_shape[0] - padded_center_crop_size) + 1) // 2\n    offset_width = ((image_shape[1] - padded_center_crop_size) + 1) // 2\n    crop_window = tf.stack([offset_height, offset_width, padded_center_crop_size, padded_center_crop_size])\n    image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n    image = resize(image, image_size, resize_method)\n    return image\n\n", "CodeBleu_score": 46.51494094927958}]}
{"instance_id": "cf16a6d37111", "generation_result": [{"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_random_crop(image_bytes, image_size, image_size, interpolation)\n    image = _flip(image)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)\n    return image", "CodeBleu_score": 42.79454114538158}, {"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    dtype = tf.bfloat16 if use_bfloat16 else tf.float32\n    image = _decode_and_random_crop(image_bytes, image_size, image_size, interpolation)\n    image = _flip(image)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = convert_image_dtype(image, dtype=dtype)\n    return image\n\n", "CodeBleu_score": 35.91840059397849}, {"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    dtype = tf.bfloat16 if use_bfloat16 else tf.float32\n    image = _decode_and_random_crop(image_bytes, image_size, image_size, interpolation)\n    image = _flip(image)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = convert_image_dtype(image, dtype)\n    return image\n\n", "CodeBleu_score": 35.698573738058606}]}
{"instance_id": "78b2a3bd2142", "generation_result": [{"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = tf.image.decode_image(image_bytes, channels=3)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, image_size, method=interpolation)\n    image = tf.image.convert_image_dtype(image, tf.bfloat16 if use_bfloat16 else tf.float32)\n    image = tf.reshape(image, [1, image_size[0], image_size[1], 3])\n    return image\n\n", "CodeBleu_score": 32.37185623496524}, {"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = tf.io.decode_image(image_bytes, channels=3)\n    image = _decode_and_center_crop(image, image_size)\n    if interpolation == 'bicubic':\n        image = tf.image.resize(image, image_size, method=tf.image.ResizeMethod.BICUBIC)\n    elif interpolation == 'bilinear':\n        image = tf.image.resize(image, image_size, method=tf.image.ResizeMethod.BILINEAR)\n    else:\n        raise ValueError('Unknown interpolation method: {}'.format(interpolation))\n    if use_bfloat16:\n        image = tf.cast(image, dtype=tf.bfloat16)\n    else:\n        image = tf.cast(image, dtype=tf.float32)\n    image = tf.reshape(image, [*image_size, 3])\n    return image", "CodeBleu_score": 44.248931695732786}, {"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    # Decode the image bytes to a float32 tensor.\n    image = tf.io.decode_image(image_bytes, channels=3, expand_animations=False)\n    # Resize the image to the specified size.\n    if interpolation == 'bicubic':\n        image = tf.compat.v1.image.resize_bicubic(image, image_size)\n    else:\n        image = tf.compat.v1.image.resize(image, image_size, method=interpolation)\n    # Convert the image to float32.\n    image = tf.cast(image, dtype=tf.float32)\n    # Center crop the image to the specified size.\n    image = _decode_and_center_crop(image, image_size)\n    # Convert the image to either bfloat16 or float32 based on the use_bfloat16 flag.\n    image = convert_image_dtype(image, use_bfloat16)\n    # Reshape the image to the specified size.\n    image = tf.reshape(image, [*image_size, 3])\n    return image", "CodeBleu_score": 45.03854963101026}]}
{"instance_id": "8bd4364a9a0e", "generation_result": [{"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n    predictions = self.predict_loop(model, eval_dataloader)\n    self.save_predictions(predictions, output_file)\n    metrics = self.compute_metrics(predictions)\n    return metrics\n\n", "CodeBleu_score": 56.01721401833982}, {"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n    if output_file == \"merged\":\n        output_file = f\"{self.output_dir}/merged_eval_results.txt\"\n    elif output_file == \"separate\":\n        output_file = f\"{self.output_dir}/separate_eval_results.txt\"\n    else:\n        output_file = f\"{self.output_dir}/{output_file}\"\n    with open(output_file, \"w\") as f:\n        f.write(\"Evaluating model...", "CodeBleu_score": 39.242803829760284}, {"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n    pred_loop = predict_loop(model, eval_dataloader, output_file)\n    metrics = compute_metrics(pred_loop)\n    return metrics", "CodeBleu_score": 52.83402587589694}]}
{"instance_id": "22d682c958c0", "generation_result": [{"code": " def print_computed_metrics(self, metrics)\n\t\n    rank1 = metrics['rank1']\n    rank5 = metrics['rank5']\n    miou = metrics['miou']\n    print(f'rank1: {rank1:.4f}')\n    print(f'rank5: {rank5:.4f}')\n    print(f'miou: {miou:.4f}')", "CodeBleu_score": 23.84664418251005}, {"code": " def print_computed_metrics(self, metrics)\n\t\n    rank1 = metrics[\"rank1\"]\n    rank5 = metrics[\"rank5\"]\n    miou = metrics[\"miou\"]\n    print(f\"rank1: {rank1:.4f}\")\n    print(f\"rank5: {rank5:.4f}\")\n    print(f\"miou: {miou:.4f}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.26908983044763}, {"code": " def print_computed_metrics(self, metrics)\n\t\n    rank1 = metrics['rank1']\n    rank5 = metrics['rank5']\n    miou = metrics['miou']\n    print('rank1: {:.4f}'.format(rank1))\n    print('rank5: {:.4f}'.format(rank5))\n    print('miou: {:.4f}'.format(miou))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.57561201545366}]}
{"instance_id": "39c1a50b7e7d", "generation_result": [{"code": "def _eval_predictions(self, segments, data)\n\t\n    average_iou = []\n    average_ranks = []\n    for segment, data in zip(segments, data):\n        iou = self._iou(segment, data)\n        average_iou.append(iou)\n        rank = self._rank(iou)\n        average_ranks.append(rank)\n    rank1 = np.sum(np.array(average_ranks) == 1) / len(average_ranks)\n    rank5 = np.sum(np.array(average_ranks) <= 5) / len(average_ranks)\n    mean_iou = np.mean(np.array(average_iou))\n    return rank1, rank5, mean_iou\n\n", "CodeBleu_score": 34.48075101059055}, {"code": "def _eval_predictions(self, segments, data)\n\t\n    average_ranks = []\n    average_iou = []\n    for segment in segments:\n        iou_list = []\n        rank_list = []\n        for data_item in data:\n            iou = self._iou(segment, data_item)\n            iou_list.append(iou)\n            rank = self._rank(iou_list)\n            rank_list.append(rank)\n        average_ranks.append(np.mean(rank_list))\n        average_iou.append(np.mean(iou_list))\n    rank1 = np.sum(np.array(average_ranks) == 1) / len(average_ranks)\n    rank5 = np.sum(np.array(average_ranks) <= 5) / len(average_ranks)\n    mean_iou = np.mean(average_iou)\n    return rank1, rank5, mean_iou\n\n", "CodeBleu_score": 42.74110829770406}, {"code": "def _eval_predictions(self, segments, data)\n\t\n    average_iou = []\n    average_ranks = []\n    for segment in segments:\n        ious = []\n        ranks = []\n        for data_segment in data:\n            iou = self._iou(segment, data_segment)\n            ious.append(iou)\n            ranks.append(self._rank(iou))\n        average_iou.append(np.mean(ious))\n        average_ranks.append(np.mean(ranks))\n    rank1 = np.sum(np.array(average_ranks) == 1) / len(average_ranks)\n    rank5 = np.sum(np.array(average_ranks) <= 5) / len(average_ranks)\n    mean_iou = np.mean(average_iou)\n    return rank1, rank5, mean_iou\n\n", "CodeBleu_score": 41.16357077041799}]}
{"instance_id": "8ccf84f8d034", "generation_result": [{"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    model.eval()\n    model.to(self.device)\n    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n        self.to_ctx(batch)\n        with torch.no_grad():\n            outputs = model(**batch)\n        scores.extend(outputs.update(batch).process())\n    self.finalize(scores, output_file)\n    return scores", "CodeBleu_score": 43.24612467763262}, {"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    model.eval()\n    model.to(self.ctx)\n    for batch in tqdm(eval_dataloader):\n        with torch.no_grad():\n            outputs = model(**batch.to(self.ctx))\n        outputs.update(batch)\n        scores.extend(self.finalize(outputs))\n    if output_file is not None:\n        self.save_results(scores, output_file)\n    return scores", "CodeBleu_score": 40.78302700802263}, {"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    model.eval()\n    model.to(self.device)\n    for batch in tqdm(eval_dataloader, desc=\"Predicting\"):\n        with torch.no_grad():\n            outputs = model(**batch.to(self.device))\n        outputs.update(batch)\n        outputs = self.process_outputs(outputs)\n        scores.extend(outputs[\"scores\"])\n    results = self.finalize(scores)\n    if output_file is not None:\n        with open(output_file, \"w\") as f:\n            json.dump(results, f)\n    return results", "CodeBleu_score": 38.42541909365262}]}
{"instance_id": "e68529ad727d", "generation_result": [{"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    text_scores, video_scores = scores\n    text_scores = np.concatenate(text_scores, axis=0)\n    video_scores = np.concatenate(video_scores, axis=0)\n    self.full_scores = None\n    return np.matmul(text_scores, video_scores.T)\n\n", "CodeBleu_score": 42.296522223978805}, {"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    text_scores = scores[0]\n    video_scores = scores[1]\n    full_scores = np.concatenate((text_scores, video_scores), axis=0)\n    self.full_scores = None\n    return np.matmul(text_scores, video_scores.T)\n\n", "CodeBleu_score": 45.23022872505559}, {"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    text_scores = scores[0]\n    video_scores = scores[1]\n    full_scores = np.concatenate([text_scores, video_scores], axis=1)\n    self.full_scores = None\n    return np.matmul(text_scores, video_scores.T)", "CodeBleu_score": 44.1922408541071}]}
{"instance_id": "e4e1861fc357", "generation_result": [{"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    Y_pred = torch.cat(Y_pred, dim=0)\n    Y_true = torch.cat(Y_true, dim=0)\n    Y_pred = Y_pred.cpu().numpy()\n    Y_true = Y_true.cpu().numpy()\n    print(f\"Prediction errors: {(Y_pred != Y_true).sum()}\")\n    if output_file:\n        with open(output_file, \"wb\") as f:\n            pickle.dump({\"Y_pred\": Y_pred, \"Y_true\": Y_true}, f)\n    return {\"Y_pred\": Y_pred, \"Y_true\": Y_true}", "CodeBleu_score": 29.630034880742034}, {"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    Y_pred = torch.cat(Y_pred, dim=0)\n    Y_true = torch.cat(Y_true, dim=0)\n    Y_pred = Y_pred.cpu().numpy()\n    Y_true = Y_true.cpu().numpy()\n    if output_file:\n        with open(output_file, 'wb') as f:\n            pickle.dump((Y_pred, Y_true), f)\n    return {'Y_pred': Y_pred, 'Y_true': Y_true}\n\n", "CodeBleu_score": 24.34933218147319}, {"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    Y_pred = torch.cat(Y_pred).cpu().numpy()\n    Y_true = torch.cat(Y_true).cpu().numpy()\n\n    errors = np.where(Y_pred != Y_true)\n    if len(errors[0]) > 0:\n        print(\n            f\"There are {len(errors[0])} errors in the predictions. Here are some samples:\"\n        )\n        for i in range(len(errors[0])):\n            print(f\"Predicted: {Y_pred[errors[0][i]]}\")\n            print(f\"True: {Y_true[errors[0][i]]}\")\n            print(\"\")\n\n    if output_file is not None:\n        pickle.dump([Y_pred, Y_true], open(output_file, \"wb\"))\n\n    return {\"pred\": Y_pred, \"true\": Y_true}\n\n", "CodeBleu_score": 31.785825719610934}]}
{"instance_id": "7df9ab9a4920", "generation_result": [{"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = utils.item(sum(log.get_loss() for log in logging_outputs))\n    sample_size_sum = utils.item(sum(log.get_sample_size() for log in logging_outputs))\n    metrics.log_scalar('loss', loss_sum / sample_size_sum, sample_size_sum, round=3)\n\n", "CodeBleu_score": 37.62125391379916}, {"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    metrics.log_scalar(\n        \"loss\",\n        sum(log.get(\"loss\", 0) for log in logging_outputs) / len(logging_outputs),\n        round=3,\n    )\n\n", "CodeBleu_score": 31.328357934864435}, {"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = utils.item(sum(log.get_loss() for log in logging_outputs))\n    sample_size_sum = utils.item(sum(log.get_sample_size() for log in logging_outputs))\n    metrics.log_scalar('loss', loss_sum / sample_size_sum, sample_size_sum, round=3)\n\n", "CodeBleu_score": 37.62125391379916}]}
{"instance_id": "7f9c326a96f7", "generation_result": [{"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n    if attention_mask is None:\n        attention_mask = torch.cat([cmasks, vmasks], dim=-1)\n    else:\n        attention_mask = torch.cat([attention_mask, vmasks], dim=-1)\n    token_type_ids = torch.cat([torch.zeros_like(cmasks), torch.ones_like(vmasks)], dim=-1)\n    return attention_mask, token_type_ids\n\n", "CodeBleu_score": 29.447727810041595}, {"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n    if attention_mask is None:\n        attention_mask = torch.cat((cmasks, vmasks), dim=-1)\n    token_type_ids = torch.cat((torch.zeros(cmasks.size(), dtype=torch.long), torch.ones(vmasks.size(), dtype=torch.long)))\n    return attention_mask, token_type_ids\n\n", "CodeBleu_score": 32.855054892547805}, {"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n\n    # Generate attention mask\n    if attention_mask is None:\n        attention_mask = torch.cat([cmasks, vmasks], dim=-1)\n\n    # Generate token type IDs\n    token_type_ids = torch.cat([\n        torch.zeros(cmasks.size(), dtype=torch.long, device=cmasks.device),\n        torch.ones(vmasks.size(), dtype=torch.long, device=vmasks.device)\n    ], dim=-1)\n\n    return attention_mask, token_type_ids", "CodeBleu_score": 39.079395244314895}]}
{"instance_id": "fa99d2a148a5", "generation_result": [{"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n    # adjust sequence length to match combined length of input_ids and input_video_embeds\n    input_ids = input_ids[:, :-1]\n    input_video_embeds = input_video_embeds[:, :-1]\n    attention_mask = attention_mask[:, :-1]\n    token_type_ids = token_type_ids[:, :-1]\n\n    # modify attention_mask and token_type_ids to fit the new sequence length\n    attention_mask = torch.cat([attention_mask, torch.zeros(attention_mask.size(0), 1)], dim=1)\n    token_type_ids = torch.cat([token_type_ids, torch.zeros(token_type_ids.size(0), 1)], dim=1)\n\n    # return dictionary containing updated input_ids, input_video_embeds, attention_mask, and token_type_ids\n    return {\n        \"input_ids\": input_ids,\n        \"input_video_embeds\": input_video_embeds,\n        \"attention_mask\": attention_mask,\n        \"token_type_ids\": token_type_ids,\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 44.40858577707403}, {"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n\n    if attention_mask is None:\n        attention_mask = torch.ones_like(input_ids)\n    if token_type_ids is None:\n        token_type_ids = torch.zeros_like(input_ids)\n\n    # We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\n    # ourselves in which case we just need to make it broadcastable to all heads.\n    if attention_mask.dim() == 3:\n        extended_attention_mask = attention_mask[:, None, :, :]\n    elif attention_mask.dim() == 2:\n        # Provided a padding mask of dimensions [batch_size, seq_length]\n        # - if the model is a decoder, apply a causal mask in addition to the padding mask\n        # - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]\n        if self.config.is_decoder:\n            batch_size, seq_length = input_ids.shape\n            seq_ids = torch.arange(seq_length, device=input_ids.device)\n            causal_mask = seq_ids[None, None, :].repeat(batch_size, self.config.num_attention_heads, 1, 1)\n            causal_mask = causal_mask < seq_ids[:, None]\n            causal_mask = causal_mask.view(batch_size, self.config.num_attention_heads, seq_length, seq_length)\n            causal_mask = causal_mask.to(dtype=attention_mask.dtype)  # needs to be bool if share_token_type_with_layer_heads is True.\n            extended_attention_mask = causal_mask[:, None, :, :] * attention_mask[:, None, None, :]\n        else:\n            extended_attention_mask = attention_mask[:, None, None, :]\n    else:\n        raise ValueError(\n            f\"Wrong shape for input_ids (shape {input_ids", "CodeBleu_score": 34.38142263599694}, {"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n    input_ids = input_ids.to(self.device)\n    input_video_embeds = input_video_embeds.to(self.device)\n    attention_mask = attention_mask.to(self.device)\n    token_type_ids = token_type_ids.to(self.device)\n\n    # Adjust sequence length to match the combined length of input_ids and input_video_embeds\n    combined_length = input_ids.size(1) + input_video_embeds.size(1)\n    input_ids = input_ids[:, -combined_length:]\n    input_video_embeds = input_video_embeds[:, -combined_length:]\n\n    # Modify attention_mask and token_type_ids to fit the new sequence length\n    attention_mask = attention_mask[:, -combined_length:]\n    token_type_ids = token_type_ids[:, -combined_length:]\n\n    return {\n        \"input_ids\": input_ids,\n        \"input_video_embeds\": input_video_embeds,\n        \"attention_mask\": attention_mask,\n        \"token_type_ids\": token_type_ids,\n        **model_kwargs,\n    }\n\n", "CodeBleu_score": 44.722333395928274}]}
{"instance_id": "b1b0d25fe620", "generation_result": [{"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t\n    pipeline = copy.deepcopy(cfg.data.test.pipeline)\n    if \"LoadImageFromFile\" in [t[\"type\"] for t in pipeline]:\n        idx = self._get_transform_idx(pipeline, \"LoadImageFromFile\")\n        pipeline[idx][\"type\"] = \"mmdet.InferencerLoader\"\n    else:\n        raise ValueError(\"LoadImageFromFile is not in the pipeline\")\n    return Compose(pipeline)\n\n", "CodeBleu_score": 26.531164197025436}, {"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t\n    pipeline = deepcopy(cfg.data.test.pipeline)\n    if 'meta_keys' in pipeline[0].keys():\n        pipeline[0].pop('meta_keys')\n    transform_idx = self._get_transform_idx(pipeline)\n    pipeline[transform_idx]['type'] = 'mmdet.InferencerLoader'\n    return Compose(pipeline)\n\n", "CodeBleu_score": 22.861437290920534}, {"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t\n    pipeline = copy.deepcopy(cfg.data.test.pipeline)\n    if 'img_id' in cfg.data.test.meta_keys:\n        pipeline[0]['meta_keys'].remove('img_id')\n    idx = self._get_transform_idx(pipeline, 'LoadImageFromFile')\n    if idx == -1:\n        raise ValueError(f'Cannot find LoadImageFromFile in pipeline: {pipeline}')\n    pipeline[idx]['type'] = 'mmdet.InferencerLoader'\n    return Compose(pipeline)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 32.791408280577244}]}
{"instance_id": "7967962856eb", "generation_result": [{"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, (str, Path)):\n        inputs = list_dir_or_file(inputs)\n    elif isinstance(inputs, (list, tuple)):\n        pass\n    else:\n        inputs = [inputs]\n    return inputs\n\n", "CodeBleu_score": 26.07227327233267}, {"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, (str, Path)):\n        if isdir(inputs):\n            inputs = list_dir_or_file(inputs)\n        else:\n            inputs = [inputs]\n    if not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n\n", "CodeBleu_score": 36.90614674437966}, {"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        if isdir(inputs):\n            list_dir_or_file(inputs)\n            inputs = get_file_backend(inputs)\n            inputs = [join_path(inputs, file_path) for file_path in inputs]\n        else:\n            inputs = [inputs]\n    elif not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n\n", "CodeBleu_score": 49.41465800635161}]}
{"instance_id": "74f727f06fa0", "generation_result": [{"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data = []\n    for input in inputs:\n        if isinstance(input, dict) and (\"img\" in input or \"img_path\" in input):\n            input = self.pipeline(input)\n        chunk_data.append(input)\n        if len(chunk_data) == chunk_size:\n            yield chunk_data\n            chunk_data = []\n    if chunk_data:\n        yield chunk_data\n\n", "CodeBleu_score": 28.0359307182273}, {"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data = []\n    for i, input in enumerate(inputs):\n        if isinstance(input, dict):\n            if \"img\" in input:\n                chunk_data.append(self.pipeline(input[\"img\"]))\n            elif \"img_path\" in input:\n                chunk_data.append(self.pipeline(input[\"img_path\"]))\n            else:\n                raise ValueError(\n                    f\"Input {i} is a dictionary but does not contain an 'img' or 'img_path' key\"\n                )\n        else:\n            chunk_data.append(input)\n\n        if len(chunk_data) == chunk_size:\n            yield chunk_data\n            chunk_data = []\n\n    if chunk_data:\n        yield chunk_data\n\n", "CodeBleu_score": 38.63604275162239}, {"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data = []\n    for input in inputs:\n        if isinstance(input, dict) and ('img' in input or 'img_path' in input):\n            chunk_data.append(self.pipeline(input))\n        else:\n            chunk_data.append(input)\n\n        if len(chunk_data) == chunk_size:\n            yield chunk_data\n            chunk_data = []\n\n    if len(chunk_data) > 0:\n        yield chunk_data\n\n", "CodeBleu_score": 27.19219558937708}]}
{"instance_id": "a43ab51afa59", "generation_result": [{"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t\n    if pred_out_dir and return_datasamples:\n        warnings.warn('Saving datasamples is not supported when return_datasamples is True.')\n    if not no_save_pred:\n        self.init_out_dir(pred_out_dir)\n    results = []\n    if not return_datasamples:\n        for pred in preds:\n            results.append(self.pred2dict(pred))\n    if visualization is not None:\n        results[0]['visualization'] = visualization\n    if print_result:\n        print(results[0])\n    return results[0]\n\n\n", "CodeBleu_score": 43.15804076315753}, {"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t\n    if not no_save_pred and pred_out_dir == '':\n        pred_out_dir = self.work_dir\n        if not os.path.exists(pred_out_dir):\n            os.makedirs(pred_out_dir)\n    if return_datasamples and pred_out_dir != '':\n        warnings.warn('Saving datasamples is not supported when return_datasamples=True')\n    result = dict(predictions=[])\n    if visualization:\n        result['visualization'] = visualization\n    if not return_datasamples:\n        for pred in preds:\n            result['predictions'].append(self.pred2dict(pred))\n    if print_result:\n        print(result)\n    if pred_out_dir != '':\n        out_file = os.path.join(pred_out_dir, 'predictions.json')\n        with open(out_file, 'w') as f:\n            json.dump(result, f, indent=4)\n        print(f'Predictions saved to {out_file}')\n    return result", "CodeBleu_score": 48.20702588636638}, {"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t\n    if not no_save_pred:\n        if not os.path.exists(pred_out_dir):\n            os.makedirs(pred_out_dir)\n        if return_datasamples:\n            warnings.warn('Saving datasamples is not supported for now.')\n\n    result = dict()\n    if return_datasamples:\n        result['datasamples'] = []\n\n    if return_datasamples:\n        for pred in preds:\n            result['datasamples'].append(pred)\n    else:\n        for pred in preds:\n            result.update(self.pred2dict(pred))\n\n    if visualization is not None:\n        result['visualization'] = visualization\n\n    if print_result:\n        self.print_result(result)\n\n    return result\n\n\n", "CodeBleu_score": 46.12113427785618}]}
{"instance_id": "a3c2561f199c", "generation_result": [{"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    test_pipeline = copy.deepcopy(cfg.data.test.pipeline[0])\n    test_pipeline.type = \"Resize\"\n    test_pipeline.img_scale = cfg.data.test.img_scale\n    test_pipeline.keep_ratio = cfg.data.test.keep_ratio\n    test_pipeline.flip = False\n    test_pipeline.flip_direction = \"horizontal\"\n    test_pipeline.pad_val = dict(img=[114, 114, 114])\n    test_pipeline.pad_to_square = False\n    test_pipeline.pad_to_multiple = cfg.data.test.pad_to_multiple\n    test_pipeline.pad_to_multiple_modulo = cfg.data.test.pad_to_multiple_modulo\n    test_pipeline.pad_to_square_modulo = cfg.data.test.pad_to_square_modulo\n    test_pipeline.pad_to_square_pad_val = dict(img=[114, 114, 114])\n    test_pipeline.pad_to_square_pad_to_multiple = cfg.data.test.pad_to_square_pad_to_multiple\n    test_pipeline.pad_to_square_pad_to_multiple_modulo = cfg.data.test.pad_to_square_pad_to_multiple_modulo\n    test_pipeline.pad_to_square_pad_to_square_modulo = cfg.data.test.pad_to_square_pad_to_square_modulo\n    test_pipeline.pad_to_square_pad_to_square_pad_val = dict(img=[114, 114, 114])\n    test_pipeline.pad_to_square_pad_to_square_pad_to_multiple = cfg.data.test.pad_to_square_pad_to_square_pad_to_multiple\n    test_pipeline.pad_to_square_pad_to_", "CodeBleu_score": 22.27400382254174}, {"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    test_pipeline = cfg.data.test.pipeline.copy()\n    test_pipeline[0] = dict(type=\"Resize\", **test_pipeline[0])\n    test_pipeline = test_pipeline[:1] + test_pipeline[-1:]\n    test_pipeline = Compose(test_pipeline)\n    return test_pipeline\n\n", "CodeBleu_score": 16.45780756429041}, {"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    test_pipeline = copy.deepcopy(cfg.dataset_pipeline.transforms[0])\n    test_pipeline.transforms = [t for t in test_pipeline.transforms if t.name == 'Resize']\n    last_transform = copy.deepcopy(cfg.dataset_pipeline.transforms[-1])\n    test_pipeline.transforms.extend(last_transform.transforms)\n    test_pipeline = Compose(test_pipeline.transforms)\n    return test_pipeline\n\n", "CodeBleu_score": 29.733616135603246}]}
{"instance_id": "48a358ab5a38", "generation_result": [{"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    data = dict(img=img, frame_id=frame_id,\n                original_shape=img.shape[:2], img_id=0, video_len=video_len)\n    data = test_pipeline(data)\n    data = collate([data], samples_per_gpu=1)\n    if next(model.parameters()).is_cuda:\n        # scatter to specified GPU\n        data = scatter(data, [device.index for device in data['img_metas'][0]['device_id']])\n    else:\n        # modify DataContainer type\n        data['img_metas'] = DC(data['img_metas'], cpu_only=True)\n        for s in data['img_metas']:\n            s['img_shape'] = s['img_shape_' + s['img_norm_cfg']['type']]\n            s['pad_shape'] = s['img_shape_' + s['img_norm_cfg']['type']]\n        data['img_metas'] = data['img_metas'][0]\n    # forward the model\n    with torch.no_grad():\n        result = model(return_loss=False, rescale=True, **data)\n    return result\n\n", "CodeBleu_score": 40.08379322867685}, {"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    img = img.astype(np.float32)\n    data = dict(img=img, frame_id=frame_id, ori_shape=img.shape[:2], img_id=0,\n                video_len=video_len)\n    data = model.test_pipeline(data)\n    data = model.data_preprocessor(data, False)\n    if model.device == 'cpu':\n        model.modules().cpu()\n    with torch.no_grad():\n        result = model(return_loss=False, rescale=True, **data)\n    return result\n\n", "CodeBleu_score": 28.368542922024904}, {"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    img = img.astype(np.float32)\n    img = img / 255.\n    data = dict(\n        img=img,\n        frame_id=frame_id,\n        ori_shape=img.shape[:2],\n        img_id=0,\n        video_len=video_len)\n    data = model.test_step(data)\n    return data\n\n", "CodeBleu_score": 16.555634324292786}]}
{"instance_id": "6c4ea2ce1787", "generation_result": [{"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            del trunc_tokens[0]\n        else:\n            trunc_tokens.pop()\n\n", "CodeBleu_score": 79.2280525202322}, {"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n        # We want to sometimes truncate from the front and sometimes from the back to add more randomness\n        # into the choice of which sequence to truncate.\n        if rng.random() < 0.5:\n            del trunc_tokens[0]\n        else:\n            trunc_tokens.pop()\n\n", "CodeBleu_score": 79.2280525202322}, {"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        if len(tokens_a) > len(tokens_b):\n            tokens_a.pop(rng.randint(len(tokens_a)))\n        else:\n            tokens_b.pop(rng.randint(len(tokens_b)))\n\n", "CodeBleu_score": 48.89496767665696}]}
{"instance_id": "007181b6729d", "generation_result": [{"code": "def get_activation(activation_string)\n\t\n    if not isinstance(activation_string, str):\n        return activation_string\n    if activation_string == \"\":\n        return None\n    if activation_string.lower() == \"relu\":\n        return torch.nn.ReLU()\n    elif activation_string.lower() == \"leakyrelu\":\n        return torch.nn.LeakyReLU()\n    elif activation_string.lower() == \"sigmoid\":\n        return torch.nn.Sigmoid()\n    elif activation_string.lower() == \"tanh\":\n        return torch.nn.Tanh()\n    else:\n        raise ValueError(\n            \"Unsupported activation function: \" + activation_string + \". Supported activation functions are: ReLU, LeakyReLU, Sigmoid, Tanh.\"\n        )", "CodeBleu_score": 31.068070243051615}, {"code": "def get_activation(activation_string)\n\t\n    if not isinstance(activation_string, str):\n        return activation_string\n    if not activation_string:\n        return None\n    activation_string = activation_string.lower()\n    if activation_string == \"linear\":\n        return lambda x: x\n    elif activation_string == \"sigmoid\":\n        return lambda x: 1 / (1 + np.exp(-x))\n    elif activation_string == \"tanh\":\n        return np.tanh\n    elif activation_string == \"relu\":\n        return lambda x: np.maximum(0, x)\n    elif activation_string == \"leaky_relu\":\n        return lambda x: np.maximum(0.01 * x, x)\n    elif activation_string == \"softmax\":\n        return lambda x: np.exp(x) / np.sum(np.exp(x))\n    else:\n        raise ValueError(\n            f\"Activation function {activation_string} not supported. Please use one of the following: linear, sigmoid, tanh, relu, leaky_relu, softmax.\"\n        )", "CodeBleu_score": 57.5050198205936}, {"code": "def get_activation(activation_string)\n\t\n    if not isinstance(activation_string, str):\n        return activation_string\n    if activation_string == \"\":\n        return None\n    if activation_string.lower() == \"sigmoid\":\n        return sigmoid\n    if activation_string.lower() == \"tanh\":\n        return tanh\n    if activation_string.lower() == \"relu\":\n        return relu\n    if activation_string.lower() == \"leakyrelu\":\n        return leaky_relu\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"linear\":\n        return linear\n    if activation_string.lower() == \"softplus\":\n        return softplus\n    if activation_string.lower() == \"softsign\":\n        return softsign\n    if activation_string.lower() == \"gelu\":\n        return gelu\n    if activation_string.lower() == \"elu\":\n        return elu\n    if activation_string.lower() == \"selu\":\n        return selu\n    if activation_string.lower() == \"mish\":\n        return mish\n    if activation_string.lower() == \"swish\":\n        return swish\n    if activation_string.lower() == \"hardswish\":\n        return hardswish\n    if activation_string.lower() == \"hardsigmoid\":\n        return hardsigmoid\n    if activation_string.lower() == \"hardtanh\":\n        return hardtanh\n    if activation_string.lower() == \"gumbelsoftmax\":\n        return gumbel_softmax\n    if activation_string.lower() == \"gumbelsoftmax_sample\":\n        return gumbel_softmax_sample\n    if activation_string.lower() == \"gumbelsoftmax_sample_hard\":\n        return gumbel_softmax_sample_hard\n    if activation_string.lower() == \"gumbelsoftmax_sample_hard_grad\":\n        return gumbel_softmax_sample_hard_grad\n    if activation_string.lower() == \"gumbelsoftmax_sample_grad\":\n        return gumbel_softmax_sample_", "CodeBleu_score": 25.636141268093226}]}
{"instance_id": "d5d6e0315899", "generation_result": [{"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n    else:\n        return tf.nn.dropout(input_tensor, dropout_prob)\n\n", "CodeBleu_score": 53.31243274886709}, {"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n    else:\n        return tf.nn.dropout(input_tensor, rate=dropout_prob)", "CodeBleu_score": 53.03103381915149}, {"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n    else:\n        return tf.nn.dropout(input_tensor, dropout_prob)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 53.31243274886709}]}
{"instance_id": "828917b9ac53", "generation_result": [{"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    to_shape = get_shape_list(to_mask, expected_rank=[2, 3])\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n    to_seq_length = to_shape[1]\n    to_mask = tf.cast(\n        tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n    to_mask = tf.minimum(to_mask, 1)\n    return to_mask\n\n", "CodeBleu_score": 41.22379939864269}, {"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    to_shape = get_shape_list(to_mask, expected_rank=[2, 3])\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n    to_seq_length = to_shape[1]\n    to_mask = tf.cast(\n        tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n    to_mask = tf.minimum(to_mask, tf.ones_like(to_mask))\n    return to_mask\n\n", "CodeBleu_score": 42.62279305200078}, {"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    to_shape = get_shape_list(to_mask, expected_rank=[2, 3])\n\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n\n    to_seq_length = to_shape[1]\n\n    to_mask = tf.cast(\n        tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32\n    )\n\n    broadcast_ones = tf.ones(shape=[batch_size, 1, from_seq_length])\n\n    broadcast_ones = tf.cast(broadcast_ones, tf.float32)\n\n    output = broadcast_ones * to_mask\n    return output\n\n", "CodeBleu_score": 48.70990568365276}]}
{"instance_id": "d7798e41a723", "generation_result": [{"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    input_tensor = tf.reshape(\n        input_tensor, [batch_size, seq_length, num_attention_heads, width])\n    input_tensor = tf.transpose(input_tensor, [0, 2, 1, 3])\n    return input_tensor\n\n", "CodeBleu_score": 47.75921652627385}, {"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    input_tensor = tf.reshape(input_tensor, [batch_size, seq_length, num_attention_heads, width])\n    input_tensor = tf.transpose(input_tensor, [0, 2, 1, 3])\n    return input_tensor\n\n", "CodeBleu_score": 42.61845112285781}, {"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    input_tensor = tf.reshape(input_tensor, [batch_size, seq_length, num_attention_heads, width])\n    input_tensor = tf.transpose(input_tensor, [0, 2, 1, 3])\n    return input_tensor", "CodeBleu_score": 42.61845112285781}]}
{"instance_id": "711d466ace09", "generation_result": [{"code": "def reshape_to_matrix(input_tensor)\n\t\n    input_shape = input_tensor.get_shape().as_list()\n    if len(input_shape) < 2:\n        raise ValueError('Input tensor must have rank at least 2.')\n    if len(input_shape) == 2:\n        return input_tensor\n    width = input_shape[-1]\n    return tf.reshape(input_tensor, [-1, width])\n\n", "CodeBleu_score": 39.472994001374964}, {"code": "def reshape_to_matrix(input_tensor)\n\t\n    input_shape = input_tensor.get_shape().as_list()\n    if len(input_shape) < 2:\n        raise ValueError('Input tensor must have rank at least 2.')\n    if len(input_shape) == 2:\n        return input_tensor\n    width = input_shape[-1]\n    return tf.reshape(input_tensor, [-1, width])\n\n", "CodeBleu_score": 39.472994001374964}, {"code": "def reshape_to_matrix(input_tensor)\n\t\n    shape = input_tensor.get_shape().as_list()\n    if len(shape) < 2:\n        raise ValueError('Input tensor must have rank at least 2.')\n    if len(shape) == 2:\n        return input_tensor\n    width = shape[-1]\n    output_shape = [-1, width]\n    return tf.reshape(input_tensor, output_shape)", "CodeBleu_score": 40.858636739619726}]}
{"instance_id": "7adcd08f531e", "generation_result": [{"code": "def get_train_examples(self, data_dir)\n\t\n    return self._create_examples(\n        self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n", "CodeBleu_score": 6.324149162613836}, {"code": "def get_train_examples(self, data_dir)\n\t\n    return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n\n", "CodeBleu_score": 5.998047197537955}, {"code": "def get_train_examples(self, data_dir)\n\t\n    train_file = os.path.join(data_dir, \"train.tsv\")\n    return self._create_examples(self._read_tsv(train_file), \"train\")\n", "CodeBleu_score": 6.209409432138726}]}
{"instance_id": "26a0bb96dab9", "generation_result": [{"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    predictions = tf.argmax(logits, axis=-1)\n    mask = tf.cast(is_real_example, dtype=tf.float32)\n    mean_loss = tf.reduce_sum(per_example_loss * mask) / tf.reduce_sum(mask)\n    accuracy = tf.reduce_sum(tf.cast(tf.equal(predictions, label_ids), dtype=tf.float32) * mask) / tf.reduce_sum(mask)\n    return {\"accuracy\": accuracy, \"loss\": mean_loss}\n\n", "CodeBleu_score": 32.21556173957747}, {"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    predictions = tf.argmax(logits, axis=-1, output_type=tf.int32)\n    accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, label_ids), tf.float32))\n    mean_loss = tf.reduce_mean(per_example_loss * tf.cast(is_real_example, tf.float32))\n    return {\n        \"accuracy\": accuracy,\n        \"mean_loss\": mean_loss,\n    }\n\n", "CodeBleu_score": 40.9602060432179}, {"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    predictions = tf.argmax(logits, axis=-1)\n    real_example_mask = tf.cast(is_real_example, tf.float32)\n    true_labels = tf.cast(label_ids, tf.float32)\n    correct_predictions = tf.cast(tf.equal(predictions, true_labels), tf.float32)\n    accuracy = tf.reduce_sum(correct_predictions * real_example_mask) / tf.reduce_sum(real_example_mask)\n    loss = tf.reduce_sum(per_example_loss * real_example_mask) / tf.reduce_sum(real_example_mask)\n    return {\"accuracy\": accuracy, \"loss\": loss}\n\n", "CodeBleu_score": 25.995447770119963}]}
{"instance_id": "6154e4d28509", "generation_result": [{"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t\n    label_map = {}\n    for (i, label) in enumerate(label_list):\n        label_map[label] = i\n\n    features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        feature = convert_single_example(max_seq_length, tokenizer, example.guid, example.text_a, example.text_b,\n                                         example.label)\n        features.append(feature)\n    return features\n\n", "CodeBleu_score": 59.471608130516444}, {"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t\n    features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        features.append(convert_single_example(example, label_list, max_seq_length,\n                                               tokenizer))\n    return features\n\n", "CodeBleu_score": 62.85829812295688}, {"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t\n    features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        features.append(convert_single_example(example, label_list, max_seq_length, tokenizer))\n    return features\n\n", "CodeBleu_score": 60.9803962559619}]}
{"instance_id": "e09c0db71ebb", "generation_result": [{"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    with tf.variable_scope(\"cls/next_sentence\"):\n        output_weights = modeling.create_initializer(tf.truncated_normal_initializer(stddev=0.02))\n        output_bias = modeling.create_initializer(tf.zeros_initializer())\n        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n        logits = tf.nn.bias_add(logits, output_bias)\n        log_probs = log_softmax(logits)\n        labels = tf.reshape(labels, [-1])\n        one_hot_labels = tf.one_hot(labels, 2, dtype=tf.float32)\n        per_example_loss = tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n        loss = tf.reduce_mean(per_example_loss)\n    return loss, per_example_loss, log_probs\n\n", "CodeBleu_score": 58.69584577905249}, {"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    with tf.variable_scope(\"next_sentence\"):\n        output_weights = modeling.create_initializer(bert_config.hidden_size)(\n            [bert_config.hidden_size, 2]\n        )\n        output_bias = modeling.create_initializer(2)([2])\n\n        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n        logits = tf.nn.bias_add(logits, output_bias)\n        log_probs = log_softmax(logits)\n\n        labels = tf.reshape(labels, [-1])\n        one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=[-1])\n        loss = tf.reduce_mean(per_example_loss)\n\n        return (loss, per_example_loss, log_probs)\n\n", "CodeBleu_score": 64.27770053048962}, {"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    with tf.variable_scope(\"cls/next_sentence\"):\n        output_weights = modeling.create_initializer(bert_config.hidden_size, bert_config.hidden_size)\n        output_bias = modeling.create_initializer(bert_config.hidden_size, 2)\n\n        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n        logits = tf.nn.bias_add(logits, output_bias)\n        log_probs = log_softmax(logits, axis=-1)\n        labels = tf.reshape(labels, [-1])\n        one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n        loss = tf.reduce_mean(per_example_loss)\n        return (loss, per_example_loss, log_probs)\n\n", "CodeBleu_score": 66.76731869904103}]}
{"instance_id": "1f66b020f485", "generation_result": [{"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n    batch_size = sequence_shape[0]\n    seq_length = sequence_shape[1]\n    width = sequence_shape[2]\n\n    flat_offsets = tf.reshape(tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])\n    flat_positions = tf.reshape(flat_offsets + positions, [-1])\n    flat_sequence_tensor = tf.reshape(sequence_tensor,\n                                      [batch_size * seq_length, width])\n    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 53.12300223751525}, {"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    shape = sequence_tensor.get_shape().as_list()\n    batch_size = shape[0]\n    seq_len = shape[1]\n    flat_offsets = tf.range(0, batch_size) * seq_len\n    flat_positions = tf.reshape(flat_offsets + positions, [-1])\n    output_tensor = tf.gather(tf.reshape(sequence_tensor, [-1, shape[-1]]), flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 29.545709453722036}, {"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    sequence_length = sequence_tensor.shape[1].value\n    flat_offsets = tf.range(0, stop=batch_size) * sequence_length\n    flat_positions = tf.reshape(positions + tf.cast(flat_offsets, tf.int32), [-1])\n    output_tensor = tf.gather(tf.reshape(sequence_tensor, [-1, hidden_size]), flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 28.299558252511254}]}
{"instance_id": "956bffee9a33", "generation_result": [{"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.parse_single_example(record, name_to_features)\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.to_int32(t)\n        example[name] = t\n    return example\n\n", "CodeBleu_score": 70.7257133394932}, {"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.parse_single_example(record, name_to_features)\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.to_int32(t)\n        example[name] = t\n    return example\n\n", "CodeBleu_score": 70.7257133394932}, {"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.parse_single_example(record, name_to_features)\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.to_int32(t)\n        example[name] = t\n    return example\n\n", "CodeBleu_score": 70.7257133394932}]}
{"instance_id": "6b97f354e641", "generation_result": [{"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    # Tokenize the original answer text\n    orig_answer_tokens = tokenizer.tokenize(orig_answer_text)\n\n    # Check if the original answer text is a subset of the input text\n    if len(orig_answer_tokens) > input_end - input_start + 1:\n        return (input_start, input_end)\n\n    # Find the start and end positions of the original answer text within the input text\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(new_start + 1, input_end + 2):\n            text_span = doc_tokens[new_start:new_end]\n            if text_span == orig_answer_tokens:\n                return (new_start, new_end - 1)\n\n    # If no match is found, return the original input start and end positions\n    return (input_start, input_end)\n\n", "CodeBleu_score": 42.71807195970637}, {"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    # Tokenize the original answer text\n    orig_answer_tokens = tokenizer.tokenize(orig_answer_text)\n\n    # Check if the original answer tokens match the input tokens\n    if orig_answer_tokens == doc_tokens[input_start:input_end + 1]:\n        return (input_start, input_end)\n\n    # Try to find a better answer span by looking for the first token of the original answer text\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(input_end, new_start - 1, -1):\n            text_span = doc_tokens[new_start:new_end + 1]\n            if text_span == orig_answer_tokens:\n                return (new_start, new_end)\n\n    # If no match is found, return the original input start and end positions\n    return (input_start, input_end)\n\n", "CodeBleu_score": 50.58176553146302}, {"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    # Tokenize the original answer text\n    orig_answer_tokens = tokenizer.tokenize(orig_answer_text)\n\n    # Check if the original answer tokens match the input tokens\n    if orig_answer_tokens == doc_tokens[input_start:input_end + 1]:\n        return (input_start, input_end)\n\n    # If not, try to find a match using the original answer tokens\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(input_end, new_start - 1, -1):\n            text_span = doc_tokens[new_start:new_end + 1]\n            if text_span == orig_answer_tokens:\n                return (new_start, new_end)\n\n    # If no match is found, return the original input start and end positions\n    return (input_start, input_end)\n\n", "CodeBleu_score": 50.58176553146302}]}
{"instance_id": "aba334b92b34", "generation_result": [{"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = None\n    for (span_index, span) in enumerate(doc_spans):\n        end = span.start + span.length - 1\n        if position < span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - span.start\n        num_right_context = end - position\n        score = (num_left_context + num_right_context) / span.length\n        if (best_score is None) or (score > best_score):\n            best_score = score\n            best_span_index = span_index\n    return cur_span_index == best_span_index\n\n", "CodeBleu_score": 57.789789915818886}, {"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = -1000000\n    best_span_index = -1\n    for (span_index, span) in enumerate(doc_spans):\n        end = span.start + span.length - 1\n        if position < span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - span.start\n        num_right_context = end - position\n        score = (num_left_context + num_right_context) / span.length\n        if score > best_score:\n            best_score = score\n            best_span_index = span_index\n    return cur_span_index == best_span_index\n\n", "CodeBleu_score": 66.7780878209808}, {"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    # For max context, we want to predict something that will be the same\n    # up the chain of span prediction\n    best_score = None\n    for (span_index, span) in enumerate(doc_spans):\n        end = span.start + span.length - 1\n        if position < span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - span.start\n        num_right_context = end - position\n        score = (num_left_context + num_right_context) / span.length\n        if (best_score is None) or (score > best_score):\n            best_score = score\n            best_span_index = span_index\n    return cur_span_index == best_span_index\n", "CodeBleu_score": 57.789789915818886}]}
{"instance_id": "cf92ad509f6a", "generation_result": [{"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with open(vocab_file, \"rb\") as f:\n        while True:\n            token = convert_to_unicode(f.readline())\n            if not token:\n                break\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 64.12861898221102}, {"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n        while True:\n            token = convert_to_unicode(reader.readline())\n            if not token:\n                break\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 67.2956448618734}, {"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with open(vocab_file, \"rb\") as reader:\n        while True:\n            token = convert_to_unicode(reader.readline())\n            if not token:\n                break\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 68.87529001107828}]}
{"instance_id": "6c865803ac12", "generation_result": [{"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n", "CodeBleu_score": 79.63749907165396}, {"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n", "CodeBleu_score": 79.63749907165396}, {"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n", "CodeBleu_score": 79.63749907165396}]}
{"instance_id": "e93b9200dc4a", "generation_result": [{"code": "def tokenize(self, text)\n\t\n    tokens = self.basic_tokenizer.tokenize(text)\n    split_tokens = []\n    for token in tokens:\n        if token in self.vocab:\n            split_tokens.append(token)\n        else:\n            split_tokens.extend(self.wordpiece_tokenizer.tokenize(token))\n    return split_tokens\n\n", "CodeBleu_score": 47.28712186884636}, {"code": "def tokenize(self, text)\n\t\n    tokens = self.basic_tokenizer.tokenize(text)\n    for token in tokens:\n        for sub_token in self.wordpiece_tokenizer.tokenize(token):\n            self.split_tokens.append(sub_token)\n    return self.split_tokens", "CodeBleu_score": 43.88651990055196}, {"code": "def tokenize(self, text)\n\t\n    text = text.lower()\n    tokens = self.basic_tokenizer.tokenize(text)\n    for token in tokens:\n        if token in self.vocab:\n            split_tokens.append(token)\n        else:\n            split_tokens = self.wordpiece_tokenizer.tokenize(token)\n            for sub_token in split_tokens:\n                self.vocab[sub_token] = self.vocab_size\n                self.vocab_size += 1\n            split_tokens.append(split_tokens)\n    return split_tokens", "CodeBleu_score": 39.49473786804067}]}
{"instance_id": "2ff6f6db53c9", "generation_result": [{"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        audio_data = self.load(path, offset, duration, sample_rate, dtype)\n        return audio_data, False\n    except Exception as e:\n        logger.exception(e)\n        return -1.0, True\n\n", "CodeBleu_score": 20.813596670790584}, {"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        logger.info(f\"Loading audio from {path}\")\n        audio = self.load(path, offset, duration, sample_rate, dtype)\n        return audio, False\n    except Exception as e:\n        logger.exception(f\"Error loading audio from {path}: {e}\")\n        return -1.0, True\n\n", "CodeBleu_score": 26.900609299573663}, {"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        logger.info(f\"Loading audio from {path} at {offset}s for {duration}s at {sample_rate}Hz with {dtype}\")\n        audio = self.load(path, offset, duration, sample_rate, dtype)\n        return audio, False\n    except Exception as e:\n        logger.exception(f\"Error loading audio from {path} at {offset}s for {duration}s at {sample_rate}Hz with {dtype}\")\n        return -1.0, True\n\n", "CodeBleu_score": 30.613793301738063}]}
{"instance_id": "12fbe1f03d8f", "generation_result": [{"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    return tf.cond(\n        tf.less(tf.shape(waveform)[-1], n_channels),\n        lambda: tf.tile(waveform, [1] * (tf.rank(waveform) - 1) + [n_channels]),\n        lambda: waveform[..., :n_channels],\n    )\n\n", "CodeBleu_score": 55.928089854841915}, {"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    n_channels = tf.cast(n_channels, tf.int32)\n    waveform_shape = tf.shape(waveform)\n    waveform_channels = waveform_shape[-1]\n    waveform = tf.cond(\n        waveform_channels >= n_channels,\n        lambda: waveform[..., :n_channels],\n        lambda: tf.tile(waveform[..., tf.newaxis], [1] * (waveform_shape.shape[0] - 1) + [n_channels]),\n    )\n    return waveform\n\n", "CodeBleu_score": 47.35330451794296}, {"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    waveform_shape = tf.shape(waveform)\n    waveform_rank = tf.rank(waveform)\n    waveform_channels = waveform_shape[waveform_rank - 1]\n\n    waveform = tf.cond(\n        waveform_channels >= n_channels,\n        lambda: waveform[..., :n_channels],\n        lambda: tf.tile(waveform[..., tf.newaxis], [1] * (waveform_rank - 1) + [n_channels]),\n    )\n\n    return waveform\n\n", "CodeBleu_score": 47.33435835980602}]}
{"instance_id": "5e215f029b2e", "generation_result": [{"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    spectrogram = gain_to_db(spectrogram, **kwargs)\n    max_db = tf.reduce_max(spectrogram)\n    spectrogram = tf.maximum(spectrogram, max_db - db_range)\n    spectrogram = from_float32_to_uint8(spectrogram)\n    return spectrogram", "CodeBleu_score": 45.77787040608967}, {"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    # Convert to dB\n    spectrogram_db = gain_to_db(spectrogram, **kwargs)\n\n    # Find maximum dB value\n    max_db = tf.reduce_max(spectrogram_db)\n\n    # Clip dB spectrogram to a specified range below the maximum dB value\n    spectrogram_db_clipped = tf.clip_by_value(\n        spectrogram_db, clip_value_min=max_db - db_range, clip_value_max=max_db\n    )\n\n    # Convert to uint8\n    spectrogram_db_uint = from_float32_to_uint8(spectrogram_db_clipped)\n\n    return spectrogram_db_uint\n\n", "CodeBleu_score": 44.34837206464154}, {"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    spectrogram_db = gain_to_db(spectrogram, **kwargs)\n    max_db = tf.reduce_max(spectrogram_db)\n    spectrogram_db_clipped = tf.clip_by_value(spectrogram_db, -db_range, max_db)\n    spectrogram_db_uint = from_float32_to_uint8(spectrogram_db_clipped)\n    return spectrogram_db_uint\n\n", "CodeBleu_score": 43.141142023230394}]}
{"instance_id": "b65c0968dae7", "generation_result": [{"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n    window_length = int(frame_length * 2 ** window_exponent)\n    window = hann_window(window_length, dtype=tf.float32)\n    stfts = tf.signal.stft(\n        waveform,\n        frame_length=frame_length,\n        frame_step=frame_step,\n        window=window,\n        pad_end=True,\n    )\n    spectrograms = tf.abs(stfts) ** spec_exponent\n    return tf.transpose(spectrograms)\n\n", "CodeBleu_score": 37.01286230444036}, {"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n    # Compute the spectrogram using STFT\n    stfts = tf.signal.stft(\n        waveform,\n        frame_length=frame_length,\n        frame_step=frame_step,\n        window_fn=lambda frame_length: tf.math.pow(tf.signal.hann_window(frame_length), window_exponent),\n    )\n    # Compute the spectrogram\n    spectrogram = tf.abs(stfts)\n    # Transpose the spectrogram\n    spectrogram = tf.transpose(spectrogram, perm=[1, 2, 0])\n    # Raise the spectrogram to the specified exponent\n    spectrogram = tf.pow(spectrogram, spec_exponent)\n    # Return the spectrogram\n    return spectrogram", "CodeBleu_score": 38.47395188769296}, {"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n    # Apply Hann window function\n    window_function = tf.pow(hann_window(frame_length, dtype=waveform.dtype), window_exponent)\n    # Compute STFT\n    stft_tensor = stft(waveform, frame_length, frame_step, window_function)\n    # Transpose the tensor\n    stft_tensor = tf.transpose(stft_tensor, perm=[1, 0, 2])\n    # Compute the absolute value of the STFT tensor\n    stft_tensor = tf.abs(stft_tensor)\n    # Raise the absolute value to the specified exponent\n    stft_tensor = tf.pow(stft_tensor, spec_exponent)\n    return stft_tensor\n\n", "CodeBleu_score": 38.63785810358043}]}
{"instance_id": "a4686140a634", "generation_result": [{"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Get the original time dimension and the new time dimension\n    original_time_dim = tf.shape(spectrogram)[1]\n    new_time_dim = tf.cast(tf.cast(original_time_dim, tf.float32) * factor, tf.int32)\n\n    # Resize the spectrogram to the new time dimension\n    resized_spectrogram = tf.image.resize(\n        spectrogram, [new_time_dim], method=method\n    )\n\n    # Adjust the resized spectrogram to the original dimensions\n    adjusted_spectrogram = tf.image.resize_with_crop_or_pad(\n        resized_spectrogram, original_time_dim, original_time_dim\n    )\n\n    return adjusted_spectrogram\n\n", "CodeBleu_score": 39.304726469381336}, {"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    time_dim = tf.shape(spectrogram)[0]\n    new_time_dim = tf.cast(tf.cast(time_dim, tf.float32) * factor, tf.int32)\n    return resize_image_with_crop_or_pad(spectrogram, new_time_dim, method)\n\n", "CodeBleu_score": 33.44514141295405}, {"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Get the original shape of the spectrogram\n    shape = tf.shape(spectrogram)\n\n    # Calculate the new time dimension\n    new_time = tf.cast(shape[0], tf.float32) * factor\n\n    # Resize the spectrogram\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        (new_time, shape[1]),\n        method=method,\n    )\n\n    # Adjust the resized spectrogram to the original dimensions\n    adjusted_spectrogram = tf.image.resize_with_crop_or_pad(\n        resized_spectrogram, shape[0], shape[1]\n    )\n\n    return adjusted_spectrogram", "CodeBleu_score": 35.66150920056034}]}
{"instance_id": "6dd01101d4ae", "generation_result": [{"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n\n    # Calculate the resizing factor based on the semitone shift\n    resizing_factor = tf.math.exp(semitone_shift * tf.math.log(2) / 12)\n\n    # Resize the spectrogram along the frequency axis using the specified method\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        size=tf.cast(\n            tf.math.ceil(tf.cast(tf.shape(spectrogram)[1], tf.float32) * resizing_factor),\n            tf.int32,\n        ),\n        method=method,\n    )\n\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        paddings=tf.constant([[0, 0], [0, tf.shape(spectrogram)[1] - tf.shape(resized_spectrogram)[1]]]),\n    )\n\n    return padded_spectrogram", "CodeBleu_score": 31.059376930782083}, {"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Calculate the resizing factor based on the semitone shift\n    resize_factor = 2 ** (semitone_shift / 12)\n    # Calculate the new height of the spectrogram after resizing\n    new_height = tf.cast(tf.shape(spectrogram)[0] * resize_factor, tf.int32)\n    # Resize the spectrogram along the frequency axis using the specified method\n    resized_spectrogram = tf.image.resize(\n        spectrogram, (new_height, tf.shape(spectrogram)[1]), method=method\n    )\n    # Calculate the padding required to maintain the original dimensions\n    padding_top = (tf.shape(spectrogram)[0] - new_height) // 2\n    padding_bottom = tf.shape(spectrogram)[0] - new_height - padding_top\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        [[padding_top, padding_bottom], [0, 0], [0, 0]],\n        mode=\"CONSTANT\",\n    )\n    return padded_spectrogram\n\n", "CodeBleu_score": 33.76727336177085}, {"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Calculate the resizing factor based on the semitone shift\n    resizing_factor = 2 ** (semitone_shift / 12)\n\n    # Calculate the new height of the spectrogram after resizing\n    new_height = tf.cast(tf.shape(spectrogram)[0], tf.float32) * resizing_factor\n\n    # Resize the spectrogram along the frequency axis using the specified method\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        (tf.cast(new_height, tf.int32), tf.shape(spectrogram)[1]),\n        method=method,\n    )\n\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        [[0, tf.maximum(0, tf.cast(new_height, tf.int32) - tf.shape(spectrogram)[0])], [0, 0]],\n        constant_values=0.0,\n    )\n\n    return padded_spectrogram\n\n", "CodeBleu_score": 35.555500605753096}]}
{"instance_id": "612f0826e56a", "generation_result": [{"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    if params.get(\"conv_activation\") == \"ReLU\":\n        return nn.ReLU()\n    elif params.get(\"conv_activation\") == \"ELU\":\n        return nn.ELU()\n    elif params.get(\"conv_activation\") == \"LeakyReLU\":\n        return nn.LeakyReLU(negative_slope=0.2)\n    else:\n        return nn.ReLU()\n\n", "CodeBleu_score": 39.48424703401421}, {"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    conv_activation = params.get(\"conv_activation\", \"ReLU\")\n    if conv_activation == \"ReLU\":\n        return nn.ReLU()\n    elif conv_activation == \"ELU\":\n        return nn.ELU()\n    elif conv_activation == \"LeakyReLU\":\n        return nn.LeakyReLU(negative_slope=0.2)\n    else:\n        raise ValueError(f\"Invalid activation function: {conv_activation}\")\n\n", "CodeBleu_score": 42.38926490878458}, {"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    if params.get(\"conv_activation\") == \"ReLU\":\n        return nn.ReLU()\n    elif params.get(\"conv_activation\") == \"ELU\":\n        return nn.ELU()\n    elif params.get(\"conv_activation\") == \"LeakyReLU\":\n        return nn.LeakyReLU(negative_slope=0.2)\n    else:\n        return nn.ReLU()\n\n", "CodeBleu_score": 39.48424703401421}]}
{"instance_id": "2f8b5a2fc0f2", "generation_result": [{"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n\n    logit_mask_list = []\n    for instrument in instruments:\n        logit_mask = apply_unet(input_tensor, instrument, params)\n        logit_mask_list.append(logit_mask)\n\n    logit_mask_combined = tf.stack(logit_mask_list, axis=-1)\n    logit_mask_combined_softmax = tf.nn.softmax(logit_mask_combined, axis=-1)\n\n    output = {}\n    for idx, instrument in enumerate(instruments):\n        output[instrument] = tf.multiply(\n            input_tensor, logit_mask_combined_softmax[:, :, :, idx]\n        )\n\n    return output", "CodeBleu_score": 32.43182546799532}, {"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    logit_mask_list = []\n    for instrument in instruments:\n        logit_mask = unet(input_tensor, instrument, params)\n        logit_mask_list.append(logit_mask)\n\n    logit_mask = tf.stack(logit_mask_list, axis=-1)\n    logit_mask = tf.nn.softmax(logit_mask, axis=-1)\n\n    output = {}\n    for i, instrument in enumerate(instruments):\n        output[instrument] = tf.multiply(input_tensor, logit_mask[:, :, :, i])\n\n    return output\n\n", "CodeBleu_score": 32.40166365384824}, {"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    logit_mask_list = []\n    for instrument in instruments:\n        logit_mask = unet_model(input_tensor, instrument, params)\n        logit_mask_list.append(logit_mask)\n    logit_mask_stack = tf.stack(logit_mask_list, axis=0)\n    softmax_mask = tf.nn.softmax(logit_mask_stack, axis=0)\n    output_dict = {}\n    for i, instrument in enumerate(instruments):\n        output_dict[instrument] = tf.multiply(input_tensor, softmax_mask[i])\n    return output_dict", "CodeBleu_score": 35.77217177095909}]}
{"instance_id": "400b19ce8520", "generation_result": [{"code": "def compute_file_checksum(path)\n\t\n    sha256 = hashlib.sha256()\n    with open(path, 'rb') as f:\n        for chunk in iter(lambda: f.read(4096), b''):\n            sha256.update(chunk)\n    return sha256.hexdigest()\n\n", "CodeBleu_score": 57.841685548191435}, {"code": "def compute_file_checksum(path)\n\t\n    sha256 = hashlib.sha256()\n    with open(path, 'rb') as file:\n        while True:\n            chunk = file.read(1024)\n            if not chunk:\n                break\n            sha256.update(chunk)\n    return sha256.hexdigest()\n\n", "CodeBleu_score": 39.47685416913966}, {"code": "def compute_file_checksum(path)\n\t\n    sha256 = hashlib.sha256()\n    with open(path, 'rb') as file:\n        while True:\n            chunk = file.read(1024)\n            if not chunk:\n                break\n            sha256.update(chunk)\n    return sha256.hexdigest()\n\n", "CodeBleu_score": 39.47685416913966}]}
{"instance_id": "5f2e9c6e15f1", "generation_result": [{"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/{self.checksum_index}\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    index = response.json()\n    if name not in index:\n        raise ValueError(f\"{name} not found in index\")\n    return index[name]\n\n", "CodeBleu_score": 36.04303011124509}, {"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/{self.checksum_index}\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    index = response.json()\n    if name not in index:\n        raise ValueError(f\"Model {name} not found in index\")\n    return index[name]\n\n", "CodeBleu_score": 36.418427243737774}, {"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/{self.checksum_index}\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    index = response.json()\n    if name not in index:\n        raise ValueError(f\"Model {name} not found in index\")\n    return index[name]\n\n", "CodeBleu_score": 36.418427243737774}]}
{"instance_id": "9312c8b6032e", "generation_result": [{"code": "def download(self, name: str, path: str) -> None:\n\t\n    url = f\"{self.url}/{name}\"\n    logger.info(f\"Downloading {name} from {url}\")\n    with httpx.Client() as client:\n        response = client.stream(\"GET\", url)\n        response.raise_for_status()\n        with NamedTemporaryFile(delete=False) as stream:\n            for chunk in response.iter_raw():\n                stream.write(chunk)\n        self.checksum(stream.name, path)\n        os.unlink(stream.name)\n        logger.info(f\"Extracting {name} to {path}\")\n\n", "CodeBleu_score": 28.42121192940973}, {"code": "def download(self, name: str, path: str) -> None:\n\t\n    url = self.url + name\n    logger.info(f\"Downloading {name} from {url}\")\n    with httpx.Client(http2=True) as client:\n        response = client.stream(url)\n        response.raise_for_status()\n        with NamedTemporaryFile() as stream:\n            for chunk in response.iter_raw():\n                stream.write(chunk)\n            stream.flush()\n            self.checksum(stream.name)\n            tar = tarfile.open(stream.name, \"r:gz\")\n            tar.extractall(path)\n            stream.close()\n            os.unlink(stream.name)\n            logger.info(f\"Extracted {name} to {path}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.823413521666936}, {"code": "def download(self, name: str, path: str) -> None:\n\t\n    url = self.get_download_url(name)\n    logger.info(\"Downloading %s to %s\", url, path)\n    with httpx.Client(http2=True) as client:\n        response = client.stream(\"GET\", url)\n        response.raise_for_status()\n        with NamedTemporaryFile(delete=False) as stream:\n            for chunk in response.iter_raw():\n                stream.write(chunk)\n            stream.flush()\n            self.validate_file_checksum(stream.name)\n            with tarfile.open(stream.name) as tar:\n                tar.extractall(path)\n            os.unlink(stream.name)\n    logger.info(\"Extracted %s to %s\", name, path)\n\n\n", "CodeBleu_score": 36.90188937013955}]}
{"instance_id": "ee9493f37d77", "generation_result": [{"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embedded:\"):\n        name = descriptor[len(\"embedded:\") :]\n        if not loader.is_resource(name):\n            raise SpleeterError(f\"Embedded configuration '{name}' not found\")\n        return json.loads(loader.open_text(name))\n    elif os.path.isfile(descriptor):\n        with open(descriptor, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    else:\n        raise SpleeterError(f\"Configuration file '{descriptor}' not found\")\n\n", "CodeBleu_score": 45.26263157967292}, {"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith('embedded:'):\n        name = descriptor[len('embedded:'):]\n        if not loader.is_resource(name):\n            raise SpleeterError(f'Embedded configuration not found: {name}')\n        return json.loads(loader.open_text(name))\n    if not os.path.exists(descriptor):\n        raise SpleeterError(f'Configuration file not found: {descriptor}')\n    with open(descriptor) as file:\n        return json.load(file)\n\n", "CodeBleu_score": 44.22596032811793}, {"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embed://\"):\n        name = descriptor[len(\"embed://\") :]\n        try:\n            resource = pkg_resources.resource_string(__name__, name).decode(\"utf-8\")\n        except FileNotFoundError as e:\n            raise SpleeterError(f\"Embedded configuration '{name}' not found\") from e\n    elif os.path.exists(descriptor):\n        with open(descriptor, \"r\", encoding=\"utf-8\") as f:\n            resource = f.read()\n    else:\n        raise SpleeterError(f\"Configuration '{descriptor}' not found\")\n    return json.loads(resource)\n\n", "CodeBleu_score": 42.65694251544724}]}
{"instance_id": "546134b67fbc", "generation_result": [{"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise NotImplementedError(\n            f\"concat_axis must be either 0 or 1, got {concat_axis}\"\n        )\n    if concat_axis == 0:\n        tensor_concat = tf.concat(list(tensor_dict.values()), axis=0)\n        tensor_processed = func(tensor_concat)\n        return {\n            key: tensor_processed[i : i + tensor.shape[0]]\n            for i, (key, tensor) in enumerate(tensor_dict.items())\n        }\n    elif concat_axis == 1:\n        tensor_concat = tf.concat(list(tensor_dict.values()), axis=1)\n        tensor_processed = func(tensor_concat)\n        return {\n            key: tensor_processed[:, i : i + tensor.shape[1]]\n            for i, (key, tensor) in enumerate(tensor_dict.items())\n        }\n\n", "CodeBleu_score": 46.84581904946642}, {"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis == 0:\n        concat_tensor = tf.concat(list(tensor_dict.values()), axis=0)\n        processed_tensor = func(concat_tensor)\n        return {\n            key: tf.split(processed_tensor, num_or_size_splits=tf.shape(value)[0], axis=0)\n            for key, value in tensor_dict.items()\n        }\n    elif concat_axis == 1:\n        concat_tensor = tf.concat(list(tensor_dict.values()), axis=1)\n        processed_tensor = func(concat_tensor)\n        return {\n            key: tf.split(processed_tensor, num_or_size_splits=tf.shape(value)[1], axis=1)\n            for key, value in tensor_dict.items()\n        }\n    else:\n        raise NotImplementedError(\n            \"concat_axis must be either 0 or 1, got {}\".format(concat_axis)\n        )\n\n", "CodeBleu_score": 46.18085534116727}, {"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise ValueError(\"concat_axis must be either 0 or 1.\")\n    if concat_axis == 0:\n        concat_tensor = tf.concat(list(tensor_dict.values()), axis=0)\n        result_tensor = func(concat_tensor)\n        result_dict = {\n            k: v for k, v in zip(tensor_dict.keys(), tf.split(result_tensor, len(tensor_dict)))\n        }\n    elif concat_axis == 1:\n        concat_tensor = tf.concat(list(tensor_dict.values()), axis=1)\n        result_tensor = func(concat_tensor)\n        result_dict = {\n            k: v for k, v in zip(tensor_dict.keys(), tf.split(result_tensor, len(tensor_dict), axis=1))\n        }\n    return result_dict\n\n", "CodeBleu_score": 47.20237891669263}]}
{"instance_id": "df48e78d46d2", "generation_result": [{"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n\n    min_val = tf.reduce_min(tensor)\n    max_val = tf.reduce_max(tensor)\n\n    return {\n        tensor_key: tf.cast(\n            (tensor - min_val) / (max_val - min_val) * 255,\n            dtype=tf.uint8,\n        ),\n        min_key: min_val,\n        max_key: max_val,\n    }\n\n", "CodeBleu_score": 58.03364374941531}, {"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n    min_value = tf.reduce_min(tensor)\n    max_value = tf.reduce_max(tensor)\n    tensor_uint8 = tf.cast((tensor - min_value) / (max_value - min_value) * 255, tf.uint8)\n    return {tensor_key: tensor_uint8, min_key: min_value, max_key: max_value}\n\n", "CodeBleu_score": 39.07952281922278}, {"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n    min_value = tf.reduce_min(tensor)\n    max_value = tf.reduce_max(tensor)\n    tensor = (tensor - min_value) / (max_value - min_value)\n    tensor = tf.cast(tensor * 255, tf.uint8)\n    return {tensor_key: tensor, min_key: min_value, max_key: max_value}\n\n", "CodeBleu_score": 47.09845284075762}]}
{"instance_id": "7f479e5de492", "generation_result": [{"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    # Calculate the padding needed to make the tensor length a multiple of the segment length\n    padding = segment_len - tf.math.floormod(tf.shape(tensor)[0], segment_len)\n    # Pad the tensor with zeros\n    padded_tensor = tf.pad(tensor, [[0, padding], [0, 0]])\n    # Reshape the padded tensor into a new tensor with the specified segment length\n    reshaped_tensor = tf.reshape(padded_tensor, [-1, segment_len, tf.shape(tensor)[-1]])\n    return reshaped_tensor\n\n", "CodeBleu_score": 28.167459035054797}, {"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    pad_len = segment_len - tf.floormod(tf.shape(tensor)[0], segment_len)\n    padded_tensor = tf.pad(tensor, [[0, pad_len], [0, 0]])\n    return tf.reshape(padded_tensor, [tf.shape(tensor)[0] // segment_len, segment_len, tf.shape(tensor)[1]])\n\n", "CodeBleu_score": 27.189124167376242}, {"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    pad_len = segment_len - floormod(tf.shape(tensor)[0], segment_len)\n    padded_tensor = tf.pad(tensor, [[0, pad_len]])\n    return tf.reshape(padded_tensor, [tf.shape(tensor)[0] // segment_len, segment_len])\n\n", "CodeBleu_score": 24.306955303257393}]}
{"instance_id": "1789fae7253f", "generation_result": [{"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    # Calculate the number of extra rows needed for padding\n    extra_rows = frame_length - tf.shape(instr_spec)[0]\n    # Create an extension of zeros with the same shape as the input spectrogram\n    zeros_extension = tf.zeros((extra_rows, tf.shape(instr_spec)[1], tf.shape(instr_spec)[2]), dtype=tf.float32)\n    # Concatenate the extension to the original spectrogram along the frequency axis\n    padded_spec = tf.concat([instr_spec, zeros_extension], axis=0)\n    # Reshape the padded spectrogram by merging the first two dimensions\n    reshaped_spec = tf.reshape(padded_spec, (1, -1, F))\n    return reshaped_spec\n\n", "CodeBleu_score": 20.06144324459421}, {"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    # Calculate the number of extra rows needed for padding\n    num_extra_rows = frame_length - tf.shape(instr_spec)[1]\n    # Create an extension of zeros with the same shape as the original spectrogram\n    zero_extension = tf.zeros((tf.shape(instr_spec)[0], num_extra_rows, tf.shape(instr_spec)[2]), dtype=tf.float32)\n    # Concatenate the extension to the original spectrogram along the frequency axis\n    extended_spectrogram = tf.concat([instr_spec, zero_extension], axis=1)\n    # Reshape the extended spectrogram by merging the first two dimensions\n    processed_spectrogram = tf.reshape(extended_spectrogram, (-1, F))\n    return processed_spectrogram\n\n", "CodeBleu_score": 21.493924597219266}, {"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    # Calculate the number of extra rows needed for padding\n    extra_rows = (frame_length - instr_spec.shape[0] % frame_length) % frame_length\n    # Create an extension of zeros\n    zeros = tf.zeros([extra_rows, instr_spec.shape[1], instr_spec.shape[2]], dtype=tf.float32)\n    # Concatenate the extension to the original spectrogram along the frequency axis\n    instr_spec = tf.concat([instr_spec, zeros], axis=0)\n    # Reshape the extended spectrogram\n    instr_spec = tf.reshape(instr_spec, [-1, instr_spec.shape[1] * instr_spec.shape[2]])\n    return instr_spec\n\n", "CodeBleu_score": 19.20539661236909}]}
{"instance_id": "8a4f4658d97c", "generation_result": [{"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path, **kwargs)\n    return tf.data.Dataset.from_tensor_slices(df.values)", "CodeBleu_score": 29.79569440659192}, {"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path, **kwargs)\n    return tf.data.Dataset.from_tensor_slices(df)", "CodeBleu_score": 26.55075431370808}, {"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path, **kwargs)\n    return tf.data.Dataset.from_tensor_slices(dict(df))", "CodeBleu_score": 27.127655353502654}]}
{"instance_id": "9a16e81b182f", "generation_result": [{"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for dim_index, target_length in enumerate(target_shape):\n        result = tf.logical_and(result, tf.equal(tf.shape(tensor_tf)[dim_index], target_length))\n    return result\n\n", "CodeBleu_score": 41.52283881764048}, {"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for i, length in enumerate(target_shape):\n        result = tf.logical_and(result, tf.equal(tf.shape(tensor_tf)[i], length))\n    return result\n\n", "CodeBleu_score": 38.26213886106719}, {"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for i, dim in enumerate(target_shape):\n        result = tf.logical_and(result, tf.equal(tf.shape(tensor_tf)[i], dim))\n    return result\n\n", "CodeBleu_score": 37.07365461522751}]}
{"instance_id": "49d5d3084b3a", "generation_result": [{"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\t\n    builder = DatasetBuilder(\n        audio_params=audio_params,\n        audio_adapter=audio_adapter,\n        chunk_duration=audio_params.get(\"chunk_duration\"),\n        random_seed=audio_params.get(\"random_seed\"),\n    )\n    dataset = builder.build(\n        train_csv_path=audio_params.get(\"train_csv_path\"),\n        cache_dir=audio_params.get(\"cache_dir\"),\n        batch_size=audio_params.get(\"batch_size\"),\n        num_chunks_per_song=audio_params.get(\"num_chunks_per_song\"),\n        data_augmentation_options=audio_params.get(\"data_augmentation_options\"),\n        cache_data=audio_params.get(\"cache_data\"),\n    )\n    return dataset\n\n", "CodeBleu_score": 42.08203574328475}, {"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\t\n    builder = DatasetBuilder(\n        audio_params=audio_params,\n        audio_adapter=audio_adapter,\n        chunk_duration=audio_params.get(\"chunk_duration\", 10),\n        random_seed=audio_params.get(\"random_seed\", 42),\n    )\n    dataset = builder.build(\n        train_csv_path=audio_path + \"train.csv\",\n        cache_dir=audio_path + \"cache\",\n        batch_size=audio_params.get(\"batch_size\", 32),\n        num_chunks_per_song=audio_params.get(\"num_chunks_per_song\", 100),\n        data_augmentation=audio_params.get(\"data_augmentation\", True),\n        cache=audio_params.get(\"cache\", True),\n    )\n    return dataset\n\n", "CodeBleu_score": 46.01072038902057}, {"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\t\n    builder = DatasetBuilder(\n        audio_params=audio_params,\n        audio_adapter=audio_adapter,\n        chunk_duration=audio_params.get(\"chunk_duration\"),\n        random_seed=audio_params.get(\"random_seed\"),\n    )\n    dataset = builder.build(\n        train_csv_path=audio_path + \"/train.csv\",\n        cache_dir=audio_path + \"/cache\",\n        batch_size=audio_params.get(\"batch_size\"),\n        num_chunks_per_song=audio_params.get(\"num_chunks_per_song\"),\n        data_augmentation_options=audio_params.get(\"data_augmentation_options\"),\n        cache_options=audio_params.get(\"cache_options\"),\n    )\n    return dataset\n\n", "CodeBleu_score": 43.34391729649271}]}
{"instance_id": "fe8bbbba06e3", "generation_result": [{"code": "def instruments(self) -> Any\n\t\n    if self.instrument_builders is None:\n        self.instrument_builders = []\n        for instrument in self.instruments:\n            self.instrument_builders.append(\n                InstrumentDatasetBuilder(\n                    instrument,\n                    self.instrument_builder_kwargs,\n                    self.instrument_builder_kwargs.get(\"data_dir\", None),\n                )\n            )\n    for builder in self.instrument_builders:\n        yield builder\n\n", "CodeBleu_score": 50.21874542399979}, {"code": "def instruments(self) -> Any\n\t\n    if not self._instruments:\n        for instrument in self.instrument_list:\n            self._instruments.append(InstrumentDatasetBuilder(self, instrument))\n    for instrument in self._instruments:\n        yield instrument", "CodeBleu_score": 42.71848885009853}, {"code": "def instruments(self) -> Any\n\t\n    if not self._instruments:\n        for instrument in self.instruments_list:\n            self._instruments.append(\n                InstrumentDatasetBuilder(\n                    self.dataset_builder, instrument, self.instruments_list\n                )\n            )\n    for instrument in self._instruments:\n        yield instrument", "CodeBleu_score": 41.62713302635316}]}
{"instance_id": "438b57fd3413", "generation_result": [{"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache:\n        if wait:\n            logger.info(f\"Waiting for cache index file at {cache}\")\n            while not os.path.exists(os.path.join(cache, \"index.json\")):\n                time.sleep(1)\n            logger.info(\"Cache index file found\")\n        os.makedirs(cache, exist_ok=True)\n        return dataset.cache(cache)\n    return dataset\n\n", "CodeBleu_score": 52.41398810809077}, {"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache:\n        if wait:\n            while not os.path.exists(os.path.join(cache, \"index.json\")):\n                logger.info(\"Waiting for cache index file...\")\n                time.sleep(10)\n        os.makedirs(cache, exist_ok=True)\n        dataset = dataset.cache(cache)\n    return dataset\n\n", "CodeBleu_score": 51.7394560463627}, {"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is None:\n        return dataset\n    if not os.path.exists(cache):\n        os.makedirs(cache)\n    if os.path.exists(os.path.join(cache, \"index.json\")):\n        logger.info(f\"Found cached dataset at {cache}\")\n        return dataset\n    logger.info(f\"Caching dataset to {cache}\")\n    dataset.cache(cache)\n    if wait:\n        while not os.path.exists(os.path.join(cache, \"index.json\")):\n            logger.info(\"Waiting for cache index file to exist...\")\n            time.sleep(1)\n    logger.info(\"Cache index file found\")\n    return dataset\n\n", "CodeBleu_score": 45.764173435151115}]}
{"instance_id": "8838a3a09a66", "generation_result": [{"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    model_dir = ModelProvider.default().get(params[\"model_name\"])\n    params.update({\"model_dir\": model_dir})\n    config = ConfigProto()\n    config.gpu_options.allow_growth = True\n    session_config = tf.compat.v1.ConfigProto(\n        gpu_options=tf.compat.v1.GPUOptions(allow_growth=True)\n    )\n    run_config = tf.estimator.RunConfig(session_config=session_config)\n    return tf.estimator.Estimator(\n        model_fn=model_function,\n        model_dir=params[\"model_dir\"],\n        params=params,\n        config=run_config,\n    )\n\n", "CodeBleu_score": 32.252336982560564}, {"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    model_dir = ModelProvider.default().get(params['model_dir'])\n    params['model_dir'] = model_dir\n    params['max_steps'] = params['max_steps'] * params['num_epochs']\n    params['num_epochs'] = 1\n    params['batch_size'] = params['batch_size'] * params['num_gpus']\n    config = ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.gpu_options.per_process_gpu_memory_fraction = 0.5\n    config.gpu_options.visible_device_list = str(params['visible_devices'])\n    run_config = tf.estimator.RunConfig(session_config=config)\n    if MWF:\n        return tf.estimator.Estimator(model_fn=model_function, model_dir=model_dir, params=params, config=run_config)\n    else:\n        return tf.estimator.Estimator(model_fn=model_function, params=params, config=run_config)\n\n", "CodeBleu_score": 31.437133542618685}, {"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    # Load model directory\n    model_dir = ModelProvider.default().get(params[\"model_dir\"])\n\n    # Update parameters with model directory\n    params.update({\"model_dir\": model_dir})\n\n    # Set up session configuration\n    config = ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.gpu_options.per_process_gpu_memory_fraction = 0.8\n    config.gpu_options.visible_device_list = \"0\"\n\n    # Create RunConfig with session configuration\n    run_config = RunConfig(session_config=config)\n\n    # Initialize and return TensorFlow estimator\n    return tf.estimator.Estimator(\n        model_fn=model_function,\n        model_dir=model_dir,\n        params=params,\n        config=run_config,\n    )\n\n", "CodeBleu_score": 34.62928631620687}]}
{"instance_id": "779c812bf2cb", "generation_result": [{"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    waveform = self._ensure_stereo(waveform)\n    prediction_generator = self._get_prediction_generator(audio_descriptor)\n    self.update_data(waveform, audio_descriptor)\n    prediction = prediction_generator.next()\n    prediction.pop(\"audio_id\")\n    return prediction\n\n", "CodeBleu_score": 39.35674460999202}, {"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    to_stereo = self.to_stereo\n    update_data = self.update_data\n    next = self.next\n    prediction = self.prediction\n    self._get_prediction_generator = self.get_prediction_generator\n    np_array = np.array\n\n    waveform = to_stereo(waveform)\n    prediction_generator = self._get_prediction_generator()\n    update_data(waveform, audio_descriptor)\n    prediction.pop(\"audio_id\")\n    return prediction_generator.next()\n\n", "CodeBleu_score": 42.91111758313979}, {"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    waveform = to_stereo(waveform)\n    prediction_generator = self._get_prediction_generator(audio_descriptor)\n    update_data(prediction_generator, waveform, audio_descriptor)\n    prediction = next(prediction_generator)\n    prediction.pop(\"audio_id\")\n    return prediction\n\n", "CodeBleu_score": 47.1539813292772}]}
{"instance_id": "cf580cd2ed93", "generation_result": [{"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape, config)\n    else:\n        backbone = config.BACKBONE\n        assert backbone in [\"resnet50\", \"resnet101\"], \"Backbone ({}) must be either resnet50 or resnet101.\".format(backbone)\n        if backbone == \"resnet50\":\n            return np.array([image_shape[0] // 4, image_shape[1] // 8, image_shape[2] // 16, image_shape[2] // 32])\n        elif backbone == \"resnet101\":\n            return np.array([image_shape[0] // 4, image_shape[1] // 8, image_shape[2] // 16, image_shape[2] // 32, image_shape[2] // 64])\n    return None", "CodeBleu_score": 36.02992266468636}, {"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape, config)\n    else:\n        backbone = config.BACKBONE\n        assert backbone in [\"resnet50\", \"resnet101\"], \"Backbone '{}' not supported.\".format(backbone)\n        return {\n            \"resnet50\": compute_resnet50_shapes,\n            \"resnet101\": compute_resnet101_shapes,\n        }[backbone](image_shape)\n\n", "CodeBleu_score": 38.75776005684953}, {"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape, config)\n    elif config.BACKBONE == \"resnet50\":\n        return {\n            \"res2\": (math.ceil(image_shape[0] / 4), math.ceil(image_shape[1] / 4)),\n            \"res3\": (math.ceil(image_shape[0] / 8), math.ceil(image_shape[1] / 8)),\n            \"res4\": (math.ceil(image_shape[0] / 16), math.ceil(image_shape[1] / 16)),\n            \"res5\": (math.ceil(image_shape[0] / 32), math.ceil(image_shape[1] / 32)),\n        }\n    elif config.BACKBONE == \"resnet101\":\n        return {\n            \"res2\": (math.ceil(image_shape[0] / 4), math.ceil(image_shape[1] / 4)),\n            \"res3\": (math.ceil(image_shape[0] / 8), math.ceil(image_shape[1] / 8)),\n            \"res4\": (math.ceil(image_shape[0] / 16), math.ceil(image_shape[1] / 16)),\n            \"res5\": (math.ceil(image_shape[0] / 32), math.ceil(image_shape[1] / 32)),\n        }\n    else:\n        return {\n            \"res2\": (math.ceil(image_shape[0] / config.BACKBONE_STRIDES[0]), math.ceil(image_shape[1] / config.BACKBONE_STRIDES[1])),\n            \"res3\": (math.ceil(image_shape[0] / config.BACKBONE_STRIDES[2]), math.ceil(image_shape[1] / config.BACKBONE_STRIDES[3])),\n            \"res4\": (math.ceil(image_shape[0] / config.BACKBONE_STRIDES", "CodeBleu_score": 37.26007438375593}]}
{"instance_id": "ebd61a2e59ca", "generation_result": [{"code": "def clip_boxes_graph(boxes, window)\n\t\n    # Convert to 2D image coordinates.\n    shape = tf.shape(input=boxes)\n    boxes = tf.reshape(boxes, [-1, 4])\n    window = tf.tile(tf.convert_to_tensor(window, dtype=boxes.dtype), [shape[0]])\n    window = tf.reshape(window, [-1, 4])\n    ori_boxes = boxes\n    # Convert to 0-indexed and to relative [0, 1) coordinates:\n    boxes = tf.concat([boxes[:, :2] - window[:, :2], boxes[:, 2:] - window[:, :2]], axis=-1)\n    boxes = tf.concat([boxes[:, :2] / (window[:, 2:] - window[:, :2]), boxes[:, 2:] / (window[:, 2:] - window[:, :2])],\n                      axis=-1)\n    boxes = tf.split(value=boxes, num_or_size_splits=2, axis=1)\n    boxes = tf.concat([tf.maximum(boxes[0], 0.0), tf.minimum(boxes[1], 1.0)], axis=1)\n    return tf.concat([boxes[:, :2] * (window[:, 2:] - window[:, :2]),\n                      boxes[:, 2:] * (window[:, 2:] - window[:, :2]) + window[:, :2]], axis=1)\n\n", "CodeBleu_score": 16.143156301629}, {"code": "def clip_boxes_graph(boxes, window)\n\t\n    window_shape = tf.shape(window)\n    window_rank = tf.rank(window)\n    window_expand_dims = tf.expand_dims(window, axis=0)\n    window_shape_expand_dims_tiled = tf.tile(tf.expand_dims(window_shape, 1), [1, 2])\n    window_rank_expand_dims_tiled = tf.tile(tf.expand_dims(window_rank, 1), [1, 2])\n    window_starts = window_expand_dims[0, 0, :]\n    window_sizes = window_expand_dims[0, 1, :]\n    rank_indices = tf.range(0, 2 * window_rank)\n    rank_indices = tf.reshape(rank_indices, [2, window_rank])\n    rank_indices = tf.transpose(rank_indices)\n    rank_indices = tf.reshape(rank_indices, [-1])\n    window_starts = tf.gather(window_starts, rank_indices)\n    window_sizes = tf.gather(window_sizes, rank_indices)\n    window_starts = tf.reshape(window_starts, window_shape_expand_dims_tiled)\n    window_sizes = tf.reshape(window_sizes, window_shape_expand_dims_tiled)\n    boxes = tf.split(boxes, 2, axis=-1)\n    boxes_starts, boxes_sizes = boxes\n    boxes_starts = tf.split(boxes_starts, 2, axis=-1)\n    boxes_sizes = tf.split(boxes_sizes, 2, axis=-1)\n    boxes_starts_min = tf.maximum(window_starts, boxes_starts[0])\n    boxes_starts_max = tf.minimum(window_starts + window_sizes, boxes_starts[1])\n    boxes_sizes_min =", "CodeBleu_score": 21.830856646209096}, {"code": "def clip_boxes_graph(boxes, window)\n\t\n    wy1, wx1, wy2, wx2 = tf.split(window, 4)\n    y1, x1, y2, x2 = tf.split(boxes, 4, axis=1)\n    y1 = tf.maximum(tf.minimum(y1, wy2), wy1)\n    x1 = tf.maximum(tf.minimum(x1, wx2), wx1)\n    y2 = tf.maximum(tf.minimum(y2, wy2), wy1)\n    x2 = tf.maximum(tf.minimum(x2, wx2), wx1)\n    clipped = tf.concat([y1, x1, y2, x2], 1)\n    clipped.set_shape((clipped.shape[0], 4))\n    return clipped\n\n", "CodeBleu_score": 55.648337002718286}]}
{"instance_id": "8e0411587a70", "generation_result": [{"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    num_anchors = len(anchors_per_location)\n    # Shared convolutional base of the RPN\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv_shared')(feature_map)\n\n    # Classification scores (before softmax) for all anchors on all feature maps\n    x = KL.Conv2D(num_anchors * 2, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_class_raw')(shared)\n\n    # Reshape to (batch, num_anchors, height, width, 2)\n    rpn_class_logits = tf.reshape(x, (tf.shape(x)[0], num_anchors, 2, tf.shape(x)[1], tf.shape(x)[2]))\n\n    # Axis 1 is the anchor dimension: [1, 2, 3]\n    rpn_class_logits = tf.transpose(rpn_class_logits, [0, 1, 3, 4, 2])\n\n    # Get all the class scores for the anchors\n    rpn_class_scores_reshape = tf.reshape(rpn_class_logits, (tf.shape(rpn_class_logits)[0], -1, 2))\n\n    # Softmax classifier\n    rpn_class_scores = KL.Activation('softmax', name='rpn_class_xxx', dtype='float32')(rpn_class_scores_reshape)\n\n    # Bounding box predictions\n    x = KL.Conv2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_bbox_pred')(shared)\n\n    # Reshape to (batch, num_anchors, height, width, 4)\n    rpn_bbox_pred = tf.reshape(x", "CodeBleu_score": 34.89603819433477}, {"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    # Shared convolutional base of the RPN\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv_shared')(feature_map)\n\n    # Classification scores\n    x = KL.Conv2D(anchors_per_location * 2, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_class_raw')(shared)\n    rpn_class_logits = tf.reshape(x, tf.shape(x)[:3] + tf.constant([2, anchors_per_location]))\n    rpn_class = KL.Activation('softmax', name='rpn_class')(rpn_class_logits)\n\n    # Bounding box predictions\n    x = KL.Conv2D(anchors_per_location * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_bbox_pred')(shared)\n    rpn_bbox = tf.reshape(x, tf.shape(x)[:3] + tf.constant([4, anchors_per_location]))\n\n    # Reshape for the classifier and regressor heads\n    rpn_class = tf.transpose(rpn_class, [0, 3, 1, 2])\n    rpn_class = tf.reshape(rpn_class, [-1, 2])\n    rpn_bbox = tf.transpose(rpn_bbox, [0, 3, 1, 2])\n    rpn_bbox = tf.reshape(rpn_bbox, [-1, 4])\n\n    # Define the Lambda layer to normalize the bounding box predictions\n    def bbox_normalize(x):\n        return x / anchor_stride\n\n    # Normalize the bounding box predictions\n    rpn_bbox = KL.Lambda(bbox_normalize, name='rpn_bbox", "CodeBleu_score": 51.22936445974031}, {"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    # Shared convolutional base of the RPN\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv_shared')(feature_map)\n\n    # Classification scores\n    x = KL.Conv2D(anchors_per_location * 2, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_class_raw')(shared)\n    rpn_class_logits = tf.reshape(x, tf.shape(x)[0:-1] + (2, anchors_per_location))\n    rpn_class = KL.Activation('softmax', name='rpn_class')(rpn_class_logits)\n\n    # Regression deltas\n    x = KL.Conv2D(anchors_per_location * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_bbox_pred')(shared)\n    rpn_bbox_pred = tf.reshape(x, tf.shape(x)[0:-1] + (4, anchors_per_location))\n\n    # Generate proposals\n    rpn_class = KL.Lambda(lambda x: tf.transpose(x, (0, 3, 1, 2)), name='rpn_class_transpose')(rpn_class)\n    rpn_class = KL.Lambda(lambda x: tf.reshape(x, [-1, 2]), name='rpn_class_reshape')(rpn_class)\n    rpn_bbox_pred = KL.Lambda(lambda x: tf.transpose(x, (0, 3, 1, 2)), name='rpn_bbox_pred_transpose')(rpn_bbox_pred)\n    rpn_bbox_pred = KL.Lambda(lambda x: tf.reshape(x, [-1, 4]), name='rpn_", "CodeBleu_score": 50.783188163794044}]}
{"instance_id": "70777c9261d8", "generation_result": [{"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    abs_diff = K.abs(y_true - y_pred)\n    loss = K.switch(abs_diff < 1, 0.5 * K.square(abs_diff), abs_diff - 0.5)\n    return K.mean(loss)\n\n", "CodeBleu_score": 23.408186544372494}, {"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    abs_diff = K.abs(y_true - y_pred)\n    less_one = K.less(abs_diff, 1)\n    loss = K.cast(less_one, 'float32') * 0.5 * abs_diff ** 2 + (1 - K.cast(less_one, 'float32')) * (abs_diff - 0.5)\n    return K.mean(loss)\n\n", "CodeBleu_score": 33.654193596809044}, {"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    # Calculate the absolute difference between true and predicted values\n    diff = K.abs(y_true - y_pred)\n\n    # Create a mask for values less than one\n    mask = K.less(diff, 1.0)\n\n    # Calculate the squared difference for small values\n    squared_diff = K.cast(mask, K.floatx()) * K.square(diff)\n\n    # Calculate the linear difference for large values\n    linear_diff = K.cast(K.not_equal(mask, 1.0), K.floatx()) * (diff - 0.5)\n\n    # Combine the squared and linear differences\n    loss = squared_diff + linear_diff\n\n    # Return the mean of the loss\n    return K.mean(loss)\n\n", "CodeBleu_score": 29.164699904577002}]}
{"instance_id": "0e747b604087", "generation_result": [{"code": "def build_model(x_train, num_classes)\n\t\n    model = KM.Model(inputs=KL.Input(shape=x_train.shape[1:]), outputs=KL.Dense(num_classes, activation='softmax')(KL.Flatten()(KL.MaxPooling2D(pool_size=(2, 2))(KL.Conv2D(32, (3, 3), activation='relu')(KL.Conv2D(32, (3, 3), activation='relu')(KL.Input(shape=x_train.shape[1:])))))))\n    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\n", "CodeBleu_score": 35.14756895180322}, {"code": "def build_model(x_train, num_classes)\n\t\n    tf.reset_default_graph()\n    model = KM.Model()\n    model.add(KL.Input(shape=x_train.shape[1:]))\n    model.add(KL.Conv2D(32, (3, 3), activation='relu'))\n    model.add(KL.Conv2D(64, (3, 3), activation='relu'))\n    model.add(KL.MaxPooling2D(pool_size=(2, 2)))\n    model.add(KL.Flatten())\n    model.add(KL.Dense(128, activation='relu'))\n    model.add(KL.Dense(num_classes, activation='softmax'))\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n", "CodeBleu_score": 27.34729608529747}, {"code": "def build_model(x_train, num_classes)\n\t\n    model = KM.Model()\n    model.add(KL.Input(shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3])))\n    model.add(KL.Conv2D(32, (3, 3), activation='relu'))\n    model.add(KL.Conv2D(64, (3, 3), activation='relu'))\n    model.add(KL.MaxPooling2D(pool_size=(2, 2)))\n    model.add(KL.Flatten())\n    model.add(KL.Dense(128, activation='relu'))\n    model.add(KL.Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\n", "CodeBleu_score": 27.45242964439501}]}
{"instance_id": "813e3e2844f4", "generation_result": [{"code": "def extract_bboxes(mask)\n\t\n    \n    # Initialize an array to store the bounding boxes for each mask layer\n    boxes = np.zeros([mask.shape[0], 4], dtype=np.int32)\n\n    # Iterate over each mask layer\n    for i in range(mask.shape[0]):\n        # Get the mask for the current layer\n        m = mask[i]\n\n        # Get the indices where the mask is present\n        y, x = np.where(m >= 0.5)\n\n        # If no mask is present, set the bounding box to zeros\n        if len(x) == 0:\n            boxes[i] = np.zeros(4, dtype=np.int32)\n            continue\n\n        # Calculate the coordinates of the bounding box\n        x1 = np.min(x)\n        x2 = np.max(x)\n        y1 = np.min(y)\n        y2 = np.max(y)\n\n        # Store the bounding box in the array\n        boxes[i] = np.array([x1, y1, x2, y2])\n\n    return boxes.astype(np.int32)\n\n", "CodeBleu_score": 31.50583705846862}, {"code": "def extract_bboxes(mask)\n\t\n    # put all masks in a big array\n    # mask: (N, H, W)\n    boxes = [np.zeros([mask.shape[0], 4], dtype=np.int32) for _ in range(mask.shape[0])]\n    for i in range(mask.shape[0]):\n        m = mask[i, :, :]\n        # (H, W, C)\n        ids = np.where(m)\n        xmin = np.min(ids[1])\n        xmax = np.max(ids[1])\n        ymin = np.min(ids[0])\n        ymax = np.max(ids[0])\n        boxes[i] = [xmin, ymin, xmax, ymax]\n    return np.array(boxes, dtype=np.int32)\n\n", "CodeBleu_score": 19.527278648372516}, {"code": "def extract_bboxes(mask)\n\t\n    # Initialize an array to store the bounding boxes\n    boxes = np.zeros((mask.shape[0], 4), dtype=np.int32)\n\n    # Loop through each mask layer\n    for i in range(mask.shape[0]):\n        # Get the indices of the mask layer\n        y, x = np.where(mask[i])\n\n        # Calculate the bounding box coordinates\n        if len(x) > 0 and len(y) > 0:\n            xmin, xmax = np.min(x), np.max(x)\n            ymin, ymax = np.min(y), np.max(y)\n            boxes[i] = [xmin, ymin, xmax, ymax]\n        else:\n            boxes[i] = [0, 0, 0, 0]\n\n    return boxes\n\n", "CodeBleu_score": 23.2914072926641}]}
{"instance_id": "7ad5d430d6ed", "generation_result": [{"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    # Calculate intersections\n    ixmin = np.maximum(box[0], boxes[:, 0])\n    iymin = np.maximum(box[1], boxes[:, 1])\n    ixmax = np.minimum(box[2], boxes[:, 2])\n    iymax = np.minimum(box[3], boxes[:, 3])\n    iw = np.maximum(ixmax - ixmin, 0.)\n    ih = np.maximum(iymax - iymin, 0.)\n    inters = iw * ih\n\n    # Calculate union areas\n    uni = ((box[2] - box[0]) * (box[3] - box[1]) +\n           boxes_area - inters)\n\n    # Compute IoU\n    iou = inters / uni\n    return iou\n\n", "CodeBleu_score": 31.112045707695813}, {"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    # Calculate the intersection areas\n    y1 = np.maximum(box[0], boxes[:, 0])\n    y2 = np.minimum(box[2], boxes[:, 2])\n    x1 = np.maximum(box[1], boxes[:, 1])\n    x2 = np.minimum(box[3], boxes[:, 3])\n    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n    # Calculate the union areas\n    union = box_area + boxes_area[:] - intersection[:]\n    # Compute the IoU values\n    iou = intersection / union\n    return iou\n\n", "CodeBleu_score": 58.663259083089194}, {"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    y1 = np.maximum(box[0], boxes[:, 0])\n    y2 = np.minimum(box[2], boxes[:, 2])\n    x1 = np.maximum(box[1], boxes[:, 1])\n    x2 = np.minimum(box[3], boxes[:, 3])\n    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n    union = box_area + boxes_area[:] - intersection[:]\n    iou = intersection / union\n    return iou\n\n", "CodeBleu_score": 58.663259083089194}]}
{"instance_id": "15941b852859", "generation_result": [{"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # If either box is empty, return empty result\n    if boxes1.shape[0] == 0 or boxes2.shape[0] == 0:\n        return np.zeros((boxes1.shape[0], boxes2.shape[0]))\n    # Compute intersections\n    ixmin = np.maximum(boxes1[:, 0], boxes2[:, 0])\n    iymin = np.maximum(boxes1[:, 1], boxes2[:, 1])\n    ixmax = np.minimum(boxes1[:, 2], boxes2[:, 2])\n    iymax = np.minimum(boxes1[:, 3], boxes2[:, 3])\n    iw = np.maximum(ixmax - ixmin, 0)\n    ih = np.maximum(iymax - iymin, 0)\n    inters = iw * ih\n    # Compute unions\n    uni = ((boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1]) +\n           (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1]) -\n           inters)\n    # Compute IoU and reshape to [boxes1 count, boxes2 count]\n    iou = inters / uni\n    overlaps = iou.reshape(boxes1.shape[0], boxes2.shape[0])\n    return overlaps\n\n", "CodeBleu_score": 50.42107444455542}, {"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # If either box is empty, return empty result\n    if boxes1.shape[0] == 0 or boxes2.shape[0] == 0:\n        return np.zeros((boxes1.shape[0], boxes2.shape[0]))\n    # Compute intersections\n    ixmin = np.maximum(boxes1[:, 0], boxes2[:, 0])\n    iymin = np.maximum(boxes1[:, 1], boxes2[:, 1])\n    ixmax = np.minimum(boxes1[:, 2], boxes2[:, 2])\n    iymax = np.minimum(boxes1[:, 3], boxes2[:, 3])\n    iw = np.maximum(ixmax - ixmin + 1., 0.)\n    ih = np.maximum(iymax - iymin + 1., 0.)\n    inters = iw * ih\n    # Compute unions\n    uni = ((boxes1[:, 2] - boxes1[:, 0] + 1.) * (boxes1[:, 3] - boxes1[:, 1] + 1.) +\n           (boxes2[:, 2] - boxes2[:, 0] + 1.) * (boxes2[:, 3] - boxes2[:, 1] + 1.) -\n           inters)\n    overlaps = inters / uni\n    return overlaps\n\n", "CodeBleu_score": 42.08552220801566}, {"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # If there are no boxes in either set of boxes, return an empty matrix.\n    if len(boxes1) == 0 or len(boxes2) == 0:\n        return np.zeros((len(boxes1), len(boxes2)), dtype=np.float32)\n\n    # Compute the area of each box in both sets of boxes.\n    area1 = boxes1[:, 2] * boxes1[:, 3]\n    area2 = boxes2[:, 2] * boxes2[:, 3]\n\n    # Initialize the overlap matrix with zeros.\n    overlaps = np.zeros((len(boxes1), len(boxes2)), dtype=np.float32)\n\n    # Iterate through each box in the second set of boxes.\n    for i in range(len(boxes2)):\n        # Compute the intersection over union (IoU) between the current box in the second set and all boxes in the first set.\n        overlaps[:, i] = compute_iou(boxes1, boxes2[i])\n\n    # Return the overlap matrix.\n    return overlaps\n\n", "CodeBleu_score": 39.76661772630477}]}
{"instance_id": "597533722ce3", "generation_result": [{"code": "def load_image(self, image_id):\n\t\n    image = self.image_info[image_id]\n    image_path = os.path.join(self.image_dir, image['path'])\n    image = Image.open(image_path)\n    image = image.convert('RGB')\n    image = np.array(image)\n    if image.shape[-1] == 4:\n        image = image[:, :, :3]\n    return image\n\n", "CodeBleu_score": 55.894552762928754}, {"code": "def load_image(self, image_id):\n\t\n    image_path = self.image_info[image_id]['path']\n    image = cv2.imread(image_path)\n    if image.shape[2] == 4:\n        image = image[:, :, :3]\n    if image.shape[2] == 1:\n        image = gray2rgb(image)\n    return image\n\n", "CodeBleu_score": 53.15298051235129}, {"code": "def load_image(self, image_id):\n\t\n    image_info = self.image_info[image_id]\n    image_path = image_info[\"path\"]\n    image = skimage.io.imread(image_path)\n    if image.shape[-1] == 4:\n        image = image[:, :, :3]\n    if image.shape[-1] == 1:\n        image = np.repeat(image, 3, -1)\n    image = image.astype(np.uint8)\n    return image\n\n", "CodeBleu_score": 55.25658801222391}]}
{"instance_id": "9b852997ca05", "generation_result": [{"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    rows = len(images) // cols + 1\n    for i, (image, title) in enumerate(zip(images, titles)):\n        plt.subplot(rows, cols, i + 1)\n        plt.imshow(image, cmap=cmap, norm=norm, interpolation=interpolation)\n        if title:\n            plt.title(title)\n    plt.show()\n\n", "CodeBleu_score": 34.311299653901415}, {"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    rows = int(len(images) / cols) + 1\n    fig = plt.figure(figsize=(14, 14 * rows // cols))\n    i = 1\n    for image, title in zip(images, titles):\n        plt.subplot(rows, cols, i)\n        plt.title(title)\n        plt.imshow(image, cmap=cmap, norm=norm, interpolation=interpolation)\n        plt.axis('off')\n        i += 1\n    plt.tight_layout()\n    plt.show()\n\n", "CodeBleu_score": 57.8597337640646}, {"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    rows = len(images) // cols + 1\n    plt.figure(figsize=(14, 14 * rows // cols))\n    i = 1\n    for image, title in zip(images, titles):\n        plt.subplot(rows, cols, i)\n        plt.title(title)\n        plt.imshow(image, cmap=cmap, norm=norm, interpolation=interpolation)\n        plt.axis('off')\n        i += 1\n    plt.show()\n\n", "CodeBleu_score": 54.88368504804219}]}
