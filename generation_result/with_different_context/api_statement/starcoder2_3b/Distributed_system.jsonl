{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    if self.loop_wait < 2:\n        self.loop_wait = 2\n    return (self.loop_wait - 2) * 1000, self._orig_kazoo_connect(*args)\n\n", "CodeBleu_score": 47.46008403228041}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    self._orig_kazoo_connect(*args)\n    wait_time = self.loop_wait - 2\n    if wait_time < 2:\n        wait_time = 2\n    return (wait_time * 1000, *args)", "CodeBleu_score": 48.56826957230547}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    self._orig_kazoo_connect = self.kazoo_connect\n    wait_time = (self.loop_wait - 2) * 1000\n    return wait_time, self._orig_kazoo_connect(*args)\n\n", "CodeBleu_score": 44.48382331951642}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, dict):\n        config = Config(config)\n    if self.set_retry_timeout:\n        self.set_retry_timeout(config.retry_timeout)\n    if self.set_loop_wait_time:\n        self.set_loop_wait_time(config.loop_wait_time)\n    if self.set_ttl:\n        self.set_ttl(config.ttl)\n    if self.set_connect_timeout:\n        if self.handler_type == PatroniSequentialThreadingHandler:\n            self.set_connect_timeout(config.connect_timeout)\n", "CodeBleu_score": 34.28898085930696}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, dict):\n        config = Config(config)\n    self.set_retry_timeout(config.retry_timeout)\n    self.set_loop_wait_time(config.loop_wait_time)\n    self.set_ttl(config.ttl)\n    if self.handler_type == PatroniSequentialThreadingHandler:\n        self.set_connect_timeout(config.connect_timeout)", "CodeBleu_score": 33.048115416366905}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, dict):\n        config = Config(config)\n    if config.retry_timeout!= self.retry_timeout:\n        self.retry_timeout = config.retry_timeout\n        self.set_retry_timeout(self.retry_timeout)\n    if config.loop_wait_time!= self.loop_wait_time:\n        self.loop_wait_time = config.loop_wait_time\n        if self.handler_type == PatroniSequentialThreadingHandler:\n            self.set_connect_timeout(self.loop_wait_time)\n    if config.ttl!= self.ttl:\n        self.ttl = config.ttl\n        self.set_ttl(self.ttl)\n\n", "CodeBleu_score": 34.4328044011781}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    if not os.path.exists(path):\n        raise ValueError(f\"The path {path} does not exist.\")\n    cluster_config = ClusterConfig.from_node(path)\n    sync_state = SyncState.from_node(path)\n    timeline_history = TimelineHistory.from_node(path)\n    members = self.get_members(path)\n    leader = self.get_leader(path)\n    status = self.get_status(path)\n    failover = self.get_failover(path)\n    failsafe = self.get_failsafe(path)\n    return Cluster(cluster_config, sync_state, timeline_history, members, leader, status, failover, failsafe)\n\n", "CodeBleu_score": 11.215638450774597}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    if not os.path.exists(path):\n        raise ValueError(f\"The specified path {path} does not exist.\")\n    config_path = os.path.join(path, \"config\")\n    if not os.path.exists(config_path):\n        raise ValueError(f\"The specified path {config_path} does not exist.\")\n    config = ClusterConfig.from_node(config_path)\n    timeline_history_path = os.path.join(path, \"timeline_history\")\n    if not os.path.exists(timeline_history_path):\n        raise ValueError(f\"The specified path {timeline_history_path} does not exist.\")\n    timeline_history = TimelineHistory.from_node(timeline_history_path)\n    sync_state_path = os.path.join(path, \"sync_state\")\n    if not os.path.exists(sync_state_path):\n        raise ValueError(f\"The specified path {sync_state_path} does not exist.\")\n    sync_state = SyncState.from_node(sync_state_path)\n    members_path = os.path.join(path, \"members\")\n    if not os.path.exists(members_path):\n        raise ValueError(f\"The specified path {members_path} does not exist.\")\n    members = self.load_members(members_path)\n    leader_path = os.path.join(path, \"leader\")\n    if not os.path.exists(leader_path):\n        raise ValueError(f\"The specified path {leader_path} does not exist.\")\n    leader = Leader.from_node(leader_path)\n    status_path = os.path.join(path, \"status\")\n    if not os.path.exists(status_path):\n        raise ValueError(f\"The specified path {status_path} does not exist.\")\n    status = self.get_status(status_path)\n    failover_path = os.path.join(path, \"failover\")\n    if not os.path.exists(failover_path):\n        raise ValueError(f\"The specified path {failover_path} does not exist.\")\n    failover = Failover.from_node(failover_path)\n    failsafe_path = os.path.join(path, \"failsafe\")\n    if not os.path.exists(failsafe_path):\n       ", "CodeBleu_score": 19.659557153845963}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(name=path.split(\"/\")[-1])\n    cluster.set_path(path)\n    cluster.set_initialized(os.path.exists(path + \"/initdb\"))\n    cluster.set_config(ClusterConfig.from_node(path))\n    cluster.set_timeline_history(TimelineHistory.from_node(path))\n    cluster.set_sync_state(SyncState.from_node(path))\n    cluster.set_members(self.get_members(path))\n    cluster.set_leader(Leader.from_node(path))\n    cluster.set_status(self.get_status(path))\n    cluster.set_failover(Failover.from_node(path))\n    cluster.set_failsafe_config(self.get_failsafe_config(path))\n    return cluster\n\n", "CodeBleu_score": 9.37110700507657}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self._leader_lock_path = self._get_leader_lock_path()\n        self._leader_lock = self._zk.create(self._leader_lock_path, b", "CodeBleu_score": 19.754618158788738}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self", "CodeBleu_score": 3.5585868493037647}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.leader_path, b''", "CodeBleu_score": 8.373786991010688}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.client_id!= self.client_id:\n        logger.warning(\n            f\"Leader client ID mismatch: {leader.client_id}!= {self.client_id}\"\n        )\n        try:\n            self.zk.delete(leader.path)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError):\n            pass\n        return False\n    try:\n        self.zk.create(leader.path, leader.client_id.encode(\"utf-8\"))\n        return True\n    except ZooKeeperError as e:\n        logger.error(f\"Failed to create leader node: {e}\")\n        return False\n\n", "CodeBleu_score": 30.341118532973628}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self.client_id!= leader.session_id:\n        logger.warning(\n            \"Leader's session ID (%s) does not match the current client's ID (%s). Leader will be deleted.\",\n            leader.session_id,\n            self.client_id,\n        )\n        try:\n            self.zk.delete(leader.path, recursive=True)\n        except ZooKeeperError as e:\n            if e.code in (NoNodeError, ConnectionClosedError, RetryFailedError):\n                pass\n            else:\n                raise\n        return False\n\n    try:\n        self.zk.create(leader.path, self.client_id.encode(\"utf-8\"), ephemeral=True)\n        return True\n    except ZooKeeperError as e:\n        if e.code in (NoNodeError, ConnectionClosedError, RetryFailedError):\n            pass\n        else:\n            raise\n\n", "CodeBleu_score": 41.28989453390114}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self.leader_id == leader.id:\n        return True\n    try:\n        self.zk.delete(self.leader_path, recursive=True)\n    except NoNodeError:\n        pass\n    except ZooKeeperError as e:\n        logger.warning(f\"Failed to delete leader node: {e}\")\n        return False\n    try:\n        self.zk.create(self.leader_path, leader.id.encode(), makepath=True)\n    except ZooKeeperError as e:\n        logger.warning(f\"Failed to create leader node: {e}\")\n        return False\n    return True\n\n", "CodeBleu_score": 32.22403721235841}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    now", "CodeBleu_score": 0.2688172043010753}, {"code": "def poll(self) -> bool\n\t\n    if", "CodeBleu_score": 0.2976325481292642}, {"code": "def poll(self) -> bool\n\t\n    if", "CodeBleu_score": 0.2976325481292642}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    try:\n        return loader(path)\n    except Exception as e:\n        raise ClusterLoadError(f\"Failed to load cluster configuration from {path}: {e}\")\n\n", "CodeBleu_score": 45.64731329213363}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if not self.ensemble_provider:\n        raise RuntimeError(\"Ensemble provider is not available.\")\n    try:\n        hosts = self.ensemble_provider.get_hosts()\n        self.hosts.update(hosts)\n    except Exception as e:\n        raise RuntimeError(f\"Failed to get Zookeeper hosts: {e}\")\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 53.766609756787076}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if not self._is_ensemble_provider_available():\n        raise Exception(\"Ensemble provider is not available.\")\n    self._update_hosts(self._get_ensemble_provider_hosts())\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 55.636264085848694}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\ttry {\n\t\tString group = zookeeperListener.getGroup();\n\t\tString dataId = zookeeperListener.getDataId();\n\t\tlogUnsubscribeStarted(group, dataId);\n\t\tzookeeperListener.unsubscribe();\n\t\tlogUnsubscribeSucceeded(group, dataId);\n\t} catch (Exception e) {\n\t\tlogUnsubscribeFailed(e);\n\t}\n}", "CodeBleu_score": 56.26404398534382}, {"code": "public void destroy(){\n\t\tif (this.zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = this.group;\n\tString dataId = this.dataId;\n\tlogUnsubscribeStarted(group, dataId);\n\ttry {\n\t\tthis.zookeeperListener.unsubscribe(group, dataId);\n\t} catch (Exception e) {\n\t\tlogUnsubscribeFailed(group, dataId, e);\n\t}\n}", "CodeBleu_score": 54.795505938786846}, {"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString dataId = getDataId();\n\tString group = getGroup();\n\tif (StringUtils.isEmpty(dataId) || StringUtils.isEmpty(group)) {\n\t\treturn;\n\t}\n\tlogUnsubscribeStarted(dataId, group);\n\ttry {\n\t\tzookeeperListener.unsubscribe(dataId, group);\n\t\tlogUnsubscribeSucceeded(dataId, group);\n\t}\n\tcatch (Exception e) {\n\t\tlogUnsubscribeFailed(dataId, group, e);\n\t}\n}", "CodeBleu_score": 68.76307257490983}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getPayload().getMetadata();\n\t} else {\n\t\treturn new HashMap<String, String>();\n\t}\n}", "CodeBleu_score": 37.42210315805}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getPayload().getMetadata();\n\t}\n\treturn new HashMap<String, String>();\n}", "CodeBleu_score": 37.339648752253765}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getMetadata();\n\t} else {\n\t\treturn Collections.emptyMap();\n\t}\n}", "CodeBleu_score": 36.89126654525693}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = String.format(\"/%s/%s\", group, serviceId);\n\tNodeCache nodeCache = new NodeCache(zkClient, path);\n\tnodeCache.start();\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tString data = nodeCache.getCurrentData().getData();\n\t\t\tzookeeperSubscribeCallback.onConfigChange(data);\n\t\t}\n\t};\n\tnodeCache.getListenable().addListener(nodeCacheListener);\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n\tzkClient.subscribe(path, zookeeperListener);\n\treturn zookeeperListener;\n}", "CodeBleu_score": 66.39979669350389}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tif (this.zkClient == null) {\n\t\tthrow new Exception(\"Zookeeper is not connected\");\n\t}\n\tif (zookeeperSubscribeCallback == null) {\n\t\tthrow new Exception(\"ZookeeperSubscribeCallback is null\");\n\t}\n\tif (StringUtils.isBlank(group)) {\n\t\tthrow new Exception(\"Group is blank\");\n\t}\n\tif (StringUtils.isBlank(serviceId)) {\n\t\tthrow new Exception(\"ServiceId is blank\");\n\t}\n\tString path = ZookeeperConstants.ZK_CONFIG_ROOT + \"/\" + group + \"/\" + serviceId;\n\tNodeCache nodeCache = new NodeCache(this.zkClient, path);\n\tnodeCache.getListenable().addListener(new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tString data = nodeCache.getCurrentData().getData();\n\t\t\tConfig config = Config.fromJson(data);\n\t\t\tzookeeperSubscribeCallback.onConfigUpdated(config);\n\t\t}\n\t});\n\tnodeCache.start();\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, zookeeperSubscribeCallback);\n\tthis.zkListeners.add(zookeeperListener);\n\treturn zookeeperListener;\n}", "CodeBleu_score": 51.87510477646621}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tif (group == null || serviceId == null || zookeeperSubscribeCallback == null) {\n\t\tthrow new IllegalArgumentException(\"group, serviceId, and callback cannot be null\");\n\t}\n\tString path = ZookeeperUtils.getConfigPath(group, serviceId);\n\tNodeCache nodeCache = new NodeCache(zk, path);\n\tnodeCache.start();\n\tnodeCache.getListenable().addListener(new NodeCacheListener() {\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tString config = nodeCache.getCurrentData().toString();\n\t\t\tzookeeperSubscribeCallback.onConfigChange(config);\n\t\t}\n\t});\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, zookeeperSubscribeCallback);\n\tzk.registerListener(zookeeperListener);\n\treturn zookeeperListener;\n}", "CodeBleu_score": 52.916154775862225}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\treturn new ZookeeperServerListDecorator(config, serviceDiscovery);\n}", "CodeBleu_score": 16.854728783987206}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\treturn new ZookeeperServerListDecorator(config, serviceDiscovery);\n}", "CodeBleu_score": 16.854728783987206}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\treturn new ZookeeperServerListDecorator(config, serviceDiscovery);\n}", "CodeBleu_score": 16.854728783987206}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tif (this.registerListenerExecutor!= null) {\n\t\t\tthis.registerListenerExecutor.onRegister(registration);\n\t\t}\n\t}\n\tcatch (BeansException ex) {\n\t\t// Ignored\n\t}\n\tthis.serviceRegistry.register(registration);\n}", "CodeBleu_score": 30.76674883317655}, {"code": "public void register(ZookeeperRegistration registration){\n\t\tif (this.registerListenerExecutor!= null) {\n\t\ttry {\n\t\t\tthis.registerListenerExecutor.onRegister(registration);\n\t\t}\n\t\tcatch (BeansException ex) {\n\t\t\tlogger.error(\"Failed to execute onRegister method on RegisterListenerExecutor\", ex);\n\t\t}\n\t}\n\tif (this.serviceRegistry!= null) {\n\t\tthis.serviceRegistry.register(registration);\n\t}\n}", "CodeBleu_score": 30.04231932397556}, {"code": "public void register(ZookeeperRegistration registration){\n\t\tAssert.notNull(registration, \"Registration must not be null\");\n\tif (this.registerListenerExecutor == null) {\n\t\tthis.serviceRegistry.register(registration);\n\t}\n\telse {\n\t\ttry {\n\t\t\tthis.registerListenerExecutor.onRegister(registration);\n\t\t}\n\t\tcatch (BeansException ex) {\n\t\t\t// Ignored\n\t\t}\n\t\tthis.serviceRegistry.register(registration);\n\t}\n}", "CodeBleu_score": 31.320113430821067}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t\tif (registration == null) {\n\t\treturn;\n\t}\n\ttry {\n\t\tRegisterListenerExecutor executor = getRegisterListenerExecutor();\n\t\tif (executor!= null) {\n\t\t\texecutor.onDeregister(registration);\n\t\t}\n\t}\n\tcatch (BeansException ex) {\n\t\tlogger.warn(\"Failed to deregister \" + registration + \": \" + ex);\n\t}\n\tserviceRegistry.remove(registration);\n}", "CodeBleu_score": 37.389129246296335}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\tif (registration == null) {\n\t\tthrow new IllegalArgumentException(\"Registration must not be null\");\n\t}\n\tif (this.executor == null) {\n\t\tthis.executor = this.applicationContext.getBean(REGISTER_LISTENER_EXECUTOR_BEAN_NAME, RegisterListenerExecutor.class);\n\t}\n\ttry {\n\t\tthis.executor.onDeregister(registration);\n\t}\n\tcatch (BeansException ex) {\n\t\tlogger.warn(\"Failed to deregister \" + registration, ex);\n\t}\n\tthis.serviceRegistry.remove(registration);\n}", "CodeBleu_score": 42.422358859340925}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tif (this.registerListenerExecutor!= null) {\n\t\t\tthis.registerListenerExecutor.onDeregister(registration);\n\t\t}\n\t}\n\tcatch (BeansException ex) {\n\t\tlogger.warn(\"Failed to deregister registration '\" + registration + \"'\", ex);\n\t}\n\tthis.serviceRegistry.remove(registration);\n}", "CodeBleu_score": 30.89107420682738}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor executor = (RegisterListenerExecutor) this.applicationContext.getBean(\"registerListenerExecutor\");\n\t\texecutor.onClose();\n\t} catch (BeansException e) {\n\t\t// ignore\n\t}\n\tthis.serviceRegistry.close();\n}", "CodeBleu_score": 64.51615904127164}, {"code": "public void close(){\n\t\ttry {\n\t\tif (executor!= null) {\n\t\t\texecutor.onClose();\n\t\t}\n\t} catch (BeansException e) {\n\t\tlogger.error(\"Could not close RegisterListenerExecutor\", e);\n\t} finally {\n\t\tserviceRegistry.close();\n\t}\n}", "CodeBleu_score": 34.107805000495645}, {"code": "public void close(){\n\t\ttry {\n\t\tif (registerListenerExecutor!= null) {\n\t\t\tregisterListenerExecutor.onClose();\n\t\t}\n\t}\n\tcatch (BeansException ex) {\n\t\tlogger.warn(\"Failed to close RegisterListenerExecutor\", ex);\n\t}\n\tfinally {\n\t\tserviceRegistry.close();\n\t}\n}", "CodeBleu_score": 32.02384740637478}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = globalConfig? \"global\" : \"local\";\n\tString dataId = globalConfig? \"global\" : \"local\";\n\tlog.info(\"subscribeConfig start, group: {}, dataId: {}\", group, dataId);\n\tZookeeperListener listener = null;\n\ttry {\n\t\tlistener = zookeeperOperation.subscribeConfig(group, dataId, callbackConfig);\n\t} catch (Exception e) {\n\t\tlog.error(\"subscribeConfig failed, group: {}, dataId: {}\", group, dataId, e);\n\t}\n\treturn listener;\n}", "CodeBleu_score": 33.20390917535926}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = null;\n\tString dataId = null;\n\tif (globalConfig) {\n\t\tgroup = globalConfig.getGroup();\n\t\tdataId = globalConfig.getDataId();\n\t} else {\n\t\tgroup = config.getGroup();\n\t\tdataId = config.getDataId();\n\t}\n\tlog.info(\"subscribeConfig start, group={}, dataId={}\", group, dataId);\n\tZookeeperListener listener = null;\n\ttry {\n\t\tlistener = zookeeperOperation.subscribeConfig(group, dataId, new ZookeeperListener.ConfigListener() {\n\t\t\t@Override\n\t\t\tpublic void onDataChange(String dataId, byte[] data) {\n\t\t\t\tif (log.isInfoEnabled()) {\n\t\t\t\t\tlog.info(\"onDataChange, dataId={}, data={}\", dataId, data);\n\t\t\t\t}\n\t\t\t\ttry {\n\t\t\t\t\tString value = new String(data, \"UTF-8\");\n\t\t\t\t\tif (log.isInfoEnabled()) {\n\t\t\t\t\t\tlog.info(\"onDataChange, value={}\", value);\n\t\t\t\t\t}\n\t\t\t\t\tif (value!= null) {\n\t\t\t\t\t\tcallback.onDataChange(value);\n\t\t\t\t\t}\n\t\t\t\t} catch (UnsupportedEncodingException e) {\n\t\t\t\t\tlog.error(\"onDataChange, UnsupportedEncodingException\", e);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic void onDataDeleted(String dataId) {\n\t\t\t\tif (log.isInfoEnabled()) {\n\t\t\t\t\tlog.info(\"onDataDeleted, dataId={}\", dataId);\n\t\t\t\t}\n\t\t\t\tcallback.onDataDeleted();\n\t\t\t}\n\t\t});\n\t} catch (Exception e) {\n\t\tlog.error(\"subscribeConfig failed, group={}, dataId={}\", group, dataId, e);\n\t}\n\tlog.info(\"subscribeConfig end, group={}, dataId={}\", group, dataId);\n\treturn listener;\n}", "CodeBleu_score": 36.46627595827695}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = null;\n\tString dataId = null;\n\tif (globalConfig) {\n\t\tgroup = globalConfig.getGroup();\n\t\tdataId = globalConfig.getDataId();\n\t} else {\n\t\tgroup = config.getGroup();\n\t\tdataId = config.getDataId();\n\t}\n\tif (StringUtils.isBlank(group) || StringUtils.isBlank(dataId)) {\n\t\tlogger.error(\"No group or dataId provided.\");\n\t\treturn null;\n\t}\n\tlogger.info(\"Subscribing to \" + group + \" \" + dataId);\n\ttry {\n\t\treturn zookeeperOperation.subscribeConfig(group, dataId, callbackConfig);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Failed to subscribe to \" + group + \" \" + dataId, e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 38.70034949420417}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t\tString connectString = connectString();\n\tif (StringUtils.isBlank(connectString)) {\n\t\tthrow new DiscoveryException(\"Zookeeper connection string is empty\");\n\t}\n\tCuratorFrameworkBuilder builder = CuratorFrameworkFactory.builder().connectString(connectString);\n\tbuilder.retryPolicy(new ExponentialBackoffRetry(retryCount(), retrySleepTime()));\n\tCuratorFramework curatorFramework = builder.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 26.15303780904083}, {"code": "public CuratorFramework curatorFramework(){\n\t\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder().connectString(curatorProperties.getConnectionString()).retryPolicy(new ExponentialBackoffRetry(curatorProperties.getRetryCount(), curatorProperties.getSleepTime())).build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 21.078031874442775}, {"code": "public CuratorFramework curatorFramework(){\n\t\tString connectionString = environment.getProperty(CONNECTION_STRING_PROPERTY);\n\tif (StringUtils.isEmpty(connectionString)) {\n\t\tthrow new DiscoveryException(\"The Zookeeper connection string cannot be empty.\");\n\t}\n\tCuratorFrameworkBuilder builder = CuratorFrameworkFactory.builder();\n\tbuilder.connectString(connectionString);\n\tbuilder.retryPolicy(new ExponentialBackoffRetry(environment.getProperty(RETRY_COUNT_PROPERTY), environment.getProperty(SLEEP_TIME_PROPERTY)));\n\tCuratorFramework curatorFramework = builder.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 28.3258553146955}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * The GatewayRouteZookeeperConfiguration#gatewayRouteZookeeperProcessor method returns a new instance of GatewayStrategyRouteZookeeperProcessor.\n\t * @return The new instance of GatewayStrategyRouteZookeeperProcessor.\n\t */\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\t@Bean\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 46.98989029494944}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * The GatewayStrategyRouteZookeeperProcessor class is a bean that is used to get the routes from the zookeeper service registry.\n\t */\n\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 51.07095756322223}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * Returns a new instance of GatewayStrategyRouteZookeeperProcessor.\n\t */\n\t@Bean\n\t@ConditionalOnProperty(value = { \"spring.cloud.gateway.discovery.locator.enabled\", \"spring.cloud.gateway.discovery.locator.enabled\" }, matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 45.49017890958923}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\tCuratorFrameworkBuilder builder = CuratorFrameworkFactory.builder();\nbuilder.connectString(connectString);\nbuilder.retryPolicy(retryPolicy);\nbuilder.namespace(namespace);\nbuilder.sessionTimeoutMs(sessionTimeoutMs);\nCuratorFramework client = builder.build();\nclient.start();\nreturn client;\n}", "CodeBleu_score": 24.947530852797364}, {"code": "public  CuratorFramework createCuratorFramework(){\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n.connectString(getZkHosts())\n.sessionTimeoutMs(getSessionTimeout())\n.retryPolicy(retryPolicy)\n.namespace(getNamespace())\n.build();\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 40.11312586761942}, {"code": "public  CuratorFramework createCuratorFramework(){\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(getZkHosts(), getSessionTimeoutMs(), getNamespace(), getRetryPolicy());\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 28.976721631520313}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\tInterProcessMutex mutex = locksMap.get(path);\nif (mutex == null) {\nmutex = new InterProcessMutex(zk, path);\nlocksMap.put(path, mutex);\n}\ntry {\nmutex.acquire();\n} catch (Exception e) {\nthrow new DistributedLockException(e);\n}\n}", "CodeBleu_score": 22.908806728569814}, {"code": "public void lock(String path) throws DistributedLockException{\n\tif (!locksMap.containsKey(path)) {\nInterProcessMutex lock = new InterProcessMutex(zk, path);\ntry {\nlock.acquire();\nlocksMap.put(path, lock);\n} catch (Exception e) {\nthrow new DistributedLockException(\"Could not acquire lock for path: \" + path, e);\n}\n}\n}", "CodeBleu_score": 21.592515726154428}, {"code": "public void lock(String path) throws DistributedLockException{\n\t\tif (path == null) {\n\t\tthrow new DistributedLockException(\"Path cannot be null\");\n\t}\n\tif (!locksMap.containsKey(path)) {\n\t\ttry {\n\t\t\tInterProcessMutex mutex = new InterProcessMutex(zkClient, path);\n\t\t\tmutex.acquire();\n\t\t\tlocksMap.put(path, mutex);\n\t\t} catch (Exception e) {\n\t\t\tthrow new DistributedLockException(\"Could not acquire lock for path \" + path, e);\n\t\t}\n\t} else {\n\t\ttry {\n\t\t\tInterProcessMutex mutex = locksMap.get(path);\n\t\t\tmutex.acquire();\n\t\t} catch (Exception e) {\n\t\t\tthrow new DistributedLockException(\"Could not re-acquire lock for path \" + path, e);\n\t\t}\n\t}\n}", "CodeBleu_score": 33.902396759717796}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tString nodePath = getZookeeper(dtpProperties);\n\tMap<Object, Object> configMap = new HashMap<Object, Object>();\n\tif (dtpProperties.getConfigType().equalsIgnoreCase(\"PROPERTIES\")) {\n\t\tconfigMap = genPropertiesTypeMap(dtpProperties);\n\t} else if (dtpProperties.getConfigType().equalsIgnoreCase(\"JSON\")) {\n\t\tString configKey = getConfigKey(dtpProperties);\n\t\tString configValue = getValue(dtpProperties, curatorFramework, nodePath, configKey);\n\t\tconfigMap = parseConfig(configValue);\n\t}\n\treturn configMap;\n}", "CodeBleu_score": 44.14354309718438}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tString nodePath = getZookeeper(dtpProperties);\n\tif (dtpProperties.getConfigType().equalsIgnoreCase(PROPERTIES)) {\n\t\treturn genPropertiesTypeMap(dtpProperties, curatorFramework, nodePath);\n\t} else if (dtpProperties.getConfigType().equalsIgnoreCase(JSON)) {\n\t\tString configKey = getConfigKey(dtpProperties);\n\t\tString val = getValue(dtpProperties, curatorFramework, nodePath, configKey);\n\t\tMap<Object, Object> configMap = ConfigHandler.parseConfig(val, dtpProperties.getJsonType());\n\t\treturn configMap;\n\t}\n\treturn null;\n}", "CodeBleu_score": 43.92171585977944}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tString nodePath = getZookeeper(dtpProperties);\n\tString configKey = getConfigKey(dtpProperties);\n\tMap<Object, Object> map = null;\n\tif (dtpProperties.getConfigType().equalsIgnoreCase(\"PROPERTIES\")) {\n\t\tmap = genPropertiesTypeMap(curatorFramework, nodePath, configKey);\n\t} else if (dtpProperties.getConfigType().equalsIgnoreCase(\"JSON\")) {\n\t\tString value = getValue(curatorFramework, nodePath, configKey);\n\t\tmap = ConfigHandler.parseConfig(value);\n\t}\n\treturn map;\n}", "CodeBleu_score": 43.378488740290265}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = getInstance();\n\tbindDtpProperties(dtpProperties);\n\tgenPropertiesMap(dtpProperties);\n\tcheckPropertyExist(dtpProperties);\n\tcreateZkPropertySource(dtpProperties);\n}", "CodeBleu_score": 28.56450544702564}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = getInstance();\n\tbindDtpProperties(dtpProperties);\n\tMap<String, Object> propertiesMap = genPropertiesMap(dtpProperties);\n\tcheckPropertyExist(propertiesMap, dtpProperties);\n\tcreateZkPropertySource(propertiesMap, dtpProperties);\n}", "CodeBleu_score": 42.822647401734514}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = getDtpProperties();\n\tbindDtpProperties(dtpProperties);\n\tMap<String, Object> propertiesMap = genPropertiesMap(dtpProperties);\n\tcheckPropertyExist(propertiesMap);\n\tcreateZkPropertySource(propertiesMap);\n}", "CodeBleu_score": 36.51854182501682}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t//...\n}", "CodeBleu_score": 4.679638655496093}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tbuilder.Register(c => new ZooKeeperServiceRouteManager(c.Resolve<ILogger<ZooKeeperServiceRouteManager>>(), c.Resolve<ISerializer<byte[]>>(), c.Resolve<IServiceRouteFactory>(), c.Resolve<ISerializer<string>>(), c.Resolve<IZookeeperClientProvider>()))\n.As<IServiceRouteManager>()\n.SingleInstance();\nreturn this;\n}", "CodeBleu_score": 43.23237208834334}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tif (builder == null)\nthrow new ArgumentNullException(nameof(builder));\nif (configInfo == null)\nthrow new ArgumentNullException(nameof(configInfo));\n\nvar serializer = builder.RegisterSerializer(configInfo);\nvar routeFactory = builder.RegisterServiceRouteFactory(configInfo);\nvar logger = builder.RegisterLogger(configInfo);\nvar zookeeperClientProvider = builder.RegisterZookeeperClientProvider(configInfo);\n\nbuilder.RegisterZookeeperServiceRouteManager(configInfo, serializer, routeFactory, logger, zookeeperClientProvider);\nreturn this;\n}", "CodeBleu_score": 31.385919090431035}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t\n// 1. Get the ZookeeperServiceCommandManager\nvar commandManager = GetServiceCommandManager(builder, configInfo);\n\n// 2. Set the command manager on the ZookeeperModule\nbuilder.Services.AddSingleton(commandManager);\n\n// 3. Return the ZookeeperModule\nreturn builder.Build();\n}", "CodeBleu_score": 20.556499405388717}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t builder.RegisterInstance(new ZookeeperServiceCommandManager(configInfo, this.logger, this.serviceEntryManager, this.serializer, this.serializer, this.serviceRouteManager, this.zookeeperClientProvider));\n return this;\n}", "CodeBleu_score": 21.143683001758614}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t if (builder == null) {\n throw new ArgumentNullException(\"builder\");\n }\n if (configInfo == null) {\n throw new ArgumentNullException(\"configInfo\");\n }\n var commandManager = new ZookeeperServiceCommandManager(configInfo);\n builder.RegisterInstance(commandManager).As<IServiceCommandManager>().SingleInstance();\n return this;\n}", "CodeBleu_score": 29.506018401771012}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tCheck.NotNull(builder, nameof(builder));\nCheck.NotNull(path, nameof(path));\nif (provider == null) {\nprovider = new PhysicalFileProvider(Path.GetDirectoryName(path)?? string.Empty);\n}\nCheck.CheckCondition(Path.IsPathRooted(path), nameof(path), \"The path must be rooted.\");\nCheck.CheckCondition(!string.IsNullOrEmpty(path), nameof(path), \"The path must not be empty.\");\nvar source = new ZookeeperConfigurationSource(path, optional, reloadOnChange);\nreturn builder.Add(source);\n}", "CodeBleu_score": 47.783269491991355}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tCheck.NotNull(builder, nameof(builder));\nCheck.NotNull(path, nameof(path));\n\nif (provider == null) {\nif (!Path.IsPathRooted(path)) {\nprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n}\n}\n\nbuilder.Add(new ZookeeperConfigurationSource(provider, path, optional, reloadOnChange));\nreturn builder.Build();\n}", "CodeBleu_score": 39.87532786595492}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tCheck.NotNull", "CodeBleu_score": 10.716002942672857}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tawait base.SetRoutesAsync(await base.GetRoutesAsync().ConfigureAwait(false).Except(Address).ConfigureAwait(false));\n}", "CodeBleu_score": 21.227883594140376}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tawait base.RemveAddressAsync(Address);\n}", "CodeBleu_score": 11.763317050647991}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tawait base.SetRoutesAsync(await base.GetRoutesAsync().ConfigureAwait(false).Except(Address).ConfigureAwait(false));\n}", "CodeBleu_score": 21.227883594140376}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tvar routePaths = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar zooKeeperClients = _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeeperClients) {\nvar oldRoutes = await GetRoutesAsync(zooKeeper.Item2);\nvar oldRouteIds = oldRoutes.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\nforeach (var deletedRouteId in deletedRouteIds) {\nvar addresses = oldRoutes.Where(p => p.ServiceDescriptor.Id == deletedRouteId).Select(p => p.Address).FirstOrDefault();\nif (addresses.Contains(hostAddr)) {\nawait zooKeeper.Item2.deleteAsync(string.Format(RoutePathFormat, deletedRouteId));\n}\n}\n}\n}", "CodeBleu_score": 52.66441339480987}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tvar routePath = GetRoutePath(hostAddr);\nvar zooKeeperClients = _zookeeperClientProvider.GetZooKeepers();\nvar oldRouteIds = _routes.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar oldRouteAddresses = _routes.Where(p => p.ServiceDescriptor.Id.In(oldRouteIds)).Select(p => p.Address).ToArray();\nvar newRouteAddresses = routes.Where(p => p.ServiceDescriptor.Id.In(newRouteIds)).Select(p => p.Address).ToArray();\nvar oldRouteIdsExceptNew = oldRouteIds.Except(newRouteIds).ToArray();\nvar oldRouteAddressesExceptNew = oldRouteAddresses.Except(newRouteAddresses).ToArray();\nvar deletedRouteIds = oldRouteIdsExceptNew.Where(p => oldRouteAddressesExceptNew.Contains(p)).ToArray();\nvar deletedRouteIdsExceptNew = deletedRouteIds.Except(newRouteIds).ToArray();\nforeach (var zooKeeper in zooKeeperClients) {\nvar zooKeeperClient = zooKeeper.Item2;\nvar deletedRouteIdsExceptNewArray = deletedRouteIdsExceptNew.ToArray();\nif (deletedRouteIdsExceptNewArray.Length > 0) {\nvar deletedRoutePaths = deletedRouteIdsExceptNewArray.Select(p => GetRoutePath(p, hostAddr)).ToArray();\nvar deletedRouteAddresses = deletedRouteIdsExceptNewArray.Select(p => _routes.Where(i => i.ServiceDescriptor.Id == p).Select(i => i.Address).FirstOrDefault()).ToArray();\nforeach (var deletedRoutePath in deletedRoutePaths) {\nvar deletedRouteAddress = deletedRouteAddresses.FirstOrDefault(p => p.Host.Equals(hostAddr.Host) && p.Port == hostAddr.Port);\nif (deletedRouteAddress!= null) {\nawait zooKeeperClient.deleteAsync(deletedRoutePath);\n}\n}\n}\n}\n}", "CodeBleu_score": 43.79171513861349}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tvar routePaths = routes.Select(i => GetRoutePath(i.ServiceDescriptor.Id, i.Address)).ToArray();\nvar zooKeeperClients = await _zookeeperClientProvider.GetZooKeepers();\n\nforeach (var zooKeeper in zooKeeperClients) {\nvar oldRoutes = await zooKeeper.Item2.getChildrenAsync(routePaths[0]);\nvar oldRouteIds = oldRoutes.Select(i => i.Path.Split('/').Last()).ToArray();\nvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n\nvar deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\nvar deletedRoutePaths = deletedRouteIds.Select(i => GetRoutePath(i, hostAddr)).ToArray();\n\nforeach (var deletedRoutePath in deletedRoutePaths) {\nawait zooKeeper.Item2.deleteAsync(deletedRoutePath);\n}\n}\n}", "CodeBleu_score": 43.04661666886021}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {\nreturn null;\n}\n_logger.LogDebug\n(data);\nvar descriptor = await _serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\nreturn await _serviceRouteFactory.CreateAsync(descriptor);\n}", "CodeBleu_score": 28.9292036510841}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {\nreturn null;\n}\n\n_logger.LogDebug(\n$@\"{nameof(GetRoute)}(byte[] data) {{\nreturn {nameof(GetRouteAsync)}(data).Result;\n}}\u3002\");\n\nreturn await GetRouteAsync(data);\n}", "CodeBleu_score": 22.399588427662593}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t_logger.LogDebug", "CodeBleu_score": 6.763716145022788}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tldRoute = this.GetRoute(oldData);\n            var newRoute = this.GetRoute(newData);\n            if (oldRoute == null || newRoute == null)\n                return;\n\n            lock (_routes) {\n                _routes = _routes.Where(i => i.ServiceDescriptor.Id!= oldRoute.ServiceDescriptor.Id)\n                       .Concat(new[] { newRoute }).ToArray();\n            }\n\n            this.OnChanged(oldRoute, newRoute);\n        }", "CodeBleu_score": 57.23348478508324}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tewRoute = await _serializer.DeserializeAsync<Route>(newData);\nvar oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id);\nif (oldRoute == null) {\nreturn;\n}\n\nlock (_routes) {\n_routes = _routes.Except(new[] { oldRoute }).Concat(new[] { newRoute }).ToArray();\n}\n\nOnChanged(new RouteChangedEventArgs(oldRoute, newRoute));\n}", "CodeBleu_score": 56.037136444537936}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tldData.Equals(newData)) {\nreturn;\n}\n\nvar newRoute = await GetRoute(newData);\nvar oldRoute = _routes.SingleOrDefault(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id);\n\nif (oldRoute!= null) {\n_routes = _routes.Except(new[] { oldRoute }).Concat(new[] { newRoute }).ToArray();\n} else {\n_routes = _routes.Concat(new[] { newRoute }).ToArray();\n}\n\nOnChanged(oldRoute, newRoute);\n}", "CodeBleu_score": 53.089983143085576}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t\tvar serviceSubscribers = await this.serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscribers.First().ServiceDescriptor.Id).ToListAsync();\n\tvar existingSubscribers = serviceSubscribers.Select(p => p.Subscriber);\n\tvar newSubscribers = subscribers.Select(p => p.Subscriber);\n\tvar existingAddresses = existingSubscribers.SelectMany(p => p.Address).ToList();\n\tvar newAddresses = newSubscribers.SelectMany(p => p.Address).ToList();\n\tvar updatedAddresses = existingAddresses.Concat(newAddresses).Distinct();\n\tforeach (var subscriber in existingSubscribers) {\n\t\tsubscriber.Address = updatedAddresses.Intersect(subscriber.Address).ToList();\n\t}\n\tforeach (var subscriber in newSubscribers) {\n\t\tsubscriber.Address = updatedAddresses.Except(subscriber.Address).ToList();\n\t}\n\tawait base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 49.29513953591478}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tvar serviceSubscribers = await GetSubscribersAsync(subscribers).ConfigureAwait(false);\nforeach (var subscriber in serviceSubscribers) {\nvar newAddresses = subscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault().Address;\nsubscriber.Address = subscriber.Address.Concat(newAddresses).Except(subscriber.Address);\n}\nawait base.SetSubscribersAsync(subscribers).ConfigureAwait(false);\n}", "CodeBleu_score": 52.97721350738909}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t\tvar existingSubscribers = await GetSubscribersAsync(subscribers.Select(p => p.ServiceDescriptor.Id));\n\tvar existingSubscribersByService = existingSubscribers.GroupBy(p => p.ServiceDescriptor.Id);\n\n\tforeach (var existingSubscribersByServiceGroup in existingSubscribersByService) {\n\t\tvar existingSubscribers = existingSubscribersByServiceGroup.ToList();\n\t\tvar existingSubscriber = existingSubscribers.FirstOrDefault();\n\n\t\tif (existingSubscriber!= null) {\n\t\t\texistingSubscriber.Address = existingSubscriber.Address.Concat(subscribers.Where(p => p.ServiceDescriptor.Id == existingSubscriber.ServiceDescriptor.Id).SelectMany(p => p.Address)).Distinct();\n\t\t} else {\n\t\t\texistingSubscriber = subscribers.FirstOrDefault(p => p.ServiceDescriptor.Id == existingSubscribersByServiceGroup.Key);\n\t\t\texistingSubscriber.Address = existingSubscriber.Address.Concat(subscribers.Where(p => p.ServiceDescriptor.Id == existingSubscribersByServiceGroup.Key).SelectMany(p => p.Address)).Distinct();\n\t\t}\n\n\t\tawait SetSubscribersAsync(existingSubscriber);\n\t}\n\n\tawait base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 46.867425554870366}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar rootPath = $\"{_config.SubscriberPath}/\";", "CodeBleu_score": 8.080482771475026}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tif (_logger.IsEnabled(LogLevel.Debug)) {\nforeach (var child in childrens) {\n_logger.LogDebug(\"Retrieving subscribers for child '{child}'\", child);\n}\n}\nvar rootPath = $\"{_subscriberRootPath}/{_subscriberPath}\";\nvar children = childrens.ToArray();\nvar subscribers = new List<ServiceSubscriber>();\nforeach (var child in children) {\nvar nodePath = $\"{rootPath}/{child}\";\nvar subscriber = await _subscriberStore.GetSubscriberAsync(nodePath);\nif (subscriber!= null) {\nsubscribers.Add(subscriber);\n}\n}\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 46.67794748950677}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tif", "CodeBleu_score": 3.0782182380408596}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\tif (_subscribers!= null) {\nreturn;\n}\n\nvar zooKeeper = await GetZooKeeper();\n\n// Wait for the connection to be established\nawait zooKeeper.Item1.WaitOne();\n\n// If the subscriber path exists, fetch the children nodes and populate _subscribers with their data\nif (await zooKeeper.Item2.existsAsync(SubscriberPath)) {\nvar children = await zooKeeper.Item2.getChildrenAsync(SubscriberPath);\n_subscribers = children.Select(x => new Subscriber(x.Key, x.Value)).ToArray();\n}\n\n// If the path does not exist, log a warning and set _subscribers to an empty array\nelse {\n_logger.LogWarning($\"The subscriber path '{SubscriberPath}' does not exist.\");\n_subscribers = new Subscriber[0];\n}\n}", "CodeBleu_score": 45.3016203576034}, {"code": "private async Task EnterSubscribers(){\n\tif (_subscribers == null) {\nvar zooKeeper = await GetZooKeeper();\nawait zooKeeper.Item1.WaitOne();\nif (await zooKeeper.Item2.existsAsync(_subscriberPath)) {\nvar children = await zooKeeper.Item2.getChildrenAsync(_subscriberPath);\n_subscribers = children.Select(c => c.Data).ToArray();\n} else {\n_logger.LogWarning(\"Subscriber path does not exist\");\n_subscribers = new string[0];\n}\n}\n}", "CodeBleu_score": 42.63971309447984}, {"code": "private async Task EnterSubscribers(){\n\t\tif (_subscribers!= null) {\n\t\treturn;\n\t}\n\t_subscribers = new ConcurrentDictionary<string, Subscriber>();\n\tvar zooKeeper = await GetZooKeeper();\n\tawait zooKeeper.Item1.WaitOne();\n\tvar result = await zooKeeper.Item2.getChildrenAsync(_subscriberPath);\n\tif (result.Error == null) {\n\t\tforeach (var child in result.Children) {\n\t\t\tvar data = await zooKeeper.Item2.getDataAsync(Path.Combine(_subscriberPath, child));\n\t\t\tif (data.Error == null) {\n\t\t\t\t_subscribers.TryAdd(child, new Subscriber(data.Data));\n\t\t\t}\n\t\t\telse {\n\t\t\t\t_logger.LogWarning($\"Could not load subscriber {child} from path {_subscriberPath}.\");\n\t\t\t}\n\t\t}\n\t}\n\telse {\n\t\t_logger.LogWarning($\"Could not load subscribers from path {_subscriberPath}.\");\n\t}\n}", "CodeBleu_score": 42.618370068351766}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tewCommand = GetServiceCommand(newData);\nvar oldCommand = GetServiceCommand(oldData);\nif (oldCommand!= null && newCommand!= null) {\nif (oldCommand.ServiceId!= newCommand.ServiceId) {\n_serviceCommands = _serviceCommands.Where(i => i.ServiceId!= oldCommand.ServiceId)\n.Concat(new[] { newCommand }).ToArray();\n}\n}\nelse if (oldCommand!= null) {\n_serviceCommands = _serviceCommands.Where(i => i.ServiceId!= oldCommand.ServiceId).ToArray();\n}\nelse if (newCommand!= null) {\n_serviceCommands = _serviceCommands.Concat(new[] { newCommand }).ToArray();\n}\nOnChanged(oldCommand, newCommand);\n}", "CodeBleu_score": 57.31958223182727}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tldData!= null && newData!= null) {\nvar newCommand = GetServiceCommand(newData);\nif (newCommand!= null) {\nvar oldCommand = GetServiceCommand(oldData);\nif (oldCommand!= null) {\nif (oldCommand.ServiceId!= newCommand.ServiceId) {\n_serviceCommands = _serviceCommands.Where(i => i.ServiceId!= oldCommand.ServiceId)\n.Concat(new[] { newCommand }).ToArray();\n}\n}\nelse {\n_serviceCommands = _serviceCommands.Where(i => i.ServiceId!= newCommand.ServiceId)\n.Concat(new[] { newCommand }).ToArray();\n}\n}\nelse {\n_serviceCommands = _serviceCommands.Where(i => i.ServiceId!= newCommand.ServiceId)\n.Concat(new[] { newCommand }).ToArray();\n}\n}\nelse {\n_serviceCommands = _serviceCommands.Where(i => i.ServiceId!= newCommand.ServiceId)\n.Concat(new[] { newCommand }).ToArray();\n}\nOnChanged(oldData, newData);\n}", "CodeBleu_score": 56.32897493308625}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\toldCommand = GetServiceCommand(oldData);", "CodeBleu_score": 10.495330456947064}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.get_Type() == Event.EventType.NodeDataChanged) {\n\t\tvar data = await _zooKeeper.Item2.getDataAsync(watchedEvent.getPath());\n\t\t_action(data, watchedEvent.getData());\n\t\t_watcher.SetCurrentData(data);\n\t}\n}", "CodeBleu_score": 20.040223763650317}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\t// Retrieve the node data asynchronously using a ZooKeeper client.\n\tvar nodeData = await _zooKeeper.GetDataAsync(watchedEvent.getPath());\n\t// Execute the specified action with the current and new data.\n\t_action(nodeData, watchedEvent.getData());\n\t// Update the watcher with the new data.\n\t_watcher.SetCurrentData(nodeData);\n}", "CodeBleu_score": 14.052438767309287}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.Type == EventType.NodeDataChanged) {\n\t\tvar nodeData = await zooKeeper.GetDataAsync(watchedEvent.Path);\n\t\taction(nodeData, watchedEvent.NodeData);\n\t\twatcher.SetCurrentData(nodeData);\n\t}\n}", "CodeBleu_score": 15.478778660291562}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tif (builder == null) {\nthrow new ArgumentNullException(nameof(builder));\n}\nif (configInfo == null) {\nthrow new ArgumentNullException(nameof(configInfo));\n}\nreturn builder.UseZookeeperClientProvider(configInfo, null);\n}", "CodeBleu_score": 24.04565872086666}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\treturn builder.UseZookeeperClientProvider(configInfo, (provider, configInfo) => new DefaultZookeeperClientProvider(configInfo, provider.Resolve<IHealthCheckService>(), provider.Resolve<IZookeeperAddressSelector>(), provider.Resolve<ILogger<DefaultZookeeperClientProvider>>()));\n}", "CodeBleu_score": 56.82506041931661}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tif (builder == null) {\nthrow new ArgumentNullException(nameof(builder));\n}\nif (configInfo == null) {\nthrow new ArgumentNullException(nameof(configInfo));\n}\nreturn builder.Services.Register(provider =>\n       new DefaultZookeeperClientProvider(\n           GetConfigInfo(configInfo),\n        provider.Resolve<IHealthCheckService>(),\n          provider.Resolve<IZookeeperAddressSelector>(),\n          provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance;\n}", "CodeBleu_score": 73.56608716264431}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t_logger.LogInformation(", "CodeBleu_score": 4.954345305588415}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t_logger.LogInformation(\"Setting routes in ZooKeeper\");\n\nvar zooKeepers = GetZooKeepers();\n\nforeach (var zooKeeper in zooKeepers) {\n\nvar client = await zooKeeper.CreateClientAsync(_confi\n_logger.LogInformation(\"Creating route path {path} in ZooKeeper\", nodePath);\n\nvar node = await zooKeeper.GetNodeAsync(nodePath);\n\nif (node == null) {\n_logger.LogInformation(\"Creating route path {path} in ZooKeeper\", nodePath);\nawait zooKeeper.CreateNodeAsync(nodePath);\n}\n\n_logger.LogInformation(\"Setting routes in ZooKeeper\");\n\nforeach (var route in routes) {\n\nvar nodePath = GetNodePath(route);\n\n_logger.LogInformation(\"Setting route {route} in ZooKeeper\", route);\n\nvar node = await zooKeeper.GetNodeAsync(nodePath);\n\nif (node == null) {\n_logger.LogInformation(\"Creating route {route} in ZooKeeper\", route);\nawait zooKeeper.CreateNodeAsync(nodePath);\n}\nelse {\n_logger.LogInformation(\"Updating route {route} in ZooKeeper\", route);\nawait zooKeeper.SetNodeDataAsync(nodePath, DataEquals(node, route)? null : Serialize(route));\n}\n}\n}\n\n_logger.LogInformation(\"Successfully set routes in ZooKeeper\");\n}", "CodeBleu_score": 41.29324423982411}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\n}", "CodeBleu_score": 1.1662014589334855}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tvar routePaths = routes.Select(r => r.MqttDescriptor.RoutePath);\nvar zooKeepers = _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar existingRoutes = await zooKeeper.Item2.getChildrenAsync(routePaths.First());\nvar oldRouteTopics = existingRoutes.Select(r => r.Path.Replace(routePaths.First(), \"\")).ToArray();\nvar newRouteTopics = routes.Select(r => r.MqttDescriptor.Topic).ToArray();\nvar deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\nforeach (var deletedRouteTopic in deletedRouteTopics) {\nvar deletedRoutePath = $\"{routePaths.First()}/{deletedRouteTopic}\";\nif (deletedRoutePath.Contains(hostAddr.Address)) {\nawait zooKeeper.Item2.deleteAsync(deletedRoutePath);\n}\n}\n}\n}", "CodeBleu_score": 47.82530628078217}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tvar routePaths = routes.Select(i => i.MqttDescriptor.RoutePath);\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nvar oldRouteTopics = routes.Select(i => i.MqttDescriptor.Topic);\nvar newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic);\nvar oldRouteAddresses = routes.Select(i => i.MqttEndpoint);\nvar newRouteAddresses = routes.Select(i => i.MqttEndpoint);\nforeach (var zooKeeper in zooKeepers) {\nvar oldRoutes = await zooKeeper.Item2.getChildrenAsync(routePaths);\nvar oldRouteAddresses = oldRoutes.Select(i => new AddressModel(i));\nvar deletedRouteTopics = oldRouteAddresses.Where(i => i.Host.Equals(hostAddr.Host)).Select(i => i.Path);\nvar deletedRouteAddresses = oldRouteAddresses.Where(i => i.Host.Equals(hostAddr.Host)).Select(i => i.Path);\nforeach (var deletedRouteTopic in deletedRouteTopics) {\nawait zooKeeper.Item2.deleteAsync(deletedRouteTopic);\n}\n}\n}", "CodeBleu_score": 44.8138239813154}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tvar routePaths = routes.Select(i => i.MqttDescriptor.Topic);\nvar zooKeeperClients = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeeperClients) {\nvar currentRoutes = await zooKeeper.Item2.getChildrenAsync(routePaths.First());\nvar oldRouteTopics = currentRoutes.Select(i => i.Path.TrimStart('/'));\nvar newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic);\nvar deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\nforeach (var deletedRouteTopic in deletedRouteTopics) {\nif (deletedRouteTopic.Contains(hostAddr.Address)) {\nawait zooKeeper.Item2.deleteAsync(deletedRouteTopic);\n}\n}\n}\n}", "CodeBleu_score": 44.734446035507894}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\n_logger.LogInformation\n_logger.IsEnabled\n\"\u8bbe\u7f6e\u7f13\u5b58\nData, ZooDefs.Ids.OPEN_ACL_\n        }", "CodeBleu_score": 6.959828109655793}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t_logger.LogInformation", "CodeBleu_score": 4.808208117177599}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\nvar", "CodeBleu_score": 2.2122028723426563}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t_logger.LogInformation($\"Creating subdirectories for path {path}\");\nvar nodePath = path;\n\nwhile (true) {\nif (await zooKeeper.Item2.existsAsync(nodePath)) {\nbreak;\n}\n\nawait zooKeeper.Item2.createAsync(nodePath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\nvar parentPath = Path.GetDirectoryName(nodePath);\nif (parentPath == null) {\nbreak;\n}\n\nnodePath = parentPath;\n}\n}", "CodeBleu_score": 39.95007519180025}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t_logger.LogInformation($\"Creating directory {path}\");\n\n// Check if the path already exists\nif (await zooKeeper.Item2.existsAsync(path)) {\n_logger.LogInformation($\"Directory {path} already exists\");\nreturn;\n}\n\n// Create the parent directory if it does not exist\nvar parentPath = Path.GetDirectoryName(path);\nif (parentPath!= null &&!await zooKeeper.Item2.existsAsync(parentPath)) {\nawait CreateSubdirectory(zooKeeper, parentPath);\n}\n\n// Create the directory\nawait zooKeeper.Item2.createAsync(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\n// Wait for the manual reset event\nzooKeeper.Item1.WaitOne();\n}", "CodeBleu_score": 47.069730845412366}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\tvar nodePath = path.TrimEnd('/');\nvar directoryPath = Path.GetDirectoryName(nodePath);\nvar directoryName = Path.GetFileName(nodePath);\n\nif (directoryPath!= null) {\nvar directoryExists = await zooKeeper.Item2.existsAsync(directoryPath);\nif (!directoryExists) {\n_logger.LogInformation($\"Creating directory {directoryPath}\");\nawait zooKeeper.Item2.createAsync(directoryPath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\n}\n\nvar nodeExists = await zooKeeper.Item2.existsAsync(nodePath);\nif (!nodeExists) {\n_logger.LogInformation($\"Creating node {nodePath}\");\nawait zooKeeper.Item2.createAsync(nodePath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\n}", "CodeBleu_score": 48.79619809441192}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t\nvar result = new List<(ManualResetEvent, ZooKeeper)>();\n\nforeach (var address in _configuration.ZooKeeperAddresses) {\nvar healthCheck = _healthCheckService.IsHealth(address);\nif (healthCheck.IsSuccess) {\nvar zk = new ZooKeeper(address, _configuration.ZooKeeperSessionTimeout, _configuration.ZooKeeperConnectionTimeout, _configuration.ZooKeeperReconnectionInterval);\nresult.Add((healthCheck.Result, zk));\n}\n}\n\nreturn result;\n}", "CodeBleu_score": 65.43198880334793}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\n", "CodeBleu_score": 16.67409785162852}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\n\tforeach (var address in _addresses) {\n\t\tvar manualResetEvent = new ManualResetEvent(false);\n\t\tvar zookeeper = await _healthCheckService.IsHealth(address);\n\t\tif (zookeeper!= null) {\n\t\t\tresult.Add((manualResetEvent, zookeeper));\n\t\t}\n\t}\n\treturn result;\n}", "CodeBleu_score": 68.45616248960404}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tif (zooKeeper == null) {\n\t\tsynchronized (this) {\n\t\t\tif (zooKeeper == null) {\n\t\t\t\tnewZooKeeper();\n\t\t\t}\n\t\t}\n\t}\n\treturn zooKeeper;\n}", "CodeBleu_score": 14.17991521289887}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tif (zk == null) {\n\t\tsynchronized (this) {\n\t\t\tif (zk == null) {\n\t\t\t\tzk = newZooKeeper();\n\t\t\t}\n\t\t}\n\t}\n\treturn zk;\n}", "CodeBleu_score": 16.632594065788105}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tif (zooKeeper == null) {\n\t\tsynchronized (this) {\n\t\t\tif (zooKeeper == null) {\n\t\t\t\tzooKeeper = new ZooKeeper(connectionString, sessionTimeout, this);\n\t\t\t}\n\t\t}\n\t}\n\treturn zooKeeper;\n}", "CodeBleu_score": 25.404439955885366}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (this.zk!= null) {\n\t\tif (this.zk.getState().isAlive()) {\n\t\t\tif (this.zk.getState().isAlive()) {\n\t\t\t\tthis.zk.close();\n\t\t\t}\n\t\t\tthis.zk = null;\n\t\t}\n\t}\n\tif (this.zk!= null) {\n\t\tif (this.zk.getState().isAlive()) {\n\t\t\tthis.zk.close();\n\t\t}\n\t\tthis.zk = null;\n\t}\n\tif (this.zk!= null) {\n\t\tif (this.zk.getState().isAlive()) {\n\t\t\tthis.zk.close();\n\t\t}\n\t\tthis.zk = null;\n\t}\n\tif (this.zk!= null) {\n\t\tif (this.zk.getState().isAlive()) {\n\t\t\tthis.zk.close();\n\t\t}\n\t\tthis.zk = null;\n\t}\n\tif (this.zk!= null) {\n\t\tif (this.zk.getState().isAlive()) {\n\t\t\tthis.zk.close();\n\t\t}\n\t\tthis.zk = null;\n\t}\n\tif (this.zk!= null) {\n\t\tif (this.zk.getState().isAlive()) {\n\t\t\tthis.zk.close();\n\t\t}\n\t\tthis.zk = null;\n\t}\n\tif (this.zk!= null) {\n\t\tif (this.zk.getState().isAlive()) {\n\t\t\tthis.zk.close();\n\t\t}\n\t\tthis.zk = null;\n\t}\n\tif (this.zk!= null) {\n\t\tif (this.zk.getState().isAlive()) {\n\t\t\tthis.zk.close();\n\t\t}\n\t\tthis.zk = null;\n\t}\n\tif (this.zk!= null) {\n\t\tif (this.zk.getState().isAlive()) {\n\t\t\tthis.zk.close();\n\t\t}\n\t\tthis.zk = null;\n\t}\n\tif (this.zk!= null) {\n\t\tif (this.zk.getState().isAlive()) {\n\t\t\tthis.zk.close();\n\t\t}\n\t\tthis.zk = null;\n\t}\n\tif (this.zk!= null) {\n\t\tif (this.zk.getState().isAlive()) {\n\t\t", "CodeBleu_score": 10.710674627544511}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tZooKeeper zooKeeper = getZooKeeper();\n\tif (zooKeeper!= null) {\n\t\tzooKeeper.close();\n\t}\n\tif (waitForShutdownTimeoutMs > 0) {\n\t\ttry {\n\t\t\tThread.sleep(waitForShutdownTimeoutMs);\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\t}\n}", "CodeBleu_score": 25.54152250149676}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (this.zk!= null) {\n\t\tif (this.zkHelper!= null) {\n\t\t\tthis.zk = this.zkHelper.getZk();\n\t\t}\n\t\ttry {\n\t\t\tthis.zk.register(new Watcher() {\n\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t}\n\t\t\t});\n\t\t\tthis.zk.close();\n\t\t\tthis.zk = null;\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\t}\n\tif (this.zkHelper!= null) {\n\t\tthis.zkHelper.close();\n\t}\n}", "CodeBleu_score": 27.043079340100384}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\treturn blockUntilConnectedOrTimedOut(DEFAULT_TIMEOUT);\n}", "CodeBleu_score": 5.2611652574301715}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\treturn blockUntilConnectedOrTimedOut(DEFAULT_TIMEOUT);\n}", "CodeBleu_score": 5.2583962214681685}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\treturn blockUntilConnectedOrTimedOut(null);\n}", "CodeBleu_score": 5.2403758988702975}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\ttry\n{\nlog.info(\"Shutting down service\");\nsetStarted(false);\nclose();\n}\ncatch (IOException e)\n{\nif (Thread.currentThread().isInterrupted())\n{\nlog.warn(\"Thread interrupted while shutting down service\");\n}\nelse\n{\nlog.error(\"Error while shutting down service\", e);\n}\n}\ncheckInterrupted\n}", "CodeBleu_score": 48.12935760762167}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\tif\n(\nstarted\n)\n{\nlog\n.\ndebug\n(\n\"Shutting down service\"\n)\n;\nstarted\n=\nfalse\n;\ntry\n{\nif\n(\nwaitForShutdownTimeoutMs\n>\n0\n)\n{\nif\n(\n!\nexecutorService\n.\nawaitTermination\n(\nwaitForShutdownTimeoutMs\nTimeUnit\n.\nMILLISECONDS\n)\n)\n{\nlog\n.\nwarn\n(\n\"Forcing shutdown of service\"\n)\n;\nexecutorService\n.\nshutdownNow\n(\n)\n;\n}\n}\nelse\n{\nexecutorService\n.\nshutdown\n(\n)\n;\n}\n}\ncatch\n(\nInterruptedException\ne\n)\n{\nlog\n.\nerror\n(\n\"Interrupted while shutting down service\"\n,\ne\n)\n;\n}\nfinally\n{\ncheckInterrupted\n(\n)\n;\n}\n}\n}", "CodeBleu_score": 25.203509352834963}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\tcheckInterrupted\nlog\nsetStarted\nclose\ncheckInterrupted\n}", "CodeBleu_score": 10.237664777396082}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\t//TODO: implement internalBlockUntilConnectedOrTimedOut\n\n\n}", "CodeBleu_score": 1.4820082928049525}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tinternalBlockUntilConnectedOrTimedOut(connectionTimeout)\n}", "CodeBleu_score": 2.862074941428435}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\t//TODO: Implement this function\n\tthrow new UnsupportedOperationException(\"Function not implemented\");\n}", "CodeBleu_score": 1.5095293943065509}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tif (client.getSessionId()!= client.getPreviousSessionId()) {\nlog.info(\"Session changed from {} to {}\", client.getPreviousSessionId(), client.getSessionId());\nclient.delete(foundNode, true);\nclient.setPreviousSessionId(client.getSessionId());\n}\nreturn foundNode;\n}", "CodeBleu_score": 21.144003120537807}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tif (createMode == CreateMode.EPHEMERAL) {\nreturn foundNode;\n}\n\nif (client.isClosed()) {\nreturn foundNode;\n}\n\nif (client.getSessionId()!= client.getSession().getId()) {\nclient.getSession().close();\nclient.getSession().start();\nclient.getSession().get();\nclient.getZooKeeper().delete(foundNode, -1);\nreturn client.getZooKeeper().create(foundNode, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, createMode);\n}\n\nreturn foundNode;\n}", "CodeBleu_score": 25.54652621426503}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t\tif (client.getCuratorZookeeperClient().getZooKeeper().exists(foundNode, false) == null) {\n\t\tif (client.isSessionExpired()) {\n\t\t\tlog.warn(\"Session expired. Deleting node \" + foundNode + \" associated with previous session\");\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().delete(foundNode, -1);\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient.getCuratorZookeeperClient().getZooKeeper().close();\n\t\t\tclient", "CodeBleu_score": 20.197474415779176}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tfinal Stat stat = new Stat();\n\tfinal Trace trace = new Trace();\n\ttrace.setPath(path);\n\ttrace.setOperation(Trace.Operation.SET_ACL);\n\ttrace.setResult(Trace.Result.UNKNOWN);\n\ttrace.setTraceId(traceId);\n\ttrace.setZooKeeperPath(path);\n\ttrace.setZooKeeperSessionId(sessionId);\n\ttrace.setZooKeeperTraceId(traceId);\n\ttrace.setZooKeeperVersion(version);\n\ttrace.setZooKeeperZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStat(stat);\n\ttrace.setZooKeeperZnodeStatVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion(version);\n\ttrace.setZooKeeperZnodeStatZnodeVersion", "CodeBleu_score": 19.191006799734197}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tfinal Stat stat = new Stat();\n\tfinal Trace trace = new Trace(TraceType.SET_ACL, path, stat);\n\ttrace.start();\n\ttry {\n\t\tfinal Stat result = client.setACL(path, aclList, -1, stat);\n\t\ttrace.setResult(result);\n\t\ttrace.commit();\n\t\treturn result;\n\t} catch (final KeeperException.NoAuthException e) {\n\t\ttrace.setResult(e);\n\t\ttrace.commit();\n\t\tthrow e;\n\t} catch (final KeeperException.BadVersionException e) {\n\t\ttrace.setResult(e);\n\t\ttrace.commit();\n\t\tthrow e;\n\t} catch (final KeeperException.ConnectionLossException e) {\n\t\ttrace.setResult(e);\n\t\ttrace.commit();\n\t\tthrow e;\n\t} catch (final KeeperException.SessionExpiredException e) {\n\t\ttrace.setResult(e);\n\t\ttrace.commit();\n\t\tthrow e;\n\t} catch (final KeeperException.Exception e) {\n\t\ttrace.setResult(e);\n\t\ttrace.commit();\n\t\tthrow e;\n\t}\n}", "CodeBleu_score": 31.596583391858584}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tfinal Stat stat = new Stat();\n\tfinal Trace trace = new Trace(\"pathInForeground\", \"Set ACL for \" + path + \" with \" + aclList);\n\ttrace.start();\n\ttry {\n\t\tfinal Stat result = zk.setACL(path, aclList, stat);\n\t\ttrace.commit(result);\n\t\treturn result;\n\t} catch (final KeeperException.NoNodeException e) {\n\t\ttrace.commit(e);\n\t\tthrow e;\n\t} catch (final KeeperException.NodeExistsException e) {\n\t\ttrace.commit(e);\n\t\tthrow e;\n\t} catch (final KeeperException.NotEmptyException e) {\n\t\ttrace.commit(e);\n\t\tthrow e;\n\t} catch (final KeeperException.SessionExpiredException e) {\n\t\ttrace.commit(e);\n\t\tthrow e;\n\t} catch (final KeeperException.InterruptedException e) {\n\t\ttrace.commit(e);\n\t\tthrow e;\n\t} catch (final KeeperException.OperationTimeoutException e) {\n\t\ttrace.commit(e);\n\t\tthrow e;\n\t} catch (final Exception e) {\n\t\ttrace.commit(e);\n\t\tthrow e;\n\t} finally {\n\t\ttrace.finish();\n\t}\n}", "CodeBleu_score": 31.732512238600634}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.cache = new CuratorCache(client, membershipPath, false);\n\tthis.node = new PersistentNode(client, membershipPath, thisId, payload, false);\n}", "CodeBleu_score": 36.18570640152872}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.cache = new CuratorCache(client, membershipPath);\n\tthis.cache.getListenable().addListener(new CuratorCacheListener() {\n\t\t@Override\n\t\tpublic void eventReceived(CuratorCacheEvent event) throws Exception {\n\t\t\tswitch (event.getType()) {\n\t\t\tcase NODE_ADDED:\n\t\t\t\tif (event.getData().getPath().equals(membershipPath)) {\n\t\t\t\t\tif (event.getData().getPath().equals(membershipPath + \"/\" + thisId)) {\n\t\t\t\t\t\t// We are the only member\n\t\t\t\t\t\tif (event.getData().getChildren().size() == 0) {\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the only member and we have no children\n\t\t\t\t\t\t\t// We are the", "CodeBleu_score": 33.930012247465115}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.cache = new CuratorCache(client, membershipPath, true);\n\tthis.cache.getListenable().addListener(new CuratorCacheListener() {\n\t\t@Override\n\t\tpublic void eventReceived(CuratorCacheEvent event) throws Exception {\n\t\t\tswitch (event.getType()) {\n\t\t\t\tcase NODE_ADDED:\n\t\t\t\t\tGroupMember.this.onNodeAdded(event.getData());\n\t\t\t\t\tbreak;\n\t\t\t\tcase NODE_REMOVED:\n\t\t\t\t\tGroupMember.this.onNodeRemoved(event.getData());\n\t\t\t\t\tbreak;\n\t\t\t\tcase NODE_UPDATED:\n\t\t\t\t\tGroupMember.this.onNodeUpdated(event.getData());\n\t\t\t\t\tbreak;\n\t\t\t\tcase CONNECTION_SUSPENDED:\n\t\t\t\t\tGroupMember.this.onConnectionSuspended();\n\t\t\t\t\tbreak;\n\t\t\t\tcase CONNECTION_RECONNECTED:\n\t\t\t\t\tGroupMember.this.onConnectionReconnected();\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t});\n\tthis.cache.start();\n\tthis.node = new PersistentNode(client, membershipPath, payload);\n}", "CodeBleu_score": 35.23715618563668}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tclient.create()\n.creatingParentsIfNeeded()\n.withMode(CreateMode.PERSISTENT)\n.forPath(path)\n.whenComplete(handleWatchedStage)\n.exceptionally(wrap)\n.join();\n}", "CodeBleu_score": 18.80169708287644}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tString data = \"Hello World!\";\ntry {\nclient.create().creatingParentsIfNeeded().forPath(path, data.getBytes());\nclient.getData().usingWatcher(new Watcher() {\n@Override\npublic void process(WatchedEvent event) throws Exception {\nSystem.out.println(\"Watch event: \" + event);\n}\n}).forPath(path);\n} catch (Exception e) {\ne.printStackTrace();\n}\n}", "CodeBleu_score": 32.64153265579741}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tclient\n.create()\n.creatingParentsIfNeeded()\n.withMode(CreateMode.PERSISTENT)\n.forPath(path)\n.whenComplete(\n(result, ex) -> {\nif (ex == null) {\nSystem.out.println(\"Node created: \" + result);\nclient\n.getData()\n.usingWatcher(new Watcher() {\n@Override\npublic void process(WatchedEvent event) {\nSystem.out.println(\"Node data changed: \" + new String(event.getData()));\n}\n})\n.forPath(path);\n} else {\nex.printStackTrace();\n}\n}\n);\n}", "CodeBleu_score": 44.607888793311446}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> results = new ArrayList<>();\n\tfor (Operation op : operations) {\n\t\ttry {\n\t\t\tresults.add(op.execute());\n\t\t} catch (KeeperException.NoNodeException e) {\n\t\t\tthrow new KeeperException(KeeperException.Code.NONODE, e);\n\t\t} catch (KeeperException.NodeExistsException e) {\n\t\t\tthrow new KeeperException(KeeperException.Code.NODEEXISTS, e);\n\t\t} catch (KeeperException.BadVersionException e) {\n\t\t\tthrow new KeeperException(KeeperException.Code.BADVERSION, e);\n\t\t} catch (KeeperException.NoChildrenForEphemeralsException e) {\n\t\t\tthrow new KeeperException(KeeperException.Code.NOCHILDRENFOREPHEMERALS, e);\n\t\t} catch (KeeperException.NotEmptyException e) {\n\t\t\tthrow new KeeperException(KeeperException.Code.NOTEMPTY, e);\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t\tthrow new KeeperException(KeeperException.Code.SESSIONEXPIRED, e);\n\t\t}\n\t}\n\treturn results;\n}", "CodeBleu_score": 21.44044576581195}, {"code": "private List<OpResult> doOperation() throws Exception{\n\tList<OpResult> results = new ArrayList<OpResult>();\n\ntry {\nresults = multi.getResult();\n} catch (KeeperException.NoNodeException e) {\nthrow new KeeperException.NoNodeException(e);\n} catch (KeeperException.NodeExistsException e) {\nthrow new KeeperException.NodeExistsException(e);\n} catch (KeeperException.BadVersionException e) {\nthrow new KeeperException.BadVersionException(e);\n} catch (KeeperException.NotEmptyException e) {\nthrow new KeeperException.NotEmptyException(e);\n} catch (KeeperException.SessionExpiredException e) {\nthrow new KeeperException.SessionExpiredException(e);\n} catch (KeeperException.ConnectionLossException e) {\nthrow new KeeperException.ConnectionLossException(e);\n} catch (KeeperException.OperationTimeoutException e) {\nthrow new KeeperException.OperationTimeoutException(e);\n} catch (KeeperException.InterruptedException e) {\nthrow new KeeperException.InterruptedException(e);\n}\n\nreturn results;\n}", "CodeBleu_score": 21.034891606601118}, {"code": "private List<OpResult> doOperation() throws Exception{\n\tList<OpResult> results = new ArrayList<OpResult>();\ntry {\nresults = zk.multi(ops);\n} catch (KeeperException.NoNodeException e) {\n// Ignore\n} catch (KeeperException.NodeExistsException e) {\n// Ignore\n} catch (KeeperException.BadVersionException e) {\n// Ignore\n} catch (KeeperException.NotEmptyException e) {\n// Ignore\n} catch (KeeperException.SessionExpiredException e) {\n// Ignore\n} catch (KeeperException.ConnectionLossException e) {\n// Ignore\n} catch (KeeperException.OperationTimeoutException e) {\n// Ignore\n} catch (KeeperException.InterruptedException e) {\n// Ignore\n}\nreturn results;\n}", "CodeBleu_score": 22.91462491951367}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\tList<String> serviceNames = serviceDiscovery.queryForNames();\nfor (String serviceName : serviceNames) {\nList<InstanceDetails> instances = serviceDiscovery.queryForInstances(serviceName);\nif (instances.isEmpty()) {\nthrow new NoNodeException(\"No instances found for service: \" + serviceName);\n}\nSystem.out.println(\"Service: \" + serviceName + \" Instances: \" + instances);\n}\nserviceDiscovery.close();\n}", "CodeBleu_score": 38.07430745170731}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\tprintln", "CodeBleu_score": 6.569979740203752}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t// Query for all service names\nList<String> serviceNames = serviceDiscovery.queryForNames();\n\n// Print each service name and its instances\nfor (String serviceName : serviceNames) {\nList<InstanceDetails> instances = serviceDiscovery.queryForInstances(serviceName);\n\n// Print the service name and its instances\nSystem.out.println(\"Service name: \" + serviceName);\nSystem.out.println(\"Instances:\");\nfor (InstanceDetails instance : instances) {\nSystem.out.println(\" - \" + instance.getHostName() + \":\" + instance.getPort());\n}\n}\n}", "CodeBleu_score": 40.23317713502694}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tchildren = children.stream().filter(child ->!child.equals(READY_NODE)).collect(Collectors.toList());\n\tCollections.sort(children);\n\treturn children;\n}", "CodeBleu_score": 32.8070965988272}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tchildren = children.stream().filter(name ->!name.equals(READY_NODE)).collect(Collectors.toList());\n\tCollections.sort(children);\n\treturn children;\n}", "CodeBleu_score": 32.958970436651924}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tchildren.remove(READY_NODE);\n\tList<String> filtered = children.stream().filter(child ->!child.contains(READY_NODE)).collect(Collectors.toList());\n\tfiltered.sort(String::compareTo);\n\treturn filtered;\n}", "CodeBleu_score": 36.74522421216025}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tzk = new ZooKeeper(newHost, timeout, this);\n}", "CodeBleu_score": 17.86994203417985}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tzk = new ZooKeeper(newHost, timeout, this);\n}", "CodeBleu_score": 17.86994203417985}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tzk = new ZooKeeper(newHost, timeout, this);\n\tif (readOnly) {\n\t\tzk.setReadOnly();\n\t}\n}", "CodeBleu_score": 21.17615426508562}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acls = new ArrayList<ACL>();\nString[] aclSegments = aclString.split(\",\");\nfor (String aclSegment : aclSegments) {\ntry {\nString[] aclComponents = aclSegment.split(\":\");\nString scheme = aclComponents[0];\nString id = aclComponents[1];\nString perms = aclComponents[2];\nACL acl = new ACL();\nacl.setId(id);\nacl.setPerms(perms);\nacls.add(acl);\n} catch (Exception e) {\nSystem.err.println(\"Invalid ACL segment: \" + aclSegment);\n}\n}\nreturn acls;\n}", "CodeBleu_score": 27.938716429409205}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> aclList = new ArrayList<ACL>();\n\nfor (String acl : aclString.split(\",\")) {\nString scheme = null;\nString id = null;\nString perms = null;\n\nint colonIndex = acl.indexOf(\":\");\n\nif (colonIndex == -1) {\nif (acl.length() > 0) {\nlogger.error(\"Invalid ACL: \" + acl);\n}\n} else {\nscheme = acl.substring(0, colonIndex);\nid = acl.substring(colonIndex + 1);\n\nif (scheme.length() == 0 || id.length() == 0) {\nlogger.error(\"Invalid ACL: \" + acl);\n} else {\nperms = acl.substring(colonIndex + 1);\n\nif (perms.length() == 0) {\nlogger.error(\"Invalid ACL: \" + acl);\n} else {\nACL aclObj = new ACL();\naclObj.setId(id);\naclObj.setPerms(getPermFromString(perms));\naclList.add(aclObj);\n}\n}\n}\n}\n}", "CodeBleu_score": 35.01860287357618}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> list = new ArrayList<ACL>();\nfor (String acl : aclString.split(\",\")) {\nif (acl.length() > 0) {\nACL aclObj = new ACL();\nint index = acl.indexOf(\":\");\nif (index > 0) {\nString id = acl.substring(0, index);\nString perms = acl.substring(index + 1);\naclObj.setId(id);\naclObj.setPerms(getPermFromString(perms));\nlist.add(aclObj);\n} else {\nlogger.error(\"Invalid ACL: \" + acl);\n}\n}\n}\nreturn list;\n}", "CodeBleu_score": 30.962165281753773}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tif (pathList == null) {\nthrow new IllegalArgumentException(\"Path list cannot be null\");\n}\nif (pathList.size() < 20) {\ndeleteSync(serverId, pathList);\n}\nelse {\ndeleteAsync(serverId, pathList);\n}\n}", "CodeBleu_score": 34.732843042298036}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tif (pathList == null)\nthrow new IllegalArgumentException(\"pathList must not be null\");\nif (pathList.size() < 20) {\nfor (String path : pathList) {\ndelete(serverId, path);\n}\n} else {\ndeleteAsync(serverId, pathList);\n}\n}", "CodeBleu_score": 52.804097063378386}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tif (pathList == null) {\nthrow new IllegalArgumentException(\"Path list cannot be null\");\n}\nif (pathList.size() == 0) {\nreturn;\n}\nif (pathList.size() < 20) {\nfor (String path : pathList) {\ndelete(serverId, path);\n}\n} else {\nList<String> pathListCopy = new ArrayList<>(pathList);\nfor (int i = 0; i < pathListCopy.size(); i += 20) {\ndeleteAsync(serverId, pathListCopy.subList(i, Math.min(pathListCopy.size(), i + 20)));\n}\n}\n}", "CodeBleu_score": 58.07251874272759}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\twriter\n.write\n(\"Connecting\nto\n\"\n+\nurl\n+\n\"\n.\n\n\"\n)\n;\nCuratorZookeeperConnectionFactory\nconnectionFactory\n=\nnew\nCuratorZookeeperConnectionFactory\n(\nurl\n)\n;\nconnectionFactory\n.\nset\n(\nnew\nCuratorZookeeperConnection\n(\n)\n)\n;\nCuratorZookeeperConnection\nconnection\n=\nconnectionFactory\n.\ncreate\n(\n)\n;\nwriter\n.\nwrite\n(\n\"Connected\nto\n\"\n+\nurl\n+\n\"\n.\n\n\"\n)\n;\nZooKeeperMain\nmain\n=\nnew\nZooKeeperMain\n(\nconnection\n)\n;\nreturn\nnew\nTerminal\n(\nid\nurl\nconnection\nmain\n)\n;\n}", "CodeBleu_score": 26.109522213786622}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\twriter\n.println\n(\n\"Connecting\nto\n\"\n+\nurl\n+\n\"\n.\n\"\n)\n;\nCuratorZookeeperConnectionFactory\nfactory\n=\nnew\nCuratorZookeeperConnectionFactory\n(\nurl\n)\n;\nfactory\n.\nsetNamespace\n(\nid\n)\n;\nfactory\n.\nsetConnectTimeoutMs\n(\nCONNECT_TIMEOUT_MS\n)\n;\nfactory\n.\nsetSessionTimeoutMs\n(\nSESSION_TIMEOUT_MS\n)\n;\nCuratorZookeeperClient\nclient\n=\nfactory\n.\nnewClient\n(\n)\n;\nclient\n.\nstart\n(\n)\n;\nwriter\n.\nprintln\n(\n\"\nConnection\nsuccessful\n.\n\"\n)\n;\nZooKeeperMain\nmain\n=\nnew\nZooKeeperMain\n(\nclient\n)\n;\nreturn\nnew\nTerminal\n(\nid\nurl\nclient\nmain\n)\n;\n}", "CodeBleu_score": 26.716069074021604}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tString\nmessage\n=\n\"Connecting\nto\n\"\n+\nurl\n+\n\"\n\"\n;\nwriter\n.\nwrite\n(\nmessage\n)\n;\nCuratorZookeeperConnectionFactory\nconnectionFactory\n=\nnew\nCuratorZookeeperConnectionFactory\n(\nurl\n)\n;\nconnectionFactory\n.\nsetConnectTimeout\n(\n1000\n)\n;\nconnectionFactory\n.\nsetSessionTimeout\n(\n1000\n)\n;\nCuratorZookeeperConnection\nconnection\n=\nconnectionFactory\n.\ncreateConnection\n(\n)\n;\nwriter\n.\nwrite\n(\n\"\nConnected\nto\n\"\n+\nurl\n+\n\"\n\"\n)\n;\nZooKeeperMain\nzooKeeperMain\n=\nnew\nZooKeeperMain\n(\nid\nurl\nconnection\n)\n;\nreturn\nnew\nTerminal\n(\nid\nurl\nconnection\nzooKeeperMain\n)\n;\n}", "CodeBleu_score": 26.30478997692188}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\t//TODO implement blockUntilConnected\n}", "CodeBleu_score": 1.0145750671711116}, {"code": "public void blockUntilConnected(){\n\t\n}", "CodeBleu_score": 1.0145750671711116}, {"code": "public void blockUntilConnected(){\n\t}", "CodeBleu_score": 1.0145750671711116}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error deleting node\", e);\n\t\tthrow new IllegalStateException(\"Error deleting node\", e);\n\t}\n}", "CodeBleu_score": 65.58140481940595}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tthis.zookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"Unable to delete nodes from Zookeeper instance: \" + serverId + \" with paths: \" + pathList, e);\n\t\tthrow new IllegalStateException(\"Unable to delete nodes from Zookeeper instance: \" + serverId + \" with paths: \" + pathList, e);\n\t}\n}", "CodeBleu_score": 53.07459029474179}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tlog.error(\"Error deleting node: \" + e.getMessage());\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 65.74344403735766}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\t\t// TODO: Implement this function\n}", "CodeBleu_score": 3.3910150352935258}, {"code": "public void disconnect(String id){\n\t\tPlatform.runLater(() -> {\n\t\tServer server = serverTree.getServer(id);\n\t\tif (server!= null) {\n\t\t\tserverTree.remove(server);\n\t\t\tserver.disconnect();\n\t\t}\n\t});\n}", "CodeBleu_score": 38.133968245268015}, {"code": "public void disconnect(String id){\n\t\tPlatform.runLater(() -> {\n\t\tServer server = serverCache.get(id);\n\t\tif (server!= null) {\n\t\t\ttry {\n\t\t\t\tserver.disconnect();\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOGGER.log(Level.WARNING, \"Could not disconnect from Zookeeper.\", e);\n\t\t\t}\n\t\t\tserverCache.remove(id);\n\t\t}\n\t});\n}", "CodeBleu_score": 44.394636952322585}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tServerConfig config = serverConfigService.getServerConfig(serverId);\n\tString connectionUrl = getConnectionUrl(config);\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 21.97558404225606}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tServer server = zookeeperDomainService.getServer(serverId);\n\tString connectionUrl = getConnectionUrl(server);\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 21.79294764314734}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t//    Terminal terminal = zookeeperDomainService.startTerminal(serverId, stream);\n//    if (sshTunnelEnabled) {\n//        terminal.connect(connectionUrl);\n//    } else {\n//        terminal.connect(connectionUrl);\n//    }\n}", "CodeBleu_score": 3.9834435308745446}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tZooKeeper zk = getZooKeeper(id);\n\t\tzk.execute(command);\n\t} catch (KeeperException e) {\n\t\tlog.error(\"Error executing command \" + command + \" on server \" + id + \": \" + e.toString());\n\t\terror(\"Error executing command \" + command + \" on server \" + id + \": \" + e.toString());\n\t} catch (InterruptedException e) {\n\t\tlog.error(\"Error executing command \" + command + \" on server \" + id + \": \" + e.toString());\n\t\terror(\"Error executing command \" + command + \" on server \" + id + \": \" + e.toString());\n\t}\n}", "CodeBleu_score": 32.76522949181195}, {"code": "public void executeCommand(String id, String command){\n\terror\n\n", "CodeBleu_score": 7.594276125461641}, {"code": "public void executeCommand(String id, String command){\n\t\n}", "CodeBleu_score": 7.627707831999869}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\tProperties properties = new Properties();\ntry {\nif (zookeeperSystemPropertiesFile.exists()) {\nproperties.load(new FileInputStream(zookeeperSystemPropertiesFile));\nlog.info(\"Loaded ZooKeeper system properties from \" + zookeeperSystemPropertiesFile);\n} else {\nlog.info(\"No ZooKeeper system properties file found at \" + zookeeperSystemPropertiesFile);\n}\n} catch (IOException e) {\nlog.error(\"Failed to load ZooKeeper system properties from \" + zookeeperSystemPropertiesFile, e);\n}\nreturn properties;\n}", "CodeBleu_score": 33.677894901268616}, {"code": "public Properties loadZookeeperSystemProperties(){\n\treturn null;\n}", "CodeBleu_score": 1.112279793882942}, {"code": "public Properties loadZookeeperSystemProperties(){\n\tProperties properties = new Properties();\ntry {\nFile file = new File(ZOOKEEPER_SYSTEM_PROPERTIES_FILE);\nif (file.exists()) {\nproperties.load(new FileInputStream(file));\n}\n} catch (IOException e) {\nlog.error(\"Error loading system properties from file: \" + ZOOKEEPER_SYSTEM_PROPERTIES_FILE, e);\n}\nreturn properties;\n}", "CodeBleu_score": 36.73999707637746}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\ttry {\nProperties properties = new Properties();\nproperties.load(new StringReader(content));\nfor (Entry<Object, Object> entry : properties.entrySet()) {\nSystem.setProperty(entry.getKey().toString(), entry.getValue().toString());\n}\n} catch (IOException e) {\nlog.error(\"Error loading system properties from content\", e);\nshowNotification(\"Error loading system properties from content\", e);\n}\ntry {\nFileOutputStream fos = new FileOutputStream(SYS_PROP_PATH);\nProperties properties = new Properties();\nproperties.load(new StringReader(content));\nfor (Entry<Object, Object> entry : properties.entrySet()) {\nproperties.setProperty(entry.getKey().toString(), entry.getValue().toString());\n}\nproperties.store(fos, \"Zookeeper system properties\");\n} catch (IOException e) {\nlog.error(\"Error saving system properties to file\", e);\nshowNotification(\"Error saving system properties to file\", e);\n}\n}", "CodeBleu_score": 36.77633729743239}, {"code": "public void saveZookeeperSystemProperties(String content){\n\tProperties properties = new Properties();\ntry {\nproperties.load(new StringReader(content));\n} catch (IOException e) {\ne.printStackTrace();\n}\nFile file = new File(SYS_PROP_PATH);\ntry {\nproperties.store(new FileOutputStream(file), null);\n} catch (IOException e) {\ne.printStackTrace();\n}\n}", "CodeBleu_score": 22.680224345397335}, {"code": "public void saveZookeeperSystemProperties(String content){\n\tProperties\nproperties\n=\nnew\nProperties\n;\ntry {\nproperties\n.\nload\n(\nnew\nStringReader\n(\ncontent\n)\n)\n;\n}\ncatch\n(\nIOException\ne\n)\n{\nlog\n.\nerror\n(\n\"\nFailed\nto\nload\nZookeeper\nsystem\nproperties\nfrom\ncontent\n\"\n,\ne\n)\n;\nshowError\n(\n\"\nFailed\nto\nload\nZookeeper\nsystem\nproperties\nfrom\ncontent\n\"\n)\n;\nreturn\n;\n}\ntry {\nFileOutputStream\nout\n=\nnew\nFileOutputStream\n(\nSYS_PROP_PATH\n)\n;\nproperties\n.\nstore\n(\nout\n,\nnull\n)\n;\nout\n.\nclose\n(\n)\n;\n}\ncatch\n(\nIOException\ne\n)\n{\nlog\n.\nerror\n(\n\"\nFailed\nto\nsave\nZookeeper\nsystem\nproperties\n\"\n,\ne\n)\n;\nshowError\n(\n\"\nFailed\nto\nsave\nZookeeper\nsystem\nproperties\n\"\n)\n;\nreturn\n;\n}\n}", "CodeBleu_score": 23.805087427584866}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\tStringBuilder response = new StringBuilder();\nBufferedReader reader = new BufferedReader(new InputStreamReader(client.getInputStream()));\ntry {\nfor (String line = reader.readLine(); line!= null; line = reader.readLine()) {\nresponse.append(line).append(\"\n\");\n}\n} catch (IOException e) {\nthrow new IllegalStateException(\"Error reading from client socket\", e);\n} finally {\ntry {\nreader.close();\n} catch (IOException e) {\n}\ntry {\nclient.close();\n} catch (IOException e) {\n}\n}\nreturn response.toString();\n}", "CodeBleu_score": 45.525408640336394}, {"code": "private String response(Socket client){\n\ttry {\nBufferedReader reader = new BufferedReader(new InputStreamReader(client.getInputStream()));\nStringBuilder sb = new StringBuilder();\nString line = null;\nwhile ((line = reader.readLine())!= null) {\nsb.append(line);\n}\nclient.close();\nreturn sb.toString();\n} catch (IOException e) {\nthrow new IllegalStateException(\"Error reading from socket\", e);\n}\n}", "CodeBleu_score": 47.11260737697492}, {"code": "private String response(Socket client){\n\tBufferedReader in = null;\ntry {\nin = new BufferedReader(new InputStreamReader(client.getInputStream()));\nStringBuilder sb = new StringBuilder();\nString line;\nwhile ((line = in.readLine())!= null) {\nsb.append(line);\n}\ncleanup(client);\nreturn sb.toString();\n} catch (IOException e) {\nthrow new IllegalStateException(e);\n} finally {\ncleanup(in);\n}\n}", "CodeBleu_score": 52.28715804525832}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\tCuratorFramework curatorFramework = new CuratorFrameworkFactory().builder()\n\t\t\t.connectString(params.connectString)\n\t\t\t.sessionTimeoutMs(params.sessionTimeoutMs)\n\t\t\t.retryPolicy(params.retryPolicy)\n\t\t\t.build();\n\tcuratorFramework.start();\n\tcuratorFramework.blockUntilConnected();\n\treturn new CuratorZookeeperConnection(curatorFramework);\n}", "CodeBleu_score": 30.856268355169675}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\tCuratorFramework client = CuratorFrameworkFactory.builder().connectString(params.connectionString).retryPolicy(params.retryPolicy).build();\n\tclient.start();\n\ttry {\n\t\tclient.blockUntilConnected(5, TimeUnit.SECONDS);\n\t} catch (Exception e) {\n\t\tclient.close();\n\t\tthrow new RuntimeException(e);\n\t}\n\treturn new CuratorZookeeperConnection(client, params);\n}", "CodeBleu_score": 45.92023901004856}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\tCuratorFramework client = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(params.connectString)\n\t\t\t.sessionTimeoutMs(params.sessionTimeoutMs)\n\t\t\t.connectionTimeoutMs(params.connectionTimeoutMs)\n\t\t\t.retryPolicy(params.retryPolicy)\n\t\t\t.build();\n\tclient.start();\n\ttry {\n\t\tclient.blockUntilConnected();\n\t} catch (Exception e) {\n\t\tclient.close();\n\t\tthrow new RuntimeException(e);\n\t}\n\treturn new CuratorZookeeperConnection(client);\n}", "CodeBleu_score": 42.59454692877076}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tString\nconnectionString\n=\ngetCurrentConnectionString\n(\n)\n;\nif\n(\nsyncInProgress\n)\n{\ninfo\n(\n\"\nZookeeper synchronization already in progress\n\"\n)\n;\nreturn\n;\n}\nsyncInProgress\n=\ntrue\n;\ndebug\n(\n\"\nStarting Zookeeper synchronization\n\"\n)\n;\nTreeCache\ncache\n=\nnew\nTreeCache\n(\ngetZookeeperClient\n(\n)\n,\nconnectionString\n)\n;\naddListener\n(\ncache\n)\n;\ntry\n{\ncache\n.\nstart\n(\nTreeCache\n.\nTreeCacheListener\n.\nNORMAL\n)\n;\n}\ncatch\n(\nException\ne\n)\n{\nerror\n(\n\"\nError starting TreeCache\n\"\n,\ne\n)\n;\ncache\n.\nclose\n(\n)\n;\nsyncInProgress\n=\nfalse\n;\nreturn\n;\n}\n}", "CodeBleu_score": 25.963431046504752}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tif\n(\n!\nsyncInProgress\n)\n{\nsyncInProgress\n=\ntrue\n;\nlog\n.\ninfo\n(\n\"\nStarting\nsync\n\"\n)\n;\ntreeCache\n=\nnew\nCuratorTreeCache\n(\ngetZookeeperClient\n(\n)\n,\ngetCurrentConnectionString\n(\n)\n)\n;\ntreeCache\n.\ngetListenable\n(\n)\n.\naddListener\n(\nnew\nCuratorTreeCacheListener\n(\n)\n)\n;\ntry\n{\ntreeCache\n.\nstart\n(\n)\n;\n}\ncatch\n(\nException\ne\n)\n{\nlog\n.\nerror\n(\n\"\nError\nstarting\nTreeCache\n\"\n,\ne\n)\n;\ntreeCache\n.\nclose\n(\n)\n;\n}\n}\nelse\n{\nlog\n.\ninfo\n(\n\"\nSync\nalready\nin\nprogress\n\"\n)\n;\n}\n}", "CodeBleu_score": 30.97777533980889}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tif\n(\n!\nsyncInProgress\n)\n{\nsyncInProgress\n=\ntrue\n;\ninfo\n(\n\"\nStarting\nsync\n\"\n)\n;\ntry\n{\naddListener\n(\nnew\nCuratorTreeCacheListener\n(\nthis\n,\nlisteners\n)\n)\n;\nstart\n(\n)\n;\n}\ncatch\n(\nException\ne\n)\n{\nclose\n(\n)\n;\nsyncInProgress\n=\nfalse\n;\nthrow\nnew\nZookeeperSyncException\n(\n\"\nError\nwhile\nstarting\nTreeCache\n\"\n,\ne\n)\n;\n}\n}\nelse\n{\ninfo\n(\n\"\nSync\nin\nprogress\n\"\n)\n;\n}\n}", "CodeBleu_score": 16.791451629616162}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tif (path == null) {\n\t\tthrow new IllegalArgumentException(\"path can't be null\");\n\t}\n\tif (listener == null) {\n\t\tthrow new IllegalArgumentException(\"listener can't be null\");\n\t}\n\tPathChildrenCache cache = new PathChildrenCache(zk, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n\tchildrenCache.put(path, cache);\n}", "CodeBleu_score": 57.004339977257736}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(zk, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 59.76736272083768}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\t// Create a new PathChildrenCache with the given path\n\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\n\t// Start the cache in BUILD_INITIAL_CACHE mode\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\n\t// Add the listener to the cache\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.56712611353464}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t\tgetLogger().info(\"Unregistering services...\");\n\tfor (String path : paths) {\n\t\ttry {\n\t\t\tcurator.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\tgetLogger().error(\"Error deleting path: \" + path, e);\n\t\t}\n\t}\n\tcurator.close();\n}", "CodeBleu_score": 48.20187761867997}, {"code": "public void unregisterService(){\n\t\tgetLogger().info(\"Unregistration started\");\n\tfor (String path : paths) {\n\t\ttry {\n\t\t\tcurator.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\tgetLogger().error(\"Could not delete path: \" + path, e);\n\t\t}\n\t}\n\tcurator.close();\n}", "CodeBleu_score": 47.66958338470913}, {"code": "public void unregisterService(){\n\t\tinfo(\"Unregistering services\");\n\tfor (String path : paths) {\n\t\ttry {\n\t\t\tcurator.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\terror(\"Failed to delete path \" + path + \": \" + e.getMessage());\n\t\t}\n\t}\n\tcurator.close();\n}", "CodeBleu_score": 44.64292900565815}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\t\ttry {\n\t\tmakeClientReady().thenAccept(client -> client.subscribeStateListener(listener));\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n}", "CodeBleu_score": 21.18529437551972}, {"code": "public void addListener(IZkStateListener listener){\n\t\ttry {\n\t\tmakeClientReady().whenComplete((zk, e) -> {\n\t\t\tif (e!= null) {\n\t\t\t\tthrow new RuntimeException(e);\n\t\t\t}\n\t\t\tzk.subscribeStateChanges(listener);\n\t\t});\n\t} catch (Exception e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 38.5318085703381}, {"code": "public void addListener(IZkStateListener listener){\n\t\ttry {\n\t\tmakeClientReady().thenRun(() -> {\n\t\t\tclient.subscribeStateListener(listener);\n\t\t});\n\t} catch (Exception e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 25.302580798976916}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis.serverAddr = serverAddr;\n\tthis.authority = authority;\n\tthis.retryPolicy = new ExponentialBackoffRetry(1000, 3);\n\tthis.connectionTimeout = 10000;\n\tthis.client = CuratorFrameworkFactory.newClient(serverAddr, authority, retryPolicy, connectionTimeout);\n\tthis.client.getConnectionStateListenable().addListener(this);\n\tthis.client.start();\n}", "CodeBleu_score": 14.326845749093826}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis.serverAddr = serverAddr;\n\tthis.authority = authority;\n\tretryPolicy = new ExponentialBackoffRetry(1000, 3);\n\tconnectionTimeoutMs = 3000;\n\tclient = CuratorFrameworkFactory.builder().connectString(serverAddr).retryPolicy(retryPolicy).connectionTimeoutMs(connectionTimeoutMs).build();\n\tclient.getConnectionStateListenable().addListener(this);\n\tclient.start();\n\tif (client.getState() == CuratorFrameworkState.STARTED) {\n\t\tthrow new IllegalStateException(\"CuratorFramework failed to start: \" + client.getState());\n\t}\n}", "CodeBleu_score": 28.181432588641254}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis(serverAddr, authority, new RetryNTimes(3, 1000));\n}", "CodeBleu_score": 3.688177827037204}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (listener!= null) {\n\t\tMap<String, ChildListener> childListeners = childListeners.get(path);\n\t\tif (childListeners!= null) {\n\t\t\tchildListeners.remove(listener);\n\t\t\tif (childListeners.size() == 0) {\n\t\t\t\tchildListeners.remove(path);\n\t\t\t\ttargetChildListeners.remove(path);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 41.923201299419055}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t}", "CodeBleu_score": 6.4131329332144436}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t}", "CodeBleu_score": 6.4131329332144436}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (zh == NULL) {\n\t\tLOG_ERR(\"Null ZooKeeper handle passed to watcher_reconnect_to_zookeeper\");\n\t\treturn -1;\n\t}\n\n\tchar *idc_host = NULL;\n\tchar *idc_port = NULL;\n\tchar *idc_path = NULL;\n\tchar *idc_host_port = NULL;\n\tint rc = 0;\n\tint i = 0;\n\n\t/* Delete the old IDC host information from the table watcher */\n\trc = lock_ht_delete(zh);\n\tif (rc!= 0) {\n\t\tLOG_ERR(\"Error deleting IDC host information from table watcher: %d\", rc);\n\t\treturn -1;\n\t}\n\n\t/* Close the old ZooKeeper handle */\n\trc = zookeeper_close(zh);\n\tif (rc!= ZOK) {\n\t\tLOG_ERR(\"Error closing ZooKeeper handle: %d\", rc);\n\t\treturn -1;\n\t}\n\n\t/* Deserialize the IDC and host information */\n\trc = deserialize_from_idc_host(idc_host, idc_port, idc_path, &idc_host_port);\n\tif (rc!= 0) {\n\t\tLOG_ERR(\"Error deserializing IDC and host information: %d\", rc);\n\t\treturn -1;\n\t}\n\n\t/* Initialize a new ZooKeeper handle with the deserialized information */\n\tzh = zookeeper_init(idc_host_port, watcher_global_watcher, 30000, 0, NULL, 0);\n\tif (zh == NULL) {\n\t\tLOG_ERR(\"Error initializing ZooKeeper handle\");\n\t\treturn -1;\n\t}\n\n\t/* Initialize the environment for the new handle */\n\tfor (i = 0; i < NUM_TABLES; i++) {\n\t\trc = init_env_for_zk(zh, i);\n\t\tif (rc!= 0) {\n\t\t\tLOG_ERR(\"Error initializing environment for table %d: %d\", i, rc);\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\t/* Reset the table watcher */\n\trc = table_watcher_init(zh);\n\tif (rc!= 0) {\n\t\t", "CodeBleu_score": 29.754563809194845}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (zh == NULL) {\n\t\tLOG_ERR(\"handle is null\");\n\t\treturn -1;\n\t}\n\tchar *idc_host = NULL;\n\tchar *idc_host_port = NULL;\n\tint rc = lock_ht_find(zh, &idc_host, &idc_host_port);\n\tif (rc!= 0) {\n\t\tLOG_ERR(\"failed to find IDC host information\");\n\t\treturn -1;\n\t}\n\tlock_ht_delete(zh, idc_host, idc_host_port);\n\tzookeeper_close(zh);\n\tdeserialize_from_idc_host(idc_host, idc_host_port, &zh);\n\tinit_env_for_zk(zh);\n\trc = zoo_awget_children(zh, IDC_PATH, watcher_table_watcher, NULL, NULL);\n\tif (rc!= ZOK) {\n\t\tLOG_ERR(\"failed to watch table\");\n\t\treturn -1;\n\t}\n\treturn 0;\n}", "CodeBleu_score": 27.7504661327776}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (zh == NULL) {\n\t\treturn -1;\n\t}\n\n\t// Delete the IDC host information associated with the handle.\n\tlock_ht_delete(ht_idc_host, zh);\n\n\t// Close the old handle.\n\tzookeeper_close(zh);\n\n\t// Deserialize the IDC and host information.\n\tchar *idc_host = deserialize_from_idc_host(zh);\n\tif (idc_host == NULL) {\n\t\treturn -1;\n\t}\n\n\t// Initialize a new ZooKeeper handle with this information.\n\tzh = zookeeper_init(idc_host, watcher, 30000, 0, NULL, 0);\n\tif (zh == NULL) {\n\t\treturn -1;\n\t}\n\n\t// Initialize the environment for the new handle.\n\tinit_env_for_zk(zh);\n\n\t// Reset the table watcher.\n\ttable_watcher_init(zh);\n\n\treturn 0;\n}", "CodeBleu_score": 11.081145219999552}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\tLOG_INFO(\"init_env_for_zk idc_host: %s, idc: %s\", idc_host.c_str(), idc.c_str());\n\t// add idc to gray list\n\tadd_gray_idc(idc);\n\t// update idc host\n\tidc_host_ = idc_host;\n\t// update idc\n\tidc_ = idc;\n\t// update zk handle\n\tzk_handle_ = zh;\n\t// update zk state\n\tzoo_state_ = ZOO_CONNECTED_STATE;\n\t// check zk connection state\n\tint ret = zoo_state(zk_handle_);\n\tif (ret!= ZOO_CONNECTED_STATE) {\n\t\tLOG_FATAL_ERR(\"zoo_state failed, ret: %d\", ret);\n\t\texit(1);\n\t}\n\t// register current host on zk server\n\tret = zk_register_ephemeral(zk_handle_, idc_host_);\n\tif (ret!= ZOK) {\n\t\tLOG_FATAL_ERR(\"zk_register_ephemeral failed, ret: %d\", ret);\n\t\texit(1);\n\t}\n\t// set watcher on notify node\n\tret = watch_notify_node(zk_handle_);\n\tif (ret!= ZOK) {\n\t\tLOG_FATAL_ERR(\"watch_notify_node failed, ret: %d\", ret);\n\t\texit(1);\n\t}\n}", "CodeBleu_score": 40.18743106202524}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\t// set the idc_host and idc for the handle\n\tidc_host_ht_update(idc_host);\n\tidc_ht_update(idc);\n\n\t// check the connection state of the handle\n\tint32_t state = zoo_state(zh);\n\tif (state!= ZOO_CONNECTED_STATE) {\n\t\tLOG_FATAL_ERR(\"Zookeeper handle is not connected\");\n\t}\n\n\t// register the current host on the Zookeeper server and set a watcher on the notify node\n\tint32_t ret = zk_register_ephemeral(zh, idc_host);\n\tif (ret!= ZOK) {\n\t\tLOG_FATAL_ERR(\"Failed to register the current host on the Zookeeper server\");\n\t}\n\twatch_notify_node(zh);\n}", "CodeBleu_score": 36.019666657228576}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\tif (!zh) {\n\t\tLOG_FATAL_ERR(\"zk handle is null\");\n\t\treturn;\n\t}\n\n\tLOG_INFO(\"idc_host: %s, idc: %s\", idc_host.c_str(), idc.c_str());\n\n\t// update internal tables\n\tlock_ht_update();\n\tif (idc_host.empty() || idc.empty()) {\n\t\tLOG_FATAL_ERR(\"idc_host or idc is empty\");\n\t\tunlock_ht_update();\n\t\treturn;\n\t}\n\tif (idc_host_ht.find(idc_host) == idc_host_ht.end()) {\n\t\tidc_host_ht[idc_host] = idc;\n\t}\n\tif (idc_ht.find(idc) == idc_ht.end()) {\n\t\tidc_ht[idc] = idc_host;\n\t}\n\tunlock_ht_update();\n\n\t// check connection state\n\tint ret = zoo_state(zh);\n\tif (ret!= ZOO_CONNECTED_STATE) {\n\t\tLOG_FATAL_ERR(\"zk handle is not connected\");\n\t\treturn;\n\t}\n\n\t// register the current host on the Zookeeper server\n\tstring notify_node = idc_host + \"/notify\";\n\tret = zoo_register_ephemeral(zh, notify_node.c_str(), NULL, 0, NULL);\n\tif (ret!= ZOK) {\n\t\tLOG_FATAL_ERR(\"register ephemeral failed: %s\", zerror(ret));\n\t\treturn;\n\t}\n\n\t// set watcher on the notify node\n\tret = zoo_awexists(zh, notify_node.c_str(), watch_notify_node, NULL, NULL);\n\tif (ret!= ZOK) {\n\t\tLOG_FATAL_ERR(\"awexists failed: %s\", zerror(ret));\n\t\treturn;\n\t}\n}", "CodeBleu_score": 42.84020221189212}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    return '%s:%s' % (username, b64encode(hashlib.sha1(password.encode()).digest()))\n\n", "CodeBleu_score": 14.955031843777483}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    return \"%s:%s\" % (username, b64encode(sha1(password.encode()).digest()).decode())\n\n", "CodeBleu_score": 14.8742170467037}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    digest_hash = hashlib.sha1(password.encode())\n    cred_hash = b64encode(digest_hash.digest())\n    return username + \":\" + cred_hash.decode()\n\n", "CodeBleu_score": 29.017026927384848}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    else:\n        lock_path = '/locks/' + self.processing_element\n        lock_value = self.zk.get(lock_path)[0]\n        return lock_value == self.instance_id\n\n", "CodeBleu_score": 42.11304723357176}, {"code": "def holds_lock(self)\n\t\n    if not self.processing_element:\n        return False\n    else:\n        lock_path = self.processing_element.get_lock_path()\n        try:\n            lock_value = self.processing_element.get_lock_value()\n        except NoNodeError:\n            return False\n        else:\n            return lock_value == self.instance_id\n\n", "CodeBleu_score": 31.781519011404015}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_path = self.get_lock_path()\n    self.zk_client.sync(lock_path)\n    lock_value = self.zk_client.get(lock_path)[0]\n    return lock_value == self.id\n", "CodeBleu_score": 43.2635411512185}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    self.processing_element = None\n    self.holds_lock = False\n    transaction = Transaction.get_current()\n    transaction.begin()\n    try:\n        lock = Lock.get_lock_by_id(self.lock_id)\n        if lock is not None and lock.holds_lock:\n            lock.processing_element = None\n            lock.holds_lock = False\n            lock.delete()\n            transaction.commit()\n            return True\n        else:\n            transaction.rollback()\n            return False\n    except:\n        transaction.rollback()\n        raise\n", "CodeBleu_score": 35.80703723490792}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    transaction = self.database.begin()\n    self.processing_element.delete()\n    self.processing_element = None\n    transaction.commit()\n    return True\n", "CodeBleu_score": 23.65180085180949}, {"code": "def consume(self)\n\t\n    if self.processing_element is not None:\n        if self.holds_lock:\n            self.processing_element.process_lock(self)\n            self.processing_element = None\n            return True\n        else:\n            return False\n    else:\n        return False\n\n", "CodeBleu_score": 29.305569442084366}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        if self._socket is None:\n            return\n        if self._read_timeout is None:\n            self._read_timeout = read_timeout\n        if self._read_timeout is not None:\n            self._socket.settimeout(self._read_timeout)\n        try:\n            header = self._read_header()\n            if header.xid == PING_XID:\n                self._log_ping()\n                self._ping_outstanding = False\n            elif header.xid == AUTH_XID:\n                self._read_auth_response(header)\n            elif header.xid == WATCH_XID:\n                self._read_watch_event(header)\n            else:\n                self._log_header(header)\n                self._read_response(header)\n        except socket.timeout:\n            pass\n        except (ConnectionResetError, OSError):\n            self._socket = None\n        except Exception as e:\n            self._set_exception(e)\n        finally:\n            self._read_timeout = None\n\n", "CodeBleu_score": 34.35988607191906}, {"code": "def _read_socket(self, read_timeout)\n\t\n    while True:\n        try:\n            if self._read_header():\n                break\n            if self._read_buffer():\n                break\n            if self._read_watch_event():\n                break\n            if self._read_response():\n                break\n            if self._read_ping():\n                break\n            if self._read_auth():\n                break\n            if self._read_exception():\n                break\n            if self._read_socket_timeout(read_timeout):\n                break\n        except (\n            asyncio.CancelledError,\n            asyncio.IncompleteReadError,\n            asyncio.TimeoutError,\n            asyncio.LimitOverrunError,\n        ) as e:\n            raise e\n        except Exception as e:\n            self.log.error(f\"Exception while reading from socket: {e}\")\n            self.log.exception(e)\n            self.set_exception(e)\n            break\n\n", "CodeBleu_score": 24.69053862023397}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        if self._read_timeout is None:\n            self._read_timeout = read_timeout\n        if self._read_timeout > 0:\n            self._socket.settimeout(self._read_timeout)\n        self._read_header()\n        if self._read_timeout > 0:\n            self._socket.settimeout(None)\n        if self._read_header.xid == PING_XID:\n            self._log_ping()\n            self._outstanding_ping = False\n            return\n        if self._read_header.xid == AUTH_XID:\n            self._read_auth_response()\n            return\n        if self._read_header.xid == WATCH_XID:\n            self._read_watch_event()\n            return\n        self._log_header()\n        self._read_response()\n    except socket.timeout:\n        pass\n    except Exception as e:\n        self._set_exception(e)\n\n", "CodeBleu_score": 30.09439448923476}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.log(\"Starting Zookeeper loop\")\n    self.connection_stopped.clear()\n    try:\n        self.log(\"Connecting to Zookeeper\")\n        self.connect()\n    except Exception as e:\n        self.log(\"Error connecting to Zookeeper: {0}\".format(e))\n        self.log(\"Warning: Zookeeper connection failed\")\n    self.connection_stopped.set()\n    self.log(\"Triggering session callback with closed state\")\n    self.session_callback(self.zk_state.CLOSED)\n    self.log(\"Stopping Zookeeper loop\")\n\n", "CodeBleu_score": 35.9027195570019}, {"code": "def zk_loop(self)\n\t\n    self.log.info(", "CodeBleu_score": 0.373134328359244}, {"code": "def zk_loop(self)\n\t\n    self.log.info('Starting Zookeeper connection loop')\n    self.connection_stopped.clear()\n    while not self.connection_stopped.is_set():\n        try:\n            self.log.info('Attempting to connect to Zookeeper')\n            self.zk = KazooClient(hosts=self.zk_hosts,\n                                  timeout=self.zk_timeout,\n                                  connection_retry=self.zk_retry,\n                                  logger=self.log)\n            self.zk.start()\n            self.log.info('Zookeeper connection established')\n            break\n        except Exception as e:\n            self.log.warning('Zookeeper connection attempt failed: %s' % e)\n            time.sleep(self.zk_retry_wait)\n    self.connection_stopped.set()\n    self.zk.add_listener(self.zk_session_callback)\n    self.log.info('Zookeeper connection loop stopped')\n\n", "CodeBleu_score": 46.10802991313728}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    index = sorted_members.index(identifier)\n    return sorted_partitions[index::len(sorted_members)]\n\n", "CodeBleu_score": 35.701061449925966}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    sorted_partitions_len = len(sorted_partitions)\n    sorted_members_len = len(sorted_members)\n    sorted_partitions_index = sorted_partitions.index(identifier)\n    sorted_partitions_index = sorted_partitions_index % sorted_members_len\n    return sorted_partitions[sorted_partitions_index::sorted_members_len]\n\n", "CodeBleu_score": 21.246749966657724}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    try:\n        index = sorted_members.index(identifier)\n    except ValueError:\n        index = 0\n    return sorted_partitions[index::len(members)]\n\n", "CodeBleu_score": 48.4826600278642}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    self._participating = False\n    self._best_effort_cleanup()\n    retry\n\n", "CodeBleu_score": 23.822724173322946}, {"code": "def leave(self)\n\t\n    self._participating = False\n    self._best_effort_cleanup()\n    retry\n\n", "CodeBleu_score": 23.822724173322946}, {"code": "def leave(self)\n\t\n    self._participating = False\n    self._best_effort_cleanup()\n    retry\n\n", "CodeBleu_score": 23.822724173322946}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t}", "CodeBleu_score": 1.686203213849344}, {"code": "public Result start(){\n\t\tResult result = Result.error();\n\ttry {\n\t\tif (statusServer() == ServerStatus.STOPPED) {\n\t\t\tresult = Result.success();\n\t\t\tstartServer();\n\t\t} else {\n\t\t\tresult = Result.error(\"Server is already running.\");\n\t\t}\n\t} catch (Exception e) {\n\t\tresult = Result.error(e);\n\t}\n\treturn result;\n}", "CodeBleu_score": 40.47181620054313}, {"code": "public Result start(){\n\t\tif (statusServer() == ServerStatus.RUNNING) {\n\t\treturn Result.success();\n\t}\n\ttry {\n\t\tFTPServer server = new FTPServer();\n\t\tserver.start();\n\t\treturn Result.success();\n\t} catch (Exception e) {\n\t\treturn Result.error(e.getMessage());\n\t}\n}", "CodeBleu_score": 31.91293531995282}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t\tif (isServerRunning()) {\n\t\ttry {\n\t\t\tftpServer.stop();\n\t\t\treturn Result.success(\"Server stopped successfully.\");\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t\treturn Result.failure(\"Server failed to stop. \" + e.getMessage());\n\t\t}\n\t} else {\n\t\treturn Result.failure(\"Server is not running.\");\n\t}\n}", "CodeBleu_score": 30.17515465461787}, {"code": "public Result stop(){\n\t\ttry {\n\t\tif (isRunning()) {\n\t\t\tftpServer.stop();\n\t\t\treturn Result.success(\"FTP server stopped.\");\n\t\t} else {\n\t\t\treturn Result.failure(\"FTP server is not running.\");\n\t\t}\n\t} catch (IOException e) {\n\t\treturn Result.failure(\"FTP server could not be stopped: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 29.781165478660355}, {"code": "public Result stop(){\n\t\ttry {\n\t\tif (isServerRunning()) {\n\t\t\tserver.stop();\n\t\t\treturn Result.success(\"Server stopped.\");\n\t\t} else {\n\t\t\treturn Result.failure(\"Server is not running.\");\n\t\t}\n\t} catch (IOException e) {\n\t\tlog.error(e.getMessage(), e);\n\t\treturn Result.failure(e.getMessage());\n\t}\n}", "CodeBleu_score": 35.55430287746499}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tif (request == null) {\n\t\tthrow new IllegalArgumentException(\"AuthorizationRequest cannot be null\");\n\t}\n\n\tif (this.authorities.isEmpty()) {\n\t\treturn null;\n\t}\n\n\tfor (final Authority authority : this.authorities) {\n\t\tfinal AuthorizationRequest updatedRequest = authority.authorize(request);\n\t\tif (updatedRequest!= null) {\n\t\t\treturn updatedRequest;\n\t\t}\n\t}\n\n\treturn null;\n}", "CodeBleu_score": 32.37415333231868}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tif (this.authorities == null || this.authorities.isEmpty()) {\n\t\treturn null;\n\t}\n\tfor (final Authority authority : this.authorities) {\n\t\tfinal AuthorizationRequest authorizedRequest = authority.authorize(request);\n\t\tif (authorizedRequest!= null) {\n\t\t\treturn authorizedRequest;\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 29.699684451191246}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tif (authorities.isEmpty()) {\n\t\treturn null;\n\t}\n\tfor (GrantedAuthority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\trequest.setAuthorized(true);\n\t\t\treturn request;\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 23.32756870017323}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t\ttry {\n\t\tgetDfs().mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\tprintStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 39.59068623920017}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tgetDfs().mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\tprintStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 39.59068623920017}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tgetDfs().mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\tprintStackTrace(e);\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 39.41977295093911}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t\ttry {\n\t\tfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 51.33018727652545}, {"code": "public boolean delete(){\n\t\ttry {\n\t\treturn this.getDfs().delete(this.getFullPath(), true);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 43.624839320998554}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tgetDfs().delete(getDfs().getUri(), true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 48.21703450402646}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tString newPath = getParent().getPath() + \"/\" + ftpFile.getName();\n\t\tFileSystem fs = getFileSystem(newPath);\n\t\tfs.rename(getPath(), newPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 57.72400719170898}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = getDfs();\n\t\tPath src = new Path(ftpFile.getPath());\n\t\tPath dst = new Path(getParent().getPath() + \"/\" + ftpFile.getName());\n\t\tfs.rename(src, dst);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 56.21999605210759}, {"code": "public boolean move(FtpFile ftpFile){\n\t\tFileSystem fs = getFileSystem();\n\ttry {\n\t\tfs.rename(ftpFile.getPath(), ftpFile.getParent().getPath() + \"/\" + ftpFile.getName());\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 55.06376452986803}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tPath path = new Path(baseDir.getAbsolutePath());\n\t\tFileSystem fs = baseDir.getFileSystem(conf);\n\t\tFileStatus[] fileStatus = fs.listStatus(path);\n\t\tList<FtpFile> list = new ArrayList<FtpFile>();\n\t\tfor (FileStatus status : fileStatus) {\n\t\t\tString name = status.getPath().getName();\n\t\t\tFtpFile file = new FtpFile(name, status.isDirectory());\n\t\t\tlist.add(file);\n\t\t}\n\t\treturn Collections.unmodifiableList(list);\n\t} catch (IOException e) {\n\t\tlog.error(e.getMessage());\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 30.34341652999052}, {"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tList<FtpFile> files = new ArrayList<FtpFile>();\n\t\tFileStatus[] statuses = getFileSystem().listStatus(getPath());\n\t\tfor (FileStatus status : statuses) {\n\t\t\tfiles.add(new FtpFile(this, status));\n\t\t}\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\tlog.error(\"Error listing files in directory: \" + getPath(), e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 21.273776281023494}, {"code": "public List<FtpFile> listFiles(){\n\t\tList<FtpFile> list = new ArrayList<FtpFile>();\n\ttry {\n\t\tFileSystem fs = getDfs();\n\t\tPath base = new Path(getBase());\n\t\tFileStatus[] files = fs.listStatus(base);\n\t\tfor (FileStatus file : files) {\n\t\t\tPath path = file.getPath();\n\t\t\tString name = path.getName();\n\t\t\tString virtual = getVirtualPath() + \"/\" + name;\n\t\t\tFtpFile ftpFile = new FtpFile(name, virtual, file.isDirectory());\n\t\t\tlist.add(ftpFile);\n\t\t}\n\t} catch (IOException e) {\n\t\tlog.error(\"Unable to list files\", e);\n\t}\n\treturn Collections.unmodifiableList(list);\n}", "CodeBleu_score": 32.912341929553726}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t\tif (configState) {\n\t\tthrow new FtpServerConfigurationException(\"Configuration already performed.\");\n\t}\n\tconfigState = true;\n\ttry {\n\t\tload();\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\"Could not load user data file: \" + userDataFile.getAbsolutePath(), e);\n\t}\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 31.56349763347577}, {"code": "public void configure(){\n\tif (configured) {\nthrow new FtpServerConfigurationException(\"Already configured.\");\n}\nconfigured = true;\nuserData = new UserData();\ntry {\nuserData.load(getUserDataFile());\n} catch (IOException e) {\nthrow new FtpServerConfigurationException(\"Failed to load user data from file '\" + getUserDataFile().getAbsolutePath() + \"'.\", e);\n}\nuserData.convertDeprecatedPropertyNames();\n}", "CodeBleu_score": 35.59453640720369}, {"code": "public void configure(){\n\t\tif (configState) {\n\t\treturn;\n\t}\n\tconfigState = true;\n\tuserProperties = new Properties();\n\ttry {\n\t\tif (userDataFile.exists()) {\n\t\t\tuserProperties.load(userDataFile.getInputStream());\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\"Error reading user data file: \" + userDataFile.getAbsolutePath(), e);\n\t}\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 43.06745211701064}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\tFile parentDir = userDataFile.getParentFile();\nif (!parentDir.exists()) {\nif (!parentDir.mkdirs()) {\nthrow new FtpException(\"Unable to create parent directory for user data file: \" + parentDir.getAbsolutePath());\n}\n}\nFileOutputStream fos = null;\ntry {\nfos = new FileOutputStream(userDataFile);\nfos.write(userData.getBytes());\n} catch (IOException e) {\nLOGGER.error(\"Error writing user data to file: \" + userDataFile.getAbsolutePath(), e);\nthrow new FtpException(\"Error writing user data to file: \" + userDataFile.getAbsolutePath(), e);\n} finally {\nif (fos!= null) {\ntry {\nfos.close();\n} catch (IOException e) {\nLOGGER.error(\"Error closing file stream for user data file: \" + userDataFile.getAbsolutePath(), e);\n}\n}\n}\n}", "CodeBleu_score": 44.522539483724415}, {"code": "private void saveUserData() throws FtpException{\n\ttry {\nif (!parentFile.exists()) {\nif (!parentFile.mkdirs()) {\nthrow new FtpException(\"Unable to create directory: \" + parentFile.getAbsolutePath());\n}\n}\nFileOutputStream outputStream = new FileOutputStream(userFile);\noutputStream.write(userData.getBytes());\noutputStream.close();\n} catch (IOException e) {\nlogger.error(\"Unable to save user data to file: \" + userFile.getAbsolutePath());\nthrow new FtpException(\"Unable to save user data to file: \" + userFile.getAbsolutePath());\n}\n}", "CodeBleu_score": 30.49902289623886}, {"code": "private void saveUserData() throws FtpException{\n\ttry {\nFile parent = userDataFile.getParentFile();\nif (parent!= null &&!parent.exists()) {\nif (!parent.mkdirs()) {\nthrow new FtpException(\"Unable to create parent directory for user data file: \" + userDataFile.getAbsolutePath());\n}\n}\nFileOutputStream out = new FileOutputStream(userDataFile);\nout.write(userData.getBytes());\nout.close();\n} catch (IOException e) {\nthrow new FtpException(\"Unable to save user data to file: \" + userDataFile.getAbsolutePath(), e);\n}\n}", "CodeBleu_score": 36.3739221810792}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t\ttry {\n\t\tHdfsUserManager hdfsUserManager = new HdfsUserManager();\n\t\thdfsUserManager.setFile(new File(\"users.properties\"));\n\t\thdfsUserManager.delete(user);\n\t\treturn new Result(true, \"Successfully deleted user \" + user);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error deleting user \" + user, e);\n\t\treturn new Result(false, \"Error deleting user \" + user);\n\t}\n}", "CodeBleu_score": 58.9080112835926}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager hdfsUserManager = new HdfsUserManager();\nhdfsUserManager.setFile(new File(\"users.properties\"));\nhdfsUserManager.delete(user);\nreturn new Result(\"Success\");\n} catch (Exception e) {\nlogger.error(e.getMessage());\nreturn new Result(\"Failure\");\n}\n}", "CodeBleu_score": 40.400988348391344}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager.getInstance().delete(user);\nreturn new Result(true, \"Success\");\n} catch (Exception e) {\ne.printStackTrace();\nreturn new Result(false, \"Error\");\n}\n}", "CodeBleu_score": 25.15842840807702}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tif (path == null) {\n\t\tthrow new IllegalArgumentException(\"Path is null\");\n\t}\n\tString pathStr = path.toString();\n\tif (pathStr.length() == 0) {\n\t\tthrow new IllegalArgumentException(\"Path is empty string\");\n\t}\n\tif (pathStr.startsWith(FS_DEFAULT_NAME_PREFIX)) {\n\t\tthrow new IllegalArgumentException(\"Path is a special name\");\n\t}\n\tif (pathStr.startsWith(FS_DEFAULT_NAME_PREFIX)) {\n\t\tthrow new IllegalArgumentException(\"Path is a special name\");\n\t}\n\tif (pathStr.startsWith(FS_DEFAULT_NAME_PREFIX)) {\n\t\tthrow new IllegalArgumentException(\"Path is a special name\");\n\t}\n\tif (pathStr.startsWith(FS_DEFAULT_NAME_PREFIX)) {\n\t\tthrow new IllegalArgumentException(\"Path is a special name\");\n\t}\n\tif (pathStr.startsWith(FS_DEFAULT_NAME_PREFIX)) {\n\t\tthrow new IllegalArgumentException(\"Path is a special name\");\n\t}\n\tif (pathStr.startsWith(FS_DEFAULT_NAME_PREFIX)) {\n\t\tthrow new IllegalArgumentException(\"Path is a special name\");\n\t}\n\tif (pathStr.startsWith(FS_DEFAULT_NAME_PREFIX)) {\n\t\tthrow new IllegalArgumentException(\"Path is a special name\");\n\t}\n\tif (pathStr.startsWith(FS_DEFAULT_NAME_PREFIX)) {\n\t\tthrow new IllegalArgumentException(\"Path is a special name\");\n\t}\n\tif (pathStr.startsWith(FS_DEFAULT_NAME_PREFIX)) {\n\t\tthrow new IllegalArgumentException(\"Path is a special name\");\n\t}\n\tif (pathStr.startsWith(FS_DEFAULT_NAME_PREFIX)) {\n\t\tthrow new IllegalArgumentException(\"Path is a special name\");\n\t}\n\tif (pathStr.startsWith(FS_DEFAULT_NAME_PREFIX)) {\n\t\tthrow new IllegalArgumentException(\"Path is a special name\");\n\t}\n\tif (pathStr.startsWith(FS_DEFAULT_NAME_PREFIX)) {\n\t\tthrow new IllegalArgumentException(\"Path is a special name\");\n\t}\n\tif (pathStr.startsWith(FS_DEFAULT_NAME_PREFIX)) {\n\t\tthrow new IllegalArgumentException(\"Path is a special name\");\n\t}\n\tif (pathStr.startsWith(FS_DEFAULT_NAME_PREFIX)) {\n\t\tthrow new IllegalArgumentException(\"", "CodeBleu_score": 14.790127046368875}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tif (path == null) {\n\t\tthrow new IllegalArgumentException(\"path is null\");\n\t}\n\tString pathStr = path.toString();\n\tif (pathStr.length() > 0) {\n\t\tif (pathStr.charAt(0)!= '/') {\n\t\t\tthrow new IllegalArgumentException(\"path does not start with a /\");\n\t\t}\n\t}\n\tif (pathStr.length() > 256) {\n\t\tthrow new IllegalArgumentException(\"path is too long\");\n\t}\n\tif (pathStr.indexOf('/', 1) >= 0) {\n\t\tthrow new IllegalArgumentException(\"path contains a / in the wrong place\");\n\t}\n\tif (pathStr.indexOf('..', 1) >= 0) {\n\t\tthrow new IllegalArgumentException(\"path contains a..\");\n\t}\n\tif (pathStr.indexOf('\\\\', 1) >= 0) {\n\t\tthrow new IllegalArgumentException(\"path contains a \\\\\");\n\t}\n\tif (pathStr.indexOf(':', 1) >= 0) {\n\t\tthrow new IllegalArgumentException(\"path contains a :\");\n\t}\n\tif (pathStr.indexOf('?', 1) >= 0) {\n\t\tthrow new IllegalArgumentException(\"path contains a?\");\n\t}\n\tif (pathStr.indexOf('*', 1) >= 0) {\n\t\tthrow new IllegalArgumentException(\"path contains a *\");\n\t}\n\tif (pathStr.indexOf('<', 1) >= 0) {\n\t\tthrow new IllegalArgumentException(\"path contains a <\");\n\t}\n\tif (pathStr.indexOf('>', 1) >= 0) {\n\t\tthrow new IllegalArgumentException(\"path contains a >\");\n\t}\n\tif (pathStr.indexOf('|', 1) >= 0) {\n\t\tthrow new IllegalArgumentException(\"path contains a |\");\n\t}\n\tif (pathStr.indexOf('\"', 1) >= 0) {\n\t\tthrow new IllegalArgumentException(\"path contains a \\\"\");\n\t}\n\tif (pathStr.indexOf('\\'', 1) >= 0) {\n\t\tthrow new IllegalArgumentException(\"path contains a \\'\");\n\t}\n\tif (pathStr.indexOf(' ', 1) >= 0) {\n\t\tthrow new IllegalArgumentException(\"path contains a space\");\n\t}\n\tif (pathStr.indexOf('\\t', 1) >=", "CodeBleu_score": 14.41810109414719}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tString pathStr = path.toString();\n\tLOG.info(\"Opening file \" + pathStr + \" with buffer size \" + bufferSize);\n\tPath qualified = getConf().makeQualified(path);\n\tFSDataInputStream in = null;\n\ttry {\n\t\tin = new FSDataInputStream(new BufferedInputStream(\n\t\t\tnew SeaweedInputStream(qualified.toUri().getPath(), getConf(), bufferSize)));\n\t} catch (IOException e) {\n\t\tLOG.warn(\"Failed to open file \" + pathStr + \" with buffer size \" + bufferSize, e);\n\t}\n\treturn in;\n}", "CodeBleu_score": 35.08124187766688}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tif (isRoot(src)) {\nreturn false;\n}\nif (src.equals(dst)) {\nreturn true;\n}\nPath dstDir = dst.getParent();\nif (dstDir!= null) {\ndstDir = qualify(dstDir);\n}\nif (lookupEntry(dstDir)!= null) {\ndst = dstDir.resolve(dst.getFileName());\n}\nsrc = qualify(src);\ndst = qualify(dst);\nreturn getStore().rename(src, dst);\n}", "CodeBleu_score": 38.083502761989244}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tif (isRoot(src)) {\nreturn false;\n}\nif (src.equals(dst)) {\nreturn true;\n}\nPath dstPath = lookupEntry(dst);\nif (dstPath!= null) {\ndstPath = dstPath.resolve(src.getFileName());\n}\nString srcPath = qualify(src);\nString dstPath = qualify(dstPath);\nif (srcPath.equals(dstPath)) {\nreturn true;\n}\nreturn store.rename(srcPath, dstPath);\n}", "CodeBleu_score": 39.18536550889792}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\treturn rename(src, dst, true);\n}", "CodeBleu_score": 6.664612665431868}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t\treturn capability.toLowerCase().equals(HSYNC) || capability.toLowerCase().equals(HFLUSH);\n}", "CodeBleu_score": 32.626726662481104}, {"code": "public boolean hasCapability(String capability){\n\t\tString cap = capability.toLowerCase();\n\tif (cap.equals(\"hsync\") || cap.equals(\"hflush\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 27.573893642883068}, {"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 20.756031968442706}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tif (offset < 0) {\n\t\tthrow new IllegalArgumentException(\"offset must be non-negative\");\n\t}\n\tif (offset > lastFlushOffset) {\n\t\tthrow new IllegalArgumentException(\"offset must be less than or equal to lastFlushOffset\");\n\t}\n\tif (offset > lastWrittenOffset) {\n\t\tthrow new IllegalArgumentException(\"offset must be less than or equal to lastWrittenOffset\");\n\t}\n\tif (offset == lastFlushOffset) {\n\t\treturn;\n\t}\n\tif (lastFlushOffset == lastWrittenOffset) {\n\t\treturn;\n\t}\n\tfinal long newFlushOffset = Math.min(lastWrittenOffset, offset);\n\tfinal long bytesToFlush = newFlushOffset - lastFlushOffset;\n\tif (bytesToFlush == 0) {\n\t\treturn;\n\t}\n\tfinal byte[] buffer = new byte[(int) bytesToFlush];\n\tfinal long start = lastFlushOffset;\n\tfinal long end = start + bytesToFlush;\n\tread(start, buffer, 0, (int) bytesToFlush);\n\ttry {\n\t\twriteMetadata(buffer, 0, (int) bytesToFlush);\n\t} catch (final IOException e) {\n\t\tthrow new IOException(\"Unable to write metadata to service\", e);\n\t}\n\tlastFlushOffset = newFlushOffset;\n}", "CodeBleu_score": 28.354320064965634}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tif (offset < 0) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be negative\");\n\t}\n\tif (offset > lastFlushOffset) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be greater than lastFlushOffset\");\n\t}\n\tif (offset == lastFlushOffset) {\n\t\treturn;\n\t}\n\tif (offset < lastFlushOffset) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be less than lastFlushOffset\");\n\t}\n\tif (offset == 0) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be zero\");\n\t}\n\tif (offset == lastFlushOffset + 1) {\n\t\treturn;\n\t}\n\tif (offset > lastFlushOffset + 1) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be greater than lastFlushOffset + 1\");\n\t}\n\tif (offset == lastFlushOffset + 2) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be lastFlushOffset + 2\");\n\t}\n\tif (offset < lastFlushOffset + 2) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be less than lastFlushOffset + 2\");\n\t}\n\tif (offset == lastFlushOffset + 3) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be lastFlushOffset + 3\");\n\t}\n\tif (offset > lastFlushOffset + 3) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be greater than lastFlushOffset + 3\");\n\t}\n\tif (offset == lastFlushOffset + 4) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be lastFlushOffset + 4\");\n\t}\n\tif (offset < lastFlushOffset + 4) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be less than lastFlushOffset + 4\");\n\t}\n\tif (offset == lastFlushOffset + 5) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be lastFlushOffset + 5\");\n\t}\n\tif (offset > lastFlushOffset + 5) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be greater than lastFlushOffset + 5\");\n\t}\n\tif (offset == lastFlushOffset + 6) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be lastFlushOffset + 6\");\n\t}\n\tif (offset < lastFlushOffset + 6) {\n\t\tthrow new IllegalArgumentException(\"offset cannot be less than lastFlushOffset", "CodeBleu_score": 25.102489112018766}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tif (offset < 0) {\n\t\tthrow new IllegalArgumentException(\"offset must be >= 0\");\n\t}\n\tif (offset > lastFlushOffset) {\n\t\tthrow new IllegalArgumentException(\"offset must be <= lastFlushOffset\");\n\t}\n\tif (offset == lastFlushOffset) {\n\t\treturn;\n\t}\n\tif (offset == 0) {\n\t\tlastFlushOffset = 0;\n\t\treturn;\n\t}\n\tfinal long newLastFlushOffset = offset;\n\tfinal long offsetToWrite = newLastFlushOffset - lastFlushOffset;\n\tif (offsetToWrite == 0) {\n\t\treturn;\n\t}\n\tif (offsetToWrite > 0) {\n\t\tif (offsetToWrite > Integer.MAX_VALUE) {\n\t\t\tthrow new IllegalArgumentException(\"offsetToWrite must be <= Integer.MAX_VALUE\");\n\t\t}\n\t\tfinal int offsetToWriteInt = (int) offsetToWrite;\n\t\tfinal byte[] buffer = new byte[offsetToWriteInt];\n\t\tread(buffer, 0, offsetToWriteInt);\n\t\tif (offsetToWriteInt!= buffer.length) {\n\t\t\tthrow new IOException(\"read returned \" + buffer.length + \" bytes, but offsetToWrite was \" + offsetToWriteInt);\n\t\t}\n\t\ttry {\n\t\t\tfilerClient.write(offsetToWriteInt, buffer, 0, offsetToWriteInt);\n\t\t} catch (final Exception e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t\tlastFlushOffset = newLastFlushOffset;\n\t}\n}", "CodeBleu_score": 33.15745381369393}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\tbufferToWrite\n.\nlimit\n(\n0\n)\n;\nbufferToWrite\n.\nposition\n(\n(\nint\n)\nwritePosition\n)\n;\nbufferToWrite\n.\nflip\n(\n)\n;\nfinal int byteLength\n=\nbufferToWrite\n.\nremaining\n(\n)\n;\nif\n(\nbyteLength\n>\n0\n)\n{\nif\n(\nwriteTaskQueue\n.\nsize\n(\n)\n>\nMAX_WRITE_TASKS\n)\n{\nwaitForTaskToComplete\n(\n)\n;\n}\nfinal WriteTask writeTask\n=\nnew\nWriteTask\n(\nbufferToWrite\nwritePosition\n)\n;\nwriteTaskQueue\n.\nadd\n(\nwriteTask\n)\n;\nwriteTask\n.\nsubmit\n(\n)\n;\n}\nreturn\nbyteLength\n;\n}", "CodeBleu_score": 23.730015273500545}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\tfinal int byteLength\n=\nbufferToWrite\n.\nlimit\n(\n)\n-\nbufferToWrite\n.\nposition\n(\n)\n;\nif\n(\nbyteLength\n>\n0\n)  {\nif\n(\ntaskQueue\n.\nsize\n(\n)\n>\nmaxTaskQueueSize\n)  {\nwaitForTaskToComplete\n(\n)\n;\n}\ntaskQueue\n.\nadd\n(\nnew\nWriteTask\n(\nbufferToWrite\nwritePosition\nbyteLength\n)\n)\n;\n}\nreturn\nbyteLength\n;\n}", "CodeBleu_score": 19.624366486204092}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\tif (bufferToWrite == null) {", "CodeBleu_score": 5.553905833449972}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\ttry {\n\t\t\tCompletionService<Task> completionService = getCompletionService();\n\t\t\tif (completionService == null) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tTask task = completionService.poll(5, TimeUnit.SECONDS);\n\t\t\tif (task == null) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (task.getException()!= null) {\n\t\t\t\tthrow task.getException();\n\t\t\t}\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 30.317223846572794}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\ttry {\n\t\t\tCompletionService.poll();\n\t\t\tbreak;\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 18.05081732701888}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\tCompletionService.poll();\n\t\tif (completionService.take() == null) {\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 11.150160086046643}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\tif (writeOperationQueue.isEmpty())\n\t\treturn;\n\n\tlong totalAppendOffset = 0;\n\tfor (int i = 0; i < writeOperationQueue.size(); i++) {\n\t\tWriteOperation operation = writeOperationQueue.get(i);\n\t\tif (operation.isDone()) {\n\t\t\ttotalAppendOffset += operation.getLength();\n\t\t\twriteOperationQueue.remove(i);\n\t\t\ti--;\n\t\t}\n\t}\n\tappendOffset = totalAppendOffset;\n}", "CodeBleu_score": 26.670210551204086}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\tint i = 0;\n\tint j = 0;\n\twhile (i < writeOperationQueue.size()) {\n\t\ttry {\n\t\t\tif (writeOperationQueue.get(i).isDone()) {\n\t\t\t\twriteOperationQueue.remove(i);\n\t\t\t\ti--;\n\t\t\t\tj += writeOperationQueue.get(i).getLength();\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t\ti++;\n\t}\n\ttotalAppendOffset += j;\n}", "CodeBleu_score": 38.79004463878084}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\tint totalOffset = 0;\n\tfor (int i = 0; i < writeOperationQueue.size(); i++) {\n\t\tif (writeOperationQueue.get(i).isDone()) {\n\t\t\ttotalOffset += writeOperationQueue.get(i).getOffset();\n\t\t\twriteOperationQueue.remove(i);\n\t\t\ti--;\n\t\t} else {\n\t\t\tthrow new IOException(\"Write operation failed: \" + writeOperationQueue.get(i).getException());\n\t\t}\n\t}\n\tthis.appendOffset = totalOffset;\n}", "CodeBleu_score": 28.847944767396367}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t\tthis.user = user;\n\tthis.homePath = user.getHomeDirectory();\n}", "CodeBleu_score": 18.96945997094878}, {"code": "protected HdfsFileSystemView(User user){\n\t}", "CodeBleu_score": 2.4752430149638065}, {"code": "protected HdfsFileSystemView(User user){\n\t}", "CodeBleu_score": 2.4752430149638065}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir == null || dir.isEmpty())\n\t\treturn false;\n\n\tif (dir.startsWith(File.separator)) {\n\t\tPath newPath = Paths.get(dir);\n\t\tif (Files.isDirectory(newPath)) {\n\t\t\tthis.currentPath = newPath;\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\n\tPath newPath = Paths.get(this.currentPath.toString(), dir);\n\tif (Files.isDirectory(newPath)) {\n\t\tthis.currentPath = newPath;\n\t\treturn true;\n\t}\n\treturn false;\n}", "CodeBleu_score": 25.335049254768094}, {"code": "public boolean changeWorkingDirectory(String dir){\n\tif (dir == null)", "CodeBleu_score": 0.9403784454884353}, {"code": "public boolean changeWorkingDirectory(String dir){\n\tPath newPath = null;\nif (dir.startsWith(\"/\")) {\nnewPath = Paths.get(dir);\n} else {\nnewPath = Paths.get(currentPath.toString() + \"/\" + dir);\n}\nif (newPath.toFile().isDirectory()) {\ncurrentPath = newPath;\nreturn true;\n}\nreturn false;\n}", "CodeBleu_score": 18.07638051573491}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis(new FilerClient(host, port, grpcPort, conf));\n}", "CodeBleu_score": 13.521061229460141}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis(new FilerClient(host, port, grpcPort, conf));\n}", "CodeBleu_score": 13.521061229460141}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis(host, port, grpcPort, conf, null);\n}", "CodeBleu_score": 13.304538402045774}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\treturn new SeaweedHadoopInputStream(path, filerClient, statistics, path.toString());\n}", "CodeBleu_score": 23.27693846699584}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\tfinal Path lookupPath = path.getFileSystem().getUri().resolve(path.toString());\nfinal FileEntry fileEntry = lookupEntry(lookupPath);\nif (fileEntry == null) {\nthrow new FileNotFoundException(\"File not found: \" + path);\n}\nreturn new SeaweedHadoopInputStream(fileEntry, filerClient, statistics, path);\n}", "CodeBleu_score": 60.53470649120401}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\tfinal String pathString = path.toString();", "CodeBleu_score": 25.35307123057258}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\tlocalHostName = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tlocalHostName = \"localhost\";\n\t}\n\tnumThreadsPerMap = conf.getInt(\"mapred.threads.per.map\", 1);\n\tnumFilesPerThread = conf.getInt(\"mapred.files.per.thread\", 1);\n\tthreadPool = Executors.newFixedThreadPool(numThreadsPerMap, new ThreadFactory() {\n\t\tpublic Thread newThread(Runnable r) {\n\t\t\tThread t = new Thread(r);\n\t\t\tt.setDaemon(true);\n\t\t\treturn t;\n\t\t}\n\t});\n}", "CodeBleu_score": 59.61717951375876}, {"code": "public void configure(JobConf conf){\n\tthis.conf = conf;\ntry {\nlocalHostName = InetAddress.getLocalHost().getHostName();\n} catch (UnknownHostException e) {\nlocalHostName = \"localhost\";\n}\nnumThreadsPerMap = conf.getInt(NUM_THREADS_PER_MAP, 1);\nfilesPerThread = conf.getInt(FILES_PER_THREAD, 1);\nthreadPool = Executors.newFixedThreadPool(numThreadsPerMap, new ThreadFactory() {\npublic Thread newThread(Runnable r) {\nThread t = new Thread(r);\nt.setDaemon(true);\nreturn t;\n}\n});\n}", "CodeBleu_score": 57.103383325301074}, {"code": "public void configure(JobConf conf){\n\tthis.conf = conf;\ntry {\nhostName = InetAddress.getLocalHost().getHostName();\n} catch (UnknownHostException e) {\nhostName = \"localhost\";\n}\nnumThreadsPerMap = conf.getInt(\"numThreadsPerMap\", 1);\nnumFilesPerThread = conf.getInt(\"numFilesPerThread\", 1);\nthreadPool = Executors.newFixedThreadPool(numThreadsPerMap, new ThreadFactory() {\npublic Thread newThread(Runnable r) {\nThread t = new Thread(r);\nt.setDaemon(true);\nreturn t;\n}\n});\n}", "CodeBleu_score": 64.80562449057832}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tif (isTrashEmptierRunning(uri)) {\nreturn;\n}\nFileSystem fs = getFileSystem(uri, conf);\nif (fs == null) {\nthrow new IOException(\"Failed to initialize FileSystem for URI: \" + uri);\n}\nfs.initializeTrashEmptier(conf);\nfs.startTrashEmptier();\n}", "CodeBleu_score": 16.926895931305598}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tif (isRunning(uri)) {\nreturn;\n}\n\ntry {\nFileSystem fs = FileSystem.get(uri, conf);\n} catch (IOException e) {\nthrow new IOException(\"Unable to create FileSystem for URI \" + uri + \": \" + e.getMessage());\n}\n\n// Create a new thread for the trash emptier task\nThread t = new Thread() {\n@Override\npublic void run() {\ntry {\n// Create the trash emptier task\nTrashEmptier task = new TrashEmptier(fs, conf);\n\n// Schedule the trash emptier task to run every 10 minutes\nlong delay = 10 * 60 * 1000;\nlong period = 10 * 60 * 1000;\n\n// Start the trash emptier task\ntask.start();\n\n// Wait for the trash emptier task to finish\ntask.join();\n} catch (Exception e) {\nLOG.error(\"Error while running the trash emptier task\", e);\n}\n}\n};\n\n// Start the trash emptier task in a new thread\nt.start();\n\n}", "CodeBleu_score": 41.9624029003644}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tif (isRunning(uri)) {\nreturn;\n}\nfinal User superuser = createRemoteUser(uri);\nfinal FileSystem fs = FileSystem.get(uri, conf, superuser);\nfinal TrashEmptier trashEmptier = new TrashEmptier(fs, conf);\ntrashEmptier.run();\n}", "CodeBleu_score": 19.299375779512335}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t\tif (context == null) {\n\t\tthrow new IllegalArgumentException(\"context cannot be null\");\n\t}\n\tif (context.isEmpty()) {\n\t\tthrow new IllegalArgumentException(\"context cannot be empty\");\n\t}\n\tif (context.contains(Context.SEPARATOR)) {\n\t\tthrow new IllegalArgumentException(\"context cannot contain the separator character\");\n\t}\n\tif (context.contains(Context.SIGNATURE_SEPARATOR)) {\n\t\tthrow new IllegalArgumentException(\"context cannot contain the signature separator character\");\n\t}\n\tif (context.contains(Context.CALLER_SEPARATOR)) {\n\t\tthrow new IllegalArgumentException(\"context cannot contain the caller separator character\");\n\t}\n\tif (context.contains(Context.CALLER_NAME_SEPARATOR)) {\n\t\tthrow new IllegalArgumentException(\"context cannot contain the caller name separator character\");\n\t}\n\tif (context.contains(Context.CALLER_TYPE_SEPARATOR)) {\n\t\tthrow new IllegalArgumentException(\"context cannot contain the caller type separator character\");\n\t}\n\tif (context.contains(Context.CALLER_VERSION_SEPARATOR)) {\n\t\tthrow new IllegalArgumentException(\"context cannot contain the caller version separator character\");\n\t}\n\tif (context.contains(Context.CALLER_METHOD_SEPARATOR)) {\n\t\tthrow new IllegalArgumentException(\"context cannot contain the caller method separator character\");\n\t}\n\tif (context.contains(Context.CALLER_LINE_SEPARATOR)) {\n\t\tthrow new IllegalArgumentException(\"context cannot contain the caller line separator character\");\n\t}\n\tif (context.contains(Context.CALLER_FILE_SEPARATOR)) {\n\t\tthrow new IllegalArgumentException(\"context cannot contain the caller file separator character\");\n\t}\n\tif (context.contains(Context.CALLER_CLASS_SEPARATOR)) {\n\t\tthrow new IllegalArgumentException(\"context cannot contain the caller class separator character\");\n\t}\n\tif (context.contains(Context.CALLER_PACKAGE_SEPARATOR)) {\n\t\tthrow new IllegalArgumentException(\"context cannot contain the caller package separator character\");\n\t}\n\tif (context.contains(Context.CALLER_SOURCE_SEPARATOR)) {\n\t\tthrow new IllegalArgumentException(\"context cannot contain the caller source separator character\");\n\t}\n\tif (context.contains(Context.CALLER_MODULE_SEPARATOR)) {\n\t\tthrow new IllegalArgumentException(\"context cannot contain the caller module separator character\");\n\t}\n\tif (context.contains(Context.CALLER_", "CodeBleu_score": 19.897649768593332}, {"code": "public static void setContext(String context) throws Exception{\n\t\t//TODO: Implement this function\n}", "CodeBleu_score": 3.1494709380915578}, {"code": "public static void setContext(String context) throws Exception{\n\t\t// Create a new context and set it as the caller context.\n\tif (context == null || context.isEmpty()) {\n\t\treturn;\n\t}\n\tString currentContext = getCurrent();\n\tif (currentContext == null || currentContext.isEmpty()) {\n\t\tsetCurrent(context);\n\t\treturn;\n\t}\n\tif (!isContextValid(currentContext)) {\n\t\tsetCurrent(context);\n\t\treturn;\n\t}\n\tif (!currentContext.contains(context)) {\n\t\tsetCurrent(currentContext + context);\n\t}\n}", "CodeBleu_score": 27.368886331258945}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t\tif (libhdfs_ == nullptr) {\n\t\tLOG_ERROR << \"HDFS library not initialized\";\n\t\treturn Status_HDFSLibraryNotInitialized;\n\t}\n\tif (uri.is_hdfs()) {\n\t\thdfsFS fs = hdfsConnect(uri.to_path().c_str, 0);\n\t\tif (fs == nullptr) {\n\t\t\tLOG_ERROR << \"HDFS connection failed\";\n\t\t\treturn Status_HDFSConnectionFailed;\n\t\t}\n\t\tif (hdfsDelete(fs, uri.to_path().c_str)!= 0) {\n\t\t\tLOG_ERROR << \"HDFS file deletion failed\";\n\t\t\thdfsDisconnect(fs);\n\t\t\treturn Status_HDFSFileDeletionFailed;\n\t\t}\n\t\thdfsDisconnect(fs);\n\t\treturn Status::Ok;\n\t} else {\n\t\tLOG_ERROR << \"HDFS URI is not HDFS\";\n\t\treturn Status_HDFSNotHDFS;\n\t}\n}", "CodeBleu_score": 44.7957231531367}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t\tif (!libhdfs_) {\n\t\treturn Status_HDFSNotInitialized;\n\t}\n\tif (!hdfsExists(libhdfs_, uri.to_string().c_str)) {\n\t\treturn Status_HDFSFileNotFound;\n\t}\n\tif (hdfsDelete(libhdfs_, uri.to_string().c_str, 0)!= 0) {\n\t\tLOG_ERROR << \"Failed to delete file \" << uri.to_string();\n\t\treturn Status_HDFSFailedToDelete;\n\t}\n\treturn Status::Ok;\n}", "CodeBleu_score": 39.082077933101296}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t\tif (hdfs_ == NULL) {\n\t\thdfs_ = hdfsConnect(uri.to_host().c_str, uri.to_port());\n\t}\n\tif (hdfs_ == NULL) {\n\t\treturn Status::HdfsError(\"Failed to connect to HDFS\");\n\t}\n\tint ret = hdfsDelete(hdfs_, uri.to_path().c_str, 0);\n\tif (ret!= 0) {\n\t\treturn Status::HdfsError(\"Failed to delete file\");\n\t}\n\treturn Status::Ok;\n}", "CodeBleu_score": 50.22002154204063}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS libhdfs_ = connect(uri);\n\tif (libhdfs_ == NULL) {\n\t\treturn Status_HDFSError;\n\t}\n\thdfsFile file = libhdfs_->hdfsOpenFile(libhdfs_, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n\tif (file == NULL) {\n\t\tLOG_ERROR << \"Failed to open file \" << uri.to_path().c_str() << \" in write and append mode.\";\n\t\treturn Status_HDFSError;\n\t}\n\tif (libhdfs_->hdfsHFlush(file)!= 0) {\n\t\tLOG_ERROR << \"Failed to flush file \" << uri.to_path().c_str();\n\t\treturn Status_HDFSError;\n\t}\n\tif (libhdfs_->hdfsCloseFile(file)!= 0) {\n\t\tLOG_ERROR << \"Failed to close file \" << uri.to_path().c_str();\n\t\treturn Status_HDFSError;\n\t}\n\treturn Status::Ok;\n}", "CodeBleu_score": 38.36563950944905}, {"code": "Status HDFS::sync(const URI& uri){\n\t\tif (!hdfsExists(libhdfs_->hdfsConnect(uri.to_path().c_str), uri.to_path().c_str)) {\n\t\tLOG_STATUS(Status::Ok)\n\t}\n\thdfsFS fs = libhdfs_->hdfsConnect(uri.to_path().c_str);\n\thdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str, O_WRONLY | O_APPEND, 0, 0, 0);\n\tif (!file) {\n\t\tLOG_STATUS(Status_HDFSError)\n\t}\n\tlibhdfs_->hdfsHFlush(file);\n\tlibhdfs_->hdfsCloseFile(fs, file);\n\tLOG_STATUS(Status::Ok)\n}", "CodeBleu_score": 33.89743919689073}, {"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS fs = connect(uri);\n\tif (fs == NULL) {\n\t\tLOG_ERROR(\"Failed to connect to HDFS file system\");\n\t\treturn Status_HDFSError;\n\t}\n\thdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n\tif (file == NULL) {\n\t\tLOG_ERROR(\"Failed to open file %s\", uri.to_path().c_str());\n\t\thdfsDisconnect(fs);\n\t\treturn Status_HDFSError;\n\t}\n\tif (libhdfs_->hdfsHFlush(file) < 0) {\n\t\tLOG_ERROR(\"Failed to flush file %s\", uri.to_path().c_str());\n\t\thdfsCloseFile(fs, file);\n\t\thdfsDisconnect(fs);\n\t\treturn Status_HDFSError;\n\t}\n\thdfsCloseFile(fs, file);\n\thdfsDisconnect(fs);\n\treturn Status::Ok;\n}", "CodeBleu_score": 43.869533843182175}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t\thdfsFS fs = connect(uri);\n\tif (!fs) {\n\t\tLOG_STATUS(Status_HDFSError, \"HDFS connection failed\");\n\t\treturn Status::HDFS_CONNECTION_FAILED;\n\t}\n\n\thdfsFileInfo* info = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\n\tif (!info) {\n\t\tLOG_STATUS(Status_HDFSError, \"HDFS file information retrieval failed\");\n\t\treturn Status::HDFS_FILE_INFO_FAILED;\n\t}\n\n\tif (!info->mSize) {\n\t\tLOG_STATUS(Status_HDFSError, \"HDFS file information not available\");\n\t\treturn Status::HDFS_FILE_INFO_NOT_AVAILABLE;\n\t}\n\n\t*nbytes = static_cast<uint64_t>(info->mSize);\n\thdfsFreeFileInfo(info, 1);\n\n\treturn Status::Ok;\n}", "CodeBleu_score": 45.699564946506264}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t\thdfsFS libhdfs_ = connect(uri);\n\tif (libhdfs_ == nullptr) {\n\t\tLOG_STATUS(Status_HDFSError, \"Cannot connect to HDFS\");\n\t\treturn Status::Fail;\n\t}\n\n\thdfsFileInfo* file_info = hdfsGetPathInfo(libhdfs_, uri.to_path().c_str);\n\tif (file_info == nullptr) {\n\t\tLOG_STATUS(Status_HDFSError, \"Cannot get file information\");\n\t\thdfsFreeFileInfo(file_info, 0);\n\t\treturn Status::Fail;\n\t}\n\n\t*nbytes = static_cast<uint64_t>(file_info->mSize);\n\thdfsFreeFileInfo(file_info, 0);\n\treturn Status::Ok;\n}", "CodeBleu_score": 45.90637437177267}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t\thdfsFS fs = connect(uri);\n\tif (fs == nullptr) {\n\t\tLOG(ERROR) << \"Failed to connect to HDFS file system.\";\n\t\treturn Status::HDFS_ConnectError;\n\t}\n\thdfsFileInfo* info = hdfsGetPathInfo(fs, uri.to_path().c_str(), 0);\n\tif (info == nullptr) {\n\t\tLOG(ERROR) << \"Failed to get file information for \" << uri.to_path() << \".\";\n\t\thdfsFreeFileInfo(info, 1);\n\t\treturn Status::HDFS_GetFileInfoError;\n\t}\n\tif (info->mKind!= kObjectKindFile) {\n\t\tLOG(ERROR) << \"The path is not a file.\";\n\t\thdfsFreeFileInfo(info, 1);\n\t\treturn Status::HDFS_NotFile;\n\t}\n\t*nbytes = info->mSize;\n\thdfsFreeFileInfo(info, 1);\n\treturn Status::Ok;\n}", "CodeBleu_score": 45.74048408810968}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\tString quorum = \"\";\nString znodeParent = \"\";\nif (hbaseCfgString!= null) {\nString[] hbaseCfg = hbaseCfgString.split(\",\");\nfor (String hbaseCfgItem : hbaseCfg) {\nif (hbaseCfgItem.startsWith(\"zookeeper.znode.parent=\")) {\nznodeParent = hbaseCfgItem.substring(\"zookeeper.znode.parent=\".length());\n} else if (hbaseCfgItem.startsWith(\"zookeeper.quorum=\")) {\nString[] quorumParts = hbaseCfgItem.substring(\"zookeeper.quorum=\".length()).split(\":\");\nif (quorumParts.length == 1) {\nquorum = quorumParts[0] + \":2181\";\n} else {\nquorum = hbaseCfgItem.substring(\"zookeeper.quorum=\".length());\n}\n}\n}\n}\nreturn new Pair<String, String>(quorum, znodeParent);\n}", "CodeBleu_score": 30.282284895337735}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\tString quorum = \"\";\nString znodeParent = \"\";\nString[] cfgArray = hbaseCfgString.split(\",\");\nfor (String cfg : cfgArray) {\nif (cfg.contains(\"zookeeper.znode.parent\")) {\nznodeParent = cfg.split(\"=\")[1];\n} else if (cfg.contains(\"zookeeper.quorum\")) {\nquorum = cfg.split(\"=\")[1];\n}\n}\nif (quorum.isEmpty()) {\nthrow new IllegalArgumentException(\"HBase configuration does not contain a Zookeeper quorum\");\n}\nif (znodeParent.isEmpty()) {\nznodeParent = \"/hbase\";\n}\nreturn Pair.of(quorum, znodeParent);\n}", "CodeBleu_score": 22.787013365724597}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\tif (hbaseCfgString == null) {", "CodeBleu_score": 4.8092838282787955}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\ttry {\n\t\tif (cfg.isThinClient()) {\n\t\t\tcfg.setJdbcConnection(HbaseSQLWriterUtil.getJdbcConnection(cfg.getHbaseMaster(), cfg.getHbaseZookeeper(), cfg.getHbaseNamespace(), cfg.getHbaseTable(), cfg.getHbaseUsername(), cfg.getHbasePassword()));\n\t\t} else {\n\t\t\tcfg.setJdbcConnection(HbaseSQLWriterUtil.getJdbcConnection(cfg.getHbaseMaster(), cfg.getHbaseZookeeper(), cfg.getHbaseNamespace(), cfg.getHbaseTable(), cfg.getHbaseUsername(), cfg.getHbasePassword(), cfg.getHbaseThriftPort()));\n\t\t}\n\t\tHbaseSQLWriterUtil.checkTable(cfg.getJdbcConnection(), cfg.getHbaseTable(), cfg.getHbaseNamespace());\n\t\tHbaseSQLWriterUtil.getTableSchema(cfg.getJdbcConnection(), cfg.getHbaseTable(), cfg.getHbaseNamespace());\n\t\tHbaseSQLWriterUtil.checkColumns(cfg.getJdbcConnection(), cfg.getHbaseTable(), cfg.getHbaseNamespace(), cfg.getColumns());\n\t} catch (Exception e) {\n\t\tthrow new AddaxException(e);\n\t}\n}", "CodeBleu_score": 18.36634231814622}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\ttry {\nHbaseSQLWriterUtil.checkTable(cfg);\n} catch (Exception e) {\nthrow new AddaxException(\"Failed to validate HbaseSQLWriter configuration. Error message: \" + e.getMessage(), e);\n}\n}", "CodeBleu_score": 13.605227593241759}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\ttry {\n\t\t// establish a JDBC connection\n\t\tConnection conn = getJdbcConnection(cfg);\n\t\t// check the existence of the specified table in the given namespace\n\t\tcheckTable(conn, cfg.getDatabase(), cfg.getTable());\n\t\t// retrieve the table schema\n\t\tResultSet rs = getTableSchema(conn, cfg.getDatabase(), cfg.getTable());\n\t\t// ensure that all configured columns exist in the target table\n\t\twhile (rs.next()) {\n\t\t\tString columnName = rs.getString(\"COLUMN_NAME\");\n\t\t\tif (!cfg.getColumns().contains(columnName)) {\n\t\t\t\tthrow new AddaxException(\"Column \" + columnName + \" does not exist in the target table.\");\n\t\t\t}\n\t\t}\n\t\t// close the JDBC connection\n\t\tconn.close();\n\t} catch (SQLException e) {\n\t\tthrow new AddaxException(\"Error while validating the configuration for HbaseSQLWriter.\", e);\n\t}\n}", "CodeBleu_score": 27.024166160130868}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\ttry {\nif (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\nSystem\n.\nout\n.\nprintln\n(\n\"Attempting to login using Kerberos principal and keytab file path: \"\n+\nkerberosPrincipal\n+\n\" and \"\n+\nkerberosKeytabFilePath\n)\n;\nUserGroupInformation\n.\nloginUserFromKeytab\n(\nkerberosPrincipal\n,\nnew\nFile\n(\nkerberosKeytabFilePath\n)\n,\nnew\nString\n[\n]\n{\nkerberosPrincipal\n}\n)\n;\n}\n}\ncatch\n(\nIOException\ne\n)\n{\nthrow\nnew\nAddaxException\n(\n\"Unable to login using Kerberos principal and keytab file path: \"\n+\nkerberosPrincipal\n+\n\" and \"\n+\nkerberosKeytabFilePath\n,\ne\n)\n;\n}\n}", "CodeBleu_score": 27.807222369235475}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\tif (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\nConfiguration configuration = new Configuration();\nconfiguration.set(\"hadoop.security.authentication\", \"kerberos\");\nUserGroupInformation.setConfiguration(configuration);\ntry {\nUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n} catch (IOException e) {\nthrow new AddaxException(String.format(\"Failed to login user %s from keytab file %s\", kerberosPrincipal, kerberosKeytabFilePath), e);\n}\n}\n}", "CodeBleu_score": 42.39222017395849}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\ttry {\nif (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\nSystem\n.\nout\n.\nprintln\n(\n\"Kerberos authentication is enabled. Attempting to login with principal: \"\n+\nkerberosPrincipal\n+\n\" and keytab file: \"\n+\nkerberosKeytabFilePath\n)\n;\nConfiguration\nconfiguration\n=\nnew\nConfiguration\n(\n)\n;\nconfiguration\n.\nset\n(\n\"\nhadoop\n.\nsecurity\n.\nauthentication\n\"\n,\n\"\nkerberos\n\"\n)\n;\nUserGroupInformation\n.\nsetConfiguration\n(\nconfiguration\n)\n;\nUserGroupInformation\n.\nloginUserFromKeytab\n(\nkerberosPrincipal\n,\nkerberosKeytabFilePath\n)\n;\n}\n}\ncatch\n(\nIOException\ne\n)\n{\nthrow\nnew\nAddaxException\n(\n\"\nFailed\nto\nlogin\nwith\nprincipal\n:\n\"\n+\nkerberosPrincipal\n+\n\"\nand\nkeytab\nfile\n:\n\"\n+\nkerberosKeytabFilePath\n,\ne\n)\n;\n}\n}", "CodeBleu_score": 36.322960892165234}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> map = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\nResultSetMetaData meta = rs.getMetaData();\nint numCols = meta.getColumnCount();\nfor (int i = 1; i <= numCols; i++) {\nString columnName = meta.getColumnName(i);\nint colType = meta.getColumnType(i);\nThinClientPTable.ThinClientPColumn column = new ThinClientPTable.ThinClientPColumn(columnName, colType);\nmap.put(columnName, column);\n}\nreturn map;\n}", "CodeBleu_score": 30.7727221357723}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> map = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\nResultSetMetaData rsmd = rs.getMetaData();\nint colCount = rsmd.getColumnCount();\nfor (int i = 1; i <= colCount; i++) {\nString columnName = rsmd.getColumnName(i);\nint columnType = rsmd.getColumnType(i);\nmap.put(columnName, new ThinClientPTable.ThinClientPColumn(columnName, columnType));\n}\nreturn map;\n}", "CodeBleu_score": 30.413310250823734}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<>();\nResultSetMetaData rsmd = rs.getMetaData();\nint numCols = rsmd.getColumnCount();\nfor (int i = 1; i <= numCols; i++) {\nString colName = rsmd.getColumnName(i);\nString colType = rsmd.getColumnTypeName(i);\nif (colName == null || colType == null) {\nthrow new SQLException(\"Invalid column name or type\");\n}\nThinClientPTable.ThinClientPColumn col = new ThinClientPTable.ThinClientPColumn(colName, colType);\ncolTypeMap.put(colName, col);\n}\nreturn colTypeMap;\n}", "CodeBleu_score": 39.79125376425498}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\t\ttry {\n\t\tPhoenixConnection phoenixConn = unwrap(conn);\n\t\tAdmin admin = phoenixConn.getAdmin();\n\t\tcheckTable(admin, tableName);\n\t\tadmin.disableTable(tableName);\n\t\tadmin.truncateTable(tableName, false);\n\t\tlogger.debug(\"Table \" + tableName + \" truncated\");\n\t} catch (Exception e) {\n\t\tasAddaxException(e);\n\t} finally {\n\t\tcloseAdmin(admin);\n\t}\n}", "CodeBleu_score": 28.702002640454396}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t\ttry {\n\t\tHBaseAdmin admin = getAdmin(conn);\n\t\tif (checkTable(admin, tableName)) {\n\t\t\tadmin.disableTable(tableName);\n\t\t\tadmin.truncateTable(tableName, false);\n\t\t\tlog.debug(\"Table {} truncated\", tableName);\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow asAddaxException(e);\n\t} finally {\n\t\tcloseAdmin(admin);\n\t}\n}", "CodeBleu_score": 23.067497445466884}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t\tPhoenixConnection phoenixConn = unwrap(conn);\n\tHBaseAdmin admin = null;\n\ttry {\n\t\tadmin = (HBaseAdmin)phoenixConn.unwrap();\n\t\tif (!admin.tableExists(tableName)) {\n\t\t\tthrow new AddaxException(ErrorCode.TABLE_NOT_FOUND, \"The table \" + tableName + \" does not exist.\");\n\t\t}\n\t\tadmin.disableTable(tableName);\n\t\tadmin.truncateTable(tableName, true);\n\t\tlogger.debug(\"Table \" + tableName + \" truncated.\");\n\t} catch (IOException e) {\n\t\tthrow new AddaxException(ErrorCode.TABLE_TRUNCATE_ERROR, \"Error truncating table \" + tableName + \".\", e);\n\t} finally {\n\t\tcloseAdmin(admin);\n\t}\n}", "CodeBleu_score": 41.36561666691261}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\tif\n(fileSystem\n.isFile\n(new Path\n(filePath))) {\nif\n(checkHdfsFileType\n(filePath)) {\ninfo\n(String\n.format\n(\"Adding file %s to source files list.\", filePath))\n;\nsourceFiles\n.add\n(filePath)\n;\n}\nelse\n{\nthrow\nnew\nAddaxException\n(String\n.format\n(\"Unsupported file type for file %s.\", filePath))\n;\n}\n}\nelse\n{\nthrow\nnew\nAddaxException\n(String\n.format\n(\"File %s does not exist.\", filePath))\n;\n}\n}", "CodeBleu_score": 19.0266011079642}, {"code": "private void addSourceFileByType(String filePath){\n\ttry {", "CodeBleu_score": 2.1812566724741114}, {"code": "private void addSourceFileByType(String filePath){\n\tString fileType = getFileType(filePath);\nif (fileType.equalsIgnoreCase(fileType)) {\ninfo\nasAddaxException\nadd\nformat\n}\n}", "CodeBleu_score": 11.164299981943424}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t//        try {", "CodeBleu_score": 4.1920025933337515}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\ttry {\n\t\tFileSystem fileSystem = FileSystem.get(new URI(sourceSequenceFilePath), readerSliceConfig);\n\t\tFSDataInputStream fsDataInputStream = fileSystem.open(new Path(sourceSequenceFilePath));\n\t\tString line;\n\t\twhile ((line = fsDataInputStream.readLine())!= null) {\n\t\t\tif (isNotBlank(line)) {\n\t\t\t\tRecord record = StorageReaderUtil.transportOneRecord(line, readerSliceConfig,\n\t\t\t\t\t\ttaskPluginCollector);\n\t\t\t\trecordSender.sendToWriter(record);\n\t\t\t}\n\t\t}\n\t\tfsDataInputStream.close();\n\t\tLOG.info(\"Sequence file start read from \" + sourceSequenceFilePath);\n\t} catch (Exception e) {\n\t\tthrow new AddaxException(e);\n\t}\n}", "CodeBleu_score": 32.09142790273858}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\ttry {\nLOG.info(\"Start reading sequence file from \" + sourceSequenceFilePath);\nFileSystem fs = FileSystem.get(new URI(sourceSequenceFilePath), readerSliceConfig);\nFSDataInputStream fsDataInputStream = fs.open(new Path(sourceSequenceFilePath));\nSequenceFile.Reader reader = new SequenceFile.Reader(fs, new Path(sourceSequenceFilePath), readerSliceConfig);\nLOG.info(\"Start reading sequence file\");\nwhile (reader.next(key, value)) {\nif (isNotBlank(value.toString())) {\ntry {\nrecordSender.send(StorageReaderUtil.transportOneRecord(key, value.toString(), readerSliceConfig,\ntaskPluginCollector));\n} catch (AddaxException e) {\nLOG.error(\"Fail to transport record, key: {}, value: {}\", key, value, e);\nthrow new AddaxException(e);\n}\n}\n}\nreader.close();\nfsDataInputStream.close();\n} catch (Exception e) {\nLOG.error(\"Fail to read sequence file, path: {}, error: {}\", sourceSequenceFilePath, e);\nthrow new AddaxException(e);\n}\n}", "CodeBleu_score": 44.14289333168914}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\ttry", "CodeBleu_score": 2.4327015440829207}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\tString type = null;\ntry {\nFileSystem fs = FileSystem.get(new URI(filepath), new Configuration());\nif (isORCFile(fs, filepath)) {\ntype = \"ORC\";\n} else if (isRCFile(fs, filepath)) {\ntype = \"RC\";\n} else if (isSequenceFile(fs, filepath)) {\ntype = \"Sequence\";\n} else if (isParquetFile(fs, filepath)) {\ntype = \"Parquet\";\n} else if (isCSVFile(fs, filepath)) {\ntype = \"CSV\";\n} else if (isTextFile(fs, filepath)) {\ntype = \"Text\";\n}\n} catch (Exception e) {\nlogger.error(\"Error in checking HDFS file type: \" + e.getMessage());\nthrow new AddaxException(e.getMessage(), e);\n}\nreturn specifiedFileType.equalsIgnoreCase(type);\n}", "CodeBleu_score": 26.689534316157683}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\ttry {", "CodeBleu_score": 2.435285040767652}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection!= null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new asAddaxException(asAddaxException.ERROR_CODE_HBASE_CONNECTION_CLOSE, e);\n\t}\n}", "CodeBleu_score": 51.476961705909765}, {"code": "public static void closeConnection(Connection hConnection){\n\ttry {\nif (hConnection!= null) {\nhConnection.close();\n}\n} catch (IOException e) {\nthrow new asAddaxException(asAddaxException.ERROR_CODE_IOEXCEPTION, e.getMessage());\n}\n}", "CodeBleu_score": 44.060989626270405}, {"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection!= null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new CloseConnectionException(e.getMessage());\n\t}\n}", "CodeBleu_score": 39.798850055145316}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(asAddaxException.asAddaxErrorCode.asAddaxErrorCode_IO_Exception, e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 40.86154542845546}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(e, asAddaxException.ERR_CLOSE_ADMIN, e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 40.09125372378743}, {"code": "public static void closeAdmin(Admin admin){\n\tcloseAdmin(admin, null)\n}", "CodeBleu_score": 10.66503115985617}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t// TODO: Implement the convertCellToLine function\n}", "CodeBleu_score": 2.1029777907619387}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t// Get the row key\nString rowKey = cell.getRow().toString();\n// Get the timestamp\nlong timestamp = cell.getTimestamp();\n// Get the column family\nString family = cell.getFamily().toString();\n// Get the qualifier\nString qualifier = cell.getQualifier().toString();\n// Get the value\nbyte[] value = cell.getValue();\n// Convert the row key to the appropriate type\nif (rowKeyTypes.containsKey(family)) {\nrowKey = convertBytesToAssignType(rowKeyTypes.get(family), rowKey);\n}\n// Convert the column value to the appropriate type\nif (columnValueTypes.containsKey(family)) {\nvalue = convertBytesToAssignType(columnValueTypes.get(family), value);\n}\n// Add the row key, family, qualifier, timestamp, and value to the record\nrecord.addColumn(rowKey, family, qualifier, timestamp, value);\n}", "CodeBleu_score": 22.681334624664263}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\nString rowKey = cell.getRow().toString();\nString family = cell.getFamily().toString();\nString qualifier = cell.getQualifier().toString();\nlong timestamp = cell.getTimestamp();\nString value = cell.getValue().toString();\n\nrecord.addColumn(family, qualifier, timestamp, value);\n}", "CodeBleu_score": 9.894734723850412}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString userStartRowkey = configuration.get(START_ROW_KEY, \"\");\n\tif (isBlank(userStartRowkey)) {\n\t\treturn new byte[0];\n\t}\n\treturn stringToBytes(userStartRowkey);\n}", "CodeBleu_score": 22.47602388403303}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowKey = configuration.get(START_ROW_KEY_KEY, \"\");\n\tif (isBlank(startRowKey)) {\n\t\treturn new byte[0];\n\t}\n\treturn stringToBytes(startRowKey);\n}", "CodeBleu_score": 22.14062043646331}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(START_ROWKEY);\n\tif (isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t} else {\n\t\tif (isBinary(startRowkey)) {\n\t\t\treturn stringToBytes(startRowkey);\n\t\t} else {\n\t\t\treturn Bytes.toBytes(startRowkey);\n\t\t}\n\t}\n}", "CodeBleu_score": 30.70674683931619}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\treturn convertInnerStartRowkey(configuration, null);\n}", "CodeBleu_score": 11.874278016764812}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\treturn convertInnerStartRowkey(configuration, null);\n}", "CodeBleu_score": 11.874278016764812}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\tString startRowKey = configuration.get(START_ROW_KEY);\nif (isBlank(startRowKey)) {\nreturn new byte[0];\n}\nreturn toBytesBinary(startRowKey);\n}", "CodeBleu_score": 37.199037083232376}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis\n.key\n(\n\tUUID\n\t.fromString\n\t(\n\t\trecord\n\t\t.key\n\t)\n)\n.headers\n(\n\tnew TbQueueMsgHeaders\n\t(\n\t\trecord\n\t\t.headers\n\t)\n)\n.data\n(\n\trecord\n\t.value\n);\n}", "CodeBleu_score": 13.367428000311026}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tthis\n.setKey\n(\nUUID\n.\nfromString\n(\nrecord\n.\nkey\n(\n)\n)\n)\n;\nthis\n.\nheaders\n=\nnew\nTbQueueMsgHeaders\n(\nrecord\n.\nheaders\n(\n)\n)\n;\nthis\n.\ndata\n=\nrecord\n.\nvalue\n(\n)\n;\n}", "CodeBleu_score": 25.50446237056504}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tkey\n= UUID.fromString\n(\nrecord\n.\nkey\n(\n)\n)\n;\nheaders\n=\nnew\nTbQueueMsgHeaders\n(\nrecord\n.\nheaders\n(\n)\n)\n;\ndata\n=\nrecord\n.\nvalue\n(\n)\n;\n}", "CodeBleu_score": 23.16641784777141}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\treturn createTransportNotificationsMsgProducer(getKafkaSettings(), getClientId(), getNotificationsTopic());\n}", "CodeBleu_score": 11.423188102944609}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\treturn createTransportNotificationsMsgProducer(null);\n}", "CodeBleu_score": 8.317686145875003}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = createTransportNotificationsMsgProducer(getSettings().getKafkaSettings(), getClientId(), getSettings().getTransportNotificationsTopic());\n\tproducer.setAdmin(createKafkaAdmin());\n\treturn producer;\n}", "CodeBleu_score": 29.334574759351995}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\treturn createToCoreNotificationsMsgConsumer(\nTB_KAFKA_CONSUMER_SETTINGS,\nTB_NOTIFICATIONS_TOPIC,\nTB_NOTIFICATIONS_CLIENT_ID,\nTB_NOTIFICATIONS_GROUP_ID);\n}", "CodeBleu_score": 7.67471382709744}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\treturn createToCoreNotificationsMsgConsumer(new TbKafkaConsumerSettings());\n}", "CodeBleu_score": 7.580740483130927}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\treturn createToCoreNotificationsMsgConsumer(\nnew TbKafkaConsumerSettings(\nnew TbKafkaConsumerTopic(\nTB_KAFKA_NOTIFICATIONS_TOPIC_NAME,\nTB_KAFKA_NOTIFICATIONS_TOPIC_NAME),\nTB_KAFKA_NOTIFICATIONS_CLIENT_ID,\nTB_KAFKA_NOTIFICATIONS_GROUP_ID,\nTB_KAFKA_NOTIFICATIONS_DECODER),\nTB_KAFKA_NOTIFICATIONS_ADMIN,\nTB_KAFKA_NOTIFICATIONS_STATS_SERVICE);\n}", "CodeBleu_score": 10.3198505442578}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (!topicNames.isEmpty()) {\n\t\tfor (String topicName : topicNames) {\n\t\t\tif (!topicName.isEmpty()) {\n\t\t\t\tif (topicName.startsWith(TOPIC_PREFIX)) {\n\t\t\t\t\tlog.info(\"Subscribing to topic \" + topicName);\n\t\t\t\t\tconsumer.subscribe(topicName);\n\t\t\t\t} else {\n\t\t\t\t\tlog.info(\"Topic \" + topicName + \" does not start with \" + TOPIC_PREFIX + \" - skipping\");\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tlog.info(\"Topic name is empty - skipping\");\n\t\t\t}\n\t\t}\n\t} else {\n\t\tlog.info(\"No topics provided - unsubscribing from all topics\");\n\t\tconsumer.unsubscribe();\n\t}\n}", "CodeBleu_score": 56.41597651402406}, {"code": "protected void doSubscribe(List<String> topicNames){\n\tif (!topicNames.isEmpty()) {\n// Create the topics if they don't exist\nfor (String topicName : topicNames) {\nif (!topicExists(topicName)) {\ncreateTopic(topicName);\n}\n}\n// Subscribe the consumer to the topics\nsubscribe(topicNames);\n} else {\n// Log an informational message\nlog.info(\"No topics to subscribe to. Unsubscribing from all topics.\");\n// Unsubscribe from all topics\nunsubscribe();\n}\n}", "CodeBleu_score": 58.42872398594267}, {"code": "protected void doSubscribe(List<String> topicNames){\n\tif (topicNames.isEmpty()) {\nlog.info(\"No topics to subscribe to\");\nunsubscribe();\nreturn;\n}\n\nfor (String topicName : topicNames) {\nif (!topics.containsKey(topicName)) {\ntopics.put(topicName, new ArrayList<Consumer>());\n}\n}\n\nfor (String topicName : topicNames) {\nList<Consumer> consumers = topics.get(topicName);\nconsumers.add(this);\n}\n}", "CodeBleu_score": 48.435488352393705}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tlong startTime = System.currentTimeMillis();\n\tList<ConsumerRecord<String, byte[]>> records = consumer.poll(durationInMillis);\n\tlong endTime = System.currentTimeMillis();\n\tlog.trace(\"Polling {} for {} ms took {} ms\", consumer.getTopic(), durationInMillis, endTime - startTime);\n\treturn records;\n}", "CodeBleu_score": 29.71265930494059}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tlong startTime = System.currentTimeMillis();\n\tList<ConsumerRecord<String, byte[]>> records = consumer.poll(durationInMillis);\n\tlong stopTime = System.currentTimeMillis();\n\tlog.info(String.format(\"Topic: %s, Duration: %d\", topic, durationInMillis));\n\tlog.info(String.format(\"Total time taken: %d\", stopTime - startTime));\n\treturn records;\n}", "CodeBleu_score": 32.73728913411902}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\ttry {\n// Start the stopwatch to measure the polling time\nStopwatch stopwatch = Stopwatch.createStarted();\n\n// Poll the consumer for records\nList<ConsumerRecord<String, byte[]>> records = consumer.poll(durationInMillis);\n\n// Stop the stopwatch and log the total time taken\nlong totalTimeMillis = stopwatch.stop().elapsed(TimeUnit.MILLISECONDS);\nlog.info(\"Poll duration: {} ms, topic: {}, records: {}\", totalTimeMillis, topic, records);\n\n// Return the records\nreturn records;\n} catch (WakeupException e) {\nlog.info(\"Received wakeup exception, stopping consumer\");\n}\nreturn Collections.emptyList();\n}", "CodeBleu_score": 42.93608338434882}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\ttry {\n\t\tif (init) {\n\t\t\tString topic = getTopicPattern(ctx, msg);\n\t\t\tString key = getKeyPattern(ctx, msg);\n\t\t\tpublish(ctx, msg, topic, key);\n\t\t} else {\n\t\t\ttellFailure(ctx, msg);\n\t\t}\n\t} catch (Exception e) {\n\t\ttellFailure(ctx, msg);\n\t}\n}", "CodeBleu_score": 17.4784013762943}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\ttry {\n\t\tif (init) {\n\t\t\tString topic = getTopicPattern(ctx);\n\t\t\tString key = getKeyPattern(ctx);\n\t\t\tpublish(ctx, msg, topic, key);\n\t\t} else {\n\t\t\ttellFailure(ctx, \"initialization error\");\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(\"Exception occurred\", e);\n\t\ttellFailure(ctx, e);\n\t}\n}", "CodeBleu_score": 17.13861574049543}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\ttry {\n\t\tString topicPattern = getTopicPattern(ctx);\n\t\tString keyPattern = getKeyPattern(ctx);\n\t\tString topic = topicPattern!= null? topicPattern.replaceAll(TOPIC_PATTERN_REGEX, msg.getTopic()) : msg.getTopic();\n\t\tString key = keyPattern!= null? keyPattern.replaceAll(KEY_PATTERN_REGEX, msg.getKey()) : msg.getKey();\n\t\texecuteAsync(ctx, topic, key, msg);\n\t} catch (Exception e) {\n\t\ttellFailure(ctx, e);\n\t}\n}", "CodeBleu_score": 29.618798932143164}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\ttry {\n\t\t// check if metadata should be added\n\t\tif (metadata) {\n\t\t\t// create headers from message metadata\n\t\t\tMap<String, String> headers = new HashMap<>();\n\t\t\tfor (String key : msg.getMetaData().keySet()) {\n\t\t\t\theaders.put(key, msg.getMetaData().get(key));\n\t\t\t}\n\t\t\t// send message with headers\n\t\t\tproducer.send(new ProducerRecord<>(topic, key, msg.getData()), new Callback() {\n\t\t\t\t@Override\n\t\t\t\tpublic void onCompletion(RecordMetadata metadata, Exception exception) {\n\t\t\t\t\tif (exception!= null) {\n\t\t\t\t\t\tctx.getLogger().debug(\"Kafka publish error: \" + exception.getMessage());\n\t\t\t\t\t} else {\n\t\t\t\t\t\tctx.getLogger().debug(\"Kafka publish success: \" + metadata.toString());\n\t\t\t\t\t}\n\t\t\t\t\tprocessRecord(ctx, msg, metadata);\n\t\t\t\t}\n\t\t\t}, headers);\n\t\t} else {\n\t\t\t// send message directly to topic\n\t\t\tproducer.send(new ProducerRecord<>(topic, key, msg.getData()), new Callback() {\n\t\t\t\t@Override\n\t\t\t\tpublic void onCompletion(RecordMetadata metadata, Exception exception) {\n\t\t\t\t\tif (exception!= null) {\n\t\t\t\t\t\tctx.getLogger().debug(\"Kafka publish error: \" + exception.getMessage());\n\t\t\t\t\t} else {\n\t\t\t\t\t\tctx.getLogger().debug(\"Kafka publish success: \" + metadata.toString());\n\t\t\t\t\t}\n\t\t\t\t\tprocessRecord(ctx, msg, metadata);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t} catch (Exception e) {\n\t\tctx.getLogger().debug(\"Kafka publish error: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 36.347935293253165}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\ttry {\n\t\tif (key == null) {\n\t\t\tsend(ctx, msg, topic);\n\t\t} else {\n\t\t\tsend(ctx, msg, topic, key);\n\t\t}\n\t} catch (Exception e) {\n\t\tdebug(ctx, \"publish: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 24.177749088703035}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\tif (msg.getMetaData() == null) {\n\t\tsend(ctx, msg, topic, key);\n\t} else {\n\t\tsend(ctx, msg, topic, key, msg.getMetaData().get(TbConstants.METADATA_KEY));\n\t}\n}", "CodeBleu_score": 18.065631950124423}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\t\ttry {\n\t\tif (producer!= null) {\n\t\t\tproducer.close();\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(\"Failed to close producer\", e);\n\t}\n}", "CodeBleu_score": 59.337711785707235}, {"code": "public void destroy(){\n\t\ttry {\n\t\tif (producer!= null) {\n\t\t\tproducer.close();\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(\"Error while closing the producer\", e);\n\t}\n}", "CodeBleu_score": 54.96976644856177}, {"code": "public void destroy(){\n\t\ttry {\n\t\tif (producer!= null) {\n\t\t\tproducer.close();\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(\"Error closing Kafka producer\", e);\n\t}\n}", "CodeBleu_score": 54.38697805490308}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\treturn createRuleEngineMsgProducer(settings, admin, getServiceId(), defaultTopic);\n}", "CodeBleu_score": 13.296133328739671}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\treturn createRuleEngineMsgProducer(getServiceId());\n}", "CodeBleu_score": 10.763126534095372}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> producer = TbQueueProducer.builder()\n\t\t\t.withKafkaSettings(kafkaSettings)\n\t\t\t.withClientId(clientId)\n\t\t\t.withDefaultTopic(defaultTopic)\n\t\t\t.withAdmin(admin)\n\t\t\t.build();\n\treturn producer;\n}", "CodeBleu_score": 32.446875429797586}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\tlong printIntervalMs = getPrintIntervalMs();\nlong kafkaResponseTimeoutMs = getKafkaResponseTimeoutMs();\nlong timeoutDuration = kafkaResponseTimeoutMs + printIntervalMs;\nscheduleWithFixedDelay(() -> {\ntry {\nif (isStatsPrintRequired()) {\nlogGroupStats();\n}\n} catch (Exception e) {\nwarn(format(\"Error while logging statistics for group %s. %s\",\ngetGroupId(), e.getMessage()));\ne.printStackTrace();\n}\n}, 0, printIntervalMs, MILLISECONDS);\n}", "CodeBleu_score": 12.610902676398778}, {"code": "private void startLogScheduling(){\n\tif (isStatsPrintRequired) {\nlong printIntervalMs = getPrintIntervalMs();\nlong kafkaResponseTimeoutMs = getKafkaResponseTimeoutMs();\nlong timeoutDurationMs = kafkaResponseTimeoutMs > printIntervalMs? kafkaResponseTimeoutMs : printIntervalMs;\nscheduleWithFixedDelay(new Runnable() {\n@Override\npublic void run() {\ntry {\nif (isStatsPrintRequired) {\nprintConsumerGroupStats();\n}\n} catch (Exception e) {\nwarn(\"Error while printing consumer group statistics for all consumer groups\", e);\n}\n}\n}, timeoutDurationMs, printIntervalMs, MILLISECONDS);\n}\n}", "CodeBleu_score": 13.099910622359834}, {"code": "private void startLogScheduling(){\n\tif (isStatsPrintRequired()) {\nlong timeout = getKafkaResponseTimeoutMs();\nscheduleWithFixedDelay(new Runnable() {\n@Override\npublic void run() {\ntry {\nlog.info(\"Kafka consumer group statistics\");\nfor (String groupId : getTopicsStatsWithLag().keySet()) {\nlog.info(\"Group ID: \" + groupId);\nlog.info(\"Topics with lag:\");\nfor (TopicStatsWithLag topicStatsWithLag : getTopicsStatsWithLag().get(groupId)) {\nlog.info(topicStatsWithLag.toString());\n}\n}\n} catch (Exception e) {\nlog.warn(\"Error while retrieving consumer group statistics for group ID: \" + groupId, e);\n}\n}\n}, timeout, getPrintIntervalMs(), MILLISECONDS);\n}\n}", "CodeBleu_score": 19.736868613623056}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 89.98389245836069}, {"code": "protected Properties toAdminProps(){\n\t\tProperties props = toProps();\n\tprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n\tprops.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, requestTimeoutMs);\n\tprops.put(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, retryBackoffMs);\n\treturn props;\n}", "CodeBleu_score": 73.40114117190078}, {"code": "protected Properties toAdminProps(){\n\t\tProperties props = toProps();\n\tprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n\tprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\n\treturn props;\n}", "CodeBleu_score": 89.99349344802474}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\tString scopedName = getScopedName(metricName, group);\nString[] tags = getTags(metricName, group);\nMetricEvent event = new MetricEvent(scopedName, tags, metric);\nswitch (metric.getType()) {\ncase COUNTER:\ncounterEvents.add(event);\nbreak;\ncase GAUGE:\ngaugeEvents.add(event);\nbreak;\ncase HISTOGRAM:\nhistogramEvents.add(event);\nbreak;\ncase METER:\nmeterEvents.add(event);\nbreak;\ndefault:\nwarn(\n\"Metric type \" + metric.getType() + \" is not supported. \" +\n\"Metric \" + metricName + \" will not be reported to the monitoring system.\");\n}\n}", "CodeBleu_score": 29.883655666629334}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\tString scopedName = metricName;\nif (group!= null) {\nscopedName = group.getName() + \".\" + scopedName;\n}\n\nMetricEvent metricEvent = new MetricEvent(metric, scopedName, group, getTags(metricName, group));\n\nif (metric instanceof Counter) {\ncounterEvents.add(metricEvent);\n} else if (metric instanceof Gauge) {\ngaugeEvents.add(metricEvent);\n} else if (metric instanceof Histogram) {\nhistogramEvents.add(metricEvent);\n} else if (metric instanceof Meter) {\nmeterEvents.add(metricEvent);\n} else {\nwarn(\"Metric type not supported: \" + metric.getClass().getName());\n}\n}", "CodeBleu_score": 48.78216333704527}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\tif (metricName == null) {\nthrow new NullPointerException(\"metricName cannot be null\");\n}\nif (group == null) {\nthrow new NullPointerException(\"group cannot be null\");\n}\nString scopedName = getScopedName(metricName, group);\nString[] tags = getTags(metricName, group);\nMetricEvent event = new MetricEvent(metric, scopedName, tags);\nif (metric instanceof Counter) {\ncounters.add(event);\n} else if (metric instanceof Gauge) {\ngauges.add(event);\n} else if (metric instanceof Histogram) {\nhistograms.add(event);\n} else if (metric instanceof Meter) {\nmeters.add(event);\n} else {\nlog.warn(\"Metric type \" + metric.getClass() + \" is not supported\");\n}\n}", "CodeBleu_score": 47.65395075030683}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\tif (metricEvent.getFields() == null) {\nMap<String, Object> fields = new HashMap<>();\nmetricEvent.setFields(fields);\n}\nif (gauge.getValue() instanceof Number) {\nmetricEvent.getFields().put(field, gauge.getValue().toString());\n} else {\nmetricEvent.getFields().put(field, gauge.getValue());\n}\nreturn metricEvent;\n}", "CodeBleu_score": 36.563874601376405}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\tif (metricEvent.getFields() == null) {\nmetricEvent.setFields(new HashMap<>());\n}\nif (gauge.getValue() instanceof Number) {\nmetricEvent.getFields().put(field, ((Number) gauge.getValue()).doubleValue());\n} else {\nmetricEvent.getFields().put(field, gauge.getValue().toString());\n}\nreturn metricEvent;\n}", "CodeBleu_score": 25.64742631798288}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\tif (metricEvent.getFields() == null) {\nmetricEvent.setFields(new HashMap<>());\n}\nif (gauge.getValue() instanceof Number) {\nmetricEvent.getFields().put(field, ((Number) gauge.getValue()).doubleValue());\n} else if (gauge.getValue() instanceof String) {\nmetricEvent.getFields().put(field, (String) gauge.getValue());\n}\nreturn metricEvent;\n}", "CodeBleu_score": 27.189642202242492}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tif (gauge == null) {\n\t\treturn metricEvent;\n\t}\n\n\tString kafkaTopic = gauge.getMetricName().split(\"\\\\.\")[2];\n\tString kafkaPartition = gauge.getMetricName().split(\"\\\\.\")[3];\n\tLong currentOffset = gauge.getValue();\n\tLong committedOffset = gauge.getValue();\n\n\tif (kafkaTopic.equals(metricEvent.getFields().get(\"kafkaTopic\"))) {\n\t\tif (kafkaPartition.equals(metricEvent.getFields().get(\"kafkaPartition\"))) {\n\t\t\tif (currentOffset!= null &&!currentOffset.equals(metricEvent.getFields().get(\"currentOffset\"))) {\n\t\t\t\tmetricEvent.getFields().put(\"currentOffset\", currentOffset);\n\t\t\t\tmetricEvent.getFields().put(\"kafkaLagTime\", timestamp - metricEvent.getTimestamp());\n\t\t\t\tmetricEvent.getFields().put(\"kafkaLagTime\", timestamp - metricEvent.getTimestamp());\n\t\t\t\tmetricEvent.getFields().put(\"kafkaLag\", currentOffset - committedOffset);\n\t\t\t\tmetricEvent.getFields().put(\"kafkaLag\", currentOffset - committedOffset);\n\t\t\t\tmetricEvent.setTimestamp(timestamp);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn metricEvent;\n}", "CodeBleu_score": 29.476919670092055}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tif (gauge == null) {\n\t\treturn metricEvent;\n\t}\n\tString name = gauge.name();\n\tString[] splitName = name.split(\"\\\\.\");\n\tString kafkaTopic = splitName[splitName.length - 1];\n\tString kafkaPartition = splitName[splitName.length - 2];\n\tlong offset = gauge.getValue();\n\tlong committedOffset = gauge.getValue();\n\tlong lag = offset - committedOffset;\n\tif (metricEvent.getFields().containsKey(kafkaTopic) && metricEvent.getFields().get(kafkaTopic).containsKey(kafkaPartition)) {\n\t\tlong currentOffset = metricEvent.getFields().get(kafkaTopic).get(kafkaPartition).getLong(CURRENT_OFFSET);\n\t\tlong committedOffset = metricEvent.getFields().get(kafkaTopic).get(kafkaPartition).getLong(COMMITTED_OFFSET);\n\t\tlong lag = currentOffset - committedOffset;\n\t\tif (currentOffset == offset && committedOffset == committedOffset) {\n\t\t\treturn metricEvent;\n\t\t}\n\t}\n\tmetricEvent.setFields(metricEvent.getFields().put(kafkaTopic, metricEvent.getFields().get(kafkaTopic).put(kafkaPartition, new HashMap<String, Long>() {\n\t\t{\n\t\t\tput(CURRENT_OFFSET, offset);\n\t\t\tput(COMMITTED_OFFSET, committedOffset);\n\t\t\tput(LAG, lag);\n\t\t\tput(TIMESTAMP, timestamp);\n\t\t}\n\t})));\n\treturn metricEvent;\n}", "CodeBleu_score": 31.762555208317245}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\t// Get the kafkaLagTimes map\n\tMap<String, Long> kafkaLagTimes = metricEvent.getFields().get(\"kafkaLagTimes\");\n\tif (kafkaLagTimes == null) {\n\t\tkafkaLagTimes = new HashMap<>();\n\t\tmetricEvent.getFields().put(\"kafkaLagTimes\", kafkaLagTimes);\n\t}\n\n\t// Get the kafkaLagMetrics map\n\tMap<String, Gauge<?>> kafkaLagMetrics = metricEvent.getFields().get(\"kafkaLagMetrics\");\n\tif (kafkaLagMetrics == null) {\n\t\tkafkaLagMetrics = new HashMap<>();\n\t\tmetricEvent.getFields().put(\"kafkaLagMetrics\", kafkaLagMetrics);\n\t}\n\n\t// Get the kafkaLagOffsets map\n\tMap<String, Long> kafkaLagOffsets = metricEvent.getFields().get(\"kafkaLagOffsets\");\n\tif (kafkaLagOffsets == null) {\n\t\tkafkaLagOffsets = new HashMap<>();\n\t\tmetricEvent.getFields().put(\"kafkaLagOffsets\", kafkaLagOffsets);\n\t}\n\n\t// Get the kafkaLagCommittedOffsets map\n\tMap<String, Long> kafkaLagCommittedOffsets = metricEvent.getFields().get(\"kafkaLagCommittedOffsets\");\n\tif (kafkaLagCommittedOffsets == null) {\n\t\tkafkaLagCommittedOffsets = new HashMap<>();\n\t\tmetricEvent.getFields().put(\"kafkaLagCommittedOffsets\", kafkaLagCommittedOffsets);\n\t}\n\n\t// Get the kafkaLagTopicNames map\n\tMap<String, String> kafkaLagTopicNames = metricEvent.getFields().get(\"kafkaLagTopicNames\");\n\tif (kafkaLagTopicNames == null) {\n\t\tkafkaLagTopicNames = new HashMap<>();\n\t\tmetricEvent.getFields().put(\"kafkaLagTopicNames\", kafkaLagTopicNames);\n\t}\n\n\t// Get the kafkaLagTopicNames map\n\tMap<String, String> kafkaLagPartitionNames = metricEvent.getFields().get(\"kafkaLagPartitionNames\");\n\tif (kafkaLagPartitionNames == null) {\n\t\tkafkaLagPartitionNames = new HashMap<>();\n\t\tmetricEvent.getFields().put(\"kafkaLagPartitionNames\", kafkaLagPartitionNames);\n\t}\n\n\t// Get the kafkaLagTopicNames map\n\tMap<String, String> kafkaLagPartitionIds = metricEvent.getFields().get(\"kafkaLagPartitionIds\");\n\tif (", "CodeBleu_score": 21.069780934510852}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tMap<String, String> props = buildKafkaProps(env);\n\tKafkaDeserializationSchema<MetricEvent> deserializationSchema = new MetricEventSchema();\n\tKafkaSource<MetricEvent> kafkaSource = new FlinkKafkaConsumer<>(topic, deserializationSchema, props);\n\tif (time!= null) {\n\t\tkafkaSource.setStartFromSpecificOffsets(buildOffsetByTime(env, time));\n\t}\n\tenv.addSource(kafkaSource);\n\treturn kafkaSource;\n}", "CodeBleu_score": 35.661258680320515}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\t// Get the global job parameters\n\tJobParameters jobParameters = env.getExecutionConfig().getJobParameters();\n\t// Build Kafka properties\n\tProperties kafkaProps = buildKafkaProps(jobParameters);\n\t// Create a FlinkKafkaConsumer for MetricEvent\n\tFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), kafkaProps);\n\t// If a specific start time is provided, set the consumer to start from the specific offsets\n\tif (time!= null) {\n\t\tconsumer.setStartFromSpecificOffsets(buildOffsetByTime(jobParameters, time));\n\t}\n\t// Add the consumer as a source to the StreamExecutionEnvironment\n\tenv.addSource(consumer).name(\"MetricEvent Source\");\n\treturn env.addSource(consumer).name(\"MetricEvent Source\");\n}", "CodeBleu_score": 48.20826953919286}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tMap<String, String> props = buildKafkaProps(env);\n\tprops.put(\"specific.start.offset.time\", time.toString());\n\tFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), props);\n\tenv.addSource(consumer);\n\treturn consumer.getDataStream();\n}", "CodeBleu_score": 36.656052453967526}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\tMap<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\nKafkaConsumer<byte[], byte[]> consumer = null;\ntry {\nconsumer = new KafkaConsumer<>(props);\nconsumer.subscribe(Collections.singletonList(parameterTool.getRequired(\"topic\")));\nMap<TopicPartition, Long> topicPartitionOffsets = consumer.offsetsForTimes(\nCollections.singletonMap(new TopicPartition(parameterTool.getRequired(\"topic\"), 0), time));\nfor (Map.Entry<TopicPartition, Long> entry : topicPartitionOffsets.entrySet()) {\npartitionOffsets.put(entry.getKey(), entry.getValue());\n}\n} finally {\nif (consumer!= null) {\nconsumer.close();\n}\n}\nreturn partitionOffsets;\n}", "CodeBleu_score": 38.899090249900276}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\ttry {\nKafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(props);\n\nMap<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\n\nList<KafkaTopicPartition> partitions = consumer.partitionsFor(topic);\nMap<KafkaTopicPartition, Long> partitionTimes = new HashMap<>();\nfor (KafkaTopicPartition partition : partitions) {\npartitionTimes.put(partition, time);\n}\n\nconsumer.offsetsForTimes(partitionTimes).forEach((partition, offset) -> {\npartitionOffsets.put(partition, offset);\n});\n\nconsumer.close();\nreturn partitionOffsets;\n} catch (Exception e) {\nthrow new RuntimeException(e);\n}\n}", "CodeBleu_score": 38.720703637798636}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\tMap<KafkaTopicPartition, Long> offsets = new HashMap<>();\n\nString groupId = parameterTool.getRequired(\"group.id\");\nprops.setProperty(\"group.id\", groupId);\n\nKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\nMap<String, List<KafkaPartitionInfo>> topicPartitions = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\nMap<KafkaTopicPartition, Long> partitionTimes = new HashMap<>();\nfor (KafkaPartitionInfo partitionInfo : topicPartitions.get(parameterTool.getRequired(\"topic\"))) {\npartitionTimes.put(new KafkaTopicPartition(parameterTool.getRequired(\"topic\"), partitionInfo.partition()), time);\n}\n\nconsumer.offsetsForTimes(partitionTimes, time).forEach((topicPartition, offset) -> offsets.put(topicPartition, offset));\n\nconsumer.close();\n\nreturn offsets;\n}", "CodeBleu_score": 46.697516733658}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t\t// Set up Kafka producer properties\n\tProperties props = new Properties();\n\tprops.put(\"bootstrap.servers\", \"localhost:9092\");\n\tprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.ByteArraySerializer\");\n\n\t// Create a KafkaProducer instance with the specified properties\n\tKafkaProducer<String, byte[]> producer = new KafkaProducer<String, byte[]>(props);\n\n\t// Create a MetricEvent with the current timestamp, name, tags, and fields\n\tMetricEvent metricEvent = new MetricEvent();\n\tmetricEvent.setTimestamp(System.currentTimeMillis());\n\tmetricEvent.setName(\"my_metric_name\");\n\tmetricEvent.setTags(new HashMap<String, String>() {{\n\t\tput(\"tag1\", \"value1\");\n\t\tput(\"tag2\", \"value2\");\n\t}});\n\tmetricEvent.setFields(new HashMap<String, Object>() {{\n\t\tput(\"field1\", \"value1\");\n\t\tput(\"field2\", \"value2\");\n\t}});\n\n\t// Create a ProducerRecord with the serialized MetricEvent and send it to the specified topic\n\tProducerRecord<String, byte[]> record = new ProducerRecord<String, byte[]>(\"my_topic\", metricEvent.toJson());\n\tproducer.send(record);\n\n\t// Print the sent data and flush the producer to ensure all data is sent\n\tSystem.out.println(\"Sent data: \" + metricEvent.toJson());\n\tproducer.flush();\n}", "CodeBleu_score": 48.829645861457706}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties props = new Properties();\n\tprops.put(\"bootstrap.servers\", \"localhost:9092\");\n\tprops.put(\"acks\", \"all\");\n\tprops.put(\"retries\", 0);\n\tprops.put(\"batch.size\", 16384);\n\tprops.put(\"linger.ms\", 1);\n\tprops.put(\"buffer.memory\", 33554432);\n\tprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tKafkaProducer<String, String> producer = new KafkaProducer<String, String>(props);\n\tMetricEvent event = new MetricEvent();\n\tevent.setTimestamp(System.currentTimeMillis());\n\tevent.setName(\"test\");\n\tevent.setTags(\"tag1\", \"tag2\");\n\tevent.setFields(\"field1\", \"field2\");\n\tproducer.send(new ProducerRecord<String, String>(\"test\", event.toJson()));\n\tSystem.out.println(\"Sent: \" + event.toJson());\n\tproducer.flush();\n}", "CodeBleu_score": 46.01389210875717}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties kafkaProps = new Properties();\n\tkafkaProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\n\tkafkaProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n\tkafkaProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class.getName());\n\tKafkaProducer<String, MetricEvent> kafkaProducer = new KafkaProducer<>(kafkaProps);\n\tMetricEvent metricEvent = new MetricEvent();\n\tmetricEvent.setTimestamp(System.currentTimeMillis());\n\tmetricEvent.setName(\"test\");\n\tmetricEvent.setTags(new HashMap<>());\n\tmetricEvent.setFields(new HashMap<>());\n\tmetricEvent.getFields().put(\"field1\", \"value1\");\n\tmetricEvent.getFields().put(\"field2\", \"value2\");\n\tProducerRecord<String, MetricEvent> record = new ProducerRecord<>(\"test\", metricEvent);\n\tkafkaProducer.send(record);\n\tkafkaProducer.flush();\n\tSystem.out.println(record.value().toJson());\n}", "CodeBleu_score": 38.75801749870248}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\ttry {\nif (this.levels.contains(event.getLevel()) &&!event.getLoggerName().contains(\"xxx\")) {\nProducerRecord<String, String> record = new ProducerRecord<String, String>(this.topic, event.getLevel().toString(), event.getMessage().getFormattedMessage());\nthis.producer.send(record, new Callback() {\npublic void onCompletion(RecordMetadata metadata, Exception exception) {\nif (exception!= null) {\nlogger.warn(\"Exception occurred while sending event to Kafka topic: \" + exception.getMessage());\n}\n}\n});\n}\n} catch (Exception e) {\nlogger.warn(\"Exception occurred while appending event to Kafka topic: \" + e.getMessage());\n}\n}", "CodeBleu_score": 43.8584622609383}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tif (this.levelList.contains(event.getLevel()) &&!event.getLoggerName().contains(this.loggerName)) {\ntry {\nthis.producer.send(new ProducerRecord(this.topic, event.getMessage().getFormattedMessage()));\n} catch (Exception e) {\nthis.logger.warn(\"Error sending log event to Kafka topic: \" + this.topic, e);\n}\n}\n}", "CodeBleu_score": 44.958404914327424}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tif (event == null) {\nreturn;\n}\n\nfinal String loggerName = event.getLoggerName();\nfinal Level level = event.getLevel();\nfinal String message = event.getMessage().getFormattedMessage();\nfinal Map<String, String> mdc = event.getContextMap();\nfinal Map<String, String> properties = event.getContextData();\nfinal Thread thread = event.getThreadName();\nfinal long timestamp = event.getMillis();\nfinal Throwable throwable = event.getThrown();\n\nif (level.isGreaterOrEqual(this.level) &&!loggerName.contains(this.exclude)) {\ntry {\nProducerRecord<String, String> record = new ProducerRecord<String, String>(this.topic, message);\nthis.producer.send(record, new Callback() {\npublic void onCompletion(RecordMetadata metadata, Exception exception) {\nif (exception == null) {\nlog.warn(\"Successfully sent log message to Kafka topic {} at offset {}\", this.topic, metadata.offset());\n} else {\nlog.warn(\"Failed to send log message to Kafka topic {} at offset {}\", this.topic, metadata.offset(), exception);\n}\n}\n});\n} catch (Exception e) {\nlog.warn(\"Failed to send log message to Kafka topic {} at offset {}\", this.topic, e);\n}\n}\n}", "CodeBleu_score": 37.20274013735065}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, v := range topicSuffixMethods {\n\t\tif v == method {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 77.83490095281837}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range topicSuffixMethods {\n\t\tif validMethod == method {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 84.19601265715382}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tswitch method {\n\tcase \"create\", \"update\", \"delete\":\n\t\treturn nil\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 29.654414474550805}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag!= \"\" {\n\t\tif val, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn val, nil\n\t\t}\n\t\treturn \"\", fmt.Errorf(\"routing tag '%s' not found in metric\", k.RoutingTag)\n\t}\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 55.46417257420037}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tvar key string\n\tif k.RoutingTag!= \"\" {\n\t\ttag, ok := metric.GetTag(k.RoutingTag)\n\t\tif!ok {\n\t\t\treturn \"\", fmt.Errorf(\"routing tag %q not present in metric\", k.RoutingTag)\n\t\t}\n\t\tkey = tag.Value.(string)\n\t} else if k.RoutingKey == \"random\" {\n\t\tkey = uuid.NewV4().String()\n\t} else {\n\t\tkey = k.RoutingKey\n\t}\n\treturn key, nil\n}", "CodeBleu_score": 46.91583696803797}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag!= \"\" {\n\t\ttagValue, ok := metric.GetTag(k.RoutingTag)\n\t\tif!ok {\n\t\t\treturn \"\", fmt.Errorf(\"RoutingTag %s not present in metric\", k.RoutingTag)\n\t\t}\n\t\treturn tagValue, nil\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 51.11982525268114}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.topicRegexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tcompiledRegexp, err := regexp.Compile(topicRegexp)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"unable to compile topic regexp %q: %v\", topicRegexp, err)\n\t\t}\n\t\tk.topicRegexps[i] = compiledRegexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 53.52999824171197}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.topicRegexps = make([]regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tif topicRegexp == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tre, err := regexp.Compile(topicRegexp)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"invalid topic regexp %q: %w\", topicRegexp, err)\n\t\t}\n\t\tk.topicRegexps[i] = *re\n\t}\n\treturn nil\n}", "CodeBleu_score": 52.62592120152141}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.topicRegexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tcompiledRegexp, err := regexp.Compile(topicRegexp)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"failed to compile topic regexp %s: %s\", topicRegexp, err)\n\t\t}\n\t\tk.topicRegexps[i] = compiledRegexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 53.50813216730857}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\tmsg, ok := h.undelivered[track.MessageID]\n\tif!ok {\n\t\th.log.Debugf(\"Message %s not found in undelivered map\", track.MessageID)\n\t\treturn\n\t}\n\tmsg.session.MarkMessage(track.MessageID)\n\tdelete(h.undelivered, track.MessageID)\n\th.delivered.Release()\n}", "CodeBleu_score": 58.70863754222806}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.ID]\n\tif!ok {\n\t\th.log.Debugf(\"message with delivery ID %d not found in undelivered map\", track.ID)\n\t\treturn\n\t}\n\n\tmsg.session.MarkMessage(track.ID)\n\tdelete(h.undelivered, track.ID)\n\th.sem.Release(1)\n}", "CodeBleu_score": 59.06236267263595}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.MessageID]\n\tif!ok {\n\t\treturn\n\t}\n\n\tmsg.session.MarkMessage(track.MessageID, telegraf.Delivered)\n\tdelete(h.undelivered, track.MessageID)\n\th.sem.Release(1)\n}", "CodeBleu_score": 49.84673525771751}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg, more := <-claim.Messages():\n\t\t\tif more {\n\t\t\t\tif err := h.Handle(ctx, msg); err!= nil {\n\t\t\t\t\th.acc.AddError(err)\n\t\t\t\t\tlog.Println(\"Error handling message:\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 58.88238725416506}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tlog.Printf(\"Starting consumer for topic %s partition %d at offset %d\n\", claim.Topic(), claim.Partition(), claim.Offset())\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\tlog.Printf(\"Context done for topic %s partition %d at offset %d\n\", claim.Topic(), claim.Partition(), claim.Offset())\n\t\t\treturn ctx.Err()\n\t\tcase msg, more := <-claim.Messages():\n\t\t\tif more {\n\t\t\t\tif err := h.Handle(ctx, msg); err!= nil {\n\t\t\t\t\th.acc.AddError(err)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tlog.Printf(\"No more messages for topic %s partition %d at offset %d\n\", claim.Topic(), claim.Partition(), claim.Offset())\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 45.03461977344913}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\t// Obtain the session context.\n\tctx := session.Context()\n\n\t// Enter a loop to reserve processing capacity.\n\tfor {\n\t\t// Wait for the context to be done or for a message from the claim.\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\t// Exit the loop if the context is done.\n\t\t\treturn ctx.Err()\n\t\tcase msg, more := <-claim.Messages():\n\t\t\t// Exit the loop if the claim is closed.\n\t\t\tif!more {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\t// Handle the message.\n\t\t\terr := h.Handle(ctx, msg)\n\t\t\tif err!= nil {\n\t\t\t\t// Log any errors encountered during handling.\n\t\t\t\th.acc.AddError(err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 57.14645934782423}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\t\tval rgx = \"\"\"^[a-zA-Z0-9_-]+$\"\"\".r\n\tif (logkafka_id.isEmpty)\n\t\tthrow new IllegalArgumentException(\"Logkafka ID cannot be empty\")\n\tif (logkafka_id == \".\" || logkafka_id == \"..\")\n\t\tthrow new IllegalArgumentException(\"Logkafka ID cannot be '.' or '..'\")\n\tif (logkafka_id.length > MAX_LOGKAFKA_ID_LENGTH)\n\t\tthrow new IllegalArgumentException(s\"Logkafka ID cannot exceed $MAX_LOGKAFKA_ID_LENGTH characters\")\n\tif (!rgx.findFirstIn(logkafka_id).isDefined)\n\t\tthrow new IllegalArgumentException(s\"Logkafka ID must contain only valid characters\")\n}", "CodeBleu_score": 26.787245435029817}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\tif (logkafka_id.isEmpty) {\nthrow new IllegalArgumentException(\"logkafka_id is empty\")\n}\nif (logkafka_id.equals(\".\") || logkafka_id.equals(\"..\")) {\nthrow new IllegalArgumentException(\"logkafka_id cannot be equal to '.' or '..'\")\n}\nif (logkafka_id.length > 255) {\nthrow new IllegalArgumentException(\"logkafka_id cannot be longer than 255 characters\")\n}\nif (!logkafka_id.matches(\"[a-zA-Z0-9\\\\-\\\\.\\\\_]+\")) {\nthrow new IllegalArgumentException(\"logkafka_id contains illegal characters\")\n}\n}", "CodeBleu_score": 24.878489216543553}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t\tif (logkafka_id.isEmpty) {\n\t\tthrow new IllegalArgumentException(\"Logkafka ID cannot be empty.\")\n\t}\n\tif (logkafka_id == \".\" || logkafka_id == \"..\") {\n\t\tthrow new IllegalArgumentException(\"Logkafka ID cannot be equal to '.' or '..'.\")\n\t}\n\tif (logkafka_id.length > 255) {\n\t\tthrow new IllegalArgumentException(s\"Logkafka ID cannot exceed 255 characters. The current length is ${logkafka_id.length}.\")\n\t}\n\tif (!logkafka_id.matches(logkafka_idRegex)) {\n\t\tthrow new IllegalArgumentException(s\"Logkafka ID must contain only valid characters. The current value is ${logkafka_id}.\")\n\t}\n}", "CodeBleu_score": 25.905097622755214}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tTry", "CodeBleu_score": 5.145501100687216}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tsystem.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse => \n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) => \n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover", "CodeBleu_score": 67.35222040981212}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tTry", "CodeBleu_score": 5.145501100687216}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tsystem.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case err: Throwable =>\n        Future.successful(-\\/(ApiError.fromThrowable(err)))\n    }\n  }", "CodeBleu_score": 79.51167748850146}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tsystem.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case t: Throwable => Future.successful(-\\/(ApiError.fromThrowable(t)))\n    }\n  }", "CodeBleu_score": 82.60897232527465}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tsystem.actorSelection(kafkaManagerActor).ask", "CodeBleu_score": 14.095846829733288}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n/**\n * The runPreferredLeaderElection function initiates a preferred leader election for specified topics in a given cluster.", "CodeBleu_score": 14.222873900293253}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n/**\n * The runPreferredLeaderElection function initiates a preferred leader election for specified topics in a given cluster.", "CodeBleu_score": 14.222873900293253}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n}", "CodeBleu_score": 8.140979095809902}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\tFuture.successful", "CodeBleu_score": 5.32422285046238}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\tFuture.successful", "CodeBleu_score": 5.32422285046238}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\tFuture.successful\nerrorOrTopicList.fold\nrunPreferredLeaderElection\ngetTopicList\ngetTopicList(clusterName).flatMap\n}", "CodeBleu_score": 14.434987436849736}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\nimport scala.concurrent.ExecutionContext.Implicits.global\n\nval results = for {\n  result <- tryWithKafkaManagerActor(KMClusterCommandRequest(clusterName, CMManualPartitionAssignments(assignments)))\n} yield result\n\nresults.map {\n  case Success(result) => true\n  case Error(e) => e\n}\n\nresults.collect {\n  case Error(e) => e\n}\n\n}", "CodeBleu_score": 25.15355295070102}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\\/-", "CodeBleu_score": 4.74373495925022}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\ttryWithKafkaManagerActor(\n      KMClusterCommandRequest (\n        clusterName,\n        CMManualPartitionAssignments(assignments)\n      )\n    )", "CodeBleu_score": 13.9397244347791}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\ttry {\n\t\t// Describe the cluster to get the available nodes within a specified timeout\n\t\tDescribeClusterResult describeResult = admin.describeCluster(Duration.ofSeconds(30));\n\n\t\t// If no nodes are available, throw a ConnectException\n\t\tif (describeResult.nodes().isEmpty()) {\n\t\t\tthrow new ConnectException(\"No nodes available\");\n\t\t}\n\n\t\t// Select the first node's ID\n\t\tString nodeId = describeResult.nodes().iterator().next().id();\n\n\t\t// Request the configuration of the selected node\n\t\tDescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, nodeId)));\n\n\t\t// If no configurations are received, throw another ConnectException\n\t\tif (describeConfigsResult.all().isEmpty()) {\n\t\t\tthrow new ConnectException(\"No configuration received\");\n\t\t}\n\n\t\t// Return the broker's configuration\n\t\treturn describeConfigsResult.all().iterator().next().config();\n\t}\n\tcatch (Exception e) {\n\t\tthrow new ConnectException(\"Error retrieving Kafka broker configuration\", e);\n\t}\n}", "CodeBleu_score": 50.28880609783026}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\ttry {\n\t\tMap<String, Config> configs = new HashMap<>();\n\t\tlong timeout = 5000;\n\t\tList<Node> nodes = admin.describeCluster(timeout).nodes().get();\n\t\tif (nodes.isEmpty()) {\n\t\t\tthrow new ConnectException(\"No Kafka broker nodes available in the cluster\");\n\t\t}\n\t\tString idString = nodes.get(0).id().toString();\n\t\tconfigs.put(idString, admin.describeConfigs(Collections.singletonList(new ConfigResource(ConfigResource.Type.BROKER, idString))).all().get().get(idString));\n\t\treturn configs.get(idString);\n\t} catch (Exception e) {\n\t\tthrow new ConnectException(\"Failed to retrieve Kafka broker configuration\", e);\n\t}\n}", "CodeBleu_score": 46.07115599834755}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\ttry {\n\t\t// Describe the cluster to get the available nodes\n\t\tList<Node> nodes = admin.describeCluster(Duration.ofSeconds(5)).nodes().get();\n\t\tif (nodes.isEmpty()) {\n\t\t\tthrow new ConnectException(\"No nodes available in the cluster.\");\n\t\t}\n\t\t// Select the first node's ID\n\t\tString nodeId = nodes.get(0).id();\n\t\t// Request the configuration of the selected node\n\t\tMap<ConfigResource, Config> configs = admin.describeConfigs(Collections.singletonList(new ConfigResource(ConfigResource.Type.BROKER, nodeId))).all().get();\n\t\tif (configs.isEmpty()) {\n\t\t\tthrow new ConnectException(\"No configurations received from the broker.\");\n\t\t}\n\t\t// Return the configuration of the selected node\n\t\treturn configs.get(new ConfigResource(ConfigResource.Type.BROKER, nodeId));\n\t}\n\tcatch (Exception e) {\n\t\tthrow new ConnectException(\"Failed to get the Kafka broker configuration.\", e);\n\t}\n}", "CodeBleu_score": 55.99970242384684}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\treturn schemaHistory.equals", "CodeBleu_score": 5.3548188487604484}, {"code": "private static Validator forKafka(final Validator validator){\n\treturn (\nschemaHistory.equals(KafkaSchemaHistory.SCHEMA_HISTORY_ENABLED)\n? validator\n: Validator.validating(0)\n);\n}", "CodeBleu_score": 12.5925286176057}, {"code": "private static Validator forKafka(final Validator validator){\n\treturn schemaHistory == KafkaSchemaHistory.INSTANCE? validator : Validator.NO_OP;\n}", "CodeBleu_score": 8.047668641308503}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t// Parse the current Kafka Connect version\n\tString kafkaConnectVersion = parseVersion(config.get(KAFKA_CONNECT_VERSION_CONFIG));\n\t// Get the \"topic.creation.enable\" property from the configuration\n\tString topicCreationEnable = config.get(TOPIC_CREATION_ENABLE_CONFIG);\n\t// Default to true if not set\n\tBoolean topicCreationEnableValue = Boolean.parseBoolean(topicCreationEnable);\n\t// Check if the Kafka Connect version is compatible with topic creation and the property is set to true\n\treturn kafkaConnectVersion.compareTo(KAFKA_CONNECT_VERSION_TOPIC_CREATION_ENABLE_MIN_VERSION) >= 0 && topicCreationEnableValue;\n}", "CodeBleu_score": 38.8073230716995}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tKafkaVersion kafkaVersion = parseVersion(config.get(KAFKA_VERSION_CONFIG));\n\tString topicCreationEnable = (String) config.get(TOPIC_CREATION_ENABLE_CONFIG);\n\tBoolean topicCreationEnableParsed = parseBoolean(topicCreationEnable);\n\tBoolean topicCreationEnabled = topicCreationEnableParsed!= null? topicCreationEnableParsed : true;\n\treturn topicCreationEnabled && kafkaVersion.isAtLeast(KAFKA_CONNECT_0_10_2);\n}", "CodeBleu_score": 39.51969390914967}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tString version = parseVersion(config);\n\tBoolean topicCreationEnabled = get(config, \"topic.creation.enable\", true);\n\treturn isTopicCreationEnabled(version, topicCreationEnabled);\n}", "CodeBleu_score": 24.834427243710667}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\tif (config == null) {", "CodeBleu_score": 3.9550490032252124}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\tString clientId = config.get(CLIENT_ID);\n\tif (clientId == null) {\n\t\tthrow new IllegalArgumentException(\"Missing mandatory configuration option: \" + CLIENT_ID);\n\t}\n\tProperties adminProperties = new Properties();\n\tadminProperties.putAll(config);\n\tadminProperties.put(AdminClientConfig.CLIENT_ID_CONFIG, clientId);\n\tadminProperties.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, config.get(BOOTSTRAP_SERVERS));\n\tadminProperties.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, config.get(REQUEST_TIMEOUT_MS));\n\tadminProperties.put(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, config.get(RETRY_BACKOFF_MS));\n\tadminProperties.put(AdminClientConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, config.get(MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION));\n\tadminProperties.put(AdminClientConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG, config.get(CONNECTIONS_MAX_IDLE_MS));\n\tadminProperties.put(AdminClientConfig.METADATA_MAX_AGE_CONFIG, config.get(METADATA_MAX_AGE));\n\tadminProperties.put(AdminClientConfig.METRICS_NUM_SAMPLES_CONFIG, config.get(METRICS_NUM_SAMPLES));\n\tadminProperties.put(AdminClientConfig.METRICS_SAMPLE_WINDOW_MS_CONFIG, config.get(METRICS_SAMPLE_WINDOW_MS));\n\tadminProperties.put(AdminClientConfig.METRICS_RECORDING_LEVEL_CONFIG, config.get(METRICS_RECORDING_LEVEL));\n\tadminProperties.put(AdminClientConfig.METRICS_SAMPLE_WINDOW_MS_CONFIG, config.get(METRICS_SAMPLE_WINDOW_MS));\n\tadminProperties.put(AdminClientConfig.METRICS_RECORDING_LEVEL_CONFIG, config.get(METRICS_RECORDING_LEVEL));\n\tadminProperties.put(AdminClientConfig.METRICS_RECORDING_LEVEL_CONFIG, config.get(METRICS_RECORDING_LEVEL));\n\tadminProperties.put(AdminClientConfig.METRICS_SAMPLE_WINDOW_MS_CONFIG, config.get(METRICS_SAMPLE_WINDOW_MS));\n\tadminProperties.put(AdminClientConfig.METRICS_RECORD", "CodeBleu_score": 29.835372200472293}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\tString clientId = config.get(CLIENT_ID_KEY);", "CodeBleu_score": 11.228461810515853}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\tif (node.isObject()) {\nMap<String, JsonNode> fields = node.fields();\nif (fields.size() == 1) {\nreturn readSimpleKey(fields.get(payloadFieldName));\n}\nreturn readCompositeKey(node);\n}\nreturn readSimpleKey(node);\n}", "CodeBleu_score": 24.81646769958536}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tif (node.isObject()) {\nif (payloadFieldName!= null) {\nif (node.has(payloadFieldName)) {\nreturn get(node.get(payloadFieldName));\n}\n}\nIterator<String> fieldNames = node.fieldNames();\nif (fieldNames.hasNext()) {\nreturn readCompositeKey(node);\n}\n}\nreturn readSimpleKey(node);\n}", "CodeBleu_score": 30.01937176870252}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tif (node.isObject()) {\nif (fieldNames.hasNext()) {\nreturn readCompositeKey(node);\n}\nreturn readSimpleKey(node);\n}\nreturn readSimpleKey(node);\n}", "CodeBleu_score": 16.82988487604842}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tString topicName = delegate\n.topicNameFor\n(\nid\n,\nprefix\n,\ndelimiter\n)\n;\n\nif (topicName == null) {\nreturn topicName;\n}\n\nif (topicName.length() > 0) {\nfor (int i = 0; i < topicName.length(); i++) {\nchar c = topicName.charAt(i);\nif (isValidTopicNameCharacter(c)) {\ncontinue;\n}\n\nif (replacementCharacter == null) {\nreturn topicName;\n}\n\ntopicName = topicName.substring(0, i)\n+ replacementCharacter\n+ topicName.substring(i + 1);\n}\n}\n\nreturn topicName;\n}", "CodeBleu_score": 35.56952165076856}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tStringBuilder builder = new StringBuilder();\nString topicName = delegate.topicNameFor(id, prefix, delimiter);\nfor (int i = 0; i < topicName.length(); i++) {\nchar c = topicName.charAt(i);\nif (isValidTopicNameCharacter(c)) {\nbuilder.append(c);\n} else {\nbuilder.append(replacementCharacter);\n}\n}\nString result = builder.toString();\nif (result.equals(topicName)) {\nreturn topicName;\n} else {\nwarn(\"Topic name '\" + topicName + \"' is invalid and will be replaced with '\" + result + \"'.\");\nreturn result;\n}\n}", "CodeBleu_score": 47.28531687406041}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\treturn topicNameFor(id, prefix, delimiter, replacementCharacter);\n}", "CodeBleu_score": 5.699543562215667}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\tsuper(connectorType, connectorConfig, queue);\n\tthis.connectorConfig = connectorConfig;\n\tthis.queue = queue;\n\tthis.replacedErrorHandler = replacedErrorHandler;\n\tthis.producerThrowable = new AtomicReference<>();\n\tthis.maxRetriesOnError = getMaxRetriesOnError(connectorConfig);\n\tthis.retryCount = replacedErrorHandler == null? 0 : replacedErrorHandler.retryCount;\n}", "CodeBleu_score": 50.785816298471765}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\tthis.connectorType = connectorType;\n\tthis.connectorConfig = connectorConfig;\n\tthis.queue = queue;\n\tthis.replacedErrorHandler = replacedErrorHandler;\n\tthis.maxRetries = getMaxRetriesOnError(connectorConfig);\n\tthis.producerThrowableRef = new AtomicReference<Throwable>(null);\n}", "CodeBleu_score": 43.367599207220465}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\n}", "CodeBleu_score": 10.3990398260886}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\tfor (Field field : fields) {\nString fieldName = field.getName();\nif (configuration.containsKey(fieldName)) {\nif (field.isCollection()) {\nfor (Object value : configuration.getCollection(fieldName)) {\nfield.validate(value);\n}\n}\nelse {\nfield.validate(configuration.get(fieldName));\n}\n}\nelse {\nfield.validate(null);\n}\n}\nif (errorMessages.size() > 0) {\nthrow new ConfigException(errorMessages.get(0));\n}\n}", "CodeBleu_score": 33.45579914618352}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\tfor\n(Field field\n:\nfields\n)\n{\nif\n(field\n.\nget\ngetValue\n(configuration\n)\n==\nnull\n)\n{\ncontinue\n;\n}\nfor\n(ValidationResult validationResult\n:\nfield\n.\nvalidate\n(configuration\n)\n)\n{\nif\n(validationResult\n.\nhasErrors\n(\n)\n)\n{\nthrow\nnew\nConfigException\n(validationResult\n.\ngetFirstErrorMessage\n(\n)\n)\n;\n}\n}\n}\n}", "CodeBleu_score": 24.238674991871044}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\tfor (Entry<String, Field> entry : fields.entrySet()) {\nString key = entry.getKey();\nField field = entry.getValue();\nif (configuration.hasKey(key)) {\nString value = configuration.getString(key);\nif (field.validate(value)) {\ncontinue;\n}\n}\nthrow new ConfigException(field.getErrorMessage(key));\n}\n}", "CodeBleu_score": 37.813390513762684}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.isPrimitive()) {\nreturn oldSchema;\n}\n\nSchemaBuilder builder = SchemaBuilder.struct();\n\n// Copy fields from the old schema to the new schema\nfor (Schema.Field field : oldSchema.getFields()) {\nif (nestedFields.contains(field.name())) {\ncontinue;\n}\n\nbuilder.field(field.name(), field.schema());\n}\n\n// Add fields from the specified headers to the new schema\nfor (Map.Entry<String, Header> headerEntry : headerToProcess.entrySet()) {\nString headerName = headerEntry.getKey();\nHeader header = headerEntry.getValue();\n\nif (headerName.equals(fieldName)) {\n// The header is for this field\nif (header.value().equals(Schema.OPTIONAL)) {\n// The header is for an optional field\nbuilder.optionalField(fieldName, header.schema());\n} else if (header.value().equals(Schema.REPEATED)) {\n// The header is for a repeated field\nbuilder.array(header.schema());\n} else {\n// The header is for a required field\nbuilder.field(fieldName, header.schema());\n}\n} else {\n// The header is for a nested field\nif (header.value().equals(Schema.OPTIONAL)) {\n// The header is for an optional nested field\nbuilder.optionalField(headerName, header.schema());\n} else if (header.value().equals(Schema.REPEATED)) {\n// The header is for a repeated nested field\nbuilder.array(header.schema());\n} else {\n// The header is for a required nested field\nbuilder.field(headerName, header.schema());\n}\n}\n}\n\n// Build the new schema\nSchema newSchema = builder.build();\n\n// Log debug information about the fields copied and added\nif (level == 0) {\ntrace(\"Copied fields from old schema to new schema: \" + oldSchema.getFields());\ntrace(\"Added fields from headers to new schema: \" + headerToProcess.entrySet());\n}\n\nreturn newSchema;\n}", "CodeBleu_score": 37.647117568541205}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.isPrimitive()) {\nreturn oldSchema;\n} else {\nSchemaBuilder builder = SchemaBuilder.struct();\nbuilder.name(oldSchema.name());\nbuilder.namespace(oldSchema.namespace());\nbuilder.doc(oldSchema.doc());\nbuilder.version(oldSchema.version());\nbuilder.default(oldSchema.default());\nbuilder.flags(oldSchema.flags());\nbuilder.add(\"schema\", oldSchema);\nfor (String header : headerToProcess.keySet()) {\nbuilder.add(header, headerToProcess.get(header));\n}\nfor (String field : oldSchema.fields()) {\nif (nestedFields.contains(field)) {\nbuilder.add(field, buildNewSchema(field, oldSchema.getField(field).schema(), headerToProcess, nestedFields, level + 1));\n} else {\nbuilder.add(field, oldSchema.getField(field));\n}\n}\nreturn builder.build();\n}\n}", "CodeBleu_score": 32.84034796655021}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.isPrimitive()) {\nreturn oldSchema;\n}\nSchemaBuilder builder = SchemaBuilder.struct();\nfor (Schema.Field field : oldSchema.getFields()) {\nif (nestedFields.contains(field.name())) {\ncontinue;\n}\nif (headerToProcess.containsKey(field.name())) {\nbuilder.field(field.name(), field.schema());\n} else {\nbuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, level + 1));\n}\n}\nfor (String headerName : headerToProcess.keySet()) {\nif (nestedFields.contains(headerName)) {\ncontinue;\n}\nbuilder.field(headerName, headerToProcess.get(headerName).schema());\n}\nreturn builder.build();\n}", "CodeBleu_score": 31.53712210285205}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\tString snapshotString\n=\nsource\n.\nget\n(\nSNAPSHOT_KEY\n)\n.\ntoString\n(\n)\n;\nreturn\nsnapshotString\n==\nnull\n?\nnull\n:\nvalueOf\n(\nsnapshotString\n.\ntoUpperCase\n(\n)\n)\n;\n}", "CodeBleu_score": 15.786999147527986}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tString snapshotString\n=\nsource\n.\nget\n(\nSNAPSHOT_KEY\n)\n.\ntoString\n(\n)\n;\nif\n(\nsnapshotString\n!=\nnull\n)\n{\nreturn\nSnapshotRecord\n.\nvalueOf\n(\nsnapshotString\n.\ntoUpperCase\n(\n)\n)\n;\n}\nreturn\nnull\n;\n}", "CodeBleu_score": 21.137103025991795}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tString snapshotString = source\n.get\n(\nSNAPSHOT_KEY\n)\n.\ngetString\n(\n)\n;\nif\n(\nsnapshotString\n==\nnull\n)\n{\nreturn\nnull\n;\n}\nreturn\nvalueOf\n(\nsnapshotString\n.\ntoUpperCase\n(\n)\n)\n;\n}", "CodeBleu_score": 18.216818420606696}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null) {\n\t\treturn Optional.empty();\n\t}\n\tString[] split = version.split(\"\\\\.\");\n\tif (split.length < 2) {\n\t\treturn Optional.empty();\n\t}\n\tString[] split2 = split[0].split(\"-\");\n\treturn Optional.of(Float.parseFloat(split2[0]));\n}", "CodeBleu_score": 47.25647821180111}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOf(parts, 2);\n\t}\n\tString[] hyphens = parts[0].split(\"-\");\n\tif (hyphens.length > 1) {\n\t\tparts[0] = hyphens[0];\n\t}\n\ttry {\n\t\treturn Optional.of(Float.parseFloat(parts[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 61.2592236251524}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null) {\n\t\treturn Optional.empty();\n\t}\n\tString[] parts = version.split(\"\\\\.\", 2);\n\tif (parts.length < 2) {\n\t\treturn Optional.empty();\n\t}\n\tString[] parts2 = parts[1].split(\"-\");\n\tif (parts2.length < 1) {\n\t\treturn Optional.empty();\n\t}\n\ttry {\n\t\treturn Optional.of(Float.parseFloat(parts2[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 51.00541989765151}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\treturn Mono\n.zip(Mono.just(clusterName), Mono.just(connectName), Mono.just(connector))\n.flatMap(tuple -> {\nfinal String cluster = tuple.getT1();\nfinal String connect = tuple.getT2();\nfinal NewConnectorDTO connectorDTO = tuple.getT3();\nreturn Mono.just(createAccessContext(cluster, connect, connectorDTO, exchange))\n.flatMap(accessContext -> {\nreturn Mono.just(validateAccess(accessContext))\n.flatMap(validated -> {\nreturn Mono.just(kafkaConnectService.createConnector(cluster, connect, connectorDTO))\n.map(connectorDTO1 -> ResponseEntity\n.ok()\n.body(connectorDTO1))\n.onErrorResume(e -> {\nreturn Mono.just(e)\n.map(error -> {\nif (error instanceof ConnectException) {\nreturn ResponseEntity\n.status(HttpStatus.INTERNAL_SERVER_ERROR)\n.body(error.getMessage());\n} else {\nreturn ResponseEntity\n.status(HttpStatus.BAD_REQUEST)\n.body(error.getMessage());\n}\n});\n});\n});\n})\n.flatMap(responseEntity -> {\nreturn Mono.just(auditOperation(responseEntity, exchange))\n.map(audit -> ResponseEntity\n.ok()\n.body(responseEntity));\n});\n});\n}", "CodeBleu_score": 35.570142987363674}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\treturn Mono.zip(Mono.just(clusterName), Mono.just(connectName), Mono.just(connector))\n.flatMap(t -> Mono.just(new AccessContext(t.getT1(), t.getT2(), AccessAction.CREATE_CONNECTOR)))\n.flatMap(validateAccess)\n.flatMap(context -> kafkaConnectService.createConnector(context.getCluster(), context.getConnect(), context.getConnector()))\n.map(connector -> ResponseEntity.ok(connectorMapper.toDto(connector)))\n.doOnNext(signal -> audit.audit(signal, exchange))\n.onErrorResume(e -> Mono.just(ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build()));\n}", "CodeBleu_score": 30.52889989602512}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\treturn Mono", "CodeBleu_score": 11.271291722980747}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\treturn Mono\n.zip(\nMono.just(clusterName),\nMono.just(connectName),\nMono.just(connectorName),\nMono.just(exchange))\n.flatMap(tuple -> {\nString cluster = tuple.getT1();\nString connect = tuple.getT2();\nString connector = tuple.getT3();\nServerWebExchange exchange1 = tuple.getT4();\nreturn Mono.just(buildAccessContext(cluster, connect, DELETE_CONNECTOR))\n.flatMap(accessContext -> validateAccess(accessContext, exchange1))\n.flatMap(accessContext -> deleteConnector(cluster, connect, connector, exchange1));\n})\n.doOnNext(response -> audit(response, operationName, audit))\n.onErrorResume(error -> {\naudit(error, operationName, audit);\nreturn Mono.just(ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build());\n})\n.map(response -> ResponseEntity.ok().build());\n}", "CodeBleu_score": 35.456103425962226}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\treturn Mono.deferContextual(context -> {\nString operationName = \"deleteConnector\";\n\n// Build the AccessContext\nAccessContext accessContext = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.actions(connectActions)\n.build();\n\n// Validate access\nreturn validateAccess(accessContext, exchange)\n.then(Mono.deferContextual(ctx -> {\n// Build the operation params\nOperationParams operationParams = OperationParams.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connector(connectorName)\n.build();\n\n// Call the Kafka Connect Service\nreturn kafkaConnectService.deleteConnector(operationParams)\n.map(response -> ResponseEntity.status(response.getStatusCode()).build())\n.doOnEach(signal -> audit(operationName, signal, operationParams))\n.onErrorResume(e -> {\nlog.error(String.format(\"Error while deleting connector %s in cluster %s on connect %s\", connectorName, clusterName, connectName), e);\nreturn Mono.just(ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build());\n});\n}))\n.onErrorResume(e -> {\nlog.error(String.format(\"Error while deleting connector %s in cluster %s on connect %s\", connectorName, clusterName, connectName), e);\nreturn Mono.just(ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build());\n});\n})\n.onErrorResume(e -> {\nlog.error(String.format(\"Error while deleting connector %s in cluster %s on connect %s\", connectorName, clusterName, connectName), e);\nreturn Mono.just(ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build());\n});\n}", "CodeBleu_score": 44.429956830087924}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\nreturn Mono.defer(() -> {\n\n// build AccessContext\nAccessContext accessContext = buildAccessContext(clusterName, connectName, DELETE_CONNECTOR);\n\n// validate access\nMono<ResponseEntity<Void>> response = validateAccess(accessContext, exchange);\n\n// if access is valid, call kafkaConnectService to delete connector\nreturn response.flatMap(r -> {\nif (r.getStatusCode().is2xxSuccessful()) {\nreturn kafkaConnectService.deleteConnector(clusterName, connectName, connectorName)\n.map(r2 -> ResponseEntity.ok().build());\n}\nreturn Mono.just(r);\n});\n\n});\n}", "CodeBleu_score": 31.588269353901723}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\treturn Mono.defer(() -> {\ntry {\nreturn Mono.just(new ResponseEntity<>(null, HttpStatus.OK));\n} catch (Exception e) {\nreturn Mono.error(e);\n}\n}).doOnEach(signal -> audit(clusterName, connectName, connectorName, action, signal, exchange));\n}", "CodeBleu_score": 14.577824945621481}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\treturn Mono.justOrEmpty(exchange.getAttribute(ACCESS_CONTEXT_KEY))\n.map(accessContext -> {\nreturn accessContext.build(clusterName, connectName, connectorName, action.getOperationName(), action.getOperationParams())\n.validateAccess()\n.flatMap(context -> {\nreturn kafkaConnectService.updateConnectorState(context.getCluster(), context.getConnectDetails(), context.getActions(), context.getOperationName(), context.getOperationParams())\n.map(response -> ResponseEntity.ok().build())\n.doOnSuccess(response -> {\nauditService.audit(context.getCluster(), context.getConnectDetails(), context.getActions(), context.getOperationName(), context.getOperationParams(), response);\n})\n.doOnError(error -> {\nauditService.audit(context.getCluster(), context.getConnectDetails(), context.getActions(), context.getOperationName(), context.getOperationParams(), error);\n});\n});\n})\n.defaultIfEmpty(ResponseEntity.status(HttpStatus.FORBIDDEN).build())\n.switchIfEmpty(ResponseEntity.status(HttpStatus.NOT_FOUND).build())\n.onErrorResume(error -> {\nauditService.audit(clusterName, connectName, connectorName, action.getOperationName(), action.getOperationParams(), error);\nreturn Mono.justOrEmpty(error);\n})\n.onErrorMap(error -> {\nif (error instanceof ConnectException) {\nreturn ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR).build();\n}\nreturn ResponseEntity.status(HttpStatus.FORBIDDEN).build();\n});\n}", "CodeBleu_score": 26.5799495020142}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\treturn Mono\n.defer(\n() -> {\nCluster cluster = getCluster(clusterName);\nConnectDetails connectDetails = getConnectDetails(clusterName, connectName);\nConnectAction connectAction = getConnectAction(action);\nString operationName = \"updateConnectorState\";\nMap<String, Object> operationParams = new HashMap<>();\noperationParams.put(\"clusterName\", clusterName);\noperationParams.put(\"connectName\", connectName);\noperationParams.put(\"connectorName\", connectorName);\noperationParams.put(\"action\", action);\nAccessContext accessContext = AccessContext\n.builder()\n.cluster(cluster)\n.connectDetails(connectDetails)\n.actions(Collections.singletonList(connectAction))\n.operationName(operationName)\n.operationParams(operationParams)\n.build();\nreturn validateAccess(accessContext)\n.flatMap(validatedAccessContext -> {\nreturn kafkaConnectService\n.updateConnectorState(validatedAccessContext, connectorName)\n.doOnNext(responseEntity -> {\naudit(validatedAccessContext, ResponseEntity.ok().build());\n})\n.thenReturn(ResponseEntity.ok().build());\n});\n}\n)\n.doOnEach(signal -> {\nif (signal.getKind().isOnNext()) {\naudit(signal.getThrowable());\n}\n}\n)\n.doOnCancel(() -> {\naudit(null);\n}\n);\n}", "CodeBleu_score": 38.772417841098125}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\trequest: Request<ConnectorPluginConfigValidationRequestDTO>,\n\tclusterName: String,\n\tconnectName: String,\n\tpluginName: String\n}", "CodeBleu_score": 28.389352466194502}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\tcluster: String,\n\tconnectName: String,\n\tpluginName: String,\n\trequestBody: ConnectorPluginConfigValidationRequestDTO\n}", "CodeBleu_score": 30.526761725542183}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\tString clusterName\n\tString connectName\n\tString pluginName\n\tConnectorPluginConfigValidationRequestDTO requestBody\n\tMono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\tvalidateConnectorPluginConfig\n\t", "CodeBleu_score": 23.200405843553227}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\tSpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n\tbuilder.initializers(new InitializingBean() {\n\t\t@Override\n\t\tpublic void afterPropertiesSet() throws Exception {\n\t\t\tdynamicConfigPropertiesInitializer.initialize();\n\t\t}\n\t});\n\treturn builder.run(args);\n}", "CodeBleu_score": 39.751366950850475}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\tSpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n\tbuilder.initializers(new InitializingBean() {\n\t\t@Override\n\t\tpublic void afterPropertiesSet() throws Exception {\n\t\t\tdynamicConfigPropertiesInitializer.initialize();\n\t\t}\n\t});\n\tConfigurableApplicationContext context = builder.run(args);\n\treturn context;\n}", "CodeBleu_score": 38.374836292743446}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t.initializers(dynamicConfigPropertiesInitializer)\n\t\t.run(args);\n}", "CodeBleu_score": 37.38165382725288}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\treturn search == null?\nt -> true :\nt -> t.getConnector().getDisplayName().toLowerCase().contains(search.toLowerCase()) ||\nt.getConnector().getTags().stream().anyMatch(tag -> tag.toLowerCase().contains(search.toLowerCase()));\n}", "CodeBleu_score": 35.78692171608899}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\treturn search == null? p -> true : p -> getStringsForSearch(p).stream().anyMatch(s -> s.containsIgnoreCase(search));\n}", "CodeBleu_score": 40.218210493156235}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\tif (search == null) {\n\t\treturn input -> true;\n\t}\n\treturn input -> {\n\t\tif (input == null) {\n\t\t\treturn false;\n\t\t}\n\t\treturn input.getConnector().getDisplayName().containsIgnoreCase(search) || input.getConnector().getId().containsIgnoreCase(search);\n\t};\n}", "CodeBleu_score": 51.779723312698444}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\nMap<String, Object> flattenedMap = new HashMap<>();\nif (propertiesMap == null) {\nreturn flattenedMap;\n}\nfor (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\nString key = entry.getKey();\nObject value = entry.getValue();\nif (value instanceof Map) {\nMap<String, Object> nestedMap = (Map<String, Object>) value;\nMap<String, Object> nestedFlattenedMap = flattenClusterProperties(prefix + \".\" + key, nestedMap);\nflattenedMap.putAll(nestedFlattenedMap);\n} else {\nflattenedMap.put(prefix + \".\" + key, value);\n}\n}\nreturn flattenedMap;\n}", "CodeBleu_score": 47.28119256995645}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\tMap<String, Object> flattenedMap = new HashMap<>();\nfor (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\nString key = entry.getKey();\nObject value = entry.getValue();\nif (value instanceof Map) {\nMap<String, Object> nestedMap = (Map<String, Object>) value;\nMap<String, Object> nestedFlattenedMap = flattenClusterProperties(prefix == null? key : prefix + \".\" + key, nestedMap);\nflattenedMap.putAll(nestedFlattenedMap);\n} else {\nflattenedMap.put(prefix == null? key : prefix + \".\" + key, value);\n}\n}\nreturn flattenedMap;\n}", "CodeBleu_score": 45.068838544002475}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\tif (propertiesMap == null) {\nreturn new HashMap<>();\n}\nMap<String, Object> flattenedMap = new HashMap<>();\nfor (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\nString key = prefix == null? entry.getKey() : prefix + \".\" + entry.getKey();\nif (entry.getValue() instanceof Map) {\nflattenedMap.putAll(flattenClusterProperties(key, (Map<String, Object>) entry.getValue()));\n} else {\nflattenedMap.put(key, entry.getValue());\n}\n}\nreturn flattenedMap;\n}", "CodeBleu_score": 44.799909815478564}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n configDef.define(SslConfig.SSL_TRUSTSTORE_LOCATION_CONFIG, Type.STRING, null, Importance.LOW, \"Path to the truststore\");\n configDef.define(SslConfig.SSL_TRUSTSTORE_PASSWORD_CONFIG, Type.PASSWORD, null, Importance.LOW, \"Password for the truststore\");\n configDef.define(SslConfig.SSL_KEYSTORE_LOCATION_CONFIG, Type.STRING, null, Importance.LOW, \"Path to the keystore\");\n configDef.define(SslConfig.SSL_KEYSTORE_PASSWORD_CONFIG, Type.PASSWORD, null, Importance.LOW, \"Password for the keystore\");\n configDef.define(SaslConfig.SASL_MECHANISM, Type.STRING, null, Importance.LOW, \"SASL mechanism to use\");\n configDef.define(SaslConfig.SASL_JAAS_CONFIG, Type.STRING, null, Importance.LOW, \"JAAS config to use\");\n configDef.define(SaslConfig.SASL_KERBEROS_SERVICE_NAME, Type.STRING, null, Importance.LOW, \"Kerberos service name\");\n configDef.define(SaslConfig.SASL_KERBEROS_KINIT_CMD, Type.STRING, null, Importance.LOW, \"Path to the Kerberos kinit command\");\n configDef.define(SaslConfig.SASL_KERBEROS_KINIT_CMD_PATH, Type.STRING, null, Importance.LOW, \"Path to the Kerberos kinit command\");\n configDef.define(SaslConfig.SASL_KERBEROS_KINIT_CMD_ARGS, Type.STRING, null, Importance.LOW, \"Arguments to the Kerberos kinit command\");\n configDef.define(SaslConfig.SASL_KERBEROS_KINIT_CMD_ENV, Type.STRING, null, Importance.LOW, \"Environment variables to the Kerberos kinit command\");\n configDef.define(SaslConfig.SASL_KERBEROS_KINIT_CMD_USER, Type.STRING, null, Importance.LOW, \"User to the Kerberos kinit command\");\n configDef.define(SaslConfig.SASL_KERBEROS_KINIT_CMD_PRINCIPAL, Type.STRING", "CodeBleu_score": 42.11353692475368}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n configDef.define(KAFKA_SSL_TRUSTSTORE_LOCATION_CONFIG, Type.PASSWORD, \"\", Importance.LOW, \"The location of the truststore file for SSL authentication.\");\n configDef.define(KAFKA_SSL_TRUSTSTORE_PASSWORD_CONFIG, Type.PASSWORD, \"\", Importance.LOW, \"The password for the truststore file for SSL authentication.\");\n configDef.define(KAFKA_SSL_KEYSTORE_LOCATION_CONFIG, Type.PASSWORD, \"\", Importance.LOW, \"The location of the keystore file for SSL authentication.\");\n configDef.define(KAFKA_SSL_KEYSTORE_PASSWORD_CONFIG, Type.PASSWORD, \"\", Importance.LOW, \"The password for the keystore file for SSL authentication.\");\n configDef.define(KAFKA_SASL_JAAS_CONFIG, Type.PASSWORD, \"\", Importance.LOW, \"The JAAS configuration for SASL authentication.\");\n configDef.define(KAFKA_SASL_MECHANISM_CONFIG, Type.PASSWORD, \"\", Importance.LOW, \"The SASL mechanism to use.\");\n return configDef.configKeys().stream()\n.filter(key -> key.startsWith(KAFKA_SSL_) || key.startsWith(KAFKA_SASL_))\n.collect(toSet());\n }", "CodeBleu_score": 50.20930665866076}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n addClientSslSupport(configDef);\n addClientSaslSupport(configDef);\n return configDef.configKeys().stream()\n.filter(key -> key.type() == ConfigDef.Type.PASSWORD)\n.collect(Collectors.toSet());\n }", "CodeBleu_score": 60.54178943393731}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn Mono.just(clusterDescription)\n.map(ClusterDescription::getAuthorizedOperations)\n.map(authorizedOperations -> authorizedOperations.contains(Operation.ALTER) && authorizedOperations.contains(Operation.ALL))\n.filter(allow -> allow)\n.map(allow -> ClusterFeature.KAFKA_ACL_EDIT)\n.switchIfEmpty(Mono.empty())\n;\n}", "CodeBleu_score": 35.893725431430305}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn Mono.defer(() -> {\nif (clusterDescription.getAclViewEnabled()) {\nreturn Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n}\nelse {\nreturn Mono.empty();\n}\n});\n}", "CodeBleu_score": 21.61900193274452}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn Mono.defer(() -> Mono.justOrEmpty(clusterDescription.getAclAuthorizations())", "CodeBleu_score": 12.873845619856938}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\nfor (TopicPartition topicPartition : prevRange.keySet()) {\nFromToOffset fromToOffset = prevRange.get(topicPartition);\nlong beginOffset = fromToOffset.getFromOffset();\nlong endOffset = fromToOffset.getToOffset();\nlong numMessagesToPoll = endOffset - beginOffset;\nlong numMessagesToRead = numMessagesToPoll + 1;\nlong numMessagesToReadPerPartition = numMessagesToRead / this.numPartitions;\nlong numMessagesToReadPerPartitionRoundedUp = ceil(numMessagesToReadPerPartition);\nlong numMessagesToReadPerPartitionWithOffsetAdjustment = numMessagesToReadPerPartitionRoundedUp + 1;\nlong numMessagesToReadPerPartitionWithOffsetAdjustmentRoundedUp = ceil(numMessagesToReadPerPartitionWithOffsetAdjustment);\nlong numMessagesToReadPerPartitionWithOffsetAdjustmentRoundedUpWithBeginOffsetAdjustment = numMessagesToReadPerPartitionWithOffsetAdjustmentRoundedUp + beginOffset;\nlong endOffsetForPartition = numMessagesToReadPerPartitionWithOffsetAdjustmentRoundedUpWithBeginOffsetAdjustment - 1;\nnextRange.put(topicPartition, new FromToOffset(beginOffset, endOffsetForPartition));\n}\nreturn nextRange;\n}", "CodeBleu_score": 27.359445025395303}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n\nfor (TopicPartition topicPartition : prevRange.keySet()) {\nlong startOffset = prevRange.get(topicPartition).from;\nlong endOffset = prevRange.get(topicPartition).to;\n\n// Determine the number of messages to poll per partition\nlong numMessagesToPoll = Math.min(maxMessagesPerPoll, endOffset - startOffset);\n\n// Adjust the start offset based on the number of messages to poll\nlong newStartOffset = startOffset + numMessagesToPoll;\n\n// Ensure the start offset does not go below the beginning offset\nnewStartOffset = Math.max(newStartOffset, beginOffsets.get(topicPartition));\n\n// Add the new start offset to the next range\nnextRange.put(topicPartition, new FromToOffset(newStartOffset, endOffset));\n}\n\nreturn nextRange;\n}", "CodeBleu_score": 29.161962521947522}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n// Initialize the next range map with the previous range\nif (prevRange!= null) {\nfor (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\nTopicPartition topicPartition = entry.getKey();\nFromToOffset fromToOffset = entry.getValue();\nnextRange.put(topicPartition, fromToOffset);\n}\n}\n// Calculate the number of messages to poll per partition\nint messagesToPoll = getMessagesToPoll();\n// Iterate over each topic partition in the next range map\nfor (Map.Entry<TopicPartition, FromToOffset> entry : nextRange.entrySet()) {\nTopicPartition topicPartition = entry.getKey();\nFromToOffset fromToOffset = entry.getValue();\n// Get the current offset for the topic partition\nlong currentOffset = fromToOffset.getFrom();\n// Get the beginning offset for the topic partition\nlong beginOffset = fromToOffset.getTo();\n// Calculate the number of messages to poll for the topic partition\nlong messagesToPollForPartition = Math.min(messagesToPoll, beginOffset - currentOffset);\n// Calculate the start offset for the topic partition\nlong startOffset = currentOffset + messagesToPollForPartition;\n// Adjust the start offset if it is less than the beginning offset\nif (startOffset < beginOffset) {\nstartOffset = beginOffset;\n}\n// Update the next range map with the new start offset\nnextRange.put(topicPartition, new FromToOffset(startOffset, beginOffset));\n}\nreturn nextRange;\n}", "CodeBleu_score": 32.321775866825696}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\t\tif (isLegacyModeEnabled()) {\n\t\tdoLaunchLegacy(input);\n\t} else {\n\t\tdoLaunchConsumer(input);\n\t}\n\tscheduleAtFixedRate(new Runnable() {\n\t\tpublic void run() {\n\t\t\tupdateLastSecondBytesRead();\n\t\t}\n\t}, 1, 1, SECONDS);\n}", "CodeBleu_score": 10.011314040476462}, {"code": "public void doLaunch(final MessageInput input){\n\ttry {\nif (isLegacyModeEnabled) {\ndoLaunchLegacy(input);\n} else {\ndoLaunchConsumer(input);\n}\n} catch (final Exception e) {\nLOG.error(\"Error while launching the input\", e);\n}\n}", "CodeBleu_score": 12.543077212935271}, {"code": "public void doLaunch(final MessageInput input){\n\tif (isLegacyModeEnabled) {\ndoLaunchLegacy(input);\n} else {\ndoLaunchConsumer(input);\n}\nlastSecondBytesRead = 0L;\nscheduleAtFixedRate(new Runnable() {\n@Override\npublic void run() {\nlastSecondBytesRead = 0L;\n}\n}, 1000, 1000, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 13.013712615732143}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\ttry {\n// Load custom properties from a configuration string\nProperties customProps = new Properties();\ncustomProps.load(new StringReader(customProperties));\n// Merge custom properties with existing properties\nprops.putAll(customProps);\n} catch (IOException e) {\nlog.error(\"Error loading custom properties: \" + e.getMessage());\n}\n}", "CodeBleu_score": 31.766745030487563}, {"code": "private void insertCustomProperties(Properties props){\n\ttry {\nString customProps = System.getProperty(\"custom.properties\");\nif (customProps!= null) {\nProperties customPropsObj = new Properties();\ncustomPropsObj.load(new StringReader(customProps));\nprops.putAll(customPropsObj);\n}\n} catch (IOException e) {\nlogger.error(\"Unable to load custom properties from configuration string: \" + e.getMessage());\n}\n}", "CodeBleu_score": 40.62212687644587}, {"code": "private void insertCustomProperties(Properties props){\n\tString customProperties = null;\ntry {\ncustomProperties = getConfiguration().getString(\"customProperties\");\n} catch (Exception e) {\n}\nif (customProperties!= null) {\nProperties customProps = new Properties();\ncustomProps.load(new StringReader(customProperties));\nprops.putAll(customProps);\n}\n}", "CodeBleu_score": 37.97446297331368}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\tlong writtenBytes = 0L;\nint writtenMessages = 0;\nfor (RawMessageEvent entry : entries) {\nif (entry == null) {\ncontinue;\n}\nif (entry.getPayload() == null) {\ncontinue;\n}\ntry {\nwriteToJournal(entry);\nwrittenBytes += entry.getPayload().length;\nwrittenMessages++;\n} catch (Exception e) {\nif (e instanceof MessageQueueException) {\nthrow (MessageQueueException) e;\n}\nif (e instanceof IOException) {\nthrow new MessageQueueException(\"Failed to write to journal\", e);\n}\nif (e instanceof RuntimeException) {\nthrow new MessageQueueException(\"Failed to write to journal\", e);\n}\nif (e instanceof Error) {\nthrow new MessageQueueException(\"Failed to write to journal\", e);\n}\n}\n}\nthis.writtenBytes.addAndGet(writtenBytes);\nthis.writtenMessages.addAndGet(writtenMessages);\n}", "CodeBleu_score": 26.073738861800788}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\tlong writtenBytes = 0;\nint writtenMessages = 0;\nfor (RawMessageEvent entry : entries) {\nif (entry == null) {\ncontinue;\n}\ntry {\nwriteToJournal(entry);\nwrittenBytes += entry.getMessageBytes();\nwrittenMessages++;\n} catch (Exception e) {\nthrow new MessageQueueException(e);\n}\n}\nthis.writtenBytes.addAndGet(writtenBytes);\nthis.writtenMessages.addAndGet(writtenMessages);\n}", "CodeBleu_score": 17.41963384125646}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\tif (entries == null) {\nreturn;\n}\nif (entries.isEmpty()) {\nreturn;\n}\nlong messageBytes = 0L;\nfor (RawMessageEvent entry : entries) {\nif (entry == null) {\ncontinue;\n}\nmessageBytes += entry.getMessageBytes();\n}\nif (messageBytes == 0L) {\nreturn;\n}\nlong start = System.currentTimeMillis();\nint attempt = 0;\nwhile (true) {\ntry {\nwriteToJournal(entries);\nbreak;\n} catch (Exception e) {\nif (attempt >= MAX_WRITE_ATTEMPTS) {\nthrow new MessageQueueException(\"Failed to write to journal for \" + messageQueue.getQueueName() + \" after \" + MAX_WRITE_ATTEMPTS + \" attempts.\", e);\n}\nattempt++;\nlong sleepTime = attempt * attempt * 100L;\nif (sleepTime > MAX_SLEEP_TIME) {\nsleepTime = MAX_SLEEP_TIME;\n}\nlong end = System.currentTimeMillis();\nlong elapsed = end - start;\nif (elapsed < sleepTime) {\ntry {\nThread.sleep(sleepTime - elapsed);\n} catch (InterruptedException e1) {\n}\n}\n}\n}\nwrittenBytes.addAndGet(messageBytes);\nwrittenMessages.addAndGet(entries.size());\n}", "CodeBleu_score": 28.59771825100835}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\tif (messages.isEmpty()) {\nreturn;\n}\nint max = 0;\nfor (Message message : messages) {\nif (message.getQueueId() > max) {\nmax = message.getQueueId();\n}\n}\nif (max > 0) {\nacknowledgedMessages.mark(messages.size());\n}\n}", "CodeBleu_score": 19.79677866092543}, {"code": "public void acknowledge(List<Message> messages){\n\tif (messages\n.isEmpty()) {\nreturn;\n}\n\nMessage message = messages\n.get(messages\n.size() - 1);\nint messageID = message\n.getMessageID();\n\nif (messageID > max) {\nmax = messageID;\n}\n\nacknowledgedMessages\n.incrementAndGet();\n}", "CodeBleu_score": 25.074115091011105}, {"code": "public void acknowledge(List<Message> messages){\n\tint max\n=\nInteger\n.\nMIN_VALUE\n;\nfor\n(\nMessage\nmessage\n:\nmessages\n)\n{\nif\n(\nmessage\n.\ngetQueueId\n(\n)\n>\nmax\n)\n{\nmax\n=\nmessage\n.\ngetQueueId\n(\n)\n;\n}\n}\nif\n(\nmax\n>\n=\n0\n)\n{\nacknowledgedMessages\n.\nadd\n(\nmax\n)\n;\n}\n}", "CodeBleu_score": 14.234731836833166}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\tif (metrics!= null) {\nmetrics.forEach((name, metric) -> {\nif (name.startsWith(LocalKafkaJournal.class.getName())) {\ntry {\nmetrics.register(name.substring(LocalKafkaJournal.class.getName().length() + 1), metric);\n} catch (Exception e) {\nLOG.warn(\"Failed to register legacy metric {} under name {}\", name, name.substring(LocalKafkaJournal.class.getName().length() + 1));\n}\n}\n});\n}\n}", "CodeBleu_score": 32.04872174781941}, {"code": "private void registerLegacyMetrics(){\n\tfinal String metricNamePrefix = \"kafka.server.KafkaServer\";", "CodeBleu_score": 2.298935804623041}, {"code": "private void registerLegacyMetrics(){\n\tString[] legacyMetricNames = {", "CodeBleu_score": 1.0619841717295042}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\treturn metricRegistry\n.register(metricName, new HdrHistogram(1000000000L))\n.timer();\n}", "CodeBleu_score": 6.36341251516345}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\tTimer timer = null;\ntry\n{\ntimer = metricRegistry.timer(metricName);\n}\ncatch (IllegalArgumentException e)\n{\ntimer = metricRegistry.timer(metricRegistry.name(metricName, \"timer\"));\n}\nreturn timer;\n}", "CodeBleu_score": 32.02353054671742}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\treturn metricRegistry\n.register(metricName, new HdrHistogram(TimeUnit.SECONDS.toNanos(1)))\n.timer();\n}", "CodeBleu_score": 6.9746976538676115}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\nmetricRegistry.register(name, new Gauge<Long>() {\npublic Long getValue() {\nlong uncommitted = size();\nif (uncommitted == 0) {\nreturn 0L;\n}\nif (committedOffset == DEFAULT_OFFSET) {\nreturn logEndOffset - logStartOffset;\n}\nreturn logEndOffset - committedOffset;\n}\n});\n} catch (IllegalArgumentException e) {\n// ignore\n}\n}", "CodeBleu_score": 43.58530193833303}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\nmetricRegistry.register(name, new Gauge<Long>() {\npublic Long getValue() {\ntry {\nlong size = size();\nif (size == 0) {\nreturn 0L;\n}\nif (committedOffset.get() == DEFAULT_OFFSET) {\nreturn logEndOffset.get() - logStartOffset.get();\n}\nreturn logEndOffset.get() - committedOffset.get();\n} catch (Exception e) {\nreturn 0L;\n}\n}\n});\n} catch (IllegalArgumentException e) {\n}\n}", "CodeBleu_score": 49.1184884202992}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\nmetricRegistry.register(name, new Gauge<Long>() {\n@Override\npublic Long getValue() {\ntry {\nlong size = size();\nif (size == 0) {\nreturn 0L;\n}\nlong logStartOffset = log.getLogStartOffset();\nlong logEndOffset = log.getLogEndOffset();\nlong committedOffset = log.getCommittedOffset();\nif (committedOffset == logStartOffset) {\nreturn logEndOffset - logStartOffset;\n} else {\nreturn logEndOffset - committedOffset;\n}\n} catch (Exception e) {\nreturn 0L;\n}\n}\n});\n} catch (IllegalArgumentException e) {\n}\n}", "CodeBleu_score": 45.70635084078604}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\nif (isDebugEnabled) {\nlogger.debug(\"No messages to write\");\n}\n} else {\nByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\nif (isDebugEnabled) {\nlogger.debug(\"Writing \" + messageSet.size() + \" messages (\" + messageSet.sizeInBytes() + \" bytes)\");\n}\nByteBufferMessageSet.append(messageSet, producer.getAppendPosition(), producer.getProducerData().getTopic(), producer.getProducerData().getPartition(), producer.getProducerData().getRecordMetadata().getPartition(), producer.getProducerData().getRecordMetadata().getOffset());\nproducer.getProducerData().setLastOffset(producer.getProducerData().getRecordMetadata().getOffset());\nproducer.getProducerData().setLastMessageSize(payloadSize);\n}\nreturn producer.getProducerData().getLastOffset();\n}", "CodeBleu_score": 32.2469662462063}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\nlog.debug(\"No messages to write\");\nreturn -1;\n}\nByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\nlog.debug(\"Message set size: {}\", messageSet.sizeInBytes());\nlong lastOffset = append(messageSet);\nlog.debug(\"Wrote {} messages to offset {}\", messages.size(), lastOffset);\nreturn lastOffset;\n}", "CodeBleu_score": 29.720345120370755}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\nlog.debug(\"No messages to write\");\n} else {\nlog.debug(\"Writing {} messages of size {} bytes\", messages.size(), payloadSize);\n}\nByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\nlong lastOffset = log.append(messageSet);\nlog.debug(\"Wrote {} messages to offset {}\", messages.size(), lastOffset);\nreturn lastOffset;\n}", "CodeBleu_score": 31.012707117170123}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\t// lock the client map\n\tlock\n\t// get the list of clients for the specified cluster ID\n\tList<AdminClient> clients = adminClientMap.get(clusterPhyId)\n\t// if no clients are found, return\n\tif clients == null\n\t\tunlock\n\t\treturn\n\t// log the start of the closing process\n\tlog \"Starting to close Kafka AdminClient instances for cluster ID \" + clusterPhyId\n\t// attempt to close all clients in the list\n\tclients.each { client ->\n\t\ttry {\n\t\t\tclient.close()\n\t\t} catch (Exception e) {\n\t\t\tlog \"Failed to close Kafka AdminClient instance for cluster ID \" + clusterPhyId + \": \" + e.message\n\t\t\te.printStackTrace()\n\t\t}\n\t}\n\t// log a success message if all clients are closed successfully\n\tlog \"Successfully closed all Kafka AdminClient instances for cluster ID \" + clusterPhyId\n\t// release the lock\n\tunlock\n}", "CodeBleu_score": 20.071973008029488}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\tsynchronized(adminClientMap) {\n\t\tList<AdminClient> adminClients = adminClientMap.get(clusterPhyId);\n\t\tif (adminClients!= null) {\n\t\t\tLOGGER.info(\"Closing Kafka AdminClient instances for cluster ID: \" + clusterPhyId);\n\t\t\tfor (AdminClient adminClient : adminClients) {\n\t\t\t\ttry {\n\t\t\t\t\tadminClient.close();\n\t\t\t\t\tLOGGER.info(\"Closed Kafka AdminClient instance for cluster ID: \" + clusterPhyId);\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\tLOGGER.error(\"Error closing Kafka AdminClient instance for cluster ID: \" + clusterPhyId, e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 32.705208279340106}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\tsynchronized (adminClients) {\n\t\tList<AdminClient> adminClients = this.adminClients.get(clusterPhyId);\n\t\tif (adminClients == null) {\n\t\t\treturn;\n\t\t}\n\t\tlog.info(\"Closing Kafka AdminClient instances for cluster ID \" + clusterPhyId);\n\t\tfor (AdminClient adminClient : adminClients) {\n\t\t\ttry {\n\t\t\t\tadminClient.close();\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.error(\"Error closing Kafka AdminClient instance for cluster ID \" + clusterPhyId + \" : \" + e.getMessage());\n\t\t\t}\n\t\t}\n\t\tlog.info(\"Kafka AdminClient instances for cluster ID \" + clusterPhyId + \" closed successfully\");\n\t}\n}", "CodeBleu_score": 34.882537024648286}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\tboolean success = true\nif (adminClientList!= null) {\nfor (AdminClient adminClient : adminClientList) {\ntry {\nadminClient.close(30000)\n} catch (Exception e) {\nsuccess = false\nlog.error(\"Error closing AdminClient for cluster \" + clusterPhyId + \": \" + e.getMessage())\n}\n}\n}\nreturn success\n}", "CodeBleu_score": 38.762843626812035}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true;\n\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30000);\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Error closing admin client for cluster ID \" + clusterPhyId + \": \" + e.getMessage());\n\t\t\tsuccess = false;\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 53.10872525426473}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true;\n\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30000);\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Error closing admin client for cluster ID {}: {}\", clusterPhyId, e.getMessage());\n\t\t\tsuccess = false;\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 58.83225664633089}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\tisRunning", "CodeBleu_score": 1.380906757561752}, {"code": "public void stop() {\n\t\tif (isRunning) {\n\t\tapp.stop();\n\t\tint attempts = 0;\n\t\twhile (isRunning && attempts < 5) {\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(\"The thread was interrupted during sleep\");\n\t\t\t}\n\t\t\tattempts++;\n\t\t}\n\t\tif (isRunning) {\n\t\t\tthrow new IllegalStateException(\"The application failed to stop\");\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 46.67343748717303}, {"code": "public void stop() {\n\tif (isRunning) {\napp.stop();\nint attempts = 0;\nwhile (isRunning && attempts < 5) {\ntry {\nThread.sleep(1000);\n} catch (InterruptedException e) {\nthrow new IllegalStateException(e);\n}\nattempts++;\n}\n}\napp = null;\n}", "CodeBleu_score": 52.38160356458456}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner eurekaServerRunner = new EurekaServerRunner(config)\n\teurekaServerRunner.enableTls()\n\teurekaServerRunner.setKeyStore(keyStoreFile, keyStorePassword)\n\teurekaServerRunner.setTrustStore(trustStoreFile, trustStorePassword)\n\teurekaServerRunner.start()\n\treturn eurekaServerRunner\n}", "CodeBleu_score": 33.40243094888232}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\tEurekaServerRunner eurekaServerRunner = new EurekaServerRunner(config)\nenableTls\nsetKeyStore\nsetTrustStore\nstart\n}", "CodeBleu_score": 21.9867779521411}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\tEurekaServerRunner eurekaServerRunner = new EurekaServerRunner(config)\nenableTls\nsetKeyStore\nsetTrustStore\nstart\nreturn eurekaServerRunner\n}", "CodeBleu_score": 27.537274932152055}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner client = EurekaClientRunner.builder()\n\t\t\t.withConfig(config)\n\t\t\t.withEurekaServer(server)\n\t\t\t.withServiceName(\"testservice\")\n\t\t\t.enableTlsClient()\n\t\t\t.build()\n\t\t\t.start()\n\t\t\t.get();\n\treturn client;\n}", "CodeBleu_score": 42.555204988428905}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\trunner.enableTlsClient();\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 62.8496435850721}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\trunner.enableTlsClient();\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 62.8496435850721}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t\tKeyTool ca = new KeyTool(CA_NAME, CA_KEY_STORE, CA_KEY_STORE_PASSWORD, CA_TRUST_STORE, CA_TRUST_STORE_PASSWORD, CA_ALIAS, CA_PASSWORD);\n\tca.createCA();\n\tca.saveCert(CA_NAME);\n\tca.saveKeyAndCert(CA_NAME);\n\n\tKeyTool server = new KeyTool(SERVER_NAME, SERVER_KEY_STORE, SERVER_KEY_STORE_PASSWORD, SERVER_TRUST_STORE, SERVER_TRUST_STORE_PASSWORD, SERVER_ALIAS, SERVER_PASSWORD);\n\tserver.createServer(CA_NAME);\n\tserver.saveCert(SERVER_NAME);\n\tserver.saveKeyAndCert(SERVER_NAME);\n\n\tKeyTool client = new KeyTool(CLIENT_NAME, CLIENT_KEY_STORE, CLIENT_KEY_STORE_PASSWORD, CLIENT_TRUST_STORE, CLIENT_TRUST_STORE_PASSWORD, CLIENT_ALIAS, CLIENT_PASSWORD);\n\tclient.createClient(CA_NAME);\n\tclient.saveCert(CLIENT_NAME);\n\tclient.saveKeyAndCert(CLIENT_NAME);\n\n\tKeyTool secondCA = new KeyTool(SECOND_CA_NAME, SECOND_CA_KEY_STORE, SECOND_CA_KEY_STORE_PASSWORD, SECOND_CA_TRUST_STORE, SECOND_CA_TRUST_STORE_PASSWORD, SECOND_CA_ALIAS, SECOND_CA_PASSWORD);\n\tsecondCA.createCA();\n\tsecondCA.saveCert(SECOND_CA_NAME);\n\tsecondCA.saveKeyAndCert(SECOND_CA_NAME);\n\n\tKeyTool secondClient = new KeyTool(SECOND_CLIENT_NAME, SECOND_CLIENT_KEY_STORE, SECOND_CLIENT_KEY_STORE_PASSWORD, SECOND_CLIENT_TRUST_STORE, SECOND_CLIENT_TRUST_STORE_PASSWORD, SECOND_CLIENT_ALIAS, SECOND_CLIENT_PASSWORD);\n\tsecondClient.createClient(SECOND_CA_NAME);\n\tsecondClient.saveCert(SECOND_CLIENT_NAME);\n\tsecondClient.saveKeyAndCert(SECOND_CLIENT_NAME);\n}", "CodeBleu_score": 21.85089773530494}, {"code": "static void createCertificates() throws Exception{\n\t\tKeyTool keyTool = new KeyTool();\n\tkeyTool.createCA();\n\tkeyTool.createServerCert();\n\tkeyTool.createClientCert();\n\tkeyTool.createSecondCACert();\n\tkeyTool.createSecondClientCert();\n}", "CodeBleu_score": 9.357452793838561}, {"code": "static void createCertificates() throws Exception{\n\t\t// Create a KeyTool instance\n\tKeyTool keyTool = new KeyTool();\n\n\t// Create a CA certificate and save it\n\tkeyTool.createCA();\n\tkeyTool.saveCert(\"ca.crt\");\n\n\t// Create a server certificate and save it\n\tkeyTool.createServer();\n\tkeyTool.saveCert(\"server.crt\");\n\n\t// Create a client certificate and save it\n\tkeyTool.createClient();\n\tkeyTool.saveCert(\"client.crt\");\n\n\t// Create a second CA certificate and save it\n\tkeyTool.createCA();\n\tkeyTool.saveCert(\"ca2.crt\");\n\n\t// Create a second client certificate and save it\n\tkeyTool.createClient();\n\tkeyTool.saveCert(\"client2.crt\");\n\n\t// Create a KeyStore for the CA and save it\n\tkeyTool.createKeyStore(\"ca.jks\", \"ca.crt\", \"ca.key\");\n\tkeyTool.saveKeyAndCert(\"ca.jks\", \"ca.crt\", \"ca.key\");\n\n\t// Create a KeyStore for the server and save it\n\tkeyTool.createKeyStore(\"server.jks\", \"server.crt\", \"server.key\");\n\tkeyTool.saveKeyAndCert(\"server.jks\", \"server.crt\", \"server.key\");\n\n\t// Create a KeyStore for the client and save it\n\tkeyTool.createKeyStore(\"client.jks\", \"client.crt\", \"client.key\");\n\tkeyTool.saveKeyAndCert(\"client.jks\", \"client.crt\", \"client.key\");\n\n\t// Create a KeyStore for the second CA and save it\n\tkeyTool.createKeyStore(\"ca2.jks\", \"ca2.crt\", \"ca2.key\");\n\tkeyTool.saveKeyAndCert(\"ca2.jks\", \"ca2.crt\", \"ca2.key\");\n\n\t// Create a KeyStore for the second client and save it\n\tkeyTool.createKeyStore(\"client2.jks\", \"client2.crt\", \"client2.key\");\n\tkeyTool.saveKeyAndCert(\"client2.jks\", \"client2.crt\", \"client2.key\");\n}", "CodeBleu_score": 21.643227965641604}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\tif (assertion.getAsBoolean()) {\nreturn;\n}\nlong startTime = currentTimeMillis();\nlong endTime = startTime + seconds * 1000;\nwhile (currentTimeMillis() < endTime) {\nif (assertion.getAsBoolean()) {\nreturn;\n}\nyield\n}\nthrow new RuntimeException(\"Assertion failed after \" + seconds + \" seconds\");\n}", "CodeBleu_score": 47.34766064114519}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\tif (assertion.getAsBoolean()) return;\nlong timeLimit = currentTimeMillis() + (seconds * 1000);\nwhile (!assertion.getAsBoolean() && currentTimeMillis() < timeLimit) {\nyield\n}\nif (!assertion.getAsBoolean()) {\nthrow new RuntimeException(\"Assertion failed after \" + seconds + \" seconds.\");\n}\n}", "CodeBleu_score": 35.91493302483151}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\tlong currentTimeMillis = System.currentTimeMillis();\nlong timeLimit = currentTimeMillis + seconds * 1000L;\nwhile (System.currentTimeMillis() < timeLimit) {\nif (assertion.getAsBoolean()) {\nreturn;\n}\n}\nthrow new RuntimeException(\"Assertion failed after \" + seconds + \" seconds.\");\n}", "CodeBleu_score": 48.060762461586606}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\t// Create a certificate builder with the public key and CA information\n\tX509V3CertificateBuilder certBuilder = new X509V3CertificateBuilder(ca, serialNumber, notBefore, notAfter, subject, new X509CertificateHolder(keyPair.getPublic().getEncoded()));\n\n\t// Add key usage and basic constraints extensions to the certificate\n\tcertBuilder.addExtension(Extension.keyUsage, false, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment));\n\tcertBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(true));\n\n\t// Sign the certificate with the private key and return the signed X509 certificate\n\treturn new JcaX509CertificateConverter().getCertificate(certBuilder.build(keyPair.getPrivate()));\n}", "CodeBleu_score": 45.22631441968984}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\tX509V3CertificateGenerator certGen = new X509V3CertificateGenerator();\n\n// Set the basic fields\ncertGen.setSerialNumber(BigInteger.valueOf(System.currentTimeMillis()));\ncertGen.setIssuerDN(new X500Principal(ca));\ncertGen.setNotBefore(new Date(System.currentTimeMillis()));\ncertGen.setNotAfter(new Date(System.currentTimeMillis() + 1000 * 60 * 60 * 24 * 365));\ncertGen.setSubjectDN(new X500Principal(\"CN=Test\"));\ncertGen.setPublicKey(keyPair.getPublic());\ncertGen.setSignatureAlgorithm(\"SHA256withRSA\");\n\n// Add extensions\ncertGen.addExtension(X509Extensions.BasicConstraints.id, false, new BasicConstraints(true));\ncertGen.addExtension(X509Extensions.KeyUsage.id, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment));\n\n// Generate the certificate\nX509Certificate cert = certGen.generate(keyPair.getPrivate());\n\nreturn cert;\n}", "CodeBleu_score": 37.52255015282237}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tX509Certificate cert = certBuilder.build(keyPair.getPrivate(), ca);\n\treturn cert;\n}", "CodeBleu_score": 27.476896448995657}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\tField field = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\t\tfield.setAccessible(true);\n\t\t\teurekaHttpClient = (EurekaHttpClient) field.get(eurekaTransport);\n\t\t} catch (NoSuchFieldException | IllegalAccessException e) {\n\t\t\tlogger.error(\"Failed to retrieve EurekaHttpClient instance.\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 41.12013578407009}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\tEurekaHttpClient eurekaHttpClient = this.eurekaHttpClient;\nif (eurekaHttpClient == null) {\ntry {\nField field = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\nfield.setAccessible(true);\neurekaHttpClient = (EurekaHttpClient) field.get(eurekaTransport);\n} catch (Exception e) {\nlog.error(\"Failed to retrieve EurekaHttpClient\", e);\n}\nthis.eurekaHttpClient = eurekaHttpClient;\n}\nreturn eurekaHttpClient;\n}", "CodeBleu_score": 45.98216020263241}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\tField field = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\t\tfield.setAccessible(true);\n\t\t\teurekaHttpClient = (EurekaHttpClient) field.get(eurekaTransport);\n\t\t} catch (NoSuchFieldException | IllegalAccessException e) {\n\t\t\tlog.error(\"Could not retrieve EurekaHttpClient instance: \" + e.getMessage());\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 38.26463510854081}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\tList<String> services = new ArrayList<>();\nList<Application> applications = getApplications();\nif (applications.isEmpty()) {\nreturn services;\n}\nfor (Application application : applications) {\nservices.addAll(application.getInstances().stream().map(InstanceInfo::getAppName).map(String::toLowerCase).collect(Collectors.toList()));\n}\nreturn services;\n}", "CodeBleu_score": 40.07289358811262}, {"code": "public List<String> getServices(){\n\tList<String> services = new ArrayList<>();\nList<Application> applications = getApplications();\nif (applications == null || applications.isEmpty()) {\nreturn services;\n}\nfor (Application application : applications) {\nList<InstanceInfo> instances = application.getInstances();\nif (instances == null || instances.isEmpty()) {\ncontinue;\n}\nfor (InstanceInfo instance : instances) {\nString name = instance.getAppName();\nif (name == null) {\ncontinue;\n}\nservices.add(name.toLowerCase());\n}\n}\nreturn services;\n}", "CodeBleu_score": 43.16344297241215}, {"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<String>();\n\tList<Application> applications = getApplications();\n\tif (applications.isEmpty()) {\n\t\treturn services;\n\t}\n\tfor (Application application : applications) {\n\t\tList<InstanceInfo> instances = application.getInstances();\n\t\tfor (InstanceInfo instance : instances) {\n\t\t\tservices.add(instance.getAppName().toLowerCase());\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 45.329690718914385}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor composite = (DiscoveryCompositeHealthContributor) entry.getValue();\n\t\t\tfor (HealthIndicator indicator : composite.getIndicators()) {\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(entry.getKey(), indicator);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\thealthContributors.put(entry.getKey(), entry.getValue());\n\t\t}\n\t}\n}", "CodeBleu_score": 47.10286091625952}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor compositeHealthContributor = (DiscoveryCompositeHealthContributor) entry.getValue();\n\t\t\tfor (HealthContributor indicator : compositeHealthContributor.getIndicators()) {\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(entry.getKey(), indicator);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\thealthContributors.put(entry.getKey(), entry.getValue());\n\t\t}\n\t}\n}", "CodeBleu_score": 46.1195545221613}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\thealthContributors.entrySet().forEach(entry -> {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\t((DiscoveryCompositeHealthContributor) entry.getValue()).getIndicators().forEach(indicator -> {\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(indicator.getName(), indicator);\n\t\t\t\t}\n\t\t\t});\n\t\t} else {\n\t\t\thealthContributors.put(entry.getKey(), entry.getValue());\n\t\t}\n\t});\n}", "CodeBleu_score": 37.94858571141167}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances.isEmpty()) {\n\t\tthrow new RuntimeException(\"No instances of provider-application available\");\n\t}\n\tServiceInstance instance = instances.get(0);\n\tString uri = instance.getUri().toString();\n\tString response = restTemplate.postForObject(uri + \"/echo\", \"Hello World\", String.class);\n\treturn response;\n}", "CodeBleu_score": 60.122388591742514}, {"code": "public String hello(){\n\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\nif (instances == null || instances.isEmpty()) {\nthrow new RuntimeException(\"No instances of provider-application were found\");\n}\nServiceInstance instance = instances.get(0);\nString uri = instance.getUri().toString();\nRestTemplate restTemplate = new RestTemplate();\nreturn restTemplate.postForObject(uri + \"/echo\", \"Hello World\", String.class);\n}", "CodeBleu_score": 48.951273298174115}, {"code": "public String hello(){\n\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\nif (instances.size() == 0) {\nthrow new RuntimeException(\"No instances of provider-application were found.\");\n}\nServiceInstance instance = instances.get(0);\nRestTemplate restTemplate = new RestTemplate();\nreturn restTemplate.postForObject(instance.getUri() + \"/echo\", \"Hello, World!\", String.class);\n}", "CodeBleu_score": 45.75343349114445}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t\t// BEGINNING OF CODE\n\tString serviceInstanceName = \"provider-application\";\n\tString response = null;\n\tRestTemplate restTemplate = new RestTemplate();\n\ttry {\n\t\tURI uri = lbClient.choose(serviceInstanceName).getUri();\n\t\tresponse = restTemplate.postForObject(uri + \"/echo\", \"Hello World!\", String.class);\n\t} catch (Exception e) {\n\t\tthrow new RuntimeException(\"Could not locate the required service instance: \" + serviceInstanceName, e);\n\t}\n\treturn response;\n\t// END OF CODE\n}", "CodeBleu_score": 43.02330196111199}, {"code": "public String world(){\n\t\tServiceInstance provider = serviceInstanceLoadBalancerClient.choose(\"provider-application\");\n\tURI uri = provider.getUri();\n\tString response = restTemplate.postForObject(uri.toString() + \"/echo\", \"Hello World!\", String.class);\n\treturn response;\n}", "CodeBleu_score": 57.406674222477584}, {"code": "public String world(){\n\tURI uri = loadBalancerClient.choose(\"provider-application\").getUri();\nRestTemplate restTemplate = new RestTemplate();\nreturn restTemplate.postForObject(uri + \"/echo\", \"world\", String.class);\n}", "CodeBleu_score": 26.514904305677216}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tsynchronizedSet = serverMap.get(serviceName);\n\t} else {\n\t\tsynchronizedSet = new HashSet<>();\n\t\tserverMap.put(serviceName, synchronizedSet);\n\t}\n\tsynchronizedSet.add(new Server(ip, port));\n\tlogger.info(\"Service registered: \" + serviceName + \" \" + ip + \" \" + port);\n\treturn true;\n}", "CodeBleu_score": 52.000066148100665}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tsynchronizedSet\nputIfAbsent\nget\ninfo\nadd\nserverMap\nputIfAbsent\nget\ninfo\nadd\nserver\nreturn\ntrue\n}", "CodeBleu_score": 26.114538177175504}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\nif (!serverMap.containsKey(serviceName)) {\nserverMap.put(serviceName, new HashSet<>());\n}\n\nServer server = new Server(ip, port);\nserverMap.get(serviceName).add(server);\n\nreturn true;\n}", "CodeBleu_score": 57.354325229765266}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tServer server = serverMap.get(serviceName).remove(new Server(ip, port));\n\t\tif (server!= null) {\n\t\t\tlogger.info(\"Deregistering \" + server.toString() + \" from \" + serviceName);\n\t\t\treturn true;\n\t\t}\n\t}\n\tlogger.info(\"Could not deregister \" + ip + \":\" + port + \" from \" + serviceName);\n\treturn false;\n}", "CodeBleu_score": 50.4446725835499}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tServer server = new Server(serviceName, ip, port);\n\tif (serverMap.containsKey(serviceName)) {\n\t\tif (serverMap.get(serviceName).remove(server)) {\n\t\t\tSystem.out.println(\"Deregistering \" + server + \" from \" + serviceName);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 43.37691195038854}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tSet<Server> servers = serverMap.get(serviceName);\n\t\tfor (Server server : servers) {\n\t\t\tif (server.getIp().equals(ip) && server.getPort() == port) {\n\t\t\t\tservers.remove(server);\n\t\t\t\tlogger.info(\"Deregistering server \" + ip + \":\" + port + \" from service \" + serviceName);\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 40.879336608689265}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = getAnnotationAttributes(metadata, RibbonClients.class);\n\tif (attributes!= null) {\n\t\tString defaultConfiguration = (String) attributes.get(DEFAULT_CONFIGURATION_KEY);\n\t\tif (StringUtils.hasText(defaultConfiguration)) {\n\t\t\tString name = this.nameGenerator.generateName(metadata);\n\t\t\tregistry.registerBeanDefinition(name, new RootBeanDefinition(RibbonClientConfiguration.class));\n\t\t\tClientConfiguration clientConfiguration = new ClientConfiguration(defaultConfiguration);\n\t\t\tclientConfiguration.setName(name);\n\t\t\tregistry.registerBeanDefinition(name, new RootBeanDefinition(ClientConfiguration.class, clientConfiguration));\n\t\t}\n\t}\n}", "CodeBleu_score": 36.561112637325195}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\t// 1. \u83b7\u53d6RibbonClients\u6ce8\u89e3\u4e2d\u7684\u5c5e\u6027\n\tMap<String, Object> attributes = getAttributes(metadata);\n\tif (attributes!= null) {\n\t\t// 2. \u5982\u679c\u5c5e\u6027\u4e2d\u5305\u542bdefaultConfiguration\uff0c\u5219\u751f\u6210\u4e00\u4e2a\u552f\u4e00\u7684bean name\uff0c\u5e76\u6ce8\u518c\u4e00\u4e2aclient configuration bean\n\t\tif (attributes.containsKey(DEFAULT_CONFIGURATION_KEY)) {\n\t\t\tString beanName = getUniqueClientConfigurationBeanName(registry);\n\t\t\tregisterClientConfiguration(registry, beanName, attributes);\n\t\t\t// 3. \u6ce8\u518c\u4e00\u4e2aRibbonClientsConfiguration bean\n\t\t\tregisterRibbonClientsConfigurationBean(registry, beanName);\n\t\t}\n\t\telse {\n\t\t\t// 4. \u5426\u5219\uff0c\u6ce8\u518c\u4e00\u4e2aRibbonClientsConfiguration bean\n\t\t\tregisterRibbonClientsConfigurationBean(registry, null);\n\t\t}\n\t}\n}", "CodeBleu_score": 24.0084307714706}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = getAttributes(metadata);\n\tString defaultConfiguration = (String) attributes.get(DEFAULT_CONFIGURATION_KEY);\n\tif (defaultConfiguration!= null) {\n\t\tString name = generateName(defaultConfiguration);\n\t\tregisterClientConfiguration(name, defaultConfiguration, registry);\n\t}\n}", "CodeBleu_score": 40.09326695417883}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\tif (serviceId == null) {\n\t\tthrow new NullPointerException(\"serviceId cannot be null\");\n\t}\n\tif (request == null) {\n\t\tthrow new NullPointerException(\"request cannot be null\");\n\t}\n\tServiceInstance instance = null;\n\ttry {\n\t\tinstance = choose(serviceId, request.getContext());\n\t} catch (Exception e) {\n\t\tlogger.error(\"Unable to choose service instance for serviceId: \" + serviceId, e);\n\t}\n\treturn instance;\n}", "CodeBleu_score": 36.29383236562242}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\treturn null;\n}", "CodeBleu_score": 11.883009317135098}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\tif (serviceId == null) {\n\t\tthrow new IllegalArgumentException(\"serviceId must not be null\");\n\t}\n\tif (request == null) {\n\t\tthrow new IllegalArgumentException(\"request must not be null\");\n\t}\n\treturn this.choose(serviceId, request.getContext());\n}", "CodeBleu_score": 25.154252358254148}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\tURI reconstructed = original;\nString host = server.getHost();\nint port = server.getPort();\nString scheme = original.getScheme();\nString path = original.getRawPath();\nString query = original.getRawQuery();\nif (host!= null && port > 0) {\nreconstructed = reconstructed.resolve(String.format(\"%s://%s:%d%s\", scheme, host, port, path));\n}\nif (query!= null && query.length() > 0) {\nreconstructed = reconstructed.resolve(String.format(\"?%s\", query));\n}\nreturn reconstructed;\n}", "CodeBleu_score": 25.669568147297063}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\tif (server == null) {\nthrow new IllegalArgumentException(\"server cannot be null\");\n}\nif (original == null) {\nthrow new IllegalArgumentException(\"original cannot be null\");\n}\nURI reconstructed = null;\ntry {\nreconstructed = new URI(original.getScheme(), null, original.getHost(), original.getPort(), original.getRawPath(), original.getRawQuery(), null);\n} catch (URISyntaxException e) {\nthrow new RuntimeException(e);\n}\nreturn reconstructed;\n}", "CodeBleu_score": 40.60401551888328}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tURI reconstructed = null;\n\tString serviceId = server.getServiceId();\n\tString scheme = original.getScheme();\n\tString host = server.getHost();\n\tint port = server.getPort();\n\tString path = original.getRawPath();\n\tString query = original.getRawQuery();\n\ttry {\n\t\treconstructed = new URI(scheme, null, host, port, path, query, null);\n\t}\n\tcatch (URISyntaxException e) {\n\t\tthrow new RuntimeException(\"Unable to reconstruct URI\", e);\n\t}\n\treturn reconstructed;\n}", "CodeBleu_score": 33.710767562173736}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t\tString serviceName = \"tutu\";\n\tString serverAddr = \"http://127.0.0.1:8080\";\n\tString url = serverAddr + \"/list?serviceName=\" + serviceName;\n\tString json = get(url);\n\tList<TutuServer> servers = parseArray(json, TutuServer.class);\n\treturn servers;\n}", "CodeBleu_score": 16.906552816843316}, {"code": "private List<TutuServer> getServer(){\n\t\tList<TutuServer> servers = new ArrayList<>();\n\tString serverAddr = getServerAddr();\n\tString serviceName = getServiceName();\n\tString url = serverAddr + \"/list?serviceName=\" + serviceName;\n\ttry {\n\t\tString json = get(url);\n\t\tJSONArray array = parseArray(json);\n\t\tfor (int i = 0; i < array.length(); i++) {\n\t\t\tJSONObject obj = array.getJSONObject(i);\n\t\t\tString ip = obj.getString(\"ip\");\n\t\t\tint port = obj.getInt(\"port\");\n\t\t\tTutuServer server = new TutuServer(ip, port);\n\t\t\tservers.add(server);\n\t\t}\n\t} catch (Exception e) {\n\t\tSystem.out.println(\"Failed to get server list: \" + e.getMessage());\n\t}\n\treturn servers;\n}", "CodeBleu_score": 34.38222126802211}, {"code": "private List<TutuServer> getServer(){\n\tString serviceName = \"tutuServer\";\nString serverAddr = \"http://localhost:8080\";\nString url = serverAddr + \"/list\";\nHttpGet httpGet = new HttpGet(url);\nhttpGet.setHeader(\"Content-Type\", \"application/json\");\nhttpGet.setHeader(\"Accept\", \"application/json\");\nCloseableHttpClient httpClient = HttpClients.createDefault();\nCloseableHttpResponse response = httpClient.execute(httpGet);\nHttpEntity entity = response.getEntity();\nString json = EntityUtils.toString(entity);\nList<TutuServer> tutuServerList = new ArrayList<>();\nJSONArray jsonArray = new JSONArray(json);\nfor (int i = 0; i < jsonArray.length(); i++) {\nJSONObject jsonObject = jsonArray.getJSONObject(i);\nString ip = jsonObject.getString(\"ip\");\nint port = jsonObject.getInt(\"port\");\ntutuServerList.add(new TutuServer(ip, port));\n}\nreturn tutuServerList;\n}", "CodeBleu_score": 33.905756708947244}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t\t// Iterate through the configured routes\n\tfor (Route route : routes) {\n\t\t// Check if the incoming path matches the route's pattern\n\t\tif (pathMatcher.match(route.getPattern(), path)) {\n\t\t\t// Extract the target path from the original path\n\t\t\tString targetPath = path.substring(route.getPattern().length());\n\t\t\t// Create a new Route object with the extracted target path and the service ID\n\t\t\treturn new Route(targetPath, route.getServiceId());\n\t\t}\n\t}\n\t// No matching route found\n\treturn null;\n}", "CodeBleu_score": 32.03255809063582}, {"code": "public Route getMatchingRoute(String path){\n\t\tif (path == null) {\n\t\treturn null;\n\t}\n\tfor (Route route : getRoutes()) {\n\t\tif (pathMatcher.match(route.getPattern(), path)) {\n\t\t\treturn new Route(route.getPattern(), route.getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 23.069833234889856}, {"code": "public Route getMatchingRoute(String path){\n\t\tif (path == null) {\n\t\treturn null;\n\t}\n\tfor (Entry<String, String> entry : routes.entrySet()) {\n\t\tString pattern = entry.getKey();\n\t\tString serviceId = entry.getValue();\n\t\tif (pathMatcher.match(pattern, path)) {\n\t\t\tString targetPath = pathMatcher.extractPathWithinPattern(pattern, path);\n\t\t\treturn new Route(targetPath, serviceId);\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 42.19835147890761}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\t// \u83b7\u53d6\u6240\u6709\u5e26\u6709@FeignClient\u6ce8\u89e3\u7684\u7c7b\n\tMap<String, Object> annotatedClasses = getAnnotatedClasses(importingClassMetadata);\n\tif (annotatedClasses.isEmpty()) {\n\t\treturn;\n\t}\n\t// \u904d\u5386\u6240\u6709\u5e26\u6709@FeignClient\u6ce8\u89e3\u7684\u7c7b\n\tfor (Map.Entry<String, Object> entry : annotatedClasses.entrySet()) {\n\t\t// \u83b7\u5f97\u5e26\u6709@FeignClient\u6ce8\u89e3\u7684\u7c7b\n\t\tClass<?> annotatedClass = (Class<?>) entry.getValue();\n\t\t// \u83b7\u5f97\u5e26\u6709@FeignClient\u6ce8\u89e3\u7684\u7c7b\u4e0a\u7684@FeignClient\u6ce8\u89e3\n\t\tFeignClient feignClient = annotatedClass.getAnnotation(FeignClient.class);\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684contextId\n\t\tString contextId = feignClient.contextId();\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684name\n\t\tString[] names = feignClient.name();\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684url\n\t\tString url = feignClient.url();\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684configuration\n\t\tClass<?>[] configuration = feignClient.configuration();\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684fallback\n\t\tClass<?> fallback = feignClient.fallback();\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684fallbackFactory\n\t\tClass<?> fallbackFactory = feignClient.fallbackFactory();\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684path\n\t\tString path = feignClient.path();\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684qualifier\n\t\tString qualifier = feignClient.qualifier();\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684decode404\n\t\tboolean decode404 = feignClient.decode404();\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684validateStatus\n\t\tint[] validateStatus = feignClient.validateStatus();\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684logLevel\n\t\tLogLevel logLevel = feignClient.logLevel();\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684loggerLevel\n\t\tLogger.Level loggerLevel = feignClient.loggerLevel();\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684contract\n\t\tClass<? extends Contract> contract = feignClient.contract();\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684targetType\n\t\tTargetType targetType = feignClient.targetType();\n\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4e0a\u7684", "CodeBleu_score": 30.166270756259927}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tif (registry.containsBeanDefinition(FEIGN_CLIENT_FACTORY_BEAN_NAME)) {\n\t\treturn;\n\t}\n\tMap<String, Object> attributes = new HashMap<>();\n\tattributes.put(FEIGN_CLIENT_FACTORY_BEAN_NAME, Boolean.TRUE);\n\tGenericBeanDefinition definition = new GenericBeanDefinition();\n\tdefinition.setBeanClass(FeignClientFactoryBean.class);\n\tdefinition.setSynthetic(true);\n\tdefinition.setAttribute(FEIGN_CLIENT_FACTORY_BEAN_NAME, Boolean.TRUE);\n\tdefinition.setSource(importingClassMetadata);\n\tdefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n\tdefinition.setAttributes(attributes);\n\tregistry.registerBeanDefinition(FEIGN_CLIENT_FACTORY_BEAN_NAME, definition);\n}", "CodeBleu_score": 21.641245124121433}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\t// \u83b7\u53d6\u626b\u63cf\u5305\n\tString packageToScan = getBasePackage(importingClassMetadata);\n\t// \u626b\u63cf\u5305\n\tSet<BeanDefinition> candidateComponents = findCandidateComponents(packageToScan);\n\tfor (BeanDefinition candidateComponent : candidateComponents) {\n\t\ttry {\n\t\t\t// \u83b7\u53d6\u6ce8\u89e3\u4fe1\u606f\n\t\t\tAnnotationAttributes attributes = AnnotationConfigUtils.attributesFor(candidateComponent);\n\t\t\t// \u83b7\u53d6@FeignClient\u6ce8\u89e3\u4fe1\u606f\n\t\t\tString name = attributes.getString(\"name\");\n\t\t\tString url = attributes.getString(\"url\");\n\t\t\tClass<?> type = attributes.getClass(\"type\");\n\t\t\t// \u6ce8\u518cbean\n\t\t\tregisterBeanDefinition(registry, candidateComponent, name, url, type);\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\tthrow new BeanDefinitionStoreException(\n\t\t\t\t\t\"Failed to read candidate component class: \" + candidateComponent.getBeanClassName(), ex);\n\t\t}\n\t}\n}", "CodeBleu_score": 26.71874836803813}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}]}
