{"instance_id": "1f9f4d85e825", "generation_result": [{"code": "def load_model_from_config(self, half_attention)\n\t\n    model_path = self.model_path\n    if model_path.endswith(\".safetensors\"):\n        from safetensors.torch import load_file\n\n        model_dict = load_file(model_path, device=\"cpu\")\n    else:\n        model_dict = torch.load(model_path, map_location=\"cpu\")\n\n    if \"state_dict\" in model_dict:\n        model_dict = model_dict[\"state_dict\"]\n\n    model_dict = {\n        k: v\n        for k, v in model_dict.items()\n        if k != \"optimizer_states\" and k != \"lr_schedulers\"\n    }\n    model_dict = {\n        k[len(\"model.\") :]: v\n        for k, v in model_dict.items()\n        if k.startswith(\"model.\")\n    }\n    model_dict = {\n        k[len(\"diffusion_model.\") :]: v\n        for k, v in model_dict.items()\n        if k.startswith(\"diffusion_model.\")\n    }\n\n    if half_attention:\n        for k in model_dict:\n            if k.endswith(\".attn.in_proj_weight\"):\n                model_dict[k] = model_dict[k].to(torch.float16)\n\n    model = instantiate_from_config(self.config.model)\n    m, u = model.load_state_dict(model_dict, strict=False)\n    if len(m) > 0:\n        print(\"missing keys:\")\n        print(m)\n    if len(u) > 0:\n        print(\"unexpected keys:\")\n        print(u)\n\n    model = model.half() if half_attention else model\n    model = model.to(self.device)\n    model.eval()\n    if not self.use_memory_efficient_attention:\n        model.model.transformer.set_attn_processor(None)\n    if self.use_memory_efficient_attention:\n        model.model.transformer.set_use_memory_efficient_attention", "CodeBleu_score": 42.54271189001555}, {"code": "def load_model_from_config(self, half_attention)\n\t\n    if self.cache_model_path is not None:\n        if os.path.exists(self.cache_model_path):\n            cache_model_path = self.cache_model_path\n        else:\n            cache_model_path = self.cache_model_path.replace(\".safetensors\", \".pt\")\n        if os.path.exists(cache_model_path):\n            print(f\"Loading model from cache: {cache_model_path}\")\n            try:\n                model = torch.load(cache_model_path, map_location=\"cpu\")\n                if model.get(\"model_config\", None) is not None:\n                    self.model_config = model[\"model_config\"]\n                if model.get(\"model_hash\", None) is not None:\n                    self.model_hash = model[\"model_hash\"]\n                if model.get(\"model_name\", None) is not None:\n                    self.model_name = model[\"model_name\"]\n                if model.get(\"model_path\", None) is not None:\n                    self.model_path = model[\"model_path\"]\n                if model.get(\"model_url\", None) is not None:\n                    self.model_url = model[\"model_url\"]\n                if model.get(\"model_version\", None) is not None:\n                    self.model_version = model[\"model_version\"]\n                if model.get(\"model_weights_path\", None) is not None:\n                    self.model_weights_path = model[\"model_weights_path\"]\n                if model.get(\"model_weights_url\", None) is not None:\n                    self.model_weights_url = model[\"model_weights_url\"]\n                if model.get(\"model_weights_hash\", None) is not None:\n                    self.model_weights_hash = model[\"model_weights_hash\"]\n                if model.get(\"model_weights_name\", None) is not None:\n                    self.model_weights_name = model[\"model_weights_name\"]\n                if model.get(\"model_weights_version\", None) is not None:\n                    self.model_weights_", "CodeBleu_score": 27.647813700118327}, {"code": "def load_model_from_config(self, half_attention)\n\t\n    if self.cache_path is not None:\n        if os.path.exists(self.cache_path):\n            if os.path.getmtime(self.cache_path) > os.path.getmtime(self.model_path):\n                print(\"Loading model from cache\")\n                model = torch.load(self.cache_path)\n                return model\n\n    print(\"Loading model from\", self.model_path)\n    model = instantiate_from_config(self.config.model)\n    model.load_state_dict(load_file(self.model_path, model_dir=self.model_dir))\n\n    if half_attention:\n        model.transformer.attention_pool.attn._qkv = model.transformer.attention_pool.attn._qkv.half()\n\n    model.half()\n    model.eval()\n    if self.device.type == \"cuda\":\n        model.to(memory_format=torch.channels_last)\n        model.apply(self.set_attention_slice)\n\n    self.model = model\n    self.model_as_float()\n    if self.cache_path is not None:\n        print(\"Saving model to cache\")\n        torch.save(self.model, self.cache_path)\n    return self.model\n\n", "CodeBleu_score": 35.603652287898754}]}
{"instance_id": "8dc955007aa2", "generation_result": [{"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n\n    # Create the DDIM sampler\n    ddim = DDIMSampler(model)\n\n    # Extract the batch size from the shape parameter\n    bs = shape[0]\n\n    # Print the eta and steps values\n    print(f\"Using eta = {eta} and {steps} steps\")\n\n    # Sample using the DDIM sampler\n    samples, intermediates = ddim.sample(steps, bs, shape,\n                                          conditioning=cond,\n                                          callback=callback,\n                                          normals_sequence=normals_sequence,\n                                          quantize_x0=quantize_x0,\n                                          eta=eta,\n                                          mask=mask, x0=x0,\n                                          temperature=temperature,\n                                          score_corrector=score_corrector, corrector_kwargs=corrector_kwargs, x_t=x_t)\n\n    # Return the generated samples and intermediate values\n    return samples, intermediates\n\n", "CodeBleu_score": 62.085934740529744}, {"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n    # make sure model is in eval mode.\n    model.eval()\n    # get the batch size from the shape\n    bs = shape[0]\n    print(f'eta: {eta}, steps: {steps}')\n    # create the DDIM sampler.\n    sampler = DDIMSampler(model)\n    # sampling\n    return sampler.sample(steps, bs, shape, cond, eta, callback=callback, normals_sequence=normals_sequence,\n                          mask=mask, x0=x0, quantize_x0=quantize_x0, temperature=temperature,\n                          score_corrector=score_corrector, corrector_kwargs=corrector_kwargs, x_t=x_t)\n\n", "CodeBleu_score": 38.64498347924445}, {"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n    ddim = DDIMSampler(model)\n    bs = shape[0]\n    print(f\"Beginning sampling with eta {eta} and {steps} steps\")\n    return ddim.sample(steps, batch_size=bs, shape=shape, conditioning=cond, eta=eta, callback=callback,\n                       normals_sequence=normals_sequence, mask=mask, x0=x0, quantize_x0=quantize_x0,\n                       temperature=temperature, score_corrector=score_corrector, corrector_kwargs=corrector_kwargs,\n                       x_t=x_t)\n\n", "CodeBleu_score": 44.64526230179873}]}
{"instance_id": "9bdcd9081480", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if self.ema_weights:\n        if context:\n            print(f\"{context}: using ema weights\")\n        self.copy_to(self.ema_weights)\n        yield\n        if context:\n            print(f\"{context}: restored model weights from ema\")\n        self.ema_weights.restore(self.parameters)\n    else:\n        yield", "CodeBleu_score": 39.1557952550063}, {"code": "def ema_scope(self, context=None)\n\t\n    if self.ema_weights is not None:\n        if context is not None:\n            print(f\"{context}: Switching to EMA weights\")\n        self.store()\n        self.copy_to(self.ema_weights)\n        if context is not None:\n            print(f\"{context}: Restoring original weights\")\n        self.restore()\n    else:\n        if context is not None:\n            print(f\"{context}: No EMA weights found\")\n\n", "CodeBleu_score": 52.72890493744489}, {"code": "def ema_scope(self, context=None)\n\t\n    if context is not None:\n        print(f\"[{context}] Switch EMA weights\")\n    self.store()\n    self.copy_to()\n    if context is not None:\n        print(f\"[{context}] Restore original weights\")\n    self.restore()\n\n", "CodeBleu_score": 34.3348474438254}]}
{"instance_id": "14ab009e1c5c", "generation_result": [{"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    sd = torch.load(path, map_location=\"cpu\")[\"state_dict\"]\n    if len(sd.keys()) == 0:\n        sd = {k: v for k, v in sd.items() if not k.startswith('cond_stage_model.')}\n    if ignore_keys:\n        sd = {k: v for k, v in sd.items() if k not in ignore_keys}\n    self.load_state_dict(sd)\n    print(\"Loaded state_dict from [{}]\".format(path))\n    return self\n\n", "CodeBleu_score": 28.4407141623624}, {"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    sd = torch.load(path, map_location=\"cpu\")[\"state_dict\"]\n    if len(sd.keys()) == 0:\n        sd = {k: v for k, v in sd.items() if not k.startswith('cond_stage_model.')}\n    if ignore_keys:\n        sd = {k: v for k, v in sd.items() if k not in ignore_keys}\n    self.load_state_dict(sd, strict=False)\n    self.load_state_dict(sd, strict=False)\n    print(f\"Restored from {path} with new keys {list(sd.keys())} and loaded {len(sd.keys())} of {len(self.state_dict()) + len(ignore_keys)}\")\n\n", "CodeBleu_score": 37.07088552783775}, {"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    sd = torch.load(path, map_location=\"cpu\")[\"state_dict\"]\n    if len(sd.keys()) == 0:\n        sd = {k: v for k, v in sd.items() if k[0] != \".\"}\n    if ignore_keys is not None:\n        sd = {k: v for k, v in sd.items() if k not in ignore_keys}\n    self.load_state_dict(sd, strict=False)\n    self.load_state_dict(sd, strict=False)\n    m, u = self.load_state_dict(sd, strict=False)\n    if len(m) > 0 and self.cfg.get(\"verbose\", False):\n        print(\"missing keys:\")\n        print(m)\n    if len(u) > 0 and self.cfg.get(\"verbose\", False):\n        print(\"unexpected keys:\")\n        print(u)", "CodeBleu_score": 36.81989053699674}]}
{"instance_id": "754176e27b81", "generation_result": [{"code": "def forward(self, input, return_pred_indices=False)\n\t\n    encoded = self.encode(input)\n    decoded = self.decode(encoded)\n    if return_pred_indices:\n        return decoded, self.pred_indices\n    return decoded\n\n", "CodeBleu_score": 30.18247215515689}, {"code": "def forward(self, input, return_pred_indices=False)\n\t\n    encoded = self.encode(input)\n    decoded = self.decode(encoded)\n    diff = torch.abs(input - decoded)\n    if return_pred_indices:\n        pred_indices = torch.argmax(decoded, dim=1)\n        return decoded, diff, pred_indices\n    return decoded, diff\n\n", "CodeBleu_score": 30.512337623973977}, {"code": "def forward(self, input, return_pred_indices=False)\n\t\n    encoded = self.encode(input)\n    decoded = self.decode(encoded)\n    if return_pred_indices:\n        return decoded, self.calc_diff(input, decoded), self.pred_indices\n    else:\n        return decoded, self.calc_diff(input, decoded)\n\n", "CodeBleu_score": 27.059395284144472}]}
{"instance_id": "443df6fdaf0d", "generation_result": [{"code": "def get_input(self, batch, k)\n\t\n    x = batch[k]\n    if len(x.shape) == 3:\n        x = x[..., None]\n    if x.shape[1] != 3:\n        x = x.permute(0, 3, 1, 2)\n    x = F.interpolate(x, self.size, mode=\"bicubic\")\n    if self.training:\n        if self.aug_shift:\n            n, _, h, w = x.shape\n            assert (self.aug_shift <= 0.5) and (self.aug_shift >= -0.5)\n            b = (\n                np.round(np.random.uniform(-self.aug_shift, self.aug_shift, (n, 2)))\n                .astype(int)\n                .clip(-h + 1, h - 1)\n            )\n            x = torch.cat(\n                [\n                    x[:, :, i : i + h - b[k, 0], j : j + w - b[k, 1]]\n                    for k, (i, j) in enumerate(b)\n                ]\n            )\n    return x.contiguous().float()\n\n", "CodeBleu_score": 46.12988821437708}, {"code": "def get_input(self, batch, k)\n\t\n    x = batch[k]\n    if len(x.shape) == 3:\n        x = x[..., None]\n    if x.shape[1] != 3:\n        x = x.permute(0, 3, 1, 2)\n    x = F.interpolate(x, size=self.size, mode=\"bicubic\")\n    if self.training:\n        if self.aug_shift:\n            x = self.shift_x(x)\n        if self.aug_blur:\n            x = self.blur_x(x)\n    x = x.contiguous().float()\n    return x\n\n", "CodeBleu_score": 39.12481247958965}, {"code": "def get_input(self, batch, k)\n\t\n    x = batch[k]\n    if len(x.shape) == 3:\n        x = x[..., None]\n    x = x.permute(0, 3, 1, 2)\n    if self.resize_enabled:\n        x = self.resize(x)\n    x = x.contiguous().float()\n    return x.detach()\n\n", "CodeBleu_score": 25.39251238738935}]}
{"instance_id": "953a2632fc15", "generation_result": [{"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t\n    x, y = batch\n    y_hat = self(x)\n    y_hat_disc = self.get_discriminator_predictions(y_hat)\n    y_disc = self.get_discriminator_predictions(y)\n    loss_disc = self.loss(y_hat_disc, y_disc)\n    loss_ae = self.loss(y_hat, y)\n    loss = loss_ae + loss_disc\n    self.log_dict(\n        {\n            \"train_loss_ae\": loss_ae,\n            \"train_loss_disc\": loss_disc,\n            \"train_loss_total\": loss,\n        },\n        on_step=True,\n        on_epoch=True,\n        prog_bar=True,\n        logger=True,\n    )\n    return loss\n\n", "CodeBleu_score": 16.204714528034895}, {"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t\n    x, y = batch\n    x_hat, z = self(x)\n    if optimizer_idx == 0:\n        loss = self.loss(x, x_hat, z)\n        self.log_dict(\n            {\n                \"train_ae_loss\": loss,\n                \"train_ae_loss_epoch\": loss,\n            },\n            prog_bar=True,\n            on_step=False,\n            on_epoch=True,\n        )\n    elif optimizer_idx == 1:\n        loss = self.loss(x, x_hat, z)\n        self.log_dict(\n            {\n                \"train_disc_loss\": loss,\n                \"train_disc_loss_epoch\": loss,\n            },\n            prog_bar=True,\n            on_step=False,\n            on_epoch=True,\n        )\n    return loss\n\n", "CodeBleu_score": 28.831520372197183}, {"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t\n    x, y = batch\n    y_hat = self(x)\n\n    # train discriminator\n    if optimizer_idx == 0:\n        # Measure discriminator's ability to classify real from generated samples\n        y_hat_real = self.discriminator(x)\n        y_hat_fake = self.discriminator(y_hat.detach())\n        loss_disc_real = self.criterion_disc(y_hat_real, torch.ones_like(y_hat_real))\n        loss_disc_fake = self.criterion_disc(y_hat_fake, torch.zeros_like(y_hat_fake))\n        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n        self.log(\"loss_disc\", loss_disc, prog_bar=True)\n        return loss_disc\n\n    # train generator\n    if optimizer_idx == 1:\n        # adversarial loss is binary cross-entropy\n        loss_adv = self.criterion_adv(self.discriminator(y_hat), torch.ones_like(y_hat))\n        self.log(\"loss_adv\", loss_adv, prog_bar=True)\n        loss = loss_adv\n        if self.lambda_pixel > 0:\n            # pixelwise loss\n            loss_pixel = self.criterion_pixel(y_hat, y)\n            self.log(\"loss_pixel\", loss_pixel, prog_bar=True)\n            loss = loss + self.lambda_pixel * loss_pixel\n        return loss\n\n    raise Exception(\"unreachable\")\n\n", "CodeBleu_score": 27.664498696983948}]}
{"instance_id": "b449b5e8b77f", "generation_result": [{"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t\n    x = self.get_input(batch, self.image_key)\n    if only_inputs:\n        return\n    x_rec = self(x)\n    if plot_ema:\n        with self.ema_scope():\n            x_rec_ema = self(x)\n    x_rec = self.to_rgb(x_rec)\n    if plot_ema:\n        x_rec_ema = self.to_rgb(x_rec_ema)\n    log_dict = {\n        \"inputs\": x,\n        \"reconstructions\": x_rec,\n    }\n    if plot_ema:\n        log_dict[\"reconstructions_ema\"] = x_rec_ema\n    self.log_dict(log_dict, **kwargs)\n\n", "CodeBleu_score": 40.03905083664611}, {"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t\n    x = self.get_input(batch, self.image_key)\n    x = x.to(memory_format=torch.contiguous_format)\n    with self.ema_scope(plot_ema):\n        recon = self(batch)\n        if isinstance(recon, dict):\n            if self.image_key in recon:\n                recon = recon[self.image_key]\n            else:\n                recon = recon[\"sample\"]\n        if self.to_rgb is not None:\n            x = self.to_rgb(x)\n            recon = self.to_rgb(recon)\n        if only_inputs:\n            return x\n        return x, recon\n\n", "CodeBleu_score": 39.3337653577836}, {"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t\n    inputs = self.get_input(batch, self.image_key)\n    reconstructions = self.get_last_output()\n\n    if only_inputs:\n        images_to_log = inputs\n    else:\n        images_to_log = [inputs, reconstructions]\n\n    for i, image_batch in enumerate(images_to_log):\n        image_batch = image_batch.to(self.device)\n        image_batch = self.ema_scope(image_batch) if plot_ema else image_batch\n        image_batch = self.to_rgb(image_batch)\n        self.log_image(image_batch, name=self.image_log_name, step=self.global_step, **kwargs)\n\n", "CodeBleu_score": 32.264191751007615}]}
{"instance_id": "540d089e3481", "generation_result": [{"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    else:\n        raise NotImplementedError('loss type [%s] is not found' % self.loss_type)\n    return loss\n\n", "CodeBleu_score": 55.82990729915077}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    else:\n        raise NotImplementedError('Loss type {} is not recognized.'.format(self.loss_type))\n    return loss\n\n", "CodeBleu_score": 55.99764152796587}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    else:\n        raise NotImplementedError('loss type [%s] is not found' % self.loss_type)\n    return loss", "CodeBleu_score": 55.82990729915077}]}
{"instance_id": "63a08283666f", "generation_result": [{"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    b, c, *spatial = x.shape\n    x_in = x\n    pos = self.positional_embedding(x_in)\n    if self.conditional:\n        c = self.get_learned_conditioning(c)\n    if self.unconditional:\n        c = torch.zeros([b, *self.ch_mult]).to(device=x_in.device)\n    t = torch.randint(0, self.num_timesteps, (b,), device=x_in.device).long()\n    if self.p_losses is not None:\n        x_uncond, x_cond = self.q_sample(x_in, t)\n        x_in = torch.cat([x_uncond, x_cond], dim=0)\n        t = torch.cat([t, t], dim=0)\n    if self.conditional:\n        x_in = torch.cat([x_in, c], dim=1)\n    x_in = self.conv_in(x_in)\n    x_in = self.transformer.forward(x_in, self.timestep_embedding(t), cond=c)\n    x_in = self.conv_out(x_in)\n    if not self.skip_rescale:\n        x_in = self.rescale_output(x_in)\n    if self.out_norm:\n        x_in = self.norm_out(x_in)\n    if self.use_checkpoint:\n        return checkpoint(self.out, x_in, pos)\n    else:\n        return self.out(x_in, pos)\n\n", "CodeBleu_score": 44.34695825341697}, {"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    b, c, h, w = x.shape\n    if not self.training:\n        t = self.test_t\n    else:\n        t = torch.randint(0, self.num_timesteps, (b,)).to(self.device).long()\n    if self.cond_mask_prob != 0:\n        if not self.training:\n            c = self.get_learned_conditioning(c)\n        (c_mask,) = self.get_input(x, self.image_size)\n        # do not condition if we set cond_mask_prob to 0\n        c *= c_mask\n        c = torch.cat((c, c_mask), 1)\n    self.model.eval()\n    with torch.no_grad():\n        x_in = self.q_sample(x, t)\n        x_in = self.conv_in(x_in)\n        x_in = torch.cat((x_in, c), 1)\n        model_out = self.model(x_in, t)\n    if self.cond_mask_prob != 0:\n        out = model_out\n    else:\n        assert len(model_out) == 1\n        out = model_out[0]\n    if self.cond_mask_prob != 0:\n        out = out[:, :3]\n    out = self.conv_out(out)\n    loss = torch.nn.functional.mse_loss(out, x)\n    return loss\n\n", "CodeBleu_score": 44.13154029734771}, {"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    b, c, *spatial = x.shape\n    x_in = x\n    pos = self.get_learned_conditioning(b, *spatial)\n    if c is not None:\n        c = self.q_sample(x_start=x_in, t=self.get_time_steps(x_in, c), noise=torch.randn_like(x_in))\n    else:\n        c = self.get_learned_conditioning(b, *spatial)\n    if self.cond_mask:\n        mask = torch.randint(0, 2, (b,)).to(device=x.device).long()\n        mask = mask[:, None]\n        mask = mask.repeat(1, c.shape[1])\n        mask = mask[:, :, None, None]\n        c = c * (1 - mask)\n    self.model.eval()\n    with torch.no_grad():\n        x_in = self.model.convert_to_fp16(x_in)\n        c = self.model.convert_to_fp16(c)\n        (model_output,), extra = self.model(x_in, c, t=self.get_time_steps(x_in, c), return_dict=False, **kwargs)\n    if self.cond_mask:\n        model_output = model_output * mask + x_in * (1 - mask)\n    if self.clip_denoised:\n        model_output = model_output.clamp(-1, 1)\n    if self.perceptual_weight > 0:\n        if self.perceptual_model == \"clip\":\n            if self.clip_model_name is None:\n                self.clip_model_name = \"ViT-B/32\"\n            clip_in = self.clip_preprocess(model_output).type(self.clip_model.visual.conv1.weight.dtype)\n            image_features = self.clip_model.encode_image(clip_in).float()\n            clip_in = self.clip_preprocess(x).type(self.clip_model.visual", "CodeBleu_score": 42.00318539407453}]}
{"instance_id": "4627e1e8ed62", "generation_result": [{"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # shape specifying (batch, height, width, channel)\n    if self.remap_used:\n        indices = indices.reshape(shape[0], shape[1], shape[2], 1)\n        # indices = indices.permute(0, 3, 1, 2)\n        indices = indices.permute(0, 3, 1, 2).contiguous()\n        # get quantized latent vectors\n        z_q = self.embedding(indices)\n\n        if shape[0] == 1:\n            z_q = z_q.view(self.latent_dim, shape[2], shape[3])\n        else:\n            z_q = z_q.view(z_q.shape[0], self.latent_dim, shape[2], shape[3])\n    else:\n        raise NotImplementedError\n    return z_q\n\n", "CodeBleu_score": 53.51755694457307}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    if indices is None:\n        return None\n    if indices.shape != shape:\n        # gather\n        indices = indices.view(-1)\n        z_q = self.embedding(indices)\n        if self.remap_used:\n            z_q = z_q.view(z_q.shape[0], self.embedding_dim, self.n_e)\n            z_q = z_q.permute(0, 2, 1).contiguous()\n        z_q = z_q.view(-1, self.embedding_dim)\n    return z_q\n\n", "CodeBleu_score": 54.476039445106196}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # shape specifying (batch, height, width, channel)\n    if self.remap_used:\n        indices = indices.reshape(shape[0], shape[1], shape[2], 1)\n        indices = self.unmap_to_all.index_select(0, indices.view(-1))\n        indices = indices.view(shape[0], shape[1], shape[2], 1)\n\n    z_q = self.embedding(indices)\n\n    if shape is not None:\n        z_q = z_q.view(z_q.shape[0], shape[3], shape[1], shape[2])\n        # reshape back to match original input shape\n        z_q = z_q.permute(0, 2, 3, 1).contiguous()\n\n    return z_q\n\n", "CodeBleu_score": 63.3269722372649}]}
{"instance_id": "c55d014827ef", "generation_result": [{"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor > 0 and dimension % factor == 0:\n        return factor, dimension // factor\n    else:\n        m = dimension\n        n = 1\n        for i in range(2, int(dimension**0.5)+1):\n            if dimension % i == 0:\n                if factor > 0 and i > factor:\n                    break\n                if dimension // i <= i:\n                    m = i\n                    n = dimension // i\n                    break\n                else:\n                    m = dimension // i\n                    n = i\n        return m, n\n\n\n\n", "CodeBleu_score": 42.08447139601802}, {"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor > 0 and dimension % factor == 0:\n        return factor, dimension // factor\n    else:\n        if factor < 0:\n            factor = -factor\n        m = dimension // 2\n        n = m\n        while m * n != dimension:\n            if m * n < dimension:\n                m += 1\n            else:\n                n -= 1\n        if m > n:\n            m, n = n, m\n        if factor > 0:\n            while m > factor:\n                m -= 1\n                n += 1\n        return m, n\n\n\n\n", "CodeBleu_score": 46.77559041156671}, {"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor > 0 and dimension % factor == 0:\n        return factor, dimension // factor\n    else:\n        m = int(dimension ** 0.5)\n        while dimension % m != 0 and m > 1:\n            m -= 1\n        return m, dimension // m\n\n", "CodeBleu_score": 19.667112331067823}]}
{"instance_id": "5d613ec26036", "generation_result": [{"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    updown = updown.to(orig_weight.device, dtype=orig_weight.dtype)\n    orig_weight = orig_weight.to(updown.device, dtype=updown.dtype)\n    updown = updown.transpose(0, 1)\n    orig_weight = orig_weight.transpose(0, 1)\n    updown = updown.reshape(updown.shape[0], -1)\n    orig_weight = orig_weight.reshape(orig_weight.shape[0], -1)\n    merged_scale1 = updown * self.scale1\n    norm = torch.norm(merged_scale1, dim=1, keepdim=True)\n    norm = norm.clamp(min=1e-8)\n    merged_scale1 = merged_scale1 / norm\n    merged_scale1 = merged_scale1.transpose(0, 1)\n    orig_weight = orig_weight.transpose(0, 1)\n    final_weight = merged_scale1 - orig_weight\n    return final_weight", "CodeBleu_score": 39.57880882869681}, {"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    updown = updown.to(orig_weight.device)\n    orig_weight = orig_weight.to(orig_weight.device)\n    transpose = updown.transpose(1, 0)\n    to = transpose.to(orig_weight.device)\n    reshape = to.reshape(to.shape[0], -1)\n    merged_scale1 = reshape * self.scale1\n    norm = merged_scale1.norm(dim=1)\n    norm = norm.to(orig_weight.device)\n    norm = norm.to(orig_weight.dtype)\n    norm = norm.reshape(norm.shape[0], 1)\n    norm = norm.repeat(1, reshape.shape[1])\n    norm = norm.to(orig_weight.device)\n    norm = norm.to(orig_weight.dtype)\n    norm = norm.reshape(norm.shape[0], reshape.shape[1])\n    norm = norm.to(orig_weight.device)\n    norm = norm.to(orig_weight.dtype)\n    merged_scale1 = merged_scale1 / norm\n    merged_scale1 = merged_scale1.to(orig_weight.device)\n    merged_scale1 = merged_scale1.to(orig_weight.dtype)\n    merged_scale1 = merged_scale1.reshape(orig_weight.shape)\n    merged_scale1 = merged_scale1.to(orig_weight.device)\n    merged_scale1 = merged_scale1.to(orig_weight.dtype)\n    merged_scale1 = merged_scale1.to(orig_weight.device)\n    merged_scale1 = merged_scale1.to(orig_weight.dtype)\n    merged_scale1 = merged_scale1.to(orig_weight.device)\n    merged_scale1 = merged_scale1.to(orig_weight.dtype)\n    merged_scale1 = merged_scale1.to(orig_weight.device)\n    merged_scale1 = merged_scale1.to(orig_weight.dtype)\n    merged_scale1 = merged_scale1.", "CodeBleu_score": 32.62540239691655}, {"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    updown = updown.to(orig_weight.device, orig_weight.dtype)\n    orig_weight = orig_weight.to(updown.device, updown.dtype)\n    transpose = updown.transpose(0, 1)\n    to = transpose.to(orig_weight.device, orig_weight.dtype)\n    reshape = to.reshape(orig_weight.shape)\n    merged_scale1 = reshape * self.scale1\n    norm = merged_scale1.norm()\n    if norm > 1.0:\n        merged_scale1 /= norm\n    to = merged_scale1.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to(orig_weight.device, orig_weight.dtype)\n    to = to.to", "CodeBleu_score": 18.915805401160846}]}
{"instance_id": "c73d0d1cd3e5", "generation_result": [{"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t\n    if ex_bias is not None:\n        ex_bias = self.apply_bias(ex_bias)\n    updown = self.apply_bias(updown)\n    updown = updown.reshape(output_shape)\n    if orig_weight.numel() == updown.numel():\n        updown = updown.reshape(orig_weight.shape)\n    if ex_bias is not None:\n        ex_bias = ex_bias * self.multiplier\n    if self.calc_scale:\n        updown = self.apply_weight_decompose(updown)\n    return updown, ex_bias\n\n", "CodeBleu_score": 45.80919559555156}, {"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t\n    if ex_bias is not None:\n        ex_bias = ex_bias * self.multiplier\n    if orig_weight.size == updown.size:\n        updown = updown.reshape(orig_weight.shape)\n    if orig_weight.numel() != updown.numel():\n        updown = updown.reshape(orig_weight.shape)\n    if self.calc_scale:\n        updown = self.apply_weight_decompose(updown)\n    return updown, ex_bias", "CodeBleu_score": 38.62024912250913}, {"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t\n    updown = updown.to(orig_weight.device)\n    if ex_bias is not None:\n        ex_bias = ex_bias.to(orig_weight.device)\n        ex_bias = self.apply_multiplier(ex_bias)\n    if self.calc_scale:\n        updown = self.apply_scale(updown)\n    if updown.size == orig_weight.size:\n        updown = updown.reshape(orig_weight.shape)\n    elif updown.numel() == orig_weight.numel():\n        updown = updown.reshape(orig_weight.shape)\n    if ex_bias is not None:\n        ex_bias = ex_bias.reshape(output_shape)\n    if self.multiplier is not None:\n        updown = self.apply_multiplier(updown)\n    if self.weight_decompose:\n        updown = self.apply_weight_decompose(updown)\n    return updown, ex_bias", "CodeBleu_score": 55.553958643364496}]}
{"instance_id": "c6a41665c62c", "generation_result": [{"code": "def calc_updown(self, orig_weight)\n\t\n    device = orig_weight.device\n    weight = self.weight.to(device)\n    if self.bias is not None:\n        bias = self.bias.to(device)\n    else:\n        bias = None\n    return self.finalize_updown(weight, bias)", "CodeBleu_score": 30.976069723011346}, {"code": "def calc_updown(self, orig_weight)\n\t\n    self.finalize_updown()\n    if self.bias is not None:\n        self.bias.data = self.bias.to(device=orig_weight.device)\n    return self.weight.data", "CodeBleu_score": 21.541295780234933}, {"code": "def calc_updown(self, orig_weight)\n\t\n    self.to(orig_weight.device)\n    return self.finalize_updown(orig_weight)", "CodeBleu_score": 5.294208948937165}]}
{"instance_id": "1bb9e5d94af8", "generation_result": [{"code": "def purge_networks_from_memory()\n\t\n    global networks_in_memory\n    while len(networks_in_memory) > MAX_NETWORKS_IN_MEMORY:\n        networks_in_memory.pop()\n    torch.cuda.empty_cache()\n\n", "CodeBleu_score": 31.96964293952409}, {"code": "def purge_networks_from_memory()\n\t\n    networks_in_memory = []\n    while len(networks_in_memory) > 100:\n        networks_in_memory.pop()\n    torch.cuda.empty_cache()\n\n", "CodeBleu_score": 30.743220404849435}, {"code": "def purge_networks_from_memory()\n\t\n    global networks_in_memory\n    if len(networks_in_memory) > max_networks_in_memory:\n        while len(networks_in_memory) > max_networks_in_memory:\n            networks_in_memory.pop()\n        gc.collect()\n\n", "CodeBleu_score": 36.959085721004215}]}
{"instance_id": "42b48ebf4d07", "generation_result": [{"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n    if hasattr(self, 'backup_weights'):\n        self.weight = copy_(self.backup_weights)\n    if hasattr(self, 'backup_bias'):\n        self.bias = copy_(self.backup_bias)\n    if isinstance(self, torch.nn.MultiheadAttention):\n        if hasattr(self, 'backup_proj_weights'):\n            self.out_proj.weight = copy_(self.backup_proj_weights)\n        if hasattr(self, 'backup_proj_bias'):\n            self.out_proj.bias = copy_(self.backup_proj_bias)\n    else:\n        if hasattr(self, 'backup_bias') is False:\n            self.bias = None\n\n", "CodeBleu_score": 33.86643712984157}, {"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n    backup_weights = getattr(self, \"backup_weights\", None)\n    backup_bias = getattr(self, \"backup_bias\", None)\n    if backup_weights is not None:\n        self.weight = backup_weights\n        self.bias = backup_bias\n    if isinstance(self, torch.nn.MultiheadAttention):\n        self.out_proj.weight = self.out_proj.backup_weights\n        self.out_proj.bias = self.out_proj.backup_bias\n    self.backup_weights = None\n    self.backup_bias = None\n\n", "CodeBleu_score": 38.28408388752147}, {"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n    if hasattr(self, \"_backup_weight\"):\n        self.weight = copy_.deepcopy(self._backup_weight)\n        del self._backup_weight\n    if hasattr(self, \"_backup_bias\"):\n        self.bias = copy_.deepcopy(self._backup_bias)\n        del self._backup_bias\n    if isinstance(self, torch.nn.MultiheadAttention):\n        if hasattr(self, \"_backup_proj_weight\"):\n            self.proj_weight = copy_.deepcopy(self._backup_proj_weight)\n            del self._backup_proj_weight\n        if hasattr(self, \"_backup_proj_bias\"):\n            self.proj_bias = copy_.deepcopy(self._backup_proj_bias)\n            del self._backup_proj_bias\n\n", "CodeBleu_score": 34.96277707012182}]}
{"instance_id": "c8fcd357131a", "generation_result": [{"code": "def network_forward(org_module, input, original_forward)\n\t\n    if len(network_list) == 0:\n        return original_forward(input)\n    input = devices.cond_cast_unet(input)\n    network_restore_weights_from_backup(org_module)\n    output = original_forward(input)\n    for network in network_list:\n        if getattr(network, \"layer\", -1) == org_module.layer:\n            output = network(output)\n    return output", "CodeBleu_score": 31.042011708984376}, {"code": "def network_forward(org_module, input, original_forward)\n\t\n    if len(network_loaded_modules) == 0:\n        return original_forward(input)\n    input = devices.cond_cast_unet(input)\n    network_restore_weights_from_backup(org_module)\n    output = original_forward(input)\n    for loaded_module in network_loaded_modules:\n        if getattr(loaded_module, 'forward', None) is not None:\n            if loaded_module.forward == org_module.forward:\n                output = loaded_module.forward(output)\n    return output\n\n", "CodeBleu_score": 36.73368734432809}, {"code": "def network_forward(org_module, input, original_forward)\n\t\n    if len(loaded_networks) == 0:\n        return original_forward(input)\n    devices.cond_cast_unet(input, module)\n    network_restore_weights_from_backup(org_module)\n    output = original_forward(input)\n    for network in loaded_networks:\n        if network.layer == org_module.name:\n            output = network.forward(output)\n    return output", "CodeBleu_score": 34.188354910105026}]}
{"instance_id": "1070211f5c11", "generation_result": [{"code": "def trainables(self)\n\t\n    trainable_params = []\n    for layer in self.model.modules():\n        if isinstance(layer, torch.nn.Linear) or isinstance(layer, torch.nn.LayerNorm):\n            trainable_params.extend(layer.parameters())\n    return trainable_params\n\n", "CodeBleu_score": 35.56149303801561}, {"code": "def trainables(self)\n\t\n    trainable_params = []\n    for name, param in self.named_parameters():\n        if param.requires_grad:\n            if 'weight' in name:\n                trainable_params.append(param)\n    return trainable_params", "CodeBleu_score": 25.512584975147863}, {"code": "def trainables(self)\n\t\n    trainable_params = []\n    for layer in self.model.modules():\n        if isinstance(layer, torch.nn.Linear) or isinstance(layer, torch.nn.LayerNorm):\n            trainable_params.extend(layer.parameters())\n    return trainable_params\n\n", "CodeBleu_score": 35.56149303801561}]}
{"instance_id": "0c3ba62c96a7", "generation_result": [{"code": "def load_hypernetworks(names, multipliers=None)\n\t\n    already_loaded = []\n    for name in names:\n        hypernetwork = None\n        if name in already_loaded:\n            hypernetwork = already_loaded[name]\n        else:\n            hypernetwork = load_hypernetwork(name)\n            already_loaded[name] = hypernetwork\n        if multipliers is not None:\n            hypernetwork.set_multiplier(multipliers[name])\n        hypernetworks.append(hypernetwork)\n\n", "CodeBleu_score": 25.44432842189553}, {"code": "def load_hypernetworks(names, multipliers=None)\n\t\n    already_loaded = []\n    for name in names:\n        if name in already_loaded:\n            hypernetwork = already_loaded[name]\n        else:\n            hypernetwork = load_hypernetwork(name)\n            already_loaded[name] = hypernetwork\n        if multipliers is not None:\n            hypernetwork.set_multiplier(multipliers[name])\n        hypernetworks.append(hypernetwork)\n\n", "CodeBleu_score": 24.021679247336124}, {"code": "def load_hypernetworks(names, multipliers=None)\n\t\n    already_loaded = []\n    for name in names:\n        if name in already_loaded:\n            hypernetwork = already_loaded[name]\n        else:\n            hypernetwork = load_hypernetwork(name)\n        if multipliers is not None:\n            hypernetwork.set_multiplier(multipliers[name])\n        hypernetworks.append(hypernetwork)\n\n", "CodeBleu_score": 23.310150157585262}]}
{"instance_id": "bea3772ed532", "generation_result": [{"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k = context\n    context_v = context\n    for hypernetwork in hypernetworks:\n        context_k, context_v = apply_single_hypernetwork(\n            hypernetwork, context_k, context_v, layer=layer\n        )\n    return context_k, context_v", "CodeBleu_score": 59.32660675130703}, {"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k = context\n    context_v = context\n    for hypernetwork in hypernetworks:\n        if layer is not None:\n            if layer in hypernetwork.layers:\n                context_k, context_v = apply_single_hypernetwork(hypernetwork, context_k, context_v, layer)\n        else:\n            context_k, context_v = apply_single_hypernetwork(hypernetwork, context_k, context_v)\n    return context_k, context_v\n\n", "CodeBleu_score": 60.67493862174835}, {"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k = context\n    context_v = context\n    for hypernetwork in hypernetworks:\n        context_k, context_v = apply_single_hypernetwork(hypernetwork, context_k, context_v, layer)\n    return context_k, context_v\n\n", "CodeBleu_score": 76.04946886953897}]}
{"instance_id": "922efa3e092f", "generation_result": [{"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    if context is None:\n        context = x\n    kv = self.to_k(context)\n    b, c, *d, h = kv.shape\n    q = self.to_q(x)\n    context_k, context_v = (kv[:, :c], kv[:, c:])\n    q = q.reshape(b, -1, h)\n    context_k = context_k.reshape(b, -1, h)\n    context_v = context_v.reshape(b, -1, h)\n    k = self.to_k(context_k)\n    v = self.to_v(context_v)\n    q, k, v = map(lambda t: rearrange(t, \"b n (h d) -> (b h) n d\", h=self.heads), (q, k, v))\n    sim = einsum(\"b i d, b j d -> b i j\", q, k) * self.scale\n    if mask is not None:\n        mask = repeat(mask, \"j -> b i j\", b=b)\n        sim = sim.masked_fill_(~mask, -torch.finfo(sim.dtype).max)\n    attn = sim.softmax(dim=-1)\n    out = einsum(\"b i j, b j d -> b i d\", attn, v)\n    out = rearrange(out, \"(b h) n d -> b n (h d)\", h=self.heads)\n    return self.to_out(out)\n\n", "CodeBleu_score": 62.89941157997793}, {"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    b, c, h, w = x.size()\n    x = x.view(b, c, h * w).permute(0, 2, 1)\n    if context is not None:\n        context = context.permute(0, 2, 1)\n    q = self.to_q(x)\n    context = context if context is not None else x\n    k = self.to_k(context)\n    v = self.to_v(context)\n    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h=self.heads), (q, k, v))\n    sim = einsum('b i d, b j d -> b i j', q, k) * self.scale\n    if mask is not None:\n        mask = repeat(mask, 'b j -> (b h) () j', h=self.heads)\n        sim.masked_fill_(~mask, -torch.finfo(sim.dtype).max)\n    attn = sim.softmax(dim=-1)\n    out = einsum('b i j, b j d -> b i d', attn, v)\n    out = rearrange(out, '(b h) n d -> b n (h d)', h=self.heads)\n    out = self.to_out(out)\n    return out\n\n", "CodeBleu_score": 60.19012441620766}, {"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    q = self.to_q(x)\n    context = default(context, x)\n    k = self.to_k(context) * self.scale\n    v = self.to_v(context)\n    del context\n    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h=self.heads), (q, k, v))\n    sim = einsum('b i d, b j d -> b i j', q, k) * self.scale\n    if exists(mask):\n        mask = rearrange(mask, 'b ... -> b (...)')\n        max_neg_value = -torch.finfo(sim.dtype).max\n        mask = repeat(mask, 'b j -> (b h) () j', h=self.heads)\n        sim = sim.masked_fill_(~mask, max_neg_value)\n    attn = sim.softmax(dim=-1)\n    out = einsum('b i j, b j d -> b i d', attn, v)\n    out = rearrange(out, '(b h) n d -> b n (h d)', h=self.heads)\n    out = self.to_out(out)\n    return out\n\n", "CodeBleu_score": 68.44330282972794}]}
{"instance_id": "8b7455a03a0e", "generation_result": [{"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t\n    original_attrs = hypernetwork.__dict__.copy()\n    hypernetwork.name = hypernetwork_name\n    hypernetwork.hash = checkpoint.get(\"hash\", None)\n    hypernetwork.filename = filename\n    try:\n        hypernetwork.save()\n    except Exception as e:\n        hypernetwork.__dict__ = original_attrs\n        raise e\n    hypernetwork.__dict__ = original_attrs\n\n", "CodeBleu_score": 24.589417941117976}, {"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t\n    # Save the original attributes\n    original_hypernetwork_name = hypernetwork.hypernetwork_name\n    original_filename = hypernetwork.filename\n    original_name = hypernetwork.name\n    original_prompt = hypernetwork.prompt\n    original_short_name = hypernetwork.short_name\n    original_negative_prompt = hypernetwork.negative_prompt\n    original_steps = hypernetwork.steps\n    original_sampler_name = hypernetwork.sampler_name\n    original_cfg_scale = hypernetwork.cfg_scale\n    original_seed = hypernetwork.seed\n    original_width = hypernetwork.width\n    original_height = hypernetwork.height\n    original_model_hash = hypernetwork.model_hash\n    original_batch_size = hypernetwork.batch_size\n    original_half_precision = hypernetwork.half_precision\n    original_use_model_config = hypernetwork.use_model_config\n    original_use_custom_seed = hypernetwork.use_custom_seed\n    original_use_cpu = hypernetwork.use_cpu\n    original_use_disk = hypernetwork.use_disk\n    original_use_ada_latent_model = hypernetwork.use_ada_latent_model\n    original_use_random_seed = hypernetwork.use_random_seed\n    original_use_tiling = hypernetwork.use_tiling\n    original_tiling_x = hypernetwork.tiling_x\n    original_tiling_y = hypernetwork.tiling_y\n    original_override_settings = hypernetwork.override_settings\n    original_override_settings_restore_afterwards = hypernetwork.override_settings_restore_afterwards\n    original_script_args = hypernetwork.script_args\n    original_script_name = hypernetwork.script_name\n    original_send_images_to_img2img = hypernetwork.send_images_to_img2img\n    original_do_not_show_images = hypernetwork.do_not_show_images\n    original_always_use_cpu = hypernetwork.always_use_cpu\n    original_do_not_copy_params_to_vae = hypernetwork.do", "CodeBleu_score": 10.243165866141256}, {"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t\n    original_attrs = hypernetwork.__dict__.copy()\n    hypernetwork.name = hypernetwork_name\n    hypernetwork.hash = checkpoint.get(\"hash\", None)\n    hypernetwork.sd_checkpoint = checkpoint.get(\"sd_checkpoint\", None)\n    hypernetwork.sd_checkpoint_name = checkpoint.get(\"sd_checkpoint_name\", None)\n    hypernetwork.filename = filename\n    try:\n        hypernetwork.save()\n    except Exception as e:\n        for key, value in original_attrs.items():\n            setattr(hypernetwork, key, value)\n        raise e\n\n", "CodeBleu_score": 34.34905085293632}]}
{"instance_id": "3175f835140f", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    pass\n\n", "CodeBleu_score": 3.051106025934401}, {"code": "def ema_scope(self, context=None)\n\t\n    if self.ema_enabled:\n        self.store(context)\n        self.copy_to(context)\n        if context is not None:\n            logger.info(f\"Switching to EMA weights - {context}\")\n    yield\n    if self.ema_enabled:\n        self.restore(context)\n        if context is not None:\n            logger.info(f\"Restoring original weights - {context}\")\n\n", "CodeBleu_score": 46.93923200956566}, {"code": "def ema_scope(self, context=None)\n\t\n    if context is None:\n        context = {}\n    if self.ema_enabled:\n        context[\"old_params\"] = self.state_dict()\n        self.load_state_dict(self.ema_state_dict())\n        if self.ema_log:\n            print(\"Switched to EMA weights\")\n    yield\n    if self.ema_enabled:\n        self.load_state_dict(context[\"old_params\"])\n        if self.ema_log:\n            print(\"Restored original weights\")\n\n", "CodeBleu_score": 35.1363290932273}]}
{"instance_id": "a7b5d5cd519a", "generation_result": [{"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    model_output = self.model(x, t)\n    if self.model_var_type in [\"learned\", \"learned_range\"]:\n        assert model_output.shape == x.shape\n        model_std = self.get_model_output_sigma(model_output)\n        if self.model_var_type == \"learned\":\n            model_std = model_std.flatten(1)\n            while len(model_std.shape) < len(x.shape):\n                model_std = model_std.unsqueeze(-1)\n    else:\n        model_std = self.betas[t]\n        model_std = self.sqrt_alphas_cumprod[t] * model_std\n    if self.model_mean_type == \"eps\":\n        x_recon = model_output\n    elif self.model_mean_type == \"x_prev\":\n        assert self.model_output_type == \"epsilon\"\n        x_recon = self.predict_start_from_noise(x, t, model_output)\n    else:\n        raise NotImplementedError(self.model_mean_type)\n    if clip_denoised:\n        x_recon.clamp_(-1, 1)\n    model_mean, posterior_variance, posterior_log_variance_clipped = self.q_posterior(\n        x_start=x_recon, x_t=x, t=t, posterior_log_variance=model_std\n    )\n    return model_mean, posterior_variance, posterior_log_variance_clipped\n\n", "CodeBleu_score": 42.74869601484069}, {"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    # x_recon = self.predict_start_from_noise(x, t=t, noise=model_output)\n    model_output = self.model(x, t)\n    if clip_denoised:\n        x_recon.clamp_(-1.0, 1.0)\n    model_mean, posterior_log_variance = torch.split(model_output, 3, dim=1)\n    posterior_variance = posterior_log_variance.exp()\n    return model_mean, posterior_variance, posterior_log_variance\n\n", "CodeBleu_score": 36.33533834927059}, {"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    model_output = self.model(x, t)\n    if self.model_var_type in [\"fixedlarge\", \"fixedsmall\"]:\n        x_recon = self.predict_start_from_noise(x, t, model_output=model_output)\n        if clip_denoised:\n            x_recon.clamp_(-1.0, 1.0)\n        model_mean, posterior_log_variance = x_recon, self.posterior_log_variance_time_0\n    else:\n        if self.model_var_type == \"learned\":\n            x_recon = self.predict_start_from_noise(x, t, noise=model_output)\n        elif self.model_var_type == \"learned_range\":\n            x_recon = self.predict_start_from_noise(x, t, noise=model_output)\n        else:\n            raise NotImplementedError(self.model_var_type)\n        if clip_denoised:\n            x_recon.clamp_(-1.0, 1.0)\n        model_mean, posterior_log_variance_clipped = self.q_posterior(\n            x_start=x_recon, x_t=x, t=t\n        )\n    return {\n        \"mean\": model_mean,\n        \"variance\": torch.exp(posterior_log_variance_clipped)\n        if self.model_var_type != \"learned_range\"\n        else posterior_log_variance_clipped,\n        \"log_variance\": posterior_log_variance_clipped,\n        \"pred_xstart\": x_recon,\n    }\n\n", "CodeBleu_score": 42.35862685056221}]}
{"instance_id": "a8652fa78473", "generation_result": [{"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='none')\n        if not mean:\n            loss = loss.sum()\n    else:\n        raise NotImplementedError('Unknown loss_type {}'.format(self.loss_type))\n    return loss\n\n", "CodeBleu_score": 54.834614526411606}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='none')\n        if not mean:\n            loss = loss.sum()\n    else:\n        raise NotImplementedError\n    return loss\n\n", "CodeBleu_score": 53.048577405959875}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='none')\n        if not mean:\n            loss = loss.sum()\n    else:\n        raise NotImplementedError(self.loss_type)\n    return loss\n\n", "CodeBleu_score": 53.86968263770287}]}
{"instance_id": "d68e4f061349", "generation_result": [{"code": "def _prior_bpd(self, x_start)\n\t\n    batch_size = x_start.shape[0]\n    t = torch.tensor([self.num_timesteps - 1] * batch_size, dtype=torch.long, device=x_start.device)\n    qt_mean, _, _, _ = self.q_mean_variance(x_start, t)\n    kl_prior = normal_kl(mean_flat(qt_mean), mean_flat(torch.zeros_like(qt_mean)), mean_flat(torch.ones_like(qt_mean)))\n    return kl_prior / np.log(2.0)\n\n", "CodeBleu_score": 50.6178300547579}, {"code": "def _prior_bpd(self, x_start)\n\t\n    batch_size = x_start.shape[0]\n    t = torch.tensor([self.num_timesteps - 1] * batch_size, device=x_start.device)\n    mean, _, log_variance = self.q_mean_variance(x_start=x_start, t=t)\n    return self.normal_kl(mean, log_variance) / np.log(2.0)\n\n", "CodeBleu_score": 42.29693799299876}, {"code": "def _prior_bpd(self, x_start)\n\t\n    batch_size = x_start.shape[0]\n    t = torch.tensor([self.num_timesteps - 1] * batch_size, device=x_start.device)\n    mean, _, log_variance = self.q_mean_variance(x_start, t)\n    mean_flat = mean.reshape(mean.shape[0], -1)\n    log_variance_flat = log_variance.reshape(log_variance.shape[0], -1)\n    return normal_kl(mean_flat, log_variance_flat) / np.log(2.0)\n\n", "CodeBleu_score": 49.01918654741751}]}
{"instance_id": "c695d93fdf2d", "generation_result": [{"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    return diskcache.Cache(\n        path=os.path.join(CACHE_DIR, subsection),\n        size_limit=4 * 1024 * 1024 * 1024,\n        sqlite_auto_vacuum=True,\n        sqlite_min_file_size=256 * 1024,\n    )\n\n", "CodeBleu_score": 57.944152750252854}, {"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    return diskcache.Cache(\n        path=os.path.join(CACHE_DIR, subsection),\n        size_limit=4 * 1024 * 1024 * 1024,\n        sqlite_auto_vacuum=True,\n        eviction_policy=\"least-recently-used\",\n        minimum=256 * 1024,\n    )\n\n", "CodeBleu_score": 55.407722246613034}, {"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    return diskcache.Cache(\n        os.path.join(cache_dir, subsection),\n        size_limit=4 * 1024 ** 3,\n        eviction_policy=\"least-recently-used\",\n        sqlite_min_file_size=256 * 1024,\n    )\n\n", "CodeBleu_score": 66.96561478082941}]}
{"instance_id": "ed4c543f0d38", "generation_result": [{"code": "def cache(subsection)\n\t\n    global caches\n    cache_lock.acquire()\n    try:\n        cache = caches.get(subsection)\n        if cache is None:\n            if not isdir(cache_dir):\n                os.mkdir(cache_dir)\n            if not isfile(cache_filename):\n                convert_old_cached_data()\n            cache = caches.get(subsection)\n            if cache is None:\n                cache = make_cache(subsection)\n                caches[subsection] = cache\n        return cache\n    finally:\n        cache_lock.release()\n\n", "CodeBleu_score": 48.88253735457985}, {"code": "def cache(subsection)\n\t\n    if subsection in caches:\n        return caches[subsection]\n    with cache_lock:\n        if subsection not in caches:\n            if not exists(cache_dir):\n                os.makedirs(cache_dir)\n            if isfile(cache_filename):\n                convert_old_cached_data()\n            if subsection not in caches:\n                caches[subsection] = make_cache(subsection)\n    return caches[subsection]\n\n", "CodeBleu_score": 41.193926771386565}, {"code": "def cache(subsection)\n\t\n    if subsection in caches:\n        return caches[subsection]\n    with cache_lock:\n        if not os.path.isdir(cache_dir):\n            os.makedirs(cache_dir)\n        if not isfile(cache_filename):\n            convert_old_cached_data()\n        if subsection not in caches:\n            caches[subsection] = make_cache(subsection)\n    return caches[subsection]\n\n", "CodeBleu_score": 44.74990218070923}]}
{"instance_id": "ccf5ea2d9fc1", "generation_result": [{"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n\n    cache = cache(subsection)\n    mtime = getmtime(filename)\n    entry = cache.get(title)\n    if entry is not None:\n        if mtime > entry.get('mtime'):\n            entry = None\n    if entry is None:\n        data = func()\n        entry = dict(data=data, mtime=mtime)\n        cache[title] = entry\n        dump_cache(cache, subsection)\n    return entry['data']\n\n", "CodeBleu_score": 34.12022827794736}, {"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n    cache = cache(subsection)\n    mtime = getmtime(filename)\n    if title in cache:\n        entry = cache[title]\n        if mtime > entry.get(\"mtime\", 0):\n            entry.valid = False\n        else:\n            return entry.get(\"data\")\n    data = func()\n    cache[title] = {\"mtime\": mtime, \"data\": data}\n    dump_cache()\n    return data\n\n", "CodeBleu_score": 28.762649243926557}, {"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n    cache = cache(subsection)\n    mtime = getmtime(filename)\n    entry = cache.get(title)\n    if entry and entry.get(\"mtime\") >= mtime:\n        return entry.get(\"data\")\n    data = func()\n    cache[title] = {\"mtime\": mtime, \"data\": data}\n    dump_cache(cache)\n    return data\n\n", "CodeBleu_score": 24.862246753764037}]}
{"instance_id": "e01a2d4f0ac2", "generation_result": [{"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n    for line in message.splitlines():\n        print(\"*** \" + line)\n    if exc_info:\n        print(textwrap.indent(traceback.format_exc(), \"    \"))\n        print(\"---\")\n\n", "CodeBleu_score": 48.63497912218981}, {"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n    for line in message.splitlines():\n        print(\"***\", line)\n    if exc_info:\n        print(textwrap.indent(traceback.format_exc(), \"    \"))\n        print(\"---\")\n\n", "CodeBleu_score": 50.57568606908429}, {"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n    for line in message.splitlines():\n        print(f\"*** {line}\")\n    if exc_info:\n        print(textwrap.indent(traceback.format_exc(), \"    \"))\n        print(\"---\")\n\n", "CodeBleu_score": 47.41811477493679}]}
{"instance_id": "125fb9d2320b", "generation_result": [{"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n    if style.prompt == \"\" and style.negative_prompt == \"\":\n        return False, prompt, negative_prompt\n\n    try:\n        extracted_prompt = extract_style_text_from_prompt(prompt, style.prompt)\n    except Exception:\n        return False, prompt, negative_prompt\n\n    try:\n        extracted_negative_prompt = extract_style_text_from_prompt(\n            negative_prompt, style.negative_prompt\n        )\n    except Exception:\n        return False, prompt, negative_prompt\n\n    return True, extracted_prompt, extracted_negative_prompt\n\n", "CodeBleu_score": 53.55945852276922}, {"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n    if style.prompt == '' and style.negative_prompt == '':\n        return False, prompt, negative_prompt\n\n    try:\n        positive_prompt = extract_style_text_from_prompt(style.prompt, prompt)\n    except Exception:\n        return False, prompt, negative_prompt\n\n    try:\n        negative_prompt = extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n    except Exception:\n        return False, prompt, negative_prompt\n\n    return True, positive_prompt, negative_prompt\n\n", "CodeBleu_score": 56.888914737426276}, {"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n    if style.prompt == \"\" and style.negative_prompt == \"\":\n        return False, prompt, negative_prompt\n\n    try:\n        positive_prompt = extract_style_text_from_prompt(prompt, style.prompt)\n    except:\n        return False, prompt, negative_prompt\n\n    try:\n        negative_prompt = extract_style_text_from_prompt(\n            negative_prompt, style.negative_prompt\n        )\n    except:\n        return False, prompt, negative_prompt\n\n    return True, positive_prompt, negative_prompt\n\n", "CodeBleu_score": 52.261266184686875}]}
{"instance_id": "0c5f729fbce2", "generation_result": [{"code": "def random_partial(self, count, n_frames)\n\t\n    if self.utterances is None:\n        self._load_utterances()\n\n    utterances = self.utterance_cycler.sample(count)\n\n    a = [(u,) + u.random_partial(n_frames) for u in utterances]\n\n    return a", "CodeBleu_score": 94.20475781398312}, {"code": "def random_partial(self, count, n_frames)\n\t\n    if self.utterances is None:\n        self._load_utterances()\n\n    utterances = self.utterance_cycler.sample(count)\n\n    a = [(u,) + u.random_partial(n_frames) for u in utterances]\n\n    return a\n\n", "CodeBleu_score": 94.20475781398312}, {"code": "def random_partial(self, count, n_frames)\n\t\n    if self.utterances is None:\n        self._load_utterances()\n\n    utterances = self.utterance_cycler.sample(count)\n\n    a = [(u,) + u.random_partial(n_frames) for u in utterances]\n\n    return a\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 94.20475781398312}]}
{"instance_id": "31e8b27b8f94", "generation_result": [{"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"Both increase only and decrease only are set\")\n    wav = wav.copy()\n    rms = np.sqrt(np.mean((wav * INT16_MAX) ** 2))\n    wave_dBFS = 20 * np.log10(rms / INT16_MAX)\n    dBFS_change = target_dBFS - wave_dBFS\n    if dBFS_change < 0 and increase_only or dBFS_change > 0 and decrease_only:\n        return wav\n    return wav * (10 ** (dBFS_change / 20))\n\n", "CodeBleu_score": 68.61431882637699}, {"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"Both increase only and decrease only are set\")\n    wav = wav.copy()\n    rms = np.sqrt(np.mean((wav * INT16_MAX) ** 2))\n    wave_dBFS = 20 * np.log10(rms / INT16_MAX)\n    dBFS_change = target_dBFS - wave_dBFS\n    if dBFS_change < 0 and increase_only or dBFS_change > 0 and decrease_only:\n        return wav\n    return wav * (10 ** (dBFS_change / 20))\n\n", "CodeBleu_score": 68.61431882637699}, {"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"Both increase only and decrease only are set\")\n    dBFS_change = target_dBFS - 10 * np.log10(np.mean(wav ** 2))\n    if (dBFS_change < 0) and increase_only:\n        return wav\n    if (dBFS_change > 0) and decrease_only:\n        return wav\n    return wav * (10 ** (dBFS_change / 20))\n\n", "CodeBleu_score": 84.8381782725433}]}
{"instance_id": "2353831e9033", "generation_result": [{"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    if device is None:\n        _device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    elif isinstance(device, str):\n        _device = torch.device(device)\n    else:\n        _device = device\n    _model = SpeakerEncoder(_device, torch.device(\"cpu\"))\n    checkpoint = torch.load(weights_fpath, map_location=\"cpu\")\n    _model.load_state_dict(checkpoint[\"model_state\"])\n    _model.eval()\n    print(\"Loaded encoder \\\"%s\\\" trained to step %d\" % (weights_fpath, checkpoint[\"step\"]))\n\n", "CodeBleu_score": 78.14487612654162}, {"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    if device is None:\n        _device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    elif isinstance(device, str):\n        _device = torch.device(device)\n    else:\n        _device = device\n    print(\"Running inference on device: {}\".format(_device))\n\n    _model = SpeakerEncoder(_device, torch.device(\"cpu\"))\n    checkpoint = torch.load(weights_fpath, map_location=\"cpu\")\n    _model.load_state_dict(checkpoint[\"model_state\"])\n    _model.eval()\n    print(\"Loaded encoder \\\"%s\\\" trained to step %d\" % (weights_fpath, checkpoint[\"step\"]))\n\n    return _model\n\n", "CodeBleu_score": 80.40902066989642}, {"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    if device is None:\n        _device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    elif isinstance(device, str):\n        _device = torch.device(device)\n    else:\n        _device = device\n    _model = SpeakerEncoder(_device, torch.device(\"cpu\"))\n    checkpoint = torch.load(weights_fpath, map_location=\"cpu\")\n    _model.load_state_dict(checkpoint[\"model_state\"])\n    _model.eval()\n    print(\"Loaded encoder \\\"%s\\\" trained to step %d\" % (weights_fpath, checkpoint[\"step\"]))\n\n", "CodeBleu_score": 78.14487612654162}]}
{"instance_id": "3231ad480199", "generation_result": [{"code": "def embed_frames_batch(frames_batch)\n\t\n    if _model is None:\n        raise Exception(\"Model not loaded\")\n    frames_batch = torch.from_numpy(frames_batch).to(_device)\n    with torch.no_grad():\n        embeddings = _model.forward(frames_batch)\n    embeddings = embeddings.detach().cpu().numpy()\n    return embeddings\n\n", "CodeBleu_score": 63.39067856637172}, {"code": "def embed_frames_batch(frames_batch)\n\t\n    if _model is None:\n        raise Exception(\"Model not loaded\")\n    with torch.no_grad():\n        frames_batch = torch.from_numpy(frames_batch).to(_device)\n        embeddings = _model.forward(frames_batch)\n        embeddings = embeddings.detach().cpu().numpy()\n    return embeddings\n\n", "CodeBleu_score": 62.88162794872143}, {"code": "def embed_frames_batch(frames_batch)\n\t\n    if _model is None:\n        raise Exception(\"Model not loaded.\")\n\n    frames_batch = torch.from_numpy(frames_batch).to(_device)\n    with torch.no_grad():\n        embeddings = _model.forward(frames_batch)\n\n    embeddings = embeddings.detach().cpu().numpy()\n    return embeddings\n\n", "CodeBleu_score": 63.48663302960589}]}
{"instance_id": "117a41716c8d", "generation_result": [{"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    assert 0 < overlap < 1\n    assert 0 < min_pad_coverage < 1\n    samples_per_frame = int((sampling_rate * mel_window_step / 1000))\n    n_frames = int(np.ceil((n_samples + 1) / samples_per_frame))\n    frame_step = max(int(np.round(partial_utterance_n_frames * (1 - overlap))), 1)\n    wav_slices, mel_slices = [], []\n    steps = max(1, n_frames - partial_utterance_n_frames + frame_step + 1)\n    for i in range(0, steps, frame_step):\n        mel_range = np.array([i, i + partial_utterance_n_frames])\n        wav_range = mel_range * samples_per_frame\n        mel_slices.append(slice(*mel_range))\n        wav_slices.append(slice(*wav_range))\n    last_wav_range = wav_slices[-1]\n    coverage = (n_samples - last_wav_range.start) / (last_wav_range.stop - last_wav_range.start)\n    if coverage < min_pad_coverage and len(mel_slices) > 1:\n        mel_slices = mel_slices[:-1]\n        wav_slices = wav_slices[:-1]\n    return wav_slices, mel_slices\n\n", "CodeBleu_score": 97.67006232562707}, {"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    assert 0 < overlap < 1\n    assert 0 < min_pad_coverage < 1\n    samples_per_frame = int((sampling_rate * mel_window_step / 1000))\n    n_frames = int(np.ceil((n_samples + 1) / samples_per_frame))\n    frame_step = max(int(np.round(partial_utterance_n_frames * (1 - overlap))), 1)\n    # Compute the slices\n    wav_slices, mel_slices = [], []\n    steps = max(1, n_frames - partial_utterance_n_frames + frame_step + 1)\n    for i in range(0, steps, frame_step):\n        mel_range = np.array([i, i + partial_utterance_n_frames])\n        wav_range = mel_range * samples_per_frame\n        mel_slices.append(slice(*mel_range))\n        wav_slices.append(slice(*wav_range))\n    # Evaluate whether extra padding is warranted or not\n    last_wav_range = wav_slices[-1]\n    coverage = (n_samples - last_wav_range.start) / (last_wav_range.stop - last_wav_range.start)\n    if coverage < min_pad_coverage and len(mel_slices) > 1:\n        mel_slices = mel_slices[:-1]\n        wav_slices = wav_slices[:-1]\n    return wav_slices, mel_slices\n\n", "CodeBleu_score": 97.67006232562707}, {"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    assert 0 < overlap < 1\n    assert 0 < min_pad_coverage < 1\n    samples_per_frame = int((sampling_rate * mel_window_step / 1000))\n    n_frames = int(np.ceil((n_samples + 1) / samples_per_frame))\n    frame_step = max(int(np.round(partial_utterance_n_frames * (1 - overlap))), 1)\n    assert 0 < frame_step\n    wav_slices, mel_slices = [], []\n    steps = max(1, n_frames - partial_utterance_n_frames + frame_step + 1)\n    for i in range(0, steps, frame_step):\n        mel_range = np.array([i, i + partial_utterance_n_frames])\n        wav_range = mel_range * samples_per_frame\n        mel_slices.append(slice(*mel_range))\n        wav_slices.append(slice(*wav_range))\n    last_wav_range = wav_slices[-1]\n    coverage = (n_samples - last_wav_range.start) / (last_wav_range.stop - last_wav_range.start)\n    if coverage < min_pad_coverage and len(mel_slices) > 1:\n        mel_slices = mel_slices[:-1]\n        wav_slices = wav_slices[:-1]\n    return wav_slices, mel_slices\n\n", "CodeBleu_score": 96.77520131364732}]}
{"instance_id": "34fe5c864f1c", "generation_result": [{"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n\n    if shape is None:\n        height = int(np.sqrt(embed.shape[0]))\n        embed = embed.reshape(height, -1)\n\n    cmap = cm.get_cmap()\n    im = ax.imshow(embed, cmap=cmap)\n    plt.colorbar(im, ax=ax)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(title)\n    sm = cm.ScalarMappable(cmap=cmap)\n    sm.set_clim(color_range[0], color_range[1])", "CodeBleu_score": 59.37315687070631}, {"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n\n    if shape is None:\n        height = int(np.sqrt(embed.shape[0]))\n        shape = (height, -1)\n\n    embed = embed.reshape(shape)\n\n    cmap = cm.get_cmap()\n    im = ax.imshow(embed, cmap=cmap)\n    plt.colorbar(im, ax=ax)\n\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(title)\n\n", "CodeBleu_score": 58.672566281820195}, {"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n\n    if ax is None:\n        ax = plt.gca()\n\n    if shape is None:\n        height = int(np.sqrt(embed.shape[0]))\n        embed = embed.reshape(height, -1)\n\n    cmap = cm.get_cmap()\n    im = ax.imshow(embed, cmap=cmap)\n    plt.colorbar(im, ax=ax)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(title)\n    sm = cm.ScalarMappable(cmap=cmap)\n    sm.set_clim(color_range)\n\n", "CodeBleu_score": 58.99663366302506}]}
{"instance_id": "92e93d50b62b", "generation_result": [{"code": "def similarity_matrix(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape\n    embeds_flat = embeds.view(speakers_per_batch * utterances_per_speaker, -1)\n    centroids_incl = torch.mean(embeds_flat, dim=1, keepdim=True)\n    centroids_excl = torch.mean(embeds_flat, dim=1, keepdim=True)\n    centroids_excl[range(speakers_per_batch), range(speakers_per_batch)] = float(\"-inf\")\n    centroids_incl = centroids_incl.unsqueeze(1)\n    centroids_excl = centroids_excl.unsqueeze(1)\n    similarity_matrix = torch.zeros(speakers_per_batch, speakers_per_batch, device=embeds.device)\n    mask_matrix = 1 - torch.eye(speakers_per_batch, device=embeds.device)\n    mask_matrix = mask_matrix.to(dtype=embeds.dtype)\n    mask_matrix = mask_matrix.unsqueeze(dim=0)\n    cos_sim_matrix_a = F.cosine_similarity(embeds_flat.unsqueeze(1), centroids_incl, dim=2)\n    cos_sim_matrix_a = cos_sim_matrix_a * mask_matrix\n    cos_sim_matrix_b = F.cosine_similarity(embeds_flat.unsqueeze(1), centroids_excl, dim=2)\n    cos_sim_matrix_b = cos_sim_matrix_b * mask_matrix\n    cos_sim_matrix = cos_sim_matrix_a + cos_sim_matrix_b\n    cos_sim_matrix = cos_sim_matrix / 2\n    similarity_matrix[range(speakers_per_batch), range(speakers_per_batch)] = cos_sim_matrix.to(dtype=embeds.dtype)\n    return similarity_matrix\n\n", "CodeBleu_score": 31.821805570900906}, {"code": "def similarity_matrix(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape\n\n    # Compute the centroids for each speaker, excluding the utterance\n    # itself from the centroid computation\n    centroids_incl = torch.mean(embeds, dim=1, keepdim=True)\n    centroids_excl = (\n        torch.sum(embeds, dim=1, keepdim=True) - embeds\n    ) / (speakers_per_batch - 1)\n\n    # Compute the cosine similarity matrix\n    similarities = torch.zeros(\n        speakers_per_batch, utterances_per_speaker, speakers_per_batch\n    ).to(self.device)\n    # one_mask[i, :, i] = 1\n    one_mask = np.eye(speakers_per_batch, dtype=np.bool)\n    for j in range(speakers_per_batch):\n        mask = np.ones((speakers_per_batch, utterances_per_speaker), dtype=np.bool)\n        mask[j, :] = False\n        mask[np.where(one_mask)[0], :] = False\n        # mask[i, :] = False\n        # mask[np.eye(speakers_per_batch).astype(np.bool)] = False\n\n        # cosine similarity of utterance i with all other utterances\n        # from speaker j\n        mask = torch.from_numpy(mask).to(self.device)\n        sim_to_centroids_incl = torch.zeros(\n            speakers_per_batch, utterances_per_speaker\n        ).to(self.device)\n        for utterance_id, utterance in enumerate(embeds.transpose(0, 1)):\n            # Calculate cosine similarity\n            sim_to_centroids_incl[\n                :, utterance_id\n            ] = self.similarity_function(\n                utterance, centroids_incl\n            )\n\n        # sim_to_centroids_incl[i, :] = cos_sim(utterances_by_", "CodeBleu_score": 31.303713666998632}, {"code": "def similarity_matrix(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape\n    embeds_flat = embeds.view(speakers_per_batch * utterances_per_speaker, -1)\n    centroids_incl = torch.mean(embeds_flat, dim=1, keepdim=True)\n    centroids_excl = torch.mean(embeds_flat, dim=1, keepdim=True)\n    centroids_incl = centroids_incl / torch.norm(centroids_incl, dim=1, keepdim=True)\n    centroids_excl = centroids_excl / torch.norm(centroids_excl, dim=1, keepdim=True)\n    centroids_incl = centroids_incl.unsqueeze(1).repeat(1, embeds_flat.shape[0], 1)\n    centroids_excl = centroids_excl.unsqueeze(1).repeat(1, embeds_flat.shape[0], 1)\n    similarity_matrix = torch.zeros(embeds_flat.shape[0], embeds_flat.shape[0], device=embeds.device)\n    mask_matrix = torch.ones_like(similarity_matrix) * -np.inf\n    mask_matrix.view(-1)[:: utterances_per_speaker + 1] = 0\n    similarity_matrix = similarity_matrix + mask_matrix\n    similarities_incl = torch.where(mask_matrix == 0, embeds_flat @ centroids_incl.transpose(0, 1), torch.zeros_like(similarity_matrix)).view(speakers_per_batch, utterances_per_speaker, speakers_per_batch).sum(dim=1)\n    similarities_excl = torch.where(mask_matrix == 0, embeds_flat @ centroids_excl.transpose(0, 1), torch.zeros_like(similarity_matrix)).view(speakers_per_batch, utterances_per_speaker, speakers_per_batch).sum(dim=1)\n    similarity_", "CodeBleu_score": 28.63930002246124}]}
{"instance_id": "a6eba54108a1", "generation_result": [{"code": "def loss(self, embeds)\n\t\n    num_speakers, num_utts = embeds.shape[:2]\n    # Similarity matrix. [num_speakers, num_utts, num_speakers, num_utts]\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape((num_speakers * num_utts, num_speakers * num_utts))\n    # Ground truth. [num_speakers * num_utts]\n    labels = np.repeat(np.arange(num_speakers), num_utts)\n    labels = torch.from_numpy(labels.astype(np.int))\n    if self.loss_fn == \"softmax\":\n        loss = self.softmax_loss(sim_matrix, labels)\n    elif self.loss_fn == \"contrast\":\n        loss = self.contrastive_loss(sim_matrix, labels)\n    else:\n        raise Exception(\"Invalid loss_type\")\n    # EER.\n    with torch.no_grad():\n        inv_argmax = lambda i: np.eye(1, num_speakers, i, dtype=np.int)[0]\n        labels = [inv_argmax(i) for i in labels.numpy()]\n        scores = sim_matrix.detach().cpu().numpy()\n\n        # Snippet from https://yangcha.github.io/EER-ROC/\n        fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)\n        eer = brentq(lambda x: 1.0 - x - interp1d(fpr, tpr)(x), 0.0, 1.0)\n\n    return loss, eer", "CodeBleu_score": 59.87358595917192}, {"code": "def loss(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape\n\n    # Loss\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape((speakers_per_batch * utterances_per_speaker, speakers_per_batch))\n\n    ground_truth = np.repeat(np.arange(speakers_per_batch), utterances_per_speaker)\n    target = torch.from_numpy(ground_truth).long().to(self.loss_device)\n    predictions = sim_matrix.reshape(-1)\n    loss = self.loss_fn(predictions, target)\n\n    # EER\n    with torch.no_grad():\n        # [speakers_per_batch, speakers_per_batch]\n        eer_mat = self.similarity_matrix(embeds).detach().cpu().numpy()\n        eer = compute_eer(eer_mat, ground_truth)\n\n    return loss, eer\n\n", "CodeBleu_score": 36.6972152627582}, {"code": "def loss(self, embeds)\n\t\n    num_speakers, num_utts = embeds.shape[:2]\n    # Similarity matrix. [num_speakers, num_utts, num_speakers, num_utts]\n    sim_matrix = self.similarity_matrix(embeds).view(num_speakers * num_utts, -1)\n    # Ground truth. [num_speakers * num_utts]\n    labels = torch.from_numpy(np.repeat(np.arange(num_speakers), num_utts)).long()\n    labels = labels.to(embeds.device)\n    # EER.\n    with torch.no_grad():\n        inv_argmax = lambda i: np.eye(1, num_speakers, i, dtype=np.float32)\n        labels = inv_argmax(labels)\n        scores = sim_matrix.detach().cpu().numpy()\n\n        # snippet from https://yangcha.github.io/EER-ROC/\n        fpr, tpr, thresholds = roc_curve(labels.flatten(), scores.flatten())\n        eer = brentq(lambda x: 1.0 - x - interp1d(fpr, tpr)(x), 0.0, 1.0)\n\n    loss = self.loss_fn(sim_matrix, labels)\n    return loss, eer\n\n", "CodeBleu_score": 55.38698758997727}]}
{"instance_id": "ac7b74b9d1b1", "generation_result": [{"code": "def log_params(self)\n\t\n    import yaml\n    from IPython.display import display, Markdown\n    from tabulate import tabulate\n\n    # Load the model and data parameters from the config file\n    with open(self.config_file, \"r\") as file:\n        params = yaml.safe_load(file)\n\n    # Create a list of tuples containing the parameter name and value\n    model_params = [(k, v) for k, v in params[\"model\"].items()]\n    data_params = [(k, v) for k, v in params[\"data\"].items()]\n\n    # Create a table for the model parameters\n    model_table = tabulate(model_params, headers=[\"Model Parameter\", \"Value\"], tablefmt=\"github\")\n\n    # Create a table for the data parameters\n    data_table = tabulate(data_params, headers=[\"Data Parameter\", \"Value\"], tablefmt=\"github\")\n\n    # Combine the tables into a single string\n    table_str = f\"## Model Parameters\n", "CodeBleu_score": 24.289405791574563}, {"code": "def log_params(self)\n\t\n    import json\n    import logging\n\n    import pandas as pd\n\n    from . import get_params\n\n    logging.basicConfig(level=logging.INFO)\n    log = logging.getLogger(\"log\")\n\n    log.info(\"Parameters\")\n\n    params = get_params()\n    params_dict = params.to_dict()\n    params_str = json.dumps(params_dict, indent=4, sort_keys=True)\n\n    log.info(params_str)\n\n    return params_str\n\n", "CodeBleu_score": 19.62501454143192}, {"code": "def log_params(self)\n\t\n    import inspect\n\n    # Get the model and data parameters\n    model_params = inspect.signature(self.model).parameters\n    data_params = inspect.signature(self.data).parameters\n\n    # Initialize a string to store the parameters\n    params_str = \"\"\n\n    # Iterate through the model parameters and add them to the string\n    for name, param in model_params.items():\n        if param.default != inspect._empty:\n            params_str += f\"{name} = {param.default}", "CodeBleu_score": 8.630048096496601}]}
{"instance_id": "4726b7864386", "generation_result": [{"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    if self.visualize_umap:\n        print(\"Drawing projections.\")\n        embeds = embeds[:max_speakers * utterances_per_speaker]\n        labels = np.repeat(np.arange(max_speakers), utterances_per_speaker)\n        reducer = umap.UMAP(min_dist=0.1)\n        embeds = reducer.fit_transform(embeds)\n        plt.clf()\n        plt.scatter(embeds[:, 0], embeds[:, 1], c=labels)\n        plt.gca().set_aspect('equal', 'datalim')\n        plt.title(f\"UMAP projection of the speaker embeddings, step {step}\")\n        if out_fpath is not None:\n            plt.savefig(out_fpath)\n        else:\n            plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 44.73570359544459}, {"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    if self.disable_vis:\n        return\n    embeds = embeds[:max_speakers*utterances_per_speaker]\n    embeds = np.array(embeds).reshape(max_speakers, utterances_per_speaker, -1)\n    embeds = np.mean(embeds, axis=1)\n    reducer = umap.UMAP()\n    embeds = reducer.fit_transform(embeds)\n    plt.clf()\n    plt.gca().set_aspect('equal', 'datalim')\n    plt.scatter(embeds[:, 0], embeds[:, 1], c=np.repeat(np.arange(max_speakers), utterances_per_speaker))\n    plt.title(f'Step {step}')\n    plt.draw()\n    if out_fpath is not None:\n        plt.savefig(out_fpath)\n    plt.pause(0.001)\n\n", "CodeBleu_score": 44.20338536408834}, {"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    if self.config.disable_visualization:\n        return\n    if embeds.shape[0] > max_speakers:\n        embeds = embeds[:max_speakers, :, :]\n        utterances_per_speaker = utterances_per_speaker[:max_speakers]\n    embeds = embeds.reshape(-1, embeds.shape[-1])\n    utterances_per_speaker = np.repeat(utterances_per_speaker, 2)\n    n_speakers = embeds.shape[0] // 2\n    utterances_per_speaker = np.repeat(utterances_per_speaker, 2)\n    embeds = reducer.fit_transform(embeds)\n    embeds_1, embeds_2 = embeds[:, 0], embeds[:, 1]\n    plt.scatter(embeds_1, embeds_2, s=1, c=utterances_per_speaker)\n    plt.gca().set_aspect(\"equal\", \"datalim\")\n    plt.clim(-0.5, max(utterances_per_speaker) + 0.5)\n    plt.title(f\"UMAP Projections Step {step}\")\n    if out_fpath is None:\n        plt.show()\n        plt.pause(0.5)\n    else:\n        plt.savefig(out_fpath)\n\n", "CodeBleu_score": 40.35782365221889}]}
{"instance_id": "274fa50985c0", "generation_result": [{"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    # Save the dimensions of input tensor.\n    (\n        batch_size,\n        text_len,\n        n_mel_channels,\n    ) = x.size()\n\n    # Determine the dimension index for speaker embedding.\n    speaker_embedding_dim = speaker_embedding.dim()\n    if speaker_embedding_dim == 2:\n        speaker_embedding_dim_index = 1\n    elif speaker_embedding_dim == 3:\n        speaker_embedding_dim_index = 2\n\n    # Repeat the speaker embedding to match the length of the input text.\n    speaker_embedding_repeated = speaker_embedding.repeat_interleave(\n        text_len, dim=speaker_embedding_dim_index\n    )\n\n    # Reshape the repeated speaker embedding to match the dimensions of the input tensor.\n    speaker_embedding_reshaped = speaker_embedding_repeated.reshape(\n        batch_size, text_len, n_mel_channels\n    )\n\n    # Transpose the reshaped speaker embedding.\n    speaker_embedding_transposed = speaker_embedding_reshaped.transpose(1, 2)\n\n    # Concatenate the speaker embedding with the input tensor along the last dimension.\n    x_with_speaker_embedding = torch.cat(\n        [x, speaker_embedding_transposed], dim=-1\n    )\n\n    return x_with_speaker_embedding\n\n", "CodeBleu_score": 33.04086435706814}, {"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    # save sizes\n    seq_len, n_channels, embedding_dim = x.size()\n    # repeat speaker embedding for each frame\n    speaker_embedding = speaker_embedding.repeat_interleave(seq_len, dim=0)\n    # reshape\n    speaker_embedding = speaker_embedding.reshape(\n        (seq_len, n_channels, embedding_dim)\n    )\n    # transpose speaker embedding\n    speaker_embedding = speaker_embedding.transpose(1, 2)\n    # concatenate\n    x = torch.cat([x, speaker_embedding], dim=-1)\n    return x\n\n", "CodeBleu_score": 20.235483741866116}, {"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    x_size = x.size()\n    se_size = speaker_embedding.size()\n    se_dim = speaker_embedding.dim()\n    if se_dim == 2:\n        speaker_embedding = speaker_embedding.repeat_interleave(x_size[0], dim=0)\n    speaker_embedding = speaker_embedding.reshape(x_size[0], x_size[1], se_size[-1])\n    speaker_embedding = speaker_embedding.transpose(1, -1)\n    x = torch.cat([x.float(), speaker_embedding.float()], dim=-1)\n    return x\n\n", "CodeBleu_score": 40.801427860775405}]}
{"instance_id": "e6742ea0fe5e", "generation_result": [{"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = next(self.parameters()).device\n    batch_size, seq_len, _ = encoder_seq_proj.size()\n    self.cumulative = torch.zeros(\n        [batch_size, seq_len], dtype=torch.float32, device=device\n    )\n    self.attention = torch.zeros(\n        [batch_size, seq_len], dtype=torch.float32, device=device\n    )\n\n", "CodeBleu_score": 27.12330408653163}, {"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = next(self.parameters()).device\n    bs, _ = encoder_seq_proj.size()\n    self.cumulative = torch.zeros(bs, self.n_tokens, device=device)\n    self.attention = torch.zeros(bs, self.n_tokens, device=device)\n\n\n", "CodeBleu_score": 30.15266338285124}, {"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = next(self.parameters()).device\n    bs, seq_len = encoder_seq_proj.size()\n    self.cumulative = torch.zeros(bs, self.max_seq_len, device=device)\n    self.attention = torch.zeros(bs, self.max_seq_len, device=device)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.9425223751153}]}
{"instance_id": "4e1fc1ed0ed7", "generation_result": [{"code": "def load(self, path, optimizer=None)\n\t\n    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    checkpoint = torch.load(path, map_location=self.device)\n    self.load_state_dict(checkpoint[\"model_state_dict\"])\n    if optimizer is not None and \"optimizer_state_dict\" in checkpoint:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n\n", "CodeBleu_score": 40.56131021566579}, {"code": "def load(self, path, optimizer=None)\n\t\n    try:\n        checkpoint = torch.load(path, map_location=self.device)\n    except FileNotFoundError:\n        print(f\"No model found at '{path}'\")\n        return\n\n    self.device = next(self.parameters()).device\n    self.load_state_dict(checkpoint[\"model_state_dict\"])\n\n    if optimizer is not None and \"optimizer_state_dict\" in checkpoint:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n\n    if \"epoch\" in checkpoint:\n        last_epoch = checkpoint[\"epoch\"]\n        print(f\"Checkpoint (epoch {last_epoch}) loaded from {path}\")\n    else:\n        print(f\"Checkpoint loaded from {path}\")\n\n    return last_epoch\n\n", "CodeBleu_score": 51.07717304206142}, {"code": "def load(self, path, optimizer=None)\n\t\n    self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    checkpoint = torch.load(path, map_location=self.device)\n    self.load_state_dict(checkpoint['model_state_dict'])\n    if optimizer is not None:\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\n", "CodeBleu_score": 41.17130300445292}]}
{"instance_id": "178e6aa16c0f", "generation_result": [{"code": "def save(self, path, optimizer=None)\n\t\n    state = {\n        'model': self.model.state_dict(),\n        'optimizer': optimizer.state_dict() if optimizer is not None else None,\n        'args': self.args,\n        'epoch': self.epoch,\n        'best_val_loss': self.best_val_loss,\n        'best_val_acc': self.best_val_acc,\n        'best_val_f1': self.best_val_f1,\n        'best_val_recall': self.best_val_recall,\n        'best_val_precision': self.best_val_precision,\n        'best_val_auc': self.best_val_auc,\n        'best_val_ap': self.best_val_ap,\n        'best_val_epoch': self.best_val_epoch,\n        'best_val_loss_epoch': self.best_val_loss_epoch,\n        'best_val_acc_epoch': self.best_val_acc_epoch,\n        'best_val_f1_epoch': self.best_val_f1_epoch,\n        'best_val_recall_epoch': self.best_val_recall_epoch,\n        'best_val_precision_epoch': self.best_val_precision_epoch,\n        'best_val_auc_epoch': self.best_val_auc_epoch,\n        'best_val_ap_epoch': self.best_val_ap_epoch,\n        'best_val_loss_state': self.best_val_loss_state,\n        'best_val_acc_state': self.best_val_acc_state,\n        'best_val_f1_state': self.best_val_f1_state,\n        'best_val_recall_state': self.best_val_recall_state,\n        'best_val_precision_state': self.best_val_precision_state,\n        'best_val_auc_state': self.best_val_auc_state,\n        '", "CodeBleu_score": 43.4993570594407}, {"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is not None:\n        torch.save({\n            'model_state_dict': self.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n        }, path)\n    else:\n        torch.save(self.state_dict(), path)\n\n", "CodeBleu_score": 64.50689885407881}, {"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is None:\n        torch.save(self.state_dict(), path)\n    else:\n        torch.save({\"model_state_dict\": self.state_dict(), \"optimizer_state_dict\": optimizer.state_dict()}, path)\n\n", "CodeBleu_score": 53.98785037133307}]}
{"instance_id": "6528fd80e87b", "generation_result": [{"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n\n", "CodeBleu_score": 55.88611500274403}, {"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n\n", "CodeBleu_score": 55.88611500274403}, {"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n\n", "CodeBleu_score": 55.88611500274403}]}
{"instance_id": "8a4fe08e0985", "generation_result": [{"code": "def text_to_sequence(text, cleaner_names)\n\t\n    sequence = []\n    while len(text):\n        m = _curly_re.match(text)\n        if not m:\n            sequence += _symbols_to_sequence(_clean_text(text, cleaner_names))\n            break\n        sequence += _symbols_to_sequence(_clean_text(m.group(1), cleaner_names))\n        sequence += _arpabet_to_sequence(m.group(2))\n        text = m.group(3)\n    sequence.append(_symbol_to_id[\"~\"])\n    return sequence\n\n", "CodeBleu_score": 83.65333784012637}, {"code": "def text_to_sequence(text, cleaner_names)\n\t\n    sequence = []\n\n    # Check for curly braces and treat their contents as ARPAbet:\n    while len(text):\n        m = _curly_re.match(text)\n        if not m:\n            sequence += _symbols_to_sequence(\n                _clean_text(text, cleaner_names))\n            break\n        sequence += _symbols_to_sequence(\n            _clean_text(m.group(1), cleaner_names))\n        sequence += _arpabet_to_sequence(m.group(2))\n        text = m.group(3)\n\n    # Append EOS token\n    sequence.append(_symbol_to_id['@spn'])\n    return sequence\n\n", "CodeBleu_score": 71.90374226004568}, {"code": "def text_to_sequence(text, cleaner_names)\n\t\n    sequence = []\n    while len(text):\n        m = _curly_re.match(text)\n        if not m:\n            clean_text = _clean_text(text, cleaner_names)\n            if m.group(1) == \"\":\n                sequence += _symbols_to_sequence(_clean_text(m.group(2), cleaner_names))\n            else:\n                sequence += _arpabet_to_sequence(m.group(2))\n            text = m.group(3)\n    return sequence\n\n", "CodeBleu_score": 60.39002360256676}]}
{"instance_id": "e1c25a37af1f", "generation_result": [{"code": "def sequence_to_text(sequence)\n\t\n    result = \"\"\n    for symbol_id in sequence:\n        if symbol_id in _id_to_symbol:\n            s = _id_to_symbol[symbol_id]\n            # Enclose ARPAbet back in curly braces\n            if len(s) > 1 and s[0] == \"@\":\n                s = \"{%s}\" % s[1:]\n            result += s\n    result = result.replace(\"}{\", \" \")\n    return result\n\n", "CodeBleu_score": 73.59928123931681}, {"code": "def sequence_to_text(sequence)\n\t\n    result = \"\"\n    for symbol_id in sequence:\n        s = _id_to_symbol[symbol_id]\n        result += \"{%s}\" % s if s in _curly else s\n    result = result.replace(\"}{\", \" \")\n    return result\n\n", "CodeBleu_score": 33.6124851499569}, {"code": "def sequence_to_text(sequence)\n\t\n    result = \"\"\n    for symbol_id in sequence:\n        if symbol_id in _id_to_symbol:\n            s = _id_to_symbol[symbol_id]\n            # Enclose ARPAbet back in curly braces\n            if len(s) > 1 and s[0] == \"@\":\n                s = \"{%s}\" % s[1:]\n            result += s\n        else:\n            result += \"{%s}\" % symbol_id\n    result = result.replace(\"}{\", \" \")\n    return result\n\n", "CodeBleu_score": 68.05691874452268}]}
{"instance_id": "7807cad4b05d", "generation_result": [{"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    # Compute the speaker embedding of the utterance\n    wav_fpath = embed_utterance[0]\n    wav = encoder.preprocess_wav(wav_fpath)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_utterance[1], embed, allow_pickle=False)\n", "CodeBleu_score": 57.9294358735881}, {"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    # Compute the speaker embedding of the utterance\n    wav_fpath, embed_fpath = fpaths\n    wav = encoder.preprocess_wav(wav_fpath)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_fpath, embed, allow_pickle=False)\n\n", "CodeBleu_score": 76.77045343010442}, {"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n    wav_fpath = embed_utterance[0]\n    embed_fpath = embed_utterance[1]\n    wav = encoder.preprocess_wav(wav_fpath)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_fpath, embed, allow_pickle=False)\n\n", "CodeBleu_score": 66.16248468583522}]}
{"instance_id": "9f860273a325", "generation_result": [{"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    wav_dir = synthesizer_root.joinpath(\"audio\")\n    metadata_fpath = synthesizer_root.joinpath(\"train.txt\")\n    assert wav_dir.exists() and metadata_fpath.exists()\n    embed_dir = synthesizer_root.joinpath(\"embeds\")\n    embed_dir.mkdir(exist_ok=True)\n\n    with metadata_fpath.open(\"r\") as metadata_file:\n        metadata = [line.split(\"|\") for line in metadata_file]\n        fpaths = [(wav_dir.joinpath(m[0]), embed_dir.joinpath(m[2])) for m in metadata]\n\n    func = partial(embed_utterance, encoder_model_fpath=encoder_model_fpath)\n    job = Pool(n_processes).imap(func, fpaths)\n    list(tqdm(job, \"Embedding\", len(fpaths), unit=\"utterances\"))\n\n", "CodeBleu_score": 90.41200959557108}, {"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    wav_dir = synthesizer_root.joinpath(\"audio\")\n    metadata_fpath = synthesizer_root.joinpath(\"train.txt\")\n    assert wav_dir.exists() and metadata_fpath.exists()\n    embed_dir = synthesizer_root.joinpath(\"embeds\")\n    embed_dir.mkdir(exist_ok=True)\n\n    with metadata_fpath.open(\"r\") as metadata_file:\n        metadata = [line.split(\"|\") for line in metadata_file]\n        fpaths = [(wav_dir.joinpath(m[0]), embed_dir.joinpath(m[2])) for m in metadata]\n\n    func = partial(embed_utterance, encoder_model_fpath=encoder_model_fpath)\n    job = Pool(n_processes).imap(func, fpaths)\n    list(tqdm(job, \"Embedding\", len(fpaths), unit=\"utterances\"))", "CodeBleu_score": 90.41200959557108}, {"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    # Verify the existence of required directories and files\n    wav_dir = synthesizer_root.joinpath(\"audio\")\n    assert wav_dir.exists()\n    metadata_fpath = synthesizer_root.joinpath(\"train.txt\")\n    assert metadata_fpath.exists()\n    embed_dir = synthesizer_root.joinpath(\"embeds\")\n    embed_dir.mkdir(exist_ok=True)\n\n    # Read the metadata file and prepare file paths\n    with metadata_fpath.open(\"r\") as metadata_file:\n        metadata = [line.split(\"|\") for line in metadata_file]\n        fpaths = [(wav_dir.joinpath(m[0]), embed_dir.joinpath(m[2])) for m in metadata]\n\n    # Create a multiprocessing pool and generate embeddings for each file\n    with Pool(n_processes) as pool:\n        futures = []\n        with tqdm(total=len(fpaths)) as pbar:\n            for wav_fpath, embed_fpath in fpaths:\n                future = pool.submit(partial(_process_utterance, wav_fpath, embed_fpath, encoder_model_fpath))\n                future.add_done_callback(lambda p: pbar.update())\n                futures.append(future)\n\n            results = [future.result() for future in tqdm(futures)]\n\n    # Save the embeddings to disk\n    synth_dir = synthesizer_root.joinpath(\"synthesizer\")\n    synth_dir.mkdir(exist_ok=True)\n    with synth_dir.joinpath(\"synthesizer.pt\").open(\"wb\") as handle:\n        pickle.dump(create_synthesizer(), handle)\n\n", "CodeBleu_score": 64.23564802932916}]}
{"instance_id": "9eb0abda14a9", "generation_result": [{"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n    attention_dir = plot_dir.joinpath('attention')\n    mel_output_dir.mkdir(exist_ok=True)\n    wav_dir.mkdir(exist_ok=True)\n    attention_dir.mkdir(exist_ok=True)\n    save_attention(attention, attention_dir.joinpath(\n        f'attention_{step}.png'))\n    np.save(mel_output_dir.joinpath(f'mel_output_{step}.npy'),\n            mel_prediction)\n    np.save(mel_output_dir.joinpath(f'target_spectrogram_{step}.npy'),\n            target_spectrogram)\n    plot_spectrogram(target_spectrogram,\n                     mel_output_dir.joinpath(f'target_spectrogram_{step}.png'))\n    plot_spectrogram(mel_prediction,\n                     mel_output_dir.joinpath(f'mel_output_{step}.png'))\n    audio.save_wav(audio.inv_mel_spectrogram(\n        mel_prediction, hparams), wav_dir.joinpath(f'wav_output_{step}.wav'))\n    audio.save_wav(audio.inv_mel_spectrogram(\n        target_spectrogram, hparams), wav_dir.joinpath(f'wav_target_{step}.wav'))\n    plot_spectrogram(mel_prediction,\n                     mel_output_dir.joinpath(f'mel_output_{step}.png'))\n    plot_spectrogram(target_spectrogram,\n                     mel_output_dir.joinpath(f'target_spectrogram_{step}.png'))\n    plot_compare_spectrogram(mel_prediction, target_spectrogram,\n                             mel_output_dir.joinpath(\n                                 f'mel_comparison_{step}.png'),\n                             f'{hparams.model_type} {time_string()} Step {step} Loss {loss:.4f}')\n    print(f'Sample {sample_num}')\n    print(f' > {sequence_to_text(input_seq)}')\n    print(f'", "CodeBleu_score": 31.685515000055663}, {"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n    attention_path = plot_dir.joinpath('attention-{}.png'.format(step))\n    save_attention(attention, attention_path)\n\n    mel_prediction = mel_prediction.transpose(0, 1)\n    mel_output_path = mel_output_dir.joinpath('mel-outputs-{}.npy'.format(step))\n    np.save(mel_output_path, mel_prediction)\n\n    wav_path = wav_dir.joinpath('wav-outputs-{}.wav'.format(step))\n    audio.save_wav(wav_path, audio.inv_mel_spectrogram(\n        mel_prediction, hparams), hparams.sample_rate)\n\n    plot_spectrogram(target_spectrogram.data.cpu().numpy()[0],\n                     mel_prediction.data.cpu().numpy()[0],\n                     attention.data.cpu().numpy()[0].T,\n                     plot_dir.joinpath('mel-spectrogram-step-{}-sample-{}.png'.format(\n                         step, sample_num)),\n                     format='png')\n\n    print('{} {} {} {}'.format(\n        time_string(),\n        ' '.join(sequence_to_text(input_seq)),\n        'step', step,\n        'loss', loss))", "CodeBleu_score": 42.485493756451696}, {"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n    attention_path = plot_dir.joinpath(f'attention-{step:09d}-{sample_num}.png')\n    save_attention(attention, attention_path)\n    mel_filename = f'mel-{step:09d}-{sample_num}.npy'\n    mel_output_path = mel_output_dir.joinpath(mel_filename)\n    np.save(mel_output_path, mel_prediction)\n    reconstructed_wav = audio.inv_mel_spectrogram(mel_prediction.T, hparams)\n    wav_path = wav_dir.joinpath(f'wav-{step:09d}-{sample_num}.wav')\n    audio.save_wav(wav_path, reconstructed_wav, hparams)\n    plot_spectrogram(target_spectrogram, plot_dir.joinpath(\n        f'mel-target-{step:09d}-{sample_num}.png'))\n    plot_spectrogram(mel_prediction, plot_dir.joinpath(\n        f'mel-predicted-{step:09d}-{sample_num}.png'))\n    plot_spectrogram(mel_prediction - target_spectrogram, plot_dir.joinpath(\n        f'mel_error-{step:09d}-{sample_num}.png'))\n    print(f'Saved outputs for step {step}, sample {sample_num}')\n    print(f'Loss: {loss:.2f}')\n    print(f'Input: {sequence_to_text(input_seq)}')\n\n", "CodeBleu_score": 36.280625947584625}]}
{"instance_id": "6bad4f500286", "generation_result": [{"code": "def num_params(self)\n\t\n    model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n    params = sum([np.prod(p.size()) for p in model_parameters])\n    print('Trainable parameters: {} Millions'.format(round(params/1000000, 3)))", "CodeBleu_score": 38.012853914892766}, {"code": "def num_params(self)\n\t\n    model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n    params = sum([np.prod(p.size()) for p in model_parameters])\n    return print(f\"{params/1e6:0.3f} million parameters\")", "CodeBleu_score": 37.57197820126542}, {"code": "def num_params(self)\n\t\n    model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n    params = sum([np.prod(p.size()) for p in model_parameters])\n    print(\"Trainable parameters: {}\".format(params / 1000000))\n    return params\n\n", "CodeBleu_score": 38.349834526859375}]}
{"instance_id": "78b876054bd4", "generation_result": [{"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    x = x.clone()\n    if pad < 1:\n        return x\n    if side == 'before':\n        new_size = (x.shape[0] + pad, x.shape[1])\n        fill_tensor = torch.zeros(new_size, dtype=x.dtype, device=x.device)\n        fill_tensor[pad:, :] = x\n    elif side == 'after':\n        new_size = (x.shape[0] + pad, x.shape[1])\n        fill_tensor = torch.zeros(new_size, dtype=x.dtype, device=x.device)\n        fill_tensor[:-pad, :] = x\n    elif side == 'both':\n        new_size = (x.shape[0] + 2 * pad, x.shape[1])\n        fill_tensor = torch.zeros(new_size, dtype=x.dtype, device=x.device)\n        fill_tensor[pad:-pad, :] = x\n    else:\n        raise ValueError(\"side must be one of 'before', 'after', or 'both'\")\n    return fill_tensor\n\n", "CodeBleu_score": 33.7355949079437}, {"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if x.size(0) >= pad:\n        return x\n    sizes = list(x.size())\n    sizes[0] = pad - x.size(0)\n    y = torch.zeros(*sizes)\n    if x.is_cuda:\n        y = y.cuda()\n    if side == 'after':\n        left = 0\n    elif side == 'before':\n        left = pad - x.size(0)\n        y[:left] = x\n    elif side == 'both':\n        left = (pad - x.size(0))//2\n        y[:left] = x[:(x.size(0)-left)]\n        y[left:left+x.size(0)] = x\n    else:\n        raise ValueError('Padding side should be one of the following: {before, after, both}')\n    y[left+x.size(0):] = x[-(pad-left-x.size(0)):]\n    return y\n\n", "CodeBleu_score": 31.19951348969735}, {"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if pad > 0:\n        if side == 'both':\n            new_size = x.size(0) + pad * 2\n        elif side == 'after':\n            new_size = x.size(0) + pad\n        else:\n            new_size = x.size(0)\n\n        if x.is_cuda:\n            new_x = torch.zeros(new_size, x.size(1), x.size(2)).cuda()\n        else:\n            new_x = torch.zeros(new_size, x.size(1), x.size(2))\n\n        if side == 'after':\n            new_x[:x.size(0), :, :] = x\n        elif side == 'before':\n            new_x[-x.size(0):, :, :] = x\n        else:\n            new_x[pad:pad + x.size(0), :, :] = x\n        x = new_x\n    return x\n\n", "CodeBleu_score": 35.31702496532637}]}
{"instance_id": "a7ed1715a3df", "generation_result": [{"code": "def save_attention(attn, path)\n\t\n    import matplotlib.pyplot as plt\n    plt.close()\n    fig = plt.figure(figsize=(12, 6))\n    plt.imshow(attn.T, interpolation='nearest', aspect='auto')\n    fig.savefig(f'{path}.png', bbox_inches='tight')\n    plt.close(fig)\n\n", "CodeBleu_score": 59.24589167006521}, {"code": "def save_attention(attn, path)\n\t\n    import matplotlib.pyplot as plt\n\n    plt.close()\n    fig = plt.figure()\n    plt.imshow(attn, aspect=\"auto\", interpolation=\"none\")\n    fig.savefig(path + \".png\")\n    plt.close(fig)\n\n", "CodeBleu_score": 42.19570771167586}, {"code": "def save_attention(attn, path)\n\t\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure()\n    plt.imshow(attn, aspect=\"auto\", interpolation=\"none\")\n    fig.savefig(path + \".png\")\n    plt.close(fig)\n\n", "CodeBleu_score": 43.553024852305356}]}
{"instance_id": "19375c9f44a2", "generation_result": [{"code": "def plot(array)\n\t\n    plt.figure(figsize=(12, 6))\n    ax = fig.add_subplot(111)\n    ax.tick_params(axis=\"x\", colors=\"blue\", labelsize=15)\n    ax.tick_params(axis=\"y\", colors=\"blue\", labelsize=15)\n    plt.plot(array, color=\"blue\")\n    plt.show()\n\n", "CodeBleu_score": 19.979831863634303}, {"code": "def plot(array)\n\t\n    fig = plt.figure(figsize=(10, 5))\n    ax = fig.add_subplot(111)\n    ax.tick_params(axis='x', colors='#777777', labelsize=12)\n    ax.tick_params(axis='y', colors='#777777', labelsize=12)\n    ax.yaxis.label.set_color('#777777')\n    ax.xaxis.label.set_color('#777777')\n    ax.set_ylabel('y-axis', fontsize=14)\n    ax.set_xlabel('x-axis', fontsize=14)\n    plt.plot(array, color='#009ACD')\n    plt.show()", "CodeBleu_score": 43.148008377153225}, {"code": "def plot(array)\n\t\n    plt.figure(figsize=(15, 5))\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.tick_params(axis='x', colors='#000000')\n    ax.tick_params(axis='y', colors='#000000')\n    plt.plot(array, color='#000000')\n    plt.set_color\n    plt.show()\n\n", "CodeBleu_score": 22.58463040103658}]}
{"instance_id": "ff94c425920c", "generation_result": [{"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    data = {\"image_name\": image_name, \"prediction\": prediction, \"confidence\": confidence}\n    csv_path = Path(\"predictions.csv\")\n    if csv_path.is_file():\n        with open(csv_path, \"a\") as csv_file:\n            writer = csv.DictWriter(csv_file, fieldnames=data.keys())\n            writer.writerow(data)\n    else:\n        with open(csv_path, \"w\") as csv_file:\n            writer = csv.DictWriter(csv_file, fieldnames=data.keys())\n            writer.writeheader()\n            writer.writerow(data)\n\n", "CodeBleu_score": 51.30570000349126}, {"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    data = {'image_name': image_name, 'prediction': prediction, 'confidence': confidence}\n    csv_path = Path('predictions.csv')\n    if csv_path.is_file():\n        with open(csv_path, 'a', newline='') as csv_file:\n            writer = csv.DictWriter(csv_file, fieldnames=data.keys())\n            writer.writeheader()\n            writer.writerow(data)\n    else:\n        with open(csv_path, 'w', newline='') as csv_file:\n            writer = csv.DictWriter(csv_file, fieldnames=data.keys())\n            writer.writeheader()\n            writer.writerow(data)", "CodeBleu_score": 50.687912708173386}, {"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    data = {'image_name': image_name, 'prediction': prediction, 'confidence': confidence}\n    csv_path = Path('predictions.csv')\n    if csv_path.is_file():\n        with open(csv_path, 'a', newline='') as csvfile:\n            writer = csv.DictWriter(csvfile, fieldnames=data.keys())\n            writer.writerow(data)\n    else:\n        with open(csv_path, 'w', newline='') as csvfile:\n            writer = csv.DictWriter(csvfile, fieldnames=data.keys())\n            writer.writeheader()\n            writer.writerow(data)", "CodeBleu_score": 51.50788982629197}]}
{"instance_id": "436161602009", "generation_result": [{"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    try:\n        LOGGER.info(f\"", "CodeBleu_score": 9.912281340461456}, {"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    try:\n        import torch\n\n        LOGGER.info(f\"{prefix} starting export with torch {torch.__version__}...\")\n        f = (file.with_suffix(\".ts\") if optimize else file)\n        _ = (\n            model.model[-1]\n            if isinstance(model, Ensemble)\n            else model[-1]\n        )\n        ts = torch.jit.trace(_, im.half() if model.fp16 else im)\n        ts = optimize_for_mobile(ts) if optimize else ts\n        (optimize and _save_for_lite_interpreter(ts, file))\n        (ts.save(f) if optimize else ts.save(file))\n        LOGGER.info(f\"{prefix} export success, saved as {file} ({file.stat().st_size} bytes)\")\n        return (f, None)\n    except Exception as e:\n        LOGGER.warning(f\"{prefix} export failure: {e}\")\n        return (None, e)\n\n", "CodeBleu_score": 49.48149883355742}, {"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    try:\n        import torch\n\n        LOGGER.info(f\"", "CodeBleu_score": 10.027696614025022}]}
{"instance_id": "78335487ac1c", "generation_result": [{"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t\n    try:\n        import coremltools as ct\n\n        LOGGER.info(f\"", "CodeBleu_score": 9.958821115096491}, {"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t\n\n", "CodeBleu_score": 5.903316866619619}, {"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t\n    try:\n        import coremltools as ct\n\n        LOGGER.info(f\"", "CodeBleu_score": 9.958821115096491}]}
{"instance_id": "80233cf71580", "generation_result": [{"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for i in range(individual_length):\n        individual.append(random.uniform(input_ranges[i][0], input_ranges[i][1]))\n    return individual\n\n", "CodeBleu_score": 47.630972577458174}, {"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for i in range(individual_length):\n        individual.append(random.uniform(input_ranges[i][0], input_ranges[i][1]))\n    return individual\n\n", "CodeBleu_score": 47.630972577458174}, {"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for i in range(individual_length):\n        individual.append(random.uniform(input_ranges[i][0], input_ranges[i][1]))\n    return individual\n\n", "CodeBleu_score": 47.630972577458174}]}
{"instance_id": "5ea979cb4a8e", "generation_result": [{"code": "def marginal_log_mean_coeff(self, t)\n\t\n    log_alpha = self.log_alpha_fn(t)\n    if self.schedule == 'discrete':\n        return log_alpha\n    elif self.schedule == 'linear':\n        return torch.log(self.alpha_0) + 0.5 * log_alpha\n    elif self.schedule == 'cosine':\n        return torch.log(self.alpha_0) - torch.cos((t + self.T / 2) / self.T * torch.pi) * log_alpha\n    else:\n        raise ValueError(f'Invalid schedule: {self.schedule}')\n", "CodeBleu_score": 36.240905799373}, {"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule_type == 'discrete':\n        return self.log_alpha_fn(t)\n    elif self.schedule_type == 'linear':\n        return self.log_alpha_fn(t) + self.interpolate_fn(t)\n    elif self.schedule_type == 'cosine':\n        return self.log_alpha_fn(t) + self.interpolate_fn(t)\n    else:\n        raise ValueError(f\"Invalid schedule type: {self.schedule_type}\")\n\n", "CodeBleu_score": 28.85662592710853}, {"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule == 'discrete':\n        log_alpha_t = log_alpha_fn(t)\n    elif self.schedule == 'linear':\n        log_alpha_t = log_alpha_fn(t) + (self.log_alpha_max - self.log_alpha_min) * (t - self.num_discrete_timesteps) / (self.num_discrete_timesteps - 1)\n    elif self.schedule == 'cosine':\n        t = t.float()\n        log_alpha_t = torch.log(interpolate_fn(torch.cos(torch.pi / 2 * (t / self.num_discrete_timesteps)), torch.tensor([0.0, 1.0])))\n    return log_alpha_t\n\n", "CodeBleu_score": 46.788670013815725}]}
{"instance_id": "7da4fae5a278", "generation_result": [{"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == \"linear\":\n        return 1.0 / self.beta_0 * (torch.exp(self.beta_0 * lamb) - 1.0)\n    elif self.schedule == \"quadratic\":\n        return 1.0 / self.alpha_0 / self.alpha_0 * (torch.sqrt(torch.exp(self.alpha_0 * lamb) - 1.0) - 1.0)\n    elif self.schedule == \"sigmoid\":\n        return 1.0 / self.alpha_0 * torch.log(1.0 / lamb - 1.0)\n    elif self.schedule == \"vp\":\n        return 1.0 / self.alpha_0 * (1.0 - torch.exp(-torch.exp(self.alpha_0 * lamb)))\n    elif self.schedule == \"discrete\":\n        return interpolate_fn(self.log_alpha, lamb)\n    else:\n        return 1.0 / self.alpha_0 * torch.arccos(1.0 / lamb - 1.0)\n\n", "CodeBleu_score": 20.801972546047967}, {"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == \"linear\":\n        return (torch.sqrt(self.beta_0 ** 2 + 2 * lamb * (self.beta_1 - self.beta_0)) - self.beta_0) / (self.beta_1 - self.beta_0)\n    elif self.schedule == \"quadratic\":\n        return (torch.sqrt(self.beta_0 ** 2 + 2 * lamb * (self.beta_1 - self.beta_0)) - self.beta_0) / (self.beta_1 - self.beta_0)\n    elif self.schedule == \"sigmoid\":\n        return (torch.sqrt(self.beta_0 ** 2 + 2 * lamb * (self.beta_1 - self.beta_0)) - self.beta_0) / (self.beta_1 - self.beta_0)\n    elif self.schedule == \"step\":\n        return (torch.sqrt(self.beta_0 ** 2 + 2 * lamb * (self.beta_1 - self.beta_0)) - self.beta_0) / (self.beta_1 - self.beta_0)\n    else:\n        log_alpha = torch.log(lamb) / 2.0 - torch.logaddexp(torch.log(self.alpha_cum[0]), -2.0 * torch.log(self.alpha_cum[-1]))\n        log_alpha = log_alpha.to(self.device)\n        t = interpolate_fn(self.alpha_cum, log_alpha)\n        return t\n\n", "CodeBleu_score": 35.785676346556365}, {"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == \"linear\":\n        t = (torch.exp(self.log_beta_min + (self.log_beta_max - self.log_beta_min) * lamb) - 1) / (\n            torch.exp(self.log_beta_max) - 1\n        )\n        return t\n    elif self.schedule == \"quadratic\":\n        t = (torch.exp(self.log_beta_min + (self.log_beta_max - self.log_beta_min) * lamb) - 1) / (\n            torch.exp(self.log_beta_max) - 1\n        )\n        return t ** 2\n    elif self.schedule == \"sigmoid\":\n        t = (torch.exp(self.log_beta_min + (self.log_beta_max - self.log_beta_min) * lamb) - 1) / (\n            torch.exp(self.log_beta_max) - 1\n        )\n        return torch.sigmoid(t)\n    elif self.schedule == \"discrete\":\n        t = interpolate_fn(self.log_alpha, lamb)\n        return t\n    elif self.schedule == \"cosine\":\n        t = (torch.exp(self.log_beta_min + (self.log_beta_max - self.log_beta_min) * lamb) - 1) / (\n            torch.exp(self.log_beta_max) - 1\n        )\n        return torch.arccos(1 - 2 * t) / math.pi\n    elif self.schedule == \"sqrt\":\n        t = (torch.exp(self.log_beta_min + (self.log_beta_max - self.log_beta_min) * lamb) - 1) / (\n            torch.exp(self.log_beta_max) - 1\n        )\n        return t ** 0.5\n    elif self.schedule == \"sqrt_reverse\":\n        t = (torch.exp(self.log_beta_min + (self.log_beta_max -", "CodeBleu_score": 25.315911423963687}]}
{"instance_id": "a519c853a2b2", "generation_result": [{"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\t\n    batch_size = x.shape[0]\n    t_expanded = expand_dims(t_continuous, 0)\n    t_expanded = t_expanded.expand(batch_size, -1)\n    if cond is not None:\n        cond = expand_dims(cond, 0)\n        cond = cond.expand(batch_size, -1)\n    model_input = get_model_input_time(x, t_expanded, cond)\n    model_output = model(model_input)\n    if model_output.shape[1] == x.shape[1]:\n        return model_output\n    elif model_output.shape[1] == 2 * x.shape[1]:\n        mean, log_var = model_output.chunk(2, dim=1)\n        log_var = noise_schedule.marginal_log_mean_coeff(t_continuous).reshape(-1, *([1] * (len(x.shape) - 1))) + log_var\n        std = noise_schedule.marginal_std(t_continuous).reshape(-1, *([1] * (len(x.shape) - 1)))\n        return mean + std * randn_like(x) * log_var.exp()\n    else:\n        raise ValueError(\"Unexpected model output shape: {}\".format(model_output.shape))\n\n", "CodeBleu_score": 34.51256531638614}, {"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\t\n    if cond is not None:\n        x = torch.cat([x, cond], dim=1)\n    t_continuous = t_continuous.expand(x.size(0), 1)\n    if model_type == \"diffusion\":\n        x = model(x, t_continuous)\n    elif model_type == \"ddpm\":\n        x = model(x, t_continuous)\n    elif model_type == \"ddim\":\n        x = model(x, t_continuous)\n    elif model_type == \"improved_ddpm\":\n        x = model(x, t_continuous)\n    elif model_type == \"ddpm_conditional\":\n        x = model(x, t_continuous, cond=cond)\n    elif model_type == \"ddim_conditional\":\n        x = model(x, t_continuous, cond=cond)\n    elif model_type == \"improved_ddpm_conditional\":\n        x = model(x, t_continuous, cond=cond)\n    else:\n        raise ValueError(f\"Unknown model type: {model_type}\")\n\n    if model_type in [\"diffusion\", \"ddpm\", \"ddim\", \"improved_ddpm\"]:\n        x = noise_schedule.marginal_std(t_continuous) * x\n    elif model_type in [\n        \"ddpm_conditional\",\n        \"ddim_conditional\",\n        \"improved_ddpm_conditional\",\n    ]:\n        x = noise_schedule.marginal_std(t_continuous) * x\n        x += noise_schedule.marginal_mean(t_continuous) * (\n            cond - noise_schedule.marginal_std(t_continuous) * x\n        )\n    return x\n\n", "CodeBleu_score": 36.767823381221696}, {"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\t\n    batch_size = x.shape[0]\n    t_continuous = t_continuous.expand(batch_size)\n    if cond is not None:\n        x = torch.cat([x, cond], dim=1)\n    x = model(x, t_continuous)\n    if model.model_type == 'eps':\n        x = x * noise_schedule.marginal_std(t_continuous)\n    elif model.model_type == 'v':\n        x = x * noise_schedule.marginal_std(t_continuous) + noise_schedule.marginal_mean(t_continuous)\n    elif model.model_type == 'v_pred':\n        alpha_bar = noise_schedule.marginal_alpha(t_continuous)\n        sigma = noise_schedule.marginal_std(t_continuous)\n        alpha = alpha_bar.sqrt()\n        c = -sigma.log()\n        x = x * alpha + c\n    return x\n\n", "CodeBleu_score": 35.08150829478235}]}
{"instance_id": "96a9b7d54823", "generation_result": [{"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t\n    if t is None:\n        t = self.threshold\n    x0 = x0.reshape(-1)\n    x0 = torch.quantile(torch.abs(x0), t)\n    x0 = torch.maximum(x0, torch.tensor(1.0))\n    x0 = x0 * torch.ones_like(x0)\n    x0 = x0.reshape(x0.shape[0], -1)\n    x0 = torch.clamp(x0, -1, 1)\n    return x0\n\n", "CodeBleu_score": 40.5271913833284}, {"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t\n    if t is None:\n        t = self.t\n    x0 = x0.reshape(-1)\n    x0 = torch.quantile(torch.abs(x0), t)\n    x0 = torch.maximum(x0, torch.ones_like(x0) * 1e-6)\n    x0 = 1.0 / x0\n    x0 = torch.clamp(x0, 1e-2, 1e2)\n    x0 = x0 * x0.numel() * 0.5\n    x0 = x0.reshape(x0.shape + (1,) * (x0.dim() - 1))\n    return x0\n\n", "CodeBleu_score": 40.98510016017875}, {"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t\n    if t is None:\n        t = self.threshold\n    s = torch.quantile(torch.abs(x0).reshape(-1), t, interpolation='higher')\n    s = torch.maximum(s, torch.tensor(1.0, device=x0.device))\n    return torch.clamp(x0 / s, -1.0, 1.0) * s\n\n", "CodeBleu_score": 35.93054720961405}]}
{"instance_id": "59c6ec6d7a6a", "generation_result": [{"code": "def data_prediction_fn(self, x, t)\n\t\n    x0 = x[:, 0]\n    dynamic_thresholding_ratio = self.dynamic_thresholding_ratio\n    max_threshold = self.max_threshold\n    threshold = dynamic_thresholding_ratio * torch.quantile(torch.abs(x0), 0.95, dim=0)\n    threshold = torch.clamp(threshold, min=1e-20, max=max_threshold)\n    x0 = torch.clamp(x0, -threshold, threshold)\n    x0 = x0 / threshold\n    return x0.reshape(x0.shape + (1,))\n\n", "CodeBleu_score": 23.33755335667672}, {"code": "def data_prediction_fn(self, x, t)\n\t\n    # x is the [N x C x ...] tensor of [0, 1]-real valued data\n    # t is the [N] vector of timesteps in the diffusion process (torch.int64)\n\n    # HINT: self.dynamic_threshold is _not_ the error threshold but a factor to adjust the threshold used for dynamic thresholding\n    # HINT: self.dynamic_threshold_ratio is _not_ the sigma but rather a scaling factor to the desired max threshold\n    # HINT: self.dynamic_threshold_v is the verbose option\n\n    # get the desired quantile range\n    q_lo = self.quantile_lo\n    q_hi = self.quantile_hi\n\n    # get the quantile range for the data x\n    q_x_lo = torch.quantile(x, q_lo, dim=1)\n    q_x_hi = torch.quantile(x, q_hi, dim=1)\n\n    # calculate the quantile range for the noise\n    q_n_lo = q_x_hi - q_x_lo\n    q_n_hi = q_x_hi - q_x_lo\n\n    # calculate the dynamic threshold value\n    dynamic_threshold = self.dynamic_threshold_ratio * torch.maximum(\n        torch.abs(q_n_lo), torch.abs(q_n_hi)\n    )\n\n    # clamp the input tensor values within the threshold\n    x = torch.clamp(x, min=-dynamic_threshold, max=dynamic_threshold)\n\n    # normalize the clamped values\n    x = x / dynamic_threshold\n\n    if self.dynamic_threshold_v:\n        print(f\"Quantile range x: {q_x_lo.min():.3f} {q_x_hi.max():.3f}\")\n        print(f\"Quantile range n: {q_n_lo.min():.3f} {q_n_hi.max():.3f}\")\n        print(f\"Dynamic threshold: {dynamic_threshold.max():.3f}\")\n\n    return x\n", "CodeBleu_score": 19.092691419270487}, {"code": "def data_prediction_fn(self, x, t)\n\t\n    x0 = self.diffusion_model(x, t)\n    dynamic_threshold = self.max_threshold * (self.dynamic_threshold_ratio ** t)\n    x0 = torch.clamp(x0, min=-dynamic_threshold, max=dynamic_threshold) / dynamic_threshold\n    return x0\n\n", "CodeBleu_score": 7.123265636369299}]}
{"instance_id": "65e3618468a2", "generation_result": [{"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = sigma_in.view(input.shape)\n    scaled_input = input / sigma_in\n    prediction = model(scaled_input, sigma_in, **kwargs)\n    adjusted_prediction = prediction * sigma_in\n    return adjusted_prediction\n\n", "CodeBleu_score": 21.4017912978054}, {"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = sigma_in.view(input.shape)\n    input = input * sigma_in\n    pred = model(input, **kwargs)\n    pred = pred * sigma_in\n    return pred\n\n", "CodeBleu_score": 27.05261027619912}, {"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = sigma_in.view(input.shape[0], 1, 1, 1)\n    input = input * sigma_in\n    prediction = model(input, sigma_in, **kwargs)\n    return prediction * sigma_in\n\n", "CodeBleu_score": 31.628955905372013}]}
{"instance_id": "b35846dfbc66", "generation_result": [{"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.enable_grad():\n        alpha = beta_0 + beta_1 * taus\n        log_alpha = torch.log(alpha)\n        log_alpha.backward(gradient=torch.ones_like(log_alpha), retain_graph=True)\n        t2alpha_fn = taus.grad\n    integrand = torch.exp(log_alpha.sum()) * torch.sqrt(torch.tensor(2 * np.pi)) * torch.exp(\n        torch.mm(torch.mm(taus.t(), t2alpha_fn), taus) / 2)\n    return integrand\n\n", "CodeBleu_score": 40.296295704496565}, {"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.inference_mode():\n        alpha = torch.sqrt(beta_0 ** 2 + beta_1 ** 2)\n        log_alpha = torch.log(alpha)\n        taus.requires_grad_()\n        taus.grad = None\n        log_alpha.backward()\n        integrand = torch.exp(log_alpha) * taus.grad\n    return integrand\n\n", "CodeBleu_score": 29.673218912315047}, {"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.inference_mode():\n        alpha = beta_0 + beta_1 * taus\n        log_alpha = torch.log(alpha)\n        log_alpha.requires_grad_(True)\n        taus.requires_grad_(True)\n        alpha.requires_grad_(True)\n        log_alpha.backward(torch.ones_like(log_alpha), retain_graph=True)\n        grad_log_alpha = taus.grad\n        taus.grad = None\n        grad_log_alpha.requires_grad_(True)\n        integrand = torch.exp(log_alpha) * grad_log_alpha\n        return integrand\n\n", "CodeBleu_score": 33.153474052079055}]}
{"instance_id": "5f3667566a10", "generation_result": [{"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    extra_args = {} if extra_args is None else extra_args\n    s_in = x.new_ones([x.shape[0]])\n    if noise_sampler is None:\n        noise_sampler = get_ancestral_step\n    if callback is None:\n        callback = lambda x: x\n    with trange(len(sigmas), disable=disable) as t:\n        for i in t:\n            sigma_t = sigmas[i]\n            sigma_t_next = sigmas[i + 1] if i < len(sigmas) - 1 else 0.0\n            sigma_hat = sigma_t\n            sigma_hat_next = sigma_t_next\n            if eta != 0.0:\n                sigma_hat = ((sigma_t ** 2 + sigma_t_next ** 2) / 2) ** 0.5\n                sigma_hat_next = ((sigma_t_next ** 2 + sigma_t_next ** 2) / 2) ** 0.5\n            x = model(x, sigma_hat * s_in, **extra_args)\n            x = noise_sampler(x, sigma_hat, sigma_hat_next, s_noise, s_in, extra_args)\n            x = callback({'x': x, 'i': i, 'sigma': sigma_hat, 'sigma_hat': sigma_hat, 'eta': eta})\n            x = x.to(dtype=to_d(x))\n            t.set_postfix(ordered_dict={'sigma': sigma_hat, 'sigma_hat': sigma_hat, 'eta': eta})\n    return x", "CodeBleu_score": 44.029225924646695}, {"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    extra_args = {} if extra_args is None else extra_args\n    s_in = x.new_ones([x.shape[0]])\n    if noise_sampler is None:\n        noise_sampler = get_ancestral_step\n    if callback is None:\n        callback = lambda st, *args, **kwargs: st\n    with trange(len(sigmas), disable=disable) as t:\n        for i in t:\n            sigma_hat = sigmas[i] * s_noise\n            x = model(x, sigma_hat * s_in, **extra_args)\n            x, x_mean = noise_sampler(model, x, sigma_hat * s_in, s_in, extra_args=extra_args, disable=disable)\n            x = x_mean + (x - x_mean) * to_d(eta, x.dtype)\n            t.set_postfix(ordered_dict={'sigma': sigmas[i]})\n            x = callback({'x': x, 'i': i, 'sigma': sigmas[i], 'sigma_hat': sigma_hat, 'eta': eta}, x)\n        x = x.clamp(-1, 1)\n    return x", "CodeBleu_score": 43.53417537622928}, {"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    extra_args = {} if extra_args is None else extra_args\n    s_in = x.new_ones([x.shape[0]])\n    sigma_fn = lambda t: t.new_tensor(sigmas)\n    noise_sampler = default_noise_sampler if noise_sampler is None else noise_sampler\n    with torch.enable_grad():\n        with trange(len(sigmas), disable=disable) as pbar:\n            for i in pbar:\n                model_output = model(x, sigma_fn(s_in) * s_noise, **extra_args)\n                eps = noise_sampler(x)\n                denoised = x + (sigma_fn(s_in) * model_output + eps) * eta\n                d = to_d(x, sigma_fn(s_in), denoised)\n                yield denoised\n                dt = sigma_fn(s_in) - sigma_fn(s_in.new_tensor([sigmas[i]]))\n                x = x + get_ancestral_step(sigma_fn(s_in.new_tensor([sigmas[i]])), d) * dt\n                if callback is not None:\n                    callback({'x': x, 'i': i, 'sigma': sigma_fn(s_in.new_tensor([sigmas[i]])), 'sigma_hat': sigma_fn(s_in), 'denoised': denoised})\n                s_in = sigma_fn(s_in.new_tensor([sigmas[i]]))\n                if sigma_fn(s_in) > 0:\n                    x = x + sigma_fn(s_in) * torch.randn_like(x)\n    return x", "CodeBleu_score": 47.70618852070607}]}
{"instance_id": "6261ded88df2", "generation_result": [{"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    if order < i:\n        raise ValueError(\"Order of integrator must be at least equal to the number of steps\")\n    def prod(t):\n        res = 1\n        for k in range(i, i + order):\n            if k != j:\n                res *= (t - t[k]) / (t[j] - t[k])\n        return res\n    return integrate.quad(prod, t[i], t[i + 1])[0]\n\n\n", "CodeBleu_score": 31.870942985220633}, {"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    if order < i:\n        raise ValueError(f\"Order {order} is too high for step index {i}.\")\n    def product_term(s):\n        return np.prod([(s - j) / (i - j) for j in range(order) if j != i])\n    return integrate.quad(product_term, t[i], t[i + 1])[0]\n\n\n", "CodeBleu_score": 27.85776453123838}, {"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    def product_term(t_):\n        prod = 1\n        for k in range(order):\n            if k != j:\n                prod *= (t_ - t[i + k]) / (t[i + j] - t[i + k])\n        return prod\n\n    if j >= order:\n        raise ValueError(\"Order is too high for the step index.\")\n    return integrate.quad(product_term, t[i], t[i + 1])[0]\n\n", "CodeBleu_score": 57.595826285391674}]}
{"instance_id": "4ee025e33ab1", "generation_result": [{"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    extra_args = {} if extra_args is None else extra_args\n    s_in = x.new_ones([x.shape[0]])\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    for sigma in trange(len(sigmas), disable=disable):\n        adjusted_sigma = sigmas[sigma].item()\n        extra_args['sigma'] = adjusted_sigma\n        extra_args['sigma_hat'] = adjusted_sigma\n        extra_args['s_in'] = s_in\n        with torch.no_grad():\n            denoised = model(x, sigma, **extra_args)\n        x = x + (denoised - x) * (sigmas[sigma] / sigmas[sigma - 1])\n        x, s_in = noise_scaling(x, s_in, sigmas[sigma], noise_sampler)\n        if callback is not None:\n            callback({'x': x, 'i': sigma, 'sigma': adjusted_sigma, 'sigma_hat': adjusted_sigma, 'denoised': denoised})\n    return x", "CodeBleu_score": 50.14631211402203}, {"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    s_in = x.new_ones([x.shape[0]])\n    for sigma in trange(len(sigmas), disable=disable):\n        extra_args['sigma'] = sigmas[sigma]\n        sigma = sigmas[sigma].item()\n        e_t = model(x, sigma, **extra_args)\n        if callback is not None:\n            callback({'x': x, 'i': sigma, 'sigma': sigmas[sigma], 'sigma_hat': sigmas[sigma], 'denoised': x})\n        denoised_x = x + e_t * (s_in - sigmas[sigma])\n        if sigmas[sigma] > 0:\n            x = x + noise_scaling * (denoised_x - x)\n        else:\n            x = denoised_x\n    return x\n\n", "CodeBleu_score": 51.090275992598336}, {"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    extra_args = {} if extra_args is None else extra_args\n    s_in = x.new_ones([x.shape[0]])\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    for sigma in trange(len(sigmas), disable=disable):\n        extra_args['sigma'] = sigmas[sigma].item()\n        sigma_down, sigma_up = sigmas[sigma], sigmas[sigma + 1] if sigma + 1 < len(sigmas) else 0.0\n        model_fn = model_wrapper(model, sigma_down, sigma_up, extra_args=extra_args)\n        denoised = model_fn(x, s_in)\n        if callback is not None:\n            callback({'x': x, 'i': sigma, 'sigma': sigmas[sigma], 'sigma_hat': sigmas[sigma], 'denoised': denoised})\n        t = sigma - len(sigmas)\n        x = x + noise_scaling(sigma_up, sigma_down, noise_sampler(x, t))\n    return x\n\n", "CodeBleu_score": 49.097016205712826}]}
{"instance_id": "cb51f91da606", "generation_result": [{"code": "def append_dims(x, target_dims)\n\t\n    dims_to_append = target_dims - x.ndim\n    if dims_to_append < 0:\n        raise ValueError(\n            f\"target_dims must be >= x.ndim, but got target_dims={target_dims} and x.ndim={x.ndim}\"\n        )\n    for _ in range(dims_to_append):\n        x = x[..., None]\n    if x.device.type == \"mps\":\n        return x.detach().clone()\n    return x.expand([-1] * dims_to_append)", "CodeBleu_score": 41.640503583611064}, {"code": "def append_dims(x, target_dims)\n\t\n    dims_to_append = target_dims - x.ndim\n    if dims_to_append < 0:\n        raise ValueError(\n            f\"target_dims must be >= x.ndim, but got target_dims={target_dims} and x.ndim={x.ndim}\")\n    for _ in range(dims_to_append):\n        x = torch.unsqueeze(x, -1)\n    if x.device.type == 'mps':\n        return x.detach().clone()\n    else:\n        return x", "CodeBleu_score": 48.66388901559221}, {"code": "def append_dims(x, target_dims)\n\t\n    ndims = len(x.shape)\n    if ndims > target_dims:\n        raise ValueError(\"expand_dims: target dims must be >= input dims\")\n    elif ndims == target_dims:\n        return x\n    else:\n        return x.expand(*x.shape, *(1,) * (target_dims - ndims))\n\n", "CodeBleu_score": 18.311829129441254}]}
{"instance_id": "9fac874a3bc7", "generation_result": [{"code": "def download_file(path, url, digest=None)\n\t\n    path = Path(path)\n    if path.exists():\n        return path\n    path.parent.mkdir(parents=True, exist_ok=True)\n    with urlopen(url) as source, path.open(\"wb\") as target:\n        copyfileobj(source, target)\n    if digest is not None:\n        if sha256(path.read_bytes()).hexdigest() != digest:\n            path.unlink()\n            raise OSError(\"incorrect hash\")\n    return path\n\n", "CodeBleu_score": 35.38250405805929}, {"code": "def download_file(path, url, digest=None)\n\t\n    if path.exists():\n        return path\n    path.parent.mkdir(parents=True, exist_ok=True)\n    with urlopen(url) as source, path.open(\"wb\") as target:\n        copyfileobj(source, target)\n    if digest is not None:\n        if digest != sha256(path.read_bytes()).hexdigest():\n            path.unlink()\n            raise OSError(\"Validation failed for \" + path.as_posix())\n    return path\n\n", "CodeBleu_score": 35.30639472506547}, {"code": "def download_file(path, url, digest=None)\n\t\n    target_dir = Path(path).parent\n    target_dir.mkdir(parents=True, exist_ok=True)\n    if not path.exists():\n        with urlopen(url) as source, open(path, \"wb\") as target:\n            copyfileobj(source, target)\n    if digest:\n        if digest != hashlib.sha256(open(path, \"rb\").read()).hexdigest():\n            raise OSError(\"incorrect hash\")\n    return path\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.90176837983188}]}
{"instance_id": "f23165e897ce", "generation_result": [{"code": "def train_mode(model, mode=True)\n\t\n    modes = [module.training for module in model.modules()]\n    model.train(mode)\n    try:\n        yield\n    finally:\n        for module, mode in zip(model.modules(), modes):\n            module.training = mode\n\n", "CodeBleu_score": 45.17133808214328}, {"code": "def train_mode(model, mode=True)\n\t\n    modes = [module.training for module in model.modules()]\n    try:\n        model.train(mode)\n        yield\n    finally:\n        for module, mode in zip(model.modules(), modes):\n            module.training = mode\n\n", "CodeBleu_score": 49.69474930325445}, {"code": "def train_mode(model, mode=True)\n\t\n    modes = [module.training for module in model.modules()]\n    try:\n        model.train(mode)\n        yield\n    finally:\n        for module, mode in zip(model.modules(), modes):\n            module.train(mode)\n\n", "CodeBleu_score": 51.903543059206555}]}
{"instance_id": "c6d59c6cb8e1", "generation_result": [{"code": "def ema_update(model, averaged_model, decay)\n\t\n    with torch.no_grad():\n        for model_param, averaged_param in zip(model.parameters(), averaged_model.parameters()):\n            averaged_param.data.mul_(decay).add_((1 - decay) * model_param.data)\n        for model_buffer, averaged_buffer in zip(model.buffers(), averaged_model.buffers()):\n            averaged_buffer.data.copy_(model_buffer.data)\n\n", "CodeBleu_score": 32.80121562764856}, {"code": "def ema_update(model, averaged_model, decay)\n\t\n    # Get the model's named parameters and buffers\n    model_params = dict(model.named_parameters())\n    model_buffers = dict(model.named_buffers())\n\n    # Get the averaged model's named parameters and buffers\n    averaged_params = dict(averaged_model.named_parameters())\n    averaged_buffers = dict(averaged_model.named_buffers())\n\n    # Iterate through the model's parameters and update the averaged model's parameters\n    for key in model_params.keys():\n        averaged_params[key].mul_(decay).add_(model_params[key], alpha=1 - decay)\n\n    # Iterate through the model's buffers and copy them to the averaged model's buffers\n    for key in model_buffers.keys():\n        averaged_buffers[key].copy_(model_buffers[key])\n\n", "CodeBleu_score": 41.61098223857475}, {"code": "def ema_update(model, averaged_model, decay)\n\t\n    with torch.no_grad():\n        for current_params, averaged_params in zip(model.parameters(), averaged_model.parameters()):\n            averaged_params.data.mul_(decay).add_((1 - decay) * current_params.data)\n        for current_buffers, averaged_buffers in zip(model.buffers(), averaged_model.buffers()):\n            averaged_buffers.data.copy_(current_buffers.data)\n\n", "CodeBleu_score": 32.712547230059556}]}
{"instance_id": "600c39a30798", "generation_result": [{"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, dtype=dtype, device=device)\n    max_value = torch.as_tensor(max_value, dtype=dtype, device=device)\n    u = torch.rand(shape, dtype=dtype, device=device)\n    return (min_value.log() - max_value.log() - torch.log(1 - u) / scale).exp() * scale + loc\n\n", "CodeBleu_score": 27.351145814261912}, {"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, dtype=dtype, device=device)\n    max_value = torch.as_tensor(max_value, dtype=dtype, device=device)\n    u = torch.rand(shape, dtype=dtype, device=device)\n    min_cdf = min_value.log().sub(loc).div(scale).sigmoid()\n    max_cdf = max_value.log().sub(loc).div(scale).sigmoid()\n    return u.mul(max_cdf - min_cdf).add(min_cdf).logit().mul(scale).add(loc).exp()\n\n", "CodeBleu_score": 42.248742905655114}, {"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, device=device, dtype=dtype)\n    max_value = torch.as_tensor(max_value, device=device, dtype=dtype)\n    u = torch.rand(shape, device=device, dtype=dtype)\n    min_cdf = min_value.log().sub(loc).div(scale).sigmoid()\n    max_cdf = max_value.log().sub(loc).div(scale).sigmoid()\n    return u.mul(max_cdf - min_cdf).add(min_cdf).logit().mul(scale).add(loc).exp()\n\n", "CodeBleu_score": 45.45199404587386}]}
{"instance_id": "75e2def2467f", "generation_result": [{"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return nn.ELU(inplace=True)\n    elif activation == \"snake\":\n        return SnakeBeta(channels, antialias=antialias)\n    elif activation == \"none\":\n        return nn.Identity()\n    else:\n        raise ValueError(\"Activation should be one of 'elu', 'snake' or 'none'\")\n\n", "CodeBleu_score": 38.041801850429806}, {"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return nn.ELU()\n    elif activation == \"snake\":\n        if channels is None:\n            raise ValueError(\"Snake activation requires a channel size\")\n        return SnakeBeta(channels, antialias=antialias)\n    elif activation == \"none\":\n        return nn.Identity()\n    else:\n        raise ValueError(f\"Activation {activation} not supported\")\n\n", "CodeBleu_score": 40.101672187075906}, {"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return nn.ELU()\n    elif activation == \"snake\":\n        return SnakeBeta(channels, antialias=antialias)\n    elif activation == \"none\":\n        return nn.Identity()\n    else:\n        raise ValueError(f\"activation {activation} not recognized\")\n\n", "CodeBleu_score": 39.14511014379335}]}
{"instance_id": "ef1714c79e51", "generation_result": [{"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t\n    t, t_unrotated = t[..., :scale], t[..., scale:]\n    freqs = freqs.to(t.dtype)\n    t, t_unrotated = map(lambda t: t.view(*t.shape[:-1], -1, 2), (t, t_unrotated))\n    t = torch.cat((t, t_unrotated), dim=-2)\n    t = apply_rotary_pos_emb_torch(t, freqs)\n    return t\n", "CodeBleu_score": 17.34935143541783}, {"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t\n    if freqs.ndim == 1:\n        freqs = freqs[:, None]\n    t, t_unrotated = t[..., ::2], t[..., 1::2]\n    t, t_unrotated = t.to(torch.float32), t_unrotated.to(torch.float32)\n    t, t_unrotated = t.view([t.shape[0], t.shape[1], -1, 2]), t_unrotated.view([t_unrotated.shape[0], t_unrotated.shape[1], -1, 2])\n    t = apply_rotary_pos_emb_subset(t, freqs, scale = scale)\n    t_unrotated = apply_rotary_pos_emb_subset(t_unrotated, freqs, scale = scale)\n    t = torch.cat([t, t_unrotated], dim = -1).flatten(-2)\n    return t\n\n", "CodeBleu_score": 37.414846950519745}, {"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t\n    if freqs.ndim == 1:\n        freqs = freqs[None]\n\n    t, t_unrotated = rearrange(t, 'b (d j) ... -> b d j ...', j = 2), req.t[:, t.shape[1] % 2:]\n    t, t_unrotated = t.to(torch.float32), t_unrotated.to(torch.float32)\n    t, t_unrotated = t.mul_(scale), t_unrotated.mul_(scale)\n\n    freqs = freqs.to(t.device)\n\n    rot_dim = freqs.shape[-1]\n    (t, t_unrotated), (freqs, _) = map(lambda t: rearrange(t, '... (d j) -> ... d j', j = 2), (t, t_unrotated, freqs))\n    t, t_unrotated = apply_rotary_pos_emb_list(t, freqs)\n    t, t_unrotated = map(lambda t: rearrange(t, '... d j -> ... (d j)'), (t, t_unrotated))\n    t = torch.cat((t, t_unrotated), dim = -1)\n    return t\n\n", "CodeBleu_score": 42.873518856079116}]}
{"instance_id": "a7a5f178c6f6", "generation_result": [{"code": "def idx2vq(self, idx, dim=-1)\n\t\n    vq = self.codebook.get_embedding(idx)\n    if dim != -1:\n        vq = vq.movedim(-1, dim)\n    return vq\n\n", "CodeBleu_score": 38.05777995440778}, {"code": "def idx2vq(self, idx, dim=-1)\n\t\n    return self.codebook.movedim(-1, dim)[idx]\n\n", "CodeBleu_score": 17.78526264547506}, {"code": "def idx2vq(self, idx, dim=-1)\n\t\n    return self.codebook.movedim(-1, dim)[idx]\n\n", "CodeBleu_score": 17.78526264547506}]}
{"instance_id": "4104c041fb20", "generation_result": [{"code": "def encode(self, x, quantize=False)\n\t\n    for block in self.down_blocks:\n        x = block(x)\n    x = self.in_block(x)\n    if quantize:\n        quantized, indices, loss = self.quantizer(x)\n        return quantized, x, indices, loss\n    return x\n\n", "CodeBleu_score": 38.991149168157165}, {"code": "def encode(self, x, quantize=False)\n\t\n    x = self.in_block(x)\n    if quantize:\n        quantized_outputs = []\n        for block in self.down_blocks:\n            x = block(x)\n            quantized_outputs.append(x)\n        return quantized_outputs\n    else:\n        for block in self.down_blocks:\n            x = block(x)\n        return x\n\n", "CodeBleu_score": 29.719944001627375}, {"code": "def encode(self, x, quantize=False)\n\t\n    if quantize:\n        return self.quantizer(x)\n    else:\n        return self.encoder(x)\n\n", "CodeBleu_score": 14.936958405067724}]}
{"instance_id": "403c52ba2d3b", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if self.parameters is None:\n        self.parameters = self.model.parameters()\n    if context is not None:\n        context.log_info(f\"EMA: {self.model.parameters()}\")\n    self.model.parameters = self.ema_parameters\n    yield\n    self.model.parameters = self.parameters\n    if context is not None:\n        context.log_info(f\"Restored: {self.model.parameters()}\")\n\n", "CodeBleu_score": 42.86148779808337}, {"code": "def ema_scope(self, context=None)\n\t\n    self.parameters = self.parameters.copy()\n    self.parameters.update(self.ema_parameters)\n    if context:\n        logpy.info(f\"{context} | EMA weights applied\")\n    yield\n    self.parameters = self.parameters.copy()\n    self.parameters.update(self.parameters_no_ema)\n    if context:\n        logpy.info(f\"{context} | EMA weights restored\")\n\n", "CodeBleu_score": 49.22112082099816}, {"code": "def ema_scope(self, context=None)\n\t\n    if self.ema_weights is None:\n        raise ValueError(\"EMA weights have not been initialized.\")\n    if context is not None:\n        self.log_info(f\"Entering EMA scope for {context}\")\n    self.store()\n    self.copy_to(self.ema_weights)\n    try:\n        yield\n    finally:\n        if context is not None:\n            self.log_info(f\"Exiting EMA scope for {context}\")\n        self.restore()\n\n", "CodeBleu_score": 44.07287018492491}]}
{"instance_id": "94b7467f98e4", "generation_result": [{"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    x = x + attn * gate_msa\n    x = self.norm2(x)\n    x = self.mlp(self.channel_proj(x)) * gate_mlp\n    return x\n\n", "CodeBleu_score": 32.879325300903474}, {"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    x = x + attn * gate_msa\n    x = self.norm2(x)\n    x = self.mlp(self.channel_last(x)) * gate_mlp\n    x = x + self.channel_first(shift_mlp)\n    x = x * self.channel_first(scale_mlp)\n    return x\n\n", "CodeBleu_score": 45.36856942044901}, {"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    x = x + attn * gate_msa\n    x = self.norm2(x)\n    x = self.mlp(self.channel_proj(x)) * gate_mlp\n    return x\n\n", "CodeBleu_score": 32.879325300903474}]}
{"instance_id": "d9fdc05542a2", "generation_result": [{"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    # Perform pre-attention processing for context and x\n    context, x, context_intermediate, x_intermediate = context_block.pre_attention(context, x)\n\n    # Concatenate qkv tensors for attention computation\n    qkv = torch.cat((context, x), dim=2)\n\n    # Apply optimized attention\n    attention_output = optimized_attention(qkv, c)\n\n    # Split attention results back into context and x parts\n    context, x = torch.split(attention_output, [context.shape[2], x.shape[2]], dim=2)\n\n    # Perform post-attention processing for context and x\n    context, x = context_block.post_attention(context, x, context_intermediate, x_intermediate)\n\n    return context, x\n\n", "CodeBleu_score": 17.38736046203667}, {"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    qkv_context = context_block.pre_attention(context)\n    qkv_x = x_block.pre_attention(x)\n    qkv = torch.cat([qkv_context, qkv_x], dim=2)\n    qkv = optimized_attention(qkv, c)\n    qkv_context, qkv_x = torch.split(qkv, [context.shape[2], x.shape[2]], dim=2)\n    context = context_block.post_attention(qkv_context)\n    x = x_block.post_attention(qkv_x)\n    return context, x\n", "CodeBleu_score": 16.198191034864486}, {"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    qkv_context = context_block.pre_attention(context)\n    qkv_x = x_block.pre_attention(x)\n    qkv = torch.cat([qkv_context, qkv_x], dim=2)\n    qkv = optimized_attention(qkv, c)\n    context_out, x_out = torch.split(qkv, [context.shape[2], x.shape[2]], dim=2)\n    context_out = context_block.post_attention(context_out)\n    x_out = x_block.post_attention(x_out)\n    return context_out, x_out\n\n", "CodeBleu_score": 16.01950392177505}]}
{"instance_id": "b219bce30160", "generation_result": [{"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    assert len(timesteps.shape) == 1\n    half_dim = embedding_dim // 2\n    emb = math.log(10000) / (half_dim - 1)\n    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n    emb = timesteps[:, None] * emb[None, :]\n    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n    if embedding_dim % 2 == 1:\n        # zero pad\n        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n    assert emb.shape == (timesteps.shape[0], embedding_dim)\n    return emb\n\n", "CodeBleu_score": 79.60681561792701}, {"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    assert len(timesteps.shape) == 1\n    half_dim = embedding_dim // 2\n    emb = math.log(10000) / (half_dim - 1)\n    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n    emb = timesteps[:, None] * emb[None, :]\n    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n    if embedding_dim % 2 == 1:\n        # zero pad\n        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n    return emb\n\n", "CodeBleu_score": 77.21369170165848}, {"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    assert len(timesteps.shape) == 1\n    half_dim = embedding_dim // 2\n    emb = math.log(10000) / (half_dim - 1)\n    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n    emb = timesteps[:, None] * emb[None, :]\n    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n    if embedding_dim % 2 == 1:\n        emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=1)\n    return emb\n\n", "CodeBleu_score": 71.95471346228456}]}
{"instance_id": "6ae8453c86be", "generation_result": [{"code": "def pytorch_attention(q, k, v)\n\t\n    q = q.view(q.shape[0], q.shape[1], q.shape[2] * q.shape[3])\n    k = k.view(k.shape[0], k.shape[1], k.shape[2] * k.shape[3])\n    v = v.view(v.shape[0], v.shape[1], v.shape[2] * v.shape[3])\n    q = q.transpose(1, 2)\n    k = k.transpose(1, 2)\n    v = v.transpose(1, 2)\n    try:\n        out = scaled_dot_product_attention(q, k, v)\n    except RuntimeError as e:\n        if \"out of memory\" in str(e):\n            logging.warning(\"OOM detected, using slice attention\")\n            out = slice_attention(q, k, v)\n        else:\n            raise e\n    out = out.transpose(1, 2)\n    out = out.reshape(out.shape[0], out.shape[1], h, w)\n    return out\n\n", "CodeBleu_score": 31.644941922912253}, {"code": "def pytorch_attention(q, k, v)\n\t\n    q = q.view(q.shape[0], q.shape[1], -1)\n    k = k.view(k.shape[0], k.shape[1], -1)\n    v = v.view(v.shape[0], v.shape[1], -1)\n\n    q = q.transpose(1, 2)\n    k = k.transpose(1, 2)\n    v = v.transpose(1, 2)\n\n    try:\n        out = scaled_dot_product_attention(q, k, v)\n    except RuntimeError as e:\n        if \"out of memory\" in str(e):\n            logging.warning(\"OOM exception occurred. Switching to slice attention.\")\n            out = slice_attention(q, k, v)\n        else:\n            raise e\n\n    out = out.transpose(1, 2)\n    out = out.reshape(out.shape[0], out.shape[1], *v.shape[1:])\n    out = out.contiguous()\n\n    return out\n\n", "CodeBleu_score": 30.630568054738095}, {"code": "def pytorch_attention(q, k, v)\n\t\n    q = q.view(q.shape[0], q.shape[1], q.shape[2] * q.shape[3])\n    k = k.view(k.shape[0], k.shape[1], k.shape[2] * k.shape[3])\n    v = v.view(v.shape[0], v.shape[1], v.shape[2] * v.shape[3])\n    q = q.transpose(1, 2)\n    k = k.transpose(1, 2)\n    v = v.transpose(1, 2)\n    try:\n        out = scaled_dot_product_attention(q, k, v)\n    except RuntimeError as e:\n        if \"out of memory\" in str(e):\n            logging.warning(\"OOM exception occurred, falling back to slice attention\")\n            out = slice_attention(q, k, v)\n        else:\n            raise e\n    out = out.transpose(1, 2)\n    out = out.reshape(out.shape[0], out.shape[1], h, w)\n    return out\n\n", "CodeBleu_score": 32.07695638154161}]}
{"instance_id": "fe4433c987ad", "generation_result": [{"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        control = control.pop(0)\n        try:\n            h = h.add_control(control, name)\n        except Exception as e:\n            logging.warning(f\"Failed to add control {name} with value {control}: {e}\")\n    return h\n\n", "CodeBleu_score": 33.28222409384796}, {"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        control = control.pop(0)\n        try:\n            h[name] = control\n        except Exception as e:\n            logging.warning(f\"Failed to apply control {name} with value {control}: {e}\")\n    return h\n\n", "CodeBleu_score": 34.302662086635515}, {"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        control = control.pop(0)\n        try:\n            h = h.add_control(control, name)\n        except AttributeError:\n            logging.warning(f\"Control {name} failed to add\")\n    return h\n\n", "CodeBleu_score": 32.24562742188074}]}
{"instance_id": "56da4547c101", "generation_result": [{"code": "def get_codebook_entry(self, indices, shape)\n\t\n    min_encodings = torch.zeros(indices.shape[0], self.num_embeddings).to(indices)\n    min_encodings.scatter_(1, indices[:,None], 1)\n    z_q = torch.matmul(min_encodings.float(), self.embedding.weight)\n    if shape is not None:\n        z_q = z_q.view(shape)\n        z_q = z_q.permute(0, 3, 1, 2).contiguous()\n    return z_q\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 65.38743805377383}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    min_encodings = torch.zeros(indices.shape[0], self.num_embeddings).to(indices)\n    min_encodings.scatter_(1, indices[:, None], 1)\n    min_encodings = min_encodings.view(*indices.shape, -1)\n    z_q = torch.matmul(min_encodings.float(), self.embedding.weight)\n    if shape is not None:\n        z_q = z_q.view(shape)\n        z_q = z_q.permute(0, 3, 1, 2).contiguous()\n    return z_q\n\n", "CodeBleu_score": 63.51925974505026}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    min_encodings = torch.zeros(indices.shape[0], self.num_embeddings)\n    min_encodings.scatter_(1, indices[:, None], 1)\n    min_encodings = min_encodings.view(*indices.shape, -1)\n    z_q = torch.matmul(min_encodings.float(), self.embedding.weight)\n    if shape is not None:\n        z_q = z_q.view(shape)\n        z_q = z_q.permute(0, 3, 1, 2).contiguous()\n    return z_q", "CodeBleu_score": 63.85354669614019}]}
{"instance_id": "548f8a1fb37d", "generation_result": [{"code": "def make_noise(self)\n\t\n    noises = [torch.randn(1, 1, 4, 4, device=self.device)]\n\n    for i in range(3, int(self.log_size) + 1):\n        for _ in range(2):\n            noises.append(torch.randn(1, 1, 2 ** i, 2 ** i, device=self.device))\n\n    return noises\n\n", "CodeBleu_score": 45.066989290457784}, {"code": "def make_noise(self)\n\t\n    noises = [torch.randn(1, 1, 4, 4, device=self.device)]\n\n    for i in range(3, int(self.log_size) + 1):\n        for _ in range(2):\n            noises.append(torch.randn(1, 1, 2 ** i, 2 ** i, device=self.device))\n\n    return noises\n\n", "CodeBleu_score": 45.066989290457784}, {"code": "def make_noise(self)\n\t\n    noises = [torch.randn(4, 4, device=self.device)]\n    for i in range(3, int(self.log_size) + 1):\n        for _ in range(2):\n            noises.append(torch.randn(2 ** i, 2 ** i, device=self.device))\n    return noises", "CodeBleu_score": 38.244827373278504}]}
{"instance_id": "42fd805563c6", "generation_result": [{"code": "def mean_latent(self, num_latent)\n\t\n    return self.style_mlp(torch.randn(num_latent, self.latent_dim)).mean(0, keepdim=True)\n\n", "CodeBleu_score": 15.84175180147677}, {"code": "def mean_latent(self, num_latent)\n\t\n    latent_in = torch.randn(\n        num_latent, self.style_dim, device=self.tmp_device\n    )\n    latent = self.style(latent_in).mean(0, keepdim=True)\n    return latent\n\n", "CodeBleu_score": 32.74787738960471}, {"code": "def mean_latent(self, num_latent)\n\t\n    latent_in = torch.randn(\n        num_latent, self.style_dim, device=self.tmp_device\n    )\n    latent = self.style(latent_in).mean(0, keepdim=True)\n    return latent\n\n", "CodeBleu_score": 32.74787738960471}]}
{"instance_id": "2f485fd924af", "generation_result": [{"code": "def color_jitter(img, shift)\n\t\n    shift = np.random.uniform(low=-shift, high=shift, size=(3,))\n    shift = shift.astype(np.float32)\n    img = img.astype(np.float32)\n    img += shift\n    img = np.clip(img, 0, 1)\n    return img\n\n", "CodeBleu_score": 38.1858042873006}, {"code": "def color_jitter(img, shift)\n\t\n    jitter = np.random.uniform(shift, shift, size=(img.shape[0], img.shape[1], 3))\n    return np.clip(img + jitter, 0, 1)\n\n", "CodeBleu_score": 34.02526145413123}, {"code": "def color_jitter(img, shift)\n\t\n    img = astype(img, 'float32')\n    shift = np.random.uniform(-shift, shift, 3)\n    img += shift\n    img = np.clip(img, 0, 1)\n    return img\n\n", "CodeBleu_score": 56.76738808299393}]}
{"instance_id": "c87ccf1fbf48", "generation_result": [{"code": "def feed_data(self, data)\n\t\n    self.lq = data[\"lq\"]\n    if \"gt\" in data:\n        self.gt = data[\"gt\"]\n    if \"facial_components\" in data:\n        facial_components = data[\"facial_components\"]\n        self.left_eye_location = facial_components[\"left_eye_location\"]\n        self.right_eye_location = facial_components[\"right_eye_location\"]\n        self.mouth_location = facial_components[\"mouth_location\"]\n\n", "CodeBleu_score": 36.09226027357403}, {"code": "def feed_data(self, data)\n\t\n    self.lq = data[\"lq\"]\n    if \"gt\" in data:\n        self.gt = data[\"gt\"]\n    if \"facial_components\" in data:\n        self.left_eye = data[\"facial_components\"][\"left_eye\"]\n        self.right_eye = data[\"facial_components\"][\"right_eye\"]\n        self.mouth = data[\"facial_components\"][\"mouth\"]\n\n", "CodeBleu_score": 41.324697189010315}, {"code": "def feed_data(self, data)\n\t\n    self.lq = data['lq']\n    if 'gt' in data:\n        self.gt = data['gt']\n    if 'facial_components' in data:\n        self.left_eye_location = data['facial_components']['left_eye']\n        self.right_eye_location = data['facial_components']['right_eye']\n        self.mouth_location = data['facial_components']['mouth']", "CodeBleu_score": 45.37629517467766}]}
{"instance_id": "8f8c7cb13037", "generation_result": [{"code": "def construct_img_pyramid(self)\n\t\n    img_pyramid = []\n    img_pyramid.insert(0, self.gt_img)\n    for i in range(1, self.num_downscales):\n        img_pyramid.insert(0, F.interpolate(img_pyramid[0], scale_factor=0.5, mode='bilinear', align_corners=False))\n    return img_pyramid\n\n", "CodeBleu_score": 30.5056650459253}, {"code": "def construct_img_pyramid(self)\n\t\n    pyramid_gt = [self.gt_img]\n    for i in range(self.num_pyramid_levels):\n        pyramid_gt.insert(0, F.interpolate(pyramid_gt[0], scale_factor=0.5, mode='bilinear', align_corners=False))\n    return pyramid_gt\n\n", "CodeBleu_score": 27.275400657821198}, {"code": "def construct_img_pyramid(self)\n\t\n    pyramid_gt = []\n    pyramid_gt.insert(0, self.gt_image)\n    for i in range(1, self.pyramid_levels):\n        pyramid_gt.insert(0, F.interpolate(pyramid_gt[0], scale_factor=0.5, mode='bilinear'))\n    return pyramid_gt\n\n", "CodeBleu_score": 29.34772944373398}]}
{"instance_id": "51247274d40c", "generation_result": [{"code": "def save(self, epoch, current_iter)\n\t\n    self.save_network(self.g_ema, self.d, self.g, self.opt_g, self.opt_d, epoch, current_iter)\n    if self.args.use_facial_discriminator:\n        self.save_network(self.g_ema, self.d_left, self.g, self.opt_g, self.opt_d, epoch, current_iter, 'left')\n        self.save_network(self.g_ema, self.d_right, self.g, self.opt_g, self.opt_d, epoch, current_iter, 'right')\n        self.save_network(self.g_ema, self.d_mouth, self.g, self.opt_g, self.opt_d, epoch, current_iter, 'mouth')\n    self.save_training_state(epoch, current_iter)\n\n", "CodeBleu_score": 49.508295395482705}, {"code": "def save(self, epoch, current_iter)\n\t\n    self.save_network(self.G, self.G_ema, self.D, epoch, current_iter)\n    if self.opts.use_facial_discriminator:\n        self.save_network(self.D_left_eye, self.D_right_eye, self.D_mouth, epoch, current_iter)\n    self.save_training_state(epoch, current_iter)", "CodeBleu_score": 28.329410590378995}, {"code": "def save(self, epoch, current_iter)\n\t\n    state_dict = self.generator.state_dict()\n    ema_state_dict = self.generator_ema.state_dict()\n    discriminator_state_dict = self.discriminator.state_dict()\n    state = {\n        \"epoch\": epoch,\n        \"iter\": current_iter,\n        \"state_dict\": state_dict,\n        \"ema_state_dict\": ema_state_dict,\n        \"discriminator_state_dict\": discriminator_state_dict,\n    }\n    if self.config.use_facial_discriminator:\n        state[\"left_eye_discriminator_state_dict\"] = self.left_eye_discriminator.state_dict()\n        state[\"right_eye_discriminator_state_dict\"] = self.right_eye_discriminator.state_dict()\n        state[\"mouth_discriminator_state_dict\"] = self.mouth_discriminator.state_dict()\n    torch.save(state, os.path.join(self.config.save_dir, \"model_state.pt\"))\n\n", "CodeBleu_score": 34.22098094629757}]}
{"instance_id": "afa0dc8128c1", "generation_result": [{"code": "def clean_folder(folder)\n\t\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                shutil.rmtree(file_path)\n            elif os.path.islink(file_path):\n                os.unlink(file_path)\n        except Exception as e:\n            print(f\"Failed to delete {file_path}. Reason: {e}\")\n\n", "CodeBleu_score": 58.267358106819735}, {"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        try:\n            if os.path.isfile(item_path) or os.path.islink(item_path):\n                os.unlink(item_path)\n            elif os.path.isdir(item_path):\n                shutil.rmtree(item_path)\n        except Exception as e:\n            print(f\"Failed to delete {item_path}. Reason: {e}\")\n\n", "CodeBleu_score": 54.3909785745615}, {"code": "def clean_folder(folder)\n\t\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.islink(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                shutil.rmtree(file_path)\n        except Exception as e:\n            print(f'Failed to delete {file_path}. Reason: {e}')\n\n", "CodeBleu_score": 64.81979778475788}]}
{"instance_id": "53588b481bdd", "generation_result": [{"code": "def next_batch(self, sample_size=1)\n\t\n    batch = []\n    sample_size = min(sample_size, len(self.memory))\n    batch = random.sample(self.memory, sample_size)\n    for sample in batch:\n        self.memory.remove(sample)\n    return batch\n\n", "CodeBleu_score": 27.61241791745912}, {"code": "def next_batch(self, sample_size=1)\n\t\n    if self.batch_size < sample_size:\n        sample_size = self.batch_size\n    batch = random.sample(self.memory, sample_size)\n    for state, action, reward, next_state, done in batch:\n        self.memory.remove((state, action, reward, next_state, done))\n    return batch\n\n", "CodeBleu_score": 37.52926314586064}, {"code": "def next_batch(self, sample_size=1)\n\t\n    if self.count < sample_size:\n        return random.sample(self.buffer, self.count)\n    else:\n        batch = random.sample(self.buffer, sample_size)\n        if self.count > 0:\n            self.count -= len(batch)\n        self.buffer = [exp for exp in self.buffer if exp not in batch]\n        return batch\n\n", "CodeBleu_score": 39.6507794518999}]}
{"instance_id": "6bfa6a4e621c", "generation_result": [{"code": "def find_estimated_top_configs(self)\n\t\n    flattened_ds_config = self.flatten(self.all_configs)\n    feature_val = []\n    configs = []\n    for config in self.all_configs:\n        configs.append(config)\n        feature_val.append(self.flatten(config))\n    feature_val = np.array(feature_val)\n    if self.metric == \"mse\":\n        cost_model = LinearRegression()\n        cost_model.fit(feature_val, self.all_costs)\n        estimated_costs = cost_model.predict(feature_val)\n    elif self.metric == \"mae\":\n        cost_model = Lasso(alpha=0.01)\n        cost_model.fit(feature_val, self.all_costs)\n        estimated_costs = cost_model.predict(feature_val)\n    elif self.metric == \"mape\":\n        cost_model = Lasso(alpha=0.01)\n        cost_model.fit(feature_val, self.all_costs)\n        estimated_costs = cost_model.predict(feature_val)\n    elif self.metric == \"rmse\":\n        cost_model = Ridge(alpha=0.01)\n        cost_model.fit(feature_val, self.all_costs)\n        estimated_costs = cost_model.predict(feature_val)\n    elif self.metric == \"r2\":\n        cost_model = Ridge(alpha=0.01)\n        cost_model.fit(feature_val, self.all_costs)\n        estimated_costs = cost_model.predict(feature_val)\n    elif self.metric == \"mape\":\n        cost_model = Ridge(alpha=0.01)\n        cost_model.fit(feature_val, self.all_costs)\n        estimated_costs = cost_model.predict(feature_val)\n    elif self.metric == \"rmse\":\n        cost_model = Ridge(alpha=0.01)\n        cost_model.fit(feature_val, self.all_costs)\n        estimated_costs = cost_model.predict", "CodeBleu_score": 20.904211504214594}, {"code": "def find_estimated_top_configs(self)\n\t\n    flattened_ds_config = self.flatten_configs()\n    feature_val = []\n    configs = []\n    for config in flattened_ds_config:\n        feature_val.append(list(config.values()))\n        configs.append(config)\n    feature_val = np.array(feature_val)\n    if self.metric == \"cost\":\n        estimates = self.cost_model.predict(feature_val)\n    elif self.metric == \"latency\":\n        estimates = self.latency_model.predict(feature_val)\n    elif self.metric == \"accuracy\":\n        estimates = self.accuracy_model.predict(feature_val)\n    elif self.metric == \"energy\":\n        estimates = self.energy_model.predict(feature_val)\n    else:\n        raise ValueError(\"Invalid metric specified.\")\n    if self.metric == \"cost\":\n        top_configs = np.argsort(estimates)[: self.top_k]\n    elif self.metric == \"latency\":\n        top_configs = np.argsort(estimates)[: self.top_k]\n    elif self.metric == \"accuracy\":\n        top_configs = np.argsort(estimates)[::-1][: self.top_k]\n    elif self.metric == \"energy\":\n        top_configs = np.argsort(estimates)[: self.top_k]\n    else:\n        raise ValueError(\"Invalid metric specified.\")\n    return top_configs\n\n", "CodeBleu_score": 24.64596681726801}, {"code": "def find_estimated_top_configs(self)\n\t\n    flattened_ds_config = self.flatten_configs(self.all_configs)\n    feature_val = []\n    configs = []\n    for k, v in flattened_ds_config.items():\n        if isinstance(v, Number):\n            feature_val.append(v)\n        else:\n            configs.append(k)\n    feature_val = np.array(feature_val)\n    feature_val = feature_val.reshape(1, -1)\n    configs = np.array(configs)\n    configs = configs.reshape(1, -1)\n    estimated_top_configs = self.cost_model.predict(feature_val)\n    estimated_top_configs = np.argsort(estimated_top_configs, axis=1)\n    if self.metric == \"min\":\n        estimated_top_configs = estimated_top_configs[:, : self.top_n]\n    else:\n        estimated_top_configs = estimated_top_configs[:, -self.top_n :]\n    return estimated_top_configs\n\n", "CodeBleu_score": 33.716965063199986}]}
{"instance_id": "d4cf48413a57", "generation_result": [{"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, dict):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 75.32964516404331}, {"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, dict):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 75.32964516404331}, {"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, dict):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 75.32964516404331}]}
{"instance_id": "c2a514249c25", "generation_result": [{"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd:\n        result = subprocess.Popen(\n            self.optimal_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n        )\n        result.wait()\n        logger.info(\n            \"Autotuning is done. The optimal command is: %s\",\n            \" \".join(self.optimal_cmd),\n        )\n    else:\n        logger.info(\"Autotuning did not find an optimal configuration.\")", "CodeBleu_score": 51.32861724083718}, {"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd:\n        logger.info(f\"Running {self.optimal_cmd}\")\n        result = subprocess.Popen(self.optimal_cmd, shell=True)\n        result.wait()\n        logger.info(f\"Finished {self.optimal_cmd}\")\n    else:\n        logger.info(\"Autotuning did not find an optimal configuration\")", "CodeBleu_score": 57.50125930127338}, {"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd:\n        result = subprocess.Popen(self.optimal_cmd, shell=True)\n        result.wait()\n        logger.info(\"Command executed successfully.\")\n    else:\n        logger.info(\"Autotuning did not find an optimal configuration.\")", "CodeBleu_score": 53.577657149963606}]}
{"instance_id": "61802de52df0", "generation_result": [{"code": "def run_job(self, exp: dict, reservations)\n\t\n    self.experiment_master_port = self.get_val_by_key(exp, \"master_port\")\n    self.experiment_result_dir = self.get_val_by_key(exp, \"result_dir\")\n    user_args = self.get_val_by_key(exp, \"args\")\n    for arg in user_args:\n        arg_name = arg.split(\"=\")[0]\n        arg_val = arg.split(\"=\")[1]\n        arg_mapping = self.get_val_by_key(exp, \"arg_mappings\")\n        if arg_mapping and arg_name in arg_mapping:\n            arg_val = arg_mapping[arg_name]\n        arg_val = self.replace_reservations(arg_val, reservations)\n        user_args[user_args.index(arg)] = arg_val\n    t = threading.Thread(target=self.run_script, args=(exp[\"script\"], user_args))\n    t.start()\n    self.running_experiments[time.time()] = exp", "CodeBleu_score": 32.66508303191047}, {"code": "def run_job(self, exp: dict, reservations)\n\t\n    master_port = exp['master_port']\n    result_dir = exp['result_dir']\n    user_args = exp['user_args']\n    user_args.append('--master_port=' + master_port)\n    user_args.append('--result_dir=' + result_dir)\n    for arg in exp['argument_mappings']:\n        user_args[user_args.index(arg['user_arg'])] = self.get_val_by_key(\n            arg['argument'], reservations)\n    t = threading.Thread(target=self.run_exp, args=(exp['script'], user_args))\n    t.start()\n    running_experiments[str(time.time())] = {\n        'master_port': master_port,\n        'result_dir': result_dir,\n        'user_args': user_args\n    }\n\n", "CodeBleu_score": 27.023872350463062}, {"code": "def run_job(self, exp: dict, reservations)\n\t\n    exp[\"master_port\"] = self.get_free_port()\n    exp[\"result_dir\"] = self.get_result_dir(exp)\n    user_args = exp[\"user_args\"]\n    for i in range(len(user_args)):\n        if user_args[i] in self.argument_mappings:\n            user_args[i] = self.argument_mappings[user_args[i]]\n    t = threading.Thread(target=self.run_script, args=(exp[\"script\"], user_args, exp[\"master_port\"], exp[\"result_dir\"]))\n    t.start()\n    running_experiments[exp[\"name\"]] = {\"timestamp\": time.time(), \"reservations\": reservations}\n\n", "CodeBleu_score": 26.301505360125404}]}
{"instance_id": "4884e2e9665c", "generation_result": [{"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if dist.is_initialized() and dist.get_rank() == 0:\n        message = f\"{dist.get_rank()}: {message}\"\n        if ranks is not None:\n            message = f\"{ranks}: {message}\"\n        with open(path, \"a\") as outfile:\n            json.dump(message, outfile)\n            outfile.write(\"", "CodeBleu_score": 26.150277170608838}, {"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if ranks is None:\n        ranks = [dist.get_rank()]\n    if self.log_to_database:\n        if dist.is_initialized():\n            if dist.get_rank() in ranks:\n                logger.debug(message)\n                with open(path, \"a\") as outfile:\n                    json.dump(message, outfile)\n                    outfile.write(\"", "CodeBleu_score": 30.413003423115548}, {"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if not dist.is_initialized():\n        ranks = [0]\n    else:\n        ranks = ranks or [dist.get_rank()]\n    for rank in ranks:\n        if rank == 0:\n            if self.log_to_database:\n                message = self.add_rank_to_message(message, rank)\n                self.append_message_to_file(message, path)\n\n", "CodeBleu_score": 26.09621701006737}]}
{"instance_id": "0429344c3c4d", "generation_result": [{"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    assert layer_index >= 0\n    layer_files = self.get_files_with_prefix(f\"layer_{layer_index}_tp_\")\n    if len(layer_files) == 0:\n        return None\n    tp_degree = self.tp_degrees[layer_index]\n    partition_data = self.partition_data(layer_files, tp_degree)\n    tp_other_layer_map = {}\n    for i, file_list in enumerate(partition_data):\n        tp_other_layer_map[i] = file_list\n    return tp_other_layer_map\n\n", "CodeBleu_score": 40.266515560507635}, {"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    layer_files = self.get_files_with_prefix(f\"{layer_index}_\")\n    if len(layer_files) == 0:\n        return {}\n    if layer_index != self.layer_index:\n        raise ValueError(\n            \"Layer index does not match the current layer index. Please check your input.\"\n        )\n    tp_partition_data = self.partition_data(\n        layer_files, self.tp_degree\n    )\n    tp_other_layer_map = {}\n    for i, files in enumerate(tp_partition_data):\n        tp_other_layer_map[i] = files\n    return tp_other_layer_map\n\n", "CodeBleu_score": 32.66610275470103}, {"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    if not self._files:\n        raise ValueError(\"No files found\")\n    if layer_index < 0:\n        raise ValueError(\"Layer index must be non-negative\")\n\n    tp_degree = self._tp_degree\n    layer_prefix = f\"layer_{layer_index}_\"\n    layer_files = get_files_with_prefix(self._files, layer_prefix)\n    layer_files = partition_data(layer_files, tp_degree)\n\n    tp_other_layer_map = {}\n    for tp_index in range(tp_degree):\n        tp_other_layer_map[tp_index] = []\n\n    for partition_index, files in enumerate(layer_files):\n        for file in files:\n            tp_other_layer_map[partition_index].append(file)\n\n    return tp_other_layer_map\n\n", "CodeBleu_score": 33.066633326654646}]}
{"instance_id": "1b65ecb9be93", "generation_result": [{"code": "def system_info()\n\t\n    system_info = {\n        \"Operating System\": platform.system(),\n        \"Architecture\": platform.architecture(),\n        \"Version\": platform.version(),\n        \"Processor\": platform.processor(),\n        \"Python Version\": platform.python_version(),\n    }\n    return system_info\n\n", "CodeBleu_score": 52.055468047033095}, {"code": "def system_info()\n\t\n    system_info = {\n        \"OS\": platform.system(),\n        \"Architecture\": platform.architecture(),\n        \"Version\": platform.version(),\n        \"Processor\": platform.processor(),\n        \"Python Version\": platform.python_version(),\n    }\n    return system_info", "CodeBleu_score": 54.78310824472419}, {"code": "def system_info()\n\t\n    system_info = {\n        \"Operating System\": platform.system(),\n        \"Architecture\": platform.architecture(),\n        \"Version\": platform.version(),\n        \"Processor\": platform.processor(),\n        \"Python Version\": platform.python_version(),\n    }\n    return system_info\n\n", "CodeBleu_score": 52.055468047033095}]}
{"instance_id": "969bcc5cf3b5", "generation_result": [{"code": "def cuda_info()\n\t\n    print(\"CUDA is available:\", torch.cuda.is_available())\n    print(\"CUDA device count:\", torch.cuda.device_count())\n    print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n    print(\"CUDA version:\", torch.version.cuda)\n\n", "CodeBleu_score": 36.50513295202826}, {"code": "def cuda_info()\n\t\n    device_count = torch.cuda.device_count()\n    is_available = torch.cuda.is_available()\n    range = torch.cuda.get_device_capability()\n    device_name = torch.cuda.get_device_name()\n    print(\"CUDA is available:\", is_available)\n    print(\"Number of devices:\", device_count)\n    print(\"Device name:\", device_name)\n    print(\"CUDA version:\", torch.version.cuda)\n\n", "CodeBleu_score": 33.48196045471945}, {"code": "def cuda_info()\n\t\n    import torch\n    device_count = torch.cuda.device_count()\n    is_available = torch.cuda.is_available()\n    range = torch.cuda.get_device_name(0)\n    return device_count, is_available, range\n\n", "CodeBleu_score": 28.427297390417028}]}
{"instance_id": "a2ba908a4c70", "generation_result": [{"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_name_key = encoder_manager.config.class_name_key\n    class_id_to_class_name = encoder_manager.config.class_id_to_class_name\n    num_items = len(dataset_items)\n    correct_predictions = {}\n    total_predictions = {}\n    for item in tqdm(dataset_items, desc=\"Computing encoder accuracy\"):\n        audio_file = item[encoder_manager.config.audio_file_key]\n        class_name = item[class_name_key]\n        if class_id_to_class_name is not None:\n            class_name = class_id_to_class_name[str(class_name)]\n        embedding = encoder_manager.compute_embedding_from_clip(audio_file)\n        if encoder_manager.config.class_name_key is not None:\n            predicted_label = encoder_manager.classifier.infer(embedding)\n            if class_name not in correct_predictions:\n                correct_predictions[class_name] = 0\n                total_predictions[class_name] = 0\n            if predicted_label == class_name:\n                correct_predictions[class_name] += 1\n            total_predictions[class_name] += 1\n    class_acc_dict = {}\n    for class_name, correct_count in correct_predictions.items():\n        total_count = total_predictions[class_name]\n        class_acc = correct_count / total_count\n        class_acc_dict[class_name] = class_acc\n    for class_name, acc in class_acc_dict.items():\n        print(f\"Class {class_name} accuracy: {acc}\")\n    avg_acc = sum(class_acc_dict.values()) / len(class_acc_dict)\n    print(f\"Average accuracy: {avg_acc}\")\n    return avg_acc\n\n", "CodeBleu_score": 39.94356497116798}, {"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_name_key = encoder_manager.config.class_name_key\n    class_id_to_class_name = encoder_manager.config.class_id_to_class_name\n    class_acc_dict = {}\n    for item in tqdm(dataset_items, desc=\"Computing encoder accuracy\"):\n        audio_file = item[encoder_manager.config.audio_file_key]\n        embedding = encoder_manager.compute_embedding_from_clip(audio_file)\n        if encoder_manager.config.class_name_key in item:\n            class_name = item[class_name_key]\n            if class_name not in class_acc_dict:\n                class_acc_dict[class_name] = {\"correct\": 0, \"total\": 0}\n            class_acc_dict[class_name][\"total\"] += 1\n            if encoder_manager.config.class_id_to_class_name is not None:\n                class_id = item[encoder_manager.config.class_id_key]\n                class_name = class_id_to_class_name[class_id]\n            if encoder_manager.config.class_name_key in item:\n                class_name = item[class_name_key]\n            if class_name not in class_acc_dict:\n                class_acc_dict[class_name] = {\"correct\": 0, \"total\": 0}\n            class_acc_dict[class_name][\"total\"] += 1\n            if encoder_manager.config.class_id_to_class_name is not None:\n                class_id = item[encoder_manager.config.class_id_key]\n                class_name = class_id_to_class_name[class_id]\n            if encoder_manager.config.class_name_key in item:\n                class_name = item[class_name_key]\n            if class_name not in class_acc_dict:\n                class_acc_dict[class_name] = {\"correct\": 0, \"total\": 0}\n            class_acc_dict[class_name][\"total\"] += 1\n            if encoder_manager", "CodeBleu_score": 28.144391754756082}, {"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_name_key = encoder_manager.config.class_name_key\n    class_id_to_class_name_mapping = encoder_manager.config.class_id_to_class_name_mapping\n    class_acc_dict = {}\n    for item in tqdm(dataset_items, desc=\"Computing encoder accuracy\"):\n        audio_file = item[encoder_manager.config.audio_file_key]\n        embedding = encoder_manager.compute_embedding_from_clip(audio_file)\n        if class_id_to_class_name_mapping is not None:\n            class_id = item[encoder_manager.config.class_id_key]\n            class_name = class_id_to_class_name_mapping[class_id]\n        else:\n            class_name = item[class_name_key]\n        if encoder_manager.model.classify:\n            embedding = embedding.unsqueeze(0)\n            embedding = torch.FloatTensor(embedding).cuda()\n            prediction = encoder_manager.model.classify(embedding)\n            predicted_label = prediction.argmax().item()\n            if class_id_to_class_name_mapping is not None:\n                predicted_class_name = encoder_manager.config.class_id_to_class_name_mapping[predicted_label]\n            else:\n                predicted_class_name = predicted_label\n            if class_name not in class_acc_dict:\n                class_acc_dict[class_name] = []\n            class_acc_dict[class_name].append(predicted_class_name == class_name)\n    for class_name, acc_list in class_acc_dict.items():\n        accuracy = sum(acc_list) / len(acc_list)\n        print(f\"Accuracy for class {class_name}: {accuracy}\")\n    total_accuracy = sum([sum(acc_list) for acc_list in class_acc_dict.values()]) / sum([len(acc_list) for acc_list in class_acc_dict.values()])\n    print(f\"Total accuracy: {total_accur", "CodeBleu_score": 42.90070441191931}]}
{"instance_id": "e01ec69ad58a", "generation_result": [{"code": "def adjust_path_and_remove_silence(audio_path)\n\t\n    output_path = audio_path.replace(input_dir, output_dir)\n    if exists(output_path) and not force:\n        return output_path, False\n    mkdir(pathlib.Path(output_path).parent, parents=True, exist_ok=True)\n    remove_silence(audio_path, output_path, chunk_size=chunk_size, threshold=threshold)\n    return output_path, True\n\n", "CodeBleu_score": 24.247232085918274}, {"code": "def adjust_path_and_remove_silence(audio_path)\n\t\n    output_path = audio_path.replace(INPUT_DIR, OUTPUT_DIR)\n    if exists(output_path) and not force:\n        return output_path, False\n    mkdir(pathlib.Path(output_path).parent, parents=True, exist_ok=True)\n    speech_detected = remove_silence(\n        audio_path,\n        output_path,\n        silence_duration_threshold=silence_duration_threshold,\n        silence_db_threshold=silence_db_threshold,\n        offset=offset,\n        duration=duration,\n    )\n    return output_path, speech_detected", "CodeBleu_score": 37.57573324849588}, {"code": "def adjust_path_and_remove_silence(audio_path)\n\t\n    output_path = audio_path.replace(INPUT_DIR, OUTPUT_DIR)\n    if exists(output_path) and not force:\n        return output_path, False\n    mkdir(pathlib.Path(output_path).parent, parents=True, exist_ok=True)\n    audio = AudioSegment.from_file(audio_path)\n    audio = remove_silence(audio, silence_thresh=SILENCE_THRESH, chunk_size=CHUNK_SIZE)\n    if not audio:\n        return output_path, False\n    audio.export(output_path, format=\"wav\")\n    return output_path, True\n\n\n", "CodeBleu_score": 34.60352071234071}]}
{"instance_id": "7e0bdb0feff8", "generation_result": [{"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir is not None:\n        copytree(input_dir, output_dir)\n        input_dir = output_dir\n    input_files = glob.glob(os.path.join(input_dir, \"**\", f\"*.{file_ext}\"), recursive=True)\n    pbar = tqdm(total=len(input_files), desc=\"Resampling audio files\")\n    with Pool(n_jobs) as p:\n        for _ in p.imap_unordered(\n            resample_file,\n            [\n                (input_file, output_sr, output_dir, file_ext, pbar)\n                for input_file in input_files\n            ],\n        ):\n            pass\n    pbar.close()\n    print(\"Resampling completed.\")\n\n", "CodeBleu_score": 48.73852240959637}, {"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir:\n        print(\"Copying input directory to output directory...\")\n        copytree(input_dir, output_dir, dirs_exist_ok=True)\n        print(\"Done.\")\n        input_dir = output_dir\n\n    print(\"Finding audio files...\")\n    audio_files = glob(os.path.join(input_dir, \"**\", f\"*.{file_ext}\"), recursive=True)\n    print(f\"Found {len(audio_files)} audio files.\")\n\n    print(\"Resampling audio files...\")\n    with Pool(processes=n_jobs) as pool:\n        for _ in tqdm(pool.imap_unordered(resample_file, zip(audio_files, [output_sr] * len(audio_files), [input_dir] * len(audio_files), [output_dir] * len(audio_files))), total=len(audio_files)):\n            pass\n\n    print(\"Done.\")\n\n", "CodeBleu_score": 55.1127338134817}, {"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir is not None:\n        shutil.copytree(input_dir, output_dir)\n        input_dir = output_dir\n\n    input_files = glob.glob(f\"{input_dir}/**/*.{file_ext}\", recursive=True)\n    print(f\"Found {len(input_files)} files\")\n\n    with Pool(n_jobs) as p:\n        with tqdm(total=len(input_files)) as pbar:\n            for _ in p.imap_unordered(\n                partial(resample_file, output_sr=output_sr, output_dir=input_dir),\n                input_files,\n            ):\n                pbar.update()\n\n    print(\"Done\")\n\n", "CodeBleu_score": 45.90317425165807}]}
{"instance_id": "a1351834ca57", "generation_result": [{"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    eval_loss = 0\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(data_loader):\n            inputs, labels = inputs.cuda(), labels.cuda()\n            inputs = inputs.view(inputs.size(0), -1)\n            labels = labels.view(labels.size(0), -1)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            eval_loss += loss.item()\n            if batch_idx == len(data_loader) - 1:\n                embeddings = outputs.cpu().numpy()\n                labels = labels.cpu().numpy().reshape(-1)\n                plot_embeddings(embeddings, labels, global_step)\n    eval_loss /= len(data_loader)\n    dashboard_logger.eval_stats(eval_loss)\n    return eval_loss", "CodeBleu_score": 32.094753043949}, {"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    eval_loss = 0\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(data_loader):\n            inputs = inputs.view(-1, 1, 28, 28).cuda()\n            labels = labels.cuda()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            eval_loss += loss.item()\n\n    eval_loss /= (batch_idx + 1)\n    dashboard_logger.eval_stats(global_step, eval_loss)\n\n    inputs = inputs.view(inputs.size(0), -1)\n    embeddings = model.encoder(inputs)\n    embeddings = embeddings.cpu().numpy()\n    labels = labels.cpu().numpy()\n    labels = np.array([labels[i] for i in range(labels.shape[0]) for j in range(inputs.size(1))])\n    plot_embeddings(embeddings, labels, global_step, dashboard_logger)\n\n    return eval_loss", "CodeBleu_score": 35.2024305956988}, {"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    eval_loss = 0.0\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(data_loader):\n            inputs = inputs.view(inputs.size(0), -1)\n            inputs = inputs.cuda()\n            labels = labels.view(labels.size(0), -1)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            eval_loss += loss.item()\n\n    eval_loss /= len(data_loader)\n    dashboard_logger.eval_stats(global_step, eval_loss)\n\n    inputs = inputs.view(inputs.size(0), -1)\n    inputs = inputs.cpu()\n    labels = labels.view(labels.size(0), -1)\n    outputs = outputs.detach().cpu()\n    dashboard_logger.eval_figures(inputs, outputs, labels, global_step)\n\n    return eval_loss\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 31.294241526274487}]}
{"instance_id": "565f8ed09916", "generation_result": [{"code": "def register_config(model_name: str) -> Coqpit\n\t\n    config_class = None\n    config_name = model_name.replace(\"_\", \"\") + \"Config\"\n\n    # Check if the model is \"xtts\"\n    if model_name == \"xtts\":\n        # Import the specific configuration\n        from xtts.configs.xtts_config import XTTSConfig as Config\n    else:\n        # Construct the configuration class name\n        config_class_name = \"\".join(w.title() for w in config_name.split(\"_\"))\n\n        # Search through predefined paths to find the configuration class\n        for config_class_path in [\n            f\"xtts.configs.{config_name}\",\n            f\"xtts.configs.{config_class_name.lower()}_config\",\n            f\"xtts.configs.{config_class_name.lower()}\",\n        ]:\n            try:\n                config_module = importlib.import_module(config_class_path)\n                config_class = getattr(config_module, config_class_name)\n                break\n            except ModuleNotFoundError:\n                pass\n\n    # Raise an error if the configuration class is not found\n    if config_class is None:\n        raise ModuleNotFoundError(f\"Config class for model {model_name} not found\")\n\n    return config_class\n\n", "CodeBleu_score": 44.48259848800703}, {"code": "def register_config(model_name: str) -> Coqpit\n\t\n    if model_name == \"xtts\":\n        from xtts.configs.xtts_config import XTTSConfig\n\n        return XTTSConfig\n    config_class_name = f\"{model_name.title()}Config\"\n    config_class = None\n    paths = [\n        f\"xtts.configs.{model_name}_config\",\n        f\"xtts.configs.{model_name.replace('_', '')}_config\",\n        f\"xtts.configs.{model_name.replace('-', '')}_config\",\n    ]\n    for path in paths:\n        try:\n            module = import_module(path)\n            config_class = getattr(module, config_class_name)\n            break\n        except ModuleNotFoundError:\n            pass\n    if config_class is None:\n        raise ModuleNotFoundError(f\"Could not find {config_class_name} in {paths}\")\n    return config_class\n", "CodeBleu_score": 46.69404630331112}, {"code": "def register_config(model_name: str) -> Coqpit\n\t\n    config_class = None\n    if model_name == \"xtts\":\n        config_class_name = \"XTTSConfig\"\n        paths = [\n            \"xtts.config\",\n            \"xtts.configs\",\n            \"xtts.configs.config\",\n            \"xtts.configs.configs\",\n        ]\n    else:\n        config_class_name = f\"{model_name.title()}Config\"\n        paths = [\n            f\"xtts.config.{model_name}\",\n            f\"xtts.configs.{model_name}\",\n            f\"xtts.configs.config.{model_name}\",\n            f\"xtts.configs.configs.{model_name}\",\n        ]\n\n    for path in paths:\n        try:\n            module = import_module(path)\n            config_class = getattr(module, config_class_name)\n            break\n        except ModuleNotFoundError:\n            pass\n\n    if config_class is None:\n        raise ModuleNotFoundError(f\"Could not find {config_class_name} in {paths}\")\n\n    return config_class\n\n", "CodeBleu_score": 43.819855197759736}]}
{"instance_id": "0ea7862506a7", "generation_result": [{"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = {}\n    ext = splitext(config_path)[-1].lower()\n    if ext == \".yaml\":\n        config_dict.update(yaml.safe_load(open(config_path, \"r\")))\n    elif ext in {\".yml\", \".json\"}:\n        config_dict.update(read_json_with_comments(config_path))\n    else:\n        raise TypeError(\"Config file type {} is not supported\".format(ext))\n\n    model_name = _process_model_name(config_dict)\n    config_class = register_config(model_name)\n    config = config_class()\n    config.from_dict(config_dict)\n    return config", "CodeBleu_score": 37.2437450204614}, {"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = {}\n    ext = splitext(config_path)[-1]\n    if ext in (\".yml\", \".yaml\"):\n        with fsspec.open(config_path, \"r\", encoding=\"utf-8\") as yaml_file:\n            config_dict = yaml.safe_load(yaml_file)\n    elif ext == \".json\":\n        config_dict = read_json_with_comments(config_path)\n    else:\n        raise TypeError(\"Config file type should be yaml or json\")\n    model_name = _process_model_name(config_dict)\n    config_class = register_config(model_name)\n    config = config_class()\n    config.from_dict(config_dict)\n    return config\n\n", "CodeBleu_score": 52.542551539278136}, {"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = {}\n    ext = splitext(config_path)[-1].lower()\n    if ext == \".yaml\":\n        with fsspec.open(config_path, \"r\", encoding=\"utf-8\") as yaml_file:\n            config_dict = yaml.safe_load(yaml_file)\n    elif ext in {\".yml\", \".json\"}:\n        with fsspec.open(config_path, \"r\", encoding=\"utf-8\") as json_file:\n            config_dict = json.load(json_file)\n    else:\n        raise TypeError(f\"Given config file has unsupported type: {ext}\")\n    config_dict = _process_model_name(config_dict)\n    model_name = config_dict[\"model\"]\n    config_class = register_config(model_name)\n    config = config_class()\n    config.from_dict(config_dict)\n    return config\n\n", "CodeBleu_score": 57.854590266372654}]}
{"instance_id": "e0db68b63143", "generation_result": [{"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        for filename in filenames:\n            if contains is not None and filename.find(contains) == -1:\n                continue\n            ext = filename[filename.rfind(\".\"):].lower()\n            if validExts is None or ext.endswith(validExts):\n                yield os.path.join(rootDir, filename)", "CodeBleu_score": 69.73539288454757}, {"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        for filename in filenames:\n            if contains is not None and filename.find(contains) == -1:\n                continue\n            ext = filename[filename.rfind(\".\"):].lower()\n            if validExts is None or ext.endswith(validExts):\n                yield os.path.join(rootDir, filename)\n\n", "CodeBleu_score": 69.73539288454757}, {"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        for filename in filenames:\n            if contains is not None and filename.find(contains) == -1:\n                continue\n            ext = filename[filename.rfind(\".\"):].lower()\n            if validExts is None or ext.endswith(validExts):\n                yield os.path.join(rootDir, filename)", "CodeBleu_score": 69.73539288454757}]}
{"instance_id": "b836fcaf0a27", "generation_result": [{"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    clear_gpu_cache()\n    if not xtts_checkpoint or not xtts_config or not xtts_vocab:\n        return \"Error: Please provide all required paths for the model, config, and vocab\"\n    config = XttsConfig.from_json(xtts_config)\n    model = XTTS.init_from_config(config)\n    model.load_checkpoint(xtts_checkpoint, None)\n    model.load_vocabulary(xtts_vocab)\n    if is_available():\n        model.cuda()\n    print(\"XTTS Model Loaded\")\n    return \"Success\"\n\n", "CodeBleu_score": 40.56113403647904}, {"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    clear_gpu_cache()\n    if xtts_checkpoint is None:\n        return \"Error: XTTS checkpoint path is not provided.\"\n    if xtts_config is None:\n        return \"Error: XTTS config path is not provided.\"\n    if xtts_vocab is None:\n        return \"Error: XTTS vocab path is not provided.\"\n    print(\"Loading XTTS model...\")\n    config = XttsConfig.load_json(xtts_config)\n    XTTS_MODEL = Xtts.init_from_config(config)\n    XTTS_MODEL.load_checkpoint(xtts_checkpoint, \"cpu\")\n    XTTS_MODEL.load_vocab(xtts_vocab)\n    if is_available():\n        XTTS_MODEL.cuda()\n    print(\"XTTS model loaded successfully.\")\n    return \"XTTS model loaded successfully.\"\n\n", "CodeBleu_score": 52.2539004292492}, {"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    clear_gpu_cache()\n    if xtts_checkpoint is None or xtts_config is None or xtts_vocab is None:\n        return \"Error: Please provide the path to the XTTS checkpoint, config, and vocab files.\"\n    config = XttsConfig.from_json(xtts_config)\n    model = XTTS.init_from_config(config)\n    model.load_checkpoint(xtts_checkpoint, config)\n    model.load_vocab(xtts_vocab)\n    if is_available():\n        model.cuda()\n    print(\"XTTS model loaded successfully.\")\n    return \"XTTS model loaded successfully.\"\n\n", "CodeBleu_score": 48.24855425624983}]}
{"instance_id": "c5d63aa0df26", "generation_result": [{"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    if self.spec_type == \"torch\":\n        num_frames = int(num_frames / self.hop_length)\n    num_frames = min(num_frames, x.shape[-1])\n    offsets = np.linspace(0, x.shape[-1] - num_frames, num=num_eval)\n    frames_batch = []\n    for offset in offsets:\n        offset = int(offset)\n        frames_batch.append(x[..., offset : offset + num_frames])\n    frames_batch = np.stack(frames_batch, axis=0)\n    embeddings = self.inference(frames_batch)\n    if return_mean:\n        embeddings = torch.mean(embeddings, dim=0, keepdim=True)\n    if l2_norm:\n        embeddings = F.normalize(embeddings, p=2, dim=1)\n    return embeddings\n\n", "CodeBleu_score": 58.89118952706524}, {"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    num_frames = min(num_frames, x.shape[-1])\n    offsets = np.linspace(0, x.shape[-1] - num_frames, num=num_eval)\n    frames_batch = []\n    for offset in offsets:\n        offset = int(offset)\n        frames_batch.append(x[..., offset:offset + num_frames])\n    frames_batch = torch.cat(frames_batch, dim=0)\n    with torch.no_grad():\n        embeddings = self.inference(frames_batch)\n    if return_mean:\n        embeddings = torch.mean(embeddings, dim=0, keepdim=True)\n    if l2_norm:\n        embeddings = F.normalize(embeddings, dim=1)\n    return embeddings\n\n", "CodeBleu_score": 40.225690021017115}, {"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    if self.torch_spec:\n        num_frames = int(num_frames * self.hop_length / self.sample_rate)\n    offsets = np.linspace(0, x.shape[0] - self.n_fft, num_eval)\n    frames_batch = []\n    for offset in offsets:\n        offset = int(offset)\n        frames_batch.append(x[offset:offset + num_frames])\n    frames_batch = np.vstack(frames_batch)\n    embeddings = self.inference(frames_batch)\n    if return_mean:\n        embeddings = torch.mean(embeddings, dim=0)\n        if l2_norm:\n            embeddings = embeddings / torch.norm(embeddings, p=2)\n    return embeddings\n\n", "CodeBleu_score": 49.052227416813516}]}
{"instance_id": "06f5b0335b26", "generation_result": [{"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n", "CodeBleu_score": 85.18641475692186}, {"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n", "CodeBleu_score": 85.18641475692186}, {"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n", "CodeBleu_score": 85.18641475692186}]}
{"instance_id": "9ac60597b633", "generation_result": [{"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    # Calculate the number of utterances per class\n    num_utterances_per_class = [len(embeddings[embeddings[:, -1] == i]) for i in range(num_classes_in_batch)]\n\n    # Limit the number of classes to 10 if necessary\n    if len(num_utterances_per_class) > 10:\n        num_utterances_per_class = num_utterances_per_class[:10]\n        embeddings = embeddings[embeddings[:, -1] < 10]\n\n    # UMAP transform\n    reducer = umap.UMAP()\n    embedding = reducer.fit_transform(embeddings[:, :-1])\n\n    # Create a scatter plot\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.scatter(embedding[:, 0], embedding[:, 1], c=embeddings[:, -1], cmap='tab10')\n\n    # Add labels to the classes\n    for i in range(len(num_utterances_per_class)):\n        ax.annotate(str(i), (embedding[np.arange(embeddings.shape[0])[embeddings[:, -1] == i], 0].mean(),\n                              embedding[np.arange(embeddings.shape[0])[embeddings[:, -1] == i], 1].mean()),\n                    color='black', fontsize=12)\n\n    # Set title and adjust aspect ratio\n    plt.title('UMAP projection')\n    ax.set_aspect('equal', 'datalim')\n\n    # Save and return the plot\n    plt.savefig('umap.png')\n    return fig\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.23708017264643}, {"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    # Calculate the number of utterances per class\n    num_utterances_per_class = np.bincount(num_classes_in_batch)\n\n    # Limit the number of classes to 10 if necessary\n    num_classes = len(np.unique(num_classes_in_batch))\n    if num_classes > 10:\n        num_classes = 10\n\n    # Perform dimensionality reduction using UMAP\n    reducer = umap.UMAP()\n    reduced_embeddings = reducer.fit_transform(embeddings)\n\n    # Create a scatter plot with colors representing different classes\n    fig, ax = plt.subplots()\n    ax.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=num_classes_in_batch, cmap='tab10')\n\n    # Set the title and adjust the aspect ratio\n    plt.title(\"UMAP projection\")\n    ax.set_aspect('equal', 'datalim')\n\n    # Save the plot as an image file\n    plt.savefig(\"umap\")\n\n    # Return the figure\n    return fig", "CodeBleu_score": 32.97882858612811}, {"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    num_utterances_per_class = np.bincount(num_classes_in_batch)\n    if len(num_utterances_per_class) > 10:\n        num_utterances_per_class = num_utterances_per_class[:10]\n    labels = np.repeat(np.arange(len(num_utterances_per_class)), num_utterances_per_class)\n    reducer = umap.UMAP()\n    embedding = reducer.fit_transform(embeddings)\n    fig, ax = plt.subplots(figsize=(12, 10))\n    ax.scatter(embedding[:, 0], embedding[:, 1], c=[sns.color_palette()[x] for x in labels])\n    plt.gca().set_aspect('equal', 'datalim')\n    plt.title('UMAP projection', fontsize=24)\n    plt.savefig('umap')\n    return fig\n\n", "CodeBleu_score": 42.87585456631389}]}
{"instance_id": "19c2b4af256d", "generation_result": [{"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cos_sim_matrix = []\n    for spk_idx, centroid in enumerate(centroids):\n        # Calculate cosine similarity matrix\n        new_centroids = self.calc_new_centroids(spk_idx, centroids, dvecs)\n        # vector based cosine similarity for speed\n        cs_row = []\n        for utt_idx, dvec in enumerate(dvecs):\n            new_dvecs = torch.cat(\n                [dvecs[:utt_idx], dvecs[utt_idx + 1 :]], dim=0\n            )  # exclude current utterance\n            cos_sim = torch.clamp(\n                torch.mm(\n                    new_dvecs.unsqueeze(1), new_centroids.transpose(1, 0)\n                ) / (torch.norm(new_dvecs, 2, 1, True) * torch.norm(new_centroids, 2, 0)),\n                1e-6,\n            )\n            cs_row.append(cos_sim)\n        cos_sim_matrix.append(torch.cat(cs_row, dim=1))\n    cos_sim_matrix = torch.stack(cos_sim_matrix)\n    return cos_sim_matrix\n\n", "CodeBleu_score": 46.9626616885412}, {"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cos_sim_matrix = []\n    for spk_idx, centroid in enumerate(centroids):\n        # Calculate cosine similarity matrix\n        new_centroids = self.calc_new_centroids(spk_idx, centroids, dvecs)\n        # vector based cosine similarity for speed\n        cos_sim = torch.clamp(torch.mm(dvecs[spk_idx], new_centroids.transpose(0, 1)) / (\n                torch.norm(dvecs[spk_idx], 2) * torch.norm(new_centroids, 2, dim=1)), 0, 1)\n        cos_sim[torch.isnan(cos_sim)] = 0\n        cos_sim_matrix.append(cos_sim)\n    cos_sim_matrix = torch.stack(cos_sim_matrix)\n    return cos_sim_matrix\n\n", "CodeBleu_score": 30.69853602410747}, {"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cos_sim_matrix = []\n    for spk_idx, centroid in enumerate(centroids):\n        # Calculate cosine similarity matrix\n        new_centroids = self.calc_new_centroids(spk_idx, centroids, dvecs)\n        # vector based cosine similarity for speed\n        cos_sim = torch.clamp(\n            torch.mm(dvecs[spk_idx], new_centroids.transpose(0, 1))\n            / (torch.norm(dvecs[spk_idx], 2) * torch.norm(new_centroids, 2, dim=1)),\n            1e-6,\n        )\n        cos_sim_matrix.append(cos_sim)\n    return torch.cat(cos_sim_matrix, dim=0)\n\n", "CodeBleu_score": 32.819694474564294}]}
{"instance_id": "c525b411a1e7", "generation_result": [{"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    N = dvecs.size(0)\n    loss = []\n    for j in range(N):\n        dvec_j = dvecs[j].unsqueeze(0)\n        dvec_j_expand = dvec_j.expand_as(dvecs)\n        # Compute the negative log softmax of the cosine similarity matrix for each embedding\n        loss_row = - F.log_softmax(cos_sim_matrix[j], 0)\n        # Add the negative log softmax of the cosine similarity matrix for each embedding to the loss list\n        loss.append(loss_row)\n    # Stack the losses for each row into a tensor\n    return torch.stack(loss)\n\n\n\n", "CodeBleu_score": 39.78089860437268}, {"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    N = dvecs.size(0)\n    L = []\n    for j in range(N):\n        L_row = []\n        for i in range(N):\n            L_row.append(-F.log_softmax(cos_sim_matrix[i], 0).squeeze(0)[j])\n        L_row = torch.stack(L_row)\n        L.append(L_row)\n    return torch.stack(L)", "CodeBleu_score": 61.408141804252836}, {"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    N = dvecs.size(0)\n    loss = []\n    for j in range(N):\n        dvec_j = dvecs[j].unsqueeze(0)\n        ref_j = dvecs[torch.arange(0, N) != j].view(N - 1, self.emb_dim)\n        ref_j = torch.cat((dvec_j, ref_j), 0)\n        cos_sim_j = F.cosine_similarity(dvec_j.repeat(N, 1), ref_j)\n        label = torch.from_numpy(np.array([0] + range(N - 1, 0, -1)))\n        label = label.to(self.device)\n        L_j = F.log_softmax(cos_sim_j, 0)\n        L_j = L_j.gather(0, label.view(-1, 1)).squeeze()\n        loss.append(L_j)\n    return torch.stack(loss)", "CodeBleu_score": 31.68635463782692}]}
{"instance_id": "25ac3945da2e", "generation_result": [{"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    loss_row = []\n    for i, dvec in enumerate(dvecs):\n        centroids_sigmoids = torch.cat([torch.sigmoid(cos_sim_matrix[i, :i]), torch.sigmoid(cos_sim_matrix[i, i+1:])])\n        contrast_losses = torch.log(1 + torch.exp(torch.sum(centroids_sigmoids)))\n        loss_row.append(contrast_losses)\n    L_row = torch.stack(loss_row)\n    return L_row\n\n", "CodeBleu_score": 34.49028956120689}, {"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    L_row = []\n    for i in range(len(dvecs)):\n        L = []\n        for j in range(len(dvecs)):\n            if i != j:\n                L.append(torch.sigmoid(cos_sim_matrix[i][j]))\n        L_row.append(torch.stack(L))\n    return torch.stack(L_row)\n\n", "CodeBleu_score": 29.345714081863854}, {"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    L_row = []\n    for i in range(dvecs.shape[0]):\n        L = []\n        for j in range(dvecs.shape[0]):\n            if i == j:\n                continue\n            else:\n                L.append(torch.sigmoid(cos_sim_matrix[i][j]))\n        L_row.append(torch.stack(L))\n    return torch.stack(L_row)\n\n", "CodeBleu_score": 32.24676195136776}]}
{"instance_id": "878d14ffabd2", "generation_result": [{"code": "def forward(self, x, _label=None)\n\t\n    # Ensure inputs have at least two utterances per speaker\n    assert x.size()[1] >= 2\n\n    # Compute centroids by averaging the embeddings\n    centroids = torch.mean(x, dim=1)\n\n    # Compute the cosine similarity matrix between the embeddings and centroids\n    cos_sim_matrix = self.calc_cosine_sim(x, centroids)\n\n    # Scale the cosine similarity matrix and shift it\n    cos_sim_matrix = self.scale_shift(cos_sim_matrix)\n\n    # Compute the embedding loss\n    embed_loss = self.embed_loss(cos_sim_matrix, _label)\n\n    # Return the mean loss\n    return embed_loss.mean()\n\n\n", "CodeBleu_score": 58.999057453568284}, {"code": "def forward(self, x, _label=None)\n\t\n    # x is N x M x D\n    # where, N is number of speakers\n    # M is number of utterances per speaker\n    # D is the embedding dim\n    num_speakers, num_utts_per_speaker = x.shape[0], x.shape[1]\n\n    # ensure num_utts_per_speaker is at least 2\n    if num_utts_per_speaker < 2:\n        raise ValueError(\n            \"Number of utterances per speaker must be at least 2,\"\n            \" got {0}\".format(num_utts_per_speaker)\n        )\n\n    # loss\n    centroids = torch.mean(x, dim=1)\n    sim_matrix = self.calc_cosine_sim(x, centroids)\n    sim_matrix = num_utts_per_speaker * torch.nn.functional.relu(sim_matrix)\n    eye = torch.eye(num_speakers).to(sim_matrix.device)\n    pos_mask = torch.roll(eye, 1, 1)\n    neg_mask = 1.0 - eye\n    loss = self.embed_loss(sim_matrix * pos_mask, eye)\n    loss += self.embed_loss(sim_matrix * neg_mask, eye)\n    loss = loss / num_speakers\n    return loss", "CodeBleu_score": 35.53119568090198}, {"code": "def forward(self, x, _label=None)\n\t\n    # Ensure inputs have at least two utterances per speaker\n    assert x.size()[1] >= 2\n    # Calculate centroids by averaging the embeddings\n    centroids = torch.mean(x, dim=1)\n    # Calculate the cosine similarity matrix between the embeddings and centroids\n    cos_sim = self.calc_cosine_sim(x, centroids)\n    # Scale the cosine similarity matrix\n    cos_sim = self.scale_sim_matrix * cos_sim\n    # Shift the cosine similarity matrix\n    cos_sim = cos_sim + self.margin\n    # Calculate the embedding loss\n    embed_loss = self.embed_loss(cos_sim, _label)\n    # Average the embedding loss\n    embed_loss = torch.mean(embed_loss)\n    return embed_loss\n\n", "CodeBleu_score": 51.41725109753016}]}
{"instance_id": "86a364c72caa", "generation_result": [{"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\t\n    voices = {}\n    for extra_voice_dir in extra_voice_dirs:\n        for root, dirs, files in os.walk(extra_voice_dir):\n            for file in files:\n                if file.endswith(\".npz\"):\n                    subdir = os.path.basename(root)\n                    if subdir not in voices:\n                        voices[subdir] = []\n                    voices[subdir].append(os.path.join(root, file))\n            if not voices:\n                for file in files:\n                    if file.endswith(\".wav\") or file.endswith(\".mp3\"):\n                        subdir = os.path.basename(root)\n                        if subdir not in voices:\n                            voices[subdir] = []\n                        voices[subdir].append(os.path.join(root, file))\n    return voices\n", "CodeBleu_score": 26.7232787248177}, {"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\t\n    voices = {}\n    for extra_voice_dir in extra_voice_dirs:\n        for subdir, dirs, files in os.walk(extra_voice_dir):\n            if not dirs:\n                if not files:\n                    continue\n                voice_files = []\n                for file in files:\n                    if file.endswith(\".npz\"):\n                        voice_files.append(os.path.join(subdir, file))\n                if not voice_files:\n                    for file in files:\n                        if file.endswith(\".wav\") or file.endswith(\".mp3\"):\n                            voice_files.append(os.path.join(subdir, file))\n                if voice_files:\n                    voices[os.path.basename(subdir)] = voice_files\n    return voices\n\n", "CodeBleu_score": 26.00722514800787}, {"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\t\n    voices = {}\n    extra_voice_dirs.append(\"voices\")\n    for extra_voice_dir in extra_voice_dirs:\n        for subdir, dirs, files in os.walk(extra_voice_dir):\n            for file in files:\n                if file.endswith(\".npz\"):\n                    if subdir not in voices:\n                        voices[subdir] = []\n                    voices[subdir].append(os.path.join(subdir, file))\n            if len(voices) == 0:\n                for file in files:\n                    if file.endswith(\".wav\") or file.endswith(\".mp3\"):\n                        if subdir not in voices:\n                            voices[subdir] = []\n                        voices[subdir].append(os.path.join(subdir, file))\n    return voices\n\n", "CodeBleu_score": 27.33770996710576}]}
{"instance_id": "02f20c8917e6", "generation_result": [{"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t\n    if voice == \"random\":\n        return None, None, None\n    voice_paths = get_voices(voice, extra_voice_dirs)\n    if len(voice_paths) > 1:\n        raise ValueError(f\"Multiple voices found for {voice}: {voice_paths}\")\n    voice_path = voice_paths[0]\n    if not os.path.exists(voice_path):\n        raise ValueError(f\"Voice {voice} not found at {voice_path}\")\n    if voice_path.endswith(\".npz\"):\n        return load_npz(voice_path)\n    else:\n        voice_name, voice_ext = os.path.splitext(voice)\n        npz_path = os.path.join(model.base_dir, \"voices\", f\"{voice_name}.npz\")\n        if not os.path.exists(npz_path):\n            print(f\"Generating {voice_name}.npz voice file...\")\n            model.generate_voice(voice_path, npz_path)\n        return load_npz(npz_path)\n\n", "CodeBleu_score": 50.480122183147415}, {"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t\n    if voice == \"random\":\n        return None, None, None\n    voice_paths = get_voices(voice, extra_voice_dirs)\n    if len(voice_paths) > 1:\n        raise ValueError(f\"Multiple voices named {voice}: {voice_paths}\")\n    voice_path = voice_paths[0]\n    if not os.path.exists(voice_path):\n        raise ValueError(\n            f\"voice {voice} not found for {model.__class__.__name__}\")\n    if voice_path.endswith(\".npz\"):\n        voice_data = load_npz(voice_path)\n        return voice_data[\"mean\"], voice_data[\"scale\"], voice_data[\"mel\"]\n    if not voice_path.endswith(\".wav\"):\n        raise ValueError(\n            f\"voice file {voice_path} is not a .wav or .npz file\")\n    voice_dir = os.path.dirname(voice_path)\n    npz_path = os.path.join(voice_dir, f\"{model.name}_{voice}.npz\")\n    if not os.path.exists(npz_path):\n        mel = audio.wav_to_mel(voice_path)\n        np.savez_compressed(npz_path, mel=mel)\n    else:\n        mel = np.load(npz_path)[\"mel\"]\n    return None, None, mel\n\n", "CodeBleu_score": 48.669805173269424}, {"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t\n    if voice == \"random\":\n        return None, None, None\n\n    voice_paths = get_voices(model, extra_voice_dirs)\n\n    if voice not in voice_paths:\n        raise ValueError(\n            f\"voice {voice} not found in voices.json. Available voices: {list(voice_paths.keys())}\"\n        )\n\n    voice_path = voice_paths[voice]\n\n    if isinstance(voice_path, list):\n        raise ValueError(\n            f\"Multiple voices found for {voice}. Please specify a path manually.\"\n        )\n\n    if not os.path.exists(voice_path):\n        raise ValueError(f\"voice {voice} not found at path {voice_path}\")\n\n    if voice_path.endswith(\".npz\"):\n        voice_data = load_npz(voice_path)\n        return voice_data[\"mean\"], voice_data[\"std\"], voice_data[\"step\"]\n\n    if not voice_path.endswith(\".wav\"):\n        raise ValueError(f\"voice {voice} is not a .wav or .npz file\")\n\n    voice_data = generate_voice(model, voice_path)\n\n    voice_name, ext = os.path.splitext(os.path.basename(voice_path))\n    npz_path = os.path.join(model.save_dir, voice_name + \".npz\")\n    np.savez_compressed(npz_path, **voice_data)\n\n    return load_voice(model, voice_name + \".npz\")\n\n", "CodeBleu_score": 47.26276912363888}]}
{"instance_id": "9458e981389f", "generation_result": [{"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, num_heads, seq_length1, seq_length2 = pos_score.size()\n    zeros = pos_score.new_zeros(batch_size, num_heads, seq_length1, 1)\n    padded_pos_score = torch.cat([zeros, pos_score], dim=-1)\n    padded_pos_score = padded_pos_score.view(\n        batch_size, num_heads, seq_length2 + 1, seq_length1)\n    pos_score = padded_pos_score[:, :, 1:].view_as(pos_score)\n    return pos_score", "CodeBleu_score": 55.066568735137686}, {"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, num_heads, seq_length1, seq_length2 = pos_score.size()\n    zeros = pos_score.new_zeros(batch_size, num_heads, seq_length1, 1)\n    padded_pos_score = torch.cat([zeros, pos_score], dim=-1)\n    padded_pos_score = padded_pos_score.view(\n        batch_size, num_heads, seq_length2 + 1, seq_length1)\n    pos_score = padded_pos_score[:, :, 1:].view_as(pos_score)\n    return pos_score", "CodeBleu_score": 55.066568735137686}, {"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, num_heads, seq_length1, seq_length2 = pos_score.size()\n    zeros = pos_score.new_zeros(batch_size, num_heads, seq_length1, 1)\n    padded_pos_score = torch.cat([zeros, pos_score], dim=-1)\n    padded_pos_score = padded_pos_score.view(batch_size, num_heads, seq_length2 + 1, seq_length1)\n    pos_score = padded_pos_score[:, :, 1:].view_as(pos_score)\n    return pos_score\n\n", "CodeBleu_score": 57.08735369887231}]}
{"instance_id": "c046d4f00e80", "generation_result": [{"code": "def run_padded_sequence(self, context, lens)\n\t\n    context_embedded = []\n    for i in range(context.size(1)):\n        context_embedded.append(self.dropout(F.relu(self.conv(context[:, i, :lens[i]].transpose(0, 1)))))\n    context_embedded = pad_sequence(context_embedded, batch_first=True)\n    return context_embedded\n\n", "CodeBleu_score": 25.989172903945047}, {"code": "def run_padded_sequence(self, context, lens)\n\t\n    # Extract the context up to the specified length for each batch element\n    context_embedded = [self.embedding(context[i, :lens[i]]) for i in range(context.size(0))]\n\n    # Apply the convolutional layers to each batch element\n    for conv in self.convs:\n        # Apply the convolutional layer\n        context_embedded = [F.relu(conv(context_embedded[i])) for i in range(context.size(0))]\n\n        # Apply dropout to the output of the convolutional layer\n        context_embedded = [self.dropout(context_embedded[i]) for i in range(context.size(0))]\n\n    # Pad the processed contexts to create a consistent batch size\n    context_embedded = pad_sequence(context_embedded, batch_first=True)\n\n    # Return the padded sequence\n    return context_embedded\n\n", "CodeBleu_score": 24.46774544650454}, {"code": "def run_padded_sequence(self, context, lens)\n\t\n    # Extract the context up to the specified length\n    context = context[:, :lens, :]\n    # Apply the convolutional layers\n    context = self.conv(context.transpose(1, 2)).transpose(1, 2)\n    # Store the processed contexts\n    context_embedded = []\n    # For each batch element, extract the processed context and store it\n    for i in range(context.size(0)):\n        context_embedded.append(context[i, :lens[i], :])\n    # Pad the processed contexts to create a consistent batch size\n    context_embedded = pad_sequence(context_embedded, batch_first=True)\n    # Apply dropout to the processed contexts\n    context_embedded = self.dropout(context_embedded)\n    # Return the padded sequence\n    return context_embedded\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.66025306637459}]}
{"instance_id": "db2644f3c681", "generation_result": [{"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    lens_sorted, indices = torch.sort(lens, dim=0, descending=True)\n    lens_sorted = lens_sorted.long()\n    _, indices_sorted = torch.sort(indices, dim=0)\n    indices_sorted = indices_sorted.long()\n    context_sorted = context.index_select(0, indices_sorted)\n    context_packed = pack_padded_sequence(context_sorted, lens_sorted, batch_first=True)\n    context_sorted_var = Variable(context_sorted)\n    context_sorted_var = context_sorted_var.cuda()\n    context_packed = context_packed.cuda()\n    context_sorted_var = context_sorted_var.cuda()\n    context_packed = context_packed.cuda()\n    context_sorted_var = context_sorted_var.cuda()\n    context_packed = context_packed.cuda()\n    context_sorted_var = context_sorted_var.cuda()\n    context_packed = context_packed.cuda()\n    context_sorted_var = context_sorted_var.cuda()\n    context_packed = context_packed.cuda()\n    context_sorted_var = context_sorted_var.cuda()\n    context_packed = context_packed.cuda()\n    context_sorted_var = context_sorted_var.cuda()\n    context_packed = context_packed.cuda()\n    context_sorted_var = context_sorted_var.cuda()\n    context_packed = context_packed.cuda()\n    context_sorted_var = context_sorted_var.cuda()\n    context_packed = context_packed.cuda()\n    context_sorted_var = context_sorted_var.cuda()\n    context_packed = context_packed.cuda()\n    context_sorted_var = context_sorted_var.cuda()\n    context_packed = context_packed.", "CodeBleu_score": 11.725907795773669}, {"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    lens_sorted, indices = torch.sort(lens, dim=0, descending=True)\n    _, indices_sorted = torch.sort(indices, dim=0)\n    lens_sorted = lens_sorted.long()\n    sorted_ctx = pack_padded_sequence(context[indices], lens_sorted.cpu(), batch_first=True)\n    sorted_ctx = fn(sorted_ctx)\n    ctx_sorted, _ = pad_packed_sequence(sorted_ctx, batch_first=True, total_length=context.size(1))\n    ctx_sorted = ctx_sorted.index_select(0, indices_sorted)\n    return ctx_sorted\n\n", "CodeBleu_score": 21.46410199728371}, {"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    lens_sorted, indices = lens.sort(0, descending=True)\n    inputs = pack_padded_sequence(context[indices], lens_sorted.cpu().numpy(), batch_first=True)\n    outputs, _ = fn(inputs, None)\n    _, _indices = torch.sort(indices)\n    return outputs[_indices]\n\n", "CodeBleu_score": 7.764752720673522}]}
{"instance_id": "ced082bffc63", "generation_result": [{"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    self.convt_pre.remove_weight_norm()\n    for block in self.conv_blocks:\n        block.remove_weight_norm()\n\n", "CodeBleu_score": 33.51046275391997}, {"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    remove_parametrizations(self.convt_pre, 'weight')\n    for block in self.conv_blocks:\n        remove_parametrizations(block, 'weight')\n\n", "CodeBleu_score": 45.031169646022775}, {"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    remove_parametrizations(self.convt_pre, 'weight')\n    for block in self.conv_blocks:\n        remove_parametrizations(block, 'weight')\n\n", "CodeBleu_score": 45.031169646022775}]}
{"instance_id": "b5a39fd97061", "generation_result": [{"code": "def map_mx_to_torch_model(mx_name)\n\t\n    mx_name = mx_name.lower()\n    if mx_name.startswith(\"se_\"):\n        mx_name = mx_name.replace(\"se_\", \"se_\")\n    elif mx_name.startswith(\"senet_\"):\n        mx_name = mx_name.replace(\"senet_\", \"senet_\")\n    elif mx_name.startswith(\"inceptionv3\"):\n        mx_name = mx_name.replace(\"inceptionv3\", \"inception_v3\")\n    torch_name = \"gluon_\" + mx_name\n    return torch_name\n\n", "CodeBleu_score": 47.32092169454966}, {"code": "def map_mx_to_torch_model(mx_name)\n\t\n    torch_name = mx_name.lower()\n    torch_name = torch_name.replace('se_', 'se')\n    torch_name = torch_name.replace('senet_', 'senet')\n    torch_name = torch_name.replace('inceptionv3', 'inception_v3')\n    torch_name = 'gluon_' + torch_name\n    return torch_name\n\n", "CodeBleu_score": 50.54166478041656}, {"code": "def map_mx_to_torch_model(mx_name)\n\t\n    mx_name = mx_name.lower()\n    mx_name = mx_name.replace('se_', 'se')\n    mx_name = mx_name.replace('senet_', 'senet')\n    mx_name = mx_name.replace('inceptionv3', 'inception_v3')\n    return 'gluon_' + mx_name\n\n", "CodeBleu_score": 31.42416923645987}]}
{"instance_id": "7eee5efdbf67", "generation_result": [{"code": "def _num_samples_per_worker(self)\n\t\n    num_samples = self.repeats * self.total_samples\n    if self.is_training:\n        num_samples = math.ceil(num_samples / self.num_workers)\n    if self.batch_size is not None:\n        num_samples = (\n            num_samples // self.batch_size\n        ) * self.batch_size\n    return int(max(num_samples, 1))\n\n", "CodeBleu_score": 32.52541304804249}, {"code": "def _num_samples_per_worker(self)\n\t\n    num_samples_per_worker = self.num_samples / self.num_replicas\n    if self.repeats:\n        num_samples_per_worker = math.ceil(num_samples_per_worker / self.repeats)\n    if self.batch_size:\n        num_samples_per_worker = max(\n            num_samples_per_worker, self.batch_size * self.num_replicas\n        )\n    return int(num_samples_per_worker)\n\n", "CodeBleu_score": 35.00166667903127}, {"code": "def _num_samples_per_worker(self)\n\t\n    num_samples_per_worker = self.repeats * self.total_samples\n    if self.training or self.replicas > 1:\n        num_samples_per_worker = math.ceil(num_samples_per_worker / self.replicas)\n    if self.batch_size is not None:\n        num_samples_per_worker = max(\n            num_samples_per_worker, self.batch_size * self.replicas\n        )\n    return num_samples_per_worker\n\n", "CodeBleu_score": 37.70063469320885}]}
{"instance_id": "a698d65ae190", "generation_result": [{"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n\n    if types is None:\n        types = IMG_EXTENSIONS\n    if isinstance(types, str):\n        types = [types]\n    assert len(types) > 0, 'at least one file type must be specified'\n    for t in types:\n        assert t in IMG_EXTENSIONS, \\\n            f'{t} is invalid; only {IMG_EXTENSIONS} are supported'\n\n    labels = []\n    filenames = []\n    for root, subdirs, files in os.walk(folder, topdown=False, followlinks=True):\n        rel_path = os.path.relpath(root, folder) if (root != folder) else ''\n        label = os.path.basename(rel_path) if leaf_name_only else rel_path.replace(os.path.sep, '_')\n        for f in files:\n            base, ext = os.path.splitext(f)\n            if ext.lower() in types:\n                filenames.append(os.path.join(root, f))\n                labels.append(label)\n\n    if len(labels) == 0:\n        raise RuntimeError(f'No file of types {\",\".join(types)} found in {folder}.')\n\n    # Read class_to_idx\n    if class_to_idx is None:\n        # Map class name to class index\n        unique_labels = set(labels)\n        sorted_labels = list(sorted(unique_labels, key=natural_key))\n        class_to_idx = {c: idx for idx, c in enumerate(sorted_labels)}\n    images_and_targets = [(f, class_to_idx[l]) for f, l in zip(filenames, labels) if l in class_to_idx]\n    if sort:\n        images_and_targets = sorted(images_and_targets, key=lambda k: natural_key(k[0]))\n    if len(images_and_targets) == 0:\n        raise RuntimeError(\n            f'No file of types {\",\".join(types)} found in {folder}.'\n        )\n\n    return images", "CodeBleu_score": 74.46248163821127}, {"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    if types is None:\n        types = IMG_EXTENSIONS\n    if class_to_idx is None:\n        # build class_to_idx based on the directory structure\n        classes = [d.name for d in os.scandir(folder) if d.is_dir()]\n        classes.sort()\n        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n    return make_dataset(\n        directory=folder,\n        class_to_idx=class_to_idx,\n        extensions=types,\n        is_valid_file=is_valid_file,\n        leaf_name_only=leaf_name_only,\n        sort=sort\n    )\n\n", "CodeBleu_score": 20.264008789095207}, {"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    if types is None:\n        types = IMG_EXTENSIONS\n    if class_to_idx is None:\n        class_to_idx = dict()\n        build_class_idx = True\n    else:\n        build_class_idx = False\n    labels = []\n    filenames = []\n    for root, subdirs, files in os.walk(folder, topdown=False, followlinks=True):\n        rel_path = os.path.relpath(root, folder) if (root != folder) else ''\n        label = os.path.basename(rel_path) if leaf_name_only else rel_path.replace(os.path.sep, '_')\n        if build_class_idx and label not in class_to_idx:\n            class_to_idx[label] = None\n        for f in files:\n            base, ext = os.path.splitext(f)\n            if ext.lower() in types:\n                filenames.append(os.path.join(root, f))\n                labels.append(label)\n    if build_class_idx:\n        classes = sorted(class_to_idx.keys(), key=natural_key)\n        for idx, c in enumerate(classes):\n            class_to_idx[c] = idx\n    image_index = [(f, class_to_idx[l]) for f, l in zip(filenames, labels) if l in class_to_idx]\n    empty_classes = set(class_to_idx.keys()) - set(labels)\n    for c in empty_classes:\n        class_to_idx.pop(c)\n    if sort:\n        image_index = sorted(image_index, key=lambda k: natural_key(k[0]))\n    return image_index, class_to_idx\n\n", "CodeBleu_score": 66.63053294707547}]}
{"instance_id": "e7fe43bdecdc", "generation_result": [{"code": "def pytorch_worker_seed()\n\t\n    worker_info = get_worker_info()\n    if worker_info is not None:\n        return worker_info.seed\n    else:\n        return 12345 + int(os.environ.get('WDS_RANK', 0))", "CodeBleu_score": 50.13363161752281}, {"code": "def pytorch_worker_seed()\n\t\n    info = get_worker_info()\n    if info is not None:\n        return info.seed\n    else:\n        return 42 + rank()\n\n", "CodeBleu_score": 39.11304882966666}, {"code": "def pytorch_worker_seed()\n\t\n    info = get_worker_info()\n    if info is not None:\n        return info.seed\n    else:\n        return 42 + get_wds_rank()\n\n", "CodeBleu_score": 39.74041767165449}]}
{"instance_id": "0ffc7e7ded25", "generation_result": [{"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    if img.mode in ('L', 'RGB'):\n        lut = []\n        for i in range(256):\n            if i < thresh:\n                lut.append(min(i + add, 255))\n            else:\n                lut.append(i)\n        return img.point(lut)\n    else:\n        return img", "CodeBleu_score": 51.86311611636141}, {"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    if img.mode == \"L\":\n        lut = []\n        for i in range(256):\n            if i < thresh:\n                lut.append(min(i + add, 255))\n            else:\n                lut.append(i)\n        img = img.point(lut)\n        return img\n    elif img.mode == \"RGB\":\n        lut = []\n        for i in range(256):\n            if i < thresh:\n                lut.append(min(i + add, 255))\n            else:\n                lut.append(i)\n        img = img.convert(\"L\")\n        img = img.point(lut)\n        img = img.convert(\"RGB\")\n        return img\n    else:\n        return img\n\n", "CodeBleu_score": 47.738511580940866}, {"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    if img.mode != 'L':\n        return img\n    lut = []\n    for i in range(256):\n        if i < thresh:\n            lut.append(min(i + add, 255))\n        else:\n            lut.append(i)\n    img = img.point(lut)\n    return img", "CodeBleu_score": 50.15851996258153}]}
{"instance_id": "5a0d29577a21", "generation_result": [{"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    transform_names, transform_probabilities = zip(*transforms.items())\n    transform_probabilities = np.array(transform_probabilities) / np.sum(transform_probabilities)\n    return transform_names, transform_probabilities\n\n", "CodeBleu_score": 26.6898346174743}, {"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    transform_names, transform_probs = zip(*transforms.items())\n    transform_probs = np.array(transform_probs) / np.sum(transform_probs)\n    return transform_names, transform_probs\n\n", "CodeBleu_score": 30.110471671460658}, {"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    transform_names = list(transforms.keys())\n    transform_probabilities = [transforms[transform_name] for transform_name in transform_names]\n    transform_probabilities = transform_probabilities / np.sum(transform_probabilities)\n    return transform_names, transform_probabilities\n\n", "CodeBleu_score": 15.237561840020858}]}
{"instance_id": "84bc5658c135", "generation_result": [{"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros_like(img)\n    for w in mixing_weights:\n        mixed += w * self._apply_operations(img.copy())\n    mixed = np.clip(mixed, 0, 255).astype(np.uint8)\n    mixed = Image.fromarray(mixed)\n    return Image.blend(img, mixed, m)\n", "CodeBleu_score": 23.543803598986134}, {"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros_like(img)\n    for weight in mixing_weights:\n        mixed += weight * self._apply_sequence(img, m)\n    mixed = np.clip(mixed, 0, 255).astype(np.uint8)\n    mixed = Image.fromarray(mixed)\n    return Image.blend(img, mixed, self.alpha)\n\n", "CodeBleu_score": 20.768511107270587}, {"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros_like(img)\n    for weight in mixing_weights:\n        mixed += weight * np.asarray(\n            self._apply_augmentation(img, m), dtype=np.float32\n        )\n    mixed = np.clip(mixed, 0, 255).astype(np.uint8)\n    mixed = Image.fromarray(mixed)\n    return Image.blend(img, mixed, self.blend_factor)", "CodeBleu_score": 25.412549074197926}]}
{"instance_id": "84b5b752ff04", "generation_result": [{"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance(x, (tuple, list)):\n        x = (x,) * n\n    elif len(x) != n:\n        _logger.warning(\"The number of channels in the input is not equal to the required number. The input will be averaged and repeated.\")\n        x = (np.mean(x),) * n\n    else:\n        assert len(x) == n\n    return x\n\n", "CodeBleu_score": 44.51819769673506}, {"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance(x, (tuple, list)):\n        x = (x,) * n\n    elif len(x) != n:\n        x = (np.mean(x),) * n\n        _logger.warning(\n            \"The number of channels of the input does not match the required number of channels. The input will be adapted by repeating the mean of the input channels.\"\n        )\n    else:\n        assert len(x) == n\n    return x\n\n", "CodeBleu_score": 45.412061036954185}, {"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance(x, (tuple, list)):\n        x = (x,) * n\n    elif len(x) != n:\n        _logger.warning(\"x should be a tuple/list of length {:d}\".format(n))\n        x = np.mean(x)\n        x = (x,) * n\n    else:\n        assert len(x) == n\n    return x\n\n", "CodeBleu_score": 42.247469740815816}]}
{"instance_id": "54754b6ba394", "generation_result": [{"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    worker_info = get_worker_info()\n    if worker_info is None:\n        return\n    if isinstance(worker_seeding, Callable):\n        seed = worker_seeding(worker_info.seed % (2 ** 32))\n        random.seed(seed)\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n    elif worker_seeding == 'all':\n        seed = worker_info.seed % (2 ** 32)\n        np.random.seed(seed)\n\n", "CodeBleu_score": 53.28168413081451}, {"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    info = get_worker_info()\n    if isinstance(info, dict):\n        seed = info.seed % 2 ** 32\n    else:\n        seed = info % 2 ** 32\n    if callable(worker_seeding):\n        seed = worker_seeding(seed)\n    elif worker_seeding == 'all':\n        seed = seed % 2 ** 32\n        random.seed(seed)\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n    else:\n        raise ValueError(f\"Expected callable or 'all', but got {worker_seeding}\")", "CodeBleu_score": 44.148209434117966}, {"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    worker_info = get_worker_info()\n    if worker_info is None:\n        return\n    worker_id = worker_info.id\n    if isinstance(worker_seeding, Callable):\n        seed = worker_seeding(worker_info)\n        random.seed(seed)\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n    elif isinstance(worker_seeding, str):\n        if worker_seeding == 'all':\n            seed = worker_info.seed % (2 ** 32 - 1)\n            random.seed(seed)\n            torch.manual_seed(seed)\n            np.random.seed(seed)\n        else:\n            raise ValueError(f'Expected worker_seeding to be a callable or \"all\", but got {worker_seeding}')\n    else:\n        raise ValueError(f'Expected worker_seeding to be a callable or \"all\", but got {worker_seeding}')", "CodeBleu_score": 57.6403556255364}]}
{"instance_id": "81dfdce940db", "generation_result": [{"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    shape = extract_jpeg_shape(image_bytes)\n    image_height = shape[0]\n    image_width = shape[1]\n    padded_center_crop_size = tf.cast(\n        (\n            (image_size / (image_size + CROP_PADDING))\n            * tf.cast(tf.minimum(image_height, image_width), tf.float32)\n        ),\n        tf.int32,\n    )\n    offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n    offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n    crop_window = tf.stack(\n        [offset_height, offset_width, padded_center_crop_size, padded_center_crop_size]\n    )\n    image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n    image = resize(image, image_size, image_size, resize_method)\n    return image\n\n", "CodeBleu_score": 53.34031849827219}, {"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    shape = extract_jpeg_shape(image_bytes)\n    image_height = shape[0]\n    image_width = shape[1]\n    padded_center_crop_size = tf.cast(\n        ((image_size / (image_size + CROP_PADDING)) * tf.cast(tf.minimum(image_height, image_width), tf.float32)), tf.int32\n    )\n    offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n    offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n    crop_window = tf.stack([offset_height, offset_width, padded_center_crop_size, padded_center_crop_size])\n    image = tf.io.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n    image = resize(image, image_size, image_size, resize_method)\n    return image\n\n", "CodeBleu_score": 53.954292262873295}, {"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    shape = tf.io.extract_jpeg_shape(image_bytes)\n    image_height = shape[0]\n    image_width = shape[1]\n    padded_center_crop_size = tf.cast(\n        ((image_size / (image_size + CROP_PADDING)) * tf.cast(tf.minimum(image_height, image_width), tf.float32)), tf.int32\n    )\n    offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n    offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n    crop_window = tf.stack([offset_height, offset_width, padded_center_crop_size, padded_center_crop_size])\n    image = tf.io.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n    image = resize(image, image_size, image_size, resize_method)\n    return image\n\n", "CodeBleu_score": 55.48611745947669}]}
{"instance_id": "cf16a6d37111", "generation_result": [{"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    shape = tf.io.extract_jpeg_shape(image_bytes)\n    bbox = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])\n    image = _decode_and_random_crop(image_bytes, shape, bbox)\n    image = _flip(image)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = tf.clip_by_value(image, 0.0, 255.0)\n    image = tf.cast(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)\n    return image\n\n", "CodeBleu_score": 44.11080038640577}, {"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    shape = tf.io.extract_jpeg_shape(image_bytes)\n    bbox = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])\n    image = _decode_and_random_crop(image_bytes, shape, bbox)\n    image = _flip(image)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = tf.clip_by_value(image, 0.0, 255.0)\n    image = tf.cast(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)\n    return image\n\n", "CodeBleu_score": 44.11080038640577}, {"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    if use_bfloat16:\n        image = _decode_and_random_crop(image_bytes, image_size, interpolation)\n        image = tf.image.random_flip_left_right(image)\n        image = tf.reshape(image, [image_size, image_size, 3])\n        image = tf.cast(image, tf.bfloat16)\n        return image\n    else:\n        image = _decode_and_random_crop(image_bytes, image_size, interpolation)\n        image = _flip(image)\n        image = tf.reshape(image, [image_size, image_size, 3])\n        image = tf.cast(image, tf.float32)\n        return image\n\n", "CodeBleu_score": 55.24314308169078}]}
{"instance_id": "78b2a3bd2142", "generation_result": [{"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_center_crop(image_bytes, image_size, image_size, crop_padding=32)\n    image = tf.image.resize(image, [image_size, image_size], method=interpolation)\n    image = tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)\n    return image\n\n", "CodeBleu_score": 39.55814772125883}, {"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_center_crop(image_bytes, image_size, image_size, interpolation)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)\n    return image\n\n", "CodeBleu_score": 43.04666537938663}, {"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    shape = tf.io.extract_jpeg_shape(image_bytes)\n    crop_size = _smaller_size(shape[0], shape[1])\n    crop_offset = tf.cast(tf.floor((shape - crop_size) / 2), tf.int32)\n    crop_size = tf.cast(crop_size, tf.int32)\n    image = tf.image.decode_and_crop_jpeg(image_bytes, crop_size, crop_offset, channels=3)\n    image = tf.image.resize(image, [image_size, image_size], method=interpolation)\n    image = convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)\n    return image\n\n", "CodeBleu_score": 37.86949230994531}]}
{"instance_id": "8bd4364a9a0e", "generation_result": [{"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n    self.model = model\n    self.model.eval()\n    self.model.to(self.device)\n    self.eval_dataloader = eval_dataloader\n    self.eval_dataloader.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.eval_dataloader = eval_dataloader\n    self.eval_dataloader.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.eval_dataloader = eval_dataloader\n    self.eval_dataloader.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.eval_dataloader = eval_dataloader\n    self.eval_dataloader.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.eval_dataloader = eval_dataloader\n    self.eval_dataloader.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.eval_dataloader = eval_dataloader\n    self.eval_dataloader.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.eval_dataloader = eval_dataloader\n    self.eval_dataloader.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.eval_dataloader = eval_dataloader\n    self.eval_dataloader.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.eval_dataloader = eval_", "CodeBleu_score": 37.92603201541159}, {"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n    if output_file is None:\n        output_file = self.output_file\n\n    outputs = self.predict_loop(model, eval_dataloader)\n    self.compute_metrics(outputs, output_file)\n    return outputs\n\n", "CodeBleu_score": 55.20622956506458}, {"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n    self.model = model\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.to(self.device)\n    self.model.eval()\n    self.model.", "CodeBleu_score": 35.91810837472317}]}
{"instance_id": "22d682c958c0", "generation_result": [{"code": " def print_computed_metrics(self, metrics)\n\t\n    rank1 = metrics[\"rank1\"]\n    rank5 = metrics[\"rank5\"]\n    miou = metrics[\"miou\"]\n    print(\"Rank@1: {:.4f}\".format(rank1))\n    print(\"Rank@5: {:.4f}\".format(rank5))\n    print(\"mIoU: {:.4f}\".format(miou))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.29336163436595}, {"code": " def print_computed_metrics(self, metrics)\n\t\n    rank1 = metrics[\"rank1\"]\n    rank5 = metrics[\"rank5\"]\n    miou = metrics[\"miou\"]\n    print(f\"Rank-1: {rank1:.4f}\")\n    print(f\"Rank-5: {rank5:.4f}\")\n    print(f\"mIoU: {miou:.4f}\")\n\n", "CodeBleu_score": 32.892074809343555}, {"code": " def print_computed_metrics(self, metrics)\n\t\n    rank1 = metrics[\"rank1\"]\n    rank5 = metrics[\"rank5\"]\n    miou = metrics[\"miou\"]\n    print(\"Rank@1: {:.4f}\".format(rank1))\n    print(\"Rank@5: {:.4f}\".format(rank5))\n    print(\"mIoU: {:.4f}\".format(miou))", "CodeBleu_score": 37.29336163436595}]}
{"instance_id": "39c1a50b7e7d", "generation_result": [{"code": "def _eval_predictions(self, segments, data)\n\t\n    average_ranks = []\n    average_iou = []\n    for segment, datum in zip(segments, data):\n        (segment_start_frame, segment_end_frame, segment_label) = segment\n        (gt_start_frame, gt_end_frame, gt_label) = datum\n        if segment_label != gt_label:\n            continue\n        segment_frames = np.arange(segment_start_frame, segment_end_frame + 1)\n        gt_frames = np.arange(gt_start_frame, gt_end_frame + 1)\n        overlap_frames = np.intersect1d(segment_frames, gt_frames)\n        union_frames = np.union1d(segment_frames, gt_frames)\n        iou = len(overlap_frames) / len(union_frames)\n        average_iou.append(iou)\n        (rank, score) = self._rank(segment_frames, gt_frames)\n        average_ranks.append(rank)\n    average_iou = np.mean(average_iou)\n    average_ranks = np.mean(average_ranks)\n    rank1 = np.mean(np.array(average_ranks) == 1)\n    rank5 = np.mean(np.array(average_ranks) <= 5)\n    return (rank1, rank5, average_iou)\n\n", "CodeBleu_score": 34.82215072176695}, {"code": "def _eval_predictions(self, segments, data)\n\t\n    average_iou = []\n    average_ranks = []\n    for segment in segments:\n        ious = []\n        ranks = []\n        for dat in data:\n            iou = self._iou(segment, dat)\n            ious.append(iou)\n            ranks.append(self._rank(iou))\n        average_iou.append(np.mean(np.sort(ious)[-self._top_predictions:]))\n        average_ranks.append(np.mean(np.sort(ranks)[-self._top_predictions:]))\n    rank1 = 100.0 * len([a for a in average_ranks if a <= 1]) / len(average_ranks)\n    rank5 = 100.0 * len([a for a in average_ranks if a <= 5]) / len(average_ranks)\n    mean_iou = np.mean(average_iou)\n    return rank1, rank5, mean_iou\n\n", "CodeBleu_score": 38.815300483491676}, {"code": "def _eval_predictions(self, segments, data)\n\t\n    average_ranks = []\n    average_iou = []\n    for segment in segments:\n        rank = []\n        iou = []\n        for d in data:\n            iou.append(segment.iou(d))\n            rank.append(segment.rank(d))\n        rank = np.array(rank)\n        iou = np.array(iou)\n        average_ranks.append(np.sum(rank == 1) / float(len(rank)))\n        average_ranks.append(np.sum(rank == 5) / float(len(rank)))\n        average_iou.append(np.mean(iou))\n    average_ranks = np.array(average_ranks)\n    average_iou = np.array(average_iou)\n    rank1 = 100.0 * np.mean(average_ranks[0::2])\n    rank5 = 100.0 * np.mean(average_ranks[1::2])\n    iou = np.mean(average_iou)\n    return rank1, rank5, iou\n", "CodeBleu_score": 38.93574498865971}]}
{"instance_id": "8ccf84f8d034", "generation_result": [{"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    model.eval()\n    model.to(self.ctx)\n    for batch in eval_dataloader:\n        batch = {k: v.to(self.ctx) for k, v in batch.items()}\n        with torch.no_grad():\n            outputs = model(**batch)\n        outputs.update(batch)\n        scores.append(outputs)\n    results = self.finalize(scores)\n    if output_file is not None:\n        self.save_results(results, output_file)\n    return results\n\n\n", "CodeBleu_score": 43.99589469713385}, {"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    model.eval()\n    model.to(self.device)\n    for i, data in enumerate(eval_dataloader):\n        with torch.no_grad():\n            data = self.to_ctx(data)\n            outputs = model(**data)\n            outputs.update(data)\n        scores.append(outputs)\n    results = self.finalize(scores)\n    if output_file is not None:\n        self.save_results(results, output_file)\n    return results\n\n", "CodeBleu_score": 53.277868721620216}, {"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    model.eval()\n    model.to(self.device)\n    for data in eval_dataloader:\n        data = self.transfer_batch_to_device(data, self.device)\n        with torch.no_grad():\n            outputs = model(**data)\n        outputs.update(data)\n        scores.append(outputs)\n    results = self.process_outputs(outputs, output_file)\n    return results", "CodeBleu_score": 55.029088158221306}]}
{"instance_id": "e68529ad727d", "generation_result": [{"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    full_scores = np.concatenate(scores, axis=0)\n    self.full_scores = None\n    return np.matmul(full_scores[0], full_scores[1].T)\n\n", "CodeBleu_score": 37.24544593314904}, {"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    text_scores, video_scores = scores\n    full_scores = np.concatenate((text_scores, video_scores), axis=1)\n    self.full_scores = None\n    return np.matmul(text_scores, video_scores.T)\n\n", "CodeBleu_score": 40.155155673730206}, {"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    full_scores = np.concatenate(scores, axis=0)\n    self.full_scores = None\n    return np.matmul(full_scores[0], full_scores[1].T)", "CodeBleu_score": 37.24544593314904}]}
{"instance_id": "e4e1861fc357", "generation_result": [{"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    if Y_pred is None:\n        return {}\n    if isinstance(Y_pred, torch.Tensor):\n        Y_pred = Y_pred.detach().cpu().numpy()\n    if isinstance(Y_true, torch.Tensor):\n        Y_true = Y_true.detach().cpu().numpy()\n    if Y_pred.shape == ():\n        Y_pred = np.expand_dims(Y_pred, 0)\n    if Y_true.shape == ():\n        Y_true = np.expand_dims(Y_true, 0)\n    if Y_pred.ndim > 2:\n        Y_pred = Y_pred.reshape(Y_pred.shape[0], -1)\n    if Y_true.ndim > 2:\n        Y_true = Y_true.reshape(Y_true.shape[0], -1)\n    if Y_pred.shape != Y_true.shape:\n        raise ValueError(\n            \"Prediction and true labels have different shapes:\",\n            Y_pred.shape,\n            Y_true.shape,\n        )\n    Y_pred = np.concatenate(Y_pred, axis=0)\n    Y_true = np.concatenate(Y_true, axis=0)\n    if output_file is not None:\n        with open(output_file, \"wb\") as f:\n            pickle.dump({\"Y_pred\": Y_pred, \"Y_true\": Y_true}, f)\n    return {\"Y_pred\": Y_pred, \"Y_true\": Y_true}\n\n", "CodeBleu_score": 44.31697490007348}, {"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    Y_pred = torch.cat(Y_pred, dim=0)\n    Y_true = torch.cat(Y_true, dim=0)\n    Y_pred = Y_pred.cpu().numpy()\n    Y_true = Y_true.cpu().numpy()\n    print(Y_pred.shape)\n    print(Y_true.shape)\n    print(Y_pred[:10])\n    print(Y_true[:10])\n    print(len(Y_pred))\n    print(len(Y_true))\n    print(len(Y_pred) == len(Y_true))\n    print(Y_pred[:10] == Y_true[:10])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(Y_pred[0] == Y_true[0])\n    print(", "CodeBleu_score": 19.63671567543028}, {"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    Y_pred = torch.cat(Y_pred)\n    Y_true = torch.cat(Y_true)\n    Y_pred = Y_pred.cpu().numpy()\n    Y_true = Y_true.cpu().numpy()\n    if output_file is not None:\n        pickle.dump((Y_pred, Y_true), open(output_file, \"wb\"))\n    print(\"Prediction errors:\", np.sum(Y_pred != Y_true))\n    for i in range(10):\n        idx = np.random.randint(0, len(Y_pred))\n        print(\"Sample\", i, \"Predicted label:\", Y_pred[idx], \"True label:\", Y_true[idx])\n    return {\"Y_pred\": Y_pred, \"Y_true\": Y_true}", "CodeBleu_score": 39.458337876352275}]}
{"instance_id": "7df9ab9a4920", "generation_result": [{"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = sum(log.get(\"loss\", 0) for log in logging_outputs)\n    sample_size = sum(log.get(\"sample_size\", 0) for log in logging_outputs)\n\n    metrics.log_scalar(\n        \"loss\", loss_sum / sample_size, sample_size, round=3\n    )  # round=3 is the number of decimal places\n\n", "CodeBleu_score": 53.59470488041398}, {"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = sum(log.get('loss', 0) for log in logging_outputs)\n    sample_size = sum(log.get('sample_size', 0) for log in logging_outputs)\n    metrics.log_scalar('loss', loss_sum / sample_size, sample_size, round=3)\n\n", "CodeBleu_score": 52.7910982560264}, {"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = sum(log.get(\"loss\", 0) for log in logging_outputs)\n    sample_size = sum(log.get(\"sample_size\", 0) for log in logging_outputs)\n    metrics.log_scalar(\"loss\", loss_sum / sample_size, sample_size, round=3)\n\n", "CodeBleu_score": 62.429646714521894}]}
{"instance_id": "7f9c326a96f7", "generation_result": [{"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n    if attention_mask is None:\n        attention_mask = torch.zeros(\n            cmasks.size(0),\n            cmasks.size(1) + vmasks.size(1),\n            dtype=torch.long\n        )\n    if self._mm_attention_mask is None:\n        self._mm_attention_mask = torch.cat(\n            [\n                torch.zeros(cmasks.size(0), cmasks.size(1), dtype=torch.long),\n                torch.ones(cmasks.size(0), vmasks.size(1), dtype=torch.long)\n            ],\n            dim=1\n        )\n    return attention_mask, self._mm_attention_mask", "CodeBleu_score": 48.27618466908618}, {"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n    if attention_mask is None:\n        attention_mask = torch.zeros(\n            (cmasks.size(0), cmasks.size(1), cmasks.size(1)),\n            device=cmasks.device,\n            dtype=cmasks.dtype\n        )\n        attention_mask[:, :, :cmasks.size(1)] = cmasks\n        attention_mask[:, :, cmasks.size(1):] = vmasks\n    token_type_ids = torch.cat(\n        [\n            torch.zeros(cmasks.size(0), cmasks.size(1), dtype=cmasks.dtype, device=cmasks.device),\n            torch.ones(cmasks.size(0), vmasks.size(1), dtype=vmasks.device, device=vmasks.device)\n        ],\n        dim=1\n    )\n    return attention_mask, token_type_ids", "CodeBleu_score": 50.50470129942531}, {"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n    if attention_mask is None:\n        attention_mask = torch.zeros(\n            (cmasks.size(0), 1, 1, cmasks.size(-1) + vmasks.size(-1)),\n            dtype=torch.long,\n            device=cmasks.device,\n        )\n    token_type_ids = torch.cat(\n        [\n            torch.zeros(\n                (cmasks.size(0), cmasks.size(-1)), dtype=torch.long, device=cmasks.device\n            ),\n            torch.ones(\n                (cmasks.size(0), vmasks.size(-1)), dtype=torch.long, device=cmasks.device\n            ),\n        ],\n        dim=-1,\n    )\n    return attention_mask, token_type_ids\n\n", "CodeBleu_score": 57.047693054338}]}
{"instance_id": "fa99d2a148a5", "generation_result": [{"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n        # get the length of the input_ids\n        input_ids_length = input_ids.size()[1]\n\n        # get the length of the input_video_embeds\n        input_video_embeds_length = input_video_embeds.size()[1]\n\n        # adjust the sequence length to match the combined length of input_ids and input_video_embeds\n        sequence_length = input_ids_length + input_video_embeds_length\n        input_ids = input_ids[:, :sequence_length]\n        input_video_embeds = input_video_embeds[:, :sequence_length]\n\n        # modify the attention_mask and token_type_ids to fit the new sequence length\n        attention_mask = attention_mask[:, :sequence_length]\n        token_type_ids = token_type_ids[:, :sequence_length]\n\n        # return the updated input_ids, input_video_embeds, attention_mask, and token_type_ids\n        return {\n            \"input_ids\": input_ids,\n            \"input_video_embeds\": input_video_embeds,\n            \"attention_mask\": attention_mask,\n            \"token_type_ids\": token_type_ids,\n            **model_kwargs,\n        }\n\n\n", "CodeBleu_score": 43.07351288589237}, {"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n\n    # Adjust sequence length to match the combined length of input_ids and input_video_embeds\n    input_ids = input_ids[:, :self.config.max_position_embeddings - self.config.video_embed_dim]\n    input_video_embeds = input_video_embeds[:, :self.config.max_position_embeddings - self.config.text_config.hidden_size]\n\n    # Modify attention_mask and token_type_ids to fit the new sequence length\n    if attention_mask is not None:\n        attention_mask = attention_mask[:, :self.config.max_position_embeddings - self.config.video_embed_dim]\n    if token_type_ids is not None:\n        token_type_ids = token_type_ids[:, :self.config.max_position_embeddings - self.config.text_config.hidden_size]\n\n    # Return the updated inputs as a dictionary\n    return {\n        \"input_ids\": input_ids,\n        \"input_video_embeds\": input_video_embeds,\n        \"attention_mask\": attention_mask,\n        \"token_type_ids\": token_type_ids,\n        **model_kwargs\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 49.33130679699953}, {"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n    # adjust sequence length to match the combined length of input_ids and input_video_embeds\n    combined_length = input_ids.size(1) + input_video_embeds.size(1)\n    input_ids = input_ids[:, :combined_length]\n    attention_mask = attention_mask[:, :combined_length]\n    token_type_ids = token_type_ids[:, :combined_length]\n\n    # modify attention_mask and token_type_ids to fit the new sequence length\n    attention_mask = torch.cat([attention_mask, torch.zeros_like(input_video_embeds)], dim=1)\n    token_type_ids = torch.cat([token_type_ids, torch.ones_like(input_video_embeds)], dim=1)\n\n    # return the updated inputs\n    return {\n        \"input_ids\": input_ids,\n        \"input_video_embeds\": input_video_embeds,\n        \"attention_mask\": attention_mask,\n        \"token_type_ids\": token_type_ids,\n        **model_kwargs\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.26223961841246}]}
{"instance_id": "b1b0d25fe620", "generation_result": [{"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t\n    cfg.data.test.pipeline[1].meta_keys.remove('img_id')\n    transform_idx = self._get_transform_idx(cfg.data.test.pipeline, 'LoadImageFromFile')\n    cfg.data.test.pipeline[transform_idx].type = 'mmdet.InferencerLoader'\n    return Compose(cfg.data.test.pipeline)\n\n", "CodeBleu_score": 17.37477025570581}, {"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t\n    cfg = cfg.deepcopy()\n    if 'meta_keys' in cfg.data.test.pipeline[0]:\n        cfg.data.test.pipeline[0].meta_keys = tuple(\n            [key for key in cfg.data.test.pipeline[0].meta_keys if key != 'img_id'])\n    transform_idx = self._get_transform_idx(cfg, 'LoadImageFromFile')\n    if transform_idx == -1:\n        raise ValueError('LoadImageFromFile is not found in the pipeline.')\n    cfg.data.test.pipeline[transform_idx].type = 'mmdet.InferencerLoader'\n    return Compose(cfg.data.test.pipeline)\n\n", "CodeBleu_score": 45.346128434173586}, {"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t\n    # Adjust the pipeline config by removing the 'img_id' key from meta_keys\n    # if present.\n    if 'meta_keys' in cfg.data.test.pipeline[0]:\n        cfg.data.test.pipeline[0].meta_keys = tuple(\n            key for key in cfg.data.test.pipeline[0].meta_keys\n            if key != 'img_id')\n\n    # Find the index of the 'LoadImageFromFile' transform.\n    load_from_file_idx = find_transform_index(\n        cfg.data.test.pipeline, 'LoadImageFromFile')\n    if load_from_file_idx == -1:\n        raise ValueError('LoadImageFromFile transform not found in the '\n                         'pipeline.')\n\n    # Update the transform type to 'mmdet.InferencerLoader'.\n    cfg.data.test.pipeline[load_from_file_idx].type = 'mmdet.InferencerLoader'\n\n    # Return the modified pipeline config wrapped in a Compose object.\n    return Compose(cfg.data.test.pipeline)\n\n", "CodeBleu_score": 40.584091635029026}]}
{"instance_id": "7967962856eb", "generation_result": [{"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        if isdir(inputs):\n            inputs = list_dir_or_file(inputs, list_dir=False, list_file=True, recursive=True)\n        else:\n            inputs = [inputs]\n    elif not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n\n", "CodeBleu_score": 43.483016150328574}, {"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        if isdir(inputs):\n            inputs = list_dir_or_file(inputs)\n        else:\n            inputs = [inputs]\n    elif not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n\n", "CodeBleu_score": 37.27664845802001}, {"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        if isdir(inputs):\n            inputs = list_dir_or_file(inputs, list_dir=False, list_file=True, recursive=True, include_dir=False)\n        else:\n            inputs = [inputs]\n    elif not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n\n", "CodeBleu_score": 45.857867103253255}]}
{"instance_id": "74f727f06fa0", "generation_result": [{"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data = []\n    for input in inputs:\n        if isinstance(input, dict) and (\"img\" in input or \"img_path\" in input):\n            input = self.pipeline(input)\n        chunk_data.append(input)\n        if len(chunk_data) == chunk_size:\n            yield copy.deepcopy(chunk_data)\n            chunk_data.clear()\n    if chunk_data:\n        yield copy.deepcopy(chunk_data)\n\n", "CodeBleu_score": 24.11410507285547}, {"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data = []\n    for input in inputs:\n        if isinstance(input, dict):\n            if 'img' in input:\n                input = self.pipeline(input)\n            elif 'img_path' in input:\n                input = self.pipeline(copy.deepcopy(input))\n        chunk_data.append(input)\n        if len(chunk_data) == chunk_size:\n            yield chunk_data\n            chunk_data = []\n    if chunk_data:\n        yield chunk_data\n\n", "CodeBleu_score": 33.49768366952055}, {"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data = []\n    for input in inputs:\n        if isinstance(input, dict) and ('img' in input or 'img_path' in input):\n            input = self.pipeline(input)\n        chunk_data.append(input)\n        if len(chunk_data) == chunk_size:\n            yield copy.deepcopy(chunk_data)\n            chunk_data.clear()\n    if len(chunk_data) > 0:\n        yield copy.deepcopy(chunk_data)\n\n", "CodeBleu_score": 23.47477269695424}]}
{"instance_id": "a43ab51afa59", "generation_result": [{"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t\n\n    if not no_save_pred and pred_out_dir:\n        self.save_pred(preds, pred_out_dir)\n\n    results = []\n    if return_datasamples:\n        warnings.warn('Saving datasamples is not supported.')\n    else:\n        for pred in preds:\n            results.append(self.pred2dict(pred))\n\n    if visualization is not None:\n        results.append(visualization)\n\n    if print_result:\n        print(json.dumps(results))\n\n    return results", "CodeBleu_score": 41.80986499229714}, {"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t\n\n", "CodeBleu_score": 17.083333333333332}, {"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t\n\n    if not no_save_pred and pred_out_dir:\n        self.save_pred(preds, pred_out_dir, **kwargs)\n\n    results = []\n    if not return_datasamples:\n        preds = self.pred2dict(preds)\n        results.append(preds)\n\n    if pred_out_dir and return_datasamples:\n        warnings.warn('Saving datasamples is not supported')\n\n    if visualization is not None:\n        results.append(visualization)\n\n    if print_result:\n        print(results)\n\n    return results", "CodeBleu_score": 42.18975641330381}]}
{"instance_id": "a3c2561f199c", "generation_result": [{"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    test_pipeline = cfg.data.test.pipeline\n    test_pipeline[0] = cfg.data.test.pipeline[0].copy()\n    test_pipeline[0].transforms = [\n        t for t in test_pipeline[0].transforms if t.type != \"Normalize\"\n    ]\n    test_pipeline[-1] = cfg.data.test.pipeline[-1].copy()\n    test_pipeline[-1].transforms = [\n        t for t in test_pipeline[-1].transforms if t.type != \"RandomResizedCrop\"\n    ]\n    test_pipeline = Compose(test_pipeline)\n    return test_pipeline\n\n", "CodeBleu_score": 33.65048468502696}, {"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    test_pipeline = cfg.dataset.pipeline\n    test_pipeline[0] = copy(test_pipeline[0])\n    test_pipeline[0].transforms = [\n        transform\n        for transform in test_pipeline[0].transforms\n        if transform.type == \"Resize\"\n    ]\n    test_pipeline[-1] = copy(test_pipeline[-1])\n    test_pipeline = Compose(test_pipeline)\n    return test_pipeline\n\n", "CodeBleu_score": 27.93514314847266}, {"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    test_pipeline = cfg.data.test.pipeline\n    test_pipeline[0] = cfg.data.test.pipeline[0].copy()\n    test_pipeline[0].transforms[0] = cfg.data.test.pipeline[0].transforms[0].copy()\n    test_pipeline[0].transforms[0].type = 'Resize'\n    test_pipeline[1] = cfg.data.test.pipeline[1].copy()\n    test_pipeline[1].type = 'PackDetInputs'\n    return test_pipeline\n\n", "CodeBleu_score": 29.777623245525465}]}
{"instance_id": "48a358ab5a38", "generation_result": [{"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n\n    # Prepare input data\n    data = dict(\n        img=img,\n        frame_id=frame_id,\n        img_shape=img.shape,\n        ori_shape=img.shape,\n        img_id=frame_id,\n        img_path=None,\n        video_len=video_len)\n\n    # Build test pipeline\n    test_pipeline = build_test_pipeline(model.cfg)\n\n    # Process data through test pipeline\n    data = test_pipeline(data)\n\n    # Convert data to tensor\n    data = collate([data], samples_per_gpu=1)\n\n    # Move data to GPU if available\n    if next(model.parameters()).is_cuda:\n        data = scatter(data, [torch.cuda.current_device()])[0]\n\n    # Ensure no unsupported modules are used\n    if not isinstance(model, nn.ModuleList) and not torch.cuda.is_available():\n        for m in model.modules():\n            assert not isinstance(\n                m, RoIPool\n            ), 'CPU inference with RoIPool is not supported currently.'\n\n    # Perform forward pass\n    with torch.no_grad():\n        result = model.test_step(data, rescale=True)\n\n    return result\n\n", "CodeBleu_score": 56.43940800649463}, {"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    cfg = model.cfg\n    device = next(model.parameters()).device  # model device\n    # prepare data\n    data = dict(img=img, frame_id=frame_id, img_shape=img.shape,\n                ori_shape=img.shape, img_id=frame_id, img_path=None,\n                video_len=video_len)\n    # build the data pipeline\n    test_pipeline = build_test_pipeline(cfg.data.test)\n    data = test_pipeline(data)\n    data = collate([data], samples_per_gpu=1)\n    if next(model.parameters()).is_cuda:\n        # scatter to specified GPU\n        data = scatter(data, [device])[0]\n    else:\n        for m in model.modules():\n            assert not isinstance(\n                m, RoIPool\n            ), 'CPU inference with RoIPool is not supported currently.'\n\n    # forward the model\n    with torch.no_grad():\n        result = model.test_step(data, rescale=True)\n    return result\n\n\n", "CodeBleu_score": 52.51431325091917}, {"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    data = dict(img=img, frame_id=frame_id, img_shape=img.shape,\n                img_id=np.array([0]), ori_shape=img.shape,\n                img_fields=['img'], video_len=video_len)\n    data = model.test_pipeline(data)\n    data = collate([data], samples_per_gpu=1)\n    if next(model.parameters()).is_cuda:\n        # scatter to specified GPU\n        data = scatter(data, [device])[0]\n    else:\n        # this is a workaround to avoid the bug of MMDataParallel\n        data['img_metas'] = data['img_metas'][0].data\n        data['img'] = data['img'][0].data\n    # forward the model\n    with torch.no_grad():\n        for module in model.modules():\n            if isinstance(module, RPNHead):\n                outputs = module.simple_test_rpn(**data)\n            elif isinstance(module, RoIHead):\n                bbox_results = module.simple_test_bboxes(**data,\n                                                          rescale=True)\n                outputs = bbox_results[0]\n            else:\n                continue\n    return outputs\n\n", "CodeBleu_score": 36.76166161772627}]}
{"instance_id": "6c4ea2ce1787", "generation_result": [{"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            trunc_tokens.pop()\n        else:\n            trunc_tokens.pop(0)\n\n", "CodeBleu_score": 69.25823085150212}, {"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            trunc_tokens.pop()\n        else:\n            trunc_tokens.pop(0)\n\n", "CodeBleu_score": 69.25823085150212}, {"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            del trunc_tokens[0]\n        else:\n            trunc_tokens.pop()\n\n", "CodeBleu_score": 76.28687604964396}]}
{"instance_id": "007181b6729d", "generation_result": [{"code": "def get_activation(activation_string)\n\t\n    if isinstance(activation_string, str):\n        if activation_string.lower() == 'linear':\n            return None\n        elif activation_string.lower() == 'relu':\n            return tf.keras.layers.ReLU()\n        elif activation_string.lower() == 'sigmoid':\n            return tf.keras.layers.Activation('sigmoid')\n        elif activation_string.lower() == 'softmax':\n            return tf.keras.layers.Softmax()\n        else:\n            raise ValueError(f\"Unsupported activation: {activation_string}\")\n    else:\n        return activation_string", "CodeBleu_score": 22.65720226886631}, {"code": "def get_activation(activation_string)\n\t\n    if not isinstance(activation_string, str):\n        return activation_string\n    if activation_string == '':\n        return None\n    if activation_string.lower() == 'relu':\n        return tf.nn.relu\n    if activation_string.lower() == 'leaky_relu':\n        return tf.nn.leaky_relu\n    if activation_string.lower() == 'tanh':\n        return tf.nn.tanh\n    if activation_string.lower() == 'sigmoid':\n        return tf.nn.sigmoid\n    if activation_string.lower() == 'softmax':\n        return tf.nn.softmax\n    if activation_string.lower() == 'linear':\n        return None\n    raise ValueError('Activation function not supported: {}'.format(activation_string))", "CodeBleu_score": 37.32173844269106}, {"code": "def get_activation(activation_string)\n\t\n    if not isinstance(activation_string, str):\n        return activation_string\n    elif not activation_string:\n        return None\n    elif activation_string.lower() == \"linear\":\n        return linear\n    elif activation_string.lower() == \"relu\":\n        return relu\n    elif activation_string.lower() == \"sigmoid\":\n        return sigmoid\n    elif activation_string.lower() == \"tanh\":\n        return tanh\n    else:\n        raise ValueError(\n            f\"Activation function '{activation_string}' not supported. Please choose from: linear, relu, sigmoid, tanh\"\n        )\n\n", "CodeBleu_score": 35.43053744658587}]}
{"instance_id": "d5d6e0315899", "generation_result": [{"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n    else:\n        return tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n\n", "CodeBleu_score": 60.84090845772291}, {"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n    else:\n        return tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n\n\n\n", "CodeBleu_score": 60.84090845772291}, {"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n    return tf.nn.dropout(input_tensor, 1.0 - dropout_prob)", "CodeBleu_score": 60.78403505639335}]}
{"instance_id": "828917b9ac53", "generation_result": [{"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n\n    to_shape = get_shape_list(to_mask, expected_rank=2)\n    to_seq_length = to_shape[1]\n\n    to_mask = tf.cast(\n        tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32\n    )\n\n    broadcast_ones = tf.ones(\n        shape=[batch_size, from_seq_length, 1], dtype=tf.float32\n    )\n    mask = broadcast_ones * to_mask\n\n    return mask", "CodeBleu_score": 59.90976989090129}, {"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n\n    to_shape = get_shape_list(to_mask, expected_rank=2)\n    to_seq_length = to_shape[1]\n\n    to_mask = tf.cast(\n        tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32\n    )\n\n    broadcast_ones = tf.ones(\n        shape=[batch_size, from_seq_length, 1], dtype=tf.float32\n    )\n    mask = broadcast_ones * to_mask\n\n    return mask\n\n", "CodeBleu_score": 59.90976989090129}, {"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n\n    to_shape = get_shape_list(to_mask, expected_rank=2)\n    to_seq_length = to_shape[1]\n\n    to_mask = tf.cast(\n        tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n\n    # broadcast from_mask to larger size mask matrix with extra\n    # dims of size 1.\n    broadcast_ones = tf.ones(\n        shape=[batch_size, from_seq_length, 1], dtype=tf.float32)\n    mask = broadcast_ones * to_mask\n\n    return mask\n\n", "CodeBleu_score": 64.38636645230761}]}
{"instance_id": "d7798e41a723", "generation_result": [{"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    output_tensor = tf.reshape(\n        input_tensor, [batch_size, seq_length, num_attention_heads, width])\n\n    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n    return output_tensor\n\n", "CodeBleu_score": 59.99845781533536}, {"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    output_tensor = tf.reshape(\n        input_tensor, [batch_size, seq_length, num_attention_heads, width])\n\n    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n    return output_tensor", "CodeBleu_score": 59.99845781533536}, {"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    output_tensor = tf.reshape(\n        input_tensor, [batch_size, seq_length, num_attention_heads, width])\n\n    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n    return output_tensor\n\n", "CodeBleu_score": 59.99845781533536}]}
{"instance_id": "711d466ace09", "generation_result": [{"code": "def reshape_to_matrix(input_tensor)\n\t\n    if input_tensor.shape.ndims is not None:\n        if input_tensor.shape.ndims < 2:\n            raise ValueError('Input tensor must have at least 2 dimensions, but saw: %s' % input_tensor.shape.ndims)\n        if input_tensor.shape.ndims == 2:\n            return input_tensor\n        width = input_tensor.shape[-1]\n        output_tensor = tf.reshape(input_tensor, [-1, width])\n        return output_tensor\n    else:\n        raise ValueError('Rank of input_tensor must be known')", "CodeBleu_score": 58.49779734203244}, {"code": "def reshape_to_matrix(input_tensor)\n\t\n    if input_tensor.shape.ndims is not None:\n        if input_tensor.shape.ndims < 2:\n            raise ValueError(\"The input tensor should have at least rank 2. Shape = %s\" % input_tensor.shape)\n        if input_tensor.shape.ndims == 2:\n            return input_tensor\n    return tf.reshape(input_tensor, [-1, input_tensor.shape[-1].value])\n\n", "CodeBleu_score": 41.03438234644538}, {"code": "def reshape_to_matrix(input_tensor)\n\t\n    if input_tensor.shape.ndims < 2:\n        raise ValueError(\"The input tensor should have at least rank 2, but got rank %d\" % input_tensor.shape.ndims)\n    if input_tensor.shape.ndims == 2:\n        return input_tensor\n    width = input_tensor.shape[-1]\n    output_tensor = tf.reshape(input_tensor, [-1, width])\n    return output_tensor\n\n", "CodeBleu_score": 63.413321512202245}]}
{"instance_id": "7adcd08f531e", "generation_result": [{"code": "def get_train_examples(self, data_dir)\n\t\n    return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n", "CodeBleu_score": 5.998047197537955}, {"code": "def get_train_examples(self, data_dir)\n\t\n    return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n", "CodeBleu_score": 5.998047197537955}, {"code": "def get_train_examples(self, data_dir)\n\t\n    return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n\n", "CodeBleu_score": 5.998047197537955}]}
{"instance_id": "26a0bb96dab9", "generation_result": [{"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    predictions = tf.argmax(logits, axis=-1)\n    accuracy = tf.metrics.accuracy(\n        labels=label_ids, predictions=predictions, weights=is_real_example)\n    mean_loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n    return {\n        \"eval_accuracy\": accuracy,\n        \"eval_loss\": mean_loss,\n    }\n\n", "CodeBleu_score": 50.456802985927304}, {"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    predictions = tf.argmax(logits, axis=-1)\n    accuracy = tf.metrics.accuracy(\n        labels=label_ids, predictions=predictions, weights=is_real_example)\n    mean_loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n    return {\n        \"eval_accuracy\": accuracy,\n        \"eval_loss\": mean_loss,\n    }\n\n", "CodeBleu_score": 50.456802985927304}, {"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    predictions = tf.argmax(logits, axis=-1)\n    accuracy = tf.metrics.accuracy(\n        labels=label_ids, predictions=predictions, weights=is_real_example)\n    mean_loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n    return {\n        \"eval_accuracy\": accuracy,\n        \"eval_loss\": mean_loss,\n    }\n\n\n\n", "CodeBleu_score": 50.456802985927304}]}
{"instance_id": "6154e4d28509", "generation_result": [{"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t\n    features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            logger.info('Writing example %d of %d' % (ex_index, len(examples)))\n        feature = convert_single_example(ex_index, example, label_list,\n                                         max_seq_length, tokenizer)\n        features.append(feature)\n    return features\n\n", "CodeBleu_score": 71.37350986795673}, {"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t\n    features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        feature = convert_single_example(ex_index, example, label_list,\n                                         max_seq_length, tokenizer)\n        features.append(feature)\n    return features\n\n", "CodeBleu_score": 73.75375987448578}, {"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t\n    features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        features.append(convert_single_example(ex_index, example, label_list,\n                                               max_seq_length, tokenizer))\n    return features\n\n", "CodeBleu_score": 65.08538860765421}]}
{"instance_id": "e09c0db71ebb", "generation_result": [{"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    with tf.variable_scope(\"cls/seq_relationship\"):\n        output_weights = tf.get_variable(\n            \"output_weights\",\n            shape=[2, bert_config.hidden_size],\n            initializer=tf.truncated_normal_initializer(stddev=bert_config.initializer_range))\n\n        output_bias = tf.get_variable(\n            \"output_bias\", shape=[2], initializer=tf.zeros_initializer())\n\n        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n        logits = tf.nn.bias_add(logits, output_bias)\n        log_probs = tf.nn.log_softmax(logits, axis=-1)\n\n        labels = tf.reshape(labels, [-1])\n        one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n\n        per_example_loss = -tf.reduce_sum(log_probs * one_hot_labels, axis=-1)\n        loss = tf.reduce_mean(per_example_loss)\n\n        return (loss, per_example_loss, log_probs)\n\n\n", "CodeBleu_score": 80.69486461123924}, {"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    with tf.variable_scope(\"cls/seq_relationship\"):\n        output_weights = tf.get_variable(\n            \"output_weights\",\n            shape=[2, bert_config.hidden_size],\n            initializer=modeling.create_initializer(bert_config.initializer_range))\n        output_bias = tf.get_variable(\n            \"output_bias\", shape=[2], initializer=tf.zeros_initializer())\n\n        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n        logits = tf.nn.bias_add(logits, output_bias)\n        log_probs = tf.nn.log_softmax(logits, axis=-1)\n\n        labels = tf.reshape(labels, [-1])\n        one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n\n        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n        loss = tf.reduce_mean(per_example_loss)\n\n        return loss, per_example_loss, log_probs\n\n", "CodeBleu_score": 84.97588967239635}, {"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    output_weights = tf.get_variable(\n        \"output_weights\", [bert_config.hidden_size, 2],\n        initializer=tf.truncated_normal_initializer(stddev=0.02))\n\n    output_bias = tf.get_variable(\n        \"output_bias\", [2], initializer=tf.zeros_initializer())\n\n    logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n    logits = tf.nn.bias_add(logits, output_bias)\n    log_probs = tf.nn.log_softmax(logits, axis=-1)\n\n    labels = tf.reshape(labels, [-1])\n    one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n\n    per_example_loss = -tf.reduce_sum(log_probs * one_hot_labels, axis=-1)\n    loss = tf.reduce_mean(per_example_loss)\n\n    return (loss, per_example_loss, log_probs)\n\n", "CodeBleu_score": 47.585726577548854}]}
{"instance_id": "1f66b020f485", "generation_result": [{"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n\n    batch_size = sequence_shape[0]\n    seq_length = sequence_shape[1]\n    width = sequence_shape[2]\n\n    flat_offsets = tf.reshape(\n        tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1]\n    )\n    flat_positions = tf.reshape(positions + flat_offsets, [-1])\n    flat_sequence_tensor = tf.reshape(sequence_tensor, [batch_size * seq_length, width])\n    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 56.34905172926283}, {"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n    batch_size = sequence_shape[0]\n    seq_length = sequence_shape[1]\n    width = sequence_shape[2]\n\n    flat_offsets = tf.reshape(\n        tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1]\n    )\n    flat_positions = tf.reshape(positions + flat_offsets, [-1])\n    flat_sequence_tensor = tf.reshape(sequence_tensor, [batch_size * seq_length, width])\n    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 56.34905172926283}, {"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n    batch_size = sequence_shape[0]\n    seq_length = sequence_shape[1]\n    width = sequence_shape[2]\n\n    flat_offsets = tf.reshape(\n        tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])\n    flat_positions = tf.reshape(positions + flat_offsets, [-1])\n    flat_sequence_tensor = tf.reshape(sequence_tensor,\n                                      [batch_size * seq_length, width])\n    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 57.853066637478335}]}
{"instance_id": "956bffee9a33", "generation_result": [{"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.parse_single_example(record, name_to_features)\n\n    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n    # So cast all int64 to int32.\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.to_int32(t)\n        example[name] = t\n\n    return example\n\n", "CodeBleu_score": 70.13047524425508}, {"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.parse_single_example(record, name_to_features)\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.to_int32(t)\n        example[name] = t\n    return example", "CodeBleu_score": 70.13047524425508}, {"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.parse_single_example(record, name_to_features)\n\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.to_int32(t)\n        example[name] = t\n    return example\n\n", "CodeBleu_score": 70.13047524425508}]}
{"instance_id": "6b97f354e641", "generation_result": [{"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    tok_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(input_end, new_start - 1, -1):\n            text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n            if text_span == tok_text:\n                return (new_start, new_end)\n\n    return (input_start, input_end)\n\n", "CodeBleu_score": 77.69943317883904}, {"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(input_end, new_start - 1, -1):\n            text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n            if text_span == tok_answer_text:\n                return (new_start, new_end)\n\n    return (input_start, input_end)\n\n", "CodeBleu_score": 80.32238626031224}, {"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(input_end, new_start - 1, -1):\n            text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n            if text_span == tok_answer_text:\n                return (new_start, new_end)\n\n    return (input_start, input_end)\n\n", "CodeBleu_score": 80.32238626031224}]}
{"instance_id": "aba334b92b34", "generation_result": [{"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = None\n    best_span_index = None\n    for (span_index, doc_span) in enumerate(doc_spans):\n        end = doc_span.start + doc_span.length - 1\n        if position < doc_span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - doc_span.start\n        num_right_context = end - position\n        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n        if best_score is None or score > best_score:\n            best_score = score\n            best_span_index = span_index\n    return cur_span_index == best_span_index\n\n", "CodeBleu_score": 78.23889503357583}, {"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = None\n    best_span_index = None\n    for (span_index, doc_span) in enumerate(doc_spans):\n        end = doc_span.start + doc_span.length - 1\n        if position < doc_span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - doc_span.start\n        num_right_context = end - position\n        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n        if best_score is None or score > best_score:\n            best_score = score\n            best_span_index = span_index\n    return cur_span_index == best_span_index\n\n", "CodeBleu_score": 78.23889503357583}, {"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = None\n    best_span_index = None\n    for (span_index, doc_span) in enumerate(doc_spans):\n        end = doc_span.start + doc_span.length - 1\n        if position < doc_span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - doc_span.start\n        num_right_context = end - position\n        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n        if best_score is None or score > best_score:\n            best_score = score\n            best_span_index = span_index\n    return cur_span_index == best_span_index\n\n", "CodeBleu_score": 78.23889503357583}]}
{"instance_id": "cf92ad509f6a", "generation_result": [{"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n        while True:\n            token = convert_to_unicode(reader.readline())\n            if not token:\n                break\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 66.58135914758769}, {"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n        while True:\n            token = convert_to_unicode(reader.readline())\n            if not token:\n                break\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 66.58135914758769}, {"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n        while True:\n            token = convert_to_unicode(reader.readline())\n            if not token:\n                break\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 66.58135914758769}]}
{"instance_id": "6c865803ac12", "generation_result": [{"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output", "CodeBleu_score": 79.63749907165396}, {"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n", "CodeBleu_score": 79.63749907165396}, {"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n", "CodeBleu_score": 79.63749907165396}]}
{"instance_id": "e93b9200dc4a", "generation_result": [{"code": "def tokenize(self, text)\n\t\n    split_tokens = []\n    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n        for sub_token in self.wordpiece_tokenizer.tokenize(token):\n            split_tokens.append(sub_token)\n    return split_tokens\n\n", "CodeBleu_score": 64.56859574727434}, {"code": "def tokenize(self, text)\n\t\n    split_tokens = []\n    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n        for sub_token in self.wordpiece_tokenizer.tokenize(token):\n            split_tokens.append(sub_token)\n    return split_tokens\n\n", "CodeBleu_score": 64.56859574727434}, {"code": "def tokenize(self, text)\n\t\n    split_tokens = []\n    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n\n        for sub_token in self.wordpiece_tokenizer.tokenize(token):\n            split_tokens.append(sub_token)\n    return split_tokens", "CodeBleu_score": 64.56859574727434}]}
{"instance_id": "2ff6f6db53c9", "generation_result": [{"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        logger.info(f\"Loading {path}\")\n        audio_data, _ = librosa.load(\n            path,\n            offset=offset,\n            duration=duration,\n            sr=sample_rate,\n            dtype=dtype,\n        )\n        return audio_data, False\n    except Exception as e:\n        logger.exception(f\"Error loading {path}: {e}\")\n        return -1.0, True\n\n", "CodeBleu_score": 37.43405553429559}, {"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        audio_data, _ = librosa.load(path=path,\n                                     offset=offset,\n                                     duration=duration,\n                                     sr=sample_rate,\n                                     dtype=dtype)\n        return audio_data, False\n    except Exception as e:\n        logger.exception(e)\n        return -1.0, True\n\n", "CodeBleu_score": 34.5243975286938}, {"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        logger.info(f\"Loading {path}\")\n        audio_data, _ = librosa.load(\n            path,\n            offset=offset,\n            duration=duration,\n            sr=sample_rate,\n            dtype=dtype,\n        )\n        return audio_data, False\n    except Exception as e:\n        logger.exception(f\"Error loading {path}\")\n        return -1.0, True\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.29565621126648}]}
{"instance_id": "12fbe1f03d8f", "generation_result": [{"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    # Get the number of channels in the waveform\n    num_channels = waveform.shape[-1]\n\n    # If the waveform has more or equal channels, trim to the desired number\n    if num_channels >= n_channels:\n        waveform = waveform[:, :n_channels]\n    # If the waveform has fewer channels, tile it to increase the channels and then trim it\n    else:\n        waveform = tf.tile(waveform, [1, n_channels // num_channels + 1])[:, :n_channels]\n\n    return waveform\n\n", "CodeBleu_score": 46.58566756338851}, {"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    n_channels_waveform = waveform.shape[-1]\n    if n_channels_waveform > n_channels:\n        waveform = waveform[..., :n_channels]\n    elif n_channels_waveform < n_channels:\n        waveform = tf.tile(waveform, tf.concat([tf.ones(len(waveform.shape[:-1]), tf.int32), [n_channels]], 0))\n        waveform = waveform[..., :n_channels]\n    return waveform\n\n", "CodeBleu_score": 44.81788082768317}, {"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    waveform_shape = tf.shape(waveform)\n    waveform_channels = waveform_shape[-1]\n    if waveform_channels < n_channels:\n        waveform = tf.tile(waveform, [1, n_channels // waveform_channels])\n    waveform = waveform[:, :n_channels]\n    return waveform\n\n", "CodeBleu_score": 47.39075359841984}]}
{"instance_id": "5e215f029b2e", "generation_result": [{"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    # Convert spectrogram to dB\n    db_spectrogram = gain_to_db(spectrogram, **kwargs)\n\n    # Find the maximum dB value\n    max_db = tf.reduce_max(db_spectrogram)\n\n    # Clip the dB spectrogram to a specified range below the maximum\n    clipped_db_spectrogram = tf.maximum(db_spectrogram, max_db - db_range)\n\n    # Convert the clipped dB spectrogram to uint8 format\n    db_uint_spectrogram = from_float32_to_uint8(clipped_db_spectrogram)\n\n    return db_uint_spectrogram", "CodeBleu_score": 48.35168501929673}, {"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    db_spectrogram = gain_to_db(spectrogram, **kwargs)\n    db_spectrogram_max = tf.reduce_max(db_spectrogram)\n    db_spectrogram_clipped = tf.maximum(db_spectrogram, db_spectrogram_max - db_range)\n    db_spectrogram_uint8 = from_float32_to_uint8(db_spectrogram_clipped)\n    return db_spectrogram_uint8", "CodeBleu_score": 47.162650631212806}, {"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    db_spectrogram = gain_to_db(spectrogram, **kwargs)\n    max_db = tf.reduce_max(db_spectrogram)\n    clipped_db_spectrogram = tf.maximum(db_spectrogram, max_db - db_range)\n    db_uint_spectrogram = from_float32_to_uint8(clipped_db_spectrogram)\n    return db_uint_spectrogram", "CodeBleu_score": 48.35168501929673}]}
{"instance_id": "b65c0968dae7", "generation_result": [{"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n\n    # Apply the Hann window function raised to a specified exponent\n    window = tf.signal.hann_window(frame_length, periodic=True) ** window_exponent\n\n    # Perform the STFT with defined frame length and step\n    stfts = tf.signal.stft(\n        waveform,\n        frame_length=frame_length,\n        frame_step=frame_step,\n        fft_length=frame_length,\n        window_fn=window,\n        pad_end=True,\n    )\n\n    # Transpose the resulting tensor\n    spectrograms = tf.transpose(tf.abs(stfts) ** spec_exponent, [0, 2, 1])\n\n    return spectrograms\n\n", "CodeBleu_score": 40.79411225715992}, {"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n\n    # Apply a Hann window raised to a specified exponent\n    window = hann_window(frame_length, periodic=True) ** window_exponent\n\n    # Perform the STFT with defined frame length and step\n    stft = tf.signal.stft(\n        waveform,\n        frame_length=frame_length,\n        frame_step=frame_step,\n        fft_length=frame_length,\n        window_fn=window,\n        pad_end=True,\n    )\n\n    # Transpose the spectrogram tensor\n    spectrogram = tf.transpose(tf.abs(stft) ** spec_exponent, [1, 2, 0])\n\n    return spectrogram", "CodeBleu_score": 40.2124427837626}, {"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n    stft = tf.signal.stft(\n        waveform,\n        frame_length=frame_length,\n        frame_step=frame_step,\n        fft_length=frame_length,\n        window_fn=tf.signal.hann_window,\n    )\n    spectrogram = tf.transpose(tf.abs(stft) ** spec_exponent)\n    return spectrogram\n\n", "CodeBleu_score": 35.15757347721324}]}
{"instance_id": "a4686140a634", "generation_result": [{"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n\n    # Get the original shape of the spectrogram\n    original_shape = tf.shape(spectrogram)\n\n    # Calculate the new time dimension by scaling the original time dimension by the factor\n    new_time_dim = tf.cast(\n        tf.cast(original_shape[1], tf.float32) * factor, tf.int32\n    )\n\n    # Resize the spectrogram using the specified interpolation method\n    resized_spectrogram = tf.image.resize(\n        spectrogram, [original_shape[0], new_time_dim], method=method\n    )\n\n    # Adjust the resized spectrogram to the original dimensions by cropping or padding\n    if factor > 1.0:\n        # If the factor is greater than 1.0, crop the spectrogram\n        cropped_spectrogram = resized_spectrogram[\n            :, :original_shape[1]\n        ]\n        return cropped_spectrogram\n    elif factor < 1.0:\n        # If the factor is less than 1.0, pad the spectrogram\n        padded_spectrogram = tf.image.resize_with_crop_or_pad(\n            resized_spectrogram,\n            target_height=original_shape[0],\n            target_width=original_shape[1],\n        )\n        return padded_spectrogram\n    else:\n        # If the factor is equal to 1.0, return the original spectrogram\n        return spectrogram", "CodeBleu_score": 36.918471747790015}, {"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Get the original shape of the spectrogram\n    original_shape = tf.shape(spectrogram)\n    # Calculate the new time dimension\n    new_time_dim = tf.cast(tf.cast(original_shape[1], tf.float32) / factor, tf.int32)\n    # Resize the spectrogram using the specified interpolation method\n    resized_spectrogram = tf.image.resize(\n        spectrogram, [original_shape[0], new_time_dim], method=method\n    )\n    # Adjust the resized spectrogram to the original dimensions\n    if new_time_dim < original_shape[1]:\n        # Crop the resized spectrogram to the original time dimension\n        adjusted_spectrogram = resized_spectrogram[:, : original_shape[1]]\n    else:\n        # Pad the resized spectrogram to the original time dimension\n        padding = tf.zeros([original_shape[0], new_time_dim - original_shape[1]])\n        adjusted_spectrogram = tf.concat([resized_spectrogram, padding], axis=1)\n    # Return the adjusted spectrogram\n    return adjusted_spectrogram\n\n", "CodeBleu_score": 39.38932498475944}, {"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Get the original shape of the spectrogram\n    original_shape = tf.shape(spectrogram)\n\n    # Calculate the new time dimension\n    new_time_dim = tf.cast(\n        tf.cast(original_shape[1], tf.float32) * factor, tf.int32\n    )\n\n    # Resize the spectrogram using the specified interpolation method\n    resized_spectrogram = tf.image.resize(\n        spectrogram, [original_shape[0], new_time_dim], method=method\n    )\n\n    # Adjust the resized spectrogram to the original dimensions by cropping or padding\n    if factor > 1.0:\n        # Crop the resized spectrogram to the original dimensions\n        adjusted_spectrogram = tf.image.resize_with_crop_or_pad(\n            resized_spectrogram, original_shape[0], original_shape[1]\n        )\n    else:\n        # Pad the resized spectrogram to the original dimensions\n        adjusted_spectrogram = tf.image.resize_with_crop_or_pad(\n            resized_spectrogram, original_shape[0], new_time_dim\n        )\n\n    # Return the adjusted spectrogram\n    return adjusted_spectrogram\n\n", "CodeBleu_score": 36.254162999622494}]}
{"instance_id": "6dd01101d4ae", "generation_result": [{"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Calculate the resizing factor based on the semitone shift\n    factor = 2 ** (semitone_shift / 12)\n\n    # Resize the spectrogram along the frequency axis\n    resized_spectrogram = tf.image.resize(\n        spectrogram, [int(spectrogram.shape[1] * factor), spectrogram.shape[2]], method=method\n    )\n\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        [\n            [\n                (spectrogram.shape[1] - resized_spectrogram.shape[1]) // 2,\n                (spectrogram.shape[1] - resized_spectrogram.shape[1]) // 2,\n            ],\n            [0, 0],\n            [0, 0],\n        ],\n    )\n\n    # Crop the padded spectrogram to the original dimensions\n    padded_spectrogram = tf.image.resize_with_crop_or_pad(\n        padded_spectrogram, spectrogram.shape[1], spectrogram.shape[2]\n    )\n\n    # Return the pitch-shifted spectrogram\n    return padded_spectrogram\n\n", "CodeBleu_score": 26.739541241307457}, {"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Calculate the resizing factor based on the semitone shift\n    factor = 2.0 ** (semitone_shift / 12.0)\n    # Resize the spectrogram along the frequency axis\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        [tf.shape(spectrogram)[1], int(tf.shape(spectrogram)[2] * factor)],\n        method=method,\n    )\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        [\n            [0, 0],\n            [0, tf.maximum(0, tf.shape(spectrogram)[2] - tf.shape(resized_spectrogram)[2])],\n            [0, 0],\n        ],\n    )\n    # Return the pitch-shifted spectrogram\n    return tf.cast(padded_spectrogram, spectrogram.dtype)\n\n", "CodeBleu_score": 33.01309546142774}, {"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n\n    # Calculate the resizing factor based on the semitone shift\n    factor = 2 ** (semitone_shift / 12)\n\n    # Resize the spectrogram along the frequency axis using the specified method\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        [int(spectrogram.shape[1] * factor), spectrogram.shape[2]],\n        method=method,\n    )\n\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        [\n            [\n                (spectrogram.shape[1] - resized_spectrogram.shape[1]) // 2,\n                (spectrogram.shape[1] - resized_spectrogram.shape[1]) // 2,\n            ],\n            [0, 0],\n        ],\n    )\n\n    # Return the pitch-shifted spectrogram\n    return padded_spectrogram\n\n", "CodeBleu_score": 27.144288625002673}]}
{"instance_id": "612f0826e56a", "generation_result": [{"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    conv_activation = params.get(\"conv_activation\", \"ReLU\")\n    if conv_activation == \"ReLU\":\n        return nn.ReLU()\n    elif conv_activation == \"ELU\":\n        return nn.ELU()\n    elif conv_activation == \"LeakyReLU\":\n        return nn.LeakyReLU(0.2)\n    else:\n        raise ValueError(\n            f\"Unsupported conv_activation value: {conv_activation}. Supported values are: ReLU, ELU, LeakyReLU.\"\n        )\n\n", "CodeBleu_score": 43.245821361591126}, {"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    conv_activation = params.get(\"conv_activation\", \"ReLU\")\n    if conv_activation == \"ReLU\":\n        return ReLU()\n    elif conv_activation == \"ELU\":\n        return ELU()\n    elif conv_activation == \"LeakyReLU\":\n        return LeakyReLU(negative_slope=0.2)\n    else:\n        raise ValueError(f\"Unknown activation: {conv_activation}\")\n\n", "CodeBleu_score": 51.05671484525368}, {"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    if params.get(\"conv_activation\") == \"LeakyReLU\":\n        return LeakyReLU(negative_slope=0.2)\n    elif params.get(\"conv_activation\") == \"ELU\":\n        return ELU()\n    else:\n        return ReLU()\n\n", "CodeBleu_score": 45.384527955413375}]}
{"instance_id": "2f8b5a2fc0f2", "generation_result": [{"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    logit_mask_list = []\n    for instrument in instruments:\n        logit_mask = apply_unet(input_tensor, instrument, params)\n        logit_mask_list.append(logit_mask)\n\n    logit_masks = tf.stack(logit_mask_list, axis=-1)\n    mask = tf.nn.softmax(logit_masks, axis=-1)\n\n    output = {}\n    for i, instrument in enumerate(instruments):\n        output[instrument] = input_tensor * mask[..., i : i + 1]\n\n    return output\n\n", "CodeBleu_score": 32.20656130011447}, {"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n\n    logit_mask_list = []\n    for instrument in instruments:\n        logit_mask = apply_unet(input_tensor, instrument, params)\n        logit_mask_list.append(logit_mask)\n\n    logit_masks = tf.stack(logit_mask_list, axis=-1)\n    mask = tf.nn.softmax(logit_masks, axis=-1)\n\n    output_dict = {}\n    for idx, instrument in enumerate(instruments):\n        output_dict[instrument] = mask[..., idx] * input_tensor\n\n    return output_dict\n\n", "CodeBleu_score": 31.576122510256976}, {"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    logit_mask_list = []\n    for instrument in instruments:\n        logit_mask = apply_unet(\n            input_tensor,\n            instrument,\n            params={\n                **params,\n                \"activation\": \"linear\",\n                \"output_activation\": \"linear\",\n            },\n        )\n        logit_mask_list.append(logit_mask)\n    logit_masks = tf.stack(logit_mask_list, axis=-1)\n    mask = tf.nn.softmax(logit_masks, axis=-1)\n    output = {}\n    for i, instrument in enumerate(instruments):\n        output[instrument] = input_tensor * mask[..., i : i + 1]\n    return output\n\n", "CodeBleu_score": 38.92428918127672}]}
{"instance_id": "400b19ce8520", "generation_result": [{"code": "def compute_file_checksum(path)\n\t\n    sha256_hash = hashlib.sha256()\n    with open(path, \"rb\") as f:\n        for byte_block in iter(lambda: f.read(4096), b\"\"):\n            sha256_hash.update(byte_block)\n        return sha256_hash.hexdigest()\n\n", "CodeBleu_score": 56.89315495721963}, {"code": "def compute_file_checksum(path)\n\t\n    sha256 = hashlib.sha256()\n    with open(path, \"rb\") as stream:\n        for chunk in iter(lambda: stream.read(4096), b\"\"):\n            sha256.update(chunk)\n    return sha256.hexdigest()\n\n", "CodeBleu_score": 72.89345930934067}, {"code": "def compute_file_checksum(path)\n\t\n    sha256 = hashlib.sha256()\n    with open(path, \"rb\") as stream:\n        while True:\n            chunk = stream.read(4096)\n            if not chunk:\n                break\n            sha256.update(chunk)\n    return sha256.hexdigest()\n\n", "CodeBleu_score": 47.113191353407935}]}
{"instance_id": "5f2e9c6e15f1", "generation_result": [{"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/{self.checksum_index}\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    index = response.json()\n    if name not in index:\n        raise ValueError(f\"Model {name} not found in index.\")\n    return index[name]\n\n", "CodeBleu_score": 36.46374963857735}, {"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/checksum.json\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    index = response.json()\n    if name not in index:\n        raise ValueError(f\"Model {name} not found\")\n    return index[name]", "CodeBleu_score": 35.80812678455473}, {"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/checksums.json\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    index = response.json()\n    if name not in index:\n        raise ValueError(f\"{name} not found in index\")\n    return index[name]", "CodeBleu_score": 35.75067079021038}]}
{"instance_id": "9312c8b6032e", "generation_result": [{"code": "def download(self, name: str, path: str) -> None:\n\t\n    url = self.url_template.format(name=name)\n    logger.info(f\"Downloading {url}\")\n    with httpx.Client(http2=True) as client:\n        with client.stream(\"GET\", url) as response:\n            response.raise_for_status()\n            with NamedTemporaryFile(delete=False) as tmp_file:\n                with tqdm(\n                    total=int(response.headers[\"Content-Length\"]),\n                    unit=\"B\",\n                    unit_scale=True,\n                    unit_divisor=1024,\n                    desc=\"Downloading\",\n                ) as progress:\n                    for chunk in response.iter_raw():\n                        tmp_file.write(chunk)\n                        progress.update(len(chunk))\n                tmp_file.close()\n                if not compute_file_checksum(tmp_file.name) == self.checksum:\n                    raise IOError(\"File checksum does not match expected value\")\n                with tarfile.open(tmp_file.name, \"r:gz\") as tar:\n                    tar.extractall(path)\n                os.unlink(tmp_file.name)\n    logger.info(f\"Extracted {name} to {path}\")", "CodeBleu_score": 50.42759705909431}, {"code": "def download(self, name: str, path: str) -> None:\n\t\n    url = self.url(name)\n    logger.info(f\"Downloading model {name} from {url}\")\n    with httpx.stream(\"GET\", url, headers=self.headers, follow_redirects=True) as response:\n        response.raise_for_status()\n        with NamedTemporaryFile() as temp_file:\n            with temp_file.open(\"wb\") as file:\n                for chunk in response.iter_raw():\n                    file.write(chunk)\n            if compute_file_checksum(temp_file.name) != self.checksum:\n                raise IOError(f\"Checksum of downloaded file {temp_file.name} does not match expected value\")\n            with tarfile.open(temp_file.name, \"r:gz\") as tar:\n                tar.extractall(path)\n            os.unlink(temp_file.name)\n            logger.info(f\"Extracted model {name} to {path}\")\n\n", "CodeBleu_score": 36.405622670075665}, {"code": "def download(self, name: str, path: str) -> None:\n\t\n    url = self.get_download_url(name)\n    logger.info(f\"Downloading {name} from {url}\")\n    with httpx.stream(\"GET\", url, headers=self.headers) as response:\n        response.raise_for_status()\n        with NamedTemporaryFile(delete=False) as f:\n            logger.info(f\"Downloading {name} to {f.name}\")\n            for chunk in response.iter_raw():\n                f.write(chunk)\n            logger.info(f\"Downloaded {name} to {f.name}\")\n            if compute_file_checksum(f.name) != self.checksum:\n                raise IOError(\"Checksum mismatch\")\n            logger.info(f\"Extracting {name} to {path}\")\n            with tarfile.open(f.name) as tar:\n                tar.extractall(path)\n            logger.info(f\"Extracted {name} to {path}\")\n            os.unlink(f.name)\n            logger.info(f\"Deleted {f.name}\")\n\n", "CodeBleu_score": 36.953949051142565}]}
{"instance_id": "ee9493f37d77", "generation_result": [{"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embedded://\"):\n        name = descriptor[len(\"embedded://\") :]\n        if not loader.is_resource(name):\n            raise SpleeterError(\n                f\"No embedded configuration file found for {name}.\"\n            )\n        with loader.open_text(name) as f:\n            return json.load(f)\n    if not exists(descriptor):\n        raise SpleeterError(f\"No configuration file found for {descriptor}.\")\n    with open(descriptor, \"r\") as f:\n        return json.load(f)", "CodeBleu_score": 58.026096729108104}, {"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embedded://\"):\n        name = descriptor.replace(\"embedded://\", \"\")\n        if not loader.is_resource(name):\n            raise SpleeterError(\n                f\"No embedded configuration file found for name {name}.\"\n            )\n        with loader.open_text(name) as stream:\n            return json.load(stream)\n    if not os.path.exists(descriptor):\n        raise SpleeterError(f\"No configuration file found for path {descriptor}.\")\n    with open(descriptor, \"r\") as stream:\n        return json.load(stream)\n\n", "CodeBleu_score": 66.2799013285306}, {"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embedded://\"):\n        name = descriptor[len(\"embedded://\") :]\n        if not loader.is_resource(name):\n            raise SpleeterError(f\"No embedded configuration file found for {name}\")\n        with loader.open_text(name) as f:\n            return json.load(f)\n    if not os.path.exists(descriptor):\n        raise SpleeterError(f\"No configuration file found for {descriptor}\")\n    with open(descriptor, \"r\") as f:\n        return json.load(f)", "CodeBleu_score": 52.69658243630205}]}
{"instance_id": "546134b67fbc", "generation_result": [{"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise NotImplementedError(\n            \"only axis 0 and 1 are supported for concatenation\"\n        )\n    concat_tensor = tf.concat(list(tensor_dict.values()), axis=concat_axis)\n    processed_concat_tensor = func(concat_tensor)\n    shapes = [tf.shape(tensor) for tensor in tensor_dict.values()]\n    if concat_axis == 0:\n        processed_tensors = tf.split(processed_concat_tensor, shapes, axis=0)\n    else:\n        processed_tensors = tf.split(processed_concat_tensor, shapes, axis=1)\n    return {\n        key: tensor for key, tensor in zip(tensor_dict.keys(), processed_tensors)\n    }\n\n", "CodeBleu_score": 47.15487607385852}, {"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    # Check if the concatenation axis is either 0 or 1\n    if concat_axis not in [0, 1]:\n        raise ValueError(\n            \"Concatenation axis must be either 0 or 1. Given: {}\".format(concat_axis)\n        )\n\n    # Concatenate the tensors along the specified axis\n    concat_tensor = tf.concat(list(tensor_dict.values()), axis=concat_axis)\n\n    # Apply the function to the concatenated tensor\n    processed_tensor = func(concat_tensor)\n\n    # Split the processed tensor back into the original dictionary format based on the concatenation axis\n    processed_tensor_dict = {}\n    if concat_axis == 0:\n        for i, key in enumerate(tensor_dict.keys()):\n            processed_tensor_dict[key] = processed_tensor[i]\n    else:\n        for i, key in enumerate(tensor_dict.keys()):\n            processed_tensor_dict[key] = processed_tensor[:, i]\n\n    return processed_tensor_dict\n\n", "CodeBleu_score": 44.068253514318776}, {"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise NotImplementedError(\n            \"Only axis 0 and 1 are supported for concatenation.\"\n        )\n\n    concat_tensor = tf.concat(list(tensor_dict.values()), concat_axis)\n    processed_tensor = func(concat_tensor)\n    processed_tensor_list = tf.split(\n        processed_tensor, len(list(tensor_dict.values())), concat_axis\n    )\n\n    processed_tensor_dict = {}\n    for i, (key, tensor) in enumerate(tensor_dict.items()):\n        processed_tensor_dict[key] = processed_tensor_list[i]\n\n    return processed_tensor_dict", "CodeBleu_score": 41.6324864659808}]}
{"instance_id": "df48e78d46d2", "generation_result": [{"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n    minimum = tf.reduce_min(tensor)\n    maximum = tf.reduce_max(tensor)\n    scaled_tensor = tf.cast(\n        tf.math.floor(255 * (tensor - minimum) / (maximum - minimum)), tf.uint8\n    )\n    return {tensor_key: scaled_tensor, min_key: minimum, max_key: maximum}\n\n", "CodeBleu_score": 39.83619809813298}, {"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n    min_value = tf.reduce_min(tensor)\n    max_value = tf.reduce_max(tensor)\n    scaled_tensor = tf.cast(\n        (tensor - min_value) / (max_value - min_value) * 255, dtype=tf.uint8\n    )\n    return {\n        tensor_key: scaled_tensor,\n        min_key: min_value,\n        max_key: max_value,\n    }\n\n", "CodeBleu_score": 45.708080069495566}, {"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n    min_value = tf.reduce_min(tensor)\n    max_value = tf.reduce_max(tensor)\n    scaled_tensor = tf.cast(\n        tf.round(255.0 * (tensor - min_value) / (max_value - min_value)), tf.uint8\n    )\n    return {tensor_key: scaled_tensor, min_key: min_value, max_key: max_value}\n\n", "CodeBleu_score": 40.10083485981855}]}
{"instance_id": "7f479e5de492", "generation_result": [{"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    # Calculate the number of segments needed\n    num_segments = tf.math.floormod(tf.shape(tensor)[0], segment_len)\n    # Calculate the padding needed\n    padding = tf.reshape(\n        tf.pad(tensor, [[0, num_segments], [0, 0]]),\n        [-1, segment_len, tensor.shape[-1]],\n    )\n    # Reshape the tensor into segments\n    segments = tf.reshape(padding, [-1, segment_len * tensor.shape[-1]])\n    return segments\n\n", "CodeBleu_score": 29.735729402055057}, {"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    pad_len = segment_len - (len(tensor) % segment_len)\n    tensor = tf.pad(tensor, [[0, pad_len]])\n    return tf.reshape(tensor, [-1, segment_len])\n\n", "CodeBleu_score": 15.999350555322453}, {"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    # Calculate the number of segments needed\n    num_segments = tf.math.floormod(tf.shape(tensor)[0], segment_len)\n    # Calculate the padding needed to make the tensor length a multiple of the segment length\n    padding = tf.reshape(tf.pad(tensor, [[0, num_segments], [0, 0]]), [-1, segment_len])\n    # Reshape the padded tensor into segments\n    return tf.reshape(padding, [-1, segment_len])\n\n", "CodeBleu_score": 23.153230847382314}]}
{"instance_id": "1789fae7253f", "generation_result": [{"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    num_extra_rows = frame_length - instr_spec.shape[0] % frame_length\n    extension = tf.zeros((num_extra_rows, F))\n    padded_instr_spec = tf.concat([instr_spec, extension], axis=0)\n    padded_instr_spec = tf.reshape(padded_instr_spec, (-1, frame_length, F))\n    return padded_instr_spec\n\n", "CodeBleu_score": 16.61856053729677}, {"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    # Calculate the number of extra rows needed for padding\n    nrows = int(np.ceil((frame_length - F) / 2))\n\n    # Create an extension of zeros\n    extension = tf.zeros((nrows, F), dtype=tf.float32)\n\n    # Concatenate the extension to the original spectrogram along the frequency axis\n    instr_spec = tf.concat([extension, instr_spec], axis=0)\n\n    # Reshape the extended spectrogram by merging the first two dimensions\n    instr_spec = tf.reshape(instr_spec, (1, -1))\n\n    return instr_spec\n\n", "CodeBleu_score": 13.299207327245293}, {"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    n_extra_rows = frame_length - (instr_spec.shape[0] % frame_length)\n    extension = tf.zeros((n_extra_rows, instr_spec.shape[1]))\n    padded_spec = tf.concat([instr_spec, extension], axis=0)\n    n_total_rows = padded_spec.shape[0]\n    n_reshaped_cols = int(n_total_rows * F / frame_length)\n    reshaped_spec = tf.reshape(padded_spec, (n_total_rows, n_reshaped_cols))\n    return reshaped_spec\n\n", "CodeBleu_score": 21.48068591939215}]}
{"instance_id": "8a4f4658d97c", "generation_result": [{"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path, **kwargs)\n    return tf.data.Dataset.from_tensor_slices(dict(df))", "CodeBleu_score": 27.127655353502654}, {"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path, **kwargs)\n    return tf.data.Dataset.from_tensor_slices(dict(df))\n\n", "CodeBleu_score": 27.127655353502654}, {"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path, **kwargs)\n    return tf.data.Dataset.from_tensor_slices(dict(df))\n\n", "CodeBleu_score": 27.127655353502654}]}
{"instance_id": "9a16e81b182f", "generation_result": [{"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for i, dim_length in enumerate(target_shape):\n        if dim_length is not None:\n            result = tf.logical_and(result, tf.equal(tf.shape(tensor_tf)[i], dim_length))\n    return result\n\n", "CodeBleu_score": 43.16853515072923}, {"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for i, length in enumerate(target_shape):\n        if length is not None:\n            result = tf.logical_and(result, tf.equal(tf.shape(tensor_tf)[i], length))\n    return result\n\n", "CodeBleu_score": 42.62285958199549}, {"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for i, length in enumerate(target_shape):\n        if length is not None:\n            result = tf.logical_and(result, tf.equal(tf.shape(tensor_tf)[i], length))\n    return result\n\n", "CodeBleu_score": 42.62285958199549}]}
{"instance_id": "49d5d3084b3a", "generation_result": [{"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\t\n    builder = DatasetBuilder(\n        audio_params=audio_params,\n        audio_adapter=audio_adapter,\n        dataset_path=audio_path,\n        chunk_duration=10,\n        random_seed=42,\n    )\n    return builder.build(\n        train_csv_path=\"train.csv\",\n        cache_dir=\"cache\",\n        batch_size=16,\n        num_chunks_per_song=10,\n        data_augmentation=True,\n        cache=True,\n    )\n\n", "CodeBleu_score": 28.9617690984192}, {"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\t\n    builder = DatasetBuilder(\n        audio_params=audio_params,\n        audio_adapter=audio_adapter,\n        train_csv_path=train_csv,\n        cache_dir=cache_dir,\n        batch_size=batch_size,\n        num_chunks_per_song=num_chunks_per_song,\n        data_augmentation_options=data_augmentation_options,\n        cache=cache,\n    )\n    return builder.build(\n        audio_path=audio_path,\n        chunk_duration=chunk_duration,\n        random_seed=random_seed,\n    )\n\n", "CodeBleu_score": 28.59829865879002}, {"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\t\n    builder = DatasetBuilder(\n        audio_params,\n        audio_adapter,\n        audio_path,\n        chunk_duration=audio_params.get(\"chunk_duration\", 10),\n        random_seed=audio_params.get(\"random_seed\", 42),\n    )\n    return builder.build(\n        train_csv_path=audio_params.get(\"train_csv_path\", None),\n        cache_dir=audio_params.get(\"cache_dir\", None),\n        batch_size=audio_params.get(\"batch_size\", 16),\n        num_chunks_per_song=audio_params.get(\"num_chunks_per_song\", 10),\n        data_augmentation=audio_params.get(\"data_augmentation\", False),\n        cache=audio_params.get(\"cache\", False),\n    )\n\n", "CodeBleu_score": 53.46424633641522}]}
{"instance_id": "fe8bbbba06e3", "generation_result": [{"code": "def instruments(self) -> Any\n\t\n    if self._instruments is None:\n        self._instruments = [InstrumentDatasetBuilder(instrument, self.data_dir, self.data_type) for instrument in self.instruments]\n    for instrument in self._instruments:\n        yield instrument\n\n", "CodeBleu_score": 34.45714294541687}, {"code": "def instruments(self) -> Any\n\t\n    if self._instruments is None:\n        self._instruments = [InstrumentDatasetBuilder(instrument, self._root) for instrument in self._instruments_list]\n    for instrument in self._instruments:\n        yield instrument\n", "CodeBleu_score": 34.12395289060796}, {"code": "def instruments(self) -> Any\n\t\n    if self._instrument_builders is None:\n        self._instrument_builders = [InstrumentDatasetBuilder(self._data_dir, instrument) for instrument in self._instruments]\n    for builder in self._instrument_builders:\n        yield builder\n\n", "CodeBleu_score": 45.96258580783421}]}
{"instance_id": "438b57fd3413", "generation_result": [{"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is None:\n        return dataset\n    if not os.path.exists(cache):\n        os.makedirs(cache)\n    while True:\n        if exists(cache):\n            logger.info(f\"Loading cached dataset from {cache}\")\n            return load_from_disk(cache)\n        else:\n            logger.info(f\"Caching dataset to {cache}\")\n            dataset.cache_files = {\"cache_files\": cache}\n            dataset.save_to_disk(cache)\n            if not wait:\n                return dataset\n            else:\n                logger.info(\"Waiting for cache to be created...\")\n                time.sleep(10)\n\n", "CodeBleu_score": 42.06903029549185}, {"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is not None:\n        os.makedirs(os.path.dirname(cache), exist_ok=True)\n        if wait:\n            while not os.path.exists(cache):\n                logger.info(f\"Waiting for cache {cache} to be created...\")\n                time.sleep(10)\n        else:\n            dataset = dataset.cache(cache)\n    return dataset\n\n", "CodeBleu_score": 56.66659610173047}, {"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is None:\n        return dataset\n    os.makedirs(os.path.dirname(cache), exist_ok=True)\n    if wait and not os.path.exists(cache):\n        while not os.path.exists(cache):\n            logger.info(f\"waiting for cache {cache}\")\n            time.sleep(10)\n    logger.info(f\"caching dataset to {cache}\")\n    dataset.cache(cache)\n    return dataset\n\n", "CodeBleu_score": 46.36487325352647}]}
{"instance_id": "8838a3a09a66", "generation_result": [{"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n\n    model_dir = ModelProvider.default().get(params['model_name'])\n    params['model_dir'] = model_dir\n\n    if MWF:\n        params['model_dir'] = os.path.join(model_dir, 'model')\n\n    session_config = tf.compat.v1.ConfigProto()\n    session_config.gpu_options.per_process_gpu_memory_fraction = 0.45\n\n    config = RunConfig(\n        model_dir=params['model_dir'],\n        save_summary_steps=params['save_summary_steps'],\n        save_checkpoints_steps=params['save_checkpoints_steps'],\n        tf_random_seed=params['tf_random_seed'],\n        keep_checkpoint_max=params['keep_checkpoint_max'],\n        log_step_count_steps=params['log_step_count_steps'],\n        session_config=session_config\n    )\n\n    estimator = tf.estimator.Estimator(\n        model_fn=model_fn,\n        model_dir=params['model_dir'],\n        params=params,\n        config=config\n    )\n\n    return estimator\n\n", "CodeBleu_score": 54.22528130453561}, {"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    model_provider = ModelProvider.default(params)\n    model_dir = model_provider.get()\n    params.update({'model_dir': model_dir})\n    session_config = tf.ConfigProto()\n    session_config.gpu_options.allow_growth = True\n    run_config = RunConfig(session_config=session_config)\n    return tf.estimator.Estimator(model_fn=model_fn, model_dir=model_dir, params=params, config=run_config)\n\n", "CodeBleu_score": 31.01986059131969}, {"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    model_dir = ModelProvider.default(params[\"model_dir\"])\n    params.update({\"model_dir\": model_dir})\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.gpu_options.per_process_gpu_memory_fraction = 0.45\n    run_config = RunConfig(\n        model_dir=params[\"model_dir\"],\n        save_summary_steps=params[\"save_summary_steps\"],\n        save_checkpoints_steps=params[\"save_checkpoints_steps\"],\n        tf_random_seed=params[\"seed\"],\n        session_config=config,\n        keep_checkpoint_max=params[\"keep_checkpoint_max\"],\n        log_step_count_steps=params[\"log_step_count_steps\"],\n    )\n    return tf.estimator.Estimator(\n        model_fn=model_fn,\n        model_dir=params[\"model_dir\"],\n        params=params,\n        config=run_config,\n        warm_start_from=MWF,\n    )\n\n", "CodeBleu_score": 30.76191349616443}]}
{"instance_id": "779c812bf2cb", "generation_result": [{"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    waveform = self._to_stereo(waveform)\n    prediction_generator = self._get_prediction_generator()\n    self._update_data(waveform, audio_descriptor)\n    prediction = next(prediction_generator)\n    prediction.pop(\"audio_id\")\n    return prediction\n\n\n", "CodeBleu_score": 44.15923024744109}, {"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    waveform = self._to_stereo(waveform)\n    prediction_generator = self._get_prediction_generator()\n    prediction_generator.update_data(waveform, audio_descriptor)\n    prediction = next(prediction_generator)\n    prediction.pop(\"audio_id\")\n    return prediction\n\n", "CodeBleu_score": 45.30894212612791}, {"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    waveform = to_stereo(waveform)\n    prediction_generator = self._get_prediction_generator()\n    update_data(prediction_generator, waveform, audio_descriptor)\n    prediction = next(prediction_generator)\n    prediction.pop(\"audio_id\")\n    return prediction\n\n", "CodeBleu_score": 48.217860011730664}]}
{"instance_id": "cf580cd2ed93", "generation_result": [{"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape)\n\n    # Currently supports ResNet only\n    assert config.BACKBONE in [\"resnet50\", \"resnet101\"]\n    return np.array(\n        [[int(math.ceil(image_shape[0] / stride)),\n            int(math.ceil(image_shape[1] / stride))]\n            for stride in config.BACKBONE_STRIDES])\n\n\n", "CodeBleu_score": 95.198357853076}, {"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape)\n\n    # Currently supports ResNet only\n    assert config.BACKBONE in [\"resnet50\", \"resnet101\"]\n    return np.array(\n        [[int(math.ceil(image_shape[0] / stride)),\n            int(math.ceil(image_shape[1] / stride))]\n         for stride in config.BACKBONE_STRIDES])\n\n", "CodeBleu_score": 94.96652467722696}, {"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape)\n\n    # Currently supports ResNet only\n    assert config.BACKBONE in [\"resnet50\", \"resnet101\"]\n    return np.array(\n        [[int(math.ceil(image_shape[0] / stride)),\n            int(math.ceil(image_shape[1] / stride))]\n         for stride in config.BACKBONE_STRIDES])\n\n", "CodeBleu_score": 94.96652467722696}]}
{"instance_id": "ebd61a2e59ca", "generation_result": [{"code": "def clip_boxes_graph(boxes, window)\n\t\n    with tf.name_scope('clip_to_window'):\n        boxes = tf.transpose(boxes)\n        window = tf.transpose(window)\n        # Split the window into two coordinates\n        wy1, wx1, wy2, wx2 = tf.unstack(window, axis=0)\n        # Split the boxes into two coordinates\n        y1, x1, y2, x2 = tf.unstack(boxes, axis=0)\n        # Clip the boxes to the window boundaries\n        y1 = tf.maximum(tf.minimum(y1, wy2), wy1)\n        x1 = tf.maximum(tf.minimum(x1, wx2), wx1)\n        y2 = tf.maximum(tf.minimum(y2, wy2), wy1)\n        x2 = tf.maximum(tf.minimum(x2, wx2), wx1)\n        # Concatenate the clipped coordinates back into a tensor\n        clipped = tf.stack([y1, x1, y2, x2], axis=0)\n        clipped = tf.transpose(clipped)\n        # Set the shape of the clipped tensor to match the original boxes tensor\n        clipped.set_shape((clipped.shape[0], 4))\n        return clipped\n\n", "CodeBleu_score": 62.750006796290094}, {"code": "def clip_boxes_graph(boxes, window)\n\t\n    with tf.name_scope('clip_to_window'):\n        # Split coordinates of boxes and window into separate variables w.r.t x and y.\n        # w.r.t stands for with respect to\n        win_y_min, win_x_min, win_y_max, win_x_max = tf.split(axis=0, num_or_size_splits=4, value=window)\n        box_y_min, box_x_min, box_y_max, box_x_max = tf.split(axis=1, num_or_size_splits=4, value=boxes)\n        # Clip the box coordinates to be within the window's boundaries.\n        clipped_y_min = tf.maximum(tf.minimum(box_y_min, win_y_max), win_y_min)\n        clipped_x_min = tf.maximum(tf.minimum(box_x_min, win_x_max), win_x_min)\n        clipped_y_max = tf.maximum(tf.minimum(box_y_max, win_y_max), win_y_min)\n        clipped_x_max = tf.maximum(tf.minimum(box_x_max, win_x_max), win_x_min)\n        # Concatenate the clipped coordinates into a tensor.\n        clipped = tf.concat([clipped_y_min, clipped_x_min, clipped_y_max, clipped_x_max], axis=1, name='clipped_boxes')\n        # Clip the box coordinates to be within the window's boundaries.\n        clipped = tf.maximum(clipped, 0.0)\n        # Return the clipped boxes with the same shape as the input boxes tensor.\n        clipped = tf.minimum(clipped, 1.0)\n        return clipped.set_shape((clipped.shape[0], 4))", "CodeBleu_score": 40.924178010544175}, {"code": "def clip_boxes_graph(boxes, window)\n\t\n    with tf.name_scope('clip_to_window'):\n        # Split window and box coordinates into individual components\n        win_y1, win_x1, win_y2, win_x2 = tf.split(window, 4)\n        box_y1, box_x1, box_y2, box_x2 = tf.split(boxes, 4, axis=1)\n\n        # Clip the box coordinates to the window boundaries\n        y1 = tf.maximum(tf.minimum(box_y1, win_y2), win_y1)\n        x1 = tf.maximum(tf.minimum(box_x1, win_x2), win_x1)\n        y2 = tf.maximum(tf.minimum(box_y2, win_y2), win_y1)\n        x2 = tf.maximum(tf.minimum(box_x2, win_x2), win_x1)\n\n        # Concatenate the clipped coordinates into a tensor\n        clipped = tf.concat([y1, x1, y2, x2], axis=1, name=\"clipped_boxes\")\n        clipped.set_shape((clipped.shape[0], 4))\n        return clipped\n\n", "CodeBleu_score": 60.89929445166919}]}
{"instance_id": "8e0411587a70", "generation_result": [{"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    # Shared convolutional layer\n    shared_layer = KL.Conv2D(512, (3, 3), padding='same', activation='relu',\n                             kernel_initializer='normal', name='rpn_conv_shared')(feature_map)\n\n    # Class scores\n    class_conv = KL.Conv2D(2 * anchors_per_location, (1, 1), padding='valid',\n                           kernel_initializer='uniform', name='rpn_class_conv')(shared_layer)\n    class_logits = KL.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 2]))(class_conv)\n    class_probabilities = KL.Activation('softmax', name='rpn_class_act')(class_logits)\n\n    # Bounding box predictions\n    box_conv = KL.Conv2D(anchors_per_location * 4, (1, 1), padding='valid',\n                         kernel_initializer='uniform', name='rpn_box_conv')(shared_layer)\n    box_predictions = KL.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 4]))(box_conv)\n\n    return class_logits, class_probabilities, box_predictions\n\n", "CodeBleu_score": 63.62209675322008}, {"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    # Shared convolutional layer\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu',\n                       strides=anchor_stride,\n                       name='rpn_conv_shared')(feature_map)\n\n    # Anchor Score. [batch, height, width, anchors per location * 2].\n    x = KL.Conv2D(2 * anchors_per_location, (1, 1), padding='valid',\n                  activation='linear', name='rpn_class_raw')(shared)\n\n    # Reshape to [batch, anchors, 2]\n    rpn_class_logits = tf.reshape(x, [tf.shape(x)[0], -1, 2])\n\n    # Softmax on last dimension of BG/FG.\n    rpn_probs = tf.nn.softmax(rpn_class_logits)\n\n    # Bounding box refinement. [batch, H, W, anchors per location, depth]\n    # where depth is [x, y, log(w), log(h)]\n    x = KL.Conv2D(anchors_per_location * 4, (1, 1), padding=\"valid\",\n                  activation='linear', name='rpn_bbox_pred')(shared)\n\n    # Reshape to [batch, anchors, 4]\n    rpn_bbox = tf.reshape(x, [tf.shape(x)[0], -1, 4])\n\n    return rpn_class_logits, rpn_probs, rpn_bbox\n\n", "CodeBleu_score": 63.80045301715168}, {"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    # Shared convolutional layer\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu',\n                       strides=anchor_stride,\n                       name='rpn_conv_shared')(feature_map)\n\n    # Anchor Score. [batch, height, width, anchors per location * 2].\n    x = KL.Conv2D(2 * anchors_per_location, (1, 1), padding='valid',\n                  activation='linear', name='rpn_class_raw')(shared)\n\n    # Reshape to [batch, anchors, 2]\n    rpn_class_logits = tf.reshape(x, [tf.shape(x)[0], -1, 2])\n\n    # Softmax on last dimension of BG/FG.\n    rpn_probs = tf.nn.softmax(rpn_class_logits, axis=-1)\n\n    # Bounding box refinement. [batch, H, W, anchors per location, depth]\n    # where depth is [x, y, log(w), log(h)]\n    x = KL.Conv2D(anchors_per_location * 4, (1, 1), padding=\"valid\",\n                  activation='linear', name='rpn_bbox_pred')(shared)\n\n    # Reshape to [batch, anchors, 4]\n    rpn_bbox = tf.reshape(x, [tf.shape(x)[0], -1, 4])\n\n    return rpn_class_logits, rpn_probs, rpn_bbox\n\n", "CodeBleu_score": 64.27293579870745}]}
{"instance_id": "70777c9261d8", "generation_result": [{"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    abs_diff = K.abs(y_true - y_pred)\n    mask = K.cast(K.less(abs_diff, 1.0), dtype=K.floatx())\n    return (abs_diff ** 2) * mask + (abs_diff - 0.5) * (1.0 - mask)\n\n", "CodeBleu_score": 29.1617869553928}, {"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    abs_diff = K.abs(y_true - y_pred)\n    mask = K.cast(K.less(abs_diff, 1.0), dtype='float32')\n    return (mask * 0.5 * K.square(abs_diff)) + (1 - mask) * (abs_diff - 0.5)\n\n", "CodeBleu_score": 32.604535028297384}, {"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    abs_diff = K.abs(y_true - y_pred)\n    mask = K.cast(K.less(abs_diff, 1.0), dtype=K.floatx())\n    return (abs_diff ** 2) * mask + (abs_diff - 0.5) * (1.0 - mask)\n\n", "CodeBleu_score": 29.1617869553928}]}
{"instance_id": "0e747b604087", "generation_result": [{"code": "def build_model(x_train, num_classes)\n\t\n    K.clear_session()\n    input_layer = KL.Input(shape=x_train.shape[1:])\n    conv_1 = KL.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(input_layer)\n    conv_2 = KL.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(conv_1)\n    max_pool = KL.MaxPooling2D(pool_size=(2, 2))(conv_2)\n    flatten = KL.Flatten()(max_pool)\n    dense_1 = KL.Dense(units=128, activation='relu')(flatten)\n    dense_2 = KL.Dense(units=num_classes, activation='softmax')(dense_1)\n    model = KM.Model(inputs=input_layer, outputs=dense_2)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n", "CodeBleu_score": 28.992966751134492}, {"code": "def build_model(x_train, num_classes)\n\t\n    K.clear_session()\n    input_layer = KL.Input(shape=x_train.shape[1:])\n    conv1 = KL.Conv2D(32, kernel_size=(3, 3), activation='relu')(input_layer)\n    conv2 = KL.Conv2D(64, kernel_size=(3, 3), activation='relu')(conv1)\n    pool = KL.MaxPooling2D(pool_size=(2, 2))(conv2)\n    flat = KL.Flatten()(pool)\n    dense1 = KL.Dense(128, activation='relu')(flat)\n    dense2 = KL.Dense(num_classes, activation='softmax')(dense1)\n    model = KM.Model(inputs=input_layer, outputs=dense2)\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model", "CodeBleu_score": 30.05304973936407}, {"code": "def build_model(x_train, num_classes)\n\t\n    K.clear_session()\n    input_layer = KL.Input(shape=x_train.shape[1:])\n    layer = KL.Conv2D(16, (3, 3), padding='same', activation='relu')(input_layer)\n    layer = KL.Conv2D(8, (3, 3), padding='same', activation='relu')(layer)\n    layer = KL.MaxPooling2D((2, 2), padding='same')(layer)\n    layer = KL.Flatten()(layer)\n    layer = KL.Dense(32, activation='relu')(layer)\n    output_layer = KL.Dense(num_classes, activation='softmax')(layer)\n    model = KM.Model(inputs=input_layer, outputs=output_layer)\n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n", "CodeBleu_score": 26.815207865475156}]}
{"instance_id": "813e3e2844f4", "generation_result": [{"code": "def extract_bboxes(mask)\n\t\n    boxes = np.zeros([mask.shape[-1], 4], dtype=np.int32)\n    for i in range(mask.shape[-1]):\n        m = mask[:, :, i]\n        horizontal_indicies = np.where(np.any(m, axis=0))[0]\n        vertical_indicies = np.where(np.any(m, axis=1))[0]\n        if horizontal_indicies.shape[0]:\n            x1, x2 = horizontal_indicies[[0, -1]]\n            y1, y2 = vertical_indicies[[0, -1]]\n            x2 += 1\n            y2 += 1\n        else:\n            x1, x2, y1, y2 = 0, 0, 0, 0\n        boxes[i] = np.array([y1, x1, y2, x2])\n    return boxes.astype(np.int32)", "CodeBleu_score": 80.16876428190413}, {"code": "def extract_bboxes(mask)\n\t\n    boxes = np.zeros([mask.shape[-1], 4], dtype=np.int32)\n    for m in range(mask.shape[-1]):\n        # Bounding box.\n        horizontal_indicies = np.where(np.any(mask[:, :, m], axis=0))[0]\n        vertical_indicies = np.where(np.any(mask[:, :, m], axis=1))[0]\n        if horizontal_indicies.shape[0]:\n            x1, x2 = horizontal_indicies[[0, -1]]\n            y1, y2 = vertical_indicies[[0, -1]]\n            # x2 and y2 should not be part of the box. Increment by 1.\n            x2 += 1\n            y2 += 1\n        else:\n            # No mask for this instance. Might happen due to\n            # resizing or cropping. Set bbox to zeros\n            x1, x2, y1, y2 = 0, 0, 0, 0\n        boxes[m] = np.array([y1, x1, y2, x2])\n    return boxes.astype(np.int32)\n\n", "CodeBleu_score": 66.11421865850897}, {"code": "def extract_bboxes(mask)\n\t\n    boxes = np.zeros([mask.shape[-1], 4], dtype=np.int32)\n    for i in range(mask.shape[-1]):\n        m = mask[:, :, i]\n        horizontal_indicies = np.where(np.any(m, axis=0))[0]\n        vertical_indicies = np.where(np.any(m, axis=1))[0]\n        if horizontal_indicies.shape[0]:\n            x1, x2 = horizontal_indicies[[0, -1]]\n            y1, y2 = vertical_indicies[[0, -1]]\n            x2 += 1\n            y2 += 1\n        else:\n            x1, x2, y1, y2 = 0, 0, 0, 0\n\n        boxes[i] = np.array([y1, x1, y2, x2])\n    return boxes.astype(np.int32)\n\n", "CodeBleu_score": 80.16876428190413}]}
{"instance_id": "7ad5d430d6ed", "generation_result": [{"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    y1 = np.maximum(box[0], boxes[:, 0])\n    y2 = np.minimum(box[2], boxes[:, 2])\n    x1 = np.maximum(box[1], boxes[:, 1])\n    x2 = np.minimum(box[3], boxes[:, 3])\n    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n    union = box_area + boxes_area[:] - intersection[:]\n    iou = intersection / union\n    return iou\n\n", "CodeBleu_score": 58.663259083089194}, {"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    y1 = np.maximum(box[0], boxes[:, 0])\n    y2 = np.minimum(box[2], boxes[:, 2])\n    x1 = np.maximum(box[1], boxes[:, 1])\n    x2 = np.minimum(box[3], boxes[:, 3])\n    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n    union = box_area + boxes_area[:] - intersection[:]\n    iou = intersection / union\n    return iou\n\n", "CodeBleu_score": 58.663259083089194}, {"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    y1 = np.maximum(box[0], boxes[:, 0])\n    y2 = np.minimum(box[2], boxes[:, 2])\n    x1 = np.maximum(box[1], boxes[:, 1])\n    x2 = np.minimum(box[3], boxes[:, 3])\n    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n    union = box_area + boxes_area[:] - intersection[:]\n    iou = intersection / union\n    return iou\n\n", "CodeBleu_score": 58.663259083089194}]}
{"instance_id": "15941b852859", "generation_result": [{"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    area1 = (boxes1[:, 2] - boxes1[:, 0] + 1) * (boxes1[:, 3] - boxes1[:, 1] + 1)\n    area2 = (boxes2[:, 2] - boxes2[:, 0] + 1) * (boxes2[:, 3] - boxes2[:, 1] + 1)\n    overlaps = np.zeros((boxes1.shape[0], boxes2.shape[0]))\n    for i in range(boxes2.shape[0]):\n        xx1 = np.maximum(boxes1[:, 0], boxes2[i, 0])\n        yy1 = np.maximum(boxes1[:, 1], boxes2[i, 1])\n        xx2 = np.minimum(boxes1[:, 2], boxes2[i, 2])\n        yy2 = np.minimum(boxes1[:, 3], boxes2[i, 3])\n        w = np.maximum(0, xx2 - xx1 + 1)\n        h = np.maximum(0, yy2 - yy1 + 1)\n        inter = w * h\n        overlaps[:, i] = inter / (area1 + area2 - inter)\n    return overlaps\n\n", "CodeBleu_score": 40.02197369461242}, {"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    area1 = (boxes1[:, 2] - boxes1[:, 0] + 1) * (boxes1[:, 3] - boxes1[:, 1] + 1)\n    area2 = (boxes2[:, 2] - boxes2[:, 0] + 1) * (boxes2[:, 3] - boxes2[:, 1] + 1)\n    overlaps = np.zeros((boxes1.shape[0], boxes2.shape[0]))\n    for i in range(boxes2.shape[0]):\n        xx1 = np.maximum(boxes1[:, 0], boxes2[i, 0])\n        yy1 = np.maximum(boxes1[:, 1], boxes2[i, 1])\n        xx2 = np.minimum(boxes1[:, 2], boxes2[i, 2])\n        yy2 = np.minimum(boxes1[:, 3], boxes2[i, 3])\n        w = np.maximum(0.0, xx2 - xx1 + 1)\n        h = np.maximum(0.0, yy2 - yy1 + 1)\n        inter = w * h\n        overlaps[:, i] = inter / (area1 + area2 - inter)\n    return overlaps\n\n", "CodeBleu_score": 39.94666037869136}, {"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    area1 = (boxes1[:, 2] - boxes1[:, 0] + 1) * (boxes1[:, 3] - boxes1[:, 1] + 1)\n    area2 = (boxes2[:, 2] - boxes2[:, 0] + 1) * (boxes2[:, 3] - boxes2[:, 1] + 1)\n    overlaps = np.zeros((boxes1.shape[0], boxes2.shape[0]))\n    for i in range(overlaps.shape[1]):\n        x_min = np.maximum(boxes1[:, 0], boxes2[i, 0])\n        y_min = np.maximum(boxes1[:, 1], boxes2[i, 1])\n        x_max = np.minimum(boxes1[:, 2], boxes2[i, 2])\n        y_max = np.minimum(boxes1[:, 3], boxes2[i, 3])\n        w = np.maximum(0, x_max - x_min + 1)\n        h = np.maximum(0, y_max - y_min + 1)\n        inter = w * h\n        overlaps[:, i] = inter / (area1 + area2 - inter)\n    return overlaps\n\n", "CodeBleu_score": 40.578426642296186}]}
{"instance_id": "597533722ce3", "generation_result": [{"code": "def load_image(self, image_id):\n\t\n\n    info = self.image_info[image_id]\n    image = imread(info['path']).astype(np.uint8)\n    # if grayscale. Convert to RGB for consistency.\n    if image.ndim != 3:\n        image = gray2rgb(image)\n    # If has an alpha channel, remove it for consistency\n    if image.shape[-1] == 4:\n        image = image[..., :3]\n    return image\n\n", "CodeBleu_score": 73.02548054832194}, {"code": "def load_image(self, image_id):\n\t\n    image_info = self.image_info[image_id]\n    image = imread(image_info['path'])\n    if image.ndim == 2:\n        image = gray2rgb(image)\n    if image.shape[-1] == 4:\n        image = image[..., :3]\n    return image\n\n", "CodeBleu_score": 66.02377116232499}, {"code": "def load_image(self, image_id):\n\t\n    image_info = self.image_info[image_id]\n    image = imread(image_info['path'])\n    if image.ndim != 3:\n        image = gray2rgb(image)\n    if image.shape[-1] == 4:\n        image = image[..., :3]\n    return image", "CodeBleu_score": 70.84361351793534}]}
{"instance_id": "9b852997ca05", "generation_result": [{"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    assert((titles is None)or (len(images) == len(titles)))\n    n_images = len(images)\n    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n    fig = plt.figure()\n    for n, (image, title) in enumerate(zip(images, titles)):\n        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n        if image.ndim == 2:\n            plt.gray()\n        plt.imshow(image, cmap = cmap, norm = norm, interpolation=interpolation)\n        a.set_title(title)\n        plt.axis('off')\n    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n    plt.show()\n\n", "CodeBleu_score": 37.51127182421}, {"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    assert((titles is None)or (len(images) == len(titles)))\n    n_images = len(images)\n    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n    fig = plt.figure()\n    for n, (image, title) in enumerate(zip(images, titles)):\n        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n        if image.ndim == 2:\n            plt.gray()\n        plt.imshow(image, cmap = cmap, norm = norm, interpolation = interpolation)\n        a.set_title(title)\n        plt.axis(\"off\")\n    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n    plt.show()\n\n", "CodeBleu_score": 37.14233479233592}, {"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    assert((titles is None)or (len(images) == len(titles)))\n    n_images = len(images)\n    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n    fig = plt.figure()\n    for n, (image, title) in enumerate(zip(images, titles)):\n        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n        if image.ndim == 2:\n            plt.gray()\n        plt.imshow(image, cmap = cmap, norm = norm, interpolation = interpolation)\n        a.set_title(title)\n        plt.axis('off')\n    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n    plt.show()\n\n", "CodeBleu_score": 37.34884452383222}]}
