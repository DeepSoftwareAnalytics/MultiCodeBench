{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait_time = max(2, self.loop_wait - 2) * 1000\n    return wait_time, self._orig_kazoo_connect(*args)\n\n", "CodeBleu_score": 50.2273244970304}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait_time = max(2, self.loop_wait - 2) * 1000\n    return wait_time, self._orig_kazoo_connect(*args)\n\n", "CodeBleu_score": 50.2273244970304}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait, _ = self._orig_kazoo_connect(*args)\n    wait = max(2, self.loop_wait - 2) * 1000\n    return wait, _", "CodeBleu_score": 50.825559302819556}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n\n    if isinstance(config, dict):\n        config = Config(config)\n\n    self.set_retry_timeout(config['retry_timeout'])\n    self.set_loop_wait(config['loop_wait'])\n    if self.set_ttl(config['ttl']):\n        if self.loop_wait != config['loop_wait'] and isinstance(self.client_handler, PatroniSequentialThreadingHandler):\n            self.client_handler.connect_timeout = self.loop_wait", "CodeBleu_score": 44.70628194899406}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    self.set_retry_timeout(config)\n    self.loop_wait = config['loop_wait']\n    self.set_ttl(config)\n    if self.loop_wait != self.prev_loop_wait and isinstance(self.client_handler, PatroniSequentialThreadingHandler):\n        self.client_handler.connect_timeout = self.loop_wait\n    self.prev_loop_wait = self.loop_wait\n\n", "CodeBleu_score": 37.25326444897076}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, dict):\n        config = Config(config)\n    self.set_retry_timeout(config['loop_wait'])\n    self.set_ttl(config['ttl'])\n    if self.loop_wait != config['loop_wait'] and isinstance(self.client_handler, PatroniSequentialThreadingHandler):\n        self.client_handler.set_connect_timeout(config['loop_wait'])\n    if self.ttl != config['ttl'] and self.ttl is not None:\n        self.close()", "CodeBleu_score": 43.853165786659225}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(path)\n\n    # Load cluster initialization state\n    if self.get_children(path, \"initialize.json\"):\n        cluster.initialize = Initialize.from_node(self.get_node(path, \"initialize.json\"))\n\n    # Load cluster configuration\n    if self.get_children(path, \"config.json\"):\n        cluster.config = ClusterConfig.from_node(self.get_node(path, \"config.json\"))\n\n    # Load timeline history\n    if self.get_children(path, \"timeline.json\"):\n        cluster.timeline_history = TimelineHistory.from_node(self.get_node(path, \"timeline.json\"))\n\n    # Load synchronization state\n    if self.get_children(path, \"synchronization.json\"):\n        cluster.synchronization = SyncState.from_node(self.get_node(path, \"synchronization.json\"))\n\n    # Load members\n    if self.get_children(path, \"members.json\"):\n        cluster.members = self.load_members(self.get_node(path, \"members.json\"))\n\n    # Load leader information\n    if self.get_children(path, \"leader.json\"):\n        cluster.leader = Leader.from_node(self.get_node(path, \"leader.json\"))\n\n    # Load cluster status\n    if self.get_children(path, \"status.json\"):\n        cluster.status = self.get_status(self.get_node(path, \"status.json\"))\n\n    # Load failover state\n    if self.get_children(path, \"failover.json\"):\n        cluster.failover = Failover.from_node(self.get_node(path, \"failover.json\"))\n\n    # Load failsafe configuration\n    if self.get_children(path, \"failsafe.json\"):\n        cluster.failsafe = ClusterConfig.from_node(self.get_node(path, \"failsafe.json\"))\n\n    return cluster\n\n", "CodeBleu_score": 20.60477937689757}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    if not self.fs.exists(path):\n        raise Exception(f\"Path does not exist: {path}\")\n\n    cluster = Cluster(self.fs, self.executor)\n    cluster.path = path\n    cluster.name = self.fs.basename(path)\n\n    # load cluster initialization state\n    init_state_path = self.path.join(path, \"init_state.json\")\n    if self.fs.exists(init_state_path):\n        cluster.init_state = InitState.from_node(self.fs.read_file(init_state_path))\n\n    # load cluster configuration\n    config_path = self.path.join(path, \"config.json\")\n    if self.fs.exists(config_path):\n        cluster.config = ClusterConfig.from_node(self.fs.read_file(config_path))\n\n    # load timeline history\n    timeline_history_path = self.path.join(path, \"timeline_history.json\")\n    if self.fs.exists(timeline_history_path):\n        cluster.timeline_history = TimelineHistory.from_node(self.fs.read_file(timeline_history_path))\n\n    # load synchronization state\n    sync_state_path = self.path.join(path, \"sync_state.json\")\n    if self.fs.exists(sync_state_path):\n        cluster.sync_state = SyncState.from_node(self.fs.read_file(sync_state_path))\n\n    # load members\n    members_path = self.path.join(path, \"members\")\n    if self.fs.exists(members_path):\n        members = self.fs.get_children(members_path)\n        for member in members:\n            member_path = self.path.join(members_path, member)\n            member_node = self.fs.read_file(member_path)\n            member_obj = Member.from_node(member_node)\n            cluster.members[member_obj.name] = member_obj\n\n    # load leader information\n    leader_path = self.path.join(path,", "CodeBleu_score": 21.884218532619208}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster()\n\n    if os.path.exists(path):\n        # Load the initialization state\n        init_path = os.path.join(path, \"init\")\n        if os.path.exists(init_path):\n            cluster.init_state = self.get_node(init_path)\n\n        # Load the configuration\n        config_path = os.path.join(path, \"config\")\n        if os.path.exists(config_path):\n            cluster.config = self.get_node(config_path)\n\n        # Load the timeline history\n        timeline_history_path = os.path.join(path, \"timeline_history\")\n        if os.path.exists(timeline_history_path):\n            cluster.timeline_history = self.get_node(timeline_history_path)\n\n        # Load the synchronization state\n        sync_state_path = os.path.join(path, \"sync_state\")\n        if os.path.exists(sync_state_path):\n            cluster.sync_state = self.get_node(sync_state_path)\n\n        # Load the members\n        members_path = os.path.join(path, \"members\")\n        if os.path.exists(members_path):\n            cluster.members = self.get_node(members_path)\n\n        # Load the leader information\n        leader_path = os.path.join(path, \"leader\")\n        if os.path.exists(leader_path):\n            cluster.leader = self.get_node(leader_path)\n\n        # Load the cluster status\n        status_path = os.path.join(path, \"status\")\n        if os.path.exists(status_path):\n            cluster.status = self.get_node(status_path)\n\n        # Load the failover state\n        failover_path = os.path.join(path, \"failover\")\n        if os.path.exists(failover_path):\n            cluster.failover = self.get_node(failover_path)\n\n        # Load the failsafe configuration\n        failsafe_path = os.path.join(path, \"", "CodeBleu_score": 19.74146109593905}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n\n    try:\n        with self._zk_lock:\n            self._zk.create(\n                self._leader_path,\n                ephemeral=True,\n                makepath=True,\n            )\n            return True\n    except kazoo.exceptions.ConnectionLoss:\n        raise ZooKeeperError(\"Connection to ZooKeeper lost\")\n    except kazoo.exceptions.KazooException as e:\n        if isinstance(e, kazoo.exceptions.NodeExistsError):\n            # Another instance has the lock\n            return False\n        else:\n            logger.error(f\"Error acquiring leader lock: {e}\")\n            raise\n    except Exception as e:\n        logger.error(f\"Error acquiring leader lock: {e}\")\n        raise\n\n", "CodeBleu_score": 47.432104104710646}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n\n", "CodeBleu_score": 0.4807692307692308}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n\n", "CodeBleu_score": 0.4807692307692308}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self.client_id != leader.session:\n        logger.warning(\n            \"Client ID %s does not match leader session %s\",\n            self.client_id,\n            leader.session,\n        )\n        try:\n            self.client.delete(leader.path)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError):\n            pass\n        except Exception as e:\n            logger.error(\"Error deleting leader ZNode: %s\", e)\n            raise ZooKeeperError(e) from e\n        try:\n            self.client.create(\n                path=self.leader_path,\n                value=self.client_id.encode(\"utf-8\"),\n                ephemeral=True,\n                sequence=False,\n            )\n        except Exception as e:\n            logger.error(\"Error creating leader ZNode: %s\", e)\n            return False\n        return True\n\n", "CodeBleu_score": 46.166426774513134}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client_id != leader.session:\n        logger.warning(\n            \"Client ID mismatch: %s != %s\",\n            self._client_id,\n            leader.session,\n        )\n        try:\n            self._zk.delete(self._leader_path, recursive=True)\n        except NoNodeError:\n            pass\n        except (ConnectionClosedError, RetryFailedError) as e:\n            logger.warning(\"Ignoring error: %s\", e)\n        except Exception as e:\n            logger.error(\"Error deleting leader: %s\", e)\n            raise ZooKeeperError(e) from e\n\n    try:\n        self._zk.create(\n            self._leader_path,\n            self._client_id.encode(\"utf-8\"),\n            ephemeral=True,\n            makepath=True,\n        )\n    except (NodeExistsError, ConnectionClosedError, RetryFailedError) as e:\n        logger.warning(\"Ignoring error: %s\", e)\n    except Exception as e:\n        logger.error(\"Error creating leader: %s\", e)\n        raise ZooKeeperError(e) from e\n\n    return True\n\n", "CodeBleu_score": 59.306017732207984}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client_id != leader.session:\n        logger.warning(\n            \"Client ID does not match leader session. \"\n            \"Deleting leader ZNode %s\",\n            leader.path,\n        )\n        try:\n            self._zk.delete(leader.path)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError) as e:\n            logger.warning(\"Error deleting leader ZNode %s: %s\", leader.path, e)\n        except Exception as e:\n            logger.error(\"Error deleting leader ZNode %s: %s\", leader.path, e)\n            raise ZooKeeperError(e)\n\n    try:\n        self._zk.create(\n            path=leader.path,\n            value=self._client_id.encode(\"utf-8\"),\n            ephemeral=True,\n            makepath=True,\n        )\n    except (NodeExistsError, ConnectionClosedError, RetryFailedError) as e:\n        logger.warning(\"Error creating leader ZNode %s: %s\", leader.path, e)\n    except Exception as e:\n        logger.error(\"Error creating leader ZNode %s: %s\", leader.path, e)\n        raise ZooKeeperError(e)\n\n    return True\n\n", "CodeBleu_score": 55.653780998912694}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    if not self._join:\n        return False\n\n    if time.time() - self._last_poll < self._poll_interval:\n        return False\n\n    self._last_poll = time.time()\n    try:\n        exhibitors = self._query_exhibitors()\n    except Exception as e:\n        logger.info(\"Failed to query exhibitors: %s\", e)\n        return False\n\n    if not isinstance(exhibitors, list):\n        logger.info(\"Exhibitors is not a list: %s\", exhibitors)\n        return False\n\n    if len(exhibitors) == 0:\n        logger.info(\"No exhibitors found\")\n        return False\n\n    exhibitors = sorted(exhibitors)\n    connection_string = \",\".join(\n        [f\"{exhibitor['hostname']}:{exhibitor['port']}\" for exhibitor in exhibitors]\n    )\n    if self._zk_connection_string != connection_string:\n        logger.info(\n            \"ZooKeeper connection string changed from %s to %s\",\n            self._zk_connection_string,\n            connection_string,\n        )\n        self._zk_connection_string = connection_string\n        self._update_state()\n        return True\n\n    return False", "CodeBleu_score": 35.61755535046359}, {"code": "def poll(self) -> bool\n\t\n    if time.time() - self._last_poll_time < self._poll_interval:\n        return False\n\n    self._last_poll_time = time.time()\n\n    exhibitors = self._query_exhibitors()\n    if not exhibitors:\n        logger.info('No exhibitors found')\n        return False\n\n    exhibitors = sorted(exhibitors, key=lambda x: x['server'])\n    zk_connection_string = ','.join([f\"{x['server']}:{x['port']}\" for x in exhibitors])\n    if self._zk_connection_string != zk_connection_string:\n        logger.info(f'ZooKeeper connection string changed from {self._zk_connection_string} to {zk_connection_string}')\n        self._zk_connection_string = zk_connection_string\n        self._update_state()\n        return True\n\n    return False\n\n", "CodeBleu_score": 37.47613505831922}, {"code": "def poll(self) -> bool\n\t\n    if time.time() - self._last_poll < self._interval:\n        return False\n    self._last_poll = time.time()\n    exhibitors = self._query_exhibitors()\n    if not exhibitors:\n        return False\n    servers = [(e[\"host\"], e[\"port\"]) for e in exhibitors]\n    servers = sorted(servers)\n    if not servers:\n        return False\n    if servers != self._servers:\n        self._servers = servers\n        self._zk_connection = \",\".join([f\"{host}:{port}\" for host, port in servers])\n        logger.info(f\"ZooKeeper connection string changed to {self._zk_connection}\")\n        self._state = ZooKeeperState.CONNECTED\n        return True\n    return False", "CodeBleu_score": 37.99940208181635}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n\n    if self.ensemble_provider is not None:\n        self.ensemble_provider.update_hosts(self.hosts)\n\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 59.94592107019485}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n\n    if self.ensemble_provider is not None:\n        self.ensemble_provider.update_hosts(self.hosts)\n\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 59.94592107019485}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self.ensemble_provider:\n        self.update_hosts(self.ensemble_provider.get_hosts())\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 60.39742393427117}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 81.45633845775137}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 81.45633845775137}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 81.45633845775137}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t    if (zookeeperListener == null) {\n        return;\n    }\n    String group = getGroup();\n    String dataId = getDataId();\n    logUnsubscribeStarted(group, dataId);\n    try {\n        zookeeperListener.unsubscribe(group, dataId);\n    } catch (Throwable t) {\n        logUnsubscribeFailed(group, dataId);\n    }\n}", "CodeBleu_score": 75.62172236281135}, {"code": "public void destroy(){\n\t    if (zookeeperListener == null) {\n        return;\n    }\n    String group = getGroup();\n    String dataId = getDataId();\n    logUnsubscribeStarted(group, dataId);\n    try {\n        zookeeperListener.unsubscribe(group, dataId);\n    } catch (Exception e) {\n        logUnsubscribeFailed(group, dataId, e);\n    }\n}", "CodeBleu_score": 79.64320210940086}, {"code": "public void destroy(){\n\t    if (zookeeperListener != null) {\n        String group = getGroup();\n        String dataId = getDataId();\n        logUnsubscribeStarted(group, dataId);\n        try {\n            zookeeperListener.unsubscribe(group, dataId);\n        } catch (Exception e) {\n            logUnsubscribeFailed(group, dataId);\n        }\n    }\n}", "CodeBleu_score": 68.87032176899629}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zookeeperServer = (ZookeeperServer) server;\n        return zookeeperServer.getPayload().getMetadata();\n    } else {\n        return Collections.emptyMap();\n    }\n}", "CodeBleu_score": 65.8163826015736}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zkServer = (ZookeeperServer) server;\n        return zkServer.getPayload();\n    }\n    return Collections.emptyMap();\n}", "CodeBleu_score": 57.513534660890954}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zookeeperServer = (ZookeeperServer) server;\n        return zookeeperServer.getPayload().getMetadata();\n    }\n    return Collections.emptyMap();\n}", "CodeBleu_score": 67.15336074372748}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t    String path = String.format(ZOOKEEPER_CONFIG_PATH, group, serviceId);\n    NodeCache nodeCache = new NodeCache(zooKeeper, path);\n    nodeCache.start();\n\n    NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception {\n            String config = new String(nodeCache.getCurrentData().getData());\n            zookeeperSubscribeCallback.callback(config);\n        }\n    };\n    nodeCache.getListenable().addListener(nodeCacheListener);\n\n    ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n    zookeeperListeners.add(zookeeperListener);\n    return zookeeperListener;\n}", "CodeBleu_score": 69.03055334042904}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t    String path = String.format(ZOOKEEPER_CONFIG_PATH, group, serviceId);\n    NodeCache nodeCache = new NodeCache(curatorFramework, path, false);\n    nodeCache.start();\n\n    NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception {\n            String data = new String(nodeCache.getCurrentData().getData(), StandardCharsets.UTF_8);\n            Map<String, String> config = convertConfig(data);\n            zookeeperSubscribeCallback.callback(config);\n        }\n    };\n\n    ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n    zookeeperListener.addListener();\n    return zookeeperListener;\n}", "CodeBleu_score": 73.9795489946999}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t    String path = \"/\" + group + \"/\" + serviceId;\n    NodeCache nodeCache = new NodeCache(curatorFramework, path);\n    nodeCache.start();\n    NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception {\n            String data = new String(nodeCache.getCurrentData().getData(), StandardCharsets.UTF_8);\n            zookeeperSubscribeCallback.callback(data);\n        }\n    };\n    nodeCache.getListenable().addListener(nodeCacheListener);\n    ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n    listeners.add(zookeeperListener);\n    return zookeeperListener;\n}", "CodeBleu_score": 67.60132196595245}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    ZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery, config.getClientName());\n    serverList.initWithNiwsConfig(config);\n    serverList.setLoadBalanceListenerExecutor(config.getLoadBalanceListenerExecutor());\n    serverList.setServiceId(config.getClientName());\n    return serverList;\n}", "CodeBleu_score": 71.34404944162928}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    ZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery, config.getClientName());\n    serverList.initWithNiwsConfig(config);\n    serverList.setLoadBalanceListenerExecutor(this.loadBalanceListenerExecutor);\n    serverList.setServiceId(config.getClientName());\n    return serverList;\n}", "CodeBleu_score": 71.98830521408006}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    ServerList<?> serverList = new ZookeeperServerListDecorator(serviceDiscovery);\n    serverList.initWithNiwsConfig(config);\n    serverList.setLoadBalanceListenerExecutor(getLoadBalanceListenerExecutor());\n    serverList.setServiceId(getServiceId(config));\n    return serverList;\n}", "CodeBleu_score": 66.83760634456831}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor executor = getBean(RegisterListenerExecutor.class);\n        executor.onRegister(registration);\n    } catch (BeansException e) {\n        // ignore\n    }\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 64.50374947026486}, {"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        this.registerListenerExecutor.onRegister(registration);\n    }\n    catch (BeansException ex) {\n        // ignore\n    }\n    this.serviceRegistry.register(registration);\n}", "CodeBleu_score": 30.09881693790661}, {"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor executor = getBean(RegisterListenerExecutor.class);\n        executor.onRegister(registration);\n    } catch (BeansException e) {\n        logger.error(\"Error invoking RegisterListenerExecutor\", e);\n    } finally {\n        serviceRegistry.register(registration);\n    }\n}", "CodeBleu_score": 57.65779065870949}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        getBean(RegisterListenerExecutor.class).onDeregister(registration);\n    } catch (BeansException e) {\n        // Ignore\n    }\n    serviceRegistry.remove(registration);\n}", "CodeBleu_score": 43.91591914432626}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        getBean(RegisterListenerExecutor.class).onDeregister(registration);\n    } catch (BeansException e) {\n        // ignore\n    }\n    serviceRegistry.remove(registration.getServiceId());\n}", "CodeBleu_score": 38.66028396481303}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        getBean(RegisterListenerExecutor.class).onDeregister(registration);\n    } catch (BeansException e) {\n        // ignore\n    }\n    serviceRegistry.remove(registration.getId());\n}", "CodeBleu_score": 38.26878533744888}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\t    try {\n        RegisterListenerExecutor executor = getBean(RegisterListenerExecutor.class);\n        executor.onClose();\n    } catch (BeansException e) {\n        // ignore\n    }\n    serviceRegistry.close();\n}", "CodeBleu_score": 65.91671259919212}, {"code": "public void close(){\n\t    try {\n        RegisterListenerExecutor executor = getBean(RegisterListenerExecutor.class);\n        executor.onClose();\n    } catch (BeansException e) {\n        // ignore\n    } finally {\n        serviceRegistry.close();\n    }\n}", "CodeBleu_score": 63.63294594782052}, {"code": "public void close(){\n\t    try {\n        RegisterListenerExecutor executor = getBean(RegisterListenerExecutor.class);\n        executor.onClose();\n    } catch (BeansException e) {\n        // ignore\n    } finally {\n        serviceRegistry.close();\n    }\n}", "CodeBleu_score": 63.63294594782052}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = globalConfig ? \"SEATA_GROUP\" : getGroup();\n    String dataId = globalConfig ? \"file\" : getDataId();\n    logger.info(\"start subscribe config: {} {} {}\", group, dataId, getNamespace());\n    try {\n        return zookeeperOperation.subscribeDataChange(group, dataId, new DataChangeListener() {\n            @Override\n            public void dataChanged(String group, String dataId, String namespace, String data) {\n                if (logger.isInfoEnabled()) {\n                    logger.info(\"receive config info:\n{}\", data);\n                }\n                process(data);\n            }\n        });\n    } catch (Exception e) {\n        logger.error(\"subscribe config {} {} failed\", group, dataId, e);\n        return null;\n    }\n}", "CodeBleu_score": 43.459363823839055}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = globalConfig ? this.globalGroup : this.group;\n    String dataId = globalConfig ? this.globalDataId : this.dataId;\n    log.info(\"Starting to subscribe to config: group: {}, dataId: {}\", group, dataId);\n    try {\n        return zookeeperOperation.subscribe(group, dataId, new ConfigChangeListener() {\n            @Override\n            public void receiveConfigInfo(String configInfo) {\n                log.info(\"Received configInfo: {}\", configInfo);\n                if (StringUtils.isEmpty(configInfo)) {\n                    log.warn(\"Ignored empty configInfo\");\n                    return;\n                }\n                try {\n                    ConfigChangeEvent changeEvent = ConfigChangeEvent.fromJson(configInfo);\n                    if (changeEvent.isChanged()) {\n                        log.info(\"Config has changed. group: {}, dataId: {}, oldValue: {}, newValue: {}, changes: {}\", group, dataId, changeEvent.getOldValue(), changeEvent.getNewValue(), changeEvent.getChangeType());\n                        refreshConfig(changeEvent);\n                    } else {\n                        log.info(\"Config has not changed. group: {}, dataId: {}, oldValue: {}, newValue: {}, changes: {}\", group, dataId, changeEvent.getOldValue(), changeEvent.getNewValue(), changeEvent.getChangeType());\n                    }\n                } catch (Exception e) {\n                    log.error(\"Failed to parse configInfo: {}\", configInfo, e);\n                }\n            }\n        });\n    } catch (Exception e) {\n        log.error(\"Failed to subscribe to config: group: {}, dataId: {}\", group, dataId, e);\n        return null;\n    }\n}", "CodeBleu_score": 38.36772412343176}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = globalConfig ? \"SEATA_GROUP\" : groupId;\n    String dataId = globalConfig ? \"seata\" : applicationId;\n    try {\n        LOGGER.info(\"Start to subscribe config: {} {}\", group, dataId);\n        return (ZookeeperListener) zookeeperOperation.subscribeConfig(group, dataId, new ZookeeperListener() {\n            @Override\n            public void receiveConfigInfo(String configInfo) {\n                LOGGER.info(\"Received config info: {} {}\", group, configInfo);\n                updateConfig(configInfo, globalConfig);\n            }\n        });\n    } catch (Exception e) {\n        LOGGER.error(\"Failed to subscribe config: {} {}\", group, dataId, e);\n        return null;\n    }\n}", "CodeBleu_score": 50.442772160553794}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t    String connectString = getProperty(\"zookeeper.connect\");\n    if (isEmpty(connectString)) {\n        throw new DiscoveryException(\"zookeeper.connect is empty\");\n    }\n    int retryCount = Integer.parseInt(getProperty(\"zookeeper.retry.count\"));\n    int retrySleep = Integer.parseInt(getProperty(\"zookeeper.retry.sleep\"));\n    RetryPolicy retryPolicy = new ExponentialBackoffRetry(retrySleep, retryCount);\n    CuratorFramework client = CuratorFrameworkFactory.builder()\n            .connectString(connectString)\n            .retryPolicy(retryPolicy)\n            .build();\n    client.start();\n    return client;\n}", "CodeBleu_score": 39.48337225877314}, {"code": "public CuratorFramework curatorFramework(){\n\t    String connectString = getProperty(ZK_CONNECT_STRING);\n    if (StringUtils.isEmpty(connectString)) {\n        throw new DiscoveryException(\"Zookeeper connection string is empty\");\n    }\n\n    int retryCount = Integer.parseInt(getProperty(ZK_RETRY_COUNT));\n    int sleepTime = Integer.parseInt(getProperty(ZK_SLEEP_TIME));\n\n    RetryPolicy retryPolicy = new ExponentialBackoffRetry(sleepTime, retryCount);\n\n    CuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n            .connectString(connectString)\n            .retryPolicy(retryPolicy)\n            .build();\n\n    curatorFramework.start();\n    return curatorFramework;\n}", "CodeBleu_score": 47.305673897616316}, {"code": "public CuratorFramework curatorFramework(){\n\t    String connectString = System.getenv(\"ZOOKEEPER_CONNECT_STRING\");\n    if (connectString == null || connectString.isEmpty()) {\n        throw new DiscoveryException(\"ZOOKEEPER_CONNECT_STRING is empty\");\n    }\n    int retryCount = Integer.parseInt(System.getenv(\"ZOOKEEPER_RETRY_COUNT\"));\n    int sleepTime = Integer.parseInt(System.getenv(\"ZOOKEEPER_SLEEP_TIME\"));\n    RetryPolicy retryPolicy = new ExponentialBackoffRetry(sleepTime, retryCount);\n    CuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n            .connectString(connectString)\n            .retryPolicy(retryPolicy)\n            .build();\n    curatorFramework.start();\n    return curatorFramework;\n}", "CodeBleu_score": 45.5482841170641}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n    @Bean\n    @ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n    public GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(ZookeeperClient zookeeperClient,\n            ZookeeperDiscoveryProperties zookeeperDiscoveryProperties, ZookeeperDiscoveryStrategyProperties zookeeperDiscoveryStrategyProperties,\n            ZookeeperDiscoveryLocatorProperties zookeeperDiscoveryLocatorProperties) {\n        return new GatewayStrategyRouteZookeeperProcessor(zookeeperClient, zookeeperDiscoveryProperties,\n                zookeeperDiscoveryStrategyProperties, zookeeperDiscoveryLocatorProperties);\n    }\n\n}", "CodeBleu_score": 40.15790114366086}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 1.394537427031336}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 1.394537427031336}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t    CuratorFramework curatorFramework = CuratorFrameworkFactory.builder().namespace(getNamespace()).connectString(getZkHosts()).retryPolicy(retryPolicy).sessionTimeoutMs(getSessionTimeout()).build();\n    curatorFramework.start();\n    return curatorFramework;\n}", "CodeBleu_score": 41.021443118798615}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t    CuratorFramework client = CuratorFrameworkFactory.builder().namespace(getNamespace()).connectString(getZkHosts()).sessionTimeoutMs(getSessionTimeout()).retryPolicy(retryPolicy()).build();\n    client.start();\n    return client;\n}", "CodeBleu_score": 33.897044463904955}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t    CuratorFramework curatorFramework = CuratorFrameworkFactory.builder().namespace(getNamespace()).retryPolicy(retryPolicy).connectString(connectString).build();\n    curatorFramework.start();\n    return curatorFramework;\n}", "CodeBleu_score": 35.6215843816941}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\t    InterProcessMutex lock = locksMap.get(path);\n    if (lock == null) {\n        lock = new InterProcessMutex(getZkCleint(), path);\n        locksMap.put(path, lock);\n    }\n    try {\n        lock.acquire();\n    } catch (Exception e) {\n        throw new DistributedLockException(\"Error acquiring lock for path \" + path, e);\n    }\n}", "CodeBleu_score": 30.785710459107165}, {"code": "public void lock(String path) throws DistributedLockException{\n\t    InterProcessMutex lock = locksMap.get(path);\n    if (lock == null) {\n        lock = new InterProcessMutex(getZkCleint(), path);\n        locksMap.put(path, lock);\n    }\n    try {\n        lock.acquire();\n    } catch (Exception e) {\n        throw new DistributedLockException(\"Error acquiring lock for path: \" + path, e);\n    }\n}", "CodeBleu_score": 30.810199499065718}, {"code": "public void lock(String path) throws DistributedLockException{\n\t    InterProcessMutex lock = locksMap.get(path);\n    if (lock == null) {\n        lock = new InterProcessMutex(getZkCleint(), path);\n        locksMap.put(path, lock);\n    }\n    try {\n        lock.acquire();\n    } catch (Exception e) {\n        throw new DistributedLockException(\"Error acquiring lock for path \" + path, e);\n    }\n}", "CodeBleu_score": 30.785710459107165}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    CuratorFramework client = getCuratorFramework(dtpProperties);\n    String nodePath = getNodePath(dtpProperties);\n    if (DtpProperties.ConfigType.PROPERTIES.equals(dtpProperties.getConfigType())) {\n        return genPropertiesTypeMap(client, nodePath);\n    } else {\n        String configKey = getConfigKey(dtpProperties);\n        String value = getVal(client, nodePath + configKey);\n        return ConfigHandler.parseConfig(value);\n    }\n}", "CodeBleu_score": 34.64916969555117}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    CuratorFramework client = getCuratorFramework(dtpProperties);\n    String nodePath = getZookeeper().getNodePath();\n    if (ConfigType.PROPERTIES.equals(dtpProperties.getConfigType())) {\n        return genPropertiesTypeMap(client, nodePath);\n    } else {\n        String configKey = getConfigKey(dtpProperties);\n        String value = getVal(client, nodePath, configKey);\n        return ConfigHandler.parseConfig(value, dtpProperties.getConfigType());\n    }\n}", "CodeBleu_score": 37.85194215935262}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    CuratorFramework client = getCuratorFramework();\n    String nodePath = getZookeeper().getNodePath();\n    if (DtpProperties.ConfigType.PROPERTIES.equals(dtpProperties.getConfigType())) {\n        return genPropertiesTypeMap(client, nodePath);\n    }\n    String configKey = getConfigKey(dtpProperties);\n    String value = getVal(client, nodePath + configKey);\n    return ConfigHandler.parseConfig(value, dtpProperties);\n}", "CodeBleu_score": 34.37544951885847}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t    DtpProperties dtpProperties = DtpProperties.getInstance();\n    Binder.get(environment).bind(DtpProperties.PREFIX, Bindable.ofInstance(dtpProperties));\n    Map<String, Object> properties = genPropertiesMap(dtpProperties);\n    checkPropertyExist(environment, properties);\n    createZkPropertySource(environment, properties);\n}", "CodeBleu_score": 60.07382868600892}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t    DtpProperties dtpProperties = DtpProperties.bindDtpProperties(environment);\n    Map<String, Object> propertiesMap = genPropertiesMap(dtpProperties);\n    checkPropertyExist(environment, propertiesMap);\n    createZkPropertySource(environment, propertiesMap);\n}", "CodeBleu_score": 53.67106714919163}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t    DtpProperties dtpProperties = DtpProperties.getInstance();\n    // Bind the DtpProperties instance with the current environment\n    Binder.get(environment).bind(DtpProperties.PREFIX, Bindable.ofInstance(dtpProperties));\n    // Generate a properties map from DtpProperties\n    Map<String, Object> properties = genPropertiesMap(dtpProperties);\n    // Check if the required property exists in the environment\n    checkPropertyExist(environment, properties);\n    // Create a Zookeeper property source with the generated properties\n    createZkPropertySource(environment, properties);\n}", "CodeBleu_score": 60.07382868600892}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    var serializer = configInfo.Config.GetSerializer();\n    builder.Register(provider => {\n        var logger = provider.GetRequiredService<ILogger<ZooKeeperServiceRouteManager>>();\n        var byteSerializer = provider.GetRequiredService<ISerializer<byte[]>>();\n        var routeFactory = provider.GetRequiredService<IServiceRouteFactory>();\n        var stringSerializer = provider.GetRequiredService<ISerializer<string>>();\n        var zooKeeperClientProvider = provider.GetRequiredService<IZookeeperClientProvider>();\n        return new ZooKeeperServiceRouteManager(\n            logger,\n            byteSerializer,\n            routeFactory,\n            stringSerializer,\n            zooKeeperClientProvider,\n            configInfo.ZooKeeper,\n            configInfo.Config.GetServiceRoute()\n        );\n    }).As<IServiceRouteManager>().SingleInstance();\n    return this;\n}", "CodeBleu_score": 46.94603047955718}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    builder.Register(provider => {\n        var logger = provider.GetRequiredService<ILogger<ZooKeeperServiceRouteManager>>();\n        var byteSerializer = provider.GetRequiredService<ISerializer<byte[]>>();\n        var stringSerializer = provider.GetRequiredService<ISerializer<string>>();\n        var routeFactory = provider.GetRequiredService<IServiceRouteFactory>();\n        var zookeeperClientProvider = provider.GetRequiredService<IZookeeperClientProvider>();\n        return new ZooKeeperServiceRouteManager(\n            configInfo.GetValue<string>(\"Zookeeper:ServiceRootPath\"),\n            byteSerializer,\n            stringSerializer,\n            routeFactory,\n            logger,\n            zookeeperClientProvider);\n    }).As<IServiceRouteManager>().SingleInstance();\n    return this;\n}", "CodeBleu_score": 47.89933766819415}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    builder.Register(provider => {\n        var logger = provider.GetRequiredService<ILogger<ZooKeeperServiceRouteManager>>();\n        var serializer = provider.GetRequiredService<ISerializer<byte[]>>();\n        var factory = provider.GetRequiredService<IServiceRouteFactory>();\n        var stringSerializer = provider.GetRequiredService<ISerializer<string>>();\n        var zookeeperClientProvider = provider.GetRequiredService<IZookeeperClientProvider>();\n        return new ZooKeeperServiceRouteManager(logger, serializer, factory, stringSerializer, zookeeperClientProvider, configInfo.RoutePath);\n    }).As<IServiceRouteManager>().SingleInstance();\n    return this;\n}", "CodeBleu_score": 47.18571220661582}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t        var commandManager = new ZookeeperServiceCommandManager(\n            builder.GetConfiguration(),\n            builder.GetRequiredService<ISerializer<byte[]>>(),\n            builder.GetRequiredService<ISerializer<string>>(),\n            builder.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(),\n            builder.GetRequiredService<IServiceRouteManager>(),\n            builder.GetRequiredService<IZookeeperClientProvider>()\n        );\n        builder.AddSingleton<IServiceCommandManager>(commandManager);\n        return this;\n    }", "CodeBleu_score": 47.59972042152882}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t            builder.RegisterType<ZookeeperServiceCommandManager>().As<IServiceCommandManager>().SingleInstance();\n            builder.RegisterType<ZookeeperServiceCommandManager>().As<IZookeeperServiceCommandManager>().SingleInstance();\n            return this;\n        }", "CodeBleu_score": 37.04329353947152}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t            if (builder == null) {\n                throw new ArgumentNullException(nameof(builder));\n            }\n\n            if (configInfo == null) {\n                throw new ArgumentNullException(nameof(configInfo));\n            }\n\n            builder.Register(provider => {\n                var clientProvider = provider.GetRequiredService<IZookeeperClientProvider>();\n                var routeManager = provider.GetRequiredService<IServiceRouteManager>();\n                var logger = provider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>();\n                var serializer = provider.GetRequiredService<ISerializer<string>>();\n                var entryManager = provider.GetRequiredService<IServiceEntryManager>();\n                var configInfo = provider.GetRequiredService<ConfigInfo>();\n                return new ZookeeperServiceCommandManager(clientProvider, routeManager, logger, serializer, entryManager, configInfo);\n            }).As<IServiceCommandManager>().SingleInstance();\n            return this;\n        }", "CodeBleu_score": 50.83741577338808}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    Check.NotNull(builder, \"builder\");\n    Check.CheckCondition(!string.IsNullOrEmpty(path), \"path\");\n    if (provider == null && Path.IsPathRooted(path)) {\n        provider = new PhysicalFileProvider(Path.GetDirectoryName(path), ExclusionFilters.Sensitive);\n        path = Path.GetFileName(path);\n    }\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    };\n    source.ResolveFileProvider();\n    builder.Add(source);\n    builder.Build();\n    return builder;\n}", "CodeBleu_score": 77.87355026037787}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    Check.NotNull(builder, nameof(builder));\n    Check.CheckCondition(!string.IsNullOrEmpty(path), nameof(path));\n    if (provider == null && Path.IsPathRooted(path)) {\n        provider = new PhysicalFileProvider(Path.GetDirectoryName(path), ExcludeDirectoriesFilter);\n        path = Path.GetFileName(path);\n    }\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    };\n    source.ResolveFileProvider();\n    builder.Add(source);\n    builder.Build();\n    return builder;\n}", "CodeBleu_score": 75.08948975767042}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    Check.NotNull(builder, nameof(builder));\n    Check.CheckCondition(!string.IsNullOrEmpty(path), nameof(path));\n    if (provider == null && Path.IsPathRooted(path)) {\n        provider = new PhysicalFileProvider(Path.GetDirectoryName(path), ExclusionFilters.None);\n    }\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    };\n    source.ResolveFileProvider();\n    builder.Add(source);\n    builder.Build();\n    return builder;\n}", "CodeBleu_score": 70.70243839650483}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t    var routes = await GetRoutesAsync();\n    foreach (var route in routes) {\n        route.Address = route.Address.Except(Address);\n    }\n    await base.SetRoutesAsync(routes);\n}", "CodeBleu_score": 90.60628261290408}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t    var routes = await GetRoutesAsync();\n    foreach (var route in routes) {\n        route.Address = route.Address.Except(Address);\n    }\n    await SetRoutesAsync(routes);\n}", "CodeBleu_score": 81.59209605417736}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t    var routes = await GetRoutesAsync();\n    foreach (var route in routes) {\n        route.Address = route.Address.Except(Address).ToList();\n    }\n    await base.SetRoutesAsync(routes);\n}", "CodeBleu_score": 82.20395302250901}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t  var path = GetServicePath(_serviceName);\n  var addresses = _zookeeperClientProvider.GetZooKeepers();\n  foreach (var zooKeeper in addresses) {\n    var oldRoutes = await GetRoutesAsync(zooKeeper.Item2, path);\n    var oldRouteIds = oldRoutes.Select(i => i.ServiceDescriptor.Id).ToArray();\n    var newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n    var deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n    foreach (var deletedRouteId in deletedRouteIds) {\n      var deletedRouteAddress = routes.Where(p => p.ServiceDescriptor.Id == deletedRouteId).Select(p => p.Address).FirstOrDefault();\n      if (deletedRouteAddress != null && deletedRouteAddress.Contains(hostAddr)) {\n        await zooKeeper.Item2.deleteAsync(path + \"/\" + deletedRouteId);\n      }\n    }\n  }\n}", "CodeBleu_score": 54.81953697553141}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var path = _zookeeperClientProvider.GetServiceRoutePath();\n    var zooKeeper = _zookeeperClientProvider.GetZooKeepers();\n    var newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n    foreach (var zooKeeperClient in zooKeeper) {\n        var oldRoutes = await zooKeeperClient.Item1.getChildrenAsync(path);\n        var oldRouteIds = oldRoutes.Children.Select(i => i.Split('-')[0]).ToArray();\n        var deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n        foreach (var deletedRouteId in deletedRouteIds) {\n            var addresses = await zooKeeperClient.Item1.getChildrenAsync(path + \"/\" + deletedRouteId);\n            var address = addresses.Children.Select(i => i.Split('-')[0]).FirstOrDefault(i => i.Contains(hostAddr.Host));\n            if (address != null) {\n                await zooKeeperClient.Item2.deleteAsync(path + \"/\" + deletedRouteId + \"/\" + address);\n            }\n        }\n    }\n}", "CodeBleu_score": 50.26752679221611}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var path = $\"{_options.ZookeeperRootNode}/{_options.ServiceName}\";\n    var addresses = _zookeeperClientProvider.GetZooKeepers();\n    foreach (var zooKeeper in addresses) {\n        var oldRoutes = await zooKeeper.Item1.getChildrenAsync(path);\n        var oldRouteIds = oldRoutes.Children.Select(i => i.Split('-')[0]).ToArray();\n        var newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n        var deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n        foreach (var deletedRouteId in deletedRouteIds) {\n            var routeAddress = routes.Where(p => p.ServiceDescriptor.Id == deletedRouteId).Select(p => p.Address).FirstOrDefault();\n            if (addresses.Contains(routeAddress)) {\n                var deletePath = $\"{path}/{deletedRouteId}-{routeAddress}\";\n                await zooKeeper.Item2.deleteAsync(deletePath);\n            }\n        }\n    }\n}", "CodeBleu_score": 56.901156565392}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t            if (data == null) {\n                return null;\n            }\n\n            if (_logger.IsEnabled(LogLevel.Debug)) {\n                _logger.LogDebug($\"Getting route from {\n                    Encoding.UTF8.GetString(data)}.\");\n            }\n\n            var descriptor = JsonConvert.DeserializeObject<ServiceRouteDescriptor>(\n                Encoding.UTF8.GetString(data));\n            return (await _serviceRouteFactory.CreateServiceRoutesAsync(new[] { descriptor })).First();\n        }", "CodeBleu_score": 50.572480576218425}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    _logger.LogDebug($\"Getting route from {\n        Encoding.UTF8.GetString(data)\n    }\");\n\n    if (data == null) {\n        return null;\n    }\n\n    var descriptor = JsonSerializer.Deserialize<ServiceRouteDescriptor>(\n        Encoding.UTF8.GetString(data)\n    );\n\n    return (await _serviceRouteFactory.CreateServiceRoutesAsync(\n        new[] { descriptor }\n    )).First();\n}", "CodeBleu_score": 43.15983810439782}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t            if (data == null)\n                return null;\n\n            if (_logger.IsEnabled(LogLevel.Debug))\n                _logger.LogDebug($\"{nameof(GetRoute)}: {Encoding.UTF8.GetString(data)}\");\n\n            var descriptor = _serializer.Deserialize<ServiceRouteDescriptor>(data);\n            return (await _serviceRouteFactory.CreateServiceRoutesAsync(new[] { descriptor })).First();\n        }", "CodeBleu_score": 55.7632389557429}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    if (DataEquals(oldData, newData)) {\n        return;\n    }\n\n    var newRoute = DeserializeRoute(newData);\n    Route oldRoute = null;\n    lock (_routes) {\n        oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id);\n        _routes = _routes.Where(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id)\n            .Concat(new[] { newRoute }).ToArray();\n    }\n\n    await OnChanged(newRoute, oldRoute);\n}", "CodeBleu_score": 66.50598882950193}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    if (DataEquals(oldData, newData)) {\n        return;\n    }\n    var newRoute = GetRoute(newData);\n    Route oldRoute;\n    lock (_routes) {\n        oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id);\n        _routes = _routes.Where(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id)\n            .Concat(new[] { newRoute }).ToArray();\n    }\n    await OnChanged(newRoute, oldRoute);\n}", "CodeBleu_score": 66.3831471863082}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    if (DataEquals(oldData, newData)) {\n        return;\n    }\n\n    var newRoute = JsonSerializer.Deserialize<Route>(newData);\n\n    lock (_routes) {\n        _routes = _routes.Where(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id)\n            .Concat(new[] { newRoute }).ToArray();\n    }\n\n    await OnChanged(newRoute, oldData.Length == 0 ? null : JsonSerializer.Deserialize<Route>(oldData));\n}", "CodeBleu_score": 63.63710088759345}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    var serviceSubscribers = await GetSubscribers();\n    foreach (var subscriber in subscribers) {\n        var serviceSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n        if (serviceSubscriber != null) {\n            serviceSubscriber.Address = serviceSubscriber.Address.Concat(subscriber.Address.Except(serviceSubscriber.Address)).ToList();\n        } else {\n            serviceSubscribers.Add(subscriber);\n        }\n    }\n    await base.SetSubscribersAsync(serviceSubscribers);\n}", "CodeBleu_score": 73.99288567070177}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    var serviceSubscribers = await GetSubscribers();\n\n    foreach (var subscriber in subscribers) {\n        var existingSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n\n        if (existingSubscriber != null) {\n            existingSubscriber.Address = existingSubscriber.Address.Concat(subscriber.Address.Except(existingSubscriber.Address)).ToList();\n        } else {\n            serviceSubscribers.Add(subscriber);\n        }\n    }\n\n    await base.SetSubscribersAsync(serviceSubscribers);\n}", "CodeBleu_score": 68.98967018469247}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    var serviceSubscribers = await GetSubscribers();\n    foreach (var subscriber in subscribers) {\n        var existingSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n        if (existingSubscriber != null) {\n            existingSubscriber.Address = existingSubscriber.Address.Concat(subscriber.Address.Except(existingSubscriber.Address)).ToList();\n        }\n    }\n    await base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 69.01641219996621}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t  \n_logger.IsEnabled\n }", "CodeBleu_score": 5.499126387950158}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t    var rootPath = _configuration.GetValue<string>(\"ServiceDiscovery:ServiceSubscribersPath\");\n    if (_logger.IsEnabled(LogLevel.Debug))\n        _logger.LogDebug(\"Getting subscribers for childrens: {Childrens}\", childrens);\n\n    var subscribers = new List<ServiceSubscriber>();\n\n    foreach (var child in childrens) {\n        var nodePath = $\"{rootPath}/{child}\";\n        var subscriber = await _consulClient.GetKVPairAsync<ServiceSubscriber>(nodePath);\n        subscribers.Add(subscriber.Response.Value);\n    }\n\n    return subscribers.ToArray();\n}", "CodeBleu_score": 46.446421637124345}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t    var rootPath = _options.RootPath + \"/subscribers\";\n    if (_logger.IsEnabled(LogLevel.Debug)) {\n        _logger.LogDebug($\"Getting subscribers for children: {string.Join(\", \", childrens)}\");\n    }\n    var subscribers = new List<ServiceSubscriber>();\n    foreach (var child in childrens) {\n        var fullPath = rootPath + \"/\" + child;\n        var subscriber = await _client.GetAsync<ServiceSubscriber>(fullPath);\n        subscribers.Add(subscriber);\n    }\n    return subscribers.ToArray();\n}", "CodeBleu_score": 45.32673286940139}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null) return;\n    var zooKeeper = GetZooKeeper();\n    await zooKeeper.Item2.existsAsync(SubscriberPath);\n    var result = await zooKeeper.Item2.getChildrenAsync(SubscriberPath);\n    if (result.Children != null) {\n        _subscribers = result.Children.ToArray();\n        _logger.LogInformation($\"Subscribers: {string.Join(',', _subscribers)}\");\n    }\n    else {\n        _logger.LogWarning(\"Subscribers path does not exist\");\n        _subscribers = Array.Empty<string>();\n    }\n}", "CodeBleu_score": 48.05210754667383}, {"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null) return;\n\n    var zooKeeper = await GetZooKeeper();\n\n    var result = await zooKeeper.Item2.existsAsync($\"/{_subscriberPath}\");\n\n    if (result.Exists) {\n        var children = await zooKeeper.Item2.getChildrenAsync($\"/{_subscriberPath}\");\n        _subscribers = children.Children.ToArray();\n    } else {\n        _logger.LogWarning($\"Subscriber path {_subscriberPath} does not exist.\");\n        _subscribers = Array.Empty<string>();\n    }\n}", "CodeBleu_score": 48.78742279745853}, {"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null) {\n        return;\n    }\n\n    var zooKeeper = await GetZooKeeper();\n    await zooKeeper.Item1.WaitOneAsync();\n\n    if (await zooKeeper.Item2.existsAsync(SubscriberPath) != null) {\n        var result = await zooKeeper.Item2.getChildrenAsync(SubscriberPath);\n        _subscribers = result.Children.ToArray();\n    } else {\n        _logger.LogWarning(\"Subscriber path {path} does not exist\", SubscriberPath);\n        _subscribers = Array.Empty<string>();\n    }\n}", "CodeBleu_score": 51.8586283384323}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t    if (oldData != null && newData != null && !oldData.DataEquals(newData)) {\n        var oldCommand = GetServiceCommand(oldData);\n        var newCommand = GetServiceCommand(newData);\n        if (oldCommand != null && newCommand != null && oldCommand.ServiceId != newCommand.ServiceId) {\n            ServiceCommands = ServiceCommands.Where(i => i.ServiceId != newCommand.ServiceId)\n                .Concat(new[] { newCommand }).ToArray();\n        }\n        OnChanged?.Invoke(this, newCommand, oldCommand);\n    }\n}", "CodeBleu_score": 63.13239662460718}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t    // Check if the old and new data are different.\n    if (!DataEquals(oldData, newData)) {\n        // Retrieve the new service command.\n        var newCommand = GetServiceCommand(newData);\n        // Update the service commands list.\n        if (ServiceCommands.Any(i => i.ServiceId == newCommand.ServiceId)) {\n            ServiceCommands = ServiceCommands.Where(i => i.ServiceId != newCommand.ServiceId)\n                .Concat(new[] { newCommand }).ToArray();\n        }\n        // Trigger the OnChanged event.\n        OnChanged?.Invoke(this, new CommandsChangeEventArgs(newCommand, ServiceCommands.FirstOrDefault(i => i.ServiceId == newCommand.ServiceId)));\n    }\n}", "CodeBleu_score": 64.55651724161294}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t    if (oldData.Length != newData.Length) {\n        return;\n    }\n    if (!oldData.SequenceEqual(newData)) {\n        var oldCommand = new ServiceCommand(oldData);\n        var newCommand = new ServiceCommand(newData);\n        if (oldCommand.ServiceId != newCommand.ServiceId) {\n            return;\n        }\n        if (oldCommand.DataEquals(newCommand)) {\n            return;\n        }\n        ServiceCommands = ServiceCommands.Where(i => i.ServiceId != newCommand.ServiceId)\n            .Concat(new[] { newCommand }).ToArray();\n        OnChanged(newCommand, oldCommand);\n    }\n}", "CodeBleu_score": 62.786728193207445}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    var currentData = await zooKeeper.Item2.getDataAsync(watchedEvent.get_Path());\n    action(currentData, watchedEvent.get_CurrentData());\n    watcher.SetCurrentData(currentData);\n}", "CodeBleu_score": 16.493624352374965}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    if (watchedEvent.get_Type() == Event.EventType.NodeDataChanged) {\n        try {\n            byte[] data = await zooKeeper.Item2.getDataAsync(watchedEvent.getPath(), false);\n            _action(watcher.CurrentData, data);\n            watcher.SetCurrentData(data);\n        } catch (KeeperException e) {\n            if (e.getCode() != KeeperException.Code.NoNode) {\n                throw;\n            }\n        }\n    }\n}", "CodeBleu_score": 51.854826088453834}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    var currentData = await _zooKeeperCall(async (zooKeeper) => {\n        var currentData = await zooKeeper.GetDataAsync(watchedEvent.get_Path());\n        return currentData;\n    });\n    _action(watchedEvent.get_CurrentData(), currentData);\n    _watcher.SetCurrentData(currentData);\n}", "CodeBleu_score": 21.297829449800503}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    builder.Services.Register(provider =>\n        new DefaultZookeeperClientProvider(\n            GetConfigInfo(configInfo),\n            provider.Resolve<IHealthCheckService>(),\n            provider.Resolve<IZookeeperAddressSelector>(),\n            provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance;\n    return builder;\n}", "CodeBleu_score": 68.19621835597654}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    builder.Services.Register(provider =>\n        new DefaultZookeeperClientProvider(\n            GetConfigInfo(configInfo),\n            provider.Resolve<IHealthCheckService>(),\n            provider.Resolve<IZookeeperAddressSelector>(),\n            provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance;\n    return builder;\n}", "CodeBleu_score": 68.19621835597654}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    builder.Services.Register(provider =>\n       new DefaultZookeeperClientProvider(\n           GetConfigInfo(configInfo),\n        provider.Resolve<IHealthCheckService>(),\n          provider.Resolve<IZookeeperAddressSelector>(),\n          provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance;\n    return builder;\n}", "CodeBleu_score": 68.77248215881002}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t    var zooKeeperClients = await _zookeeperProvider.GetZooKeepers();\n    foreach (var zooKeeperClient in zooKeeperClients) {\n        var nodePath = _config.ZooKeeperRoutePath;\n        if (await zooKeeperClient.ExistsAsync(nodePath) == null) {\n            await zooKeeperClient.CreateAsync(nodePath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n        }\n        foreach (var route in routes) {\n            var routePath = $\"{nodePath}/{route.Id}\";\n            var routeData = JsonSerializer.SerializeToUtf8Bytes(route);\n            if (await zooKeeperClient.ExistsAsync(routePath) == null) {\n                await zooKeeperClient.CreateAsync(routePath, routeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n                _logger.LogInformation(\"\u6dfb\u52a0\u8def\u7531\uff1a{routePath}\", routePath);\n            } else {\n                await zooKeeperClient.SetDataAsync(routePath, routeData);\n                _logger.LogInformation(\"\u66f4\u65b0\u8def\u7531\uff1a{routePath}\", routePath);\n            }\n        }\n        _logger.LogInformation(\"\u6210\u529f\u6dfb\u52a0\u8def\u7531\uff1a{nodePath}\", nodePath);\n    }\n}", "CodeBleu_score": 46.820561834424055}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t  var zooKeepers = _zookeeperProvider.GetZooKeepers();\n  foreach (var zooKeeper in zooKeepers) {\n    var nodePath = _configuration.GetServiceRoutePath();\n    if (await zooKeeper.ExistsAsync(nodePath) == null) {\n      _logger.LogInformation($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\uff0c\u6b63\u5728\u521b\u5efa...\");\n      await zooKeeper.CreateRecursiveAsync(nodePath, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n    }\n\n    foreach (var route in routes) {\n      var routePath = $\"{nodePath}/{route.Id}\";\n      var routeData = route.Serialize();\n      if (await zooKeeper.ExistsAsync(routePath) == null) {\n        _logger.LogInformation($\"\u8282\u70b9\uff1a{routePath}\u4e0d\u5b58\u5728\uff0c\u6b63\u5728\u521b\u5efa...\");\n        await zooKeeper.CreateAsync(routePath, routeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n      } else {\n        _logger.LogInformation($\"\u8282\u70b9\uff1a{routePath}\u5df2\u5b58\u5728\uff0c\u6b63\u5728\u66f4\u65b0...\");\n        await zooKeeper.SetDataAsync(routePath, routeData, -1);\n      }\n    }\n  }\n\n  _logger.LogInformation(\"\u6210\u529f\u6dfb\u52a0MQTT\u670d\u52a1\u8def\u7531\");\n}", "CodeBleu_score": 48.00368118689118}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t  _logger.LogInformation(\"\u5f00\u59cb\u8bbe\u7f6eMQTT\u670d\u52a1\u8def\u7531...\");\n  var zooKeepers = await _zookeeperProvider.GetZooKeepers();\n  foreach (var zooKeeper in zooKeepers) {\n    var nodePath = _zookeeperProvider.GetServiceRoutePath(zooKeeper);\n    if (!await _zookeeperProvider.ExistsAsync(zooKeeper, nodePath)) {\n      await _zookeeperProvider.CreateAsync(zooKeeper, nodePath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n    }\n    foreach (var route in routes) {\n      var routePath = _zookeeperProvider.GetServiceRoutePath(zooKeeper, route.RoutePath);\n      var routeData = JsonSerializer.SerializeToUtf8Bytes(route);\n      if (await _zookeeperProvider.ExistsAsync(zooKeeper, routePath)) {\n        await _zookeeperProvider.SetDataAsync(zooKeeper, routePath, routeData);\n        _logger.LogInformation(\"\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\", routePath);\n      } else {\n        await _zookeeperProvider.CreateAsync(zooKeeper, routePath, routeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n        _logger.LogInformation(\"\u521b\u5efa\u8282\u70b9\uff1a{nodePath}\", routePath);\n      }\n    }\n    _logger.LogInformation(\"\u6210\u529f\u8bbe\u7f6eMQTT\u670d\u52a1\u8def\u7531\");\n  }\n}", "CodeBleu_score": 51.715820720980396}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = MqttServiceRoute.GetRoutePath();\n    var zooKeepers = _zookeeperClientProvider.GetZooKeepers();\n    foreach (var zooKeeper in zooKeepers) {\n        var oldRouteTopics = await zooKeeper.Item2.getChildrenAsync(routePath);\n        var newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n        var deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\n        foreach (var deletedRouteTopic in deletedRouteTopics) {\n            var route = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\n            if (route != null && route.Addresses.Contains(hostAddr)) {\n                await zooKeeper.Item2.deleteAsync($\"{routePath}/{deletedRouteTopic}\");\n            }\n        }\n    }\n}", "CodeBleu_score": 60.009176939025224}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    var oldRouteTopics = _routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var toBeDeletedRoutes = oldRouteTopics.Except(newRouteTopics).ToArray();\n    var zooKeepers = _zookeeperClientProvider.GetZooKeepers();\n    foreach (var zooKeeper in zooKeepers) {\n        foreach (var deletedRouteTopic in toBeDeletedRoutes) {\n            var deletedRoute = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\n            if (deletedRoute != null && deletedRoute.Addresses.Contains(hostAddr)) {\n                var routePath = ZooKeeperPathHelper.GetMqttServiceRoutePath(deletedRoute.ServiceId, deletedRouteTopic);\n                await zooKeeper.Item2.deleteAsync(routePath);\n            }\n        }\n    }\n}", "CodeBleu_score": 59.52654164813118}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = _zookeeperClientProvider.GetZooKeepers().Item1;\n    var zooKeeper = _zookeeperClientProvider.GetZooKeepers().Item2;\n    var oldRoutes = await zooKeeper.Item2.getChildrenAsync(routePath);\n    var oldRouteTopics = oldRoutes.Select(i => JsonConvert.DeserializeObject<MqttServiceRoute>(i).MqttDescriptor.Topic).ToArray();\n    var newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\n    foreach (var deletedRouteTopic in deletedRouteTopics) {\n        var deletedRoute = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\n        if (deletedRoute != null) {\n            var addresses = deletedRoute.Addresses.Select(i => i.Address).ToArray();\n            if (addresses.Contains(hostAddr.Address)) {\n                var route = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\n                if (route != null) {\n                    var routeStr = JsonConvert.SerializeObject(route);\n                    var routeData = Encoding.UTF8.GetBytes(routeStr);\n                    await zooKeeper.Item2.deleteAsync($\"{routePath}/{routeStr}\");\n                }\n            }\n        }\n    }\n}", "CodeBleu_score": 56.08982597554773}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t    _logger.LogInformation(\"\u5f00\u59cb\u8bbe\u7f6e\u670d\u52a1\u7f13\u5b58\");\n    var cachePath = Path.Combine(_configuration.RootPath, \"caches\");\n    var zooKeepers = _zookeeperProvider.GetZooKeepers();\n    foreach (var zooKeeper in zooKeepers) {\n        await zooKeeper.EnsurePathAsync(cachePath);\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var data = JsonSerializer.SerializeToUtf8Bytes(cacheDescriptor);\n            var nodePath = Path.Combine(cachePath, cacheDescriptor.Id);\n            if (await zooKeeper.ExistsAsync(nodePath) == null) {\n                await zooKeeper.CreateAsync(nodePath, data, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n            } else {\n                var stat = await zooKeeper.SetDataAsync(nodePath, data);\n                if (stat == null) {\n                    _logger.LogWarning(\"\u66f4\u65b0\u7f13\u5b58\u5931\u8d25\uff1a{nodePath}\", nodePath);\n                }\n            }\n        }\n    }\n    _logger.LogInformation(\"\u6210\u529f\u8bbe\u7f6e\u670d\u52a1\u7f13\u5b58\");\n}", "CodeBleu_score": 41.59728294325912}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 1.0587007191288007}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t    _logger.LogInformation(\"Updating service cache descriptors in Zookeeper...\");\n\n    var cachePath = GetCachePath();\n\n    var zooKeepers = _zookeeperProvider.GetZooKeepers();\n\n    foreach (var zooKeeper in zooKeepers) {\n        await EnsurePathAsync(zooKeeper, cachePath);\n\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var nodePath = GetCacheNodePath(cachePath, cacheDescriptor.ServiceName);\n            var data = JsonSerializer.SerializeToUtf8Bytes(cacheDescriptor);\n\n            if (!await NodeExistsAsync(zooKeeper, nodePath)) {\n                await CreateNodeAsync(zooKeeper, nodePath, data);\n            } else {\n                await UpdateNodeAsync(zooKeeper, nodePath, data);\n            }\n        }\n    }\n\n    _logger.LogInformation(\"Successfully added service caches to Zookeeper.\");\n}", "CodeBleu_score": 36.31462428951053}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    zooKeeper.Item1.WaitOne();\n    if (await zooKeeper.Item2.existsAsync(path) == null) {\n        _logger.LogInformation($\"Creating subdirectory: {path}\");\n        var subdirectories = path.Split('/');\n        string currentPath = \"\";\n        foreach (var subdirectory in subdirectories) {\n            currentPath += $\"/{subdirectory}\";\n            if (await zooKeeper.Item2.existsAsync(currentPath) == null) {\n                await zooKeeper.Item2.createAsync(currentPath, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            }\n        }\n    }\n}", "CodeBleu_score": 56.12490703899466}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    zooKeeper.Item1.WaitOne();\n    if (await zooKeeper.Item2.existsAsync(path) == null) {\n        _logger.LogInformation($\"Creating Zookeeper node path: {path}\");\n        var subdirectories = path.Split('/');\n        var currentPath = string.Empty;\n        foreach (var subdirectory in subdirectories) {\n            currentPath += $\"/{subdirectory}\";\n            if (await zooKeeper.Item2.existsAsync(currentPath) == null) {\n                await zooKeeper.Item2.createAsync(currentPath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            }\n        }\n    }\n}", "CodeBleu_score": 59.51687438683619}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    zooKeeper.Item1.WaitOne();\n    if (await zooKeeper.Item2.existsAsync(path) == null) {\n        _logger.LogInformation($\"Creating Zookeeper node path: {path}\");\n        var subdirectories = path.Split('/');\n        string currentPath = \"\";\n        foreach (var subdirectory in subdirectories) {\n            currentPath += $\"/{subdirectory}\";\n            if (await zooKeeper.Item2.existsAsync(currentPath) == null) {\n                await zooKeeper.Item2.createAsync(currentPath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            }\n        }\n    }\n}", "CodeBleu_score": 59.16777455601533}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new List<(ManualResetEvent, ZooKeeper)>();\n\n    foreach (var address in _addresses) {\n        var isHealth = await _healthCheckService.IsHealth(address);\n        if (!isHealth) {\n            continue;\n        }\n\n        var zooKeeper = CreateZooKeeper(address);\n        result.Add((new ManualResetEvent(false), zooKeeper));\n    }\n\n    return result;\n}", "CodeBleu_score": 72.44909944548289}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new List<(ManualResetEvent, ZooKeeper)>();\n    foreach (var address in _configuration.Addresses) {\n        var isHealth = await _healthCheckService.IsHealth(address);\n        if (isHealth) {\n            var zooKeeper = CreateZooKeeper(address);\n            result.Add((new ManualResetEvent(false), zooKeeper));\n        }\n    }\n    return result;\n}", "CodeBleu_score": 73.69214102048537}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new List<(ManualResetEvent, ZooKeeper)>();\n    foreach (var address in _addresses) {\n        var isHealth = await _healthCheckService.IsHealth(address);\n        if (isHealth) {\n            var zooKeeper = CreateZooKeeper(address);\n            result.Add((zooKeeper.ManualResetEvent, zooKeeper));\n        }\n    }\n    return result;\n}", "CodeBleu_score": 73.96657872027282}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\t    if (zk != null) {\n        return zk;\n    }\n    synchronized (this) {\n        if (zk != null) {\n            return zk;\n        }\n        String connectionString = getConnectionString();\n        zk = new ZooKeeper(connectionString, sessionTimeout, this);\n        zk.addAuthInfo(\"digest\", authString.getBytes());\n        return zk;\n    }\n}", "CodeBleu_score": 35.06459473466403}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t    synchronized (this) {\n        if (zk == null) {\n            zk = new ZooKeeper(ensembleProvider.getConnectionString(), 3000, this);\n            zk.sync(null, true);\n        }\n        return zk;\n    }\n}", "CodeBleu_score": 32.95071489328553}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t    synchronized (this) {\n        if (zooKeeper == null) {\n            String connectionString = ensembleProvider.getConnectionString();\n            zooKeeper = new ZooKeeper(connectionString, sessionTimeout, this);\n        }\n        return zooKeeper;\n    }\n}", "CodeBleu_score": 36.10462432543679}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t  if (zk != null) {\n    try {\n      zk.removeAllWatches(zk.getSessionId(), true, new Watcher() {\n        public void process(WatchedEvent event) {\n        }\n      } , null);\n    }\n    catch (KeeperException e) {\n      LOG.error(\"Unexpected exception while closing ZooKeeper\", e);\n    }\n    if (waitForShutdownTimeoutMs > 0) {\n      try {\n        Thread.sleep(waitForShutdownTimeoutMs);\n      }\n      catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n      }\n    }\n    try {\n      zk.close();\n    }\n    catch (InterruptedException e) {\n      Thread.currentThread().interrupt();\n    }\n    zk = null;\n  }\n}", "CodeBleu_score": 39.21940648457448}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t  try {\n    ZooKeeper zk = helper.getZooKeeper();\n    if (zk != null) {\n      zk.register(new Watcher() {\n\n        @Override\n        public void process(WatchedEvent event) {\n        }\n      });\n      zk.close();\n    }\n  } finally {\n    if (waitForShutdownTimeoutMs > 0) {\n      Thread.sleep(waitForShutdownTimeoutMs);\n    }\n  }\n}", "CodeBleu_score": 32.88176510196973}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t  ZooKeeper zk = null;\n  try {\n    zk = zkHelper.getZk();\n    if (zk != null) {\n      zk.register(new Watcher() {\n\n        public void process(WatchedEvent event) {\n        }\n      });\n      if (waitForShutdownTimeoutMs > 0) {\n        zk.close();\n        zk.waitUntilClientDisconnected(waitForShutdownTimeoutMs);\n      }\n      else {\n        zk.close();\n      }\n    }\n  }\n  catch (InterruptedException e) {\n    Thread.currentThread().interrupt();\n  }\n  finally {\n    zkHelper.setZk(null);\n  }\n}", "CodeBleu_score": 38.96970217515296}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    long start = System.currentTimeMillis();\n    LOG.info(\"Starting to block until connected or timed out\");\n    boolean isConnected = internalBlockUntilConnectedOrTimedOut();\n    LOG.info(\"Blocking until connected or timed out finished\");\n    long end = System.currentTimeMillis();\n    LOG.info(\"Blocking until connected or timed out took {} ms\", end - start);\n    return isConnected;\n}", "CodeBleu_score": 39.75378767186052}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    if (!started) {\n        throw new IllegalStateException(\"Client is not started\");\n    }\n\n    log.info(\"Blocking until connected or timed out\");\n    try {\n        return connected.await(timeout, TimeUnit.MILLISECONDS);\n    } finally {\n        log.info(\"Blocking until connected or timed out finished\");\n    }\n}", "CodeBleu_score": 22.736317017291174}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    // Log the start of the operation\n    logger.info(\"Blocking until connected or timed out\");\n    // Trace the connection process\n    startAdvancedTracer(\"ClientConnection\");\n    // Check if the client is connected\n    boolean isConnected = internalBlockUntilConnectedOrTimedOut();\n    // Log the end of the operation\n    logger.info(\"Blocked until connected or timed out\");\n    // Return the connection status\n    return isConnected;\n}", "CodeBleu_score": 31.705114730708505}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t    log.info(\"Shutting down service\");\n    started = false;\n    try {\n        state.close(waitForShutdownTimeoutMs);\n    } catch (IOException e) {\n        if (!Thread.interrupted()) {\n            log.error(\"Error while shutting down service\", e);\n        }\n    }\n}", "CodeBleu_score": 52.55019252277222}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t    if (!started) {\n        return;\n    }\n\n    if (state != null) {\n        try {\n            state.close(waitForShutdownTimeoutMs);\n        } catch (IOException e) {\n            if (Thread.currentThread().isInterrupted()) {\n                log.info(\"Interrupted while closing state\", e);\n            } else {\n                log.error(\"Failed to close state\", e);\n            }\n        }\n    }\n\n    started = false;\n}", "CodeBleu_score": 49.59715860892181}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t    log.info(\"Shutting down service...\");\n    started = false;\n    try {\n        state.close(waitForShutdownTimeoutMs);\n    } catch (IOException e) {\n        if (!Thread.interrupted()) {\n            log.error(\"Error while shutting down service\", e);\n        }\n    }\n}", "CodeBleu_score": 52.50390343755586}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t    long remaining = connectionTimeout;\n    while (remaining > 0) {\n        final CountDownLatch latch = new CountDownLatch(1);\n        Watcher watcher = new Watcher() {\n            @Override\n            public void process(WatchedEvent event) {\n                if (event.getState() == Event.KeeperState.SyncConnected) {\n                    latch.countDown();\n                }\n            }\n        };\n        try {\n            addWatch(watcher, false);\n            latch.await(remaining, TimeUnit.MILLISECONDS);\n            remaining = connectionTimeout - (connectionTimeout - remaining);\n        } finally {\n            removeWatcher(watcher);\n        }\n        if (state == State.CONNECTED) {\n            return;\n        }\n    }\n    throw new TimeoutException(\"Failed to connect to any of the given hosts\");\n}", "CodeBleu_score": 46.620770058537666}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t  long waitTime = this.connectionTimeout;\n  while (this.state != State.CONNECTED && waitTime > 0) {\n    long startTime = System.currentTimeMillis();\n    try {\n      this.connectionStateLatch.await(waitTime, TimeUnit.MILLISECONDS);\n    }\n catch (    InterruptedException e) {\n      throw e;\n    }\n    long elapsedTime = System.currentTimeMillis() - startTime;\n    waitTime = waitTime - elapsedTime;\n  }\n}", "CodeBleu_score": 19.379962730791775}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t    // \u68c0\u67e5\u662f\u5426\u5df2\u7ecf\u8fde\u63a5\n    if (isConnected()) {\n        return;\n    }\n    // \u8bbe\u7f6e\u8fde\u63a5\u72b6\u6001\n    setConnected(false);\n    // \u83b7\u53d6\u8fde\u63a5\u8d85\u65f6\u65f6\u95f4\n    long timeout = getConnectTimeout();\n    // \u8ba1\u7b97\u5269\u4f59\u8d85\u65f6\u65f6\u95f4\n    long remainingTime = timeout - (System.currentTimeMillis() - getStartTime());\n    // \u5982\u679c\u5269\u4f59\u8d85\u65f6\u65f6\u95f4\u5c0f\u4e8e\u7b49\u4e8e0\uff0c\u5219\u629b\u51fa\u5f02\u5e38\n    if (remainingTime <= 0) {\n        throw new InterruptedException(\"Connection timed out\");\n    }\n    // \u521b\u5efa\u4e00\u4e2a\u4e34\u65f6\u76d1\u89c6\u5668\n    Watcher watcher = new Watcher() {\n        @Override\n        public void process(WatchedEvent event) {\n            if (event.getState() == KeeperState.SyncConnected) {\n                // \u5982\u679c\u8fde\u63a5\u72b6\u6001\u4e3a\u5df2\u8fde\u63a5\uff0c\u5219\u8bbe\u7f6e\u8fde\u63a5\u72b6\u6001\u4e3a\u5df2\u8fde\u63a5\n                setConnected(true);\n                // \u5524\u9192\u7b49\u5f85\u7ebf\u7a0b\n                countDownLatch.countDown();\n            }\n        }\n    };\n    // \u6dfb\u52a0\u76d1\u89c6\u5668\n    addWatch(watcher, true);\n    try {\n        // \u7b49\u5f85\u8fde\u63a5\u72b6\u6001\u53d8\u4e3a\u5df2\u8fde\u63a5\uff0c\u6216\u8005\u8d85\u65f6\u65f6\u95f4\u5230\u8fbe\n        countDownLatch.await(remainingTime, TimeUnit.MILLISECONDS);\n    } finally {\n        // \u79fb\u9664\u76d1\u89c6\u5668\n        removeWatch(watcher);\n    }\n}", "CodeBleu_score": 35.80420212286799}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t    if (createMode == CreateMode.EPHEMERAL) {\n        if (client.getSessionId() != client.getSessionIdOfFoundNode()) {\n            LOG.info(\"Session ID changed during protected mode operation. Deleting old node {}\", foundNode);\n            client.delete().forPath(foundNode);\n            client.setSessionIdOfFoundNode(client.getSessionId());\n        }\n    }\n    return foundNode;\n}", "CodeBleu_score": 30.781057678871576}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t    if (createMode == CreateMode.EPHEMERAL_SEQUENTIAL) {\n        int foundIndex = foundNode.lastIndexOf(client.getZooKeeper().getSessionId());\n        if (foundIndex != -1) {\n            String foundSessionId = foundNode.substring(foundIndex);\n            if (!client.getSessionId().equals(foundSessionId)) {\n                log.warn(\"Found ephemeral node not matching session: {}\", foundNode);\n                client.getZooKeeper().delete(foundNode, -1);\n                client.setSessionId(foundSessionId);\n            }\n        }\n    }\n    return foundNode;\n}", "CodeBleu_score": 44.27420456262915}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t    if (createMode == CreateMode.EPHEMERAL || createMode == CreateMode.EPHEMERAL_SEQUENTIAL) {\n        if (foundNode != null && foundNode.startsWith(client.getNamespace())) {\n            String foundNodeSession = ZKPaths.extractSessionId(foundNode);\n            if (foundNodeSession != null && !foundNodeSession.equals(client.getSessionId())) {\n                LOG.warn(\"Found node \" + foundNode + \" has session id \" + foundNodeSession + \" which does not match current session id \" + client.getSessionId());\n                client.getZooKeeper().delete(foundNode, -1);\n                client.setSessionId(foundNodeSession);\n            }\n        }\n    }\n    return foundNode;\n}", "CodeBleu_score": 40.20602633661793}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t    Stat stat = null;\n    try {\n        stat = zk.setACL(path, aclList, -1);\n    } catch (KeeperException.SessionExpiredException e) {\n        LOG.warn(\"Session expired when setting ACL for path \" + path, e);\n    } catch (KeeperException.ConnectionLossException e) {\n        LOG.warn(\"Connection loss when setting ACL for path \" + path, e);\n    } catch (KeeperException.OperationTimeoutException e) {\n        LOG.warn(\"Operation timeout when setting ACL for path \" + path, e);\n    } catch (KeeperException e) {\n        LOG.warn(\"Unknown exception when setting ACL for path \" + path, e);\n    }\n    return stat;\n}", "CodeBleu_score": 23.719926776147705}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t    final Stat stat = new Stat();\n    final StringBuilder sb = new StringBuilder();\n    sb.append(\"setACL: \");\n    sb.append(path);\n    final Trace trace = TracerFactory.getTracerFactory().getTraceInstance(this.getClass().getName(), \"pathInForeground\");\n    trace.setStartTime();\n    try {\n        final Stat result = this.zk.setACL(path, aclList, -1);\n        trace.setSuccessful(true);\n        return result;\n    }\n    catch (Exception e) {\n        trace.setSuccessful(false);\n        throw e;\n    }\n    finally {\n        trace.setStopTime();\n        trace.commit();\n    }\n}", "CodeBleu_score": 43.28222192046086}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t    final Stat stat = new Stat();\n    final int retryCount = 10;\n    final int retryInterval = 1000;\n    boolean success = false;\n    int attempt = 0;\n    while (!success && attempt < retryCount) {\n        try {\n            final Stat result = zooKeeper.setACL(path, aclList, stat.getVersion());\n            success = true;\n            return result;\n        } catch (KeeperException.NoNodeException e) {\n            logger.warn(\"Node not found: \" + path);\n            break;\n        } catch (KeeperException.ConnectionLossException e) {\n            logger.warn(\"Connection lost while setting ACL for path: \" + path, e);\n            Thread.sleep(retryInterval);\n            attempt++;\n        }\n    }\n    if (!success) {\n        logger.error(\"Failed to set ACL for path: \" + path);\n    }\n    return stat;\n}", "CodeBleu_score": 29.56257662444917}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.payload = payload;\n    validateThisId();\n    this.cache = new CuratorCache(client, membershipPath, false);\n    this.memberNode = client.create()\n            .withMode(CreateMode.EPHEMERAL)\n            .forPath(makePath(membershipPath, thisId), payload);\n    this.cache.start();\n}", "CodeBleu_score": 50.14131068404238}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.payload = payload;\n\n    // Check if the member ID is valid\n    checkNotNull(thisId, \"id cannot be null\");\n    checkArgument(!thisId.contains(PATH_SEPARATOR), \"id may not contain the path separator character\");\n\n    // Set up a CuratorCache for the specified membership path\n    this.membershipCache = CuratorCache.build(client, membershipPath);\n\n    // Create a PersistentNode with ephemeral mode for the member using the provided payload\n    this.member = new PersistentNode(client, membershipPath + PATH_SEPARATOR + thisId, CreateMode.EPHEMERAL, payload);\n}", "CodeBleu_score": 49.30282073010486}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t    checkNotNull(client, \"client\");\n    checkNotNull(membershipPath, \"membershipPath\");\n    checkNotNull(thisId, \"thisId\");\n    checkArgument(!thisId.contains(\"/\"), \"thisId must not contain '/'\");\n    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.path = makePath(this.membershipPath, this.thisId);\n    this.cache = new CuratorCache(client, this.membershipPath, new GroupMemberSerializer());\n    this.cache.start();\n    try {\n        this.node = client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(this.path, payload);\n    } catch (Exception e) {\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 42.556150112915105}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    client.create().creatingParentsIfNeeded().withMode(CreateMode.PERSISTENT).forPath(path, new byte[0]);\n    try {\n        client.getData().usingWatcher((watchedEvent) -> {\n            System.out.println(\"Watched event: \" + watchedEvent);\n        }).forPath(path);\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}", "CodeBleu_score": 32.75278428715096}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    try {\n        client.create().creatingParentsIfNeeded().withMode(CreateMode.PERSISTENT).forPath(path);\n        client.getData().usingWatcher(new Watcher() {\n            @Override\n            public void process(WatchedEvent event)  {\n                handleWatchedStage(event);\n            }\n        }).forPath(path);\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}", "CodeBleu_score": 38.88646317804664}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    try {\n        client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(path);\n        client.getData().usingWatcher(new Watcher() {\n            @Override\n            public void process(WatchedEvent event)  {\n                if (event.getType() == Event.EventType.NodeCreated) {\n                    System.out.println(\"Node created: \" + event.getPath());\n                } else if (event.getType() == Event.EventType.NodeDataChanged) {\n                    System.out.println(\"Node data changed: \" + event.getPath());\n                } else if (event.getType() == Event.EventType.NodeDeleted) {\n                    System.out.println(\"Node deleted: \" + event.getPath());\n                }\n            }\n        }).forPath(path);\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}", "CodeBleu_score": 33.818618220745456}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t    List<OpResult> result = zk.multi(ops);\n    ops.clear();\n    if (result.size() > 0) {\n        OpResult firstResult = result.get(0);\n        if (firstResult.getErr() != Code.OK.intValue()) {\n            int code = firstResult.getErr();\n            throw KeeperException.create(Code.get(code));\n        }\n    }\n    return result;\n}", "CodeBleu_score": 35.00565784081689}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t  List<OpResult> result = zk.multi(ops);\n  if (result.get(0).getErr() != Code.OK.intValue()) {\n    throw new KeeperException.Code(result.get(0).getErr()).create();\n  }\n  return result;\n}", "CodeBleu_score": 17.342897827834815}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t    List<OpResult> result = zk.multi(ops);\n    if (result.size() > 0 && result.get(0).getErr() != Code.OK) {\n        Code code = result.get(0).getErr();\n        throw new KeeperException.MultiException(code);\n    }\n    return result;\n}", "CodeBleu_score": 25.556040230115805}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    try {\n        serviceDiscovery.queryForNames().stream()\n                .forEach(serviceName -> {\n                    try {\n                        serviceDiscovery.queryForInstances(serviceName).stream()\n                                .forEach(ServiceDiscoveryExample::outputInstance);\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                    }\n                });\n    } catch (NoNodeException e) {\n        System.out.println(\"No service registered yet!\");\n    } finally {\n        serviceDiscovery.close();\n    }\n}", "CodeBleu_score": 33.66524597750804}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    try {\n        Collection<String> serviceNames = serviceDiscovery.queryForNames();\n        for (String serviceName : serviceNames) {\n            Collection<InstanceDetails> instances = serviceDiscovery.queryForInstances(serviceName);\n            System.out.println(\"Service: \" + serviceName);\n            for (InstanceDetails instance : instances) {\n                outputInstance(instance);\n            }\n            System.out.println();\n        }\n    } catch (NoNodeException e) {\n        System.out.println(\"No service registered yet.\");\n    } finally {\n        serviceDiscovery.closeQuietly();\n    }\n}", "CodeBleu_score": 59.91311294750765}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    try {\n        serviceDiscovery.queryForNames().stream().forEach(serviceName -> {\n            try {\n                serviceDiscovery.queryForInstances(serviceName).stream().forEach(instance -> {\n                    outputInstance(instance);\n                });\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        });\n    } catch (NoNodeException e) {\n        System.out.println(\"No service registered yet!\");\n    } finally {\n        closeQuietly(serviceDiscovery);\n    }\n}", "CodeBleu_score": 35.071239384762556}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t    return children.stream().filter(name -> !READY_NODE.equals(name)).sorted().collect(Collectors.toList());\n}", "CodeBleu_score": 15.193362495204255}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t    return children.stream().filter(name -> !READY_NODE.equals(name)).sorted().collect(Collectors.toList());\n}", "CodeBleu_score": 15.193362495204255}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t    return children.stream().filter(child -> !READY_NODE.equals(child)).sorted().collect(Collectors.toList());\n}", "CodeBleu_score": 15.222058684431461}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t  if (zk != null) {\n    zk.close();\n  }\n  zk = new ZooKeeper(newHost, SESSION_TIMEOUT, this);\n  countDownLatch.await();\n  if (zk.getState() == ZooKeeper.States.CONNECTEDREADONLY) {\n    System.out.println(\"Connected to ZooKeeper in read-only mode\");\n  } else {\n    System.out.println(\"Connected to ZooKeeper\");\n  }\n}", "CodeBleu_score": 31.35091486827649}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t  if (zk != null) {\n    zk.close();\n  }\n  zk = new ZooKeeper(newHost, SESSION_TIMEOUT, this);\n  connectedSignal.await();\n}", "CodeBleu_score": 21.794894969088986}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t  if (zk != null) {\n    zk.close();\n  }\n  zk = new ZooKeeper(newHost, sessionTimeout, this);\n  connectedSignal.await();\n}", "CodeBleu_score": 22.080886560678465}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> aclList = new ArrayList<ACL>();\n    String[] acls = aclString.split(\",\");\n    for (String acl : acls) {\n        String[] parts = acl.split(\":\");\n        if (parts.length != 3) {\n            LOG.error(\"Invalid ACL format: \" + acl);\n            continue;\n        }\n        String scheme = parts[0];\n        String id = parts[1];\n        String perms = parts[2];\n        ACL a = new ACL(perms.length(), scheme.getBytes(), id.getBytes());\n        a.setPerms(getPermFromString(perms));\n        aclList.add(a);\n    }\n    return aclList;\n}", "CodeBleu_score": 32.00341207693467}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> acls = new ArrayList<ACL>();\n    String[] aclSegs = aclString.split(\",\");\n    for (String aclSeg : aclSegs) {\n        if (aclSeg.isEmpty()) {\n            continue;\n        }\n        String[] idAndPerms = aclSeg.split(\":\");\n        if (idAndPerms.length != 2) {\n            LOG.error(\"Invalid ACL \" + aclSeg + \". There must be exactly one ':' char \" + \"separating userId and perms.\");\n            continue;\n        }\n        String scheme = null;\n        String id = idAndPerms[0];\n        byte[] perms = getPermsFromString(idAndPerms[1]);\n        int firstColon = id.indexOf(':');\n        if (firstColon > 0) {\n            scheme = id.substring(0, firstColon);\n            id = id.substring(firstColon + 1);\n        }\n        acls.add(new ACL(scheme, id, perms));\n    }\n    return acls;\n}", "CodeBleu_score": 36.11566578598476}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> acls = new ArrayList<>();\n    String[] segments = aclString.split(\",\");\n    for (String segment : segments) {\n        String[] parts = segment.split(\":\");\n        if (parts.length != 3) {\n            log.error(\"Invalid ACL format: \" + segment);\n            continue;\n        }\n        String scheme = parts[0];\n        String id = parts[1];\n        String perms = parts[2];\n        ACL acl = new ACL(perms.length(), scheme.getBytes(), id.getBytes());\n        acl.setId(acl.newId(scheme, id));\n        acl.setPerms(acl.getPermsFromString(perms));\n        acls.add(acl);\n    }\n    return acls;\n}", "CodeBleu_score": 29.954415451272602}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    Objects.requireNonNull(pathList);\n    assertZookeeperExists(serverId);\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            get(serverId).delete().forPath(path);\n        }\n    } else {\n        deleteAsync(serverId, pathList);\n    }\n}", "CodeBleu_score": 73.7836570785939}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    Objects.requireNonNull(pathList, \"pathList cannot be null\");\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            deleteSync(serverId, path);\n        }\n    } else {\n        deleteAsync(serverId, pathList);\n    }\n}", "CodeBleu_score": 52.78094237612178}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    Objects.requireNonNull(pathList);\n    assertZookeeperExists(serverId);\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            delete(serverId, path);\n        }\n    } else {\n        deleteAsync(serverId, pathList);\n    }\n}", "CodeBleu_score": 69.52509145795867}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t    writer.write(\"Connecting to \" + url + \"...\n\");\n    CuratorFramework client = new CuratorZookeeperConnectionFactory(url).getClient();\n    writer.write(\"Connected.\n\");\n    ZooKeeperMain main = new ZooKeeperMain(client);\n    return new Terminal(id, url, client, main);\n}", "CodeBleu_score": 29.902182134725074}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t    writer.write(\"Connecting to \" + url + \"...\");\n    CuratorFramework connection = new CuratorZookeeperConnectionFactory().create(url);\n    writer.write(\"Connected.\");\n    ZooKeeperMain zooKeeperMain = new ZooKeeperMain(connection);\n    return new Terminal(id, url, connection, zooKeeperMain);\n}", "CodeBleu_score": 32.98547191208466}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t    writer.write(\"Connecting to \" + url + \"... \");\n    CuratorFramework client = CuratorZookeeperConnectionFactory.create(url);\n    writer.write(\"done.\n\");\n    ZooKeeperMain main = new ZooKeeperMain(client);\n    return new Terminal(id, url, client, main);\n}", "CodeBleu_score": 26.391143256974626}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\t    int i = 0;\n    while (i < 6) {\n        try {\n            sleep(1000);\n            if (isConnected()) {\n                return;\n            }\n            connect();\n        } catch (Exception e) {\n            close();\n            throw new IllegalStateException(e);\n        }\n        i++;\n    }\n    close();\n    throw new IllegalStateException(\"Could not establish connection!\");\n}", "CodeBleu_score": 45.67414189095872}, {"code": "public void blockUntilConnected(){\n\t    int retries = 6;\n    while (!isConnected() && retries > 0) {\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            throw new IllegalStateException(e);\n        }\n        retries--;\n    }\n    if (!isConnected()) {\n        close();\n        throw new IllegalStateException(\"SSH Connection could not be established\");\n    }\n}", "CodeBleu_score": 53.128885427161556}, {"code": "public void blockUntilConnected(){\n\t    int attempts = 0;\n    while (attempts < 6) {\n        try {\n            if (isConnected()) {\n                return;\n            }\n            attempts++;\n            Thread.sleep(1000);\n        } catch (Exception e) {\n            close();\n            throw new IllegalStateException(e);\n        }\n    }\n    close();\n    throw new IllegalStateException(\"Failed to establish SSH tunnel connection\");\n}", "CodeBleu_score": 47.82002787517479}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        log.error(\"\u5220\u9664\u8282\u70b9\u5931\u8d25\", e);\n        throw new IllegalStateException(\"\u5220\u9664\u8282\u70b9\u5931\u8d25\");\n    }\n}", "CodeBleu_score": 67.92856452520519}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        log.error(\"delete node error\", e);\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 88.00958964464397}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        log.error(\"delete node error, serverId: {}, pathList: {}\", serverId, pathList, e);\n        throw new IllegalStateException(\"delete node error\");\n    }\n}", "CodeBleu_score": 66.26640408789504}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\t    Platform.runLater(() -> {\n        ServerConfig serverConfig = serverConfigs.stream().filter(s -> s.getId().equals(id)).findFirst().orElseThrow();\n        zkClient.disconnect(serverConfig.getId());\n        serverConfigs.remove(serverConfig);\n    });\n}", "CodeBleu_score": 56.77941974355916}, {"code": "public void disconnect(String id){\n\t    Platform.runLater(() -> {\n        var server = getById(id).orElseThrow();\n        var zk = server.getZk();\n        zk.disconnect(server.getId());\n        remove(id);\n    });\n}", "CodeBleu_score": 50.89642784500153}, {"code": "public void disconnect(String id){\n\t        Platform.runLater(() -> {\n            ServerConfig serverConfig = getById(id);\n            serverConfig.disconnect();\n            remove(serverConfig);\n        });\n    }", "CodeBleu_score": 35.091913024135714}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    Server server = serverService.getById(serverId);\n    String host = server.getHost();\n    int port = server.getPort();\n    boolean sshTunnelEnabled = server.getSshTunnelEnabled();\n    String connectionUrl = sshTunnelEnabled ? sshTunnelService.getConnectionUrl(serverId) : String.format(\"http://%s:%s/\", host, port);\n    zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 43.00288507865808}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    Server server = serverService.getById(serverId);\n    String host = server.getHost();\n    int port = server.getPort();\n    boolean sshTunnelEnabled = server.getSshTunnelEnabled();\n    if (sshTunnelEnabled) {\n        String sshHost = sshTunnelService.getHost();\n        int sshPort = sshTunnelService.getPort();\n        String connectionUrl = String.format(\"ssh://%s:%d@%s:%d\", server.getUsername(), server.getPassword(), sshHost, sshPort);\n        zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n    } else {\n        String connectionUrl = String.format(\"http://%s:%d\", host, port);\n        zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n    }\n}", "CodeBleu_score": 40.01569061606877}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    Server server = serverService.getById(serverId).orElseThrow(() -> new ServerNotFoundException(serverId));\n    String host = server.getHost();\n    Integer port = server.getPort();\n    Boolean sshTunnelEnabled = server.getSshTunnelEnabled();\n\n    String connectionUrl = String.format(\"ws://%s:%d/websocket\", host, port);\n    if (sshTunnelEnabled) {\n        String sshTunnelHost = server.getSshTunnelHost();\n        Integer sshTunnelPort = server.getSshTunnelPort();\n        connectionUrl = String.format(\"ws://%s:%d/websocket\", sshTunnelHost, sshTunnelPort);\n    }\n\n    zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 39.22763409336627}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t    try {\n        executeCommand(id, command);\n    } catch (Exception e) {\n        logger.error(\"Failed to execute command on server with ID: \" + id, e);\n        displayErrorMessage(\"Failed to execute command on server with ID: \" + id + \". Please try again.\");\n    }\n}", "CodeBleu_score": 51.696060992013045}, {"code": "public void executeCommand(String id, String command){\n\t    try {\n        // Execute the command on the server identified by the ID\n        executeCommandOnServer(id, command);\n    } catch (Exception e) {\n        // Log the error with the server ID and command\n        log.error(\"Error executing command on server with ID: {}\", id, e);\n\n        // Display an error message indicating that the command execution failed\n        displayErrorMessage(\"Failed to execute command on server with ID: \" + id + \". Please try again.\");\n    }\n}", "CodeBleu_score": 49.676627460941475}, {"code": "public void executeCommand(String id, String command){\n\t    try {\n        ZookeeperServer server = zookeeperServerRepository.findById(id);\n        server.executeCommand(command);\n    } catch (Exception e) {\n        logger.error(\"Failed to execute command on server with ID: {}\", id, e);\n        throw new RuntimeException(\"Failed to execute command on server with ID: \" + id + \". Please try again.\");\n    }\n}", "CodeBleu_score": 42.54335208896693}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\t    Properties properties = new Properties();\n    String filePath = \"zookeeper.properties\";\n    File file = new File(filePath);\n    if (file.exists()) {\n        try {\n            properties.load(new FileInputStream(file));\n            logger.info(\"Loaded Zookeeper system properties from file: {}\", filePath);\n        } catch (IOException e) {\n            logger.error(\"Error loading Zookeeper system properties from file: {}\", filePath, e);\n        }\n    } else {\n        logger.error(\"Zookeeper system properties file does not exist: {}\", filePath);\n    }\n    return properties;\n}", "CodeBleu_score": 46.07758838441109}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t    Properties properties = new Properties();\n    String filePath = \"src/main/resources/zookeeper.properties\";\n\n    try {\n        File file = new File(filePath);\n        if (file.exists()) {\n            properties.load(new FileReader(file));\n            logger.info(\"Loaded properties from file: \" + file.getAbsolutePath());\n        } else {\n            logger.error(\"File not found: \" + file.getAbsolutePath());\n        }\n    } catch (IOException e) {\n        logger.error(\"Error loading properties from file: \" + filePath, e);\n    }\n\n    return properties;\n}", "CodeBleu_score": 40.31863333947799}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t    Properties properties = new Properties();\n    try {\n        File file = new File(zookeeperPropertiesFilePath);\n        if (!file.exists()) {\n            LOGGER.error(\"Zookeeper properties file does not exist: {}\", zookeeperPropertiesFilePath);\n            return properties;\n        }\n        try (InputStream inputStream = new FileInputStream(file)) {\n            properties.load(inputStream);\n            LOGGER.info(\"Loaded zookeeper properties: {}\", properties);\n        }\n    } catch (IOException e) {\n        LOGGER.error(\"Error loading zookeeper properties from file: {}\", zookeeperPropertiesFilePath, e);\n    }\n    return properties;\n}", "CodeBleu_score": 50.74540899928207}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\t    Properties properties = new Properties();\n    try {\n        properties.load(new StringReader(content));\n    } catch (IOException e) {\n        log.error(\"Error loading properties from content\", e);\n        showNotification(\"Error loading properties from content\", NotificationType.ERROR_MESSAGE);\n        return;\n    }\n    try {\n        properties.store(new FileOutputStream(SYS_PROP_PATH), null);\n    } catch (IOException e) {\n        log.error(\"Error saving properties to file\", e);\n        showNotification(\"Error saving properties to file\", NotificationType.ERROR_MESSAGE);\n    }\n}", "CodeBleu_score": 36.14883927800848}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t    Properties props = new Properties();\n    try {\n        props.load(new StringReader(content));\n    } catch (IOException e) {\n        LOGGER.error(\"Failed to load properties from content.\", e);\n        Notification.show(\"Failed to load properties from content.\", 5000, Notification.Position.MIDDLE);\n        return;\n    }\n    try {\n        props.store(new FileOutputStream(SYS_PROP_PATH), \"Zookeeper System Properties\");\n    } catch (IOException e) {\n        LOGGER.error(\"Failed to save properties to file.\", e);\n        Notification.show(\"Failed to save properties to file.\", 5000, Notification.Position.MIDDLE);\n        return;\n    }\n}", "CodeBleu_score": 36.58670845309969}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t    Properties properties = new Properties();\n    try {\n        properties.load(new StringReader(content));\n    } catch (IOException e) {\n        log.error(\"Error loading Zookeeper system properties\", e);\n        showNotification(\"Error loading Zookeeper system properties\", NotificationType.ERROR);\n        return;\n    }\n    try {\n        properties.store(new FileOutputStream(SYS_PROP_PATH), null);\n    } catch (IOException e) {\n        log.error(\"Error saving Zookeeper system properties\", e);\n        showNotification(\"Error saving Zookeeper system properties\", NotificationType.ERROR);\n    }\n}", "CodeBleu_score": 35.869941384037475}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\t    try {\n        BufferedReader in = getInputStream(client);\n        StringBuilder response = new StringBuilder();\n        String line;\n        while ((line = in.readLine()) != null) {\n            response.append(line).append(\"\n\");\n            if (line.contains(\"\\r\n\")) {\n                break;\n            }\n        }\n        cleanup(client);\n        return response.toString();\n    } catch (IOException e) {\n        throw new IllegalStateException(\"Error reading from client\", e);\n    }\n}", "CodeBleu_score": 41.08993331806703}, {"code": "private String response(Socket client){\n\t    try {\n        BufferedReader in = new BufferedReader(\n                new InputStreamReader(client.getInputStream()));\n\n        StringBuilder response = new StringBuilder();\n        String line;\n        while ((line = in.readLine()) != null) {\n            response.append(line);\n        }\n\n        cleanup(client);\n        return response.toString();\n    } catch (IOException e) {\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 55.96766708486876}, {"code": "private String response(Socket client){\n\t    try {\n        BufferedReader in = getInputStream(client);\n        StringBuilder response = new StringBuilder();\n        String line;\n        while ((line = in.readLine()) != null) {\n            response.append(line).append(\"\n\");\n        }\n        cleanup(client);\n        return response.toString();\n    } catch (Exception e) {\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 50.76669359903801}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t    CuratorFramework client = CuratorFrameworkFactory.newClient(params.getConnectionString(), params.getRetryPolicy());\n    client.start();\n    try {\n        if (!client.blockUntilConnected(5, TimeUnit.SECONDS)) {\n            client.close();\n            throw new RuntimeException(\"Could not establish connection to Zookeeper\");\n        }\n    } catch (InterruptedException e) {\n        client.close();\n        throw new RuntimeException(\"Interrupted while waiting for Zookeeper connection\", e);\n    }\n    return new CuratorZookeeperConnection(params, client);\n}", "CodeBleu_score": 62.946386843593615}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t    CuratorFramework client = CuratorFrameworkFactory.newClient(params.getConnectionString(), new RetryNTimes(10, 5000));\n    client.start();\n    try {\n        if (!client.blockUntilConnected(5, TimeUnit.SECONDS)) {\n            throw new RuntimeException(\"Timed out waiting for Zookeeper connection\");\n        }\n    } catch (InterruptedException e) {\n        throw new RuntimeException(\"Interrupted while waiting for Zookeeper connection\", e);\n    }\n    return new CuratorZookeeperConnection(client, params);\n}", "CodeBleu_score": 61.85982891303027}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t    try {\n        CuratorFramework client = CuratorFrameworkFactory.newClient(params.getConnectionString(), new ExponentialBackoffRetry(1000, 3));\n        client.start();\n        if (!client.blockUntilConnected(5, TimeUnit.SECONDS)) {\n            client.close();\n            throw new RuntimeException(\"Failed to connect to Zookeeper\");\n        }\n        return new CuratorZookeeperConnection(client, params);\n    } catch (Exception e) {\n        throw new RuntimeException(\"Failed to create Zookeeper connection\", e);\n    }\n}", "CodeBleu_score": 61.787436496592186}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t    String connectionString = getZookeeperClient().getCurrentConnectionString();\n    if (getListenable().isSyncing()) {\n        getListenable().getLogger().info(\"Synchronization is already in progress for Zookeeper connection string: \" + connectionString);\n        return;\n    }\n    getListenable().getLogger().debug(\"Starting synchronization for Zookeeper connection string: \" + connectionString);\n    getListenable().setSyncing(true);\n    getListenable().getLogger().debug(\"Adding CuratorTreeCacheListener for Zookeeper connection string: \" + connectionString);\n    getListenable().getTreeCache().getListenable().addListener(new CuratorTreeCacheListener(getListenable(), listeners));\n    getListenable().getLogger().debug(\"Attempting to start TreeCache for Zookeeper connection string: \" + connectionString);\n    try {\n        getListenable().getTreeCache().start();\n    } catch (Exception e) {\n        getListenable().getLogger().error(\"Error while starting TreeCache for Zookeeper connection string: \" + connectionString, e);\n        getListenable().getTreeCache().close();\n    }\n}", "CodeBleu_score": 42.23113520441789}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t    String connectionString = getZookeeperClient().getCurrentConnectionString();\n    if (isSynchronizing.compareAndSet(false, true)) {\n        log.info(\"Starting synchronization of Zookeeper nodes for connection string: {}\", connectionString);\n        TreeCache treeCache = new TreeCache(getZookeeperClient().getClient(), \"/\");\n        treeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n        try {\n            treeCache.start();\n        } catch (Exception e) {\n            log.error(\"Error starting synchronization of Zookeeper nodes for connection string: {}\", connectionString, e);\n            treeCache.close();\n        }\n    } else {\n        log.info(\"Synchronization of Zookeeper nodes for connection string: {} is already in progress\", connectionString);\n    }\n}", "CodeBleu_score": 47.64466452493753}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t    String connectionString = getZookeeperClient().getCurrentConnectionString();\n    if (syncInProgress.compareAndSet(false, true)) {\n        log.info(\"Starting Zookeeper synchronization for connection string: {}\", connectionString);\n        TreeCache cache = new TreeCache(getZookeeperClient().get(), \"/\");\n        cache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n        try {\n            cache.start();\n        } catch (Exception e) {\n            log.error(\"Error while starting Zookeeper synchronization for connection string: {}\", connectionString, e);\n            cache.close();\n        }\n    } else {\n        log.info(\"Zookeeper synchronization already in progress for connection string: {}\", connectionString);\n    }\n}", "CodeBleu_score": 45.20392740644446}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache pathChildrenCache = new PathChildrenCache(client, path, true);\n    //BUILD_INITIAL_CACHE \u662f\u5f00\u59cb\u7f13\u5b58\u5168\u90e8\u8282\u70b9\u6570\u636e\n    pathChildrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    pathChildrenCache.getListenable().addListener(listener);\n}", "CodeBleu_score": 98.29481120936092}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache cache = new PathChildrenCache(client, path, true);\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    cache.getListenable().addListener(listener);\n}", "CodeBleu_score": 73.84492591071368}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache cache = new PathChildrenCache(curatorFramework, path, true);\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    cache.getListenable().addListener(listener);\n}", "CodeBleu_score": 61.706571445982426}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t    log.info(\"Unregistering service\");\n    for (String path : paths) {\n        try {\n            curator.delete().forPath(path);\n        } catch (Exception e) {\n            log.error(\"Error unregistering service: {}\", e.getMessage());\n        }\n    }\n    curator.close();\n}", "CodeBleu_score": 57.981482333075654}, {"code": "public void unregisterService(){\n\t    log.info(\"Unregistering service {}\", serviceName);\n    try {\n        for (String path : paths) {\n            curatorClient.deletePath(path);\n        }\n    } catch (Exception e) {\n        log.error(\"Error unregistering service: {}\", getMessage(e));\n    } finally {\n        curatorClient.close();\n    }\n}", "CodeBleu_score": 48.75699379573742}, {"code": "public void unregisterService(){\n\t    log.info(\"Unregistering services...\");\n    for (String path : paths) {\n        try {\n            client.delete().forPath(path);\n        } catch (Exception e) {\n            log.error(\"Error deleting path: {}\", e.getMessage());\n        }\n    }\n    client.close();\n}", "CodeBleu_score": 56.14754988730461}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\t    CompletableFuture.runAsync(() -> {\n        try {\n            makeClientReady();\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }).whenComplete((unused, throwable) -> {\n        if (throwable != null) {\n            throw new RuntimeException(throwable);\n        }\n        subscribeStateChanges(listener);\n    });\n}", "CodeBleu_score": 35.72207586606771}, {"code": "public void addListener(IZkStateListener listener){\n\t    makeClientReady().thenRunAsync(() -> {\n        subscribeStateChanges(listener);\n    }, executorService);\n}", "CodeBleu_score": 12.511570890050027}, {"code": "public void addListener(IZkStateListener listener){\n\t    try {\n        makeClientReady().get();\n    } catch (InterruptedException | ExecutionException e) {\n        throw new RuntimeException(e);\n    }\n    subscribeStateChanges(listener);\n}", "CodeBleu_score": 26.176662916630434}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t    this.serverAddr = serverAddr;\n    this.authority = authority;\n\n    // Retry policy\n    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n\n    // Connection timeout\n    int connectionTimeoutMs = 30 * 1000;\n\n    // Create CuratorFramework client\n    curatorFramework = CuratorFrameworkFactory.builder()\n            .connectString(serverAddr)\n            .retryPolicy(retryPolicy)\n            .connectionTimeoutMs(connectionTimeoutMs)\n            .build();\n\n    // Add connection state listener\n    curatorFramework.getConnectionStateListenable().addListener(this::stateChanged);\n\n    // Start the client\n    try {\n        curatorFramework.start();\n    } catch (Exception e) {\n        throw new IllegalStateException(\"Failed to start CuratorFramework client\", e);\n    }\n}", "CodeBleu_score": 33.04515317166167}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t    this.serverAddr = serverAddr;\n    this.authority = authority;\n    this.retryPolicy = new ExponentialBackoffRetry(1000, 3);\n    this.connectionTimeoutMs = 30 * 1000;\n    this.zkClient = CuratorFrameworkFactory.builder()\n            .connectString(serverAddr)\n            .retryPolicy(retryPolicy)\n            .connectionTimeoutMs(connectionTimeoutMs)\n            .build();\n    if (authority != null) {\n        zkClient.getZookeeperClient().getZooKeeper().addAuthInfo(\"digest\", authority.getBytes());\n    }\n    zkClient.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n        @Override\n        public void stateChanged(CuratorFramework client, ConnectionState newState) {\n            if (newState == ConnectionState.LOST) {\n                LOG.info(\"Connection lost. Retrying...\");\n            } else if (newState == ConnectionState.CONNECTED) {\n                LOG.info(\"Connected to ZooKeeper\");\n            } else if (newState == ConnectionState.RECONNECTED) {\n                LOG.info(\"Reconnected to ZooKeeper \");\n            }\n        }\n    });\n    try {\n        zkClient.start();\n    } catch (Exception e) {\n        throw new IllegalStateException(e.getMessage(), e);\n    }\n}", "CodeBleu_score": 57.81347791378071}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t    this.serverAddr = serverAddr;\n    this.authority = authority;\n    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n    this.client = CuratorFrameworkFactory.newClient(serverAddr, retryPolicy);\n    this.client.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n        @Override\n        public void stateChanged(CuratorFramework client, ConnectionState newState) {\n            if (newState == ConnectionState.LOST) {\n                logger.info(\"Lost connection to Zookeeper server\");\n            } else if (newState == ConnectionState.CONNECTED) {\n                logger.info(\"Connected to Zookeeper server\");\n            } else if (newState == ConnectionState.RECONNECTED) {\n                logger.info(\"Reconnected to Zookeeper server\");\n            }\n        }\n    });\n    this.client.start();\n    try {\n        if (authority != null) {\n            client.getZookeeperClient().getZooKeeper().addAuthInfo(\"digest\", authority.getBytes());\n        }\n    } catch (Exception e) {\n        throw new IllegalStateException(e.getMessage(), e);\n    }\n}", "CodeBleu_score": 46.88836552596345}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t    Map<ChildListener, TargetChildListener> listeners = pathToListeners.get(path);\n    if (listeners != null) {\n        TargetChildListener targetChildListener = listeners.remove(listener);\n        if (targetChildListener != null) {\n            targetChildListener.cancel();\n        }\n    }\n}", "CodeBleu_score": 64.16759664528132}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t    Map<ChildListener, TargetChildListener> listeners = this.listeners.get(path);\n    if (listeners != null) {\n        TargetChildListener targetListener = listeners.remove(listener);\n        if (targetListener != null) {\n            targetListener.removeListener(listener);\n            if (listeners.isEmpty()) {\n                this.listeners.remove(path);\n            }\n        }\n    }\n}", "CodeBleu_score": 67.96837291658392}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t    Map<ChildListener, TargetChildListener> listeners = this.listeners.get(path);\n    if (listeners != null) {\n        TargetChildListener targetListener = listeners.remove(listener);\n        if (targetListener != null) {\n            targetListener.removeListener(listener);\n            if (listeners.isEmpty()) {\n                this.listeners.remove(path);\n            }\n        }\n    }\n}", "CodeBleu_score": 67.96837291658392}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t    if (zh == NULL) {\n        return ZINVALIDHANDLE;\n    }\n\n    char *idc = NULL;\n    char *host = NULL;\n    int ret = lock_ht_find(zh, &idc, &host);\n    if (ret != ZOK) {\n        return ret;\n    }\n\n    lock_ht_delete(zh);\n\n    deserialize_from_idc_host(idc, host, &idc, &host);\n    zookeeper_close(zh);\n\n    zh = zookeeper_init(host, 10000, watcher_global, 0, idc, 0);\n    if (zh == NULL) {\n        LOG_ERR(\"zookeeper_init failed, idc: %s, host: %s\", idc, host);\n        return ZINVALIDHANDLE;\n    }\n\n    ret = init_env_for_zk(zh);\n    if (ret != ZOK) {\n        return ret;\n    }\n\n    reset_table_watcher(reinterpret_cast<unsigned long>(zh));\n    return ZOK;\n}", "CodeBleu_score": 33.084760991906094}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t    if (zh == NULL) {\n        return -1;\n    }\n\n    char *idc_host = NULL;\n    lock_ht_find(zh, &idc_host);\n    lock_ht_delete(zh);\n\n    zookeeper_close(zh);\n\n    char *idc = NULL;\n    char *host = NULL;\n    deserialize_from_idc_host(idc_host, &idc, &host);\n\n    zhandle_t *new_zh = zookeeper_init(host, 30000, watcher, (void *)zh, 0, NULL);\n    if (new_zh == NULL) {\n        LOG_ERR(\"zookeeper_init failed\");\n        return -1;\n    }\n\n    init_env_for_zk(new_zh, idc);\n    set_table_watcher(new_zh);\n\n    return 0;\n}", "CodeBleu_score": 23.483553820078725}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t  if (zh == NULL) {\n    return ZINVALIDHANDLE;\n  }\n\n  char *idc = (char *)zoo_get_context(zh);\n  char *host = (char *)zoo_get_context(zh);\n\n  lock_ht_delete(idc_host_ht, idc);\n  lock_ht_delete(idc_zh_ht, idc);\n  free(idc);\n  free(host);\n\n  zookeeper_close(zh);\n\n  idc = deserialize_from_idc_host(host);\n  if (idc == NULL) {\n    LOG_ERR(\"Failed to deserialize from IDC and host\");\n    return ZINVALIDARGUMENT;\n  }\n\n  zh = zookeeper_init(host, watcher_global, 10000, 0, NULL, 0);\n  if (zh == NULL) {\n    LOG_ERR(\"Failed to initialize ZooKeeper handle\");\n    free(idc);\n    free(host);\n    return ZINVALIDARGUMENT;\n  }\n\n  init_env_for_zk(zh);\n\n  lock_ht_insert(idc_host_ht, idc, strlen(idc), host, strlen(host) + 1);\n  lock_ht_insert(idc_zh_ht, idc, strlen(idc), zh, sizeof(zh));\n\n  lock_ht_find(table_watcher_ht, idc, strlen(idc), &table_watcher);\n  if (table_watcher != NULL) {\n    table_watcher->zh = zh;\n  }\n\n  return ZOK;\n}", "CodeBleu_score": 41.95785518278093}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t    if (!zh) {\n        return;\n    }\n\n    // Update internal tables with the handle and host information\n    update_zk_handle_host(zh, idc_host);\n    update_zk_host_handle(idc_host, zh);\n\n    // Check the connection state of the Zookeeper handle\n    int state = zoo_state(zh);\n    if (state != ZOO_CONNECTED_STATE) {\n        return;\n    }\n\n    // Register the current host on the Zookeeper server\n    string notify_node = ZK_NOTIFY_NODE + \"/\" + idc_host;\n    int ret = zk_register_ephemeral(zh, notify_node.c_str(), idc.c_str(), idc.size(), ZK_NOTIFY_NODE_ACL, 0);\n    if (ret != ZOK) {\n        LOG_FATAL_ERR(\"register notify node failed, ret=%d, errno=%d, error=%s\", ret, zerror(ret), zerror(ret));\n        return;\n    }\n\n    // Set a watcher on the notify node\n    ret = zoo_wexists(zh, notify_node.c_str(), watch_notify_node, (void *)notify_node.c_str(), nullptr);\n    if (ret != ZOK) {\n        LOG_FATAL_ERR(\"watch notify node failed, ret=%d, errno=%d, error=%s\", ret, zerror(ret), zerror(ret));\n        return;\n    }\n\n    // Depending on the result of setting the watcher, add the IDC to a gray list or log an error\n    if (ret == ZOK) {\n        add_gray_idc(idc);\n    } else {\n        LOG_INFO(\"watch notify node failed, ret=%d, errno=%d, error=%s\", ret, zerror(ret), zerror(ret));\n    }\n}", "CodeBleu_score": 50.765677462484746}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t    // Update internal tables with the handle and host information\n    zk_handle_to_host[zh] = idc_host;\n    zk_handle_to_idc[zh] = idc;\n\n    // Check the connection state of the Zookeeper handle\n    if (zoo_state(zh) != ZOO_CONNECTED_STATE) {\n        return;\n    }\n\n    // Register the current host on the Zookeeper server\n    int ret = zk_register_ephemeral(zh, zk_notify_node, idc_host.c_str());\n    if (ret != ZOK) {\n        LOG_FATAL_ERR(\"zk_register_ephemeral failed, ret:%d\", ret);\n        return;\n    }\n\n    // Set a watcher on the notify node\n    ret = zoo_wexists(zh, zk_notify_node, watch_notify_node, NULL, NULL);\n    if (ret != ZOK) {\n        LOG_FATAL_ERR(\"zoo_wexists failed, ret:%d\", ret);\n        return;\n    }\n\n    // Add the IDC to a gray list or log an error if the operation fails\n    if (ret == ZOK) {\n        add_gray_idc(idc);\n    } else {\n        LOG_INFO(\"add_gray_idc failed, ret:%d\", ret);\n    }\n}", "CodeBleu_score": 50.55590482059481}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t    // Update internal tables with the handle and host information\n    update_zk_handle_map(zh, idc_host);\n    update_zk_host_map(zh, idc_host);\n\n    // Check the connection state of the Zookeeper handle\n    if (!is_zk_connected(zh)) {\n        return;\n    }\n\n    // Register the current host on the Zookeeper server\n    if (0 != zk_register_ephemeral(zh, idc_host, idc)) {\n        LOG_FATAL_ERR(\"register idc host to zk failed\");\n    }\n\n    // Set a watcher on the notify node\n    if (0 != watch_notify_node(zh, idc_host)) {\n        // If the operation fails, add the IDC to a gray list\n        add_gray_idc(idc);\n        LOG_INFO(\"watch notify node failed\");\n    }\n}", "CodeBleu_score": 33.84417353025769}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(f\"{username}:{password}\".encode()).digest()\n    return f\"{username}:{base64.b64encode(cred_hash).decode().strip()}\"\n\n", "CodeBleu_score": 24.880859049571193}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1((username + \":\" + password).encode()).digest()\n    cred_hash = base64.b64encode(cred_hash).strip().decode()\n    return f\"{username}:{cred_hash}\"", "CodeBleu_score": 26.502822488924245}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(f\"{username}:{password}\".encode(\"utf-8\")).digest()\n    return f\"{username}:{b64encode(cred_hash).decode('utf-8').strip()}\"\n\n", "CodeBleu_score": 23.625352980878723}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if not self.pe:\n        return False\n    lock_path = self.pe.get_lock_path()\n    with self.zk.Lock(lock_path):\n        lock_value = self.zk.get(lock_path)[0]\n        return lock_value == self.id\n\n", "CodeBleu_score": 33.965401152597614}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_path = self.processing_element.lock_path\n    self.zk_client.sync(lock_path)\n    lock_value = self.zk_client.get(lock_path)[0]\n    return lock_value == self.instance_id\n\n", "CodeBleu_score": 44.912075326300894}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n\n    lock_path = self.processing_element.lock_path\n    self.processing_element.client.sync(lock_path)\n    lock_value = self.processing_element.client.get(lock_path)[0]\n    return lock_value.decode() == self.instance_id\n\n", "CodeBleu_score": 43.41435390988009}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    if self.processing_element is not None and self.holds_lock:\n        with self.lock_manager.transaction_manager.transaction() as transaction:\n            self.processing_element.delete()\n            self.processing_element = None\n            self.holds_lock = False\n        return True\n    else:\n        return False", "CodeBleu_score": 37.20262868686356}, {"code": "def consume(self)\n\t\n    if self.processing_element is not None and self.holds_lock:\n        with self.database.transaction() as transaction:\n            transaction.delete(self.processing_element)\n            self.processing_element = None\n            self.holds_lock = False\n            return True\n    return False", "CodeBleu_score": 34.48409938439255}, {"code": "def consume(self)\n\t\n    if self.processing_element is not None and self.holds_lock:\n        with self.lock_table.transaction() as transaction:\n            transaction.delete(self.processing_element)\n            transaction.delete(self)\n            return True\n    return False\n\n", "CodeBleu_score": 28.542560211009913}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header, buffer = await self._read_header(read_timeout)\n        if header.xid == PING_XID:\n            log.debug(\"Received ping\")\n            self._clear_outstanding_ping()\n        elif header.xid == AUTH_XID:\n            await self._handle_auth_response(header, buffer)\n        elif header.xid == WATCH_XID:\n            await self._read_watch_event(header, buffer)\n        else:\n            log.debug(\"Received header: %s\", header)\n            await self._read_response(header, buffer)\n    except asyncio.TimeoutError:\n        log.debug(\"Read timeout\")\n        self._clear_outstanding_ping()\n    except Exception as e:\n        log.exception(\"Error reading from socket\")\n        async_object.set_exception(self, e)\n\n", "CodeBleu_score": 41.52792147810687}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header = await self._read_header(read_timeout)\n        if header.xid == PING_XID:\n            log.debug(\"Received ping\")\n            self._clear_outstanding_ping()\n        elif header.xid == AUTH_XID:\n            await self._read_auth_response(header)\n        elif header.xid == WATCH_XID:\n            await self._read_watch_event(header)\n        else:\n            log.debug(\"Received %s\", header)\n            await self._read_response(header)\n    except asyncio.TimeoutError:\n        raise\n    except Exception as e:\n        self._close_socket()\n        async_object.set_exception(e)\n        raise\n\n", "CodeBleu_score": 35.40422175317231}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header, buffer = await self._read_header(read_timeout)\n    except asyncio.TimeoutError:\n        raise ConnectionTimeoutError(\n            \"Connection timeout while reading from the socket\"\n        )\n    if header.xid == PING_XID:\n        log.debug(\"Received ping\")\n        self._clear_outstanding_ping()\n    elif header.xid == AUTH_XID:\n        await self._read_auth_response(header, buffer)\n    elif header.xid == WATCH_XID:\n        await self._read_watch_event(header, buffer)\n    else:\n        log.debug(\"Received header: %s\", header)\n        await self._read_response(header, buffer)\n\n", "CodeBleu_score": 34.28613936020621}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.logger.info(\"Starting ZK loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.logger.info(\"Connecting to ZK\")\n            self.zk.start(self.zk_connect_timeout)\n            self.logger.info(\"Connected to ZK\")\n            break\n        except Exception as e:\n            self.logger.warning(\n                \"Failed to connect to ZK, retrying in %s seconds: %s\",\n                self.zk_retry_interval,\n                e,\n            )\n            time.sleep(self.zk_retry_interval)\n    else:\n        self.logger.info(\"Stopping ZK loop\")\n        self.connection_stopped.set()\n        self.trigger_session_callback(zk.State.CLOSED)\n        self.logger.info(\"Stopped ZK loop\")\n\n", "CodeBleu_score": 45.666732376605815}, {"code": "def zk_loop(self)\n\t\n    self.logger.info(\"Starting Zookeeper loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.connect()\n        except Exception as e:\n            self.logger.warning(\"Zookeeper connection failed: %s\", e)\n            if self.stopped.wait(self.retry_policy.next()):\n                break\n        else:\n            self.logger.info(\"Zookeeper connection established\")\n            break\n    else:\n        self.logger.info(\"Zookeeper connection stopped\")\n        self.connection_stopped.set()\n        self.session_callback(self.CONNECTION_LOST)\n        self.logger.info(\"Zookeeper connection stopped\")\n\n", "CodeBleu_score": 45.812467433332024}, {"code": "def zk_loop(self)\n\t\n    self.logger.info(\"Starting zk loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.zk.start()\n            break\n        except Exception:\n            self.logger.warning(\"Connection attempt failed, retrying...\")\n            time.sleep(self.retry_policy.next())\n    else:\n        self.logger.info(\"Stopping zk loop\")\n        self.connection_stopped.set()\n        self.session_callback(self.zk, \"closed\")\n        self.logger.info(\"Stopped zk loop\")\n\n", "CodeBleu_score": 44.097435004353734}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members = sorted(members)\n    partitions = sorted(partitions)\n    idx = members.index(identifier)\n    return partitions[idx::len(members)]", "CodeBleu_score": 39.64689755031}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_partitions = sorted(partitions)\n    sorted_members = sorted(members)\n    index = sorted_members.index(identifier)\n    return sorted_partitions[index::len(sorted_members)]", "CodeBleu_score": 35.701061449925966}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    index = sorted_members.index(identifier)\n    return sorted_partitions[index::len(sorted_members)]\n\n", "CodeBleu_score": 35.701061449925966}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    if not self._participating:\n        return\n    try:\n        self._leave()\n    except:\n        self._best_effort_cleanup()\n        raise\n    self._participating = False\n\n", "CodeBleu_score": 42.59701483671369}, {"code": "def leave(self)\n\t\n    self._participating = False\n    try:\n        self._retry(self._leave)\n    except Exception as e:\n        self._logger.exception(e)\n        self._best_effort_cleanup()\n\n", "CodeBleu_score": 45.42387295178861}, {"code": "def leave(self)\n\t\n    try:\n        self._barrier.leave()\n    except Exception as e:\n        self._logger.error(f\"Error while leaving the barrier: {e}\")\n        self._best_effort_cleanup()\n        raise e\n    self._participating = False\n\n", "CodeBleu_score": 43.28687456555427}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t    try {\n        statusServer();\n    } catch (Exception e) {\n        try {\n            startServer();\n        } catch (Exception e2) {\n            return error(e2.getMessage());\n        }\n    }\n    return success();\n}", "CodeBleu_score": 29.47912181042806}, {"code": "public Result start(){\n\t    if (statusServer()) {\n        return Result.success();\n    } else {\n        try {\n            startServer();\n            return Result.success();\n        } catch (Exception e) {\n            return Result.error(e.getMessage());\n        }\n    }\n}", "CodeBleu_score": 31.219416789967536}, {"code": "public Result start(){\n\t    try {\n        if (!statusServer()) {\n            Runtime.getRuntime().exec(\"./sbin/start-ftpserver.sh\");\n            return new Result(true, \"HDFS over FTP server started successfully.\");\n        } else {\n            return new Result(false, \"HDFS over FTP server is already running.\");\n        }\n    } catch (IOException e) {\n        return new Result(false, \"An error occurred while starting the HDFS over FTP server: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 29.560734216720512}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t    try {\n        if (isRunning()) {\n            server.stop();\n            return Result.success(\"FTP server stopped successfully.\");\n        } else {\n            return Result.failure(\"FTP server is not running.\");\n        }\n    } catch (Exception e) {\n        log.error(\"Error stopping FTP server: {}\", e.getMessage());\n        return Result.failure(\"Error stopping FTP server: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 38.99709611235901}, {"code": "public Result stop(){\n\t    try {\n        if (!statusServer()) {\n            return new Result(false, \"Server is not running\");\n        }\n        server.stop();\n        return new Result(true, \"Server stopped\");\n    } catch (Exception e) {\n        logger.error(\"Error stopping server\", e);\n        return new Result(false, \"Error stopping server\");\n    }\n}", "CodeBleu_score": 35.137572950009755}, {"code": "public Result stop(){\n\t    if (!isRunning()) {\n        return Result.error(\"Server is not running\");\n    }\n\n    try {\n        server.stop();\n        return Result.success(\"Server stopped\");\n    } catch (Exception e) {\n        logger.error(\"Error stopping server\", e);\n        return Result.error(\"Error stopping server\");\n    }\n}", "CodeBleu_score": 35.407852664205876}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    if (authorities == null) {\n        return null;\n    }\n    for (Authority authority : authorities) {\n        if (authority.canAuthorize(request)) {\n            request = authority.authorize(request);\n            if (request == null) {\n                return null;\n            }\n        }\n    }\n    return request;\n}", "CodeBleu_score": 43.93060972752032}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    if (this.authorities.isEmpty()) {\n        return null;\n    }\n    for (AuthorizationAuthority authority : this.authorities) {\n        if (authority.canAuthorize(request)) {\n            request = authority.authorize(request);\n            if (request == null) {\n                return null;\n            }\n        }\n    }\n    return request;\n}", "CodeBleu_score": 42.95719185891297}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    if (this.authorities == null) {\n        return null;\n    }\n    for (GrantedAuthority authority : this.authorities) {\n        if (authority.canAuthorize(request)) {\n            request = authority.authorize(request);\n            if (request == null) {\n                return null;\n            }\n        }\n    }\n    return request;\n}", "CodeBleu_score": 43.226842092764336}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t    try {\n        FileSystem fs = getDfs();\n        return fs.mkdirs(fullPath);\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 65.07700130106436}, {"code": "public boolean mkdir(){\n\t    try {\n        FileSystem fs = FileSystem.get(new Configuration());\n        return fs.mkdirs(fullPath);\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 69.12035712870532}, {"code": "public boolean mkdir(){\n\t    try {\n        FileSystem fs = FileSystem.get(conf);\n        fs.mkdirs(fullPath);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 72.54919288594809}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t    try {\n        FileSystem fileSystem = getDfs();\n        return fileSystem.delete(fullPath, true);\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 60.473896838922435}, {"code": "public boolean delete(){\n\t    try {\n        FileSystem fs = FileSystem.get(getConfiguration());\n        return fs.delete(fullPath, true);\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 65.9757925681705}, {"code": "public boolean delete(){\n\t        try {\n            FileSystem fs = getDfs();\n            return fs.delete(fullPath, true);\n        } catch (IOException e) {\n            e.printStackTrace();\n            return false;\n        }\n    }", "CodeBleu_score": 58.72333301168188}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t    try {\n        FileSystem fs = FileSystem.get(getConf());\n        fs.rename(new Path(ftpFile.getAbsolutePath()), new Path(getParent() + \"/\" + ftpFile.getName()));\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 63.923413394823}, {"code": "public boolean move(FtpFile ftpFile){\n\t    try {\n        FileSystem fileSystem = FileSystem.get(getConf());\n        fileSystem.rename(new Path(ftpFile.getAbsolutePath()), new Path(getParent() + \"/\" + ftpFile.getName()));\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 62.77747815756243}, {"code": "public boolean move(FtpFile ftpFile){\n\t    try {\n        FileSystem fs = FileSystem.get(new Configuration());\n        fs.rename(new Path(ftpFile.getAbsolutePath()), new Path(getParent() + \"/\" + ftpFile.getName()));\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 63.46302918183382}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t    try {\n        FileStatus[] statuses = getDfs().listStatus(getPath());\n        List<FtpFile> files = new ArrayList<FtpFile>(statuses.length);\n        String base = getAbsolutePath();\n        if (!base.endsWith(PATH_SEPARATOR_STR)) {\n            base += PATH_SEPARATOR_STR;\n        }\n        for (FileStatus status : statuses) {\n            files.add(new HdfsFtpFile(base + status.getPath().getName(), status));\n        }\n        return Collections.unmodifiableList(files);\n    } catch (IOException e) {\n        LOG.error(\"listFiles error\", e);\n        return null;\n    }\n}", "CodeBleu_score": 32.32959624549564}, {"code": "public List<FtpFile> listFiles(){\n\t    try {\n        FileSystem fs = getDfs();\n        FileStatus[] fileStatuses = fs.listStatus(getName());\n        List<FtpFile> files = new ArrayList<FtpFile>();\n        for (FileStatus fileStatus : fileStatuses) {\n            String path = getAbsolutePath() + \"/\" + fileStatus.getPath().getName();\n            files.add(new HdfsFtpFile(path, fileStatus));\n        }\n        return Collections.unmodifiableList(files);\n    } catch (IOException e) {\n        LOG.error(\"Error listing files\", e);\n        return null;\n    }\n}", "CodeBleu_score": 33.19909192261877}, {"code": "public List<FtpFile> listFiles(){\n\t    try {\n        FileSystem fs = getDfs();\n        FileStatus[] fileStatuses = fs.listStatus(getPath());\n        String[] names = getAbsolutePath().split(\"/\");\n        String baseDir = names[names.length - 1];\n        List<FtpFile> files = new ArrayList<FtpFile>();\n        for (FileStatus fileStatus : fileStatuses) {\n            String name = fileStatus.getPath().getName();\n            String virtualPath = getAbsolutePath() + \"/\" + name;\n            files.add(new HdfsFtpFile(getAbsolutePath(), name, fileStatus, fs, getDfs(), baseDir));\n        }\n        return Collections.unmodifiableList(files);\n    } catch (IOException e) {\n        LOG.error(\"Could not list files for path: \" + getAbsolutePath(), e);\n        return null;\n    }\n}", "CodeBleu_score": 38.36120609633343}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t    if (configured) {\n        return;\n    }\n\n    try {\n        if (exists()) {\n            load();\n        }\n    } catch (IOException e) {\n        throw new FtpServerConfigurationException(\n                \"Could not load user data file \" + getAbsolutePath(), e);\n    }\n\n    configured = true;\n\n    convertDeprecatedPropertyNames();\n}", "CodeBleu_score": 25.349564104525623}, {"code": "public void configure(){\n\t    if (configured) {\n        return;\n    }\n\n    try {\n        if (exists()) {\n            load();\n        }\n    } catch (IOException e) {\n        throw new FtpServerConfigurationException(getAbsolutePath(), e);\n    }\n\n    configured = true;\n\n    convertDeprecatedPropertyNames();\n}", "CodeBleu_score": 21.609598401521417}, {"code": "public void configure(){\n\t    if (isConfigured) {\n        return;\n    }\n\n    isConfigured = true;\n\n    // Load the properties file\n    try {\n        load();\n    } catch (IOException e) {\n        String filePath = getAbsolutePath();\n        throw new FtpServerConfigurationException(\n                \"Failed to load user data file \" + filePath + \": \" + e.getMessage(), e);\n    }\n\n    // Convert any deprecated property names\n    convertDeprecatedPropertyNames();\n}", "CodeBleu_score": 32.294789361393065}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\t    File parent = userDataFile.getParentFile();\n    if (parent != null && !parent.exists()) {\n        if (!parent.mkdirs()) {\n            throw new ConfigurationException(\"Unable to create parent directories for user data file\");\n        }\n    }\n    try (FileOutputStream fos = new FileOutputStream(userDataFile)) {\n        userData.store(fos, \"User data\");\n    } catch (IOException e) {\n        LOG.error(\"Error saving user data\", e);\n        throw new FtpException(\"Error saving user data\", e);\n    }\n}", "CodeBleu_score": 38.41316738668804}, {"code": "private void saveUserData() throws FtpException{\n\t    File userDataFile = new File(getAbsolutePath() + File.separator + USER_DATA_FILE);\n    File parentDir = userDataFile.getParentFile();\n    if (!parentDir.exists()) {\n        if (!parentDir.mkdirs()) {\n            throw new ConfigurationException(\"Cannot create parent directory for user data file: \" + userDataFile.getAbsolutePath());\n        }\n    }\n    try {\n        FileOutputStream fos = new FileOutputStream(userDataFile);\n        store(fos, null);\n        close();\n    } catch (IOException e) {\n        log.error(\"Cannot save user data to file: \" + userDataFile.getAbsolutePath(), e);\n        throw new FtpException(\"Cannot save user data to file: \" + userDataFile.getAbsolutePath(), e);\n    } finally {\n        close();\n    }\n}", "CodeBleu_score": 41.92879771733124}, {"code": "private void saveUserData() throws FtpException{\n\t    File parent = getParentFile();\n    if (!parent.exists()) {\n        if (!mkdirs()) {\n            throw new FtpException(\n                    \"Unable to create user data directory: \" + parent.getAbsolutePath());\n        }\n    }\n    try (FileOutputStream fos = new FileOutputStream(getAbsoluteFile())) {\n        store(fos, null);\n    } catch (IOException e) {\n        LOG.error(\"Failed to save user data\", e);\n        throw new FtpException(\"Failed to save user data\", e);\n    }\n}", "CodeBleu_score": 30.162827219029964}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    try {\n        HdfsUserManager hdfsUserManager = new HdfsUserManager();\n        hdfsUserManager.setFile(new File(\"users.properties\"));\n        hdfsUserManager.deleteUser(user);\n        return new Result(Result.SUCCESS, \"Delete user \" + user + \" success.\");\n    } catch (Exception e) {\n        logger.error(e.getMessage(), e);\n        return new Result(Result.FAILURE, \"Delete user \" + user + \" failure.\");\n    }\n}", "CodeBleu_score": 50.851577901454334}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    try {\n        HdfsUserManager hdfsUserManager = new HdfsUserManager();\n        hdfsUserManager.setFile(\"users.properties\");\n        hdfsUserManager.deleteUser(user);\n        return new Result(true, \"Success\");\n    } catch (Exception e) {\n        logger.error(e.getMessage());\n        return new Result(false, \"Failure\");\n    }\n}", "CodeBleu_score": 50.51005532628169}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    try {\n        HdfsUserManager hdfsUserManager = new HdfsUserManager();\n        hdfsUserManager.setFile(new File(\"users.properties\"));\n        hdfsUserManager.deleteUser(user);\n        return new Result(Result.SUCCESS, \"Successfully deleted user \" + user);\n    } catch (Exception e) {\n        LOGGER.error(\"Error deleting user \" + user, e);\n        return new Result(Result.FAILURE, \"Error deleting user \" + user + \": \" + e.getMessage());\n    }\n}", "CodeBleu_score": 59.438398480191324}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t    LOG.debug(\"Opening file \" + path + \" with buffer size \" + bufferSize);\n    Path qualifiedPath = getConf().get(FS_DEFAULT_NAME_KEY, FS_DEFAULT_NAME);\n    qualifiedPath = new Path(qualifiedPath, path);\n    LOG.debug(\"Qualified path is \" + qualifiedPath);\n    try {\n        return new FSDataInputStream(getInt().open(qualifiedPath, bufferSize));\n    } catch (IOException e) {\n        LOG.warn(\"Error opening file \" + path + \" with buffer size \" + bufferSize, e);\n        return null;\n    }\n}", "CodeBleu_score": 38.74020672842418}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t  LOG.debug(\"Opening file \" + path + \" with buffer size \" + bufferSize);\n  Path qualifiedPath = getConf().getQualifiedPath(path);\n  LOG.debug(\"Qualified path \" + qualifiedPath);\n  try {\n    return new FSDataInputStream(new BufferedInputStream(getInt().open(qualifiedPath), bufferSize));\n  } catch (Exception e) {\n    LOG.warn(\"Error opening file \" + path, e);\n    return null;\n  }\n}", "CodeBleu_score": 31.900856560278136}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t    debug(\"open: %s, %d\", path, bufferSize);\n    Path qualifiedPath = getConf().qualify(path);\n    debug(\"open: qualifiedPath: %s\", qualifiedPath);\n    try {\n        return new FSDataInputStream(\n                new BufferedInputStream(\n                        getInt().open(qualifiedPath), bufferSize));\n    } catch (IOException e) {\n        warn(\"open: failed to open %s\", qualifiedPath, e);\n        return null;\n    }\n}", "CodeBleu_score": 33.34092708103651}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t    LOG.debug(\"Rename: {} to {}\", src, dst);\n\n    if (src.isRoot()) {\n        return false;\n    }\n\n    if (src.equals(dst)) {\n        return true;\n    }\n\n    FileStatus dstEntry = lookupEntry(dst);\n    if (dstEntry != null && dstEntry.isDirectory()) {\n        dst = new Path(dst, src.getName());\n    }\n\n    src = qualify(src);\n    dst = qualify(dst);\n\n    return store.rename(src, dst);\n}", "CodeBleu_score": 47.496048504409885}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t    LOG.debug(\"rename {} to {}\", src, dst);\n    if (src.isRoot()) {\n        return false;\n    }\n    if (src.equals(dst)) {\n        return true;\n    }\n    Path dstParent = dst.getParent();\n    FileStatus dstEntry = lookupEntry(dstParent);\n    if (dstEntry != null && dstEntry.isDirectory()) {\n        dst = dstParent.child(dst.getName());\n    }\n    src = qualify(src);\n    dst = qualify(dst);\n    return store.rename(src, dst);\n}", "CodeBleu_score": 52.39222062709262}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t    LOG.debug(\"rename \" + src + \" to \" + dst);\n    if (src.equals(root)) {\n        return false;\n    }\n    if (src.equals(dst)) {\n        return true;\n    }\n    Path dstEntry = lookupEntry(dst);\n    if (dstEntry != null && dstEntry.isDirectory()) {\n        dst = new Path(dst, src.getName());\n    }\n    Path srcPath = qualify(src);\n    Path dstPath = qualify(dst);\n    return store.rename(srcPath, dstPath);\n}", "CodeBleu_score": 45.01331048946281}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t    String cap = capability.toLowerCase();\n    if (cap.equals(\"hsync\")) {\n        return supportFlush;\n    }\n    if (cap.equals(\"hflush\")) {\n        return supportFlush;\n    }\n    return false;\n}", "CodeBleu_score": 33.654928435288035}, {"code": "public boolean hasCapability(String capability){\n\t    if (capability.toLowerCase().equals(\"hflush\")) {\n        return supportFlush;\n    } else if (capability.toLowerCase().equals(\"hsync\")) {\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 29.219807920208968}, {"code": "public boolean hasCapability(String capability){\n\t    if (capability.toLowerCase().equals(\"hflush\")) {\n        return supportFlush;\n    } else if (capability.toLowerCase().equals(\"hsync\")) {\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 29.219807920208968}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t    // If the offset is negative or zero, return without doing anything.\n    if (offset <= 0) {\n        return;\n    }\n\n    // Get the parent directory of the file.\n    final String parentDir = getParentDirectory();\n\n    // If the parent directory is null, return without doing anything.\n    if (parentDir == null) {\n        return;\n    }\n\n    // Create a new metadata object for the file.\n    final FileMetaData meta = new FileMetaData(fileName, offset);\n\n    // Get the current time in milliseconds.\n    final long currentTime = System.currentTimeMillis();\n\n    // Set the last flush time of the metadata object to the current time.\n    meta.setLastFlushTime(currentTime);\n\n    // Set the last flush time of the file to the current time.\n    lastFlushTime = currentTime;\n\n    // Write the metadata object to the filer client.\n    filerClient.writeFileMeta(parentDir, meta);\n}", "CodeBleu_score": 26.71228709423848}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t    if (offset < 0) {\n        throw new IllegalArgumentException(\"Offset must be non-negative\");\n    }\n\n    if (offset < lastFlushOffset) {\n        throw new IllegalArgumentException(\"Offset must be greater than lastFlushOffset\");\n    }\n\n    if (offset > lastFlushOffset) {\n        if (offset > lastFlushOffset + writtenBytes.size()) {\n            throw new IllegalArgumentException(\"Offset must be less than or equal to lastFlushOffset + writtenBytes.size()\");\n        }\n\n        int numBytesToWrite = (int) (offset - lastFlushOffset);\n        byte[] bytesToWrite = new byte[numBytesToWrite];\n        for (int i = 0; i < numBytesToWrite; i++) {\n            bytesToWrite[i] = writtenBytes.get((int) (lastFlushOffset + i));\n        }\n\n        try {\n            filerClient.write(fileHandle, offset, bytesToWrite);\n        } catch (Exception e) {\n            throw new IOException(\"Error writing to filer\", e);\n        }\n\n        writtenBytes.subList(0, numBytesToWrite).clear();\n        lastFlushOffset = offset;\n    }\n}", "CodeBleu_score": 31.488555905024608}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t    if (offset == lastFlushOffset) {\n        return;\n    }\n    if (offset < lastFlushOffset) {\n        throw new IOException(\"flush offset \" + offset + \" is less than last flush offset \" + lastFlushOffset);\n    }\n    if (offset > lastFlushOffset) {\n        if (writtenBytes.size() > 0) {\n            try {\n                filerClient.write(writtenBytes.toByteArray());\n            } catch (final Throwable t) {\n                throw new IOException(\"flush written bytes to service failed\", t);\n            }\n            writtenBytes.reset();\n        }\n        lastFlushOffset = offset;\n        final long lastFlushTime = System.currentTimeMillis();\n        final String parentDirectory = getParentDirectory();\n        final String path = parentDirectory + \"/\" + fileName;\n        try {\n            filerClient.setAttribute(path, \"lastFlushOffset\", String.valueOf(lastFlushOffset));\n            filerClient.setAttribute(path, \"lastFlushTime\", String.valueOf(lastFlushTime));\n        } catch (final Throwable t) {\n            throw new IOException(\"flush written bytes to service failed\", t);\n        }\n    }\n}", "CodeBleu_score": 31.879348852959556}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t    // Flip the buffer to prepare for reading\n    bufferToWrite.flip();\n\n    // Calculate the byte length of the buffer\n    final int byteLength = bufferToWrite.limit();\n\n    // Ensure the task queue is not overloaded\n    shrinkWriteOperationQueue();\n\n    // Submit a write task to the completion service\n    writeOperationQueue.add(writeService.submit(new Callable<Integer>() {\n        @Override\n        public Integer call() throws Exception {\n            // Write the data to the service at the specified position\n            writeService.write(bufferToWrite, writePosition);\n\n            // Record the write operation\n            writeOperationQueue.add(new WriteOperation(writePosition, byteLength));\n\n            // Release the buffer\n            bufferToWrite.release();\n\n            // Return the number of bytes written\n            return byteLength;\n        }\n    }));\n\n    // Return the number of bytes written\n    return byteLength;\n}", "CodeBleu_score": 31.183219248181164}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t    bufferToWrite.flip();\n    final int bufferSize = bufferToWrite.remaining();\n    ensureTaskQueueNotOverloaded();\n    final WriteTask writeTask = new WriteTask(bufferToWrite, writePosition);\n    writeTask.addListener(new IORunnableListener<Integer>() {\n        @Override\n        public void operationComplete(final IORunnable<Integer> ioRunnable, final Integer result) {\n            recordWriteOperation(writeTask);\n            manageOperationQueue();\n        }\n    }, executor);\n    completionService.submit(writeTask);\n    return bufferSize;\n}", "CodeBleu_score": 31.75560055271951}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t    bufferToWrite.flip();\n    final int byteLength = bufferToWrite.limit();\n    ensureTaskQueueNotOverloaded();\n    final WriteTask writeTask = new WriteTask(bufferToWrite, writePosition);\n    writeTask.submitToCompletionService(completionService);\n    recordWriteOperation(byteLength);\n    manageOperationQueue();\n    return byteLength;\n}", "CodeBleu_score": 24.976785108812667}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t    while (true) {\n        try {\n            Future<?> f = completionService.take();\n            if (f == null) {\n                return;\n            }\n        } catch (InterruptedException e) {\n            throw new IOException(e);\n        }\n    }\n}", "CodeBleu_score": 28.67202943893262}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t    while (true) {\n        try {\n            Future<?> f = completionService.take();\n            if (f == null) {\n                return;\n            }\n            f.get();\n        } catch (InterruptedException e) {\n            throw new IOException(\"Interrupted\", e);\n        } catch (ExecutionException e) {\n            throw new IOException(\"Error\", e);\n        }\n    }\n}", "CodeBleu_score": 31.926992839194963}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t    try {\n        while (completionService.poll() == null) {\n            // Wait for the next task to complete\n        }\n    } catch (InterruptedException e) {\n        throw new IOException(\"Interrupted while waiting for task to complete\", e);\n    }\n}", "CodeBleu_score": 22.922935316035094}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t    // Iterate through the queue\n    Iterator<WriteOperation> it = writeOperationQueue.iterator();\n    while (it.hasNext()) {\n        WriteOperation op = it.next();\n        // Check if the task is done\n        if (op.isDone()) {\n            // Update the total append offset\n            totalAppendOffset += op.getLength();\n            // Remove the completed task from the queue\n            it.remove();\n        } else {\n            // If the task is not done, break the loop\n            break;\n        }\n    }\n}", "CodeBleu_score": 27.34799642726849}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t    Iterator<WriteOperation> iter = writeOperationQueue.iterator();\n    while (iter.hasNext()) {\n        WriteOperation operation = iter.next();\n        if (operation.isDone()) {\n            totalAppendOffset += operation.getLength();\n            iter.remove();\n        }\n    }\n}", "CodeBleu_score": 27.26612755566754}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t    Iterator<WriteOperation> iterator = writeOperationQueue.iterator();\n    while (iterator.hasNext()) {\n        WriteOperation writeOperation = iterator.next();\n        if (writeOperation.isDone()) {\n            try {\n                totalAppendOffset += writeOperation.getLength();\n            } catch (ExecutionException e) {\n                throw new IOException(e);\n            }\n            iterator.remove();\n        }\n    }\n}", "CodeBleu_score": 32.06707514391183}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t  if (user == null) {\n    throw new IllegalArgumentException(\"user cannot be null\");\n  }\n  if (user.getHomeDirectory() == null) {\n    throw new IllegalArgumentException(\"user home directory cannot be null\");\n  }\n  this.homePath=user.getHomeDirectory();\n  this.user=user;\n}", "CodeBleu_score": 72.1647133956209}, {"code": "protected HdfsFileSystemView(User user){\n\t  if (user == null) {\n    throw new IllegalArgumentException(\"user is null\");\n  }\n  if (user.getHomeDirectory() == null) {\n    throw new IllegalArgumentException(\"user.getHomeDirectory() is null\");\n  }\n  this.homePath = user.getHomeDirectory();\n  this.user = user;\n}", "CodeBleu_score": 73.63461327657026}, {"code": "protected HdfsFileSystemView(User user){\n\t  if (user == null) {\n    throw new IllegalArgumentException(\"user cannot be null\");\n  }\n  if (user.getHomeDirectory() == null) {\n    throw new IllegalArgumentException(\"user home directory cannot be null\");\n  }\n  this.homePath=user.getHomeDirectory();\n  this.user=user;\n}", "CodeBleu_score": 72.1647133956209}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t    Path newPath;\n    if (dir.startsWith(\"/\")) {\n        newPath = root.resolve(dir.substring(1));\n    } else {\n        newPath = currentPath.resolve(dir);\n    }\n    if (newPath.startsWith(root) && Files.isDirectory(newPath)) {\n        currentPath = newPath;\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 20.784831337695636}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t    Path newPath;\n    if (dir.startsWith(\"/\")) {\n        newPath = Paths.get(dir);\n    } else {\n        newPath = Paths.get(currentPath.toString(), dir);\n    }\n    if (newPath.getParent().toString().equals(\"/\")) {\n        return false;\n    }\n    if (Files.isDirectory(newPath)) {\n        currentPath = newPath;\n        return true;\n    } else {\n        return false;\n    }\n}", "CodeBleu_score": 28.828482955371765}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t    Path newPath;\n    if (dir.startsWith(\"/\")) {\n        newPath = Paths.get(dir);\n    } else {\n        newPath = Paths.get(currentPath.toString(), dir);\n    }\n    if (newPath.toString().equals(\"/\")) {\n        return false;\n    }\n    if (Files.isDirectory(newPath)) {\n        currentPath = newPath;\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 26.43016445292858}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessVolumeServerByPublicUrl = conf.getBoolean(SeaweedConstants.ACCESS_VOLUME_SERVER_BY_PUBLIC_URL, false);\n    this.accessVolumeServerByFilerProxy = conf.getBoolean(SeaweedConstants.ACCESS_VOLUME_SERVER_BY_FILER_PROXY, false);\n    this.accessVolumeServerByDirect = !(this.accessVolumeServerByPublicUrl || this.accessVolumeServerByFilerProxy);\n}", "CodeBleu_score": 39.41525300598603}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.setAccessVolumeServerByConfiguration(conf);\n}", "CodeBleu_score": 32.913955635207095}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n\n    this.filerClient = new FilerClient(host, port, grpcPort);\n\n    String accessMode = conf.get(SeaweedFSConstants.ACCESS_MODE);\n    if (accessMode != null) {\n        if (accessMode.equals(SeaweedFSConstants.ACCESS_MODE_DIRECT)) {\n            this.setAccessVolumeServerByDirect();\n        } else if (accessMode.equals(SeaweedFSConstants.ACCESS_MODE_PUBLIC_URL)) {\n            this.setAccessVolumeServerByPublicUrl();\n        } else if (accessMode.equals(SeaweedFSConstants.ACCESS_MODE_FILER_PROXY)) {\n            this.setAccessVolumeServerByFilerProxy();\n        }\n    }\n}", "CodeBleu_score": 41.15388536520243}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t    LOG.debug(\"openFileForRead: {}\", path);\n    final FileEntry entry = lookupEntry(path);\n    if (entry == null) {\n        throw new FileNotFoundException(path.toString());\n    }\n    return new SeaweedHadoopInputStream(filerClient, statistics, path);\n}", "CodeBleu_score": 69.60515298133673}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t    LOG.debug(\"Opening file {} for reading\", path);\n    final FileEntry entry = lookupEntry(path);\n    if (entry == null) {\n        throw new FileNotFoundException(\"File \" + path + \" does not exist\");\n    }\n    return new SeaweedHadoopInputStream(filerClient, statistics, path);\n}", "CodeBleu_score": 69.21151693851978}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t    LOG.debug(\"Opening {} for read\", path);\n    SeaweedHadoopFileSystem.FileEntry entry = lookupEntry(path);\n    if (entry == null) {\n        throw new FileNotFoundException(path.toString());\n    }\n    return new SeaweedHadoopInputStream(filerClient, statistics, path);\n}", "CodeBleu_score": 70.03392783334958}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\t  this.conf = conf;\n  try {\n    hostName = InetAddress.getLocalHost().getHostName();\n  }\n catch (  UnknownHostException e) {\n    hostName=\"localhost\";\n  }\n  numThreadsPerMap = conf.getInt(NUM_THREADS_PER_MAP, 1);\n  filesPerThread = conf.getInt(FILES_PER_THREAD, 1);\n  threadPool = Executors.newFixedThreadPool(numThreadsPerMap);\n  for (  Thread t : threadPool) {\n    t.setDaemon(true);\n  }\n}", "CodeBleu_score": 48.72107942831275}, {"code": "public void configure(JobConf conf){\n\t    this.conf = conf;\n    try {\n        this.localHost = InetAddress.getLocalHost().getHostName();\n    } catch (UnknownHostException e) {\n        this.localHost = \"localhost\";\n    }\n    this.numThreadsPerMap = conf.getInt(MRJobConfig.NUM_MAPS, 1);\n    this.numFilesPerThread = conf.getInt(MRJobConfig.NUM_FILES, 1);\n    this.threadPool = Executors.newFixedThreadPool(this.numThreadsPerMap, new ThreadFactory() {\n        public Thread newThread(Runnable r) {\n            Thread t = new Thread(r);\n            t.setDaemon(true);\n            return t;\n        }\n    });\n}", "CodeBleu_score": 49.21196339104972}, {"code": "public void configure(JobConf conf){\n\t  this.conf = conf;\n  try {\n    hostName = InetAddress.getLocalHost().getHostName();\n  }\n catch (  Exception e) {\n    hostName=\"localhost\";\n  }\n  numThreadsPerMap = conf.getInt(JobConf.MAP_TASKS, JobConf.DEFAULT_MAP_TASKS);\n  numFilesPerThread = conf.getInt(JobConf.MAP_OUTPUT_FILE, JobConf.DEFAULT_MAP_OUTPUT_FILE);\n  threadPool = Executors.newFixedThreadPool(numThreadsPerMap, new ThreadFactory() {\n    private int count=0;\n    public Thread newThread(    Runnable r) {\n      Thread t = new Thread(r);\n      t.setDaemon(true);\n      t.setName(\"mapper-\" + count++);\n      return t;\n    }\n  }\n);\n}", "CodeBleu_score": 52.65424477308386}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t    final String host = getHost(uri);\n    synchronized (TrashEmptier.class) {\n        if (isRunning(host)) {\n            return;\n        }\n        final UserGroupInformation ugi = createRemoteUser(conf);\n        final FileSystem fs = getEmptier(conf);\n        final Trash trash = getConf(conf);\n        final TrashScheduler scheduler = new TrashScheduler(fs, trash, ugi);\n        final long interval = toMillis(conf.get(DFS_TRASH_INTERVAL_KEY, DFS_TRASH_INTERVAL_DEFAULT));\n        final long delay = toMillis(conf.get(DFS_TRASH_CHECK_INTERVAL_KEY, DFS_TRASH_CHECK_INTERVAL_DEFAULT));\n        final ScheduledExecutorService executor = Executors.newSingleThreadScheduledExecutor(new ThreadFactory() {\n            @Override\n            public Thread newThread(Runnable r) {\n                final Thread t = new Thread(r);\n                t.setDaemon(true);\n                return t;\n            }\n        });\n        executor.scheduleAtFixedRate(new Runnable() {\n            @Override\n            public void run() {\n                try {\n                    scheduler.expunge(interval);\n                } catch (IOException e) {\n                    LOG.warn(\"Trash emptier failed to expunge trash\", e);\n                }\n            }\n        }, delay, interval, TimeUnit.MILLISECONDS);\n        executors.put(host, executor);\n    }\n}", "CodeBleu_score": 34.81179664204811}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t    // Check if the trash emptier is already running for the specified host\n    if (isRunning(uri)) {\n        return;\n    }\n\n    // Create a superuser\n    UserGroupInformation superUser = createRemoteUser(uri, conf);\n\n    // Initialize a JuiceFileSystemImpl instance as the superuser\n    try {\n        superUser.doAs((PrivilegedExceptionAction<Void>) () -> {\n            initialize(conf);\n            return null;\n        });\n    } catch (InterruptedException e) {\n        throw new IOException(e);\n    }\n\n    // Start the trash emptier task\n    try {\n        superUser.doAs((PrivilegedExceptionAction<Void>) () -> {\n            getEmptier().start(getConf());\n            return null;\n        });\n    } catch (InterruptedException e) {\n        throw new IOException(e);\n    }\n}", "CodeBleu_score": 30.295892324058027}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t    final String host = getHost(uri);\n    synchronized (this) {\n        if (isRunning(host)) {\n            return;\n        }\n        final UserGroupInformation superuser = createRemoteUser(uri, conf);\n        try {\n            final FileSystem fs = new JuiceFileSystemImpl();\n            fs.initialize(uri, conf);\n            final Trash trash = getEmptier(conf);\n            final ScheduledExecutorService executor = Executors.newScheduledThreadPool(1);\n            executor.scheduleWithFixedDelay(new Runnable() {\n\n                @Override\n                public void run() {\n                    try {\n                        trash.emptyTrash(fs);\n                    } catch (IOException e) {\n                        LOG.warn(\"Error emptying trash\", e);\n                    }\n                }\n            }, 0, toMillis(conf), TimeUnit.MILLISECONDS);\n            running.put(host, executor);\n        } catch (IOException e) {\n            throw new IOException(\"Error starting trash emptier\", e);\n        }\n    }\n}", "CodeBleu_score": 38.338576636685666}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t    String current = getCurrent();\n    if (current == null || !isContextValid(current)) {\n        current = build(context);\n    } else if (!current.contains(context)) {\n        current = current + \",\" + context;\n    }\n    setCurrent(current);\n}", "CodeBleu_score": 25.254934122804784}, {"code": "public static void setContext(String context) throws Exception{\n\t    // Get the current caller context\n    String currentContext = getCurrent();\n\n    // Check if the current context is valid\n    if (!isContextValid(currentContext)) {\n        // If the current context is invalid, create a new caller context\n        build(context);\n    } else {\n        // If the current context is valid, check if it already includes the provided context\n        if (!currentContext.contains(context)) {\n            // If the current context does not already include the provided context, append the new context to the existing one\n            String newContext = currentContext + \";\" + context;\n            // Set the new caller context\n            setCurrent(newContext);\n        }\n    }\n}", "CodeBleu_score": 21.099122885015735}, {"code": "public static void setContext(String context) throws Exception{\n\t    // Get the current caller context\n    String currentContext = getCurrent();\n\n    // Check if the current context is valid\n    if (!isContextValid(currentContext)) {\n        // If the current context is invalid, create a new caller context\n        build(context);\n    } else {\n        // If the current context is valid, check if it already includes the provided context\n        if (!currentContext.contains(context)) {\n            // If the current context does not already include the provided context, append the new context to the existing one\n            String newContext = currentContext + \",\" + context;\n            setCurrent(newContext);\n        }\n    }\n}", "CodeBleu_score": 21.09028098024397}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t  RETURN_NOT_OK(connect(uri.to_path()));\n  int ret = hdfsDelete(fs_, uri.to_path().c_str());\n  if (ret < 0) {\n    auto err = std::string(hdfsGetLastError());\n    LOG_STATUS(Status_HDFSError(err));\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot delete file \") + uri.to_string() +\n        std::string(\"; \") + err));\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 59.943162709265565}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t  auto fs = connect(uri.to_path());\n  if (fs == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to delete file \") + uri.to_string()));\n  }\n\n  int rc = hdfsDelete(fs.get(), uri.to_path().c_str());\n  if (rc != 0) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to delete file \") + uri.to_string()));\n  }\n\n  return Status::Ok();\n}", "CodeBleu_score": 65.98879421742454}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t  std::string file_name = uri.to_path();\n  hdfsFS fs = connect(uri);\n  if (fs == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to connect to HDFS backend\")));\n  }\n  int rc = hdfsDelete(fs, file_name.c_str());\n  if (rc == -1) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to delete file \") + file_name));\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 56.804558727047436}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\t  RETURN_NOT_OK(connect(uri));\n\n  // Check if file exists\n  bool is_file;\n  RETURN_NOT_OK(this->is_file(uri, &is_file));\n  if (!is_file)\n    return Status::Ok();\n\n  // Open file\n  hdfsFile file =\n      libhdfs_->hdfsOpenFile(fs_, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n  if (!file) {\n    auto err = std::string(libhdfs_->hdfsGetLastError());\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot open HDFS file \") + uri.to_string() +\n        std::string(\"\n\") + err));\n  }\n\n  // Flush file\n  auto ret = libhdfs_->hdfsHFlush(fs_, file);\n  if (ret < 0) {\n    auto err = std::string(libhdfs_->hdfsGetLastError());\n    libhdfs_->hdfsCloseFile(fs_, file);\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot flush HDFS file \") + uri.to_string() +\n        std::string(\"\n\") + err));\n  }\n\n  // Close file\n  RETURN_NOT_OK(close_file(file));\n\n  return Status::Ok();\n}", "CodeBleu_score": 63.54258731925633}, {"code": "Status HDFS::sync(const URI& uri){\n\t  // Connect\n  hdfsFS fs = connect();\n  if (fs == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot connect to HDFS\"));\n  }\n\n  // Check if file exists\n  int exists = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n  if (!exists) {\n    return Status::Ok();\n  }\n\n  // Open file\n  hdfsFile file = libhdfs_->hdfsOpenFile(\n      fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n  if (file == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot open HDFS file \") + uri.to_string()));\n  }\n\n  // Flush file\n  int ret = libhdfs_->hdfsHFlush(fs, file);\n  if (ret < 0) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot flush HDFS file \") + uri.to_string()));\n  }\n\n  // Close file\n  RETURN_NOT_OK(libhdfs_->hdfsCloseFile(fs, file));\n\n  return Status::Ok();\n}", "CodeBleu_score": 63.05371894455549}, {"code": "Status HDFS::sync(const URI& uri){\n\t  // Connect\n  RETURN_NOT_OK(connect(nullptr));\n\n  // Check file type\n  bool is_file;\n  RETURN_NOT_OK(this->is_file(uri, &is_file));\n  if (!is_file)\n    return Status::Ok();\n\n  // Open file\n  hdfsFile file =\n      libhdfs_->hdfsOpenFile(fs_, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n  if (!file) {\n    auto st = LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot open HDFS file \") + uri.to_string()));\n    return st;\n  }\n\n  // Flush\n  if (libhdfs_->hdfsHFlush(fs_, file)) {\n    auto st = LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot flush HDFS file \") + uri.to_string()));\n    tdb_close(fs_, file);\n    return st;\n  }\n\n  // Close file\n  if (libhdfs_->hdfsCloseFile(fs_, file)) {\n    auto st = LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot close HDFS file \") + uri.to_string()));\n    return st;\n  }\n\n  return Status::Ok();\n}", "CodeBleu_score": 64.5604186068457}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  // Connect to the HDFS file system\n  hdfsFS fs = connect();\n  if (fs == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot connect to HDFS\"));\n  }\n\n  // Get the file information\n  hdfsFileInfo* file_info = hdfsGetPathInfo(fs, uri.to_string().c_str());\n  if (file_info == nullptr) {\n    std::stringstream errmsg;\n    errmsg << \"Cannot get path info from HDFS '\" << uri.to_string() << \"'\";\n    return LOG_STATUS(Status_HDFSError(errmsg.str()));\n  }\n\n  // Check if the path is a file\n  if (file_info->mKind != kObjectKindFile) {\n    std::stringstream errmsg;\n    errmsg << \"Path '\" << uri.to_string() << \"' is not a file\";\n    return LOG_STATUS(Status_HDFSError(errmsg.str()));\n  }\n\n  // Set the size in bytes\n  *nbytes = static_cast<uint64_t>(file_info->mSize);\n\n  // Free the file information\n  hdfsFreeFileInfo(file_info, 1);\n\n  // Return success\n  return Status::Ok();\n}", "CodeBleu_score": 53.89383857776233}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  if (uri.is_hdfs()) {\n    *nbytes = 0;\n    hdfsFS fs = connect();\n    if (fs == nullptr)\n      return LOG_STATUS(Status_HDFSError(\n          std::string(\"Failed to connect to HDFS backend\")));\n\n    int ret = 0;\n    hdfsFileInfo* fileInfo = hdfsGetPathInfo(fs, uri.to_path().c_str());\n    if (fileInfo == nullptr) {\n      ret = hdfsGetLastError();\n      std::string err_msg = std::string(\"Cannot get path info: \") +\n                            std::string(hdfsGetLastError());\n      hdfsFreeFileInfo(fileInfo, 1);\n      disconnect();\n      return LOG_STATUS(Status_HDFSError(err_msg));\n    }\n\n    if (fileInfo->mKind != tObjectKind::kObjectKindFile) {\n      hdfsFreeFileInfo(fileInfo, 1);\n      disconnect();\n      return LOG_STATUS(Status_HDFSError(\n          std::string(\"Path is not a file: \" + uri.to_string())));\n    }\n\n    *nbytes = static_cast<uint64_t>(fileInfo->mSize);\n    hdfsFreeFileInfo(fileInfo, 1);\n    disconnect();\n    return Status::Ok();\n  }\n\n  return LOG_STATUS(Status_HDFSError(\n      std::string(\"Non HDFS URI: \" + uri.to_string())));\n}", "CodeBleu_score": 54.81460516496276}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  // Connect to HDFS\n  hdfsFS fs = connect();\n  if (fs == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot connect to HDFS\"));\n  }\n\n  // Get file info\n  hdfsFileInfo* file_info = hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (file_info == nullptr) {\n    std::stringstream errmsg;\n    errmsg << \"Cannot get file info \" << uri.to_string();\n    return LOG_STATUS(Status_HDFSError(errmsg.str()));\n  }\n\n  // Retrieve file size\n  if (!hdfsIsFile(file_info)) {\n    std::stringstream errmsg;\n    errmsg << \"Path is not a file \" << uri.to_string();\n    return LOG_STATUS(Status_HDFSError(errmsg.str()));\n  }\n  *nbytes = static_cast<uint64_t>(file_info->mSize);\n\n  // Clean up\n  hdfsFreeFileInfo(file_info, 1);\n\n  return Status::Ok();\n}", "CodeBleu_score": 55.2098389880013}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    String quorum = null;\n    String znodeParent = null;\n    String[] configs = hbaseCfgString.split(\",\");\n    for (String config : configs) {\n        String[] keyValue = config.split(\"=\");\n        if (keyValue.length != 2) {\n            continue;\n        }\n        String key = keyValue[0].trim();\n        String value = keyValue[1].trim();\n        if (key.equals(\"hbase.zookeeper.quorum\")) {\n            quorum = value;\n            if (!value.contains(\":\")) {\n                quorum += \":2181\";\n            }\n        } else if (key.equals(\"zookeeper.znode.parent\")) {\n            znodeParent = value;\n        }\n    }\n    if (quorum == null) {\n        throw new IllegalArgumentException(\"Invalid HBase configuration string: \" + hbaseCfgString);\n    }\n    if (znodeParent == null) {\n        znodeParent = \"/hbase\";\n    }\n    return new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 34.12452847605776}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    String quorum = hbaseCfgString;\n    String znodeParent = \"/hbase\";\n    int colonIndex = hbaseCfgString.indexOf(':');\n    if (colonIndex != -1) {\n        quorum = hbaseCfgString.substring(0, colonIndex);\n        try {\n            int port = Integer.parseInt(hbaseCfgString.substring(colonIndex + 1));\n            quorum += \":\" + port;\n        } catch (NumberFormatException e) {\n            // ignore, assume default port\n        }\n    }\n    int slashIndex = hbaseCfgString.lastIndexOf('/');\n    if (slashIndex != -1) {\n        znodeParent = hbaseCfgString.substring(slashIndex);\n    }\n    return new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 38.20381850503812}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    String quorum = null;\n    String znodeParent = null;\n    String[] cfgPairs = hbaseCfgString.split(\",\");\n    for (String cfgPair : cfgPairs) {\n        String[] kv = cfgPair.split(\"=\");\n        if (kv.length != 2) {\n            continue;\n        }\n        String key = kv[0].trim();\n        String value = kv[1].trim();\n        if (key.equals(\"hbase.zookeeper.quorum\")) {\n            quorum = value;\n            if (!value.contains(\":\")) {\n                quorum += \":2181\";\n            }\n        } else if (key.equals(\"zookeeper.znode.parent\")) {\n            znodeParent = value;\n        }\n    }\n    if (quorum == null) {\n        throw new IllegalArgumentException(\"HBase configuration string does not contain a valid quorum\");\n    }\n    if (znodeParent == null) {\n        znodeParent = \"/hbase\";\n    }\n    return new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 33.386442825308066}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    try (Connection conn = getJdbcConnection(cfg.getJdbcUrl(), cfg.getUserName(), cfg.getPassword())) {\n        checkTable(conn, cfg.getNamespace(), cfg.getTableName());\n        List<Column> columns = getColumns(conn, cfg.getNamespace(), cfg.getTableName());\n        for (Column column : cfg.getColumns()) {\n            getColumnForColumnName(columns, column.getName());\n        }\n    } catch (SQLException e) {\n        throw asAddaxException(e);\n    }\n}", "CodeBleu_score": 20.524707293916087}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    try (Connection conn = getJdbcConnection(cfg)) {\n        checkTable(cfg, conn);\n        List<Column> columns = getColumns(cfg, conn);\n        for (String columnName : cfg.getColumn()) {\n            boolean found = false;\n            for (Column column : columns) {\n                if (column.getName().equals(columnName)) {\n                    found = true;\n                    break;\n                }\n            }\n            if (!found) {\n                throw asAddaxException(String.format(\"Column %s does not exist in table %s\", columnName, cfg.getTable()));\n            }\n        }\n    } catch (SQLException e) {\n        throw asAddaxException(e);\n    }\n}", "CodeBleu_score": 26.076693641021336}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    // Establish a JDBC connection\n    Connection conn = getJdbcConnection(cfg.getJdbcUrl(), cfg.getUsername(), cfg.getPassword());\n\n    // Check if the specified table exists in the given namespace\n    checkTable(conn, cfg.getTableName(), cfg.getNamespace());\n\n    // Retrieve the table schema\n    List<Column> columns = getColumns(conn, cfg.getTableName(), cfg.getNamespace());\n\n    // Ensure that all configured columns exist in the target table\n    for (String columnName : cfg.getColumn()) {\n        boolean columnExists = false;\n        for (Column column : columns) {\n            if (column.getName().equalsIgnoreCase(columnName)) {\n                columnExists = true;\n                break;\n            }\n        }\n        if (!columnExists) {\n            throw asAddaxException(ErrorCode.CONFIG_INVALID, String.format(\"Column '%s' does not exist in the target table.\", columnName));\n        }\n    }\n}", "CodeBleu_score": 30.400271153016647}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n        try {\n            UserGroupInformation.setConfiguration(HadoopConfiguration.getConfiguration());\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            LOG.error(\"Kerberos login error\", e);\n            throw new AsAddaxException(format(\"Kerberos login error: %s\", e.getMessage()));\n        }\n    }\n}", "CodeBleu_score": 39.48294652116117}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\n        try {\n            UserGroupInformation.setConfiguration(new Configuration());\n            loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            error(\"Kerberos login error: {}\", e.getMessage());\n            throw asAddaxException(format(\"Kerberos login error: %s\", e.getMessage()), e);\n        }\n    }\n}", "CodeBleu_score": 32.66633213901886}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (kerberosPrincipal != null && !kerberosPrincipal.isBlank() && kerberosKeytabFilePath != null && !kerberosKeytabFilePath.isBlank()) {\n        try {\n            UserGroupInformation.setConfiguration(new Configuration());\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            LOGGER.error(e.getMessage());\n            throw new AsAddaxException(format(\"Kerberos login error: %s\", e.getMessage()));\n        }\n    }\n}", "CodeBleu_score": 35.534554097466696}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t        Map<String, ThinClientPTable.ThinClientPColumn> colTypes = new HashMap<>();\n        ResultSetMetaData metaData = rs.getMetaData();\n        for (int i = 1; i <= metaData.getColumnCount(); i++) {\n            String colName = metaData.getColumnLabel(i);\n            String colType = metaData.getColumnTypeName(i);\n            if (colName == null || colType == null) {\n                throw new SQLException(\"Column name or type is null\");\n            }\n            colTypes.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n        }\n        return colTypes;\n    }", "CodeBleu_score": 42.248888735151304}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t        Map<String, ThinClientPTable.ThinClientPColumn> colTypes = new HashMap<>();\n        ResultSetMetaData metaData = rs.getMetaData();\n        int columnCount = metaData.getColumnCount();\n        for (int i = 1; i <= columnCount; i++) {\n            String columnName = metaData.getColumnLabel(i);\n            String columnType = metaData.getColumnTypeName(i);\n            if (columnName == null || columnType == null) {\n                throw new SQLException(\"Column name or type is null\");\n            }\n            ThinClientPTable.ThinClientPColumn col = new ThinClientPTable.ThinClientPColumn(columnName, columnType);\n            colTypes.put(columnName, col);\n        }\n        return colTypes;\n    }", "CodeBleu_score": 44.761144296198225}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t        Map<String, ThinClientPTable.ThinClientPColumn> colMap = new HashMap<>();\n        ResultSetMetaData metaData = rs.getMetaData();\n        for (int i = 1; i <= metaData.getColumnCount(); i++) {\n            String colName = metaData.getColumnLabel(i);\n            String colType = metaData.getColumnTypeName(i);\n            if (colName == null || colType == null) {\n                throw new SQLException(\"Column name or type is null\");\n            }\n            colMap.put(colName, new ThinClientPTable.ThinClientPColumn(colType));\n        }\n        return colMap;\n    }", "CodeBleu_score": 39.37133658845818}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try {\n        PhoenixConnection phoenixConn = conn.unwrap(PhoenixConnection.class);\n        Admin admin = phoenixConn.getAdmin();\n\n        if (!checkTable(admin, tableName)) {\n            throw new AddaxException(-100, \"Table \" + tableName + \" does not exist\");\n        }\n\n        disableTable(admin, tableName);\n\n        admin.truncateTable(tableName, true);\n\n        LOG.debug(\"Table {} has been truncated\", tableName);\n    } catch (Exception e) {\n        throw asAddaxException(e);\n    } finally {\n        closeAdmin(admin);\n    }\n}", "CodeBleu_score": 44.598673964594035}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try {\n        PhoenixConnection phoenixConn = conn.unwrap(PhoenixConnection.class);\n        Admin admin = phoenixConn.getHBaseAdmin();\n        if (checkTable(admin, tableName)) {\n            disableTable(admin, tableName);\n            admin.truncateTable(TableName.valueOf(tableName), true);\n            log.debug(\"Table {} has been truncated\", tableName);\n        }\n    } catch (Exception e) {\n        throw asAddaxException(ErrorCode.UNKNOWN_ERROR, e.getMessage(), e);\n    } finally {\n        closeAdmin(admin);\n    }\n}", "CodeBleu_score": 40.24707102025601}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try {\n        PhoenixConnection phoenixConn = conn.unwrap(PhoenixConnection.class);\n        Admin admin = phoenixConn.getAdmin();\n        checkTable(admin, tableName);\n        disableTable(admin, tableName);\n        admin.truncateTable(tableName, false);\n        logger.debug(\"Table \" + tableName + \" has been truncated\");\n    } catch (Exception e) {\n        throw asAddaxException(ErrorCode.UNKNOWN_ERROR, \"Truncate table \" + tableName + \" failed\", e);\n    } finally {\n        closeAdmin(admin);\n    }\n}", "CodeBleu_score": 40.584670786227}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\t    FileType fileType = FileType.getFileType(filePath);\n    if (fileType == null) {\n        logger.error(\"The file type is not supported. filePath: {}\", filePath);\n        throw new AddaxException(\"The file type is not supported. filePath: \" + filePath);\n    }\n    if (fileType.equals(this.fileType)) {\n        logger.info(\"The file is added to the source files list. filePath: {}\", filePath);\n        sourceFiles.add(filePath);\n    } else {\n        logger.error(\"The file type does not match the configured file type. filePath: {}, fileType: {}, configured fileType: {}\", filePath, fileType, this.fileType);\n        throw new AddaxException(\"The file type does not match the configured file type. filePath: \" + filePath + \", fileType: \" + fileType + \", configured fileType: \" + this.fileType);\n    }\n}", "CodeBleu_score": 35.55236885581332}, {"code": "private void addSourceFileByType(String filePath){\n\t    if (filePath.endsWith(fileType)) {\n        LOG.info(\"File {} is added as a source file\", filePath);\n        sourceFiles.add(filePath);\n    } else {\n        String errorMessage = String.format(\"File %s is not a %s file\", filePath, fileType);\n        LOG.error(errorMessage);\n        throw new AsAddaxException(errorMessage);\n    }\n}", "CodeBleu_score": 27.59165152908493}, {"code": "private void addSourceFileByType(String filePath){\n\t    try {\n        FileType fileType = getFileType(filePath);\n        if (fileType == FileType.HDFS) {\n            log.info(\"Adding HDFS file: {}\", filePath);\n            sourceFiles.add(filePath);\n        } else {\n            log.error(\"Unsupported file type for HDFS: {}\", fileType);\n            throw new AsAddaxException(\"Unsupported file type for HDFS: \" + fileType);\n        }\n    } catch (Exception e) {\n        throw new AsAddaxException(\"Failed to check HDFS file type: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 28.565930498046722}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t        try {\n            LOG.info(\"Start to read sequence file from {}\", sourceSequenceFilePath);\n            FileSystem fs = FileSystem.get(new Configuration());\n            Path path = new Path(sourceSequenceFilePath);\n            SequenceFile.Reader reader = new SequenceFile.Reader(fs, path, readerSliceConfig);\n            Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n            Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), readerSliceConfig);\n            while (reader.next(key, value)) {\n                if (isNotBlank(value.toString())) {\n                    transportOneRecord(key, value, recordSender, taskPluginCollector);\n                }\n            }\n            reader.close();\n            LOG.info(\"Finish reading sequence file from {}\", sourceSequenceFilePath);\n        } catch (IOException e) {\n            LOG.error(\"Failed to read sequence file from {}\", sourceSequenceFilePath, e);\n            throw new AddaxException(\"Failed to read sequence file from \" + sourceSequenceFilePath, e);\n        }\n    }", "CodeBleu_score": 49.525277255108136}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t    LOG.info(\"Start reading sequence file from {}\", sourceSequenceFilePath);\n    try (SequenceFile.Reader reader = new SequenceFile.Reader(FileSystem.get(new Configuration()),\n            new Path(sourceSequenceFilePath), readerSliceConfig)) {\n        Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n        Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), readerSliceConfig);\n        while (reader.next(key, value)) {\n            if (value.toString().isNotBlank()) {\n                StorageReaderUtil.transportOneRecord(key.toString(), value.toString(), recordSender, taskPluginCollector);\n            }\n        }\n    } catch (Exception e) {\n        LOG.error(\"Read sequence file error\", e);\n        throw new AddaxException(AddaxException.TASK_ERROR_CODE, \"Read sequence file error\", e);\n    }\n}", "CodeBleu_score": 47.948101027949285}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t        LOG.info(\"Start read sequence file: {}\", sourceSequenceFilePath);\n        try (SequenceFile.Reader reader = new SequenceFile.Reader(new FileSystem(readerSliceConfig),\n                new Path(sourceSequenceFilePath), readerSliceConfig)) {\n            Text key = new Text();\n            Text value = new Text();\n            while (reader.next(key, value)) {\n                if (StringUtils.isNotBlank(value.toString())) {\n                    StorageReaderUtil.transportOneRecord(key.toString(), value.toString(), recordSender, taskPluginCollector);\n                }\n            }\n        } catch (Exception e) {\n            LOG.error(\"Read sequence file: {} failed.\", sourceSequenceFilePath, e);\n            throw new AddaxException(\"Read sequence file: \" + sourceSequenceFilePath + \" failed.\", e);\n        }\n    }", "CodeBleu_score": 44.170538146910076}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    try (FileSystem fs = FileSystem.get(new Configuration())) {\n        Path path = new Path(filepath);\n        if (fs.exists(path)) {\n            if (specifiedFileType.equalsIgnoreCase(\"ORC\")) {\n                return isORCFile(fs, path);\n            } else if (specifiedFileType.equalsIgnoreCase(\"RC\")) {\n                return isRCFile(fs, path);\n            } else if (specifiedFileType.equalsIgnoreCase(\"Sequence\")) {\n                return isSequenceFile(fs, path);\n            } else if (specifiedFileType.equalsIgnoreCase(\"Parquet\")) {\n                return isParquetFile(fs, path);\n            } else if (specifiedFileType.equalsIgnoreCase(\"CSV\")) {\n                return isCSVFile(fs, path);\n            } else if (specifiedFileType.equalsIgnoreCase(\"Text\")) {\n                return isTextFile(fs, path);\n            } else {\n                return false;\n            }\n        } else {\n            return false;\n        }\n    } catch (Exception e) {\n        log.error(\"Error occurred while checking HDFS file type: {}\", e.getMessage());\n        throw asAddaxException(AddaxException.COMMAND_ERROR, e.getMessage());\n    }\n}", "CodeBleu_score": 36.70943005952353}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    try (FileSystem fs = FileSystem.get(new Configuration())) {\n        Path path = new Path(filepath);\n        FileStatus fileStatus = fs.getFileStatus(path);\n\n        switch (specifiedFileType) {\n            case \"ORC\":\n                return isORCFile(fileStatus);\n            case \"RC\":\n                return isRCFile(fileStatus);\n            case \"Sequence\":\n                return isSequenceFile(fileStatus);\n            case \"Parquet\":\n                return isParquetFile(fileStatus);\n            case \"CSV\":\n                return isCSVFile(fileStatus);\n            case \"Text\":\n                return isTextFile(fileStatus);\n            default:\n                return false;\n        }\n    } catch (IOException e) {\n        logger.error(\"Error occurred while checking HDFS file type\", e);\n        throw new AddaxException(ErrorCode.FILE_TYPE_ERROR, \"Error occurred while checking HDFS file type\");\n    }\n}", "CodeBleu_score": 32.402169317728124}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    try {\n        FileSystem fileSystem = FileSystem.get(new Configuration());\n        Path path = new Path(filepath);\n        CompressionCodecFactory factory = new CompressionCodecFactory(fileSystem.getConf());\n        CompressionCodec codec = factory.getCodec(path);\n        if (codec != null) {\n            filepath = codec.getDefaultExtension();\n        }\n        if (specifiedFileType.equalsIgnoreCase(\"ORC\")) {\n            return isORCFile(filepath);\n        } else if (specifiedFileType.equalsIgnoreCase(\"RC\")) {\n            return isRCFile(filepath);\n        } else if (specifiedFileType.equalsIgnoreCase(\"SEQUENCE\")) {\n            return isSequenceFile(filepath);\n        } else if (specifiedFileType.equalsIgnoreCase(\"PARQUET\")) {\n            return isParquetFile(filepath);\n        } else if (specifiedFileType.equalsIgnoreCase(\"CSV\")) {\n            return isCSVFile(filepath);\n        } else if (specifiedFileType.equalsIgnoreCase(\"TEXT\")) {\n            return isTextFile(filepath);\n        } else {\n            return false;\n        }\n    } catch (Exception e) {\n        LOG.error(\"Error checking HDFS file type: \" + e.getMessage(), e);\n        throw new AddaxException(ErrorCode.UNSUPPORTED_FILE_TYPE, e);\n    }\n}", "CodeBleu_score": 43.8786872008339}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t    if (hConnection != null) {\n        try {\n            hConnection.close();\n        }\n        catch (IOException e) {\n            throw new asAddaxException(\"HBASE_CONNECTION_CLOSE_FAILED\", e);\n        }\n    }\n}", "CodeBleu_score": 50.671245111763156}, {"code": "public static void closeConnection(Connection hConnection){\n\t    if (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new asAddaxException(\"Could not close HBase connection\", e);\n        }\n    }\n}", "CodeBleu_score": 48.77854883274859}, {"code": "public static void closeConnection(Connection hConnection){\n\t    if (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new asAddaxException(e.getMessage(), \"HBase\", \"closeConnection\", \"HBase\", 500);\n        }\n    }\n}", "CodeBleu_score": 44.41516865715756}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t    if (admin != null) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw new asAddaxException(asAddaxErrorCode.ASADDAX_HBASE_ADMIN_CLOSE_FAILURE, e.getMessage(), e);\n        }\n    }\n}", "CodeBleu_score": 51.374075639563024}, {"code": "public static void closeAdmin(Admin admin){\n\t    if (admin != null) {\n        try {\n            admin.close();\n        }\n        catch (IOException e) {\n            throw new asAddaxException(asAddaxException.HBASE_ADMIN_CLOSE_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 54.45986777507383}, {"code": "public static void closeAdmin(Admin admin){\n\t    if (admin != null) {\n        try {\n            admin.close();\n        }\n        catch (IOException e) {\n            throw new asAddaxException(asAddaxException.CLOSE_ADMIN_FAILED, e);\n        }\n    }\n}", "CodeBleu_score": 53.40858427141251}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t        if (cell == null) {\n            return;\n        }\n\n        // Add row key\n        addRowKey(cell, record);\n\n        // Add timestamp\n        addTimestamp(cell, record);\n\n        // Add column family and qualifier name\n        addColumn(cell, record);\n\n        // Add column value\n        addColumnValue(cell, record);\n    }", "CodeBleu_score": 2.4736497881360506}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t        byte[] rowKey = cell.getRowArray();\n        byte[] columnFamily = cell.getFamilyArray();\n        byte[] qualifier = cell.getQualifierArray();\n        long timestamp = cell.getTimestamp();\n        byte[] value = cell.getValueArray();\n\n        String rowKeyType = getTypeName(rowKey);\n        String rowKeyFormat = getFormat(rowKeyType);\n        String rowKeyValue = convertBytesToAssignType(rowKey, rowKeyType, rowKeyFormat);\n        addColumn(record, \"rowKey\", rowKeyValue);\n\n        String columnFamilyType = getTypeName(columnFamily);\n        String columnFamilyFormat = getFormat(columnFamilyType);\n        String columnFamilyValue = convertBytesToAssignType(columnFamily, columnFamilyType, columnFamilyFormat);\n        addColumn(record, \"columnFamily\", columnFamilyValue);\n\n        String qualifierType = getTypeName(qualifier);\n        String qualifierFormat = getFormat(qualifierType);\n        String qualifierValue = convertBytesToAssignType(qualifier, qualifierType, qualifierFormat);\n        addColumn(record, \"qualifier\", qualifierValue);\n\n        String timestampType = getTypeName(timestamp);\n        String timestampFormat = getFormat(timestampType);\n        String timestampValue = convertBytesToAssignType(timestamp, timestampType, timestampFormat);\n        addColumn(record, \"timestamp\", timestampValue);\n\n        String valueType = getTypeName(value);\n        String valueFormat = getFormat(valueType);\n        String valueValue = convertBytesToAssignType(value, valueType, valueFormat);\n        addColumn(record, \"value\", valueValue);\n    }", "CodeBleu_score": 34.347166805387694}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t        // Extract the row key, timestamp, column family, qualifier, and value from the cell\n        String rowKey = Bytes.toString(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength());\n        long timestamp = cell.getTimestamp();\n        String family = Bytes.toString(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength());\n        String qualifier = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());\n        String value = Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());\n\n        // Determine the types and formats for the row key and column value based on predefined mappings\n        String rowKeyType = \"STRING\";\n        String rowKeyFormat = \"TEXT\";\n        String columnValueType = \"STRING\";\n        String columnValueFormat = \"TEXT\";\n\n        // Convert the extracted data to the appropriate types and add them as columns to the record\n        record.addColumn(new StringColumn(\"rowKey\", rowKey, rowKeyType, rowKeyFormat));\n        record.addColumn(new StringColumn(\"family\", family, \"STRING\", \"TEXT\"));\n        record.addColumn(new StringColumn(\"qualifier\", qualifier, \"STRING\", \"TEXT\"));\n        record.addColumn(new LongColumn(\"timestamp\", timestamp, \"LONG\", \"LONG\"));\n        record.addColumn(new StringColumn(\"value\", value, columnValueType, columnValueFormat));\n    }", "CodeBleu_score": 29.86644991971779}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(Constants.USER_START_ROWKEY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return new byte[0];\n    }\n    boolean isBinary = configuration.getBool(Constants.USER_START_ROWKEY_IS_BINARY);\n    if (isBinary) {\n        return stringToBytes(startRowkey);\n    } else {\n        return startRowkey.getBytes(StandardCharsets.UTF_8);\n    }\n}", "CodeBleu_score": 59.85043564456758}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(Constants.START_ROWKEY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return new byte[0];\n    }\n    if (configuration.getBool(Constants.IS_BINARY_ROWKEY, false)) {\n        return stringToBytes(startRowkey);\n    } else {\n        return startRowkey.getBytes(Constants.DEFAULT_CHARSET);\n    }\n}", "CodeBleu_score": 51.702380670241844}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(Constants.USER_START_ROWKEY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return new byte[0];\n    }\n    boolean isBinaryRowkey = configuration.getBool(Constants.USER_IS_BINARY_ROWKEY);\n    if (isBinaryRowkey) {\n        return stringToBytes(startRowkey);\n    } else {\n        return startRowkey.getBytes(StandardCharsets.UTF_8);\n    }\n}", "CodeBleu_score": 61.03002766241934}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(Constants.START_ROWKEY, \"\");\n    if (StringUtils.isBlank(startRowkey)) {\n        return new byte[0];\n    }\n    return Bytes.toBytesBinary(startRowkey);\n}", "CodeBleu_score": 66.33769075413758}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(Constants.START_ROWKEY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return new byte[0];\n    } else {\n        return Bytes.toBytesBinary(startRowkey);\n    }\n}", "CodeBleu_score": 66.57367869241256}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(Constants.START_ROWKEY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return new byte[0];\n    }\n    return Bytes.toBytesBinary(startRowkey);\n}", "CodeBleu_score": 68.73514123415757}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.headers = new TbQueueMsgHeaders();\n    record.headers().forEach(header -> this.headers.put(header.key(), header.value()));\n    this.data = record.value();\n}", "CodeBleu_score": 54.8456197185472}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.headers = new TbQueueMsgHeaders();\n    record.headers().forEach(header -> this.headers.put(header.key(), header.value()));\n    this.data = record.value();\n}", "CodeBleu_score": 54.8456197185472}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.headers = new TbQueueMsgHeaders(record.headers());\n    this.data = record.value();\n}", "CodeBleu_score": 43.38814105979103}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    TbKafkaProducerTemplate<TbProtoQueueMsg<ToTransportMsg>> producerTemplate =\n            new TbKafkaProducerTemplate<>(kafkaSettings, clientId, defaultTopic);\n    TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbQueueProducer<>(producerTemplate);\n    producer.setAdmin(admin);\n    return producer;\n}", "CodeBleu_score": 30.379685056145178}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    TbQueueProducerTemplate<TbProtoQueueMsg<ToTransportMsg>> template = new TbQueueProducerTemplate<>(settings, clientId, defaultTopic, ToTransportMsg.class);\n    TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = template.build();\n    producer.setAdmin(admin);\n    return producer;\n}", "CodeBleu_score": 34.83296172442204}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    TbKafkaSettings kafkaSettings = settings.getKafka();\n    TbKafkaClientId clientId = new TbKafkaClientId(getServiceId());\n    TbKafkaTopicName defaultTopic = new TbKafkaTopicName(getNotificationsTopic());\n    TbKafkaProducerTemplate<TbProtoQueueMsg<ToTransportMsg>> builder = TbKafkaProducerTemplate.<TbProtoQueueMsg<ToTransportMsg>>builder()\n            .settings(kafkaSettings)\n            .clientId(clientId)\n            .defaultTopic(defaultTopic);\n    TbKafkaAdmin admin = new TbKafkaAdmin(kafkaSettings);\n    TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = builder.build();\n    producer.setAdmin(admin);\n    return producer;\n}", "CodeBleu_score": 43.4608721469513}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    return new TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>>(settings, topic, clientId, groupId) {\n        @Override\n        protected void init() {\n            decoder = new TbProtoDecoder<>(ToCoreNotificationMsg.getDescriptor());\n            admin = new TbKafkaAdmin(settings, clientId);\n            statisticsService = new TbKafkaStatsService(settings, getFullTopicName(topic), admin);\n        }\n    };\n}", "CodeBleu_score": 26.780156049963455}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    return new TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>>(settings, topic, clientId, groupId)\n            .setMessageDecoder(new TbProtoMsgDecoder<>(ToCoreNotificationMsg.getDescriptor()))\n            .configure(admin, statisticsService);\n}", "CodeBleu_score": 15.555205393701026}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate =\n            new TbKafkaConsumerTemplate<>(settings, buildTopicName(TOPIC_CORE_NOTIFICATIONS), clientId, groupId);\n    consumerTemplate.setMessageDecoder(new ProtobufMsgDecoder<>(ToCoreNotificationMsg.class));\n    consumerTemplate.configureConsumer(admin, statsService);\n    return consumerTemplate;\n}", "CodeBleu_score": 20.320600539598455}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (!topicNames.isEmpty()) {\n        topicNames.forEach(topicName -> {\n            if (!topicExists(topicName)) {\n                createTopic(topicName);\n            }\n        });\n        subscribe(topicNames);\n    } else {\n        log.info(\"No topics provided. Unsubscribing consumer from all topics.\");\n        unsubscribe();\n    }\n}", "CodeBleu_score": 59.100728683733784}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (!topicNames.isEmpty()) {\n        topicNames.forEach(topicName -> {\n            try {\n                createTopicIfNecessary(topicName);\n            } catch (Exception e) {\n                throw new RuntimeException(\"Failed to create topic \" + topicName, e);\n            }\n        });\n        consumer.subscribe(topicNames);\n    } else {\n        log.info(\"No topics provided. Unsubscribing consumer from all topics.\");\n        consumer.unsubscribe();\n    }\n}", "CodeBleu_score": 62.496980315273056}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (topicNames.isEmpty()) {\n        log.info(\"No topics provided. Unsubscribing from all topics.\");\n        consumer.unsubscribe();\n    } else {\n        log.info(\"Subscribing to topics: {}\", topicNames);\n        topicNames.forEach(topicName -> {\n            try {\n                createTopicIfNotExists(topicName);\n            } catch (Exception e) {\n                log.error(\"Error creating topic: {}\", topicName, e);\n            }\n        });\n        consumer.subscribe(topicNames);\n    }\n}", "CodeBleu_score": 53.849531528212346}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t        Stopwatch stopwatch = Stopwatch.createStarted();\n        LOGGER.info(\"Polling topic {} for {} ms\", getTopic(), durationInMillis);\n        ConsumerRecords<String, byte[]> records = poll(durationInMillis);\n        stopwatch.stop();\n        LOGGER.info(\"Polled topic {} for {} ms\", getTopic(), stopwatch.elapsed(TimeUnit.MILLISECONDS));\n        if (records.isEmpty()) {\n            return emptyList();\n        } else {\n            return records.records(getTopic()).stream()\n                    .map(this::trace)\n                    .collect(Collectors.toList());\n        }\n    }", "CodeBleu_score": 47.87287515222279}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t    Stopwatch stopwatch = Stopwatch.createStarted();\n    log.trace(\"Polling topic {} for {} ms\", getTopic(), durationInMillis);\n    ConsumerRecords<String, byte[]> records = poll(durationInMillis);\n    stopwatch.stop();\n    log.trace(\"Polled topic {} for {} ms\", getTopic(), stopwatch.elapsed(TimeUnit.MILLISECONDS));\n    if (records.isEmpty()) {\n        return emptyList();\n    }\n    return records.records(getTopic()).stream().map(record -> new ConsumerRecord<>(record.topic(), record.partition(), record.offset(), record.key(), record.value())).collect(Collectors.toList());\n}", "CodeBleu_score": 49.14552681066354}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t    Stopwatch stopwatch = Stopwatch.createStarted();\n    LOGGER.trace(\"Polling topic {} for {} ms\", getTopic(), durationInMillis);\n    ConsumerRecords<String, byte[]> records = poll(durationInMillis);\n    stopwatch.stop();\n    LOGGER.trace(\"Polled topic {} for {} ms, {} records found\", getTopic(), stopwatch.elapsed(TimeUnit.MILLISECONDS),\n        records.count());\n    if (records.isEmpty()) {\n        return emptyList();\n    }\n    return stream(records.iterator())\n        .map(record -> new ConsumerRecord<>(record.topic(), record.partition(), record.offset(), record.key(),\n            record.value()))\n        .collect(toList());\n}", "CodeBleu_score": 49.153006682301694}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    try {\n        executeAsync(ctx, () -> {\n            try {\n                KafkaSettings settings = ctx.getSettings(KafkaSettings.class);\n                String topicPattern = getTopicPattern(settings);\n                String keyPattern = getKeyPattern(settings);\n                if (topicPattern.isEmpty() || keyPattern.isEmpty()) {\n                    tellFailure(ctx, msg);\n                    return;\n                }\n                String topic = processPattern(topicPattern, msg);\n                String key = processPattern(keyPattern, msg);\n                publish(settings, topic, key, msg);\n                ackIfNeeded(ctx, settings);\n            } catch (Exception e) {\n                log.error(\"[{}] Failed to publish message to Kafka\", ctx.getSelf().getName(), e);\n                tellFailure(ctx, msg);\n            }\n        });\n    } catch (Exception e) {\n        log.error(\"[{}] Failed to publish message to Kafka\", ctx.getSelf().getName(), e);\n        tellFailure(ctx, msg);\n    }\n}", "CodeBleu_score": 44.97896745130932}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    try {\n        KafkaActionConfiguration configuration = ctx.getNode().getConfiguration();\n        String topicPattern = configuration.getTopicPattern();\n        String keyPattern = configuration.getKeyPattern();\n        if (topicPattern == null || topicPattern.isEmpty()) {\n            ctx.tellFailure(ctx.getSelf(), new Exception(\"Topic pattern is empty\"));\n            return;\n        }\n        if (keyPattern == null || keyPattern.isEmpty()) {\n            ctx.tellFailure(ctx.getSelf(), new Exception(\"Key pattern is empty\"));\n            return;\n        }\n        if (msg == null) {\n            ctx.tellFailure(ctx.getSelf(), new Exception(\"Message is empty\"));\n            return;\n        }\n        executeAsync(ctx, msg, topicPattern, keyPattern);\n    } catch (Exception e) {\n        ctx.tellFailure(ctx.getSelf(), e);\n    }\n}", "CodeBleu_score": 42.02437068950729}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    try {\n        processPattern(msg, ctx);\n        if (ctx.isFailure()) {\n            return;\n        }\n        ackIfNeeded(ctx, msg);\n        getTopicPattern().getAsyncExecutor().executeAsync(publish(msg));\n    } catch (Exception e) {\n        log.error(\"[{}] Failed to publish message to Kafka\", ctx.getSelf().getName(), e);\n        ctx.tellFailure(e);\n    }\n}", "CodeBleu_score": 19.050303507729748}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t    try {\n        if (addMetaData) {\n            Map<String, String> headers = msg.getMetaData();\n            if (headers != null) {\n                Iterator<Map.Entry<String, String>> it = headers.entrySet().iterator();\n                while (it.hasNext()) {\n                    Map.Entry<String, String> entry = it.next();\n                    headers.put(entry.getKey(), entry.getValue());\n                }\n            }\n            ctx.send(topic, key, msg.getData(), headers);\n        } else {\n            ctx.send(topic, key, msg.getData());\n        }\n        processRecord(ctx, msg);\n    } catch (Exception e) {\n        ctx.debug(\"Failed to publish message to topic \" + topic + \": \" + e.getMessage());\n    }\n}", "CodeBleu_score": 36.59473161865287}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t    try {\n        byte[] data = getData(msg);\n        ProducerRecord<String, byte[]> record = processRecord(ctx, msg, topic, key, data);\n        if (addMetaData) {\n            Map<String, String> metaData = getMetaData(ctx, msg);\n            Headers headers = new RecordHeaders();\n            for (Map.Entry<String, String> entry : metaData.entrySet()) {\n                headers.add(entry.getKey(), entry.getValue().getBytes());\n            }\n            record = new ProducerRecord<>(topic, null, key, data, headers);\n        }\n        send(ctx, record);\n    } catch (Exception e) {\n        log.debug(\"[{}] Failed to publish message: {}\", getSelfId(), msg);\n    }\n}", "CodeBleu_score": 44.75475491404948}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t    try {\n        if (addMetaData) {\n            Map<String, String> headers = msg.getMetaData();\n            if (headers == null) {\n                headers = new HashMap<>();\n            }\n            headers.put(TbMsgHeaders.MSG_ID, msg.getId().toString());\n            headers.put(TbMsgHeaders.ORIGINATOR_TENANT_ID, msg.getOriginator().getTenantId().toString());\n            headers.put(TbMsgHeaders.ORIGINATOR_ENTITY_ID, msg.getOriginator().getId().toString());\n            headers.put(TbMsgHeaders.ORIGINATOR_ENTITY_TYPE, msg.getOriginator().getEntityType().name());\n            headers.put(TbMsgHeaders.MSG_TYPE, msg.getType());\n            headers.put(TbMsgHeaders.REQUEST_ID, ctx.getRequestId().toString());\n            headers.put(TbMsgHeaders.SEARCH_TEXT, ctx.getSearchText());\n            headers.put(TbMsgHeaders.RELATED_ENTITY_ID, ctx.getRelatedId().toString());\n            headers.put(TbMsgHeaders.RELATED_ENTITY_TYPE, ctx.getRelatedType().name());\n            headers.put(TbMsgHeaders.ENTITY_NAME, ctx.getEntityName());\n            headers.put(TbMsgHeaders.MSG_SCOPE, msg.getScope().name());\n            headers.put(TbMsgHeaders.REQUEST_TYPE, ctx.getRequestType().name());\n            headers.put(TbMsgHeaders.REQUEST_SCOPE, ctx.getRequestScope().name());\n            headers.put(TbMsgHeaders.REQUEST_STATUS, ctx.getRequestStatus().name());\n            headers.put(TbMsgHeaders.REQUEST_BODY, ctx.getRequestBody());\n            headers.put(TbMsgHeaders.REQUEST_QUERY, ctx.getRequestQuery());\n            headers.put(TbMsgHeaders.REQUEST_BODY_SEARCH_TEXT, ctx.getRequestBodySearchText());\n            headers.put(TbMsgHeaders.REQUEST_QUERY_SEARCH_TEXT, ctx.getRequestQuerySearch", "CodeBleu_score": 23.68972493813638}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\t    try {\n        if (producer != null) {\n            producer.close();\n        }\n    } catch (Exception e) {\n        log.error(\"Failed to close Kafka producer cleanly\", e);\n    }\n}", "CodeBleu_score": 68.54518428350683}, {"code": "public void destroy(){\n\t    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            logger.error(\"Failed to close Kafka producer cleanly\", e);\n        }\n    }\n}", "CodeBleu_score": 68.62067764422697}, {"code": "public void destroy(){\n\t    try {\n        if (producer != null) {\n            producer.close();\n        }\n    } catch (Exception e) {\n        log.error(\"Failed to close Kafka producer cleanly\", e);\n    }\n}", "CodeBleu_score": 68.54518428350683}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    KafkaProducerTemplateBuilder<String, byte[]> builder =\n            KafkaProducerTemplateBuilder.builder(settings, clientId, defaultTopic, admin);\n    return builder.build();\n}", "CodeBleu_score": 31.818341135735828}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    TbQueueProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> builder = TbQueueProducerTemplateBuilder.<TbProtoQueueMsg<ToRuleEngineMsg>>builder()\n            .kafkaSettings(kafkaSettings)\n            .clientId(serviceInfoProvider.getServiceId() + \"-rule-engine-msg-producer\")\n            .defaultTopic(defaultTopic)\n            .admin(admin);\n    return builder.build();\n}", "CodeBleu_score": 41.75066511380218}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    return new TbQueueProducer<>(\n            KafkaTemplateBuilder.<String, byte[]>builder()\n                    .settings(kafkaSettings)\n                    .clientId(serviceInfoProvider.getServiceId())\n                    .defaultTopic(defaultTopic)\n                    .admin(admin)\n                    .build()\n    );\n}", "CodeBleu_score": 21.61744170991137}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\t    try {\n        Duration kafkaResponseTimeout = Duration.ofMillis(getKafkaResponseTimeoutMs());\n        ScheduledExecutorService scheduledExecutorService = Executors.newSingleThreadScheduledExecutor();\n        scheduledExecutorService.scheduleWithFixedDelay(\n                () -> {\n                    try {\n                        if (isStatsPrintRequired()) {\n                            for (String groupId : getMonitoredConsumerGroupIds()) {\n                                Map<TopicPartition, OffsetAndMetadata> partitionsToOffsetAndMetadata = listConsumerGroupOffsets(groupId);\n                                Map<TopicPartition, Long> endOffsets = getEndOffsets(partitionsToOffsetAndMetadata.keySet());\n                                List<TopicStatsWithLag> topicsStatsWithLag = getTopicsStatsWithLag(partitionsToOffsetAndMetadata, endOffsets);\n                                if (!topicsStatsWithLag.isEmpty()) {\n                                    log.warn(\n                                            \"Consumer group '{}' has lagging topics: {}\",\n                                            groupId,\n                                            topicsStatsWithLag\n                                    );\n                                }\n                            }\n                        }\n                    } catch (Exception e) {\n                        log.warn(\n                                \"Failed to retrieve consumer group offsets for group '{}'\",\n                                groupId,\n                                e\n                        );\n                    }\n                },\n                getPrintIntervalMs(),\n                getPrintIntervalMs(),\n                TimeUnit.MILLISECONDS\n        );\n    } catch (Exception e) {\n        log.error(\"Failed to schedule logging of Kafka consumer group statistics\", e);\n    }\n}", "CodeBleu_score": 37.78220593055842}, {"code": "private void startLogScheduling(){\n\t    try {\n        long timeoutDuration = TimeUnit.MILLISECONDS.convert(kafkaResponseTimeoutMs, TimeUnit.MILLISECONDS);\n        scheduledExecutorService.scheduleWithFixedDelay(() -> {\n            try {\n                if (isStatsPrintRequired.get()) {\n                    for (String groupId : groupIds) {\n                        Map<TopicPartition, OffsetAndMetadata> partitionsToOffsetAndMetadata =\n                                getAdminClient().listConsumerGroupOffsets(groupId);\n                        Map<TopicPartition, Long> endOffsets = getAdminClient().endOffsets(partitionsToOffsetAndMetadata.keySet());\n                        Map<String, TopicStatsWithLag> topicsStatsWithLag = getTopicsStatsWithLag(\n                                partitionsToOffsetAndMetadata, endOffsets);\n                        if (!topicsStatsWithLag.isEmpty()) {\n                            log.info(\"Group: {}, Topics with lag: {}\", groupId, topicsStatsWithLag);\n                        }\n                    }\n                }\n            } catch (Exception e) {\n                log.warn(\"Error while printing group stats for groupId: {}, error: {}\", groupId, e.getMessage(), e);\n            }\n        }, printIntervalMs, printIntervalMs, TimeUnit.MILLISECONDS);\n    } catch (Exception e) {\n        log.warn(\"Error while scheduling stats printing task, error: {}\", e.getMessage(), e);\n    }\n}", "CodeBleu_score": 40.44057881963071}, {"code": "private void startLogScheduling(){\n\t    Duration kafkaResponseTimeout = Duration.ofMillis(kafkaResponseTimeoutMs);\n    Duration timeout = kafkaResponseTimeout.plus(Duration.ofMillis(printIntervalMs));\n    ScheduledExecutorService executor = Executors.newSingleThreadScheduledExecutor();\n    executor.scheduleWithFixedDelay(() -> {\n        try {\n            if (isStatsPrintRequired()) {\n                for (String groupId : groupIds) {\n                    try {\n                        Map<TopicPartition, OffsetAndMetadata> partitionsToOffsetAndMetadata = getTopicsStatsWithLag(groupId);\n                        if (!partitionsToOffsetAndMetadata.isEmpty()) {\n                            log.warn(\"Consumer group {} has lagging topics: {}\", groupId, partitionsToOffsetAndMetadata);\n                        }\n                    } catch (Exception e) {\n                        log.warn(\"Error while monitoring consumer group {}: {}\", groupId, e.getMessage(), e);\n                    }\n                }\n            }\n        } catch (Exception e) {\n            log.warn(\"Error while monitoring consumer groups: {}\", e.getMessage(), e);\n        }\n    }, printIntervalMs, printIntervalMs, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 32.173417880910705}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\t    Properties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n    return props;\n}", "CodeBleu_score": 91.69084212730418}, {"code": "protected Properties toAdminProps(){\n\t    Properties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    props.put(AdminClientConfig.RETRIES_CONFIG, 3);\n    return props;\n}", "CodeBleu_score": 82.54321802981079}, {"code": "protected Properties toAdminProps(){\n\t    Properties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n    return props;\n}", "CodeBleu_score": 91.69084212730418}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t    String scopedName = getScopedName(metricName, group);\n    MetricEvent event = new MetricEvent(scopedName, getTags(group));\n    if (metric instanceof Counter) {\n        counters.put(metric, event);\n    } else if (metric instanceof Gauge) {\n        gauges.put(metric, event);\n    } else if (metric instanceof Histogram) {\n        histograms.put(metric, event);\n    } else if (metric instanceof Meter) {\n        meters.put(metric, event);\n    } else {\n        logger.warn(\"Metric type not supported: \" + metric.getClass());\n    }\n}", "CodeBleu_score": 51.57296399345328}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t    String scopedName = getScopedName(metricName, group);\n    MetricEvent event = new MetricEvent(scopedName, getTags(group));\n    if (metric instanceof Counter) {\n        counters.put(metric, event);\n    } else if (metric instanceof Gauge) {\n        gauges.put(metric, event);\n    } else if (metric instanceof Histogram) {\n        histograms.put(metric, event);\n    } else if (metric instanceof Meter) {\n        meters.put(metric, event);\n    } else {\n        warn(String.format(\"Metric type %s is not supported.\", metric.getClass().getName()));\n    }\n}", "CodeBleu_score": 52.45186488914464}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t    String scopedName = getScopedName(metricName, group);\n    MetricEvent event = new MetricEvent(scopedName, getTags(metric, group));\n    if (metric instanceof Counter) {\n        counters.add((Counter) metric);\n        counterEvents.add(event);\n    } else if (metric instanceof Gauge) {\n        gauges.add((Gauge) metric);\n        gaugeEvents.add(event);\n    } else if (metric instanceof Histogram) {\n        histograms.add((Histogram) metric);\n        histogramEvents.add(event);\n    } else if (metric instanceof Meter) {\n        meters.add((Meter) metric);\n        meterEvents.add(event);\n    } else {\n        warn(String.format(\"The metric type %s is not supported\", metric.getClass().getName()));\n    }\n}", "CodeBleu_score": 51.48752964949439}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t    Object value = gauge.getValue();\n    if (value instanceof Number) {\n        metricEvent.setFields(Map.of(field, value));\n    } else {\n        metricEvent.setFields(Map.of(field, value.toString()));\n    }\n    return metricEvent;\n}", "CodeBleu_score": 26.882505226968632}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t    Object value = gauge.getValue();\n    if (value instanceof Number) {\n        Number numberValue = (Number) value;\n        metricEvent.put(field, numberValue);\n    } else if (value instanceof String) {\n        String stringValue = (String) value;\n        metricEvent.put(field, stringValue);\n    } else {\n        throw new IllegalArgumentException(\"Unsupported value type: \" + value.getClass());\n    }\n    return metricEvent;\n}", "CodeBleu_score": 39.85283090319999}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t    Object value = gauge.getValue();\n    if (value instanceof Number) {\n        Number numberValue = (Number) value;\n        metricEvent.setFields(metricEvent.getFields().put(field, numberValue));\n    } else {\n        metricEvent.setFields(metricEvent.getFields().put(field, value.toString()));\n    }\n    return metricEvent;\n}", "CodeBleu_score": 35.00386054801718}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t    if (gauge == null) {\n        return metricEvent;\n    }\n\n    String gaugeValue = gauge.getValue().toString();\n    String[] components = gaugeValue.split(\",\");\n    if (components.length != 3) {\n        return metricEvent;\n    }\n\n    String currentOffset = components[0].split(\":\")[1].trim();\n    String dataTimestamp = components[1].split(\":\")[1].trim();\n    String committedOffset = components[2].split(\":\")[1].trim();\n\n    if (metricEvent.getFields().get(\"currentOffset\") != null && metricEvent.getFields().get(\"currentOffset\").equals(currentOffset) &&\n            metricEvent.getFields().get(\"dataTimestamp\") != null && metricEvent.getFields().get(\"dataTimestamp\").equals(dataTimestamp) &&\n            metricEvent.getFields().get(\"committedOffset\") != null && metricEvent.getFields().get(\"committedOffset\").equals(committedOffset)) {\n        return metricEvent;\n    }\n\n    metricEvent.getFields().put(\"currentOffset\", currentOffset);\n    metricEvent.getFields().put(\"dataTimestamp\", dataTimestamp);\n    metricEvent.getFields().put(\"committedOffset\", committedOffset);\n\n    metricEvent.setTimestamp(timestamp);\n    return metricEvent;\n}", "CodeBleu_score": 36.28890312765194}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t    String[] components = gauge.toString().split(\":\");\n    String currentOffsets = components[1].split(\",\")[0].replaceAll(\"currentOffsets=\\\\{\", \"\");\n    String dataTimestamp = components[2].split(\",\")[0].replaceAll(\"dataTimestamp=\", \"\");\n    String committedOffsets = components[3].split(\"\\\\}\")[0].replaceAll(\"committedOffsets=\\\\{\", \"\");\n    String[] currentOffsetComponents = currentOffsets.split(\",\");\n    String[] committedOffsetComponents = committedOffsets.split(\",\");\n    if (currentOffsetComponents.length == committedOffsetComponents.length) {\n        for (int i = 0; i < currentOffsetComponents.length; i++) {\n            String currentOffset = currentOffsetComponents[i].split(\"=\")[1];\n            String committedOffset = committedOffsetComponents[i].split(\"=\")[1];\n            String topic = currentOffsetComponents[i].split(\"=\")[0].replaceAll(\"\\\\{\", \"\");\n            String topicGroup = topic.split(\"-\")[0];\n            String metricName = \"kafka.lag.\" + topicGroup;\n            String metricKey = metricName + \".\" + topic;\n            if (kafkaLagTimes.containsKey(metricKey)) {\n                if (kafkaLagTimes.get(metricKey) == timestamp) {\n                    continue;\n                }\n            }\n            kafkaLagTimes.put(metricKey, timestamp);\n            metricEvent.setTimestamp(timestamp);\n            metricEvent.setName(metricName);\n            metricEvent.setTags(Collections.singletonMap(\"topic\", topic));\n            metricEvent.setFields(Collections.singletonMap(\"value\", Long.parseLong(currentOffset) - Long.parseLong(committedOffset)));\n        }\n    }\n    return metricEvent;\n}\n", "CodeBleu_score": 32.1639501555989}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t  def kafkaLagTimes = metricEvent.getKafkaLagTimes()\n  def kafkaLagTimesUpdated = false\n  def kafkaLagTimesMap = metricEvent.getKafkaLagTimes()\n  def kafkaLagTimesMapUpdated = false\n  def kafkaLagTimesMapValues = metricEvent.getKafkaLagTimes().values()\n  def kafkaLagTimesMapValuesUpdated = false\n  def kafkaLagTimesMapValuesKeys = metricEvent.getKafkaLagTimes().values().keys()\n  def kafkaLagTimesMapValuesKeysUpdated = false\n  def kafkaLagTimesMapValuesKeysValues = metricEvent.getKafkaLagTimes().values().keys().values()\n  def kafkaLagTimesMapValuesKeysValuesUpdated = false\n  def kafkaLagTimesMapValuesKeysValuesKeys = metricEvent.getKafkaLagTimes().values().keys().values().keys()\n  def kafkaLagTimesMapValuesKeysValuesKeysUpdated = false\n  def kafkaLagTimesMapValuesKeysValuesKeysValues = metricEvent.getKafkaLagTimes().values().keys().values().keys().values()\n  def kafkaLagTimesMapValuesKeysValuesKeysValuesUpdated = false\n  def kafkaLagTimesMapValuesKeysValuesKeysValuesKeys = metricEvent.getKafkaLagTimes().values().keys().values().keys().values().keys()\n  def kafkaLagTimesMapValuesKeysValuesKeysValuesKeysUpdated = false\n  def kafkaLagTimesMapValuesKeysValuesKeysValuesKeysValues = metricEvent.getKafkaLagTimes().values().keys().values().keys().values().keys().values()\n  def kafkaLagTimesMapValuesKeysValuesKeysValuesKeysValuesKeysUpdated = false\n  def kafkaLagTimesMapValuesKeysValuesKeysValuesKeysValuesKeysValues = metricEvent.getKafkaLagTimes().values().keys().values().keys().values().keys().values().keys()\n  def kafkaLagTimesMapValuesKeysValuesKeysValuesKeysValuesKeysValuesUpdated = false\n  def kafkaLagTimesMapValuesKeysValuesKeysValuesKeysValuesKeys", "CodeBleu_score": 12.741022659500087}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t    Map<String, String> globalJobParameters = getConfig(env);\n    Properties kafkaProps = buildKafkaProps(globalJobParameters);\n    FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), kafkaProps);\n    if (time != null) {\n        setStartFromSpecificOffsets(consumer, time);\n    }\n    addSource(env, consumer);\n    return env.addSource(consumer);\n}", "CodeBleu_score": 45.83539930985302}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t    // Get global job parameters from the StreamExecutionEnvironment\n    ParameterTool params = (ParameterTool) env.getConfig().getGlobalJobParameters();\n    // Build Kafka properties using the global job parameters\n    Properties props = buildKafkaProps(params);\n    // Instantiate a FlinkKafkaConsumer for MetricEvent with the topic, schema, and properties\n    FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(\n            topic,\n            new MetricEventSchema(),\n            props);\n    // If a specific start time is provided, set the consumer to start from the specific offsets based on the given time\n    if (time != null) {\n        consumer.setStartFromSpecificOffsets(buildOffsetByTime(time));\n    }\n    // Add the consumer as a source to the StreamExecutionEnvironment\n    DataStreamSource<MetricEvent> source = env.addSource(consumer);\n    return source;\n}", "CodeBleu_score": 68.53395330929122}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t    Map<String, String> globalJobParameters = getConfig(env);\n    Properties kafkaProps = buildKafkaProps(globalJobParameters);\n    FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(\n            topic,\n            new MetricEventSchema(),\n            kafkaProps\n    );\n    if (time != null) {\n        setStartFromSpecificOffsets(consumer, time);\n    }\n    addSource(env, consumer);\n    return env.addSource(consumer);\n}", "CodeBleu_score": 51.6710872894687}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t    String groupId = String.valueOf(time);\n    props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupId);\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n    Map<String, List<PartitionInfo>> partitions = consumer.listTopics();\n    Map<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\n    for (Map.Entry<String, List<PartitionInfo>> entry : partitions.entrySet()) {\n        String topic = entry.getKey();\n        List<PartitionInfo> partitionInfoList = entry.getValue();\n        for (PartitionInfo partitionInfo : partitionInfoList) {\n            int partition = partitionInfo.partition();\n            KafkaTopicPartition topicPartition = new KafkaTopicPartition(topic, partition);\n            partitionOffsets.put(topicPartition, time);\n        }\n    }\n    Map<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(partitionOffsets);\n    consumer.close();\n    return offsets.entrySet().stream()\n            .collect(Collectors.toMap(\n                    entry -> new KafkaTopicPartition(entry.getKey().topic(), entry.getKey().partition()),\n                    entry -> entry.getValue().offset()\n            ));\n}", "CodeBleu_score": 44.4910370675048}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t    props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, String.valueOf(time));\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n    Map<TopicPartition, Long> partitions = consumer.partitionsFor(parameterTool.getRequired(TOPIC_OPTION)).entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, e -> time));\n    Map<KafkaTopicPartition, Long> offsets = consumer.offsetsForTimes(partitions);\n    consumer.close();\n    return offsets;\n}", "CodeBleu_score": 34.71818822780591}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t    String groupId = String.valueOf(time);\n    props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupId);\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n    List<PartitionInfo> partitions = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\n    Map<TopicPartition, Long> timestampsToSearch = new HashMap<>();\n    for (PartitionInfo partitionInfo : partitions) {\n        timestampsToSearch.put(new TopicPartition(parameterTool.getRequired(\"topic\"), partitionInfo.partition()), time);\n    }\n    Map<KafkaTopicPartition, Long> partitionOffsets = consumer.offsetsForTimes(timestampsToSearch);\n    consumer.close();\n    return partitionOffsets;\n}", "CodeBleu_score": 47.352325998669585}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t    // Set up Kafka producer properties\n    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n    // Create KafkaProducer instance with properties\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    // Create MetricEvent and populate with current timestamp, name, tags, and fields\n    MetricEvent event = new MetricEvent();\n    event.setTimestamp(System.currentTimeMillis());\n    event.setName(\"my_metric\");\n    event.setTags(new HashMap<String, String>() {{\n        put(\"tag1\", \"value1\");\n        put(\"tag2\", \"value2\");\n    }});\n    event.setFields(new HashMap<String, Object>() {{\n        put(\"field1\", 1);\n        put(\"field2\", 2);\n    }});\n\n    // Create ProducerRecord with serialized MetricEvent and send to specified topic\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"my_topic\", event.toJson());\n    producer.send(record);\n\n    // Print sent data and flush producer to ensure all data is sent\n    System.out.println(\"Sent data: \" + event.toJson());\n    producer.flush();\n}", "CodeBleu_score": 50.00514875080436}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t    // Set up Kafka producer properties\n    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n    // Create KafkaProducer instance\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    // Create MetricEvent\n    MetricEvent event = new MetricEvent();\n    event.setTimestamp(System.currentTimeMillis());\n    event.setName(\"my_metric\");\n    event.setTags(new HashMap<>());\n    event.getTags().put(\"tag1\", \"value1\");\n    event.setFields(new HashMap<>());\n    event.getFields().put(\"field1\", 1.0);\n\n    // Create ProducerRecord and send to topic\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"my_topic\", event.toJson());\n    producer.send(record);\n\n    // Print sent data and flush producer\n    System.out.println(\"Sent data: \" + event.toJson());\n    producer.flush();\n}", "CodeBleu_score": 49.47385968817297}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    MetricEvent event = new MetricEvent();\n    event.setTimestamp(System.currentTimeMillis());\n    event.setName(\"my_metric\");\n    event.setTags(new HashMap<>());\n    event.getTags().put(\"tag1\", \"value1\");\n    event.getTags().put(\"tag2\", \"value2\");\n    event.setFields(new HashMap<>());\n    event.getFields().put(\"field1\", 123);\n    event.getFields().put(\"field2\", 456);\n\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"my_topic\", event.toJson());\n    producer.send(record);\n    System.out.println(\"Sent data: \" + event.toJson());\n    producer.flush();\n    producer.close();\n}", "CodeBleu_score": 51.26182429793877}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    if (this.levels.contains(event.getLevel()) && !event.getLoggerName().contains(\"xxx\")) {\n        try {\n            this.producer.send(new ProducerRecord(this.topic, event.getMessage().getFormattedMessage())).get();\n        } catch (Exception e) {\n            LOGGER.warn(\"Error while sending message to Kafka\", e);\n        }\n    }\n}", "CodeBleu_score": 47.563475373149736}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    try {\n        if (this.levels.contains(event.getLevel()) && !event.getLoggerName().contains(\"xxx\")) {\n            byte[] logMessage = this.getLayout().toByteArray(event);\n            ProducerRecord<String, String> record = new ProducerRecord<String, String>(this.topic, new String(logMessage, \"UTF-8\"));\n            this.producer.send(record);\n        }\n    } catch (Exception e) {\n        this.warn(\"Error sending log event to Kafka\", e);\n    }\n}", "CodeBleu_score": 49.82980161130432}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    try {\n        if (event.getLevel().isIn(this.levels)) {\n            String loggerName = event.getLoggerName();\n            if (!loggerName.contains(\"xxx\")) {\n                String message = event.getMessage().getFormattedMessage();\n                ProducerRecord<String, String> record = new ProducerRecord<>(this.topic, loggerName, message);\n                this.producer.send(record);\n            }\n        }\n    } catch (Exception e) {\n        LOGGER.warn(\"Error processing event\", e);\n    }\n}", "CodeBleu_score": 46.289972956796696}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, m := range []string{\"\", \"create\", \"update\", \"delete\"} {\n\t\tif method == m {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 71.5972508504744}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 89.40480295903943}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tvalidMethods := []string{\n\t\t\"\",\n\t\t\"last\",\n\t\t\"first\",\n\t\t\"max\",\n\t\t\"min\",\n\t\t\"avg\",\n\t\t\"sum\",\n\t\t\"count\",\n\t}\n\n\tfor _, validMethod := range validMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 77.38688592306009}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tkey := k.RoutingKey\n\n\tif key == \"random\" {\n\t\tuuid, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn uuid.String(), nil\n\t}\n\n\tif key == \"\" {\n\t\treturn \"\", nil\n\t}\n\n\ttag, ok := metric.GetTag(k.RoutingTag)\n\tif ok {\n\t\treturn tag, nil\n\t}\n\n\treturn key, nil\n}", "CodeBleu_score": 73.03448890425524}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingKey == \"random\" {\n\t\tuuid, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn uuid.String(), nil\n\t}\n\n\tif k.RoutingTag != \"\" {\n\t\ttag, ok := metric.GetTag(k.RoutingTag)\n\t\tif !ok {\n\t\t\treturn \"\", fmt.Errorf(\"routing tag %q not found in metric %v\", k.RoutingTag, metric.Name())\n\t\t}\n\t\treturn tag, nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 73.42119991550994}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \"\" {\n\t\tif value, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn value, nil\n\t\t} else {\n\t\t\treturn \"\", fmt.Errorf(\"metric does not contain tag %s\", k.RoutingTag)\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\tuuid, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn uuid.String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 78.36239346805043}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tregexps := make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, regexpStr := range k.TopicRegexps {\n\t\tregexp, err := regexp.Compile(regexpStr)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regular expression %q: %v\", regexpStr, err)\n\t\t}\n\t\tregexps[i] = regexp\n\t}\n\tk.topicRegexps = regexps\n\treturn nil\n}", "CodeBleu_score": 43.547455920084076}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tregexps := make([]*regexp.Regexp, len(k.TopicRegexps))\n\n\tfor i, regexpStr := range k.TopicRegexps {\n\t\tr, err := regexp.Compile(regexpStr)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regular expression %q: %v\", regexpStr, err)\n\t\t}\n\t\tregexps[i] = r\n\t}\n\n\tk.topicRegexps = regexps\n\treturn nil\n}", "CodeBleu_score": 44.153262674728325}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tregexps := make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, regexpStr := range k.TopicRegexps {\n\t\tregexp, err := regexp.Compile(regexpStr)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regexp %q: %w\", regexpStr, err)\n\t\t}\n\t\tregexps[i] = regexp\n\t}\n\tk.topicRegexps = regexps\n\treturn nil\n}", "CodeBleu_score": 43.15819622534953}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif !ok {\n\t\th.mu.Unlock()\n\t\treturn\n\t}\n\tif msg.Delivered() {\n\t\tmsg.session.MarkMessage(track.ID, \"\")\n\t\tdelete(h.undelivered, track.ID)\n\t\th.sem.Release(1)\n\t}\n\th.mu.Unlock()\n}", "CodeBleu_score": 55.68902581032016}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif ok && msg.Delivered() {\n\t\tmsg.session.MarkMessage(msg, \"\")\n\t\tdelete(h.undelivered, track.ID)\n\t\th.sem.Release(1)\n\t}\n\th.mu.Unlock()\n}", "CodeBleu_score": 50.1237357801348}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif !ok {\n\t\th.mu.Unlock()\n\t\treturn\n\t}\n\n\tmsg.Delivered = true\n\th.mu.Unlock()\n\n\tif err := track.Session.MarkMessage(msg.Message, \"\"); err != nil {\n\t\th.log.Errorf(\"Failed to mark message as delivered: %v\", err)\n\t}\n\n\th.mu.Lock()\n\tdelete(h.undelivered, track.ID)\n\th.mu.Unlock()\n\n\th.sem.Release(1)\n}", "CodeBleu_score": 51.627896826650485}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\th.Handle(ctx, msg)\n\t\t\tsession.MarkMessage(msg, \"\")\n\t\t\th.acc.AddError(session.Context().Err())\n\t\t}\n\t}\n}", "CodeBleu_score": 54.77221302026479}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase message, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\th.Handle(ctx, message)\n\t\t\tsession.MarkMessage(message, \"\")\n\t\t}\n\t}\n}", "CodeBleu_score": 48.17577205411324}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase message, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\th.Handle(ctx, message)\n\t\t\tsession.MarkMessage(message, \"\")\n\t\t\th.acc.AddError(session.Context().Err())\n\t\t}\n\t}\n}", "CodeBleu_score": 54.915911433443554}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\t    if (logkafka_id.isEmpty) {\n        throw new IllegalArgumentException(\"Logkafka ID cannot be empty\")\n    }\n    if (logkafka_id == \".\" || logkafka_id == \"..\") {\n        throw new IllegalArgumentException(\"Logkafka ID cannot be '.' or '..'\")\n    }\n    if (logkafka_id.length > 255) {\n        throw new IllegalArgumentException(\"Logkafka ID cannot exceed 255 characters\")\n    }\n    if (!logkafka_id.matches(\"^[a-zA-Z0-9\\\\._-]+$\")) {\n        throw new IllegalArgumentException(\"Logkafka ID can only contain alphanumeric characters, '.', '_', and '-'\")\n    }\n}", "CodeBleu_score": 21.204990498384536}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t  val rgx = \"^[a-zA-Z0-9_-]+$\".r\n\n  if (logkafka_id.isEmpty) {\n    throw new IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be empty\")\n  }\n\n  if (logkafka_id.equals(\".\") || logkafka_id.equals(\"..\")) {\n    throw new IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be . or ..\")\n  }\n\n  if (logkafka_id.length > 250) {\n    throw new IllegalCharacterInLogkafkaId(\"Logkafka ID cannot exceed 250 characters\")\n  }\n\n  if (!rgx.findFirstIn(logkafka_id).equals(logkafka_id)) {\n    throw new IllegalCharacterInLogkafkaId(\"Logkafka ID can only contain alphanumeric characters, hyphens, and underscores\")\n  }\n}", "CodeBleu_score": 31.265714550164493}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t    if (logkafka_id.isEmpty()) {\n        throw new IllegalArgumentException(\"Logkafka ID cannot be empty\")\n    }\n    if (logkafka_id.equals(\".\") || logkafka_id.equals(\"..\")) {\n        throw new IllegalArgumentException(\"Logkafka ID cannot be '.' or '..'\")\n    }\n    if (logkafka_id.length() > MAX_LOGKAFKA_ID_LENGTH) {\n        throw new IllegalArgumentException(\n            \"Logkafka ID cannot exceed \" + MAX_LOGKAFKA_ID_LENGTH + \" characters\"\n        )\n    }\n    if (!LOGKAFKA_ID_REGEX.matcher(logkafka_id).matches()) {\n        throw new IllegalArgumentException(\n            \"Logkafka ID can only contain alphanumeric characters, underscores, and hyphens\"\n        )\n    }\n}", "CodeBleu_score": 27.132946538841324}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse => \n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) => \n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover {\n      case t: Throwable =>\n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 81.55700720123423}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse => \n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) => \n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover {\n      case t: Throwable =>\n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 81.55700720123423}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse => \n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) => \n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover {\n      case t: Throwable =>\n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 81.55700720123423}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case t: Throwable =>\n        Future.successful(-\\/(ApiError.fromThrowable(t)))\n    }\n  }", "CodeBleu_score": 82.35880466965436}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case t: Throwable =>\n        -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 75.28622754929306}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case t: Throwable => -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 75.0306295608407}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val commandRequest = KMClusterCommandRequest(clusterName, PreferredLeaderElection(topics))\n    KafkaManager.ask[KMClusterCommandRequest, ApiError \\/ ClusterContext](commandRequest).mapTo[ApiError \\/ ClusterContext]\n  }", "CodeBleu_score": 23.326114526408915}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val command = KMClusterCommandRequest(clusterName, PreferredLeaderElection(topics))\n    KafkaManager.ask(command).map {\n      case ApiError(error) => Left(error)\n      case ClusterContext(context) => Right(context)\n    }\n  }", "CodeBleu_score": 25.427256100904682}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val cmd = KMClusterCommandRequest(clusterName, PreferredLeaderElection(topics))\n    kafkaManager ! cmd\n    cmd.result.map {\n      case Right(clusterContext) => Right(clusterContext)\n      case Left(error) => Left(error)\n    }\n  }", "CodeBleu_score": 25.70704606641709}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t    getTopicList(clusterName).flatMap {\n      case Left(error) =>\n        Future.successful(error)\n      case Right(topicList) =>\n        runPreferredLeaderElection(clusterName, topicList)\n    }\n  }", "CodeBleu_score": 23.29221511448909}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t  getTopicList(clusterName).flatMap {\n    case Left(error) => Future.successful(error)\n    case Right(topicList) => runPreferredLeaderElection(clusterName, topicList)\n  }\n}", "CodeBleu_score": 20.70795902864766}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t  getTopicList(clusterName).flatMap { topicList =>\n    runPreferredLeaderElection(clusterName, topicList)\n  }\n}", "CodeBleu_score": 15.479125983679417}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t    val results = tryWithKafkaManagerActor(\n      KMClusterCommandRequest (\n        clusterName,\n        CMManualPartitionAssignments(assignments)\n      )\n    )\n    results.map {\n      case ApiError(code, message) =>\n        Left(ApiError(code, message))\n      case _ =>\n        Right(())\n    }\n  }", "CodeBleu_score": 28.385425250338596}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t    implicit val ec = context.dispatcher\n    val results = KafkaManagerActor.tryWithKafkaManagerActor(\n      KMClusterCommandRequest (\n        clusterName,\n        CMManualPartitionAssignments(assignments)\n      )\n    )\n    val errors = results.map(_.result.collect {\n      case Left(ApiError(_, _, _)) => true\n      case _ => false\n    })\n    if (errors.isEmpty) {\n      Success(())\n    } else {\n      Failure(errors)\n    }\n  }", "CodeBleu_score": 34.90198973388174}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t    implicit val ec = context.dispatcher\n    val results = tryWithKafkaManagerActor(\n      KMClusterCommandRequest (\n        clusterName,\n        CMManualPartitionAssignments(assignments)\n      )\n    )\n    val errors = results.map(result => result.result.collect {\n      case Left(error) => ApiError(error.message)\n    })\n    if (errors.isEmpty) {\n      Successful(())\n    } else {\n      Failed(errors)\n    }\n  }", "CodeBleu_score": 41.685784006975425}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    Config config;\n    try {\n        DescribeClusterResult describeClusterResult = admin.describeCluster();\n        Collection<Node> nodes = describeClusterResult.nodes().get();\n        if (nodes.isEmpty()) {\n            throw new ConnectException(\"No nodes found in Kafka cluster\");\n        }\n        String nodeId = nodes.iterator().next().idString();\n        config = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, nodeId))).get().values().get(nodeId);\n        if (config == null) {\n            throw new ConnectException(\"No configs found for node \" + nodeId);\n        }\n    } catch (ExecutionException e) {\n        throw new ConnectException(\"Failed to describe cluster\", e);\n    }\n    return config;\n}", "CodeBleu_score": 57.820620210962815}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    Config config = null;\n    try {\n        DescribeClusterResult describeClusterResult = admin.describeCluster();\n        Collection<Node> nodes = describeClusterResult.nodes().get();\n        if (nodes.isEmpty()) {\n            throw new ConnectException(\"No nodes found in the Kafka cluster\");\n        }\n        Node node = nodes.iterator().next();\n        String nodeId = node.idString();\n        config = admin.describeConfigs(Collections.singletonList(new ConfigResource(ConfigResource.Type.BROKER, nodeId))).all().get().get(nodeId);\n        if (config == null) {\n            throw new ConnectException(\"No configuration found for node \" + nodeId);\n        }\n    } catch (InterruptedException | ExecutionException e) {\n        throw new ConnectException(\"Failed to retrieve Kafka broker configuration\", e);\n    }\n    return config;\n}", "CodeBleu_score": 54.2749043679614}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    // Describe the cluster to get the available nodes within a specified timeout\n    DescribeClusterResult describeClusterResult = admin.describeCluster(new DescribeClusterOptions().timeoutMs(10000));\n    // If no nodes are available, throw a ConnectException\n    if (describeClusterResult.nodes().get().isEmpty()) {\n        throw new ConnectException(\"No nodes found in the Kafka cluster\");\n    }\n    // Select the first node's ID\n    Node node = describeClusterResult.nodes().get().stream().findFirst().get();\n    // Request the configuration of the selected node\n    ConfigResource configResource = new ConfigResource(ConfigResource.Type.BROKER, node.idString());\n    // If no configurations are received, throw a ConnectException\n    Config config = admin.describeConfigs(Collections.singleton(configResource)).all().get().values().get(configResource);\n    if (config == null) {\n        throw new ConnectException(\"No configurations found for the Kafka broker\");\n    }\n    // Return the broker's configuration\n    return config;\n}", "CodeBleu_score": 51.40874377878987}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t    return (name, value) -> {\n        if (value instanceof String) {\n            final String stringValue = (String) value;\n            if (stringValue.equalsIgnoreCase(\"KafkaSchemaHistory\")) {\n                return validator.validate(name, value);\n            }\n        }\n        return 0;\n    };\n}", "CodeBleu_score": 27.900361427573152}, {"code": "private static Validator forKafka(final Validator validator){\n\t    return (config, mode) -> {\n        if (config.get(SCHEMA_HISTORY_INTERVAL_CONFIG) == KafkaSchemaHistory.class) {\n            return validator.validate(config, mode);\n        }\n        return Collections.emptyMap();\n    };\n}", "CodeBleu_score": 27.22997535809477}, {"code": "private static Validator forKafka(final Validator validator){\n\t    return (name, config) -> {\n        final Object schemaHistory = config.get(SCHEMA_HISTORY_CONFIG);\n        if (schemaHistory instanceof String && ((String) schemaHistory).equalsIgnoreCase(KAFKA_SCHEMA_HISTORY)) {\n            return validator.validate(name, config);\n        } else {\n            return 0;\n        }\n    };\n}", "CodeBleu_score": 32.54782687121971}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t    if (version == null) {\n        version = parseVersion(config.get(KafkaConnectVersion.VERSION));\n    }\n    if (version == null) {\n        return true;\n    }\n    return parseBoolean(config.get(KafkaConnectVersion.TOPIC_CREATION_ENABLE), true);\n}", "CodeBleu_score": 25.579997313072965}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t  // Parse the Kafka Connect version from the configuration\n  Version version = parseVersion(config);\n\n  // Check if the Kafka Connect version is compatible with topic creation\n  if (version.isCompatibleWith(KAFKA_CONNECT_TOPIC_CREATION_VERSION)) {\n    // Get the \"topic.creation.enable\" property from the configuration, defaulting to true if not set\n    Boolean isTopicCreationEnabled = parseBoolean(config, TOPIC_CREATION_ENABLE_CONFIG, true);\n\n    // Return true if the Kafka Connect version is compatible with topic creation and the property is set to true\n    return isTopicCreationEnabled;\n  }\n\n  // Return false if the Kafka Connect version is not compatible with topic creation\n  return false;\n}", "CodeBleu_score": 27.006460201903458}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t    Version version = getVersion();\n    if (version.major() == 0 && version.minor() <= 10) {\n        return parseBoolean(config.get(TOPIC_CREATION_ENABLE_CONFIG), true);\n    }\n    return true;\n}", "CodeBleu_score": 17.677281075123826}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t    String clientId = config.get(KafkaOffsetBackingStore.CLIENT_ID_CONFIG);\n    if (clientId == null) {\n        throw new IllegalArgumentException(\"Missing mandatory configuration option: \" + KafkaOffsetBackingStore.CLIENT_ID_CONFIG);\n    }\n    Properties adminProps = new Properties();\n    adminProps.putAll(config);\n    adminProps.remove(KafkaOffsetBackingStore.CLIENT_ID_CONFIG);\n    SharedTopicAdmin sharedAdmin = SharedTopicAdmin.create(adminProps);\n    return new KafkaOffsetBackingStore(sharedAdmin, clientId, converterForOffsetStore(config));\n}", "CodeBleu_score": 31.536783160155395}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t    Objects.requireNonNull(config, \"config cannot be null\");\n    String clientId = config.get(KafkaOffsetBackingStore.CLIENT_ID_CONFIG);\n    if (clientId == null) {\n        throw new IllegalArgumentException(\"Missing mandatory configuration option: \" + KafkaOffsetBackingStore.CLIENT_ID_CONFIG);\n    }\n    Properties adminProps = new Properties();\n    adminProps.putAll(config);\n    adminProps.put(AdminClientConfig.CLIENT_ID_CONFIG, clientId);\n    SharedTopicAdmin admin = SharedTopicAdmin.create(adminProps);\n    return new KafkaOffsetBackingStore(admin, clientId, converterForOffsetStore(config));\n}", "CodeBleu_score": 32.15260706931763}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t    final String clientId = config.get(\"client.id\");\n    if (clientId == null) {\n        throw new IllegalArgumentException(\"Missing mandatory configuration option 'client.id'\");\n    }\n    final Properties adminProperties = new Properties();\n    adminProperties.putAll(config);\n    final SharedTopicAdmin sharedTopicAdmin = SharedTopicAdmin.create(adminProperties);\n    return new KafkaOffsetBackingStore(sharedTopicAdmin, clientId, converterForOffsetStore(config));\n}", "CodeBleu_score": 30.54997860452493}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\t    if (!node.isObject()) {\n        throw new IOException(\"Invalid key type: expected object, got \" + node.getNodeType());\n    }\n    if (node.has(\"payload\")) {\n        node = node.get(\"payload\");\n    }\n    if (node.size() == 1) {\n        Iterator<String> fieldNames = node.fieldNames();\n        String fieldName = fieldNames.next();\n        return (T) readValue(node.get(fieldName));\n    } else {\n        return (T) readValue(node);\n    }\n}", "CodeBleu_score": 44.85084148298667}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t    if (!node.isObject()) {\n        throw new IOException(\"Expected JSON object, got: \" + node);\n    }\n    if (node.has(PAYLOAD_FIELD)) {\n        node = node.get(PAYLOAD_FIELD);\n    }\n    if (node.size() == 1) {\n        String fieldName = node.fieldNames().next();\n        return readValue(node.get(fieldName), fieldName);\n    } else {\n        return readValue(node, null);\n    }\n}", "CodeBleu_score": 41.13158519551704}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t    if (!node.isObject()) {\n        throw new IOException(\"Key must be an object\");\n    }\n\n    if (node.has(\"payload\")) {\n        node = node.get(\"payload\");\n    }\n\n    Iterator<String> fieldNames = node.fieldNames();\n    if (fieldNames.hasNext()) {\n        String fieldName = fieldNames.next();\n        if (fieldNames.hasNext()) {\n            return readValue(node, compositeKeyClass);\n        } else {\n            return readValue(node.get(fieldName), keyClass);\n        }\n    } else {\n        return null;\n    }\n}", "CodeBleu_score": 45.184127789960144}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t    String topicName = delegate.topicNameFor(id, prefix, delimiter);\n    StringBuilder sanitizedTopicName = new StringBuilder();\n    boolean replaced = false;\n    for (int i = 0; i < topicName.length(); i++) {\n        char c = topicName.charAt(i);\n        if (isValidTopicNameCharacter(c)) {\n            sanitizedTopicName.append(c);\n        } else {\n            sanitizedTopicName.append(replacementCharacter);\n            replaced = true;\n        }\n    }\n    if (replaced) {\n        warn(\"Topic name '\" + topicName + \"' contains invalid characters. Replacing with '\" + replacementCharacter + \"'.\");\n    }\n    return sanitizedTopicName.toString();\n}", "CodeBleu_score": 55.85187190187308}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t    String topicName = delegate.topicNameFor(id, prefix, delimiter);\n    StringBuilder sanitizedTopicName = new StringBuilder();\n    boolean replaced = false;\n\n    for (int i = 0; i < topicName.length(); i++) {\n        char c = topicName.charAt(i);\n        if (isValidTopicNameCharacter(c)) {\n            sanitizedTopicName.append(c);\n        } else {\n            sanitizedTopicName.append(replacementCharacter);\n            replaced = true;\n        }\n    }\n\n    if (replaced) {\n        warn(\"Topic name contains invalid characters. Replacing with \" + replacementCharacter + \": \" + topicName);\n        return sanitizedTopicName.toString();\n    } else {\n        return topicName;\n    }\n}", "CodeBleu_score": 60.65781751649546}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t    String topicName = constructTopicName(id);\n    StringBuilder sanitizedName = new StringBuilder();\n    for (int i = 0; i < topicName.length(); i++) {\n        char c = topicName.charAt(i);\n        if (isValidTopicNameCharacter(c)) {\n            sanitizedName.append(c);\n        } else {\n            sanitizedName.append(delimiter);\n        }\n    }\n    if (sanitizedName.length() != topicName.length()) {\n        warn(\"Invalid characters in topic name \" + topicName + \". Replacing with \" + delimiter);\n        return sanitizedName.toString();\n    }\n    return topicName;\n}", "CodeBleu_score": 44.45336369380079}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t        this.connectorType = connectorType;\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.retryCount = replacedErrorHandler == null ? 0 : replacedErrorHandler.getRetries();\n        this.maxRetriesOnError = connectorConfig.getMaxRetriesOnError();\n    }", "CodeBleu_score": 50.3746657118395}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t    this.connectorType = connectorType;\n    this.connectorConfig = connectorConfig;\n    this.queue = queue;\n    this.producerThrowable = new AtomicReference<>();\n    this.maxRetriesOnError = connectorConfig.getInt(CommonConnectorConfig.RETRY_BACKOFF_MS_CONFIG);\n    if (replacedErrorHandler != null) {\n        this.retries = replacedErrorHandler.retries;\n    }\n}", "CodeBleu_score": 62.74106212424022}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t    this.connectorType = connectorType;\n    this.connectorConfig = connectorConfig;\n    this.queue = queue;\n\n    if (replacedErrorHandler != null) {\n        retryCount = replacedErrorHandler.getRetries();\n    }\n\n    if (connectorConfig.getMaxRetriesOnError() != null) {\n        maxRetries = connectorConfig.getMaxRetriesOnError();\n    }\n}", "CodeBleu_score": 56.101190482529205}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\t    ValidationResult result = validate(configuration, fields);\n    if (result.hasError()) {\n        throw new ConfigException(result.errorMessages().get(0));\n    }\n}", "CodeBleu_score": 23.278920999603255}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t    validate(configuration, fields, \"\");\n}", "CodeBleu_score": 7.218152269925926}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t    ValidationResult validationResult = validate(configuration, fields);\n    if (validationResult.hasError()) {\n        throw new ConfigException(validationResult.errorMessages());\n    }\n}", "CodeBleu_score": 24.075133960221756}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t    if (oldSchema.isPrimitive()) {\n        return oldSchema;\n    }\n    SchemaBuilder newSchemaBuilder = SchemaBuilder.struct();\n    for (Field field : oldSchema.fields()) {\n        String fieldName = field.name();\n        Schema fieldSchema = field.schema();\n        if (fieldSchema.isPrimitive()) {\n            newSchemaBuilder.field(fieldName, fieldSchema);\n        } else {\n            Schema newFieldSchema = buildNewSchema(fieldName, fieldSchema, headerToProcess, nestedFields, level + 1);\n            newSchemaBuilder.field(fieldName, newFieldSchema);\n        }\n    }\n    if (headerToProcess != null && headerToProcess.containsKey(fieldName)) {\n        Header header = headerToProcess.get(fieldName);\n        if (header.getType() == Header.Type.STRUCT) {\n            for (String nestedFieldName : header.getNestedFields()) {\n                newSchemaBuilder.field(nestedFieldName, Schema.STRING_SCHEMA);\n            }\n        }\n    }\n    log.debug(\"Copied fields: {}\", newSchemaBuilder.fields());\n    log.debug(\"Added fields: {}\", headerToProcess);\n    return newSchemaBuilder.build();\n}", "CodeBleu_score": 43.000591698771004}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t    if (oldSchema.isPrimitive()) {\n        return oldSchema;\n    }\n\n    SchemaBuilder schemaBuilder = SchemaBuilder.struct();\n\n    for (Field field : oldSchema.fields()) {\n        String name = field.name();\n        Schema schema = field.schema();\n\n        if (nestedFields.contains(name)) {\n            schemaBuilder.field(name, buildNewSchema(name, schema, headerToProcess, nestedFields, level + 1));\n        } else {\n            schemaBuilder.field(name, schema);\n        }\n    }\n\n    Header header = headerToProcess.get(fieldName);\n\n    if (header != null) {\n        for (Field field : header.fields()) {\n            String name = field.name();\n            Schema schema = field.schema();\n\n            if (nestedFields.contains(name)) {\n                schemaBuilder.field(name, buildNewSchema(name, schema, headerToProcess, nestedFields, level + 1));\n            } else {\n                schemaBuilder.field(name, schema);\n            }\n        }\n    }\n\n    Schema newSchema = schemaBuilder.build();\n\n    if (logger.isDebugEnabled()) {\n        logger.debug(\"Copied {} fields from old schema and added {} fields from header to new schema\",\n                oldSchema.fields().size(), header == null ? 0 : header.fields().size());\n        logger.debug(\"New schema: {}\", newSchema);\n    }\n\n    return newSchema;\n}", "CodeBleu_score": 42.55096322862385}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t    if (oldSchema.isPrimitive()) {\n        return oldSchema;\n    }\n\n    SchemaBuilder schemaBuilder = SchemaBuilder.struct();\n    for (Field field : oldSchema.fields()) {\n        String fieldName = field.name();\n        Schema fieldSchema = field.schema();\n        if (headerToProcess.containsKey(fieldName)) {\n            Header header = headerToProcess.get(fieldName);\n            schemaBuilder.field(fieldName, header.schema());\n            log.debug(\"Field {} added to the schema\", fieldName);\n        } else if (fieldSchema.isPrimitive()) {\n            schemaBuilder.field(fieldName, fieldSchema);\n            log.debug(\"Field {} copied from the schema\", fieldName);\n        } else {\n            List<String> newNestedFields = new ArrayList<>(nestedFields);\n            newNestedFields.add(fieldName);\n            schemaBuilder.field(fieldName, buildNewSchema(fieldName, fieldSchema, headerToProcess, newNestedFields, level + 1));\n        }\n    }\n\n    Schema newSchema = schemaBuilder.build();\n    log.debug(\"New schema built for field {} with schema {}\", fieldName, newSchema);\n    return newSchema;\n}", "CodeBleu_score": 41.25478703654941}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\t  if (source.schema().field(SnapshotRecord.SNAPSHOT_KEY) != null && source.getString(SnapshotRecord.SNAPSHOT_KEY) != null) {\n    String snapshotString = source.getString(SnapshotRecord.SNAPSHOT_KEY);\n    return SnapshotRecord.valueOf(snapshotString.toUpperCase());\n  }\n  return null;\n}", "CodeBleu_score": 47.14156468707389}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t  Schema sourceSchema = source.schema();\n  if (sourceSchema.field(SNAPSHOT_KEY) != null && sourceSchema.field(SNAPSHOT_KEY).schema().name().equals(SnapshotRecord.class.getSimpleName())) {\n    String snapshotString = source.getString(SNAPSHOT_KEY);\n    if (snapshotString != null) {\n      return SnapshotRecord.valueOf(snapshotString.toUpperCase());\n    }\n  }\n  return null;\n}", "CodeBleu_score": 56.87043453135453}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t    if (source == null) {\n        return null;\n    }\n    String snapshotString = source.getString(SNAPSHOT_KEY);\n    if (snapshotString == null) {\n        return null;\n    }\n    snapshotString = snapshotString.toUpperCase();\n    return SnapshotRecord.valueOf(snapshotString);\n}", "CodeBleu_score": 34.75462557497021}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t    try {\n        String[] parts = version.split(\"\\\\.\");\n        if (parts.length > 2) {\n            parts = Arrays.copyOfRange(parts, 0, 2);\n        }\n        String[] subParts = parts[0].split(\"-\");\n        return Optional.of(Float.parseFloat(subParts[0]));\n    } catch (Exception e) {\n        return Optional.empty();\n    }\n}", "CodeBleu_score": 66.61546715154962}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t    try {\n        String[] parts = version.split(\"\\\\.\");\n        if (parts.length > 2) {\n            parts = Arrays.copyOfRange(parts, 0, 2);\n        }\n        String firstPart = parts[0];\n        if (firstPart.contains(\"-\")) {\n            firstPart = firstPart.split(\"-\")[0];\n        }\n        return Optional.of(Float.parseFloat(firstPart));\n    } catch (Exception e) {\n        return Optional.empty();\n    }\n}", "CodeBleu_score": 64.66532642916486}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t    try {\n        String[] parts = version.split(\"\\\\.\");\n        if (parts.length > 2) {\n            parts = Arrays.copyOfRange(parts, 0, 2);\n        }\n        String[] subParts = parts[0].split(\"-\");\n        return Optional.of(Float.parseFloat(subParts[0]));\n    } catch (Exception e) {\n        return Optional.empty();\n    }\n}", "CodeBleu_score": 66.61546715154962}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t    AccessContext context = AccessContext.builder()\n            .clusterName(clusterName)\n            .connectName(connectName)\n            .action(Action.CREATE)\n            .build();\n    return validateAccess(context, exchange)\n            .then(connector)\n            .map(NewConnectorDTO::getConnector)\n            .flatMap(connector -> kafkaConnectService.createConnector(connector, clusterName, connectName))\n            .map(ResponseEntity::ok)\n            .audit(context, AuditSignal.CREATE);\n}", "CodeBleu_score": 51.28192935218125}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t    return clusterService.getCluster(clusterName)\n            .flatMap(cluster -> {\n                AccessContext context = AccessContext.builder()\n                        .cluster(cluster)\n                        .connect(connectName)\n                        .namespace(cluster.getMetadata().getNamespace())\n                        .resource(Resource.CONNECT)\n                        .action(Action.CREATE)\n                        .build();\n\n                return validateAccess.validateMono(context, connector)\n                        .flatMap(signal -> {\n                            audit.createAuditRecord(context, signal);\n                            return kafkaConnectService.createConnector(cluster, connectName, connector);\n                        })\n                        .map(connectorDTO -> ResponseEntity.status(HttpStatus.CREATED)\n                                .body(connectorDTO));\n            });\n}", "CodeBleu_score": 47.299296318431495}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t    AccessContext context = AccessContext.builder()\n            .cluster(clusterName)\n            .connect(connectName)\n            .actions(List.of(ConnectActions.CREATE))\n            .build();\n\n    return validateAccess(context, exchange)\n            .then(connector)\n            .flatMap(c -> kafkaConnectService.createConnector(clusterName, connectName, c))\n            .map(ResponseEntity::ok)\n            .doOnEach(audit.signal(Level.INFO, context, \"Create connector {connector} on {cluster}\"));\n}", "CodeBleu_score": 59.30963711406129}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t    AccessContext accessContext = AccessContext.builder()\n            .clusterName(clusterName)\n            .connectName(connectName)\n            .requiredActions(List.of(Action.CONNECT_WRITE))\n            .build();\n    return validateAccess(accessContext, exchange)\n            .then(kafkaConnectService.deleteConnector(clusterName, connectName, connectorName))\n            .map(ResponseEntity::ok)\n            .doOnEach(audit(exchange, accessContext));\n}", "CodeBleu_score": 47.80148452595869}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t    AccessContext accessContext = AccessContext.builder()\n            .clusterName(clusterName)\n            .connectName(connectName)\n            .requiredActions(List.of(Action.DELETE_CONNECTOR))\n            .build();\n\n    return validateAccess(accessContext, exchange)\n            .then(kafkaConnectService.deleteConnector(clusterName, connectName, connectorName))\n            .map(ResponseEntity::ok)\n            .doOnEach(audit(exchange, accessContext, OperationParams.builder()\n                    .connectName(connectName)\n                    .connectorName(connectorName)\n                    .build()));\n}", "CodeBleu_score": 46.80560279654456}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t    AccessContext accessContext = AccessContext.builder()\n            .clusterName(clusterName)\n            .connectName(connectName)\n            .requiredActions(List.of(DELETE_CONNECTOR))\n            .build();\n\n    return validateAccess(accessContext, exchange)\n            .flatMap(validation -> {\n                if (validation.getStatus().equals(Status.ACCEPTED)) {\n                    return kafkaConnectService.deleteConnector(clusterName, connectName, connectorName)\n                            .map(response -> ResponseEntity.noContent().build());\n                } else {\n                    return Mono.just(ResponseEntity.status(HttpStatus.FORBIDDEN).build());\n                }\n            })\n            .doOnEach(audit(clusterName, connectName, connectorName, exchange, DELETE_CONNECTOR));\n}", "CodeBleu_score": 41.64022587478518}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t        return kafkaConnectService.updateConnectorState(clusterName, connectName, connectorName, action)\n                .doOnEach(audit.doOnEach(clusterName, connectName, connectorName, action, exchange))\n                .map(ResponseEntity::ok);\n    }", "CodeBleu_score": 13.3648905356028}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t    return of(clusterName, connectName, connectorName, action)\n            .map(operationParams -> buildContext(exchange.getRequest(), operationParams))\n            .doOnEach(validateAccess(exchange))\n            .then(doOnEach(audit(exchange)))\n            .then(doOnEach(connectActions(kafkaConnectService)))\n            .then(Mono.just(ResponseEntity.noContent().build()));\n}", "CodeBleu_score": 20.32879661831667}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t    return getCluster(clusterName)\n        .flatMap(cluster -> {\n            ConnectDTO connect = cluster.getConnect(connectName);\n            List<ConnectAction> actions = connectActions(action);\n            OperationParams operationParams = operationParams(connectorName, actions);\n            AccessContext context = accessContextBuilder()\n                .withCluster(cluster)\n                .withConnect(connect)\n                .withActions(actions)\n                .withOperationName(updateConnectorState.name())\n                .withOperationParams(operationParams)\n                .build();\n            return validateAccess(context)\n                .flatMap(accessValidationResponse -> {\n                    if (accessValidationResponse.isAllowed()) {\n                        return kafkaConnectService.updateConnectorState(connect, connectorName, action)\n                            .doOnEach(audit.log(exchange, updateConnectorState, context,\n                                audit.parameters()\n                                    .with(CONNECTOR_NAME, connectorName)\n                                    .with(ACTION, action.name())\n                                    .with(ACTIONS, actions)\n                                    .build()\n                            ));\n                    } else {\n                        return Mono.error(new AccessDeniedException(accessValidationResponse.getMessage()));\n                    }\n                });\n        })\n        .map(ResponseEntity::ok)\n        .onErrorResume(AccessDeniedException.class, e -> Mono.just(ResponseEntity.status(HttpStatus.FORBIDDEN).build()));\n}", "CodeBleu_score": 40.67747175196848}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t    /**\n     * Validates the configuration of a connector plugin in a specified Kafka Connect cluster.\n     *\n     * @param clusterName The name of the Kafka Connect cluster.\n     * @param connectName The name of the Kafka Connect instance.\n     * @param pluginName The name of the connector plugin.\n     * @param requestBody The request body containing the configuration of the connector plugin.\n     * @return A Mono emitting a ResponseEntity containing the validation result.\n     */\n    @PostMapping(value = \"/{clusterName}/connect/{connectName}/plugins/{pluginName}/config/validate\", produces = [MediaType.APPLICATION_JSON_VALUE])\n    @Operation(summary = \"Validate connector plugin config\", description = \"Validate connector plugin config\", tags = [\"connector\"])\n    @ApiResponses(value = [\n        @ApiResponse(responseCode = \"200\", description = \"Successful operation\", content = [\n            @Content(mediaType = \"application/json\", schema = @Schema(implementation = ConnectorPluginConfigValidationResponseDTO::class))\n        ]),\n        @ApiResponse(responseCode = \"404\", description = \"Cluster not found\"),\n        @ApiResponse(responseCode = \"500\", description = \"Error occurred while validating connector plugin config\")\n    ])\n    fun validateConnectorPluginConfig(\n        @Parameter(description = \"The name of the Kafka Connect cluster\", required = true)\n        @PathVariable(\"clusterName\") clusterName: String,\n\n        @Parameter(description = \"The name of the Kafka Connect instance\", required = true)\n        @PathVariable(\"connectName\") connectName: String,\n\n        @Parameter(description = \"The name of the connector plugin\", required = true)\n        @PathVariable(\"pluginName\") pluginName: String,\n\n        @Parameter(description = \"The request body containing the configuration of the connector plugin\", required = true)\n        @RequestBody requestBody: ConnectorPluginConfigValidationRequestDTO\n    ): Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> {\n        return kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, requestBody)\n            .map", "CodeBleu_score": 33.88167626794344}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t    return kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, requestBody)\n            .map(ResponseEntity::ok);\n}", "CodeBleu_score": 31.192307619585748}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t    return kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, requestBody)\n            .map(ResponseEntity.ok());\n}", "CodeBleu_score": 25.920041116540116}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    SpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n    builder.initializers(new DynamicConfigPropertiesInitializer());\n    return builder.run(args);\n}", "CodeBleu_score": 45.22206797006011}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    return new SpringApplicationBuilder(KafkaUiApplication.class)\n            .initializers(dynamicConfigPropertiesInitializer())\n            .run(args);\n}", "CodeBleu_score": 43.99171500726811}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    return new SpringApplicationBuilder(KafkaUiApplication.class)\n            .initializers(dynamicConfigPropertiesInitializer())\n            .run(args);\n}", "CodeBleu_score": 43.99171500726811}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t    if (search == null) {\n        return connector -> true;\n    }\n\n    final String searchLower = search.toLowerCase();\n    return connector -> getStringsForSearch(connector).stream().anyMatch(s -> s.toLowerCase().contains(searchLower));\n}", "CodeBleu_score": 58.30469210158691}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t    if (search == null) {\n        return connector -> true;\n    }\n\n    final String searchLower = search.toLowerCase();\n    return connector -> getStringsForSearch(connector).stream().anyMatch(str -> str.toLowerCase().contains(searchLower));\n}", "CodeBleu_score": 58.19016734597879}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t    if (search == null) {\n        return connector -> true;\n    }\n\n    final String searchLower = search.toLowerCase();\n\n    return connector -> {\n        final List<String> stringsForSearch = getStringsForSearch(connector);\n        return stringsForSearch.stream().anyMatch(str -> containsIgnoreCase(str, searchLower));\n    };\n}", "CodeBleu_score": 56.29303793706514}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    Map<String, Object> flattenedProperties = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattenedProperties;\n    }\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      if (prefix != null) {\n        key = prefix + \".\" + key;\n      }\n      Object value = entry.getValue();\n      if (value instanceof Map) {\n        flattenedProperties.putAll(flattenClusterProperties(key, (Map<String, Object>) value));\n      } else {\n        flattenedProperties.put(key, value);\n      }\n    }\n    return flattenedProperties;\n  }", "CodeBleu_score": 51.16390104978941}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    Map<String, Object> flattened = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattened;\n    }\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = prefix == null ? entry.getKey() : prefix + \".\" + entry.getKey();\n      if (entry.getValue() instanceof Map) {\n        flattened.putAll(flattenClusterProperties(key, (Map<String, Object>) entry.getValue()));\n      } else {\n        flattened.put(key, entry.getValue());\n      }\n    }\n    return flattened;\n  }", "CodeBleu_score": 54.63365034855636}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    Map<String, Object> flattened = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattened;\n    }\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      if (prefix != null) {\n        key = prefix + \".\" + key;\n      }\n      Object value = entry.getValue();\n      if (value instanceof Map) {\n        flattened.putAll(flattenClusterProperties(key, (Map<String, Object>) value));\n      } else {\n        flattened.put(key, value);\n      }\n    }\n    return flattened;\n  }", "CodeBleu_score": 56.790973071879925}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t        final ConfigDef configDef = new ConfigDef();\n        addClientSslSupport(configDef);\n        addClientSaslSupport(configDef);\n        return configDef.entrySet().stream()\n                .filter(entry -> entry.getValue().type() == ConfigDef.Type.PASSWORD)\n                .map(Map.Entry::getKey)\n                .collect(Collectors.toSet());\n    }", "CodeBleu_score": 73.07058560801474}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t        ConfigDef configDef = new ConfigDef();\n        addClientSslSupport(configDef);\n        addClientSaslSupport(configDef);\n        return configDef.configKeys().stream()\n                .filter(k -> configDef.get(k).type() == ConfigDef.Type.PASSWORD)\n                .collect(Collectors.toSet());\n    }", "CodeBleu_score": 64.88021891340415}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t    final ConfigDef configDef = new ConfigDef();\n    addClientSslSupport(configDef);\n    addClientSaslSupport(configDef);\n    return configDef.configKeys().stream()\n            .filter(configKey -> configKey.type == ConfigDef.Type.PASSWORD)\n            .map(ConfigKey::name)\n            .collect(Collectors.toSet());\n}", "CodeBleu_score": 69.49529155779133}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return Mono.just(clusterDescription)\n            .filter(cd -> cd.getAuthorizedOperations().contains(AclOperation.ALL) || cd.getAuthorizedOperations().contains(AclOperation.ALTER))\n            .filter(cd -> cd.getAclViewEnabled())\n            .map(cd -> KAFKA_ACL_EDIT);\n}", "CodeBleu_score": 31.064923913667126}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return Mono.just(clusterDescription)\n        .map(ClusterDescription::getAuthorizedOperations)\n        .map(operations -> operations.stream().anyMatch(operation -> operation.equals(AclOperation.ALL) || operation.equals(AclOperation.ALTER)))\n        .filter(Boolean::booleanValue)\n        .map(hasAllOrAlter -> hasAllOrAlter && clusterDescription.aclViewEnabled())\n        .filter(Boolean::booleanValue)\n        .map(hasAllOrAlterAndAclViewEnabled -> new ClusterFeature(KAFKA_ACL_EDIT));\n}", "CodeBleu_score": 31.102487879706665}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return Mono.just(clusterDescription)\n            .map(ClusterDescription::authorizedOperations)\n            .filter(operations -> operations.contains(AclOperation.ALL) || operations.contains(AclOperation.ALTER))\n            .filter(operations -> clusterDescription.isAclViewEnabled())\n            .map(operations -> KAFKA_ACL_EDIT);\n}", "CodeBleu_score": 34.116989865342624}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    // Initialize the map of offsets to read from based on the previous range or the offsets from seek operations if the previous range is empty\n    TreeMap<TopicPartition, FromToOffset> range = prevRange.isEmpty() ? seekOperations.getOffsetsForSeek() : prevRange;\n\n    // Calculate the number of messages to poll per partition\n    int numMessagesToPollPerPartition = getNumMessagesToPollPerPartition();\n\n    // For each topic partition in the range\n    for (Map.Entry<TopicPartition, FromToOffset> entry : range.entrySet()) {\n        // Get the topic partition and the current offset range\n        TopicPartition tp = entry.getKey();\n        FromToOffset fromToOffset = entry.getValue();\n\n        // Determine the start offset for this partition\n        long startOffset = fromToOffset.getFromOffset();\n\n        // Adjust the start offset based on the number of messages to poll for this partition\n        startOffset = Math.max(startOffset, fromToOffset.getFromOffset() - numMessagesToPollPerPartition);\n\n        // Update the offset range with the adjusted start offset\n        range.put(tp, new FromToOffset(startOffset, fromToOffset.getToOffset()));\n    }\n\n    // Return the updated offset range\n    return range;\n}", "CodeBleu_score": 30.91013839321104}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    // Initialize the map of offsets to read from based on the previous range or the offsets from seek operations if the previous range is empty\n    TreeMap<TopicPartition, FromToOffset> range = prevRange == null || prevRange.isEmpty() ? seekOperations.getOffsetsForSeek() : prevRange;\n\n    // Calculate the number of messages to poll per partition\n    int messagesPerPartition = (int) Math.ceil((double) this.maxPollRecords / this.assignedPartitions.size());\n\n    // For each topic partition, determine the start offset and adjust it based on the number of messages to poll\n    for (TopicPartition partition : this.assignedPartitions) {\n        FromToOffset fromToOffset = range.get(partition);\n        long startOffset = fromToOffset == null ? 0 : fromToOffset.getFromOffset();\n        startOffset = Math.max(startOffset, this.seekOperations.getBeginOffsets().get(partition));\n        range.put(partition, new FromToOffset(startOffset, startOffset + messagesPerPartition));\n    }\n\n    return range;\n}", "CodeBleu_score": 35.18967852031846}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    // Initialize a map of offsets to read from based on the previous range or the offsets from seek operations if the previous range is empty\n    TreeMap<TopicPartition, FromToOffset> offsetsToReadFrom = new TreeMap<>(prevRange == null ? seekOperations.getOffsetsForSeek() : prevRange);\n    // Calculate the number of messages to poll per partition\n    int messagesToPollPerPartition = (int) Math.ceil((double) maxPollRecords / (double) offsetsToReadFrom.size());\n    // For each topic partition, determine the start offset and adjust it based on the number of messages to poll, ensuring it does not go below the beginning offset\n    offsetsToReadFrom.entrySet().stream().forEach(entry -> {\n        FromToOffset fromToOffset = entry.getValue();\n        long startOffset = fromToOffset.getFrom();\n        long endOffset = fromToOffset.getTo();\n        if (startOffset == -1) {\n            startOffset = endOffset;\n        }\n        long nextStartOffset = startOffset + messagesToPollPerPartition;\n        if (nextStartOffset < fromToOffset.getBegin()) {\n            nextStartOffset = fromToOffset.getBegin();\n        }\n        offsetsToReadFrom.put(entry.getKey(), new FromToOffset(nextStartOffset, endOffset));\n    });\n    return offsetsToReadFrom;\n}", "CodeBleu_score": 39.69473243096565}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\t    if (legacyMode) {\n        if (isNullOrEmpty(zkConnect)) {\n            throw new IllegalArgumentException(\"ZooKeeper connection string is required for legacy mode\");\n        }\n        if (isNullOrEmpty(topic)) {\n            throw new IllegalArgumentException(\"Topic is required for legacy mode\");\n        }\n    } else {\n        if (isNullOrEmpty(bootstrapServers)) {\n            throw new IllegalArgumentException(\"Bootstrap servers are required for new consumer mode\");\n        }\n        if (isNullOrEmpty(topic)) {\n            throw new IllegalArgumentException(\"Topic is required for new consumer mode\");\n        }\n        if (isNullOrEmpty(groupId)) {\n            throw new IllegalArgumentException(\"Group ID is required for new consumer mode\");\n        }\n    }\n\n    try {\n        input.init(this);\n    } catch (final Exception e) {\n        throw new RuntimeException(\"Failed to initialize message input\", e);\n    }\n\n    // Wait for the server to be running\n    awaitRunning();\n\n    // Register for server lifecycle events\n    server.getLifecycle().addServerLifecycleListener(new ServerLifecycleListener() {\n        @Override\n        public void serverStarted(final ServerLifecycleEvent event) {\n            // no-op\n        }\n\n        @Override\n        public void serverStopped(final ServerLifecycleEvent event) {\n            // Stop the input when the server is stopped\n            input.stop();\n        }\n    });\n\n    // Schedule a task to update the last second bytes read every second\n    server.getScheduler().scheduleAtFixedRate(new Runnable() {\n        @Override\n        public void run() {\n            input.updateLastSecondBytesRead();\n        }\n    }, 1, 1, TimeUnit.SECONDS);\n\n    // Launch the input\n    if (legacyMode) {\n        doLaunchLegacy(input);\n    } else {\n        doLaunchConsumer(input);\n    }\n}", "CodeBleu_score": 39.484360234983384}, {"code": "public void doLaunch(final MessageInput input){\n\t    if (isLegacyMode()) {\n        validateLegacy();\n    } else {\n        validateConsumer();\n    }\n    awaitRunning();\n    register(input);\n    if (isLegacyMode()) {\n        doLaunchLegacy(input);\n    } else {\n        doLaunchConsumer(input);\n    }\n    scheduleAtFixedRate(input, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 17.58129447135698}, {"code": "public void doLaunch(final MessageInput input){\n\t    if (isLegacyMode()) {\n        validateLegacyConfig();\n    } else {\n        validateConsumerConfig();\n    }\n\n    input.initialize();\n    input.launch();\n\n    waitForServerRunning();\n    registerForServerLifecycleEvents();\n\n    if (isLegacyMode()) {\n        doLaunchLegacy(input);\n    } else {\n        doLaunchConsumer(input);\n    }\n\n    scheduleAtFixedRate(input, () -> input.getAndSet(LAST_SECOND_BYTES_READ, 0L), 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 21.558729443808723}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t    try {\n        String customProperties = getString(CUSTOM_PROPERTIES);\n        if (customProperties != null) {\n            Properties customProps = new Properties();\n            customProps.load(new StringReader(customProperties));\n            props.putAll(customProps);\n        }\n    } catch (IOException e) {\n        error(\"Error loading custom properties\", e);\n    }\n}", "CodeBleu_score": 47.68342829296038}, {"code": "private void insertCustomProperties(Properties props){\n\t    try {\n        String customProperties = getString(CUSTOM_PROPERTIES_KEY);\n        if (customProperties != null) {\n            Properties customProps = new Properties();\n            customProps.load(new StringReader(customProperties));\n            props.putAll(customProps);\n        }\n    } catch (IOException e) {\n        LOG.error(\"Error loading custom properties\", e);\n    }\n}", "CodeBleu_score": 50.580999445029185}, {"code": "private void insertCustomProperties(Properties props){\n\t    try {\n        String config = getString(CONFIG_KEY);\n        if (config != null) {\n            Properties customProps = new Properties();\n            customProps.load(new StringReader(config));\n            props.putAll(customProps);\n        }\n    } catch (IOException e) {\n        error(\"Error loading custom properties\", e);\n    }\n}", "CodeBleu_score": 46.590815960154735}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t    if (entries == null || entries.isEmpty()) {\n        return;\n    }\n    List<RawMessageEvent> filteredEntries = entries.stream()\n        .filter(Objects::nonNull)\n        .collect(Collectors.toList());\n    if (filteredEntries.isEmpty()) {\n        return;\n    }\n    List<byte[]> journalEntries = filteredEntries.stream()\n        .map(RawMessageEvent::getMessageBytes)\n        .collect(Collectors.toList());\n    int totalBytes = journalEntries.stream()\n        .mapToInt(bytes -> bytes.length)\n        .sum();\n    try {\n        journal.write(journalEntries);\n    } catch (JournalException e) {\n        throw new MessageQueueException(e);\n    }\n    writtenMessages.addAndGet(filteredEntries.size());\n    writtenBytes.addAndGet(totalBytes);\n}", "CodeBleu_score": 39.61353091438211}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t    List<RawMessageEvent> filteredEntries = entries.stream().filter(Objects::nonNull).collect(Collectors.toList());\n    List<JournalEntry> journalEntries = filteredEntries.stream().map(this::toJournalEntry).collect(Collectors.toList());\n    long totalMessageBytes = filteredEntries.stream().mapToLong(this::getMessageBytes).sum();\n\n    int attempts = 0;\n    while (true) {\n        try {\n            journal.write(journalEntries);\n            break;\n        } catch (JournalException e) {\n            attempts++;\n            if (attempts >= MAX_RETRIES) {\n                throw new MessageQueueException(\"Failed to write to journal after \" + MAX_RETRIES + \" attempts\", e);\n            }\n            try {\n                Thread.sleep((long) Math.pow(2, attempts) * 1000);\n            } catch (InterruptedException ex) {\n                throw new MessageQueueException(\"Interrupted while waiting for retry\", ex);\n            }\n        }\n    }\n\n    writtenMessages.addAndGet(filteredEntries.size());\n    writtenBytes.addAndGet(totalMessageBytes);\n}", "CodeBleu_score": 43.58686560942042}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t    // Filter out null entries\n    List<RawMessageEvent> nonNullEntries = entries.stream().filter(Objects::nonNull).collect(Collectors.toList());\n\n    // Map each event to a journal entry\n    List<byte[]> journalEntries = nonNullEntries.stream().map(this::getEncodedRawMessage).collect(Collectors.toList());\n\n    // Calculate the total message bytes\n    int totalMessageBytes = nonNullEntries.stream().mapToInt(this::getMessageBytes).sum();\n\n    // Attempt to write to the journal\n    int written = writeToJournal(journalEntries);\n\n    // Update metrics\n    writtenMessages.addAndGet(written);\n    writtenBytes.addAndGet(totalMessageBytes);\n}", "CodeBleu_score": 30.161553262847747}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\t  // Identify the maximum valid message queue ID from the list of messages\n  Optional<Long> maxValidMessageQueueId = messages.stream().map(Message::getQueueId).max(Long::compare);\n  // If the maximum valid message queue ID is present, acknowledge it\n  maxValidMessageQueueId.ifPresent(max -> {\n    // Update the metrics by marking the number of acknowledged messages\n    metrics.mark(messages.size());\n    // Acknowledge the maximum valid message queue ID\n    acknowledge(max);\n  });\n}", "CodeBleu_score": 34.24081591356375}, {"code": "public void acknowledge(List<Message> messages){\n\t    Optional<Long> maxMessageId = messages.stream().map(Message::getId).max(Long::compare);\n    maxMessageId.ifPresent(id -> {\n        acknowledgedMessages.addAll(messages);\n        metrics.mark(messages.size());\n    });\n}", "CodeBleu_score": 33.59523735254492}, {"code": "public void acknowledge(List<Message> messages){\n\t    long maxId = messages.stream().filter(message -> message.getId() <= max).mapToLong(Message::getId).max().orElse(0);\n    messages.stream().filter(message -> message.getId() <= max).forEach(message -> message.acknowledge());\n    metrics.mark(acknowledgedMessages, messages.size());\n}", "CodeBleu_score": 40.51518327636895}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\t    // Filter the metrics to include only those starting with the LocalKafkaJournal class name\n    metricRegistry.filter(new MetricFilter() {\n        @Override\n        public boolean matches(String name, Metric metric) {\n            return name.startsWith(LocalKafkaJournal.class.getName());\n        }\n    }).forEach((name, metric) -> {\n        // Construct a legacy metric name\n        String legacyName = \"kafka.journal.\" + name.substring(name.lastIndexOf('.') + 1);\n        try {\n            // Attempt to register the metric under the legacy name\n            metricRegistry.register(legacyName, metric);\n        } catch (IllegalArgumentException e) {\n            // If registration fails, log a warning message\n            LOG.warn(\"Failed to register legacy metric: {} -> {}\", name, legacyName);\n        }\n    });\n}", "CodeBleu_score": 45.335642332687044}, {"code": "private void registerLegacyMetrics(){\n\t    getMetrics().filter(entry -> entry.getKey().startsWith(LocalKafkaJournal.class.getName())).forEach(entry -> {\n        String legacyMetricName = entry.getKey().replace(LocalKafkaJournal.class.getName(), \"kafka.local.journal\");\n        try {\n            getMetrics().register(legacyMetricName, entry.getValue());\n        } catch (IllegalArgumentException e) {\n            warn(\"Failed to register legacy metric {} under {}\", entry.getKey(), legacyMetricName);\n        }\n    });\n}", "CodeBleu_score": 50.8402755042733}, {"code": "private void registerLegacyMetrics(){\n\t    metricRegistry.filterMetrics(metric -> metric.getName().startsWith(LocalKafkaJournal.class.getName())).forEach((name, metric) -> {\n        String legacyName = name.replaceFirst(LocalKafkaJournal.class.getName(), \"kafka.local.journal\");\n        try {\n            metricRegistry.register(legacyName, metric);\n        } catch (IllegalArgumentException e) {\n            LOG.warn(\"Failed to register legacy metric {} under the name {}\", name, legacyName);\n        }\n    });\n}", "CodeBleu_score": 47.44978943573951}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t    Timer timer = metricRegistry.timer(metricName);\n    return timer;\n}", "CodeBleu_score": 11.331535144421881}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t    try {\n        return metricRegistry.timer(metricName);\n    } catch (IllegalArgumentException e) {\n        return metricRegistry.getTimers().get(metricName);\n    }\n}", "CodeBleu_score": 21.97987496955459}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t    Timer timer;\n    try {\n        timer = metricRegistry.timer(metricName);\n    } catch (IllegalArgumentException e) {\n        timer = metricRegistry.getTimers().get(metricName).iterator().next();\n    }\n    return timer;\n}", "CodeBleu_score": 41.96445223188299}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t    try {\n        metricRegistry.register(MetricRegistry.name(name, \"uncommitted\"), new Gauge<Long>() {\n            @Override\n            public Long getValue() {\n                if (size() == 0) {\n                    return 0L;\n                }\n                long committed = getCommittedOffset();\n                if (committed == -1L) {\n                    return getLogEndOffset() - getLogStartOffset();\n                } else {\n                    return getLogEndOffset() - committed;\n                }\n            }\n        });\n    } catch (IllegalArgumentException e) {\n        // already registered\n    }\n}", "CodeBleu_score": 60.07858391678253}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t    try {\n        metricRegistry.register(MetricRegistry.name(name, \"uncommitted\"), (Gauge<Integer>) () -> {\n            if (size() == 0) {\n                return 0;\n            }\n            if (getCommittedOffset() == -1) {\n                return (int) (getLogEndOffset() - getLogStartOffset());\n            } else {\n                return (int) (getLogEndOffset() - getCommittedOffset());\n            }\n        });\n    } catch (IllegalArgumentException ignored) {\n    }\n}", "CodeBleu_score": 52.46973067348001}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t    metricRegistry.register(name, (Gauge<Integer>) () -> {\n        try {\n            long committedOffset = getCommittedOffset();\n            if (committedOffset == -1) {\n                return 0;\n            }\n            if (committedOffset == -2) {\n                return (int) (getLogEndOffset() - getLogStartOffset());\n            }\n            return (int) (getLogEndOffset() - committedOffset);\n        } catch (IllegalArgumentException e) {\n            // Ignore\n        }\n        return 0;\n    });\n}", "CodeBleu_score": 47.33349694793987}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t    if (messages.isEmpty()) {\n        if (isDebugEnabled)\n            debug(\"No messages to flush\");\n        return lastOffset;\n    }\n\n    ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages, payloadSize);\n    if (isDebugEnabled)\n        debug(\"Flushing %d messages (%d bytes) to log %s\", messageSet.size(), messageSet.sizeInBytes, log);\n\n    long lastOffset = append(messageSet);\n    log.mark(messageSet.size());\n    this.lastOffset = lastOffset;\n    return lastOffset;\n}", "CodeBleu_score": 35.44277290528749}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t    if (messages.isEmpty()) {\n        log.debug(\"No messages to flush\");\n        return -1;\n    }\n\n    ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n    log.debug(\"Writing {} messages to {}\", messageSet.size(), log.name());\n\n    long lastOffset = log.append(messageSet);\n\n    log.mark(messages.size());\n\n    log.debug(\"Wrote {} messages to {} in {} ms\", messages.size(), log.name(), time.milliseconds() - startTime);\n\n    return lastOffset;\n}", "CodeBleu_score": 36.869381197776406}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t    if (messages.isEmpty) {\n        if (isDebugEnabled) {\n            debug(s\"No messages to append to log ${log.name}\")\n        }\n        return log.highWatermark\n    }\n\n    val messageSet = new ByteBufferMessageSet(messages, compressionCodec, payloadSize)\n    if (isDebugEnabled) {\n        debug(s\"Writing ${messageSet.sizeInBytes} bytes to log ${log.name}\")\n    }\n    log.append(messageSet)\n    val lastOffset = log.lastOffset\n    if (isDebugEnabled) {\n        debug(s\"Wrote ${messageSet.size} messages (${messageSet.sizeInBytes} bytes) to log ${log.name} at offset $lastOffset\")\n    }\n    mark(messageSet.size)\n    return lastOffset\n}", "CodeBleu_score": 28.312249085619158}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    try {\n        lock.lock();\n        List<AdminClient> adminClientList = clientMap.get(clusterPhyId);\n        if (adminClientList == null || adminClientList.isEmpty()) {\n            return;\n        }\n        log.info(\"[KafkaAdminClient] start to close kafka admin client, clusterPhyId:{}\", clusterPhyId);\n        boolean success = true;\n        for (AdminClient adminClient : adminClientList) {\n            try {\n                adminClient.close();\n            } catch (Exception e) {\n                log.error(\"[KafkaAdminClient] close kafka admin client error, clusterPhyId:{}\", clusterPhyId, e);\n                success = false;\n            }\n        }\n        if (success) {\n            log.info(\"[KafkaAdminClient] close kafka admin client success, clusterPhyId:{}\", clusterPhyId);\n        } else {\n            log.error(\"[KafkaAdminClient] close kafka admin client error, clusterPhyId:{}\", clusterPhyId);\n        }\n    } catch (Exception e) {\n        log.error(\"[KafkaAdminClient] close kafka admin client error, clusterPhyId:{}\", clusterPhyId, e);\n    } finally {\n        lock.unlock();\n    }\n}", "CodeBleu_score": 60.45514425835747}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    try {\n        lock.lock();\n        List<AdminClient> adminClients = clientMap.get(clusterPhyId);\n        if (adminClients == null || adminClients.isEmpty()) {\n            return;\n        }\n        logger.info(\"start to close admin client of cluster {}\", clusterPhyId);\n        boolean success = true;\n        for (AdminClient adminClient : adminClients) {\n            try {\n                adminClient.close();\n            } catch (Exception e) {\n                logger.error(\"close admin client error\", e);\n                success = false;\n            }\n        }\n        if (success) {\n            logger.info(\"close admin client success of cluster {}\", clusterPhyId);\n        } else {\n            logger.error(\"close admin client error of cluster {}\", clusterPhyId);\n        }\n    } catch (Exception e) {\n        logger.error(\"close admin client error\", e);\n    } finally {\n        lock.unlock();\n    }\n}", "CodeBleu_score": 54.266532734110605}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    try {\n        lock.lock();\n        List<AdminClient> clientList = clientMap.get(clusterPhyId);\n        if (clientList == null) {\n            return;\n        }\n        logger.info(\"start to close kafka admin client, clusterId:{}\", clusterPhyId);\n        boolean success = true;\n        for (AdminClient client : clientList) {\n            try {\n                client.close();\n            } catch (Exception e) {\n                success = false;\n                logger.error(\"close kafka admin client error, clusterId:{}\", clusterPhyId, e);\n            }\n        }\n        if (success) {\n            logger.info(\"close kafka admin client success, clusterId:{}\", clusterPhyId);\n        }\n    } finally {\n        lock.unlock();\n    }\n}", "CodeBleu_score": 56.68882611187536}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    boolean success = true\n    if (adminClientList != null) {\n        for (AdminClient adminClient : adminClientList) {\n            try {\n                adminClient.close(Duration.ofSeconds(30))\n            } catch (Exception e) {\n                logger.error(\"Error closing AdminClient for cluster ${clusterPhyId}\", e)\n                success = false\n            }\n        }\n    }\n    return success\n}", "CodeBleu_score": 57.62872076261294}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    if (adminClientList == null) {\n        return true\n    }\n    boolean success = true\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30))\n        } catch (Exception e) {\n            logger.error(\"Failed to close adminClient for cluster ${clusterPhyId}\", e)\n            success = false\n        }\n    }\n    return success\n}", "CodeBleu_score": 60.47743419480439}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    if (adminClientList == null) {\n        return true\n    }\n    boolean success = true\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30))\n        } catch (Exception e) {\n            logger.error(\"Failed to close AdminClient for cluster {}\", clusterPhyId, e)\n            success = false\n        }\n    }\n    return success\n}", "CodeBleu_score": 64.42488077294273}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\t    if (isRunning()) {\n        app.stop();\n        int attempts = 0;\n        while (app.isRunning() && attempts < 5) {\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n                throw new IllegalStateException(e);\n            }\n            attempts++;\n        }\n        app = null;\n    }\n}", "CodeBleu_score": 55.66702799953999}, {"code": "public void stop() {\n\t        if (isRunning()) {\n            app.stop();\n            for (int i = 0; i < 5; i++) {\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    throw new IllegalStateException(e);\n                }\n                if (!app.isRunning()) {\n                    break;\n                }\n            }\n            app = null;\n        }\n    }", "CodeBleu_score": 46.76873708079924}, {"code": "public void stop() {\n\t    if (isRunning())  {\n        app.stop();\n        for (int i = 0; i < 5; i++)  {\n            if (!app.isRunning())  {\n                return;\n            }\n            try  {\n                sleep(1000);\n            }  catch (InterruptedException e)  {\n                throw new IllegalStateException(e);\n            }\n        }\n        throw new IllegalStateException(\"App failed to stop\");\n    }\n    app = null;\n}", "CodeBleu_score": 40.421713162994166}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner runner = new EurekaServerRunner(config)\n    runner.enableTls()\n    runner.setKeystore(keystore, keystorePassword)\n    runner.setTruststore(truststore, truststorePassword)\n    runner.start()\n    return runner\n}", "CodeBleu_score": 39.53274863919414}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner server = new EurekaServerRunner(config)\n    server.enableTls()\n    server.setKeyStore(keyStore, keyStorePassword)\n    server.setTrustStore(trustStore, trustStorePassword)\n    server.start()\n    return server\n}", "CodeBleu_score": 43.41393246442865}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner runner = new EurekaServerRunner(config)\n    runner.enableTls()\n    runner.setKeystore(keystoreFile, keystorePass)\n    runner.setTrustStore(truststoreFile, truststorePass)\n    runner.start()\n    return runner\n}", "CodeBleu_score": 34.85392345405083}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t    EurekaClientRunner client = new EurekaClientRunner(config, server, \"testservice\")\n    client.enableTlsClient()\n    client.start()\n    return client\n}", "CodeBleu_score": 52.620036415058436}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t    EurekaClientRunner client = new EurekaClientRunner(config, server, \"testservice\")\n    client.enableTlsClient()\n    client.start()\n    return client\n}", "CodeBleu_score": 52.620036415058436}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t    EurekaClientRunner client = new EurekaClientRunner(config, server, \"testservice\")\n    client.enableTlsClient()\n    client.start()\n    return client\n}", "CodeBleu_score": 52.620036415058436}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t    // Create a KeyTool instance for generating certificates\n    KeyTool keyTool = new KeyTool();\n\n    // Generate a CA certificate and save it\n    keyTool.generateCertificate(\n        \"ca\",\n        \"ca\",\n        \"ca\",\n        \"ca\",\n        \"ca\",\n        \"ca\",\n        \"ca\",\n        \"ca\",\n        \"ca\",\n        \"ca\"\n    );\n    saveCert(keyTool.getCertificate(), \"ca.crt\");\n\n    // Generate a server certificate and sign it with the CA certificate\n    keyTool.generateCertificate(\n        \"server\",\n        \"server\",\n        \"server\",\n        \"server\",\n        \"server\",\n        \"server\",\n        \"server\",\n        \"server\",\n        \"server\",\n        \"server\"\n    );\n    keyTool.signCertificate(\n        \"ca\",\n        \"ca\",\n        \"ca\",\n        \"ca\",\n        \"server\"\n    );\n    saveCert(keyTool.getCertificate(), \"server.crt\");\n\n    // Generate a client certificate and sign it with the CA certificate\n    keyTool.generateCertificate(\n        \"client\",\n        \"client\",\n        \"client\",\n        \"client\",\n        \"client\",\n        \"client\",\n        \"client\",\n        \"client\",\n        \"client\",\n        \"client\"\n    );\n    keyTool.signCertificate(\n        \"ca\",\n        \"ca\",\n        \"ca\",\n        \"ca\",\n        \"client\"\n    );\n    saveCert(keyTool.getCertificate(), \"client.crt\");\n\n    // Generate a second CA certificate and save it\n    keyTool.generateCertificate(\n        \"ca2\",\n        \"ca2\",\n        \"ca2\",\n        \"ca2\",\n        \"ca2\",\n        \"ca2\",\n        \"ca2\",\n        \"ca2\",\n        \"ca2\",\n        \"ca2\"\n    );\n    saveCert(keyTool.getCertificate(), \"ca2.crt\");\n\n    // Generate a second client certificate and sign it with the second CA certificate\n    keyTool.generateCertificate(\n", "CodeBleu_score": 14.88309977737902}, {"code": "static void createCertificates() throws Exception{\n\t    // Create a KeyTool instance for the CA\n    KeyTool caKeyTool = KeyTool.getInstance(\"JKS\");\n    caKeyTool.init(\"changeit\".toCharArray());\n\n    // Generate a CA certificate\n    X500Name caDn = new X500Name(\"CN=CA\");\n    BigInteger caSerial = BigInteger.valueOf(1);\n    Date caStartDate = new Date();\n    Date caEndDate = new Date(caStartDate.getTime() + 365 * 24 * 60 * 60 * 1000);\n    X509Certificate caCert = caKeyTool.generateCertificate(caDn, caSerial, caStartDate, caEndDate);\n\n    // Save the CA certificate and key\n    saveCert(caCert, \"ca.crt\");\n    saveKeyAndCert(caKeyTool.getPrivateKey(), \"ca.key\", caCert);\n\n    // Create a KeyTool instance for the server\n    KeyTool serverKeyTool = KeyTool.getInstance(\"JKS\");\n    serverKeyTool.init(\"changeit\".toCharArray());\n\n    // Generate a server certificate and sign it with the CA certificate\n    X500Name serverDn = new X500Name(\"CN=localhost\");\n    BigInteger serverSerial = BigInteger.valueOf(2);\n    Date serverStartDate = new Date();\n    Date serverEndDate = new Date(serverStartDate.getTime() + 365 * 24 * 60 * 60 * 1000);\n    X509Certificate serverCert = serverKeyTool.generateCertificate(serverDn, serverSerial, serverStartDate, serverEndDate);\n    X509Certificate[] chain = new X509Certificate[] { caCert };\n    serverCert = serverKeyTool.signCertificate(serverCert, chain, \"changeit\".toCharArray());\n\n    // Save the server certificate and key\n    saveCert(serverCert, \"server.crt\");\n    saveKeyAndCert(serverKeyTool.getPrivateKey(), \"server.key\", serverCert);\n\n    // Create a KeyTool instance for the client\n    KeyTool clientKey", "CodeBleu_score": 31.712499035770815}, {"code": "static void createCertificates() throws Exception{\n\t    KeyTool keyTool = new KeyTool();\n\n    // Create a CA certificate and key\n    keyTool.createCA(\"ca\");\n\n    // Create a server certificate and key signed by the CA\n    keyTool.createServerCert(\"server\", \"ca\");\n\n    // Create a client certificate and key signed by the CA\n    keyTool.createClientCert(\"client\", \"ca\");\n\n    // Save the CA certificate and key\n    saveCert(\"ca.crt\", keyTool.getCertificate(\"ca\"));\n    saveKeyAndCert(\"ca.key\", keyTool.getPrivateKey(\"ca\"));\n\n    // Save the server certificate and key\n    saveCert(\"server.crt\", keyTool.getCertificate(\"server\"));\n    saveKeyAndCert(\"server.key\", keyTool.getPrivateKey(\"server\"));\n\n    // Save the client certificate and key\n    saveCert(\"client.crt\", keyTool.getCertificate(\"client\"));\n    saveKeyAndCert(\"client.key\", keyTool.getPrivateKey(\"client\"));\n\n    // Create a second CA certificate and key\n    keyTool.createCA(\"ca2\");\n\n    // Create a client certificate and key signed by the second CA\n    keyTool.createClientCert(\"client2\", \"ca2\");\n\n    // Save the second CA certificate and key\n    saveCert(\"ca2.crt\", keyTool.getCertificate(\"ca2\"));\n    saveKeyAndCert(\"ca2.key\", keyTool.getPrivateKey(\"ca2\"));\n\n    // Save the second client certificate and key\n    saveCert(\"client2.crt\", keyTool.getCertificate(\"client2\"));\n    saveKeyAndCert(\"client2.key\", keyTool.getPrivateKey(\"client2\"));\n}", "CodeBleu_score": 23.25993344208333}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long startTime = System.currentTimeMillis();\n    long timeLimit = seconds * 1000L;\n    while (!assertion.getAsBoolean()) {\n        if (System.currentTimeMillis() - startTime >= timeLimit) {\n            throw new RuntimeException(\"Assertion not met within \" + seconds + \" seconds\");\n        }\n        Thread.yield();\n    }\n}", "CodeBleu_score": 40.32127714944407}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long startTime = System.currentTimeMillis();\n    long timeLimit = seconds * 1000;\n    while (!assertion.getAsBoolean()) {\n        if (System.currentTimeMillis() - startTime >= timeLimit) {\n            throw new RuntimeException(\"Assertion not met within \" + seconds + \" seconds\");\n        }\n        try {\n            Thread.sleep(100);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n}", "CodeBleu_score": 36.554069185396244}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long startTime = System.currentTimeMillis();\n    long timeLimit = seconds * 1000L;\n    while (!assertion.getAsBoolean() && System.currentTimeMillis() - startTime < timeLimit) {\n        try {\n            Thread.sleep(100);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n    if (!assertion.getAsBoolean()) {\n        throw new RuntimeException(\"Assertion not met within \" + seconds + \" seconds\");\n    }\n}", "CodeBleu_score": 36.34711677490362}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t    X509v3CertificateBuilder certBuilder = new X509v3CertificateBuilder(\n            new X500Name(ca),\n            BigInteger.valueOf(System.currentTimeMillis()),\n            new Date(System.currentTimeMillis() + 1000L * 60 * 60 * 24 * 365 * 10),\n            new X500Name(\"CN=\" + keyPair.getPublic().toString()),\n            keyPair.getPublic()\n    );\n\n    certBuilder.addExtension(\n            Extension.keyUsage,\n            true,\n            new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment)\n    );\n\n    certBuilder.addExtension(\n            Extension.basicConstraints,\n            true,\n            new BasicConstraints(false)\n    );\n\n    X509CertificateHolder certificateHolder = certBuilder.build(\n            new JcaContentSignerBuilder(\"SHA256WithRSA\").build(keyPair.getPrivate())\n    );\n\n    return new JcaX509CertificateConverter().setProvider(\"BC\").getCertificate(certificateHolder);\n}", "CodeBleu_score": 34.728493513116945}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t    X509Certificate cert = certBuilder(keyPair, ca).build();\n    cert.verify(keyPair.getPublic());\n    return cert;\n}", "CodeBleu_score": 26.257841309534275}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t    // Construct a certificate builder with the public key and CA information\n    X509v3CertificateBuilder certBuilder = new JcaX509v3CertificateBuilder(\n        new X500Name(\"CN=\" + ca),\n        BigInteger.valueOf(System.currentTimeMillis()),\n        new Date(),\n        new Date(System.currentTimeMillis() + 1000L * 60 * 60 * 24 * 365 * 10),\n        new X500Name(\"CN=\" + ca),\n        keyPair.getPublic()\n    );\n\n    // Add key usage and basic constraints extensions to the certificate\n    certBuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment));\n    certBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\n    // Sign the certificate with the private key\n    ContentSigner contentSigner = new JcaContentSignerBuilder(\"SHA256WithRSA\").build(keyPair.getPrivate());\n    X509CertificateHolder certHolder = certBuilder.build(contentSigner);\n\n    // Return the signed X509 certificate\n    return new JcaX509CertificateConverter().getCertificate(certHolder);\n}", "CodeBleu_score": 38.19004081818554}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (EurekaHttpClient == null) {\n        try {\n            Field registrationClient = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n            registrationClient.setAccessible(true);\n            EurekaHttpClient = (EurekaHttpClient) registrationClient.get(eurekaTransport);\n        } catch (IllegalAccessException | NoSuchFieldException e) {\n            log.error(\"Error accessing EurekaHttpClient\", e);\n        }\n    }\n    return EurekaHttpClient;\n}", "CodeBleu_score": 48.398780568503454}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (eurekaHttpClient == null) {\n        try {\n            Field registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\")\n            registrationClientField.setAccessible(true)\n            eurekaHttpClient = registrationClientField.get(eurekaTransport) as EurekaHttpClient\n        } catch (IllegalAccessException e) {\n            log.error(\"Failed to access registrationClient field in eurekaTransport\", e)\n        }\n    }\n    return eurekaHttpClient\n}", "CodeBleu_score": 46.21352894255871}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (eurekaHttpClient == null) {\n        try {\n            Field registrationClient = eurekaTransport.getClass().getDeclaredField(\"registrationClient\")\n            registrationClient.setAccessible(true)\n            eurekaHttpClient = (EurekaHttpClient) registrationClient.get(eurekaTransport)\n        } catch (IllegalAccessException e) {\n            logger.error(\"Error accessing registrationClient field\", e)\n        }\n    }\n    return eurekaHttpClient\n}", "CodeBleu_score": 45.62949630189756}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t    List<String> services = new ArrayList<>();\n    List<Application> applications = getApplications();\n    if (applications.isEmpty()) {\n        return services;\n    }\n    for (Application application : applications) {\n        for (InstanceInfo instanceInfo : application.getInstances()) {\n            services.add(instanceInfo.getServiceName().toLowerCase());\n        }\n    }\n    return services;\n}", "CodeBleu_score": 44.5648464228548}, {"code": "public List<String> getServices(){\n\t    List<String> services = new ArrayList<>();\n    List<Application> applications = getApplications();\n    if (applications.isEmpty()) {\n        return services;\n    } else {\n        for (Application application : applications) {\n            if (!application.getInstances().isEmpty()) {\n                services.add(application.getName().toLowerCase());\n            }\n        }\n        return services;\n    }\n}", "CodeBleu_score": 40.180985121503845}, {"code": "public List<String> getServices(){\n\t        List<String> services = new ArrayList<>();\n        List<Application> registeredApplications = getApplications().getRegisteredApplications();\n        if (registeredApplications == null || registeredApplications.isEmpty()) {\n            return emptyList();\n        }\n        registeredApplications.forEach(application -> {\n            if (application.getInstances().size() > 0) {\n                services.add(application.getName().toLowerCase());\n            }\n        });\n        return services;\n    }", "CodeBleu_score": 42.51679121158786}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    healthContributors.forEach((key, value) -> {\n        if (value instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor discoveryCompositeHealthContributor = (DiscoveryCompositeHealthContributor) value;\n            discoveryCompositeHealthContributor.getIndicators().forEach((indicatorKey, indicatorValue) -> {\n                if (!(indicatorValue instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(indicatorKey, indicatorValue);\n                }\n            });\n        } else {\n            healthContributors.put(key, value);\n        }\n    });\n}", "CodeBleu_score": 36.37312629613646}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    for (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n        if (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor discoveryCompositeHealthContributor = (DiscoveryCompositeHealthContributor) entry.getValue();\n            for (Map.Entry<String, HealthIndicator> discoveryEntry : discoveryCompositeHealthContributor.getIndicators().entrySet()) {\n                if (!(discoveryEntry.getValue() instanceof EurekaHealthIndicator)) {\n                    this.healthContributors.put(discoveryEntry.getKey(), discoveryEntry.getValue());\n                }\n            }\n        } else {\n            this.healthContributors.put(entry.getKey(), entry.getValue());\n        }\n    }\n}", "CodeBleu_score": 46.196841310884686}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    for (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n        HealthContributor contributor = entry.getValue();\n        if (contributor instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor discoveryCompositeContributor = (DiscoveryCompositeHealthContributor) contributor;\n            for (HealthIndicator indicator : discoveryCompositeContributor.getIndicators().values()) {\n                if (!(indicator instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(indicator.getId(), indicator);\n                }\n            }\n        } else {\n            healthContributors.put(entry.getKey(), entry.getValue());\n        }\n    }\n}", "CodeBleu_score": 45.377580536105015}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.size() == 0) throw new RuntimeException(\"provider-application instance not found\");\n    String url = instances.get(0).getUri().toString();\n    return restTemplate.postForObject(url + \"/echo\", \"Hello World\", String.class);\n}", "CodeBleu_score": 43.52109272935073}, {"code": "public String hello(){\n\t    // Attempt to discover an instance of \"provider-application\"\n    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"Unable to find any instances of 'provider-application'\");\n    }\n\n    // Get the URI of the first instance\n    String serviceUri = String.format(\"%s/echo\", instances.get(0).getUri());\n\n    // Send a POST request to the \"/echo\" endpoint of the provider application\n    String response = restTemplate.postForObject(serviceUri, \"Hello\", String.class);\n\n    return response;\n}", "CodeBleu_score": 56.19946640210887}, {"code": "public String hello(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.size() == 0) {\n        throw new RuntimeException(\"No service instance for provider-application found.\");\n    }\n    String uri = instances.get(0).getUri().toString();\n    String response = restTemplate.postForObject(uri + \"/echo\", \"Hello\", String.class);\n    return response;\n}", "CodeBleu_score": 63.3438411186013}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t    ServiceInstance instance = loadBalancerClient.choose(\"provider-application\");\n    if (instance == null) {\n        throw new RuntimeException(\"Unable to find service instance named 'provider-application'\");\n    }\n    URI uri = instance.getUri();\n    String response = restTemplate.postForObject(uri + \"/echo\", \"Hello\", String.class);\n    return response;\n}", "CodeBleu_score": 61.54075199227276}, {"code": "public String world(){\n\t    ServiceInstance instance = loadBalancer.choose(\"provider-application\");\n    if (instance == null) {\n        throw new RuntimeException(\"Failed to find service: provider-application\");\n    }\n    URI uri = instance.getUri();\n    String result = restTemplate.postForObject(uri.resolve(\"/echo\"), \"Hello World\", String.class);\n    return result;\n}", "CodeBleu_score": 61.584295678318355}, {"code": "public String world(){\n\t    // Choose a service instance using a load balancer client\n    ServiceInstance instance = loadBalancerClient.choose(\"provider-application\");\n\n    // Construct a URI for the POST request\n    URI uri = getUri(instance);\n\n    // Send a POST request using a RestTemplate and retrieve the response as a String\n    return postForObject(uri, \"Hello World\", String.class);\n}", "CodeBleu_score": 24.773858248034742}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    logger.info(\"Registering service: \" + serviceName + \" with IP: \" + ip + \" and port: \" + port);\n    if (!serverMap.containsKey(serviceName)) {\n        serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n    }\n    serverMap.get(serviceName).add(new Server(ip, port));\n    return true;\n}", "CodeBleu_score": 53.36343386842197}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    logger.info(\"Registering service: \" + serviceName + \" with IP: \" + ip + \" and port: \" + port);\n    if (!serverMap.containsKey(serviceName)) {\n        serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<Server>()));\n    }\n    serverMap.get(serviceName).add(new Server(ip, port));\n    return true;\n}", "CodeBleu_score": 50.29667561952213}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t        logger.info(\"Registering service: \" + serviceName + \" with IP: \" + ip + \" and port: \" + port);\n        if (!serverMap.containsKey(serviceName)) {\n            serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<Server>()));\n        }\n        serverMap.get(serviceName).add(new Server(ip, port));\n        return true;\n    }", "CodeBleu_score": 48.79505793137884}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t        logger.info(\"deregister service: \" + serviceName + \", ip: \" + ip + \", port: \" + port);\n        Set<Server> servers = serverMap.get(serviceName);\n        if (servers == null) {\n            return false;\n        }\n        Server server = new Server(ip, port);\n        return servers.remove(server);\n    }", "CodeBleu_score": 55.988502982206825}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    log.info(\"deregister service: \" + serviceName + \" ip: \" + ip + \" port: \" + port);\n    Set<Server> set = serverMap.get(serviceName);\n    if (set == null) {\n        log.warn(\"deregister fail, service not found, serviceName: \" + serviceName + \" ip: \" + ip + \" port: \" + port);\n        return false;\n    }\n    Server server = new Server(ip, port);\n    set.remove(server);\n    return true;\n}", "CodeBleu_score": 56.96777149748797}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    logger.info(\"deregister service: \" + serviceName + \" ip: \" + ip + \" port: \" + port);\n    Set<Server> set = serverMap.get(serviceName);\n    if (set == null) {\n        logger.error(\"no such service: \" + serviceName);\n        return false;\n    }\n    Server server = new Server(ip, port);\n    set.remove(server);\n    return true;\n}", "CodeBleu_score": 57.495390386066425}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attrs = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attrs == null) {\n        return;\n    }\n    Map<String, Object> defaultAttrs = (Map<String, Object>) attrs.get(\"defaultConfiguration\");\n    if (defaultAttrs != null) {\n        String name = (String) defaultAttrs.get(\"name\");\n        registerClientConfiguration(registry, name, defaultAttrs);\n    }\n}", "CodeBleu_score": 56.575572780911564}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attrs = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attrs == null) {\n        return;\n    }\n    Map<String, Object> defaultAttrs = (Map<String, Object>) attrs.get(\"defaultConfiguration\");\n    if (defaultAttrs != null) {\n        String name = (String) defaultAttrs.get(\"name\");\n        registerClientConfiguration(registry, name, defaultAttrs);\n    }\n}", "CodeBleu_score": 56.575572780911564}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attrs = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attrs == null) {\n        return;\n    }\n    Map<String, Object> defaultAttrs = (Map<String, Object>) attrs.get(\"defaultConfiguration\");\n    if (defaultAttrs != null) {\n        String name = getName(metadata);\n        registerClientConfiguration(defaultAttrs, name, registry);\n    }\n}", "CodeBleu_score": 57.01059233074013}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    ServiceInstance instance = getInstance(serviceId);\n    if (instance == null) {\n        return null;\n    }\n    return new ServiceInstance(serviceId, instance.getHost(), instance.getPort());\n}", "CodeBleu_score": 37.60665318372563}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    ServiceInstance server = getInstance(serviceId);\n    if (server == null) {\n        return null;\n    }\n    return new DefaultServiceInstance(server.getServiceId(), server.getHost(), server.getPort(), server.isSecure());\n}", "CodeBleu_score": 38.24899741272627}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    ServiceInstance server = getInstance(serviceId);\n    if (server == null) {\n        return null;\n    }\n    return new TutuServiceInstance(server);\n}", "CodeBleu_score": 28.021227384483684}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    try {\n        StringBuilder sb = new StringBuilder();\n        sb.append(original.getScheme())\n                .append(\"://\")\n                .append(server.getHost())\n                .append(\":\")\n                .append(server.getPort());\n        if (original.getRawPath() != null) {\n            sb.append(original.getRawPath());\n        }\n        if (original.getRawQuery() != null) {\n            sb.append(\"?\").append(original.getRawQuery());\n        }\n        URI uri = new URI(sb.toString());\n        return uri;\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 79.9073454518233}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    try {\n        URIBuilder uriBuilder = new URIBuilder(original);\n        String host = server.getHost();\n        int port = server.getPort();\n        uriBuilder.setHost(host);\n        uriBuilder.setPort(port);\n        if (original.getRawQuery() != null) {\n            uriBuilder.setCustomQuery(original.getRawQuery());\n        }\n        return uriBuilder.build();\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 46.02326414448126}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    try {\n        return new URI(server.getScheme(), null, server.getHost(), server.getPort(), original.getPath(), original.getRawQuery(), null);\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(\"Error reconstructing URI\", e);\n    }\n}", "CodeBleu_score": 22.843234888309393}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t    def serviceName = \"tutu\"\n    def serverAddr = getServerAddr()\n    def params = [\n            serviceName: serviceName\n    ]\n    def response = httpGet(serverAddr + \"/list\", params)\n    def jsonArray = parseArray(response)\n    return jsonArray.collect {\n        new TutuServer(it.getString(\"ip\"), it.getInteger(\"port\"))\n    }\n}", "CodeBleu_score": 22.3859689052148}, {"code": "private List<TutuServer> getServer(){\n\t    def params = [:]\n    params.put(\"serviceName\", serviceName)\n\n    def response = httpGet(serverAddr + \"/list\", params)\n\n    if (response.status != 200) {\n        return []\n    }\n\n    def jsonArray = parseArray(response.content)\n\n    return jsonArray.stream().map({\n        def ip = it.get(\"ip\").asString()\n        def port = it.get(\"port\").asInt()\n        return new TutuServer(ip, port)\n    }).collect(Collectors.toList())\n}", "CodeBleu_score": 30.79543278611816}, {"code": "private List<TutuServer> getServer(){\n\t    def params = [:]\n    params.put(\"serviceName\", serviceName)\n    def url = serverAddr + \"/list\"\n    def response = http.get(url, params)\n    if (response.status == 200) {\n        def json = parseArray(response.content)\n        def servers = json.collect {\n            new TutuServer(it.getString(\"ip\"), it.getInteger(\"port\"))\n        }\n        return servers\n    } else {\n        return []\n    }\n}", "CodeBleu_score": 23.994977067500283}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t    for (ZuulRoute route : routes.values()) {\n        String pattern = route.getPath();\n        boolean isMatch = pathMatcher.match(pattern, path);\n        if (isMatch) {\n            String finalPath = path.substring(pattern.length());\n            return new Route(finalPath, route.getServiceId());\n        }\n    }\n    return null;\n}", "CodeBleu_score": 37.927020635319366}, {"code": "public Route getMatchingRoute(String path){\n\t    for (ZuulRoute route : this.routes.values()) {\n        String pattern = route.getPath();\n        boolean isMatch = this.pathMatcher.match(pattern, path);\n        if (isMatch) {\n            String finalPath = this.pathMatcher.extractPathWithinPattern(pattern, path);\n            return new Route(finalPath, route.getLocation());\n        }\n    }\n    return null;\n}", "CodeBleu_score": 39.30384830623675}, {"code": "public Route getMatchingRoute(String path){\n\t    for (ZuulRoute route : this.routes.values()) {\n        if (this.pathMatcher.match(route.getPath(), path)) {\n            String targetPath = this.pathMatcher.extractPathWithinPattern(route.getPath(), path);\n            return new Route(targetPath, route.getServiceId());\n        }\n    }\n    return null;\n}", "CodeBleu_score": 35.574975584090254}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    String packageName = getPackageName(importingClassMetadata);\n    Set<BeanDefinitionHolder> beanDefinitions = scanPackageByAnnotation(packageName, FeignClient.class);\n\n    for (BeanDefinitionHolder definition : beanDefinitions) {\n        GenericBeanDefinition beanDefinition = (GenericBeanDefinition) definition.getBeanDefinition();\n        beanDefinition.getPropertyValues().add(\"contextId\", definition.getBeanName());\n        beanDefinition.getPropertyValues().add(\"type\", beanDefinition.getBeanClassName());\n        beanDefinition.setBeanClass(FeignClientFactoryBean.class);\n        registry.registerBeanDefinition(definition.getBeanName(), beanDefinition);\n    }\n}", "CodeBleu_score": 35.29064600252732}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    // Get the package name of the importing class\n    String packageName = ClassUtils.getPackageName(importingClassMetadata.getClassName());\n    // Scan for classes annotated with @FeignClient within the package\n    Set<BeanDefinitionHolder> beanDefinitions = scanPackageByAnnotation(packageName, FeignClient.class);\n    // Iterate over the bean definitions\n    for (BeanDefinitionHolder holder : beanDefinitions) {\n        // Get the bean definition\n        GenericBeanDefinition definition = (GenericBeanDefinition) holder.getBeanDefinition();\n        // Get the class name of the bean definition\n        String className = definition.getBeanClassName();\n        // Set the context ID of the bean definition to the class name\n        definition.getPropertyValues().add(\"contextId\", className);\n        // Set the type of the bean definition to the class name\n        definition.setBeanClass(ClassUtils.resolveClassName(className, this.resourceLoader.getClassLoader()));\n        // Register the bean definition with the registry using its class name as the bean name\n        registry.registerBeanDefinition(className, definition);\n    }\n}", "CodeBleu_score": 41.54683713092971}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    String packageName = importingClassMetadata.getClassName();\n    int dotIndex = packageName.lastIndexOf('.');\n    if (dotIndex != -1) {\n        packageName = packageName.substring(0, dotIndex);\n    }\n    Set<BeanDefinitionHolder> beanDefinitions = scanPackageByAnnotation(packageName, FeignClient.class);\n    for (BeanDefinitionHolder holder : beanDefinitions) {\n        GenericBeanDefinition definition = (GenericBeanDefinition) holder.getBeanDefinition();\n        definition.getPropertyValues().add(\"contextId\", definition.getBeanClassName());\n        definition.getPropertyValues().add(\"type\", definition.getBeanClassName());\n        registry.registerBeanDefinition(definition.getBeanClassName(), definition);\n    }\n}", "CodeBleu_score": 36.46765498217963}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}]}
