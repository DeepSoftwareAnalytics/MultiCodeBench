{"instance_id": "58936b2a621b", "generation_result": [{"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\n\n\n\n\n", "CodeBleu_score": 83.87646776544821}, {"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\n\n", "CodeBleu_score": 83.87646776544821}, {"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 83.87646776544821}]}
{"instance_id": "83b142d9d251", "generation_result": [{"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n    x_train, x_test, y_train, y_test = train_test_split(\n        data,\n        label,\n        test_size=1 - support_ratio,\n        stratify=label,\n        random_state=42,\n    )\n    return x_train, x_test, y_train, y_test", "CodeBleu_score": 65.30740775035834}, {"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n    x_train, x_test, y_train, y_test = train_test_split(\n        data, label, train_size=support_ratio, stratify=label, random_state=42\n    )\n    return x_train, x_test, y_train, y_test\n\n", "CodeBleu_score": 79.02154969744815}, {"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n    x_train, x_test, y_train, y_test = train_test_split(\n        data,\n        label,\n        test_size=1 - support_ratio,\n        random_state=42,\n        stratify=label,\n    )\n    return x_train, x_test, y_train, y_test\n\n", "CodeBleu_score": 65.30740775035834}]}
{"instance_id": "5fd02b540f61", "generation_result": [{"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n    X, y = make_regression(n_samples=1000, n_features=3, random_state=42)\n    X_test, y_test = make_regression(\n        n_samples=1000, n_features=3, random_state=42\n    )\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    return X_train, y_train, X_test, y_test\n\n", "CodeBleu_score": 36.329233714901285}, {"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n    X, y = make_regression(n_samples=1000, n_features=3, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    return X_train, y_train, X_test, y_test\n\n", "CodeBleu_score": 38.92483101817302}, {"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n    X, y = make_regression(n_samples=1000, n_features=3, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    return X_train, y_train, X_test, y_test\n\n", "CodeBleu_score": 38.92483101817302}]}
{"instance_id": "ad958cb31a57", "generation_result": [{"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    return GMMParameters(\n        ndarrays[0],\n        ndarrays[1],\n        ndarrays[2],\n        ndarrays[3],\n        ndarrays[4],\n    )\n\n", "CodeBleu_score": 43.55158623916156}, {"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    means, covariances, weights, num_samples = ndarrays\n    return GMMParameters(means, covariances, weights, num_samples)\n\n", "CodeBleu_score": 37.7162582802266}, {"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    return GMMParameters(\n        label=ndarrays[0],\n        means=ndarrays[1],\n        weights=ndarrays[2],\n        covariances=ndarrays[3],\n        num_samples=ndarrays[4],\n    )\n\n", "CodeBleu_score": 79.03672928896962}]}
{"instance_id": "061d5a5b9d56", "generation_result": [{"code": "def datafiles_fusion(data_paths):\n\t\n    X, Y = load_svmlight_file(data_paths[0])\n    X = X.toarray()\n    for i in range(1, len(data_paths)):\n        X_i, Y_i = load_svmlight_file(data_paths[i])\n        X_i = X_i.toarray()\n        assert X.shape[1] == X_i.shape[1]\n        X = np.concatenate((X, X_i))\n        Y = np.concatenate((Y, Y_i))\n    return X, Y", "CodeBleu_score": 38.87156018741532}, {"code": "def datafiles_fusion(data_paths):\n\t\n    X, Y = load_svmlight_file(data_paths[0])\n    X = X.toarray()\n    for i in range(1, len(data_paths)):\n        X_new, Y_new = load_svmlight_file(data_paths[i])\n        X_new = X_new.toarray()\n        if X_new.shape[1] != X.shape[1]:\n            raise ValueError(\"Number of features in file {} does not match first file.\".format(i+1))\n        X = np.concatenate((X, X_new), axis=0)\n        Y = np.concatenate((Y, Y_new), axis=0)\n    return X, Y", "CodeBleu_score": 42.47554027612402}, {"code": "def datafiles_fusion(data_paths):\n\t\n    for i, data_path in enumerate(data_paths):\n        if i == 0:\n            X, Y = load_svmlight_file(data_path)\n            X = X.toarray()\n        else:\n            X_new, Y_new = load_svmlight_file(data_path)\n            X_new = X_new.toarray()\n            assert X_new.shape[1] == X.shape[1]\n            X = np.concatenate((X, X_new), axis=0)\n            Y = np.concatenate((Y, Y_new), axis=0)\n    return X, Y\n\n", "CodeBleu_score": 33.35692278570235}]}
{"instance_id": "977d3bd5d5a3", "generation_result": [{"code": "def eval_learning(y_test, y_pred)\n\t\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average='micro')\n    precision = precision_score(y_test, y_pred, average='micro')\n    f1 = f1_score(y_test, y_pred, average='micro')\n    return accuracy, recall, precision, f1\n\n", "CodeBleu_score": 33.42910286151195}, {"code": "def eval_learning(y_test, y_pred)\n\t\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average='micro')\n    precision = precision_score(y_test, y_pred, average='micro')\n    f1 = f1_score(y_test, y_pred, average='micro')\n    return accuracy, recall, precision, f1\n\n", "CodeBleu_score": 33.42910286151195}, {"code": "def eval_learning(y_test, y_pred)\n\t\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average='micro')\n    precision = precision_score(y_test, y_pred, average='micro')\n    f1 = f1_score(y_test, y_pred, average='micro')\n    return accuracy, recall, precision, f1\n\n", "CodeBleu_score": 33.42910286151195}]}
{"instance_id": "f4c838f1f092", "generation_result": [{"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for batch_idx, (data, targets) in enumerate(train_loader):\n            data = data.to(device)\n            targets = targets.to(device)\n            scores = model(data)\n            loss = criterion(scores, targets)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n", "CodeBleu_score": 55.688534569327295}, {"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for batch_idx, (data, targets) in enumerate(train_loader):\n            data = data.to(device=device)\n            targets = targets.to(device=device)\n            # forward\n            scores = model(data)\n            loss = criterion(scores, targets)\n            # backward\n            optimizer.zero_grad()\n            loss.backward()\n            # gradient descent or adam step\n            optimizer.step()\n\n", "CodeBleu_score": 55.64131995088088}, {"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for batch_idx, (data, target) in enumerate(train_loader):\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n\n", "CodeBleu_score": 57.43372813526146}]}
{"instance_id": "35068c779c02", "generation_result": [{"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    assert cfg.dataset.type == \"LIBSVM\"\n    train_dataset_path = cfg.dataset.train_dataset_path\n    train_dataset_name = cfg.dataset.train_dataset_name\n    data, labels = load_svmlight_file(train_dataset_path)\n    data = data.toarray().astype(np.float32)\n    labels = labels.astype(np.int32)\n    print(np.unique(labels, return_counts=True))\n    print(data.shape)\n    if train_dataset_name == \"MUSHROOMS\":\n        labels[labels == 1] = 0\n        labels[labels != 0] = 1\n    else:\n        raise RuntimeError(\"Unknown dataset\")\n    return Dataset(\n        data=torch.Tensor(data),\n        labels=torch.Tensor(labels),\n    )\n", "CodeBleu_score": 32.92024972351137}, {"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    assert cfg.dataset.type == DatasetType.LIBSVM\n    train_dataset_path = cfg.dataset.train_dataset_path\n    train_dataset_name = cfg.dataset.train_dataset_name\n    data, labels = load_svmlight_file(\n        path=train_dataset_path,\n        multilabel=False,\n        zero_based=True,\n        dtype=np.float32,\n    )\n    data = data.toarray()\n    labels = labels.astype(np.int32)\n    print(f\"unique labels: {np.unique(labels, return_counts=True)}\")\n    print(f\"data shape: {data.shape}\")\n    if train_dataset_name == \"MUSHROOMS\":\n        labels = np.where(labels == 1, 0, 1)\n    else:\n        raise RuntimeError(\n            f\"Dataset {train_dataset_name} is not supported for this experiment.\"\n        )\n    return TensorDataset(torch.Tensor(data), torch.Tensor(labels))\n\n", "CodeBleu_score": 34.18917913387109}, {"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    if cfg.dataset.type != \"LIBSVM\":\n        raise RuntimeError(f\"{cfg.dataset.type} is not a valid dataset type\")\n    train_dataset_path = os.path.join(cfg.dataset.path, cfg.dataset.name)\n    print(f\"Loading {train_dataset_path}\")\n    data, labels = load_svmlight_file(train_dataset_path)\n    data = data.toarray().astype(np.float32)\n    labels = labels.astype(np.int32)\n    print(f\"unique labels: {np.unique(labels, return_counts=True)}; data shape: {data.shape}\")\n    if cfg.dataset.name == \"MUSHROOMS\":\n        labels = np.array([0 if label == 1 else 1 for label in labels])\n    else:\n        raise RuntimeError(f\"{cfg.dataset.name} is not a valid dataset name\")\n    return data_utils.TensorDataset(torch.Tensor(data), torch.Tensor(labels))", "CodeBleu_score": 42.22946545014786}]}
{"instance_id": "d602a96e571e", "generation_result": [{"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, \"fit_transform\"):\n        res = transformer.fit_transform(X, y, **fit_params)\n    else:\n        res = transformer.fit(X, y, **fit_params).transform(X)\n    if weight is None:\n        return res, transformer\n    return res * weight, transformer\n\n", "CodeBleu_score": 88.84159847409744}, {"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, \"fit_transform\"):\n        res = transformer.fit_transform(X, y, **fit_params)\n    else:\n        res = transformer.fit(X, y, **fit_params).transform(X)\n    if weight is None:\n        return res, transformer\n    return res * weight, transformer\n\n", "CodeBleu_score": 88.84159847409744}, {"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, \"fit_transform\"):\n        res = transformer.fit_transform(X, y, **fit_params)\n    else:\n        res = transformer.fit(X, y, **fit_params).transform(X)\n    if weight is None:\n        return res, transformer\n    return res * weight, transformer\n\n", "CodeBleu_score": 88.84159847409744}]}
{"instance_id": "fcf88a773fd8", "generation_result": [{"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    X = check_array(X, accept_sparse=\"csc\", copy=copy, force_all_finite=False)\n    if isinstance(transform, _NoTransformer):\n        return X\n    if selected == \"all\":\n        return transform.transform(X)\n    if len(selected) == 0:\n        return X\n    n_features = X.shape[1]\n    ind = np.arange(n_features)\n    sel = np.zeros(n_features, dtype=bool)\n    sel[np.asarray(selected)] = True\n    not_sel = np.logical_not(sel)\n    n_selected = np.sum(sel)\n    if n_selected == 0:\n        return X\n    X_sel = transform.transform(X[:, ind[sel]])\n    X_not_sel = X[:, ind[not_sel]]\n    if sparse.issparse(X_sel) or sparse.issparse(X_not_sel):\n        return sparse.hstack((X_sel, X_not_sel))\n    else:\n        return np.hstack((X_sel, X_not_sel))", "CodeBleu_score": 69.7317272145955}, {"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    X = check_array(X, accept_sparse=\"csc\", force_all_finite=False)\n    if isinstance(transform, str):\n        raise ValueError(\n            \"Specifying the string '%s' to mean the full \"\n            \"matrix is not supported. Specify a sparse \"\n            \"matrix instead.\" % transform\n        )\n    elif selected == \"all\":\n        return transform(X)\n    elif len(selected) == 0:\n        # no features selected.\n        if X.shape[1] != transform.shape[0]:\n            raise ValueError(\n                \"X has %d features, but transform is a %s matrix\"\n                % (X.shape[1], transform.shape)\n            )\n        return X\n    else:\n        transform = atleast2d_or_csr(transform)\n        if transform.shape[1] != X.shape[1]:\n            raise ValueError(\n                \"X has %d features, but transform a %s matrix\" % (X.shape[1], transform.shape)\n            )\n        X_sel = X[:, selected]\n        X_not_sel = X[:, np.logical_not(selected)]\n        X_sel = transform(X_sel)\n        if sparse.issparse(X_sel) and not sparse.issparse(X):\n            X_sel = X_sel.toarray()\n        X[:, selected] = X_sel\n        X = np.hstack((X_sel, X_not_sel))\n        return X", "CodeBleu_score": 37.038425023728465}, {"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    X = check_array(X, accept_sparse=\"csc\", copy=copy, force_all_finite=False)\n    if isinstance(transform, str):\n        raise ValueError(\n            \"Specifying the string 'all' or 'pairwise' to select all \"\n            \"features or pairwise features is deprecated and will be \"\n            \"removed in 0.23. Use 'all' or 'pairwise' in the \"\n            \"function call or SelectorMixin instead.\"\n        )\n    if selected == \"all\":\n        return transform.fit_transform(X)\n    elif len(selected) == 0:\n        return X\n    else:\n        n_features = X.shape[1]\n        ind = np.arange(n_features)\n        mask = np.logical_not(np.in1d(ind, selected))\n        not_selected = ind[mask]\n        if len(not_selected):\n            X_not_selected = X[:, not_selected]\n            if sparse.issparse(X_not_selected):\n                X_not_selected = X_not_selected.tocsc()\n            else:\n                X_not_selected = X_not_selected.copy()\n        else:\n            X_not_selected = np.empty(0).reshape(X.shape[0], 0)\n        X_selected = X[:, selected]\n        if sparse.issparse(X_selected):\n            X_selected = X_selected.tocsc()\n        else:\n            X_selected = X_selected.copy()\n        X_new = np.hstack(\n            [\n                X_not_selected,\n                transform.fit_transform(X_selected),\n            ]\n        )\n        return X_new\n\n", "CodeBleu_score": 44.68475314572166}]}
{"instance_id": "c9dfb00047d1", "generation_result": [{"code": "def _transform_new(self, X)\n\t\n    X = check_array(X, accept_sparse=\"csc\", dtype=None)\n    n_samples, n_features = X.shape\n    X_int, X_mask = self._encode(X)\n    n_values = [codes.shape[0] for codes in self.categories_]\n    X_mask = X_mask.ravel()\n    indices = np.repeat(np.arange(n_features, dtype=np.int32), n_values)\n    indptr = np.cumsum(\n        np.insert(n_values, 0, 0)\n    )\n    data = np.ones(n_samples * n_features, dtype=np.int32)\n    out = sparse.csr_matrix(\n        (data, indices, indptr),\n        shape=(n_samples, indices.max() + 1),\n        dtype=self.dtype,\n    ).T\n    mask = np.array(X_mask, dtype=bool)\n    out[mask] = X_int.ravel()\n    if not self.sparse:\n        out = out.toarray()\n        out = out[:, np.any(X_mask, axis=0)]\n    return out\n\n", "CodeBleu_score": 31.53319951113503}, {"code": "def _transform_new(self, X)\n\t\n    X = check_array(X, accept_sparse=\"csc\", dtype=None)\n    n_samples, n_features = X.shape\n    X_int, X_mask = self._encode(X)\n    n_samples, n_features = X_mask.shape\n    X_mask = np.asarray(X_mask, dtype=\"int8\")\n    diff = np.diff(X_int.indptr)\n    if (np.any((diff < 0)) or np.any((diff >= self.categories_))):\n        raise ValueError(\"Negative value in X_int.indptr\")\n    indices = np.repeat(np.arange(n_features, dtype=np.int32), diff)\n    indptr = np.cumsum(np.hstack(([0], diff)))\n    data = np.empty(n_samples, dtype=self.dtype_)\n    data[:] = self.categories_ - 1\n    out = sparse.csr_matrix((data, indices, indptr), shape=(n_samples, n_features), dtype=self.dtype_)\n    mask = np.asarray(X_mask.ravel(), dtype=\"bool\")\n    out[~mask] = X_int.data\n    return out.toarray() if (self.sparse is False) else out\n\n", "CodeBleu_score": 30.58354198662352}, {"code": "def _transform_new(self, X)\n\t\n    X = check_array(X, accept_sparse=\"csc\", dtype=None)\n    n_samples, n_features = X.shape\n    X_int, X_mask = self._encode(X)\n    n_values = [cats.shape[0] for cats in self.categories_]\n    indices = _transform_selected(X_int, X_mask, n_values)\n    indptr = np.asarray(indices.sum(axis=1).cumsum().tolist() + [0])\n    data = (np.ones(n_samples, dtype=X.dtype) if self.sparse else None)\n    return sparse.csr_matrix((data, indices, indptr), shape=(n_samples, n_features))\n\n", "CodeBleu_score": 21.038233296241156}]}
{"instance_id": "fcde391a8972", "generation_result": [{"code": "def convert_to_sklearn(self)\n\t\n    if self.log:\n        return loguniform(self.lower, self.upper)\n    else:\n        return uniform(self.lower, self.upper)", "CodeBleu_score": 23.057045198751105}, {"code": "def convert_to_sklearn(self)\n\t\n    if self.log:\n        return loguniform(self.lower, self.upper)\n    else:\n        return uniform(self.lower, self.upper)", "CodeBleu_score": 23.057045198751105}, {"code": "def convert_to_sklearn(self)\n\t\n    if self.log:\n        return loguniform(self.lower, self.upper)\n    else:\n        return uniform(self.lower, self.upper)", "CodeBleu_score": 23.057045198751105}]}
{"instance_id": "5d5413adcca6", "generation_result": [{"code": "def _render(self, state: AnalysisState) -> None\n\t\n    additional_args = self._get_args(state)\n    fig_args = self._get_fig_args(state)\n    features = self._get_features(state)\n    if self.headers:\n        self.render_header_if_needed(state, self.headers)\n    fig, axs = plt.subplots(len(features), len(features), **fig_args)\n    axs = axs.ravel()\n    if self.two_way_interaction:\n        data = state.data[features].dropna()\n        features = data.columns\n    else:\n        data = state.data[features]\n    kwargs = {**additional_args, **self.kwargs}\n    for i, feature in enumerate(features):\n        pdp = PartialDependenceDisplay.from_estimator(\n            state.model,\n            data,\n            features=features,\n            kind=self.kind,\n            ax=axs[i],\n            **kwargs,\n        )\n    plt.tight_layout()\n    plt.show()\n\n", "CodeBleu_score": 46.98950675272389}, {"code": "def _render(self, state: AnalysisState) -> None\n\t\n    additional_args = state.derived_state.partial_dependence_state.args\n    figure_args = state.derived_state.partial_dependence_state.figure_args\n    features = state.derived_state.partial_dependence_state.features\n    self.render_header_if_needed()\n    fig, axs = plt.subplots(\n        len(features),\n        len(features),\n        **figure_args,\n    )\n    if len(features) == 1:\n        axs = [axs]\n    for i, feature in enumerate(features):\n        for j, feature2 in enumerate(features):\n            if i > j:\n                continue\n            if state.derived_state.partial_dependence_state.two_way_interaction:\n                data = state.derived_state.partial_dependence_state.data.dropna(\n                    subset=[feature, feature2]\n                )\n            else:\n                data = state.derived_state.partial_dependence_state.data\n            kwargs = self._get_args(additional_args, feature, feature2)\n            PartialDependenceDisplay.from_estimator(\n                state.derived_state.partial_dependence_state.model,\n                data,\n                features=[feature, feature2],\n                ax=axs[i, j],\n                **kwargs,\n            )\n    plt.tight_layout()\n    plt.show()\n\n", "CodeBleu_score": 33.381537219401125}, {"code": "def _render(self, state: AnalysisState) -> None\n\t\n    args = self._get_args(state)\n    figargs = args.get(\"figargs\", {})\n    features = args.get(\"features\", [])\n    if len(features) == 0:\n        return\n    if self.render_header_if_needed(state):\n        self.render_header(state)\n    fig, axs = plt.subplots(\n        len(features),\n        len(features),\n        squeeze=False,\n        figsize=(10, 8),\n        **figargs,\n    )\n    axs = axs.ravel()\n    kwargs = {**args, **self._predefined_kwargs}\n    if args.get(\"twoway\", False):\n        data = state.data.copy()\n        data = data[data.notna().all(axis=1)]\n    for i, feature in enumerate(features):\n        kwargs[\"features\"] = [feature]\n        kwargs[\"ax\"] = axs[i]\n        PartialDependenceDisplay.from_estimator(\n            state.model,\n            data,\n            **kwargs,\n        )\n    plt.tight_layout()\n    plt.show()", "CodeBleu_score": 44.09706588297595}]}
{"instance_id": "db8aac29180b", "generation_result": [{"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self.feature_generator is None:\n        self.feature_generator = LabelEncoderFeatureGenerator(verbose=0)\n        self.feature_generator.fit(X)\n    if self.feature_generator.identified_features:\n        X = X.copy()\n        X[self.feature_generator.identified_features] = self.feature_generator.transform(\n            X[self.feature_generator.identified_features]\n        )\n    X = X.fillna(0)\n    return X.to_numpy(dtype=\"float32\")", "CodeBleu_score": 46.531125076764354}, {"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self.feature_generator is None:\n        self.feature_generator = LabelEncoderFeatureGenerator(verbose=0)\n        self.feature_generator.fit(X)\n    if self.feature_generator.identified_features:\n        X = X.copy()\n        X[self.feature_generator.identified_features] = self.feature_generator.transform(X[self.feature_generator.identified_features])\n    X = X.fillna(0)\n    X = X.to_numpy(dtype=\"float32\")\n    return X", "CodeBleu_score": 48.44587220786292}, {"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self.feature_generator is None:\n        self.feature_generator = LabelEncoderFeatureGenerator(verbose=0)\n        self.feature_generator.fit(X)\n    if self.feature_generator.identified_features:\n        X = X.copy()\n        X[self.feature_generator.identified_features] = self.feature_generator.transform(X[self.feature_generator.identified_features])\n    X = X.fillna(0)\n    X = X.to_numpy(dtype=np.float32)\n    return X\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 50.2257411272087}]}
{"instance_id": "d4eb45e6d013", "generation_result": [{"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    model_params = self._get_model_params(**kwargs)\n    num_trees_per_estimator = self._get_num_trees_per_estimator(\n        model_params, X, **kwargs\n    )\n    min_num_estimators = max(40, num_trees_per_estimator)\n    if isinstance(self.search_space, dict):\n        min_num_estimators = max(min_num_estimators, len(self.search_space))\n    bytes_per_estimator = (\n        X.nbytes * 1.5 + 100000000\n    )  # 100000000 is the expected size of other objects, can be fine-tuned\n    expected_min_mem_usage = bytes_per_estimator * min_num_estimators\n    return expected_min_mem_usage", "CodeBleu_score": 36.77053361680373}, {"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    model_params = self._get_model_params(**kwargs)\n    num_trees_per_estimator = self._get_num_trees_per_estimator(X, **kwargs)\n    min_num_estimators = self.min_num_estimators\n    if len(self.search_space) > 0:\n        min_num_estimators = 40\n    if min_num_estimators > num_trees_per_estimator:\n        min_num_estimators = num_trees_per_estimator\n    bytes_per_estimator = self._get_bytes_per_estimator(X, model_params, num_trees_per_estimator)\n    if isinstance(X, pd.DataFrame):\n        bytes_per_estimator *= 2\n    expected_min_memory_usage = bytes_per_estimator * min_num_estimators\n    return expected_min_memory_usage\n\n", "CodeBleu_score": 34.87757038170506}, {"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    model_params = self._get_model_params(**kwargs)\n    num_trees_per_estimator = self._get_num_trees_per_estimator(model_params)\n    if num_trees_per_estimator is None:\n        num_estimators = 40\n    else:\n        num_estimators = len(num_trees_per_estimator)\n    if num_estimators < 40:\n        num_estimators = 40\n    if isinstance(self.search_space, dict):\n        num_estimators = max(num_estimators, 40)\n    bytes_per_estimator = (X.shape[0] * X.shape[1] * 8) / num_estimators\n    adjustment_factor = 1.5\n    expected_min_memory_usage = bytes_per_estimator * num_estimators * adjustment_factor\n    return expected_min_memory_usage", "CodeBleu_score": 40.841689474157874}]}
{"instance_id": "6923cb007f4c", "generation_result": [{"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n    # Create a Counter object from the n-gram frequency data\n    ngram_counter = Counter(ngram_freq)\n\n    # Identify the top n most common n-grams\n    top_ngrams = ngram_counter.most_common(vocab_size)\n\n    # Sort the names of the top n n-grams\n    sorted_ngrams = sorted(ngram for ngram, _ in top_ngrams)\n\n    # Create a new vocabulary dictionary with the top n n-grams\n    new_vocab = {ngram: idx for idx, ngram in enumerate(sorted_ngrams)}\n\n    # Update the vectorizer's vocabulary with the new vocabulary\n    vectorizer.vocabulary_ = new_vocab\n\n    return vectorizer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.84820130227579}, {"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n    ngram_counter = Counter(ngram_freq)\n    top_ngrams = [ngram for ngram, freq in ngram_counter.most_common(vocab_size)]\n    top_ngrams.sort()\n    vocab = {ngram: i for i, ngram in enumerate(top_ngrams)}\n    vectorizer.vocabulary_ = vocab\n    return vectorizer\n\n", "CodeBleu_score": 32.03089298109193}, {"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n    counter = Counter(ngram_freq)\n    top_ngrams = [ngram for ngram, freq in counter.most_common(vocab_size)]\n    top_ngrams.sort()\n    vocab = {ngram: i for i, ngram in enumerate(top_ngrams)}\n    vectorizer.vocabulary_ = vocab\n    return vectorizer\n\n", "CodeBleu_score": 33.33929039127168}]}
{"instance_id": "0e837b2d8088", "generation_result": [{"code": " def _select_continuous(self, df, features)\n\t\n    cont_features = []\n    skewed_features = []\n    skew_threshold = self.parameters[\"skew_threshold\"]\n    for feature in features:\n        skew = df[feature].skew()\n        if abs(skew) > skew_threshold:\n            skewed_features.append(feature)\n        else:\n            cont_features.append(feature)\n    return {\"continuous\": cont_features, \"skewed\": skewed_features}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 34.86733123856303}, {"code": " def _select_continuous(self, df, features)\n\t\n    features_to_select = {}\n    skewness_threshold = self.parameters[\"skewness_threshold\"]\n\n    for feature in features:\n        skewness = df[feature].skew()\n        if abs(skewness) > skewness_threshold:\n            features_to_select[\"skewed\"] = features_to_select.get(\"skewed\", []) + [\n                feature\n            ]\n        else:\n            features_to_select[\"continuous\"] = features_to_select.get(\n                \"continuous\", []\n            ) + [feature]\n    return features_to_select\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.02058252966712}, {"code": " def _select_continuous(self, df, features)\n\t\n    features_dict = defaultdict(list)\n    skew_threshold = self.parameters[\"skew_threshold\"]\n\n    for col in features:\n        skew = df[col].skew()\n        if np.abs(skew) > skew_threshold:\n            features_dict[\"skewed\"].append(col)\n        else:\n            features_dict[\"continuous\"].append(col)\n\n    return features_dict\n\n\n", "CodeBleu_score": 34.1772775223301}]}
{"instance_id": "bb569c10f975", "generation_result": [{"code": "def _get_weights(dist, weights):\n\t\n\n", "CodeBleu_score": 0.45454545454545453}, {"code": "def _get_weights(dist, weights):\n\t\n    if weights is None or weights == 'uniform':\n        return None\n    if weights == 'distance':\n        weights = np.ma.masked_array(dist, np.isinf(dist))\n        weights = 1. / weights\n    elif callable(weights):\n        weights = weights(dist)\n    else:\n        raise ValueError(\"weights not recognized: should be \"\n                         \"'uniform', 'distance', or a callable function\")\n    return weights\n\n", "CodeBleu_score": 47.56686782168676}, {"code": "def _get_weights(dist, weights):\n\t\n\n", "CodeBleu_score": 0.45454545454545453}]}
{"instance_id": "12aaa9c78402", "generation_result": [{"code": "def predict_loo(self)\n\t\n    distances, indices = self.kneighbors()\n    weights = self._get_weights(distances)\n    _y = self.y.reshape(-1, 1) if len(self.y.shape) == 1 else self.y\n    pred = np.empty((self.n, self.k))\n    for i in range(self.n):\n        if self.weights == \"uniform\":\n            pred[i] = np.mean(_y[indices[i]], axis=0)\n        else:\n            pred[i] = np.sum(_y[indices[i]] * weights[i], axis=0) / np.sum(weights[i])\n    return pred.ravel() if len(_y.shape) == 1 else pred", "CodeBleu_score": 28.2725324519235}, {"code": "def predict_loo(self)\n\t\n    distances, indices = self.kneighbors()\n    weights = self._get_weights(distances)\n    _y = self.y.reshape(-1, 1) if len(self.y.shape) == 1 else self.y\n    preds = np.empty((self.n, self.k))\n    for i in range(self.n):\n        if self.weights == \"uniform\":\n            preds[i, :] = np.mean(_y[indices[i, :]], axis=0)\n        else:\n            preds[i, :] = np.sum(_y[indices[i, :]] * weights[i, :], axis=0) / np.sum(weights[i, :])\n    return preds.flatten() if len(self.y.shape) == 1 else preds", "CodeBleu_score": 28.688857327778877}, {"code": "def predict_loo(self)\n\t\n    distances, indices = self.kneighbors()\n    weights = self._get_weights(distances)\n    if len(_y.shape) == 1:\n        _y = _y.reshape(-1, 1)\n    predictions = np.empty(_y.shape)\n    for i in range(_y.shape[0]):\n        if self.weights:\n            predictions[i] = np.sum(\n                _y[indices[i]] * weights[i], axis=0) / np.sum(weights[i])\n        else:\n            predictions[i] = np.mean(_y[indices[i]], axis=0)\n    if len(_y.shape) == 1:\n        predictions = predictions.flatten()\n    return predictions", "CodeBleu_score": 37.18792884985625}]}
{"instance_id": "b316687d9e9b", "generation_result": [{"code": "def isotonic(input_data, quantile_list)\n\t\n    quantile_list = np.array(quantile_list).reshape(-1)\n    batch_size = input_data.shape[0]\n    new_output_data = []\n    for i in range(batch_size):\n        fit_transform = IsotonicRegression(\n            out_of_bounds=\"clip\").fit_transform(quantile_list, input_data[i, :])\n        new_output_data.append(fit_transform)\n    return np.stack(new_output_data)", "CodeBleu_score": 45.35765398564474}, {"code": "def isotonic(input_data, quantile_list)\n\t\n    quantile_list = np.array(quantile_list).reshape(-1)\n    batch_size = input_data.shape[0]\n    new_output_data = []\n    for i in range(batch_size):\n        data = input_data[i]\n        data = data.reshape(-1)\n        ir = IsotonicRegression(out_of_bounds=\"clip\")\n        y_ = ir.fit_transform(quantile_list, data)\n        new_output_data.append(y_)\n    new_output_data = np.stack(new_output_data)\n    return new_output_data\n\n", "CodeBleu_score": 45.527909549872916}, {"code": "def isotonic(input_data, quantile_list)\n\t\n    quantile_list = np.array(quantile_list).reshape(-1)\n    batch_size = input_data.shape[0]\n    new_output_data = []\n    for i in range(batch_size):\n        fit_transform = IsotonicRegression(\n            quantile_list, y_min=0.0, y_max=1.0, increasing=True\n        ).fit_transform\n        new_output_data.append(fit_transform(input_data[i, :]))\n    return np.stack(new_output_data)\n\n", "CodeBleu_score": 44.697110402173415}]}
{"instance_id": "17566e088b4e", "generation_result": [{"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer.fit(text_data)\n    vectorizer.stop_words_ = None\n    vectorized_text = vectorizer.transform(text_data)\n    return vectorizer, vectorized_text", "CodeBleu_score": 45.22807051565422}, {"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer.fit(text_data)\n    vectorizer.stop_words_ = None\n    return vectorizer, vectorizer.transform(text_data)\n\n", "CodeBleu_score": 40.6826747095547}, {"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer.fit(text_data)\n    vectorizer.stop_words_ = None\n    vectorized_data = vectorizer.transform(text_data)\n    return vectorizer, vectorized_data\n\n", "CodeBleu_score": 45.25213029105295}]}
{"instance_id": "be23c0afc2d6", "generation_result": [{"code": "def preprocess(df, test_size, shuffle)\n\t\n    df = df[~df.eq(\"--\").any(axis=1)]\n    df = df.drop(columns=[col for col, n_unique in df.nunique().items() if n_unique <= 1 or \"id\" in col])\n    df = df.drop(columns=[col for col in df.columns if col.endswith(\"_short\")])\n    return train_test_split(df, test_size=test_size, shuffle=shuffle)\n\n", "CodeBleu_score": 28.59029097010946}, {"code": "def preprocess(df, test_size, shuffle)\n\t\n    # Remove rows with missing entries\n    df = df[df.iloc[:, 1] != \"--\"]\n    # Drop columns with unique values less than or equal to 1\n    n_unique = df.nunique()\n    cols_to_drop = [col for col, count in n_unique.items() if count <= 1 or \"id\" in col]\n    df = df.drop(cols_to_drop, axis=1)\n    # Remove shortcut columns\n    df = df.drop([\"days_to_death\", \"year_of_death\"], axis=1)\n    # Split the data into training and testing sets\n    train, test = train_test_split(df, test_size=test_size, shuffle=shuffle)\n    return train, test\n\n", "CodeBleu_score": 31.54658109365849}, {"code": "def preprocess(df, test_size, shuffle)\n\t\n    # Remove rows with missing entries marked by \"--\"\n    df = df[df.ne('--').all(axis=1)]\n\n    # Drop columns with unique values less than or equal to one\n    n_unique = df.nunique().items()\n    df = df.drop(columns=[col for col, count in n_unique if count <= 1])\n\n    # Drop columns with \"id\" in their name\n    df = df.drop(columns=[col for col in df.columns if 'id' in col])\n\n    # Drop shortcut columns like \"days_to_death\" and \"year_of_death\"\n    df = df.drop(columns=['days_to_death', 'year_of_death'])\n\n    # Split the data into training and testing sets\n    train_df, test_df = train_test_split(df, test_size=test_size, shuffle=shuffle)\n\n    return train_df, test_df\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 32.910298074461814}]}
{"instance_id": "6a82997a8c59", "generation_result": [{"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n    X_train, Y_train, X_test, Y_test = get_dataset(\n        dataset=dataset, make_sparse=sparse, return_categorical=False\n    )\n    cs = classifier.get_hyperparameter_search_space()\n    default_config = cs.get_default_configuration()\n    classifier = classifier(\n        random_state=1,\n        **{hp_name: default_config[hp_name] for hp_name in default_config},\n    )\n\n    classifier.iterative_fit(\n        X_train, Y_train, n_iter=2, refit=True, random_state=1\n    )\n\n    n_iter = 2\n    while not classifier.configuration_fully_fitted:\n        n_iter *= 2\n        classifier.iterative_fit(\n            X_train, Y_train, n_iter=n_iter, refit=False, random_state=1\n        )\n\n    predictions = classifier.predict(X_test)\n    return predictions, Y_test, classifier\n\n", "CodeBleu_score": 39.40520745830941}, {"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n    X_train, Y_train, X_test, Y_test = get_dataset(dataset, sparse=sparse)\n    cs = classifier.get_hyperparameter_search_space()\n    default = cs.get_default_configuration()\n\n    classifier = classifier(\n        configuration=default,\n        random_state=1,\n    )\n\n    classifier.iterative_fit(X_train, Y_train, n_iter=2, refit=True)\n    n_iter = 2\n    while not classifier.configuration_fully_fitted():\n        classifier.iterative_fit(X_train, Y_train, n_iter=n_iter, refit=False)\n        n_iter *= 2\n\n    Y_pred = classifier.predict(X_test)\n    return Y_pred, Y_test, classifier", "CodeBleu_score": 39.650243284761856}, {"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n    X_train, Y_train, X_test, Y_test = get_dataset(dataset, sparse=sparse)\n    cs = classifier.get_hyperparameter_search_space()\n    default_config = cs.get_default_configuration()\n    classifier = classifier(configuration=default_config, random_state=1)\n    classifier.iterative_fit(X_train, Y_train, n_iter=2, refit=True)\n    for i in range(3, 11):\n        classifier.iterative_fit(X_train, Y_train, n_iter=2 ** i, refit=False)\n        assert classifier.configuration_fully_fitted()\n    predictions = classifier.predict(X_test)\n    return predictions, Y_test, classifier\n\n", "CodeBleu_score": 39.201015540371245}]}
{"instance_id": "d0d8450c4c17", "generation_result": [{"code": "def _load_models(self)\n\t\n    if self.ensemble_class:\n        self.ensemble = load_ensemble(\n            self.ensemble_class, self.backend, self.seed)\n\n    if not self.ensemble and self.evaluator.output_condition and self.resampling_strategy:\n        self.ensemble = self._load_best_individual_model()\n\n    if self.ensemble:\n        model_identifiers = get_selected_model_identifiers(\n            self.ensemble, self.evaluator.output_condition)\n\n        self.models = load_models_by_identifiers(\n            model_identifiers, self.backend, self.seed)\n\n        if self.resampling_strategy in ['cv', 'partial_cv']:\n            self.cv_models = load_cv_models_by_identifiers(\n                model_identifiers, self.backend, self.seed)\n        else:\n            self.cv_models = None\n    else:\n        self.models = []\n        self.cv_models = None", "CodeBleu_score": 41.18256485061839}, {"code": "def _load_models(self)\n\t\n    if self.ensemble_class is not None:\n        self.ensemble = load_ensemble(self.ensemble_class, self.backend, self.seed)\n        self.model_identifiers = self.ensemble.get_selected_model_identifiers()\n        self.models = load_models_by_identifiers(self.model_identifiers, self.backend)\n    else:\n        if self.evaluator_output_condition is not None and self.resampling_strategy is not None:\n            self.ensemble = self._load_best_individual_model()\n            self.model_identifiers = self.ensemble.get_selected_model_identifiers()\n            self.models = load_models_by_identifiers(self.model_identifiers, self.backend)\n        else:\n            self.ensemble = None\n            self.model_identifiers = []\n            self.models = []\n\n    if self.resampling_strategy == \"cv\":\n        self.cv_models = load_cv_models_by_identifiers(self.model_identifiers, self.backend)\n    else:\n        self.cv_models = None\n\n    if self.ensemble is None:\n        self.models = []\n        self.cv_models = []\n\n", "CodeBleu_score": 42.28818687864411}, {"code": "def _load_models(self)\n\t\n    if self.ensemble_class is not None:\n        self.ensemble = load_ensemble(\n            self.ensemble_class, self.backend, self.seed\n        )\n        self.model_identifiers = self.ensemble.get_model_identifiers()\n        self.models = load_models_by_identifiers(\n            self.model_identifiers, self.backend, self.seed\n        )\n        self.cv_models = None\n    else:\n        if (\n            self.evaluator.output_condition is not None\n            and self.evaluator.output_condition.resampling_strategy\n            not in [\n                ResamplingStrategyEnum.CV,\n                ResamplingStrategyEnum.CV_SPLIT,\n                ResamplingStrategyEnum.BOOTSTRAP,\n            ]\n        ):\n            self._load_best_individual_model()\n        self.model_identifiers = get_selected_model_identifiers(\n            self.evaluator\n        )\n        self.models = load_models_by_identifiers(\n            self.model_identifiers, self.backend, self.seed\n        )\n        if (\n            self.evaluator.output_condition is not None\n            and self.evaluator.output_condition.resampling_strategy\n            in [\n                ResamplingStrategyEnum.CV,\n                ResamplingStrategyEnum.CV_SPLIT,\n                ResamplingStrategyEnum.BOOTSTRAP,\n            ]\n        ):\n            self.cv_models = load_cv_models_by_identifiers(\n                self.model_identifiers, self.backend, self.seed\n            )\n        else:\n            self.cv_models = None\n\n    if self.ensemble is None:\n        self.models = []\n        self.cv_models = []\n\n", "CodeBleu_score": 38.61218774383139}]}
{"instance_id": "ef71b1cddb50", "generation_result": [{"code": "def load_task(task_id)\n\t\n    task = openml.tasks.get_task(task_id)\n    X, y = task.get_X_and_y()\n    train_indices, test_indices = task.get_train_test_split_indices()\n    dataset = task.get_dataset()\n    _, categorical = dataset.get_data(\n        target=dataset.default_target_attribute\n    )\n    X_train = X[train_indices]\n    y_train = y[train_indices]\n    X_test = X[test_indices]\n    y_test = y[test_indices]\n    is_categorical = [\n        feat.data_type == \"categorical\" for feat in dataset.features\n    ]\n    y_train = np.array([int(y) for y in y_train])\n    y_test = np.array([int(y) for y in y_test])\n    for feat_idx in range(len(is_categorical)):\n        if is_categorical[feat_idx]:\n            unique_values = np.unique(\n                np.concatenate(\n                    (X_train[:, feat_idx], X_test[:, feat_idx])\n                )\n            )\n            map_dict = dict(\n                zip(unique_values, range(len(unique_values)))\n            )\n            X_train[:, feat_idx] = np.array(\n                [map_dict[x] for x in X_train[:, feat_idx]]\n            )\n            X_test[:, feat_idx] = np.array(\n                [map_dict[x] for x in X_test[:, feat_idx]]\n            )\n    return X_train, y_train, X_test, y_test, is_categorical\n\n", "CodeBleu_score": 40.18291411551479}, {"code": "def load_task(task_id)\n\t\n    task = openml.tasks.get_task(task_id)\n    X, y = task.get_X_and_y()\n    train_indices, test_indices = task.get_train_test_split_indices()\n    dataset = task.get_dataset()\n    _, categorical = dataset.get_data(\n        target=dataset.default_target_attribute, dataset_format=\"dataframe\"\n    )\n    for i in range(len(categorical)):\n        categorical[i] = categorical[i].astype(int)\n    X_train = X.iloc[train_indices]\n    y_train = y.iloc[train_indices]\n    X_test = X.iloc[test_indices]\n    y_test = y.iloc[test_indices]\n    label_map = dict(\n        (label, idx) for idx, label in enumerate(np.unique(y_train))\n    )\n    y_train = np.array([label_map[y] for y in y_train])\n    y_test = np.array([label_map[y] for y in y_test])\n    feature_types = []\n    for i in range(X.shape[1]):\n        if categorical[i]:\n            feature_types.append(\"categorical\")\n        else:\n            feature_types.append(\"numerical\")\n    return X_train, y_train, X_test, y_test, feature_types\n\n", "CodeBleu_score": 44.03412894818787}, {"code": "def load_task(task_id)\n\t\n    task = openml.tasks.get_task(task_id)\n    dataset = openml.datasets.get_dataset(task.dataset_id)\n    X, y, categorical_indicator, attribute_names = dataset.get_data(\n        dataset_format=\"array\", target=dataset.default_target_attribute\n    )\n    train_indices, test_indices = task.get_train_test_split_indices()\n    X_train = X[train_indices]\n    y_train = y[train_indices]\n    X_test = X[test_indices]\n    y_test = y[test_indices]\n    categorical_indicator = list(map(lambda x: True if x == \"nominal\" else False, categorical_indicator))\n    return X_train, y_train, X_test, y_test, categorical_indicator\n\n", "CodeBleu_score": 28.63183677552427}]}
{"instance_id": "90bd6edbcc9e", "generation_result": [{"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if isinstance(y, pd.DataFrame):\n        return y.to_numpy()\n    elif isinstance(y, pd.Series):\n        return y.to_numpy()\n    elif isinstance(y, np.ndarray):\n        return y\n    elif isinstance(y, list):\n        return y\n    elif isinstance(y, pd.SparseDataFrame):\n        return y.to_dense().to_numpy()\n    elif isinstance(y, pd.SparseSeries):\n        return y.to_dense().to_numpy()\n    elif isinstance(y, pd.SparseArray):\n        return y.to_dense().to_numpy()\n    elif isinstance(y, pd.SparseDtype):\n        return y.to_dense().to_numpy()\n    elif isinstance(y, pd.SparseArray):\n        return y.to_dense().to_numpy()\n    elif isinstance(y, pd.SparseDtype):\n        return y.to_dense().to_numpy()\n    elif isinstance(y, pd.SparseArray):\n        return y.to_dense().to_numpy()\n    elif isinstance(y, pd.SparseDtype):\n        return y.to_dense().to_numpy()\n    elif isinstance(y, pd.SparseArray):\n        return y.to_dense().to_numpy()\n    elif isinstance(y, pd.SparseDtype):\n        return y.to_dense().to_numpy()\n    elif isinstance(y, pd.SparseArray):\n        return y.to_dense().to_numpy()\n    elif isinstance(y, pd.SparseDtype):\n        return y.to_dense().to_numpy()\n    elif isinstance(y, pd.SparseArray):\n        return y.to_dense().to_numpy()\n    elif isinstance(y, pd.SparseDtype):\n        return y.to_", "CodeBleu_score": 35.29556971823072}, {"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if isinstance(y, SUPPORTED_SPARSE_TARGET_TYPES):\n        y = y.toarray()\n        if y.shape[1] == 1:\n            y = y.flatten()\n        elif y.shape[1] == 2:\n            y = pd.DataFrame(y)\n        else:\n            y = pd.DataFrame(y)\n    return y", "CodeBleu_score": 55.85554293749308}, {"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if isinstance(y, pd.DataFrame):\n        return y.values\n    elif isinstance(y, pd.Series):\n        return y.values\n    elif isinstance(y, np.ndarray):\n        return y\n    elif isinstance(y, list):\n        return y\n    elif isinstance(y, pd.DataFrame):\n        return y.values\n    elif isinstance(y, pd.Series):\n        return y.values\n    elif isinstance(y, np.ndarray):\n        return y\n    elif isinstance(y, list):\n        return y\n    elif isinstance(y, pd.DataFrame):\n        return y.values\n    elif isinstance(y, pd.Series):\n        return y.values\n    elif isinstance(y, np.ndarray):\n        return y\n    elif isinstance(y, list):\n        return y\n    elif isinstance(y, pd.DataFrame):\n        return y.values\n    elif isinstance(y, pd.Series):\n        return y.values\n    elif isinstance(y, np.ndarray):\n        return y\n    elif isinstance(y, list):\n        return y\n    elif isinstance(y, pd.DataFrame):\n        return y.values\n    elif isinstance(y, pd.Series):\n        return y.values\n    elif isinstance(y, np.ndarray):\n        return y\n    elif isinstance(y, list):\n        return y\n    elif isinstance(y, pd.DataFrame):\n        return y.values\n    elif isinstance(y, pd.Series):\n        return y.values\n    elif isinstance(y, np.ndarray):\n        return y\n    elif isinstance(y, list):\n        return y\n    elif isinstance(y, pd.DataFrame):\n        return y.values\n    elif isinstance(y, pd.Series):\n        return y.values\n    elif isinstance(y, np.ndarray):\n        return y\n    elif isinstance(y, list):\n        return y\n    elif isinstance(y, pd.DataFrame):\n        return y.values\n   ", "CodeBleu_score": 34.24816818608014}]}
{"instance_id": "5728e3d4f914", "generation_result": [{"code": "def _calculate_weights(self) -> None\n\t\n    counts = np.sum(self.ensemble_members, axis=0)\n    self.weights_ = np.zeros(self.n_models_)\n    for i in range(self.n_models_):\n        self.weights_[i] = counts[i] / self.n_models_\n    if np.sum(self.weights_) < 1:\n        self.weights_ = self.weights_ / np.sum(self.weights_)\n\n", "CodeBleu_score": 23.05409539074357}, {"code": "def _calculate_weights(self) -> None\n\t\n    counts = np.sum(self.ensemble_members, axis=0)\n    self.weights_ = np.zeros(self.n_models_)\n    for i in range(self.n_models_):\n        self.weights_[i] = counts[i] / self.n_models_\n    if np.sum(self.weights_) < 1:\n        self.weights_ = self.weights_ / np.sum(self.weights_)\n\n", "CodeBleu_score": 23.05409539074357}, {"code": "def _calculate_weights(self) -> None\n\t\n    counts = np.sum(self.ensemble_members, axis=0)\n    self.weights_ = np.zeros(self.n_models)\n    for i, count in enumerate(counts):\n        self.weights_[i] = count / self.n_models\n    if np.sum(self.weights_) < 1:\n        self.weights_ = self.weights_ / np.sum(self.weights_)\n\n", "CodeBleu_score": 22.50345651979542}]}
{"instance_id": "4f9c4799fd8f", "generation_result": [{"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\t\n    y_proba = super().predict_proba(X, batch_size=batch_size, n_jobs=n_jobs)\n    if self.target_type_ != \"multilabel-indicator\":\n        assert np.allclose(np.sum(y_proba, axis=1), 1)\n    assert np.all((0 <= y_proba) & (y_proba <= 1))\n    return y_proba\n\n", "CodeBleu_score": 31.539810435392635}, {"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\t\n    proba = super().predict_proba(X, batch_size, n_jobs)\n    if self.target_type_ != \"multilabel-indicator\":\n        assert np.allclose(np.sum(proba, axis=1), 1)\n    assert np.all((0 <= proba) & (proba <= 1))\n    return proba\n\n", "CodeBleu_score": 27.75056117428513}, {"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\t\n    probas = super(OneVsRestClassifier, self).predict_proba(X, batch_size=batch_size, n_jobs=n_jobs)\n    if self.target_type_ == \"multilabel-indicator\":\n        return probas\n    assert np.allclose(np.sum(probas, axis=1), np.ones_like(probas[:, 0]))\n    assert np.all((0 <= probas) & (probas <= 1))\n    return probas\n\n", "CodeBleu_score": 35.850995774109705}]}
{"instance_id": "a9a13150aebe", "generation_result": [{"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if Ybin.ndim == 1:\n        Y = Ybin\n    else:\n        Y = np.dot(Ybin, range(Ybin.shape[1]))\n    return Y\n\n", "CodeBleu_score": 53.1489387646343}, {"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if Ybin.ndim == 1:\n        return Ybin\n    else:\n        return np.dot(Ybin, range(Ybin.shape[1]))\n\n", "CodeBleu_score": 32.043052488809614}, {"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if Ybin.ndim == 1:\n        Ybin = Ybin[:, None]\n    return Ybin.dot(range(Ybin.shape[1]))\n\n", "CodeBleu_score": 29.651857759024523}]}
{"instance_id": "e97d38e62f81", "generation_result": [{"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n    if fit_params is None:\n        fit_params = {}\n    if self.config.balancing_strategy == \"weighting\":\n        balancing = Balancing(X, y, self.config.classifier, self.config.feature_preprocessor)\n        fit_params.update(balancing.get_weights())\n    self._init_params.update(self.config.hyperparameters)\n    self.set_hyperparameters()\n    return super().fit_transformer(X, y, fit_params)", "CodeBleu_score": 35.10607647622384}, {"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n\n    if fit_params is None:\n        fit_params = {}\n\n    if self.config[\"balancing_strategy\"] == \"weighting\":\n        balancing = Balancing(self.config, self.init_params)\n        fit_params.update(balancing.get_weights(X, y))\n\n    self.init_params.update(self.config)\n    self.set_hyperparameters(self.config, self.init_params)\n    fit_params.update(self.init_params)\n\n    return super().fit_transformer(X, y, fit_params)\n\n", "CodeBleu_score": 37.37386722282706}, {"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n    if fit_params is None:\n        fit_params = {}\n    if self.config[\"balancing\"][\"strategy\"] == \"weighting\":\n        balancing = Balancing(self.config, self.init_params)\n        fit_params[\"classifier__class_weight\"] = balancing.get_weights(\n            y, \"classifier\"\n        )\n        fit_params[\"feature_preprocessor__class_weight\"] = balancing.get_weights(\n            y, \"feature_preprocessor\"\n        )\n    self.set_hyperparameters()\n    self.init_params.update(self.hyperparameters)\n    fit_params.update(self._init_params)\n    return super().fit_transformer(X, y, fit_params)\n\n", "CodeBleu_score": 45.16165890416023}]}
{"instance_id": "b1aaad80a9c4", "generation_result": [{"code": "def test_glm_identity_link_func()\n\t\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([1, 2, 3])\n    model = utils.StatsmodelsSklearnLikeWrapper(\n        assembler.assemble(\n            assemblers.StatsmodelsModelAssemblerSelector(\n                Tweedie(var_power=1),\n                Power(1),\n            ),\n        ),\n    )\n    model.fit(X, y)\n    utils.cmp_exprs(\n        model.assembler_.assemble(model.model_),\n        ast.BinNumExpr(\n            ast.NumVal(0.0),\n            ast.BinNumExpr(\n                ast.NumVal(0.0),\n                ast.BinNumExpr(\n                    ast.NumVal(0.0),\n                    ast.FeatureRef(0),\n                    ast.FeatureRef(1),\n                ),\n                ast.BinNumExpr(\n                    ast.NumVal(0.0),\n                    ast.FeatureRef(0),\n                    ast.FeatureRef(0),\n                ),\n            ),\n            ast.BinNumExpr(\n                ast.NumVal(0.0),\n                ast.BinNumExpr(\n                    ast.NumVal(0.0),\n                    ast.FeatureRef(1),\n                    ast.FeatureRef(1),\n                ),\n                ast.BinNumExpr(\n                    ast.NumVal(0.0),\n                    ast.FeatureRef(1),\n                    ast.FeatureRef(0),\n                ),\n            ),\n        ),\n    )\n\n", "CodeBleu_score": 21.041425786299477}, {"code": "def test_glm_identity_link_func()\n\t\n    # Create a small dataset\n    data = {\n        \"x1\": [1, 2, 3, 4, 5],\n        \"x2\": [2, 3, 4, 5, 6],\n        \"y\": [5, 7, 9, 11, 13],\n    }\n    df = pd.DataFrame(data)\n\n    # Wrap the GLM from Statsmodels\n    glm_model = utils.StatsmodelsSklearnLikeWrapper(\n        sm.GLM, family=sm.families.Tweedie(link=sm.genmod.families.links.Power())\n    )\n\n    # Set up the GLM with a Tweedie family and Power(1) link\n    glm = glm_model(\n        formula=\"y ~ x1 + x2\", data=df, family=sm.families.Tweedie(link=sm.genmod.families.links.Power())\n    )\n\n    # Fit the model\n    glm.fit()\n\n    # Assemble the model into an expression\n    assembler = assemblers.StatsmodelsModelAssemblerSelector(glm)\n    expr = assembler.assemble()\n\n    # Compare the assembled expression to an expected expression\n    assert utils.cmp_exprs(\n        expr,\n        ast.BinNumExpr(\n            ast.BinNumExpr(\n                ast.BinNumExpr(\n                    ast.NumVal(0.0),\n                    ast.NumVal(0.0),\n                    ast.BinNumOpType.ADD,\n                ),\n                ast.BinNumExpr(\n                    ast.BinNumExpr(\n                        ast.FeatureRef(0),\n                        ast.NumVal(0.0),\n                        ast.BinNumOpType.ADD,\n                    ),\n                    ast.BinNumExpr(\n                        ast.BinNumExpr(\n                            ast.FeatureRef(1),\n                            ast.NumVal(0.0),\n                            ast.BinNumOpType.ADD,\n                        ),\n                        ast.NumVal(0.0),\n                        ast.B", "CodeBleu_score": 36.32872043810573}, {"code": "def test_glm_identity_link_func()\n\t\n    data = pd.DataFrame({\"x1\": [1, 2, 3, 4, 5], \"x2\": [2, 3, 4, 5, 6], \"y\": [2, 4, 5, 4, 5]})\n    glm_model = sm.GLM(data[\"y\"], data[[\"x1\", \"x2\"]], family=sm.families.Tweedie(var_power=1, link=sm.families.links.identity()))\n    glm_model_wrapper = utils.StatsmodelsSklearnLikeWrapper(glm_model)\n    glm_model_wrapper.fit(data[[\"x1\", \"x2\"]], data[\"y\"])\n    assembler = assemblers.StatsmodelsModelAssemblerSelector(glm_model_wrapper)\n    assembled_expr = assembler.assemble()\n    expected_expr = ast.BinNumExpr(\n        ast.BinNumExpr(\n            ast.FeatureRef(0),\n            ast.NumVal(2.0),\n            ast.BinNumOpType.MUL,\n        ),\n        ast.NumVal(0.0),\n        ast.BinNumOpType.ADD,\n    )\n    assert utils.cmp_exprs(assembled_expr, expected_expr)\n\n", "CodeBleu_score": 46.18954362293316}]}
{"instance_id": "bcab63e592d0", "generation_result": [{"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n    if isinstance(agg, tuple):\n        name, func = agg\n    else:\n        name = agg if isinstance(agg, str) else agg.__name__\n        func = agg\n\n    new_col = f\"{col}__{name}\"\n    return self.df.groupby(self.by)[col].agg(func).rename(new_col)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 63.124772749268274}, {"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n    if isinstance(agg, tuple):\n        agg_name, agg_func = agg\n    else:\n        agg_name = agg.__name__ if hasattr(agg, '__name__') else str(agg)\n        agg_func = agg\n\n    new_col_name = f'{col.name}_{agg_name}'\n    return self.groupby(col.name, group_keys=False).agg(agg_func).rename(columns={col.name: new_col_name})\n\n", "CodeBleu_score": 50.13006857014331}, {"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n\n    if isinstance(agg, tuple):\n        name, func = agg\n    else:\n        name = agg if isinstance(agg, str) else agg.__name__\n        func = agg\n\n    col_name = f\"{col.name}_{name}\"\n\n    if col_name in self.columns:\n        raise ValueError(f\"Column name '{col_name}' already exists.\")\n\n    return self.groupby(self.group_vars, dropna=False)[col.name].agg(func)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 61.33475830779496}]}
{"instance_id": "114d623dae7b", "generation_result": [{"code": "def _corrfunc(self, x, y, **kws)\n\t\n\n    # Get the hue groups\n    hue_groups = self.hue_groups if hasattr(self, 'hue_groups') else None\n    if hue_groups is None:\n        hue_groups = [None]\n\n    # Compute the correlation coefficient\n    r, p = stats.pearsonr(x, y)\n\n    # Adjust the font size based on the number of hue groups and the correlation value\n    fontsize = self.fontsize / (len(hue_groups) * abs(r))\n\n    # Get the appropriate axis\n    ax = plt.gca()\n\n    # Annotate the axis with the correlation coefficient, adjusting the position based on the hue group index\n    for i, hue_group in enumerate(hue_groups):\n        if hue_group is None:\n            hue_group = ''\n        else:\n            hue_group = f'{hue_group} '\n        ax.annotate(f'{hue_group}r = {r:.2f}', xy=(0.1, 0.9 - i * 0.05), xycoords='axes fraction', fontsize=fontsize, **kws)\n\n    # Return the correlation coefficient\n    return r\n\n\n", "CodeBleu_score": 23.917432069887706}, {"code": "def _corrfunc(self, x, y, **kws)\n\t\n\n    # Get the hue groups and number of groups\n    hue_groups = self.hue_vals\n    n_groups = len(hue_groups)\n\n    # Compute the correlation coefficient\n    r, _ = stats.pearsonr(x, y)\n\n    # Adjust the font size based on the number of hue groups and the correlation value\n    font_size = np.abs(r) / (1 + n_groups) + 0.1\n    font_size = min(font_size, 1)\n\n    # Get the appropriate axis\n    ax = plt.gca()\n\n    # Annotate the axis with the correlation coefficient\n    if \"label\" in kws:\n        label = kws[\"label\"]\n    else:\n        label = \"r = {:.2f}\".format(r)\n    hue_idx = list(hue_groups.keys()).index(label)\n    x_pos = -0.1 + 0.8 * (hue_idx) / (n_groups - 1)\n    y_pos = 1.1 / (n_groups)\n    ax.annotate(\n        label,\n        xy=(0.05, y_pos),\n        xycoords=ax.transAxes,\n        color=\"black\",\n        weight=\"bold\",\n        fontsize=font_size * 13,\n        ha=\"left\",\n        va=\"bottom\",\n    )\n\n    # Return the correlation coefficient\n    return r", "CodeBleu_score": 28.541882573241136}, {"code": "def _corrfunc(self, x, y, **kws)\n\t\n\n    # Check if x or y contains NaN values\n    if np.isnan(x).any() or np.isnan(y).any():\n        # If either x or y contains NaN values, return without annotating\n        return\n\n    # Check if hue is present in the kws dictionary\n    if 'hue' in kws.keys():\n        # If hue is present, extract the hue column from the kws dictionary\n        hue = kws['hue']\n\n        # Check if hue is a categorical variable\n        if hue.dtype.name == 'category':\n            # If hue is a categorical variable, compute the correlation coefficient for each hue group\n            for hue_level in hue.cat.categories:\n                # Extract the rows for the current hue group\n                x_hue = x[hue == hue_level]\n                y_hue = y[hue == hue_level]\n\n                # Compute the correlation coefficient between x_hue and y_hue\n                r, _ = stats.pearsonr(x_hue, y_hue)\n\n                # Annotate the correlation coefficient on the plot\n                self._annotate(r, x_hue, y_hue, kws, hue_level)\n        else:\n            # If hue is not a categorical variable, compute the correlation coefficient between x and y\n            r, _ = stats.pearsonr(x, y)\n\n            # Annotate the correlation coefficient on the plot\n            self._annotate(r, x, y, kws)\n    else:\n        # If hue is not present, compute the correlation coefficient between x and y\n        r, _ = stats.pearsonr(x, y)\n\n        # Annotate the correlation coefficient on the plot\n        self._annotate(r, x, y, kws)\n\n", "CodeBleu_score": 24.57532679007658}]}
{"instance_id": "4c1ade308953", "generation_result": [{"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n\t\n    if method == 'decimal':\n        return round(src, rounddigit)\n    elif method == 'sig':\n        with decimal.localcontext() as ctx:\n            ctx.prec = rounddigit\n            return ctx.create_decimal(src)\n    elif method == 'format':\n        return float(f'{src:.{rounddigit}g}')\n    else:\n        raise ValueError('Invalid method specified. Choose from \"decimal\", \"sig\", or \"format\".')\n\n", "CodeBleu_score": 76.24878795104063}, {"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n\t\n    if rounddigit is None:\n        rounddigit = 2\n    if method == 'decimal':\n        return round(src, rounddigit)\n    elif method == 'sig':\n        with decimal.localcontext() as ctx:\n            ctx.prec = rounddigit\n            return ctx.create_decimal(src)\n    elif method == 'format':\n        return format(src, f'.{rounddigit}g')\n    else:\n        raise ValueError(\"Invalid method. Choose 'decimal', 'sig', or 'format'.\")\n\n", "CodeBleu_score": 74.79721446468409}, {"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n\t\n    if method == 'decimal':\n        return round(src, rounddigit)\n    elif method == 'sig':\n        with decimal.localcontext() as ctx:\n            ctx.prec = rounddigit\n            return ctx.create_decimal(src)\n    elif method == 'format':\n        return float(f'{src:.{rounddigit}g}')\n    else:\n        raise ValueError(\"Invalid method. Choose from 'decimal', 'sig', or 'format'.\")\n\n", "CodeBleu_score": 76.74644151222753}]}
{"instance_id": "a9923e678320", "generation_result": [{"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n\t\n    if rounddigit is None:\n        return srcdict\n    newdict = {}\n    for k, v in srcdict.items():\n        if isinstance(v, float):\n            newdict[k] = cls._round_digits(v, rounddigit, method)\n        else:\n            newdict[k] = v\n    return newdict\n\n", "CodeBleu_score": 59.09752487141713}, {"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n\t\n    rounddigit = rounddigit if rounddigit is not None else cls._round_digits\n    if rounddigit is None:\n        return srcdict\n    if rounddigit == 0:\n        return srcdict\n    if method == 'decimal':\n        return {k: cls._round_digits(v, rounddigit) for k, v in srcdict.items()}\n    elif method == 'sig':\n        return {k: cls._round_digits_sig(v, rounddigit) for k, v in srcdict.items()}\n    elif method == 'format':\n        return {k: cls._round_digits_format(v, rounddigit) for k, v in srcdict.items()}\n    else:\n        raise ValueError(f\"Invalid method: {method}\")\n\n", "CodeBleu_score": 32.69778561928096}, {"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n\t\n    if rounddigit is None:\n        return srcdict\n    if method == 'decimal':\n        return {k: cls._round_digits(v, rounddigit) if isinstance(v, float) else v for k, v in srcdict.items()}\n    elif method == 'sig':\n        return {k: cls._round_digits(v, rounddigit) if isinstance(v, float) else v for k, v in srcdict.items()}\n    elif method == 'format':\n        return {k: cls._round_digits(v, rounddigit) if isinstance(v, float) else v for k, v in srcdict.items()}\n    else:\n        raise ValueError(f\"Invalid method: {method}. Supported methods are 'decimal', 'sig', and 'format'.\")\n\n", "CodeBleu_score": 30.809638378081743}]}
{"instance_id": "b6106e079dc0", "generation_result": [{"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    data = pd.DataFrame({x_name: x, y_name: y})\n    if hue_data is not None:\n        data[hue_name] = hue_data\n    sns.scatterplot(x=x_name, y=y_name, hue=hue_name, data=data, ax=ax, **scatter_kws)\n    if ax.get_legend() is not None:\n        if legend_kws.get(\"title\") is None:\n            ax.get_legend().set_title(hue_name)\n        ax.legend(**legend_kws)\n\n", "CodeBleu_score": 37.32346424259153}, {"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    if hue_data is not None:\n        df = pd.DataFrame(np.stack([x, y, hue_data], axis=1), columns=[x_name, y_name, hue_name])\n    else:\n        df = pd.DataFrame(np.stack([x, y], axis=1), columns=[x_name, y_name])\n    sns.scatterplot(data=df, x=x_name, y=y_name, hue=hue_name, ax=ax, **scatter_kws)\n    if legend_kws is not None:\n        if \"title\" not in legend_kws.keys():\n            legend_kws[\"title\"] = hue_name\n        ax.legend(**legend_kws)\n\n", "CodeBleu_score": 54.72394694651983}, {"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    df = pd.DataFrame(np.stack([x, y], axis=1), columns=[x_name, y_name])\n    if hue_data is not None:\n        df[hue_name] = hue_data\n    sns.scatterplot(data=df, x=x_name, y=y_name, hue=hue_name, ax=ax, **scatter_kws)\n    if not legend_kws.keys().__contains__(\"title\"):\n        legend_kws[\"title\"] = hue_name\n    ax.legend(**legend_kws)\n\n", "CodeBleu_score": 38.53469216109231}]}
{"instance_id": "257e0aa5dd4d", "generation_result": [{"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n    data = self._get_transformed_data()\n    exog = self._get_exogenous_data()\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning)\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        self.model = self.model_class(data, exog=exog, **fit_args)\n    return self\n\n", "CodeBleu_score": 43.328289510523696}, {"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n    self._get_transformed_data()\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning)\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        self.model = self.model.fit(\n            endog=self.endog, exog=self.exog, **fit_args\n        )\n    return self\n\n", "CodeBleu_score": 46.45181583900806}, {"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n    endog, exog = self._get_transformed_data()\n\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning)\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        self.model = self.model.fit(endog=endog, exog=exog, **fit_args)\n\n    return self\n\n", "CodeBleu_score": 48.263981438641025}]}
{"instance_id": "6446de2223e8", "generation_result": [{"code": "def create_model(self, **kwargs)\n\t\n    if self.model_type == \"holt_winters\":\n        data = self._get_transformed_data()\n        model = ExponentialSmoothing(\n            data,\n            trend=kwargs.get(\"trend\", \"add\"),\n            seasonal=kwargs.get(\"seasonal\", \"add\"),\n            seasonal_periods=kwargs.get(\"seasonal_periods\", 12),\n        )\n    elif self.model_type == \"auto_arima\":\n        try:\n            from pmdarima import AutoARIMA\n        except ImportError:\n            logger.error(\"pmdarima not installed. Run `pip install pmdarima`\")\n            exit()\n        data = self._get_transformed_data()\n        model = AutoARIMA(**kwargs)\n    elif self.model_type == \"sarimax\":\n        data = self._get_transformed_data()\n        exog = self.exog\n        if exog is not None:\n            model = SARIMAX(data, exog=exog, **kwargs)\n        else:\n            model = SARIMAX(data, **kwargs)\n    else:\n        raise Exception(\"Model type not recognized\")\n    return model\n\n", "CodeBleu_score": 50.51341796191375}, {"code": "def create_model(self, **kwargs)\n\t\n    if self.model_type == \"holt_winters\":\n        data = self._get_transformed_data()\n        return ExponentialSmoothing(\n            data,\n            trend=kwargs.get(\"trend\", \"add\"),\n            seasonal=kwargs.get(\"seasonal\", \"add\"),\n            seasonal_periods=kwargs.get(\"seasonal_periods\", 12),\n        )\n    elif self.model_type == \"auto_arima\":\n        try:\n            from pmdarima import AutoARIMA\n\n            data = self._get_transformed_data()\n            return AutoARIMA(**kwargs)\n        except ImportError:\n            logger.error(\"Please install pmdarima to use auto_arima model.\")\n            sys.exit(1)\n    elif self.model_type == \"sarimax\":\n        data = self._get_transformed_data()\n        exog = kwargs.get(\"exog\")\n        if exog is not None:\n            return SARIMAX(data, exog=exog, **kwargs)\n        else:\n            return SARIMAX(data, **kwargs)\n    else:\n        raise Exception(f\"Model type {self.model_type} not recognized.\")", "CodeBleu_score": 37.1684924076542}, {"code": "def create_model(self, **kwargs)\n\t\n    if self.model_type == \"holt_winters\":\n        data = self._get_transformed_data()\n        model = ExponentialSmoothing(\n            data,\n            trend=self.trend,\n            damped=self.damped,\n            seasonal=self.seasonal,\n            seasonal_periods=self.seasonal_periods,\n        )\n    elif self.model_type == \"auto_arima\":\n        try:\n            from pmdarima import AutoARIMA\n        except Exception:\n            logger.error(\"pmdarima not installed. Run `pip install pmdarima`\")\n            sys.exit()\n        data = self._get_transformed_data()\n        model = AutoARIMA(**kwargs)\n    elif self.model_type == \"sarimax\":\n        data = self._get_transformed_data()\n        exog = kwargs.get(\"exog\")\n        if exog is not None:\n            model = SARIMAX(data, exog=exog, **kwargs)\n        else:\n            model = SARIMAX(data, **kwargs)\n    else:\n        raise Exception(\"Model type not recognized\")\n    return model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 49.415924773303686}]}
{"instance_id": "b2f67820e27f", "generation_result": [{"code": "def _to_chx(array)\n\t\n    if isinstance(array, cupy.ndarray):\n        if cupy is None:\n            raise RuntimeError(\"CuPy is not available.\")\n        return _from_cupy(array)\n    elif isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    else:\n        return array\n\n", "CodeBleu_score": 64.8335625522476}, {"code": "def _to_chx(array)\n\t\n    if isinstance(array, chainerx.ndarray):\n        return array\n    elif isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    elif _cupy_available and isinstance(array, cupy.ndarray):\n        return _from_cupy(array)\n    else:\n        return array\n\n", "CodeBleu_score": 67.98893818782813}, {"code": "def _to_chx(array)\n\t\n    if isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    elif isinstance(array, cupy.ndarray):\n        return _from_cupy(array)\n    else:\n        return array\n\n", "CodeBleu_score": 75.22514168335545}]}
{"instance_id": "b96f7d9bcc95", "generation_result": [{"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if len(ys) > 0 and len(ys[0].shape) != len(x.shape):\n        split_sizes = np.array([y.shape[axis] for y in ys])\n        empty_shape = list(x.shape)\n        empty_shape[axis] = 0\n        empty = np.empty(empty_shape)\n        split_sizes = np.split(empty, indices_or_sections, axis)[1:]\n        ys = [y if y.shape[axis] == split_sizes[i].shape[axis] else y.reshape(split_sizes[i].shape) for i, y in enumerate(ys)]\n    return ys\n", "CodeBleu_score": 41.20272305230118}, {"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if len(ys) != len(indices_or_sections) + 1:\n        raise ValueError('ys must have one more element than indices_or_sections')\n    if len(ys) == 0:\n        raise ValueError('ys must not be empty')\n    if len(ys[0].shape) != len(x.shape):\n        split_sizes = np.array(indices_or_sections)\n        split_sizes[split_sizes < 0] += x.shape[axis]\n        split_sizes = np.sort(split_sizes)\n        split_sizes = np.concatenate([split_sizes, [x.shape[axis]]])\n        split_sizes = np.diff(split_sizes)\n        ys = np.split(np.empty(x.shape), split_sizes, axis=axis)\n    for y, y_split in zip(ys, np.split(x, indices_or_sections, axis=axis)):\n        if y.shape != y_split.shape:\n            y[:] = np.reshape(y_split, y.shape)\n    return ys", "CodeBleu_score": 33.736559143174524}, {"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if len(ys) == 1:\n        return ys\n    split_sizes = [y.shape[axis] for y in ys]\n    if len(ys) != len(indices_or_sections) and len(ys) != len(split_sizes):\n        # calculate expected shapes for the split segments\n        temp_split = np.split(np.empty(x.shape), indices_or_sections, axis)\n        expected_shapes = [y.shape[:axis] + (s,) + y.shape[axis + 1:] for y, s in zip(temp_split, split_sizes)]\n        # reshape segments if necessary\n        ys = [y.reshape(expected_shape) if y.shape != expected_shape else y for y, expected_shape in zip(ys, expected_shapes)]\n    return ys\n\n", "CodeBleu_score": 36.58632020844479}]}
{"instance_id": "cf39fb123842", "generation_result": [{"code": "def to_device_batch(batch):\n\t\n    if device is None:\n        return batch\n    elif device < 0:\n        return [chainer.dataset.to_device(device, x) for x in batch]\n    else:\n        xp = cp.get_array_module(batch[0])\n        concat = xp.concatenate(batch, axis=0)\n        sections = np.cumsum([len(x) for x in batch[:-1]], dtype=np.int32)\n        concat_dev = chainer.dataset.to_device(device, concat)\n        batch_dev = cp.split(concat_dev, sections)\n        return batch_dev\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 85.37397593848598}, {"code": "def to_device_batch(batch):\n\t\n    if device is None:\n        return batch\n    elif device < 0:\n        return [chainer.dataset.to_device(device, x) for x in batch]\n    else:\n        xp = chainer.cuda.get_array_module(*batch)\n        concat = xp.concatenate(batch, axis=0)\n        sections = numpy.cumsum([len(x)\n                                for x in batch[:-1]], dtype=numpy.int32)\n        concat_dev = chainer.dataset.to_device(device, concat)\n        batch_dev = xp.split(concat_dev, sections)\n        return batch_dev\n\n", "CodeBleu_score": 88.08080884134426}, {"code": "def to_device_batch(batch):\n\t\n    if device is None:\n        return batch\n    elif device < 0:\n        return [chainer.dataset.to_device(device, x) for x in batch]\n    else:\n        xp = cp.get_array_module(*batch)\n        concat = xp.concatenate(batch, axis=0)\n        sections = np.cumsum([len(x) for x in batch[:-1]], dtype=np.int32)\n        concat_dev = chainer.dataset.to_device(device, concat)\n        batch_dev = cp.split(concat_dev, sections)\n        return batch_dev\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 81.00649559935873}]}
{"instance_id": "845c744d897c", "generation_result": [{"code": "def make_image(trainer)\n\t\n    seed = trainer.updater.epoch\n    xp = gen.xp\n    z = Variable(xp.asarray(gen.make_hidden(16)))\n    with chainer.using_config('train', False):\n        x = gen(z)\n    x = chainer.cuda.to_cpu(x.data)\n    np.random.seed(seed)\n    x = np.asarray(np.clip(x * 255, 0.0, 255.0), dtype=np.uint8)\n    _, _, H, W = x.shape\n    x = x.reshape((16, 1, H, W))\n    x = x.transpose(0, 2, 3, 1)\n    preview_dir = '{}/preview'.format(args.out)\n    if not os.path.exists(preview_dir):\n        os.makedirs(preview_dir)\n    Image.fromarray(x).save(preview_dir +\n                            '/image_{:0>8}.png'.format(trainer.updater.iteration))\n\n", "CodeBleu_score": 54.76547830566967}, {"code": "def make_image(trainer)\n\t\n    seed = np.random.randint(100000)\n    print('seed:', seed)\n    np.random.seed(seed)\n    n_images = 10\n    xp = gen.xp\n    z = Variable(xp.asarray(gen.make_hidden(n_images)))\n    with chainer.using_config('train', False):\n        with chainer.using_config('enable_backprop', False):\n            x = gen(z)\n    x = chainer.cuda.to_cpu(x.data)\n    np.random.seed()\n    x = np.asarray(np.clip(x * 127.5 + 127.5, 0.0, 255.0), dtype=np.uint8)\n    _, _, H, W = x.shape\n    x = x.reshape((n_images, 1, H, W))\n    x = x.transpose(0, 2, 3, 1)\n    preview_dir = '{}/preview'.format(args.out)\n    preview_path = preview_dir + '/image{:0>8}.png'.format(trainer.updater.iteration)\n    if not os.path.exists(preview_dir):\n        os.makedirs(preview_dir)\n    Image.fromarray(x[0, :, :, :]).save(preview_path)\n\n", "CodeBleu_score": 65.49119954001901}, {"code": "def make_image(trainer)\n\t\n    seed = np.random.randint(1000000)\n    print('seed:', seed)\n    np.random.seed(seed)\n    n_images = 64\n    xp = gen.xp\n    z = Variable(xp.asarray(gen.make_hidden(n_images)))\n    with chainer.using_config('train', False):\n        x = gen(z)\n    x = chainer.cuda.to_cpu(x.data)\n    np.random.seed()\n    x = np.asarray(np.clip(x * 255, 0.0, 255.0), dtype=np.uint8)\n    _, _, H, W = x.shape\n    x = x.reshape((n_images, 3, H, W))\n    x = x.transpose(0, 2, 3, 1)\n    preview_dir = '{}/preview'.format(args.out)\n    preview_path = preview_dir + '/image{:0>8}.png'.format(trainer.updater.iteration)\n    if not os.path.exists(preview_dir):\n        os.makedirs(preview_dir)\n    Image.fromarray(x[0]).save(preview_path)\n\n", "CodeBleu_score": 68.62026094358642}]}
{"instance_id": "fc2162d43aee", "generation_result": [{"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    from_dtype = np.dtype(from_dtype)\n    to_dtype = np.dtype(to_dtype)\n    from_pos = _typechars.find(from_dtype.char)\n    to_pos = _typechars.find(to_dtype.char)\n    return from_pos <= to_pos\n\n", "CodeBleu_score": 47.30748086205847}, {"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    from_dtype = np.dtype(from_dtype)\n    to_dtype = np.dtype(to_dtype)\n    if from_dtype == to_dtype:\n        return True\n    from_pos = _typechars.find(from_dtype.char)\n    to_pos = _typechars.find(to_dtype.char)\n    if from_pos < 0 or to_pos < 0:\n        return False\n    return from_pos <= to_pos\n\n", "CodeBleu_score": 48.26954851302714}, {"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    from_dtype = np.dtype(from_dtype)\n    to_dtype = np.dtype(to_dtype)\n    from_pos = _typechars.find(from_dtype.char)\n    to_pos = _typechars.find(to_dtype.char)\n    return from_pos <= to_pos\n\n", "CodeBleu_score": 47.30748086205847}]}
{"instance_id": "5b8e2d5e6e12", "generation_result": [{"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    if g is not None:\n        if isinstance(g, YellowbrickVisualizer):\n            g = g.ax\n        elif isinstance(g, plt.Axes):\n            pass\n        else:\n            raise YellowbrickValueError(\"Unrecognized object for g keyword\")\n    else:\n        g = plt.gca()\n\n    if len(labels) != len(colors):\n        raise YellowbrickValueError(\n            \"Cannot create legend with {} labels and {} colors\".format(\n                len(labels), len(colors)\n            )\n        )\n\n    handles = [patches.Patch(color=color, label=label) for label, color in zip(labels, colors)]\n    return g.legend(handles=handles, **legend_kwargs)", "CodeBleu_score": 55.89911976309651}, {"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    if g is None:\n        g = plt.gca()\n    elif isinstance(g, Visualizer):\n        g = g.ax\n    elif not isinstance(g, Axes):\n        raise YellowbrickValueError(\n            \"g must be a Visualizer, None, or an Axes object\"\n        )\n\n    if len(labels) != len(colors):\n        raise YellowbrickValueError(\n            \"labels and colors must have the same length\"\n        )\n\n    handles = [patches.Patch(color=color, label=label) for label, color in zip(labels, colors)]\n    return g.legend(handles=handles, **legend_kwargs)", "CodeBleu_score": 57.46481541619002}, {"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    if g is None:\n        ax = plt.gca()\n    elif isinstance(g, Visualizer):\n        ax = g.ax\n    else:\n        ax = g\n\n    if len(labels) != len(colors):\n        raise YellowbrickValueError(\n            \"Size mismatch: there are {} labels but {} colors\".format(\n                len(labels), len(colors)\n            )\n        )\n\n    legend_handles = [patches.Patch(color=c, label=l) for l, c in zip(labels, colors)]\n    return ax.legend(handles=legend_handles, **legend_kwargs)\n\n", "CodeBleu_score": 51.429321947998204}]}
{"instance_id": "494e7f719eb6", "generation_result": [{"code": "def pcoords_time(X, y, fast=True)\n\t\n    plt.subplots()\n    plt.clf()\n    plt.close()\n    oz = ParallelCoordinates(fast=fast)\n    start = time.time()\n    oz.fit_transform(X, y)\n    end = time.time()\n    plt.cla()\n    plt.close()\n    return end - start\n\n", "CodeBleu_score": 30.683853384249847}, {"code": "def pcoords_time(X, y, fast=True)\n\t\n    ax = plt.subplots()[1]\n    oz = ParallelCoordinates(fast=fast)\n    t1 = time.time()\n    oz.fit_transform(X, y)\n    t2 = time.time()\n    plt.clf()\n    plt.close()\n    return t2 - t1\n\n", "CodeBleu_score": 24.604096255304846}, {"code": "def pcoords_time(X, y, fast=True)\n\t\n    # Create a plot axis\n    ax = plt.subplots()\n    # Initialize the ParallelCoordinates visualizer with the specified speed setting\n    oz = ParallelCoordinates(fast=fast)\n    # Record the start time\n    start = time.time()\n    # Fit and transform the input data X and y with the visualizer\n    oz.fit_transform(X, y)\n    # Calculate the elapsed time\n    elapsed = time.time() - start\n    # Clear and close the current plot to free up resources\n    plt.cla()\n    plt.close()\n    # Return the elapsed time for the fit and transform process\n    return elapsed\n\n", "CodeBleu_score": 44.58043273379347}]}
{"instance_id": "db4143bc029f", "generation_result": [{"code": "def draw_instances(self, X, y, **kwargs):\n\t\n    # Get alpha transparency value from object's attributes or default to 0.25\n    alpha = self.alpha if hasattr(self, 'alpha') else 0.25\n\n    # For each instance, extract feature vector and corresponding label, determine color based on label, and plot feature vector against predefined increment sequence\n    for i in range(len(X)):\n        x = X[i]\n        y_i = y[i]\n        color = self.get_colors(y_i)\n        self.ax.plot(x, range(len(x)), color=color, alpha=alpha, **kwargs)\n\n    # Return axis object with plotted instances\n    return self.ax", "CodeBleu_score": 53.11814114485439}, {"code": "def draw_instances(self, X, y, **kwargs):\n\t\n    alpha = kwargs.get(\"alpha\", self.alpha)\n    for x, y in zip(X, y):\n        color = self.get_colors()[y]\n        self.ax.plot(range(len(x)), x, color=color, alpha=alpha)\n    return self.ax\n\n", "CodeBleu_score": 32.636605962504575}, {"code": "def draw_instances(self, X, y, **kwargs):\n\t\n    alpha = kwargs.get('alpha', self.alpha)\n    for i in range(len(X)):\n        x_i = X[i]\n        y_i = y[i]\n        color = self.get_colors()[y_i]\n        self.ax.scatter(range(len(x_i)), x_i, color=color, alpha=alpha)\n    return self.ax\n\n", "CodeBleu_score": 44.15646020185277}]}
{"instance_id": "676433312ffe", "generation_result": [{"code": "def draw_classes(self, X, y, **kwargs):\n\t\n    alpha = kwargs.get('alpha', self.alpha)\n    X = np.hstack((X, np.ones((X.shape[0], 1))))\n    increments = [None]\n    for i, y_class in enumerate(np.unique(y)):\n        color = self.get_colors(i)\n        X_in_class = X[y == y_class]\n        self.ax.plot(\n            np.arange(X_in_class.shape[0]),\n            X_in_class.flatten(),\n            color=color,\n            alpha=alpha,\n            label=y_class\n        )\n        increments_separated = [None]\n        increments_separated.append(len(X_in_class))\n        increments += increments_separated\n    self.ax.set_xticks(np.cumsum(increments))\n    self.ax.set_xticklabels(np.unique(y))\n    self.ax.set_xlim(0, len(X))\n    self.ax.set_ylim(0, 1)\n    self.ax.set_ylabel('Probability')\n    self.ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n    return self.ax\n\n", "CodeBleu_score": 42.30020891446081}, {"code": "def draw_classes(self, X, y, **kwargs):\n\t\n    alpha = kwargs.get(\"alpha\", self.alpha)\n    X_in_class = np.hstack((X, np.ones((X.shape[0], 1)) * self.increments))\n    increments_separated = [None]\n    for i in range(len(np.unique(y))):\n        color = self.get_colors(i)\n        X_in_class_i = X_in_class[y == i]\n        self.ax.plot(X_in_class_i.flatten(), color=color, alpha=alpha)\n        increments_separated.append(None)\n    self.ax.set_xticks(increments_separated)\n    return self.ax", "CodeBleu_score": 39.22352662189469}, {"code": "def draw_classes(self, X, y, **kwargs):\n\t\n    alpha = kwargs.get('alpha', self.alpha)\n    X_in_class = np.hstack((X, np.ones((X.shape[0], 1))))\n    increments = [None]\n    for class_label in np.unique(y):\n        color = self.get_colors(class_label)\n        instances = X_in_class[y == class_label]\n        instances = instances.flatten()\n        increments_separated = [x for x in instances if x is not None]\n        increments.extend(increments_separated)\n        increments.append(None)\n        self.ax.plot(increments, color=color, alpha=alpha)\n    return self.ax", "CodeBleu_score": 42.229317605865}]}
{"instance_id": "9d297b12a673", "generation_result": [{"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n    # Set up the figure and axes grid\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n\n    # Perform RadViz analysis on occupancy data\n    occupancy = load_occupancy()\n    oz = RadViz(ax=axes[0], title=\"RadViz Analysis of Occupancy Data\")\n    oz.fit(occupancy, occupancy[\"occupied\"])\n    oz.finalize()\n\n    # Perform Rank2D analysis on concrete data\n    concrete = load_concrete()\n    oz = Rank2D(ax=axes[1], title=\"Rank2D Analysis of Concrete Data\")\n    oz.fit(concrete, concrete[\"Compressive Strength (MPa)\"])\n    oz.transform(concrete)\n    oz.finalize()\n\n    # Save the figure to the specified file path\n    plt.savefig(fname)\n    plt.tight_layout()\n    plt.show()", "CodeBleu_score": 25.912643585215555}, {"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n    # Set up the side-by-side axes grid with a specified figure size\n    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n\n    # Perform RadViz analysis on occupancy data\n    oz = RadViz(ax=ax[0])\n    oz.fit(X_train, y_train)\n    oz.finalize()\n\n    # Perform Rank2D analysis on concrete data\n    oz = Rank2D(ax=ax[1])\n    oz.fit(X_train, y_train)\n    oz.transform(X_test)\n    oz.finalize()\n\n    # Save the resulting figure to a specified file path\n    plt.savefig(fname)\n\n", "CodeBleu_score": 29.567116103400426}, {"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n    oz = RadViz(ax=ax[0], alpha=0.8)\n    oz.fit(X_train, y_train)\n    oz.finalize()\n    oz = Rank2D(ax=ax[1], alpha=0.8)\n    oz.fit(X_train, y_train)\n    oz.transform(X_train)\n    oz.finalize()\n    plt.savefig(fname)\n    plt.tight_layout()\n    plt.show()\n\n", "CodeBleu_score": 32.300006967514015}]}
{"instance_id": "fd1b4b9cd7ef", "generation_result": [{"code": "def regression(fname=\"regression.png\")\n\t\n    fig, ax = plt.subplots(1, 2, figsize=(18, 6))\n    alphas = np.logspace(-10, 0, 200)\n    oz = PredictionError(RidgeCV(alphas=alphas))\n    oz.fit(X_train, y_train)\n    oz.score(X_test, y_test)\n    oz.poof()\n    oz = ResidualsPlot(LassoCV(alphas=alphas))\n    oz.fit(X_train, y_train)\n    oz.score(X_test, y_test)\n    oz.poof()\n    plt.tight_layout()\n    path = os.path.join(os.getcwd(), \"figures\", fname)\n    plt.savefig(path)\n    return path", "CodeBleu_score": 43.98323729194358}, {"code": "def regression(fname=\"regression.png\")\n\t\n    plt.figure(figsize=(18, 6))\n    alphas = np.logspace(-6, 6, 250)\n    plt.subplot(1, 2, 1)\n    oz = PredictionError(LassoCV(alphas=alphas))\n    oz.fit(load_concrete().drop(columns=\"csMPa\"), load_concrete().csMPa)\n    oz.score(load_concrete().drop(columns=\"csMPa\"), load_concrete().csMPa)\n    oz.finalize()\n    plt.subplot(1, 2, 2)\n    oz = ResidualsPlot(RidgeCV(alphas=alphas))\n    oz.fit(load_concrete().drop(columns=\"csMPa\"), load_concrete().csMPa)\n    oz.score(load_concrete().drop(columns=\"csMPa\"), load_concrete().csMPa)\n    oz.finalize()\n    plt.tight_layout()\n    plt.savefig(fname)\n    return fname", "CodeBleu_score": 31.860330416829463}, {"code": "def regression(fname=\"regression.png\")\n\t\n    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n    alphas = np.logspace(-8, 2, 50)\n    oz = PredictionError(RidgeCV(alphas=alphas))\n    oz.fit(X_train, y_train)\n    oz.score(X_test, y_test)\n    oz.poof()\n    oz = ResidualsPlot(LassoCV(alphas=alphas))\n    oz.fit(X_train, y_train)\n    oz.score(X_test, y_test)\n    oz.poof()\n    plt.tight_layout()\n    path = os.path.join(os.getcwd(), \"figures\", fname)\n    plt.savefig(path)\n    return path", "CodeBleu_score": 43.136802108359355}]}
{"instance_id": "627126918f88", "generation_result": [{"code": "def classification(fname=\"classification.png\")\n\t\n    # Create a figure with two subplots side by side\n    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n\n    # Load the spam dataset and split into train and test sets\n    X, y = load_spam(split=True)\n\n    # Fit a MultinomialNB classifier on the train set\n    clf = MultinomialNB()\n    clf.fit(X[\"train\"], y[\"train\"])\n\n    # Display a ClassificationReport on the left subplot\n    oz = ClassificationReport(clf, ax=ax[0], labels=[\"ham\", \"spam\"])\n    oz.fit(X[\"test\"], y[\"test\"])\n    oz.finalize()\n\n    # Load the entire spam dataset and fit a LogisticRegression model\n    X, y = load_spam(split=False)\n    clf = LogisticRegression()\n    clf.fit(X, y)\n\n    # Display a DiscriminationThreshold on the right subplot\n    oz = DiscriminationThreshold(clf, ax=ax[1], alpha=0.8)\n    oz.fit(X, y)\n    oz.finalize()\n\n    # Adjust the layout and save the figure to a file\n    plt.tight_layout()\n    plt.savefig(fname)\n\n", "CodeBleu_score": 31.661220840351284}, {"code": "def classification(fname=\"classification.png\")\n\t\n    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n\n    oz = ClassificationReport(LogisticRegression(), ax=ax[0])\n    oz.fit(load_spam(return_X_y=True), load_spam(return_X_y=True))\n    oz.finalize()\n\n    oz = DiscriminationThreshold(MultinomialNB(), ax=ax[1])\n    oz.fit(load_spam(return_X_y=True), load_spam(return_X_y=True))\n    oz.finalize()\n\n    plt.tight_layout()\n    plt.savefig(fname)\n    return fig", "CodeBleu_score": 24.449484289769117}, {"code": "def classification(fname=\"classification.png\")\n\t\n    fig, ax = plt.subplots(ncols=2, figsize=(12, 6))\n    oz = ClassificationReport(\n        MultinomialNB(),\n        cv=2,\n        title=\"Spam Classification Report\",\n        ax=ax[0],\n        test_size=0.2,\n        train_X=load_spam().loc[\"train\", \"X\"],\n        train_y=load_spam().loc[\"train\", \"y\"],\n    )\n    oz.score(load_spam().loc[\"test\", \"X\"], load_spam().loc[\"test\", \"y\"])\n    oz.finalize()\n    oz = DiscriminationThreshold(\n        LogisticRegression(solver=\"lbfgs\"),\n        title=\"Discrimination Threshold\",\n        ax=ax[1],\n        test_size=0.2,\n        train_X=load_spam().loc[\"train\", \"X\"],\n        train_y=load_spam().loc[\"train\", \"y\"],\n    )\n    oz.finalize()\n    plt.tight_layout()\n    plt.savefig(fname)\n\n", "CodeBleu_score": 24.53762349928707}]}
{"instance_id": "318d3a674694", "generation_result": [{"code": "def get_color_cycle()\n\t\n    try:\n        import matplotlib as mpl\n        if mpl.__version__ >= '1.5.0':\n            return [color for color in mpl.rcParams['axes.prop_cycle']]\n        else:\n            return mpl.rcParams['axes.color_cycle']\n    except KeyError:\n        return mpl.rcParams['axes.color_cycle']\n\n", "CodeBleu_score": 40.89241337070328}, {"code": "def get_color_cycle()\n\t\n    try:\n        import matplotlib\n        if matplotlib.__version__ >= '1.5.0':\n            return [color for color in matplotlib.rcParams['axes.prop_cycle'].by_key()['color']]\n        else:\n            return matplotlib.rcParams['axes.color_cycle']\n    except KeyError:\n        return matplotlib.rcParams['axes.color_cycle']\n", "CodeBleu_score": 40.030460307714534}, {"code": "def get_color_cycle()\n\t\n    try:\n        from matplotlib import pyplot as plt\n        from matplotlib import __version__ as mpl_version\n        from distutils.version import LooseVersion\n        if LooseVersion(mpl_version) >= LooseVersion(\"1.5.0\"):\n            try:\n                color_cycle = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n            except KeyError:\n                color_cycle = plt.rcParams[\"axes.color_cycle\"]\n        else:\n            color_cycle = plt.rcParams[\"axes.color_cycle\"]\n    except ImportError:\n        color_cycle = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"]\n    return color_cycle\n\n", "CodeBleu_score": 37.29306069944879}]}
{"instance_id": "f3fac557334c", "generation_result": [{"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x_normalized, self.y_normalized)\n    plt.plot(self.x_normalized, self.distance, 'r')\n    plt.ylim(0, 1.1)\n    plt.vlines(self.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n    plt.yticks(np.arange(0, 1.1, 0.1))\n    plt.xticks(np.arange(0, 1.1, 0.1))\n    plt.show()\n\n", "CodeBleu_score": 49.858733504609795}, {"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n\n    plt.figure(figsize=(8, 8))\n    plt.ylim(0, 1)\n    plt.vlines(\n        x=self.knee,\n        ymin=0,\n        ymax=1,\n        color=\"red\",\n        linestyle=\"--\",\n        label=\"Knee point\",\n    )\n    plt.yticks(np.arange(0, 1.1, 0.1))\n    plt.xticks(np.arange(0, 1.1, 0.1))\n    plt.plot(self.x, self.y_normalized, label=\"Normalized curve\")\n    plt.plot(self.x, self.y_distance, color=\"red\", label=\"Distance curve\")\n    plt.legend()\n    plt.show()\n\n", "CodeBleu_score": 40.35890360540606}, {"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x_normalized, self.y_normalized)\n    plt.ylim(0, 1)\n    plt.vlines(self.knee, 0, 1, linestyles=\"dashed\", colors=\"r\")\n    plt.yticks(np.arange(0, 1, 0.1))\n    plt.xticks(np.arange(0, 1, 0.1))\n    plt.show()\n\n", "CodeBleu_score": 26.65322218937386}]}
{"instance_id": "b2d48aae4fce", "generation_result": [{"code": "def plot_knee(\n        self,\n    )\n\t\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x, self.y)\n    plt.vlines(self.knee, plt.ylim()[0], plt.ylim()[1], linestyles=\"dashed\")\n    plt.show()\n\n", "CodeBleu_score": 62.59171772404311}, {"code": "def plot_knee(\n        self,\n    )\n\t\n    fig = plt.figure(figsize=(8, 8))\n    plt.plot(self.x, self.y, \"b|\", mew=2)\n    plt.vlines(x=self.knee, ymin=0, ymax=plt.ylim()[1], linestyles=\"--\", colors=\"r\")\n    plt.show()\n\n", "CodeBleu_score": 48.67621058884749}, {"code": "def plot_knee(\n        self,\n    )\n\t\n\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x, self.y, \"bx-\")\n    plt.vlines(self.x[self.knee], plt.ylim()[0], plt.ylim()[1], linestyles=\"dashed\")\n    plt.show()\n\n", "CodeBleu_score": 53.586332828002405}]}
{"instance_id": "4450ba2384c9", "generation_result": [{"code": "def plot_pca_interactive(data, n_components=6)\n\t\n    from sklearn.decomposition import PCA\n    from ipywidgets import interact\n\n    pca = PCA(n_components=n_components)\n    Xproj = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        plot_image_components(data[i], Xproj[i], titles=[\"original\", \"PCA components\"])\n\n    interact(show_decomp, i=(0, data.shape[0] - 1))\n\n", "CodeBleu_score": 77.12652040218558}, {"code": "def plot_pca_interactive(data, n_components=6)\n\t\n    from sklearn.decomposition import PCA\n    from ipywidgets import interact\n\n    pca = PCA(n_components=n_components)\n    Xproj = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        plot_image_components(data[i], Xproj[i], titles=[\"original\", \"PCA components\"])\n\n    interact(show_decomp, i=(0, data.shape[0] - 1))\n\n", "CodeBleu_score": 77.12652040218558}, {"code": "def plot_pca_interactive(data, n_components=6)\n\t\n\n    from sklearn.decomposition import PCA\n    from ipywidgets import interact\n\n    pca = PCA(n_components=n_components)\n    Xproj = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        plot_image_components(data[i], Xproj[i], titles=[\"original\", \"PCA components\"])\n\n    interact(show_decomp, i=(0, len(data) - 1))\n\n", "CodeBleu_score": 70.45880243764903}]}
{"instance_id": "b09a163f3ff1", "generation_result": [{"code": "def plot_iris_knn()\n\t\n    iris = datasets.load_iris()\n    X = iris.data[:, :2]  # we only take the first two features.\n    y = iris.target\n    knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n    knn.fit(X, y)\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    pl.figure()\n    pl.pcolormesh(xx, yy, Z, cmap=pl.cm.Paired)\n    pl.scatter(X[:, 0], X[:, 1], c=y, cmap=pl.cm.Paired)\n    pl.xlabel('Sepal length')\n    pl.ylabel('Sepal width')\n    pl.xlim(xx.min(), xx.max())\n    pl.ylim(yy.min(), yy.max())\n    pl.xticks(())\n    pl.yticks(())\n    pl.show()\n\n", "CodeBleu_score": 67.36845888869918}, {"code": "def plot_iris_knn()\n\t\n    iris = datasets.load_iris()\n    X = iris.data[:, :2]\n    y = iris.target\n    knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n    knn.fit(X, y)\n    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    pl.figure()\n    pl.pcolormesh(xx, yy, Z, cmap=pl.cm.Paired)\n    pl.scatter(X[:, 0], X[:, 1], c=y, cmap=pl.cm.Paired)\n    pl.xlabel('Sepal length')\n    pl.ylabel('Sepal width')\n    pl.xlim(xx.min(), xx.max())\n    pl.ylim(yy.min(), yy.max())\n    pl.xticks(())\n    pl.yticks(())\n    pl.show()", "CodeBleu_score": 68.96509633401149}, {"code": "def plot_iris_knn()\n\t\n    iris = datasets.load_iris()\n    X = iris.data[:, :2]  # we only take the first two features. We could\n    # avoid this ugly slicing by using a two-dim dataset\n    y = iris.target\n\n    knn = neighbors.KNeighborsClassifier(5)\n    knn.fit(X, y)\n\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n                         np.linspace(y_min, y_max, 100))\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n\n    # Put the result into a color plot\n    Z = Z.reshape(xx.shape)\n    pl.figure()\n    pl.pcolormesh(xx, yy, Z, cmap=pl.cm.Paired)\n\n    # Plot also the training points\n    pl.scatter(X[:, 0], X[:, 1], c=y, cmap=pl.cm.Paired)\n    pl.xlabel('sepal length')\n    pl.ylabel('sepal width')\n\n    pl.xlim(xx.min(), xx.max())\n    pl.ylim(yy.min(), yy.max())\n    pl.xticks(())\n    pl.yticks(())\n\n    pl.show()\n\n", "CodeBleu_score": 65.92375332358029}]}
{"instance_id": "8eaee3207c09", "generation_result": [{"code": "def plot_sgd_separator()\n\t\n    # we create 50 separable points\n    X, Y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n\n    # fit the model\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)\n    clf.fit(X, Y)\n\n    # plot the line, the points, and the nearest vectors to the plane\n    xx = np.linspace(-1, 5, 10)\n    yy = np.linspace(-1, 5, 10)\n\n    X1, X2 = np.meshgrid(xx, yy)\n    Z = np.empty(X1.shape)\n    for (i, j), val in np.ndenumerate(X1):\n        x1 = val\n        x2 = X2[i, j]\n        p = clf.decision_function([[x1, x2]])\n        Z[i, j] = p[0]\n    levels = [-1.0, 0.0, 1.0]\n    linestyles = [\"dashed\", \"solid\", \"dashed\"]\n    ax = plt.axes()\n    ax.contour(\n        X1, X2, Z, levels, colors=\"k\", linestyles=linestyles\n    )\n    ax.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired)\n\n    ax.axis(\"tight\")\n\n", "CodeBleu_score": 60.23980733156215}, {"code": "def plot_sgd_separator()\n\t\n    # we create 50 separable points\n    X, Y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n\n    # fit the model\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)\n    clf.fit(X, Y)\n\n    # plot the line, the points, and the nearest vectors to the plane\n    xx = np.linspace(-1, 5, 10)\n    yy = np.linspace(-1, 5, 10)\n\n    X1, X2 = np.meshgrid(xx, yy)\n    Z = np.empty(X1.shape)\n    for (i, j), val in np.ndenumerate(X1):\n        x1 = val\n        x2 = X2[i, j]\n        p = clf.decision_function([[x1, x2]])\n        Z[i, j] = p[0]\n    levels = [-1.0, 0.0, 1.0]\n    linestyles = [\"dashed\", \"solid\", \"dashed\"]\n    ax = plt.axes()\n    ax.contour(X1, X2, Z, levels, colors=\"k\", linestyles=linestyles)\n    ax.scatter(X[:, 0], X[:, 1], c=Y, cmap=\"spring\", edgecolor=\"k\")\n\n    ax.axis(\"tight\")\n\n", "CodeBleu_score": 59.39475322237261}, {"code": "def plot_sgd_separator()\n\t\n    # we create 50 separable points\n    X, Y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n\n    # fit the model\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)\n    clf.fit(X, Y)\n\n    # plot the line, the points, and the nearest vectors to the plane\n    xx = np.linspace(-1, 5, 10)\n    yy = np.linspace(-1, 5, 10)\n\n    X1, X2 = np.meshgrid(xx, yy)\n    Z = np.empty(X1.shape)\n    for (i, j), val in np.ndenumerate(X1):\n        x1 = val\n        x2 = X2[i, j]\n        p = clf.decision_function([[x1, x2]])\n        Z[i, j] = p[0]\n    levels = [-1.0, 0.0, 1.0]\n    linestyles = [\"dashed\", \"solid\", \"dashed\"]\n    colors = \"k\"\n\n    ax = plt.axes()\n    ax.contour(\n        X1, X2, Z, levels, colors=colors, linestyles=linestyles\n    )\n    ax.scatter(\n        X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired\n    )\n\n    ax.axis(\"tight\")\n\n", "CodeBleu_score": 61.90360815077772}]}
{"instance_id": "8b54f999b4c0", "generation_result": [{"code": "def dump_svmlight_file(self, file)\n\t\n    X = np.array(self.data)\n    y = X[:, 2]\n    X = X[:, :2]\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 30.29354181628772}, {"code": "def dump_svmlight_file(self, file)\n\t\n    X, y = self.data[:, :-1], self.data[:, -1]\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 32.17044400405285}, {"code": "def dump_svmlight_file(self, file)\n\t\n    X = np.array(self.data)\n    y = X[:, 2]\n    X = X[:, :2]\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 30.29354181628772}]}
{"instance_id": "2419013adc6e", "generation_result": [{"code": "def fit(self)\n\t\n    print(\"fitting...\")\n    X, y = self.data.get(\"X\", \"y\", add_intercept=True)\n    C = self.params.get(\"C\", None)\n    gamma = self.params.get(\"gamma\", None)\n    coef0 = self.params.get(\"coef0\", None)\n    degree = self.params.get(\"degree\", None)\n    kernel = self.params.get(\"kernel\", None)\n    if len(np.unique(y)) == 1:\n        clf = svm.OneClassSVM(\n            nu=0.1, kernel=kernel, gamma=gamma, coef0=coef0, degree=degree\n        )\n    else:\n        clf = svm.SVC(\n            C=C,\n            kernel=kernel,\n            gamma=gamma,\n            coef0=coef0,\n            degree=degree,\n            probability=False,\n        )\n    clf.fit(X, y)\n    if hasattr(clf, \"score\"):\n        print(\"Accuracy:\", clf.score(X, y))\n    self.decision_surface = self.decision_surface(clf)\n    self.surface_type = \"non_probabilistic\"\n    self.fitted = True\n    self.trigger(\"changed\")\n\n", "CodeBleu_score": 41.29635573931834}, {"code": "def fit(self)\n\t\n    print(\"fitting started\")\n    X = self.data[:, :-1]\n    y = self.data[:, -1]\n    C = self.complexity\n    gamma = self.gamma\n    coef0 = self.coef0\n    degree = self.degree\n    kernel = self.kernel\n    if len(np.unique(y)) == 1:\n        clf = svm.OneClassSVM(kernel=kernel, gamma=gamma, coef0=coef0, degree=degree)\n    else:\n        clf = svm.SVC(kernel=kernel, C=C, gamma=gamma, coef0=coef0, degree=degree)\n    clf.fit(X, y)\n    if hasattr(clf, \"score\"):\n        print(\"Accuracy:\", clf.score(X, y))\n    self.decision_surface = self.set_surface(clf)\n    self.surface_type = \"svm\"\n    self.fitted = True\n    self.trigger_event(\"surface_changed\")\n\n", "CodeBleu_score": 35.824445742188}, {"code": "def fit(self)\n\t\n    print(\"Fitting...\")\n    X, y = self.data.train_data()\n    C = self.params[\"complexity\"]\n    gamma = self.params[\"gamma\"]\n    coef0 = self.params[\"coef0\"]\n    degree = self.params[\"degree\"]\n    kernel = self.params[\"kernel\"]\n    if len(np.unique(y)) == 1:\n        clf = svm.OneClassSVM(\n            kernel=kernel,\n            degree=degree,\n            gamma=gamma,\n            coef0=coef0,\n            nu=0.5,\n            shrinking=True,\n        )\n    else:\n        clf = svm.SVC(\n            kernel=kernel,\n            degree=degree,\n            gamma=gamma,\n            coef0=coef0,\n            C=C,\n            shrinking=True,\n            probability=False,\n            tol=0.001,\n            cache_size=200,\n            class_weight=None,\n            verbose=False,\n            max_iter=-1,\n            decision_function_shape=\"ovr\",\n            random_state=None,\n        )\n    clf.fit(X, y)\n    if hasattr(clf, \"score\"):\n        print(\"Accuracy:\", clf.score(X, y))\n    self.decision_surface = clf.decision_function(X)\n    self.surface_type = \"decision_surface\"\n    self.fitted = True\n    self.trigger(\"changed\")\n\n", "CodeBleu_score": 43.280326118222156}]}
{"instance_id": "e887fd2a8513", "generation_result": [{"code": "def source_decode(sourcecode, verbose=0)\n\t\n    import_string, object_string = sourcecode.split(\".\")\n    if sourcecode.startswith(\"tpot.\"):\n        import_string = \".\".join([\"tpot\", import_string])\n    try:\n        imported_object = __import__(import_string, globals(), locals(), [object_string])\n    except ImportError as e:\n        if verbose > 2:\n            raise e\n        else:\n            print(\"Warning: could not import %s\" % sourcecode)\n            return sourcecode, None, None\n    return import_string, object_string, imported_object\n\n", "CodeBleu_score": 36.13310270328042}, {"code": "def source_decode(sourcecode, verbose=0)\n\t\n    import_string, object_string = sourcecode.split(\".\")\n    if sourcecode.startswith(\"tpot.\"):\n        import_string = \".\".join([\"tpot\", import_string])\n    try:\n        imported_object = importlib.import_module(import_string)\n    except ImportError as e:\n        if verbose > 2:\n            raise ImportError(\n                \"{}: {}\".format(sourcecode, str(e))\n            )\n        else:\n            print(\n                \"{}: {}\".format(sourcecode, str(e))\n            )\n            return None, None, None\n    return import_string, object_string, imported_object\n", "CodeBleu_score": 41.211965946601495}, {"code": "def source_decode(sourcecode, verbose=0)\n\t\n    import_str, obj_str = sourcecode.split(\".\")\n    if sourcecode.startswith(\"tpot.\"):\n        import_str = import_str.replace(\"tpot\", \"tpot.builtins\")\n    try:\n        imported_obj = __import__(import_str, fromlist=[obj_str])\n    except ImportError as e:\n        if verbose > 2:\n            raise e\n        else:\n            print(\"Warning: could not import {}\".format(sourcecode))\n            return None, None, None\n    return import_str, obj_str, getattr(imported_obj, obj_str)\n\n", "CodeBleu_score": 37.21040761506466}]}
{"instance_id": "5d6f629c3363", "generation_result": [{"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n    sample_weight_dict = {}\n    if sample_weight is not None:\n        for step_name, step in pipeline_steps:\n            fit_method = getattr(step, \"fit\", None)\n            if fit_method is not None:\n                argspec = inspect.getargspec(fit_method)\n                if \"sample_weight\" in argspec.args:\n                    key = \"{}_sample_weight\".format(step_name)\n                    sample_weight_dict[key] = sample_weight\n    if sample_weight_dict:\n        return sample_weight_dict\n    else:\n        return None\n\n", "CodeBleu_score": 44.824618645600935}, {"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n    sample_weights = {}\n    if sample_weight is not None:\n        for name, step in pipeline_steps:\n            if hasattr(step, \"fit\"):\n                fit_args = inspect.getargspec(step.fit)[0]\n                if \"sample_weight\" in fit_args:\n                    sample_weights[name + \"__sample_weight\"] = sample_weight\n    if sample_weights:\n        return sample_weights\n    else:\n        return None\n\n", "CodeBleu_score": 40.556268816472766}, {"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n    sample_weight_dict = {}\n    if sample_weight is not None:\n        for step_name, step in pipeline_steps:\n            if hasattr(step, \"fit\"):\n                fit_args = inspect.getargspec(step.fit)[0]\n                if \"sample_weight\" in fit_args:\n                    sample_weight_dict[step_name + \"_sample_weight\"] = sample_weight\n    if sample_weight_dict:\n        return sample_weight_dict\n    else:\n        return None\n\n", "CodeBleu_score": 49.14188486887552}]}
{"instance_id": "cae17d519818", "generation_result": [{"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n    if not self.pareto_front_:\n        raise RuntimeError(\n            \"You must have a Pareto front in order to call this function. \"\n            \"Either you are using a custom TPOT object or you are \"\n            \"calling this function before TPOT has finished optimizing.\"\n        )\n\n    if verbosity >= 1:\n        print(self._summary_of_best_pipeline_string(features, target))\n\n    if verbosity >= 2:\n        print()\n\n    self.fitted_pipeline_ = self.compile_and_fit_pipeline(\n        self.pareto_front_[0], features, target\n    )\n\n    self.pareto_front_fitted_pipelines_ = [\n        self.compile_and_fit_pipeline(pipeline, features, target)\n        for pipeline in self.pareto_front_\n    ]\n\n", "CodeBleu_score": 23.538080133113642}, {"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n    if self.pareto_front_ is None:\n        raise RuntimeError('You must call `fit` before asking for the best pipeline.')\n    best_pipeline = self.pareto_front_[0]\n    if self.verbosity >= 1:\n        print('", "CodeBleu_score": 10.330767671914403}, {"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n    if self.pareto_front is None:\n        raise RuntimeError(\n            \"TPOT has not been fitted yet. Please call fit() before calling summary().\"\n        )\n    if self.verbosity > 0:\n        print(self.best_pipeline_string)\n        if self.verbosity > 1:\n            print(\"", "CodeBleu_score": 10.738869439673055}]}
{"instance_id": "638683d78167", "generation_result": [{"code": "def score(self, testing_features, testing_target)\n\t\n    if not self._check_dataset(testing_features, testing_target):\n        raise RuntimeError(\"The testing dataset is not valid.\")\n    if not self.optimized:\n        raise RuntimeError(\"The pipeline has not been optimized.\")\n    if not isinstance(testing_features, pd.DataFrame):\n        raise TypeError(\"The testing features must be a pandas DataFrame.\")\n    if not isinstance(testing_target, pd.Series):\n        raise TypeError(\"The testing target must be a pandas Series.\")\n    if self.scorer in SCORERS:\n        scorer = SCORERS[self.scorer]\n    elif callable(self.scorer):\n        scorer = self.scorer\n    else:\n        raise ValueError(\n            \"The scorer must be a string or a callable. \"\n            \"Valid strings are: {}\".format(\", \".join(SCORERS.keys()))\n        )\n    return scorer(self.fitted_pipeline, testing_features.astype(float), testing_target.astype(float))", "CodeBleu_score": 43.79027654332939}, {"code": "def score(self, testing_features, testing_target)\n\t\n    if not self.optimized:\n        raise RuntimeError(\"You must optimize the pipeline first.\")\n    self._check_dataset(testing_features, testing_target)\n    if isinstance(self.scoring, str):\n        scorer = SCORERS[self.scoring]\n    elif callable(self.scoring):\n        scorer = self.scoring\n    else:\n        raise ValueError(\n            f\"Invalid scoring function: {self.scoring}. Must be a string or callable.\"\n        )\n    return scorer(self.fitted_pipeline, testing_features.astype(float), testing_target.astype(float))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.06782575130001}, {"code": "def score(self, testing_features, testing_target)\n\t\n    if not self.optimized:\n        raise RuntimeError(\"You must optimize the pipeline before scoring.\")\n    testing_features, testing_target = self._check_dataset(\n        testing_features, testing_target\n    )\n    if isinstance(self.scoring, str):\n        scorer = SCORERS[self.scoring]\n    elif callable(self.scoring):\n        scorer = self.scoring\n    else:\n        raise ValueError(\n            \"scoring must be a string or a callable, \"\n            f\"got {self.scoring} of type {type(self.scoring)}.\"\n        )\n    return scorer(self.fitted_pipeline, testing_features, testing_target)\n\n", "CodeBleu_score": 43.51264940115862}]}
{"instance_id": "a04382560333", "generation_result": [{"code": " def _impute_values(self, features)\n\t\n    if self.verbosity > 1:\n      print(\"Imputing values...\")\n\n    if self.imputer is None:\n      self.imputer = SimpleImputer(strategy=\"median\")\n      self.imputer.fit(features)\n\n    imputed_features = self.imputer.transform(features)\n    return imputed_features\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 72.01452387402243}, {"code": " def _impute_values(self, features)\n\t\n    if self.verbosity > 1:\n        print(\"Imputing missing values...\")\n    if self.imputer is None:\n        self.imputer = SimpleImputer(strategy=\"median\")\n        self.imputer.fit(features)\n    return self.imputer.transform(features)\n\n", "CodeBleu_score": 73.93042169190348}, {"code": " def _impute_values(self, features)\n\t\n    if self.verbosity > 1:\n        print(\"Imputing missing values...\")\n    if self.imputer is None:\n        self.imputer = SimpleImputer(strategy=\"median\")\n        self.imputer.fit(features)\n    return self.imputer.transform(features)", "CodeBleu_score": 73.93042169190348}]}
{"instance_id": "0043d411c332", "generation_result": [{"code": "def _compile_to_sklearn(self, expr)\n\t\n\n    # Generate the pipeline code string from the expression and a predefined set of operators\n    code_str = generate_pipeline_code(expr, self.operators)\n\n    # Evaluate the pipeline code string within a specific context to obtain the scikit-learn pipeline object\n    namespace = {\"array\": np.array, \"np\": np, \"pd\": pd}\n    namespace.update(self.operators)\n    namespace.update(self.named_steps)\n    pipeline = eval(code_str, namespace)\n\n    # Set the memory attribute for the pipeline\n    pipeline.memory = self.memory\n\n    # If a random state is specified, recursively set the random_state parameter for each step in the pipeline\n    if self.random_state is not None:\n        set_param_recursive(pipeline, \"random_state\", self.random_state)\n\n    # Return the configured scikit-learn pipeline\n    return pipeline\n\n", "CodeBleu_score": 42.926367821193686}, {"code": "def _compile_to_sklearn(self, expr)\n\t\n\n    operators = self._operators\n    if isinstance(expr, str):\n        code = expr\n    else:\n        code = generate_pipeline_code(expr, operators)\n    namespace = {\"np\": np, \"pd\": pd, \"sp\": sp, \"sk\": sk}\n    for step in self._steps:\n        namespace[step.__class__.__name__] = step\n    try:\n        eval_expression = eval(code, namespace, namespace)\n    except NameError as e:\n        raise NameError(\n            \"Name '{}' is not defined. Please add a definition for this class in the search space.\".format(\n                str(e).split(\"'\")[1]\n            )\n        )\n    eval_expression.memory = self._memory\n    if self._random_state is not None:\n        set_param_recursive(eval_expression.steps, \"random_state\", self._random_state)\n    return eval_expression\n\n", "CodeBleu_score": 39.41150533792715}, {"code": "def _compile_to_sklearn(self, expr)\n\t\n\n    pipeline_code = generate_pipeline_code(expr, self.operators)\n    context = {\"array\": self.array, \"df\": self.df}\n    pipeline = eval(pipeline_code, context)\n    pipeline.memory = self.memory\n    if self.random_state is not None:\n        set_param_recursive(pipeline.steps, \"random_state\", self.random_state)\n    return pipeline\n\n", "CodeBleu_score": 42.245446703301006}]}
{"instance_id": "ca0ce462aa76", "generation_result": [{"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n    primitives_sets = [set(ind.primitives) for ind in population]\n    individuals_as_strings = [str(ind) for ind in population]\n\n    eligible_pairs = []\n    for i, ind1 in enumerate(population):\n        for j, ind2 in enumerate(population):\n            if i != j and not ind1_prims.isdisjoint(ind2_prims) and individuals_as_strings[i] != individuals_as_strings[j]:\n                eligible_pairs.append((i, j))\n                eligible_pairs.append((j, i))\n\n    if not eligible_pairs:\n        return None, None\n\n    pair_index = randint(0, len(eligible_pairs) - 1)\n    ind1_index, ind2_index = eligible_pairs[pair_index]\n\n    return population[ind1_index], population[ind2_index]\n\n", "CodeBleu_score": 32.08341601719013}, {"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n    primitives_sets = [set(ind1_prims.get_primitives(ind)) for ind in population]\n    population_strings = [str(ind) for ind in population]\n    eligible_pairs = []\n    for i in range(len(population)):\n        for j in range(i + 1, len(population)):\n            if primitives_sets[i].isdisjoint(primitives_sets[j]):\n                continue\n            if population_strings[i] == population_strings[j]:\n                continue\n            eligible_pairs.append((i, j))\n            eligible_pairs.append((j, i))\n    if not eligible_pairs:\n        return None, None\n    pair = random.choice(eligible_pairs)\n    return population[pair[0]], population[pair[1]]\n\n", "CodeBleu_score": 31.861760299818187}, {"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n\n    # Create sets of primitive nodes for each individual\n    primitive_sets = [set(ind1_prims.get_primitives(ind)) for ind in population]\n\n    # Convert individuals to strings\n    individuals_str = [str(ind) for ind in population]\n\n    # Identify pairs of individuals that share at least one primitive and are not identical\n    eligible_pairs = []\n    for i, set1 in enumerate(primitive_sets):\n        for j, set2 in enumerate(primitive_sets[i + 1:]):\n            if not set1.isdisjoint(set2) and individuals_str[i] != individuals_str[i + j + 1]:\n                eligible_pairs.append((i, i + j + 1))\n                eligible_pairs.append((i + j + 1, i))\n\n    # If no eligible pairs are found, return None for both individuals\n    if not eligible_pairs:\n        return None, None\n\n    # Randomly select one of the eligible pairs\n    pair = random.choice(eligible_pairs)\n\n    # Return the corresponding individuals from the population\n    return population[pair[0]], population[pair[1]]\n\n", "CodeBleu_score": 32.749319828039845}]}
{"instance_id": "4b03c843f506", "generation_result": [{"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n    steps = []\n    for operator in operators:\n        steps += _process_operator(operator, pipeline_tree)\n    n_steps = len(steps)\n    if n_steps > 1:\n        return \"make_pipeline(", "CodeBleu_score": 18.975635849820996}, {"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n    steps = []\n    for operator in operators:\n        steps.append(process_operator(operator, pipeline_tree))\n    num_steps = len(steps)\n    if num_steps > 1:\n        code = f\"make_pipeline(", "CodeBleu_score": 18.39868030108514}, {"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n    steps = []\n    for operator in operators:\n        steps.append(process_operator(operator, pipeline_tree))\n    n_steps = len(steps)\n    if n_steps > 1:\n        code = \"make_pipeline(", "CodeBleu_score": 17.858311670455155}]}
{"instance_id": "e9aec2ee39a4", "generation_result": [{"code": "def _process_operator(operator, operators, depth=0)\n\t\n    name = operator.name\n    if name == 'CombineDFs':\n        steps.append(('union', CombineDFs()))\n        return\n    tpot_op = get_by_name(name, operators)\n    steps.append((name, tpot_op.__class__(**tpot_op.parameters)))\n    for input_op in operator.inputs:\n        if not isinstance(input_op, Operator) or depth > 0:\n            _process_operator(input_op, operators, depth + 1)\n    if operator.is_root and depth > 0:\n        steps.append(('stacking', StackingEstimator(steps)))\n\n", "CodeBleu_score": 32.9002817692326}, {"code": "def _process_operator(operator, operators, depth=0)\n\t\n    name = operator.name\n    if name == 'CombineDFs':\n        steps.append(operator.export())\n    else:\n        tpot_op = get_by_name(operators, name)\n        if tpot_op is None:\n            raise ValueError('Could not find operator %s' % name)\n        for input_op in operator.inputs:\n            if input_op.name != 'CombineDFs':\n                steps.extend(_process_operator(input_op, operators, depth=depth + 1))\n        if operator.is_root and depth > 0:\n            steps.append(StackingEstimator(tpot_op))\n        else:\n            steps.append(tpot_op)\n    return steps\n\n", "CodeBleu_score": 38.033395936882485}, {"code": "def _process_operator(operator, operators, depth=0)\n\t\n\n    name = operator.name\n    if name == \"CombineDFs\":\n        steps.append((\"union\", _combine_dfs(operator.inputs)))\n    else:\n        op = get_by_name(name, operators)\n        steps.append((name, op))\n        for input_node in operator.inputs:\n            if not input_node.is_pipeline_root:\n                _process_operator(input_node, operators, depth=depth + 1)\n        if depth == 0 and not operator.is_pipeline_root:\n            steps.append((\"stacking\", StackingEstimator(steps)))\n\n", "CodeBleu_score": 30.298297355498633}]}
{"instance_id": "0513bf969510", "generation_result": [{"code": "def transform(self, X)\n\t\n    self._X_selected = X.select_dtypes(include=['object'])\n    if self._X_selected.shape[1] == 0:\n        raise ValueError('No categorical features found in the input data.')\n    ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n    ohe.fit(self._X_selected)\n    return ohe.transform(self._X_selected)", "CodeBleu_score": 32.02959237821798}, {"code": "def transform(self, X)\n\t\n    if self.auto_select_categorical_features:\n        X_selected = self._X_selected\n        if X_selected is None:\n            raise ValueError(\"No categorical features selected.\")\n        X_selected_transformed = self.ohe.fit_transform(X_selected)\n        return X_selected_transformed\n    else:\n        return X\n\n", "CodeBleu_score": 28.320912970186768}, {"code": "def transform(self, X)\n\t\n    _X_selected = X.select_dtypes(include=['object'])\n    if _X_selected.shape[1] == 0:\n        raise ValueError('No categorical features found.')\n    else:\n        ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n        return ohe.fit_transform(_X_selected)\n\n", "CodeBleu_score": 32.304530512560504}]}
{"instance_id": "5b1bcf42ca9e", "generation_result": [{"code": "def balanced_accuracy(y_true, y_pred)\n\t\n\n    # Identify all unique classes present in the true and predicted labels\n    classes = np.unique(np.concatenate((y_true, y_pred)))\n\n    # Initialize a list to store the class accuracies\n    all_class_accuracies = []\n\n    # Loop over each class\n    for c in classes:\n        # Identify the indices where the true label is equal to the current class\n        indices_true = np.where(y_true == c)[0]\n\n        # Identify the indices where the predicted label is equal to the current class\n        indices_pred = np.where(y_pred == c)[0]\n\n        # Calculate the sensitivity (true positives / total actual positives)\n        sensitivity = np.sum(y_true[indices_true] == y_pred[indices_true]) / len(indices_true)\n\n        # Calculate the specificity (true negatives / total actual negatives)\n        specificity = np.sum(y_true[np.where(y_true != c)[0]] != y_pred[np.where(y_true != c)[0]]) / len(np.where(y_true != c)[0])\n\n        # If the true labels consist of only one class, set specificity to 1\n        if len(np.unique(y_true)) == 1:\n            specificity = 1\n\n        # Calculate the class accuracy as the average of sensitivity and specificity\n        class_accuracy = (sensitivity + specificity) / 2\n\n        # Append the class accuracy to the list of all class accuracies\n        all_class_accuracies.append(class_accuracy)\n\n    # Return the mean of all class accuracies as the balanced accuracy\n    return np.mean(all_class_accuracies)\n\n", "CodeBleu_score": 23.256451988188868}, {"code": "def balanced_accuracy(y_true, y_pred)\n\t\n\n    # Identify all unique classes present in the true and predicted labels\n    classes = np.unique(np.concatenate((y_true, y_pred)))\n\n    # Initialize a list to store the class accuracies\n    all_class_accuracies = []\n\n    # Loop over each class\n    for c in classes:\n        # Identify the indices of the current class in the true and predicted labels\n        indices_true = np.where(y_true == c)[0]\n        indices_pred = np.where(y_pred == c)[0]\n\n        # Calculate the sensitivity (true positive rate) for the current class\n        if len(indices_true) > 0:\n            tp = len(np.where(y_true[indices_true] == y_pred[indices_true])[0])\n            sensitivity = tp / len(indices_true)\n        else:\n            sensitivity = 0\n\n        # Calculate the specificity (true negative rate) for the current class\n        if len(indices_pred) > 0:\n            tn = len(np.where(y_true[indices_pred] != y_pred[indices_pred])[0])\n            specificity = tn / len(indices_pred)\n        else:\n            specificity = 0\n\n        # If the true labels consist of only one class, set specificity to 1\n        if len(classes) == 1:\n            specificity = 1\n\n        # Calculate the class accuracy as the average of sensitivity and specificity\n        class_accuracy = (sensitivity + specificity) / 2\n\n        # Append the class accuracy to the list of all class accuracies\n        all_class_accuracies.append(class_accuracy)\n\n    # Return the mean of all class accuracies as the balanced accuracy\n    return np.mean(all_class_accuracies)\n\n", "CodeBleu_score": 27.147528927241616}, {"code": "def balanced_accuracy(y_true, y_pred)\n\t\n    classes = np.unique(y_true)\n    class_accuracies = []\n\n    for c in classes:\n        true_positives = np.sum((y_true == c) & (y_pred == c))\n        false_positives = np.sum((y_true != c) & (y_pred == c))\n        true_negatives = np.sum((y_true != c) & (y_pred != c))\n        false_negatives = np.sum((y_true == c) & (y_pred != c))\n\n        sensitivity = true_positives / (true_positives + false_negatives)\n        specificity = true_negatives / (true_negatives + false_positives) if np.sum(y_true == c) > 0 else 1\n\n        class_accuracy = (sensitivity + specificity) / 2\n        class_accuracies.append(class_accuracy)\n\n    return np.mean(class_accuracies)\n\n\n\n", "CodeBleu_score": 24.600935066681703}]}
{"instance_id": "19a9ad39de0a", "generation_result": [{"code": "def transform(self, X, y=None)\n\t\n    X = check_array(X, accept_sparse='csr')\n    if self.copy:\n        X = X.copy()\n    if self.with_mean:\n        X = X - self.mean_\n    if self.with_std:\n        X = X / self.scale_\n    return X\n\n", "CodeBleu_score": 7.450700481390856}, {"code": "def transform(self, X, y=None)\n\t\n    X = check_array(X, accept_sparse='csr')\n    non_zeros = np.count_nonzero(X, axis=1)\n    zeros = X.shape[1] - non_zeros\n    return np.hstack((non_zeros[:, np.newaxis], zeros[:, np.newaxis], X))\n\n", "CodeBleu_score": 13.688039513024156}, {"code": "def transform(self, X, y=None)\n\t\n    X = check_array(X, accept_sparse='csr')\n    n_samples, n_features = X.shape\n\n    X_nonzero = np.count_nonzero(X, axis=1)\n    X_zero = n_features - X_nonzero\n\n    X_nonzero = np.reshape(X_nonzero, (n_samples, 1))\n    X_zero = np.reshape(X_zero, (n_samples, 1))\n\n    X_transformed = np.hstack((X_nonzero, X_zero, X))\n    return X_transformed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 22.095703768351374}]}
{"instance_id": "5e8db0b5d447", "generation_result": [{"code": "def _init_pretest(self, features, target)\n\t\n    self.n_classes_ = len(np.unique(target))\n    if self.n_classes_ < 2:\n        raise ValueError(\n            \"The number of unique target classes must be at least 2.\"\n        )\n    if len(features) < self.n_classes_:\n        raise ValueError(\n            \"The training size must be at least the number of unique target classes.\"\n        )\n    (self.pretest_X_, self.pretest_y_) = train_test_split(\n        features, target, random_state=self.random_state\n    )\n    if len(np.unique(self.pretest_y_)) < self.n_classes_:\n        self.pretest_y_ = self.pretest_y_[\n            : self.n_classes_\n        ]\n\n", "CodeBleu_score": 26.549712591644255}, {"code": "def _init_pretest(self, features, target)\n\t\n    self.pretest_size = max(np.unique(target).size, self.min_samples_leaf)\n    self.pretest_X, _, self.pretest_y, _ = train_test_split(\n        features, target, train_size=self.pretest_size, random_state=self.random_state\n    )\n    if not np.array_equal(np.unique(self.pretest_y), np.unique(target)):\n        for i in np.unique(target):\n            self.pretest_y[i] = i\n\n", "CodeBleu_score": 25.95386492349472}, {"code": "def _init_pretest(self, features, target)\n\t\n    self.n_classes_ = len(np.unique(target))\n    self.n_pretest_ = max(self.n_classes_, int(self.train_size * len(features)))\n    self.pretest_X_, _, self.pretest_y_, _ = train_test_split(features, target, train_size=self.n_pretest_, random_state=self.random_state)\n    if len(np.unique(self.pretest_y_)) != self.n_classes_:\n        for c in np.unique(target):\n            if c not in self.pretest_y_:\n                self.pretest_X_ = np.vstack((self.pretest_X_, features[target == c][0]))\n                self.pretest_y_ = np.hstack((self.pretest_y_, np.array([c])))\n    return self\n\n", "CodeBleu_score": 29.100078408815133}]}
{"instance_id": "5e3d48667396", "generation_result": [{"code": "def _to_numpy_type(dtype)\n\t\n    if isinstance(dtype, tf.dtypes.DType):\n        return dtype.as_numpy_dtype\n    else:\n        return dtype\n\n", "CodeBleu_score": 31.29023423875224}, {"code": "def _to_numpy_type(dtype)\n\t\n    if isinstance(dtype, tf.dtypes.DType):\n        return dtype.as_numpy_dtype\n    return dtype\n\n", "CodeBleu_score": 36.12379432275329}, {"code": "def _to_numpy_type(dtype)\n\t\n    if dtype is None:\n        return None\n    if isinstance(dtype, np.dtype):\n        return dtype\n    if isinstance(dtype, tf.DType):\n        return dtype.as_numpy_dtype\n    if isinstance(dtype, str):\n        return np.dtype(dtype)\n    raise ValueError(f\"Unsupported data type: {dtype}\")\n\n", "CodeBleu_score": 67.99831007062345}]}
{"instance_id": "8f1120fdd463", "generation_result": [{"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    try:\n        if batch_size is None:\n            return tfds.as_numpy(ds)\n        else:\n            return tfds.as_numpy(ds.batch(batch_size))\n    except:\n        return tfds.as_numpy(ds.batch(1))\n\n", "CodeBleu_score": 10.273251381870216}, {"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    try:\n        ds = ds.batch(batch_size)\n    except TypeError:\n        ds = ds.batch(batch_size=batch_size)\n    try:\n        ds = ds.as_numpy_iterator()\n    except AttributeError:\n        ds = ds.make_one_shot_iterator().get_next()\n    return ds\n\n", "CodeBleu_score": 17.61290964138732}, {"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    try:\n        ds = ds.batch(batch_size)\n        return tfds.as_numpy(ds)\n    except AttributeError:\n        return tfds.as_numpy(ds)\n\n", "CodeBleu_score": 11.082502212990926}]}
{"instance_id": "282271955871", "generation_result": [{"code": "def get_prng(seed)\n\t\n    seed = np.asarray(seed, dtype=np.uint32)\n    assert seed.shape == ()\n    key = np.asarray(seed, dtype=np.uint32)\n    key = np.bitwise_and(key, np.uint32(0xffffffff))\n    key = np.right_shift(key, np.uint32(32))\n    subkey = np.asarray(key, dtype=np.uint32)\n    key = np.concatenate([key, subkey], axis=0)\n    return key", "CodeBleu_score": 22.19781585392862}, {"code": "def get_prng(seed)\n\t\n    if not isinstance(seed, (int, float)):\n        raise TypeError(\"Seed must be a scalar.\")\n    seed = int(seed)\n    key = jax.random.PRNGKey(seed)\n    return key\n\n", "CodeBleu_score": 20.413305905730017}, {"code": "def get_prng(seed)\n\t\n    seed = np.asarray(seed, dtype=np.uint32)\n    if seed.shape == ():\n        seed = np.asarray(seed, dtype=np.uint32)\n        key = np.concatenate([seed, seed])\n    else:\n        key = np.asarray(seed, dtype=np.uint32)\n    return key\n\n", "CodeBleu_score": 24.08826976737967}]}
{"instance_id": "42234dccce9a", "generation_result": [{"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n\n    if isinstance(s, pdt.DatetimeTZDtype):\n        return s.tz_convert(dtype.tz)\n\n    if pdt.is_datetime64_dtype(s):\n        return s.dt.tz_localize(dtype.tz)\n\n    if pdt.is_numeric_dtype(s):\n        return pd.to_datetime(s, unit=\"ns\", utc=True).dt.tz_localize(dtype.tz)\n\n    return s.astype(pandas_type).dt.tz_localize(dtype.tz)\n\n", "CodeBleu_score": 55.42382902758245}, {"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n    if isinstance(s.dtype, pdt.DatetimeTZDtype):\n        return s.dt.tz_convert(dtype.tz)\n    elif pdt.is_datetime64_dtype(s):\n        return s.dt.tz_localize(dtype.tz)\n    elif pdt.is_numeric_dtype(s):\n        return pd.to_datetime(s, unit=\"ms\", utc=True).dt.tz_localize(dtype.tz)\n    else:\n        return pd.to_datetime(s, utc=True).dt.tz_localize(dtype.tz)", "CodeBleu_score": 64.072582489418}, {"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n    if isinstance(s.dtype, pdt.DatetimeTZDtype):\n        return s.dt.tz_convert(cls.timezone)\n    elif pdt.is_datetime64_dtype(s):\n        return s.dt.tz_localize(cls.timezone)\n    elif pdt.is_numeric_dtype(s):\n        return pd.to_datetime(s, unit=\"s\").dt.tz_localize(\"UTC\").dt.tz_convert(cls.timezone)\n    else:\n        return pd.to_datetime(s).dt.tz_localize(\"UTC\").dt.tz_convert(cls.timezone)\n\n", "CodeBleu_score": 58.71256167260361}]}
{"instance_id": "9cee7388879b", "generation_result": [{"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if arg.dtype.tz is not None:\n        arg = arg.dt.tz_localize(None)\n    if lower_bound.dtype.tz is not None:\n        lower_bound = lower_bound.dt.tz_localize(None)\n    if upper_bound.dtype.tz is not None:\n        upper_bound = upper_bound.dt.tz_localize(None)\n    if lower_bound.dtype.tz is not None:\n        lower_bound = lower_bound.dt.tz_localize(None)\n    if upper_bound.dtype.tz is not None:\n        upper_bound = upper_bound.dt.tz_localize(None)\n    if lower_bound.dtype.tz is not None:\n        lower_bound = lower_bound.dt.tz_localize(None)\n    if upper_bound.dtype.tz is not None:\n        upper_bound = upper_bound.dt.tz_localize(None)\n    if lower_bound.dtype.tz is not None:\n        lower_bound = lower_bound.dt.tz_localize(None)\n    if upper_bound.dtype.tz is not None:\n        upper_bound = upper_bound.dt.tz_localize(None)\n    if lower_bound.dtype.tz is not None:\n        lower_bound = lower_bound.dt.tz_localize(None)\n    if upper_bound.dtype.tz is not None:\n        upper_bound = upper_bound.dt.tz_localize(None)\n    if lower_bound.dtype.tz is not None:\n        lower_bound = lower_bound.dt.tz_localize(None)\n    if upper_bound.dtype.tz is not None:\n        upper_bound = upper_bound.dt.tz_localize(None)\n    if lower_bound.dtype.tz is not None:\n        lower_bound = lower_bound.dt.tz_localize(None)\n    if upper_bound.dtype.tz is not None:\n        upper_bound = upper_bound.dt.tz_localize(None)\n    if lower_bound.d", "CodeBleu_score": 17.513642331249592}, {"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if arg.dtype.tz is None:\n        arg = arg.tz_localize(\"UTC\")\n    else:\n        arg = arg.tz_convert(\"UTC\")\n    start = lower_bound.tz_localize(\"UTC\")\n    end = upper_bound.tz_localize(\"UTC\")\n    if start > end:\n        raise ValueError(\"Lower bound is after upper bound\")\n    indexer = da.zeros(arg.shape, dtype=bool)\n    for i, (t1, t2) in enumerate(zip(start, end)):\n        indexer[:, i] = (arg[:, i] >= t1) & (arg[:, i] <= t2)\n    return cls.from_array(indexer, index=arg.index, columns=arg.columns)", "CodeBleu_score": 32.538199644106136}, {"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if isinstance(arg, dd.DataFrame):\n        if arg.index.tz is None:\n            arg = arg.tz_localize(\"UTC\")\n        else:\n            arg = arg.tz_convert(\"UTC\")\n        indexer = (arg.index >= lower_bound) & (arg.index <= upper_bound)\n        return da.from_array(indexer, chunks=arg.chunksize)\n    else:\n        raise TypeError(f\"Invalid type: {type(arg)}\")\n\n", "CodeBleu_score": 30.203377944025434}]}
{"instance_id": "0ab1cc8ccf71", "generation_result": [{"code": "def asseries(cls, value, like=None)\n\t\n    if isinstance(value, dd.Series):\n        return value\n    if isinstance(value, dd.Scalar):\n        return dd.from_array(value.to_delayed(), like=like)\n    if isinstance(value, pd.Series):\n        return dd.from_pandas(value, npartitions=1, like=like)\n    if like is not None:\n        if isinstance(like, (list, tuple)):\n            return dd.from_array(value, like=like)\n        if isinstance(like, dict):\n            return dd.from_array(value, like=like)\n    return dd.from_array(value)\n\n", "CodeBleu_score": 31.773735077827304}, {"code": "def asseries(cls, value, like=None)\n\t\n    if isinstance(value, dd.Series):\n        return value\n    if isinstance(value, dd.Scalar):\n        value = value.to_array()\n    if isinstance(value, pd.Series):\n        return dd.from_pandas(value, 1)\n    if like is not None:\n        if isinstance(like, tuple):\n            return dd.from_array(value, like)\n        if isinstance(like, list):\n            return dd.from_array(value, like)\n        if isinstance(like, dict):\n            return dd.from_array(value, like)\n    return dd.from_array(value, 1)\n\n", "CodeBleu_score": 30.924816843718617}, {"code": "def asseries(cls, value, like=None)\n\t\n    if isinstance(value, dd.Series):\n        return value\n    if isinstance(value, dd.Scalar):\n        value = value.to_delayed()\n    if isinstance(value, pd.Series):\n        return dd.from_pandas(value, npartitions=1)\n    if like is not None:\n        if isinstance(like, tuple):\n            return dd.from_array(value, chunks=(len(like),))\n        if isinstance(like, list):\n            return dd.from_array(value, chunks=(len(like),))\n        if isinstance(like, dict):\n            return dd.from_array(value, chunks=(len(like),))\n    return dd.from_array(value, chunks=(len(value),))", "CodeBleu_score": 36.22115076224945}]}
{"instance_id": "926220a06a0c", "generation_result": [{"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t\n    if dictionary is None:\n        dictionary = {}\n    for key, value in dictionary.items():\n        if not isinstance(value, (dd.DataFrame, pd.DataFrame)):\n            raise TypeError(\n                f\"Invalid type for dictionary value: {type(value)}. \"\n                \"Expected dd.DataFrame or pd.DataFrame.\"\n            )\n    super().connect(dictionary)\n\n", "CodeBleu_score": 69.01998523679148}, {"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t\n\n    if dictionary is None:\n        dictionary = {}\n    else:\n        for key, value in dictionary.items():\n            if not isinstance(value, (dd.DataFrame, pd.DataFrame)):\n                raise TypeError(\n                    f\"Invalid type for dictionary value: {type(value)}. Expected dd.DataFrame or pd.DataFrame.\"\n                )\n    super().connect(dictionary)\n\n", "CodeBleu_score": 53.726024729910414}, {"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t\n    if dictionary is None:\n        dictionary = {}\n    for key, value in dictionary.items():\n        if not isinstance(value, (dd.DataFrame, pd.DataFrame)):\n            raise TypeError(\n                f\"Invalid type for dictionary value: {key} = {value}\",\n            )\n    super().do_connect(dictionary)\n\n", "CodeBleu_score": 66.10870298269154}]}
{"instance_id": "95afc38c9125", "generation_result": [{"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    classes = get_module_members(library_name)\n    if estimator_name not in classes:\n        raise ValueError(\"Estimator {0} can not be found.\".format(estimator_name))\n    if len(classes[estimator_name]) > 1:\n        logger.debug(\n            \"Multiple classes <{0}> with the same name found: {1}\".format(\n                estimator_name, \", \".join(classes[estimator_name])\n            )\n        )\n        logger.warning(\"Using the first of the found classes.\")\n    estimator_class = classes[estimator_name][0]\n    if not issubclass(estimator_class, sklearn.base.BaseEstimator):\n        logger.info(\n            \"{0} is not an sklearn estimator. \"\n            \"Did you forget to inherit from sklearn.base.BaseEstimator?\".format(\n                estimator_class\n            )\n        )\n    return estimator_class", "CodeBleu_score": 41.74960666545145}, {"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    classes = get_module_members(library_name)\n    if estimator_name not in classes:\n        raise ValueError(f\"Estimator {estimator_name} not found in {library_name}.\")\n    if len(classes[estimator_name]) > 1:\n        logger.debug(f\"Multiple estimators found for {estimator_name}: {classes[estimator_name]}\")\n        logger.warning(\"Using the first one.\")\n    estimator_class = classes[estimator_name][0]\n    if not issubclass(estimator_class, BaseEstimator):\n        logger.info(f\"{estimator_name} is not an sklearn estimator.\")\n    return estimator_class\n\n", "CodeBleu_score": 37.8546696569249}, {"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    classes = get_module_members(library_name)\n    check_estimator = classes.get(estimator_name)\n    if check_estimator is None:\n        raise ValueError(f\"Estimator {estimator_name} could not be found\"\n                         f\" in {library_name}.\")\n    if len(check_estimator) > 1:\n        logger.debug(f\"Multiple estimators with name {estimator_name} found: {check_estimator}.\")\n        logger.warning(\"Using the first one.\")\n    estimator_class = check_estimator[0]\n    if not issubclass(estimator_class, BaseEstimator):\n        logger.info(f\"{estimator_class} is not an sklearn estimator. \"\n                    f\"All estimators should be derived from \"\n                    f\"sklearn.base.BaseEstimator.\")\n    return estimator_class\n\n", "CodeBleu_score": 32.97768750647882}]}
{"instance_id": "9562a9cc043b", "generation_result": [{"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    with open(join(dirname(abspath(__file__)), \"estimator_to_task_map.json\"), \"r\") as f:\n        estimator_to_task_map = json.load(f)\n    for task, postfixes in estimator_to_task_map.items():\n        if any(estimator_name.endswith(postfix) for postfix in postfixes):\n            return task\n    return \"unknown\"", "CodeBleu_score": 44.01535413033121}, {"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    with open(\n        join(\n            dirname(abspath(__file__)), \"estimator_to_task_map.json\"\n        ),\n        \"r\",\n    ) as f:\n        estimator_to_task_map = json.load(f)\n    for task, postfixes in estimator_to_task_map.items():\n        if any(estimator_name.endswith(postfix) for postfix in postfixes):\n            return task\n    return \"unknown\"", "CodeBleu_score": 50.5218162631247}, {"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    with open(\n        abspath(join(dirname(__file__), \"estimator_to_task_map.json\")), \"r\"\n    ) as f:\n        estimator_to_task_map = json.load(f)\n    for task, postfixes in estimator_to_task_map.items():\n        if any(estimator_name.endswith(postfix) for postfix in postfixes):\n            return task\n    return \"unknown\"", "CodeBleu_score": 46.848552120052226}]}
{"instance_id": "2f50195d043a", "generation_result": [{"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    data = {}\n    for data_filename in get_filenames_by_prefix(data_cache, data_name):\n        if data_filename.endswith(\".json\"):\n            continue\n        component, file_extension = data_filename.split(\".\")[0].split(\"_\")\n        data[component] = load_data_file(data_filename)\n    return data\n\n", "CodeBleu_score": 35.85703590586702}, {"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    data_files = get_filenames_by_prefix(data_cache, data_name)\n    data = {}\n    for data_file in data_files:\n        if data_file.endswith(\".json\"):\n            continue\n        component, file_ext = data_file.split(\".\")\n        data[component] = load_data_file(data_file)\n    return data\n\n", "CodeBleu_score": 37.325372675285415}, {"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    data_cache = Path(data_cache)\n    data_filename = data_cache / data_name\n    data = load_data_file(data_filename)\n    return data\n\n", "CodeBleu_score": 9.24381402142417}]}
{"instance_id": "e0281206029e", "generation_result": [{"code": "def retrieve(url: str, filename: str) -> None\n\t\n    if os.path.isfile(filename):\n        return\n    if url.startswith(\"http\"):\n        response = requests.get(url, stream=True)\n        if response.status_code != 200:\n            raise AssertionError(f\"Failed to download {url}: {response.status_code}\")\n        total_size = int(response.headers.get(\"content-length\", 0))\n        block_size = 1024\n        written_size = 0\n        with open(filename, \"wb\") as datafile:\n            for data in response.iter_content(block_size):\n                written_size += len(data)\n                datafile.write(data)\n        if total_size > 0 and written_size != total_size:\n            raise AssertionError(\n                f\"Incomplete download {url}: {written_size} of {total_size} bytes\"\n            )\n\n", "CodeBleu_score": 70.04910816805598}, {"code": "def retrieve(url: str, filename: str) -> None\n\t\n    if os.path.isfile(filename):\n        print(f\"File {filename} already exists, skipping download.\")\n        return\n    if url.startswith(\"http\"):\n        with requests.get(url, stream=True) as response:\n            if response.status_code != 200:\n                raise AssertionError(f\"Failed to download (status code {response.status_code}): {url}\")\n            total = int(response.headers.get(\"content-length\"))\n            with open(filename, \"wb\") as datafile:\n                for chunk in tqdm(iterable=response.iter_content(chunk_size=1024), total=int(total / 1024), unit=\"kB\"):\n                    datafile.write(chunk)\n                    datafile.flush()\n    if total != 0 and total != os.path.getsize(filename):\n        raise AssertionError(\"Incomplete download\")", "CodeBleu_score": 51.52740564535502}, {"code": "def retrieve(url: str, filename: str) -> None\n\t\n    if os.path.isfile(filename):\n        print(f\"File {filename} already exists, download skipped\")\n        return\n    print(f\"Downloading {url} to {filename}\")\n    if url.startswith(\"http\"):\n        response = requests.get(url, stream=True)\n        if response.status_code != 200:\n            raise AssertionError(\n                f\"Failed to download url {url}, response code is {response.status_code}\"\n            )\n        total_size = int(response.headers.get(\"content-length\", 0))\n        block_size = 1024\n        wrote = 0\n        with open(filename, \"wb\") as datafile:\n            for data in response.iter_content(block_size):\n                wrote = wrote + len(data)\n                datafile.write(data)\n            if total_size != 0 and wrote != total_size:\n                raise AssertionError(\"Only part of the data is written\")\n\n", "CodeBleu_score": 66.35129759868146}]}
{"instance_id": "a69a71cc2fe8", "generation_result": [{"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n    (x, y), _ = fetch_covtype(\n        return_X_y=True,\n        data_home=data_cache,\n        download_if_missing=True,\n        shuffle=False,\n        random_state=42,\n    )\n    y = y - 1\n    if dataset_params.get(\"binary_classification\"):\n        y = (y > 0).astype(int)\n    return (\n        {\"x\": x, \"y\": y},\n        {\n            \"n_classes\": 2 if dataset_params.get(\"binary_classification\") else 7,\n            \"default_split\": {\n                \"train_size\": 0.8,\n                \"stratify\": y if dataset_params.get(\"stratify_split\") else None,\n            },\n        },\n    )\n\n", "CodeBleu_score": 41.929553988874225}, {"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n    features, labels = fetch_covtype(\n        data_home=raw_data_cache, return_X_y=True, as_frame=False\n    )\n    labels -= 1\n    if dataset_params.get(\"binary\"):\n        labels = (labels > 0).astype(np.float32)\n    dataset = {\n        \"features\": features,\n        \"labels\": labels,\n    }\n    description = {\n        \"name\": data_name,\n        \"n_classes\": len(np.unique(labels)),\n        \"default_split\": {\n            \"train_size\": 0.8,\n            \"stratify\": True,\n        },\n    }\n    return dataset, description", "CodeBleu_score": 41.42485351275283}, {"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n    X, y = fetch_covtype(return_X_y=True, data_home=raw_data_cache)\n    y = y.astype(int) - 1\n    if dataset_params.get(\"binary\", False):\n        y[y > 0] = 1\n    return {\n        \"X\": X,\n        \"y\": y,\n    }, {\n        \"n_classes\": 2 if dataset_params.get(\"binary\", False) else 7,\n        \"default_split_params\": {\n            \"train_size\": 0.7,\n            \"stratify\": True,\n        },\n    }\n\n", "CodeBleu_score": 46.41617762609071}]}
{"instance_id": "129cbd2529ef", "generation_result": [{"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = []\n    for element in input_list:\n        if isinstance(element, list):\n            output_list.extend(flatten_list(element))\n        else:\n            output_list.append(element)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 41.300490207417845}, {"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = []\n    for element in input_list:\n        if isinstance(element, list):\n            output_list.extend(flatten_list(element))\n        else:\n            output_list.append(element)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 41.300490207417845}, {"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = []\n    for element in input_list:\n        if isinstance(element, list):\n            output_list.extend(flatten_list(element))\n        else:\n            output_list.append(element)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 41.300490207417845}]}
{"instance_id": "2d38c2c60b59", "generation_result": [{"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n    if eps is None:\n        x = np.where(x >= 0, x, np.nan)\n        x = np.where(x <= 1, x, np.nan)\n    else:\n        x = np.clip(x, eps, 1 - eps)\n\n    if complex_mode == \"split\":\n        return np.log(x / (1 - x))\n    elif complex_mode == \"magnitude\":\n        return np.log(np.abs(x) / (1 - np.abs(x)))\n    elif complex_mode == \"jax\":\n        return np.log(x / (np.ones_like(x) - x))\n    else:\n        raise ValueError(\n            \"complex_mode must be one of 'split', 'magnitude', or 'jax'.\"\n        )\n\n", "CodeBleu_score": 47.64261696639623}, {"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n    if complex_mode == \"jax\":\n        return jnp.logit(x, eps=eps, out=out)\n    elif complex_mode == \"split\":\n        return jnp.logit(x.real, eps=eps, out=out) + 1j * jnp.logit(\n            x.imag, eps=eps, out=out\n        )\n    elif complex_mode == \"magnitude\":\n        return jnp.logit(jnp.abs(x), eps=eps, out=out) + 1j * jnp.logit(\n            jnp.angle(x), eps=eps, out=out\n        )\n    else:\n        raise ValueError(\n            \"complex_mode must be one of 'split', 'magnitude', or 'jax'\"\n        )\n\n", "CodeBleu_score": 27.867659422353253}, {"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n    if eps is None:\n        x = np.where(np.logical_or(x > 1, x < 0), np.nan, x)\n    else:\n        x = np.clip(x, eps, 1 - eps)\n    if complex_mode == \"split\":\n        return np.log(x / (1 - x))\n    elif complex_mode == \"magnitude\":\n        return np.log(np.abs(x) / (1 - np.abs(x))) * (1j * np.angle(x))\n    else:\n        return np.log(x / (1 - x))\n\n", "CodeBleu_score": 63.83227371188741}]}
{"instance_id": "205e296f8621", "generation_result": [{"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    return np.where(np.logical_and(x > -lambd, x < lambd), 0, x)\n\n", "CodeBleu_score": 24.168028841508633}, {"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    return np.where(np.abs(x) > lambd, x, 0).astype(x.dtype)\n\n", "CodeBleu_score": 26.578348319387135}, {"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    return np.where(np.abs(x) > lambd, x, 0).astype(x.dtype)\n\n", "CodeBleu_score": 26.578348319387135}]}
{"instance_id": "5b133f6ebe2d", "generation_result": [{"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    result = []\n    for n in range(0, window_length):\n        result.append(round(np.sin(np.pi / 2 * np.sin(np.pi / window_length * (n + 0.5)) ** 2), 8))\n\n    if not isinstance(result, np.ndarray):\n        return np.array(result, dtype=dtype)\n    else:\n        return result", "CodeBleu_score": 41.093728624155105}, {"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    result = []\n    for n in range(0, window_length):\n        temp = round(np.sin(np.pi / 2 * np.sin(np.pi / window_length * (n + 0.5)) ** 2), 8)\n        if dtype == np.float32:  # Use np.float32 if it's specifically requested\n            temp = round(float(temp), 6)\n        result.append(temp)\n    return np.array(result, dtype=dtype, out=out)\n\n", "CodeBleu_score": 37.22666627074539}, {"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    result = []\n    for n in range(window_length):\n        result.append(round(np.sin((np.pi / 2) * (np.sin(np.pi / window_length * (n + 0.5)) ** 2)), 8))\n    return np.array(result, dtype=dtype, out=out)\n\n", "CodeBleu_score": 40.34280304742094}]}
{"instance_id": "473296f771a9", "generation_result": [{"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    ivy.set_backend(\"numpy\")\n    with ivy.PreciseMode():\n        coeffs = ivy.promote_types(coeffs, x)\n        return ivy.array(np.polyval(coeffs, x))\n\n", "CodeBleu_score": 30.206299365847876}, {"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    ivy.set_precision_mode(\"precise\")\n    coeffs = ivy.promote_types_of_inputs([coeffs, x])\n    return ivy.to_array(np.polyval(coeffs, x))", "CodeBleu_score": 22.44990560136404}, {"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    with ivy.PreciseMode():\n        coeffs = ivy.promote_types(coeffs, x)\n        return ivy.array(np.polyval(coeffs, x))\n\n", "CodeBleu_score": 27.951971336495916}]}
{"instance_id": "b8455221cb2a", "generation_result": [{"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if axis is None:\n        num = len(x.shape)\n        axis = tuple(range(num))\n    elif isinstance(axis, list):\n        axis = tuple(axis)\n    return np.amax(x, axis=axis, keepdims=keepdims, out=out)\n\n", "CodeBleu_score": 49.318466036485155}, {"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if axis is None:\n        num = len(x.shape)\n        axis = tuple(range(num))\n    elif isinstance(axis, list):\n        axis = tuple(axis)\n    return np.amax(x, axis=axis, keepdims=keepdims, out=out)", "CodeBleu_score": 49.318466036485155}, {"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.asarray(np.amax(x, axis=axis, keepdims=keepdims, out=out))\n\n", "CodeBleu_score": 45.255456923765294}]}
{"instance_id": "f72489f434a3", "generation_result": [{"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if not ivy.is_float_dtype(x1):\n        x1, x2 = promote_types_of_inputs(x1, x2)\n    return np.copysign(x1, x2, out=out)", "CodeBleu_score": 46.902523125962546}, {"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if not ivy.is_float_dtype(x1):\n        x1, x2 = promote_types_of_inputs(x1, x2)\n    return np.copysign(x1, x2, out=out)", "CodeBleu_score": 46.902523125962546}, {"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if not ivy.is_float_dtype(x1):\n        x1, x2 = promote_types_of_inputs(x1, x2)\n        x1 = x1.astype(ivy.default_float_dtype(as_native=True))\n    return np.copysign(x1, x2, out=out)\n\n", "CodeBleu_score": 70.06951148667954}]}
{"instance_id": "55c0d77e4dc2", "generation_result": [{"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if dtype is None:\n        dtype = np.int64\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    if isinstance(axis, np.ndarray):\n        axis = tuple(axis.tolist())\n    if isinstance(axis, tuple):\n        if len(axis) == 1:\n            axis = axis[0]\n    return np.count_nonzero(a, axis=axis, keepdims=keepdims, dtype=dtype, out=out)\n\n", "CodeBleu_score": 62.50688890760374}, {"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    try:\n        np.count_nonzero\n    except:\n        raise Exception(\"install numpy\")\n    a = np.asarray(a)\n    if dtype is None:\n        dtype = np.int64\n    if axis is None:\n        n = np.size(a)\n        return np.array(n - np.count_nonzero(a), dtype=dtype)\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    return np.asarray(np.count_nonzero(a, axis=axis, keepdims=keepdims, dtype=dtype), dtype=dtype)\n\n", "CodeBleu_score": 61.30262990760358}, {"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if axis is None:\n        np_axis = None\n    else:\n        np_axis = tuple(axis) if isinstance(axis, list) else axis\n    return np.asarray(np.count_nonzero(a, axis=np_axis, keepdims=keepdims), dtype=dtype)\n\n", "CodeBleu_score": 56.26404034427301}]}
{"instance_id": "784bf7d24fc2", "generation_result": [{"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    pass\n\n", "CodeBleu_score": 29.600163260004287}, {"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    pass\n\n", "CodeBleu_score": 29.600163260004287}, {"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    pass\n\n", "CodeBleu_score": 29.600163260004287}]}
{"instance_id": "efa0a51af6bc", "generation_result": [{"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    if x.size == 0:\n        return x\n    x, y = promote_types_of_inputs(x, y)\n    return np.multiply(x, np.log(y), out=out)\n\n", "CodeBleu_score": 64.82837146261302}, {"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    x, y = promote_types_of_inputs(x, y)\n    if not np.all(x):\n        return np.array(0.0, dtype=x.dtype)\n    return np.multiply(x, np.log(y), out=out)\n\n", "CodeBleu_score": 54.880187753456624}, {"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    if x.dtype != y.dtype:\n        y = y.astype(x.dtype)\n    x, y = promote_types_of_inputs(x, y)\n    if ivy.exists(out):\n        return ivy.inplace_update(out, x * np.log(y))\n    return x * np.log(y)\n\n", "CodeBleu_score": 61.78020270625913}]}
{"instance_id": "ac1645284260", "generation_result": [{"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    kernel_size, strides, depth_pooling = _depth_max_pooling_helper(x, kernel, strides, dims, data_format)\n    if depth_pooling:\n        x = np.transpose(x, (0, 1, 3, 2))\n    return x, kernel_size, strides, depth_pooling\n\n", "CodeBleu_score": 36.21691387394546}, {"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    kernel, strides, depth_pooling = _depth_max_pooling_helper(x.shape, kernel, strides, dims, data_format)\n    if depth_pooling:\n        x = np.transpose(x, (0, 1, 2, 4, 3))\n    return x, kernel, strides, depth_pooling\n\n", "CodeBleu_score": 48.33928102270716}, {"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    kernel, strides, depth_pooling = _depth_max_pooling_helper(x, kernel, strides, dims, data_format)\n    if depth_pooling:\n        x = np.transpose(x, (0, dims[0], dims[1], dims[2], dims[3]))\n    return x, kernel, strides, depth_pooling\n\n", "CodeBleu_score": 52.74352558736468}]}
{"instance_id": "18ff0a4f7550", "generation_result": [{"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if training:\n        if data_format == \"NCW\":\n            x = np.transpose(x, (0, 2, 1))\n        if len(x.shape) == 2:\n            mask = binomial(1, 1 - prob, size=(1, x.shape[1]))\n        else:\n            mask = binomial(1, 1 - prob, size=(x.shape[0], 1, x.shape[2]))\n        scale = 1 / (1 - prob)\n        x = np.where(mask, scale * x, 0)\n        if data_format == \"NCW\":\n            x = np.transpose(x, (0, 2, 1))\n    return x\n\n", "CodeBleu_score": 51.29122975425564}, {"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if training:\n        if len(x.shape) == 2:\n            shape = (x.shape[0], x.shape[1], 1)\n        else:\n            shape = (x.shape[0], 1, x.shape[2])\n        mask = np.where(\n            np.random.binomial(np.ones(shape, dtype=np.bool), prob),\n            np.ones(shape, dtype=np.bool),\n            np.zeros(shape, dtype=np.bool),\n        )\n        if data_format == \"NCW\":\n            mask = np.transpose(mask, (0, 2, 1))\n        scale = 1.0 / (1.0 - prob)\n        return np.where(mask, scale * x, x)\n    return x", "CodeBleu_score": 44.43841453113004}, {"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if training:\n        if data_format == \"NCW\":\n            x = np.transpose(x, (0, 2, 1))\n        ndims = len(x.shape)\n        if ndims == 2:\n            prob = prob\n            mask = np.random.binomial(1, prob, size=(x.shape[0], 1))\n        elif ndims == 3:\n            prob = prob\n            mask = np.random.binomial(1, prob, size=(x.shape[0], x.shape[1], 1))\n        scale = 1.0 / (1.0 - prob)\n        x = x * mask * scale\n        if data_format == \"NCW\":\n            x = np.transpose(x, (0, 2, 1))\n    return x", "CodeBleu_score": 48.384048328721875}]}
{"instance_id": "0ce45eb7cbd9", "generation_result": [{"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n    if axis is None:\n        axis_size = x.size\n    else:\n        axis_size = x.shape[axis]\n    if k > axis_size:\n        raise ValueError(\"k must be less than or equal to axis_size\")\n    if axis is None:\n        axis = 0\n        x = np.ravel(x)\n\n    if largest:\n        index_array = np.argpartition(x, kth=axis_size - k, axis=axis)\n        topk_indices = index_array[np.arange(x.shape[axis] - k, x.shape[axis]), ...]\n        topk_values = np.take_along_axis(x, topk_indices, axis)\n    else:\n        index_array = np.argpartition(x, kth=k - 1, axis=axis)\n        topk_indices = np.take(index_array, np.arange(k), axis=axis)\n        topk_values = np.take_along_axis(x, topk_indices, axis)\n\n    if sorted:\n        sorted_indices_in_topk = np.argsort(topk_values, axis=axis)\n        if largest:\n            sorted_indices_in_topk = np.flip(sorted_indices_in_topk, axis=axis)\n        sorted_topk_values = np.take_along_axis(\n            topk_values, sorted_indices_in_topk, axis=axis\n        )\n        sorted_topk_indices = np.take_along_axis(\n            topk_indices, sorted_indices_in_topk, axis=axis\n        )\n        topk_values = sorted_topk_values\n        topk_indices = sorted_topk_indices\n\n    if out is not None:\n        out[0] = topk_values\n        out[1] = topk_indices\n    else:\n        topk_res = namedtuple(\"top_k\", \"values indices\")\n        out = topk_res(topk_values, topk_indices)\n\n   ", "CodeBleu_score": 43.87976580671508}, {"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n    # Validate the input\n    assert x.ndim > 0, \"x must have at least one dimension\"\n    assert k > 0, \"k must be greater than zero\"\n    assert -x.ndim <= axis < x.ndim, \"axis must be a valid axis of x\"\n\n    # Calculate the indices of the top k elements\n    if largest:\n        indices = np.argpartition(x, -k, axis=axis)\n        indices = np.take(indices, np.arange(x.shape[axis] - k, x.shape[axis]), axis)\n    else:\n        indices = np.argpartition(x, k - 1, axis=axis)\n        indices = np.take(indices, np.arange(k), axis)\n\n    # Extract the top k elements and their indices\n    top_k_values = np.take_along_axis(x, indices, axis)\n    top_k_indices = np.take_along_axis(np.indices(x.shape), indices, axis)\n\n    # Sort the results if requested\n    if sorted:\n        if largest:\n            sort_indices = np.argsort(-top_k_values, axis=axis)\n        else:\n            sort_indices = np.argsort(top_k_values, axis=axis)\n        top_k_values = np.take_along_axis(top_k_values, sort_indices, axis)\n        top_k_indices = np.take_along_axis(top_k_indices, sort_indices, axis)\n\n    # Store the results in the output arrays if provided\n    if out is not None:\n        out_values, out_indices = out\n        np.copyto(out_values, top_k_values)\n        np.copyto(out_indices, top_k_indices)\n\n    # Return the results as a named tuple\n    return TopKResults(values=top_k_values, indices=top_k_indices)\n\n", "CodeBleu_score": 48.19022281373449}, {"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n    # TODO: Add support for other data types.\n    # TODO: Add support for non-default data types.\n    # TODO: Add support for non-default axes.\n    # TODO: Add support for non-default largest.\n    # TODO: Add support for non-default sorted.\n    # TODO: Add support for non-default out.\n    # TODO: Add support for non-default dtype.\n    # TODO: Add support for non-default casting.\n    # TODO: Add support for non-default order.\n    # TODO: Add support for non-default where.\n    # TODO: Add support for non-default keepdims.\n    # TODO: Add support for non-default initial.\n    # TODO: Add support for non-default where.\n    # TODO: Add support for non-default keepdims.\n    # TODO: Add support for non-default initial.\n    # TODO: Add support for non-default where.\n    # TODO: Add support for non-default keepdims.\n    # TODO: Add support for non-default initial.\n    # TODO: Add support for non-default where.\n    # TODO: Add support for non-default keepdims.\n    # TODO: Add support for non-default initial.\n    # TODO: Add support for non-default where.\n    # TODO: Add support for non-default keepdims.\n    # TODO: Add support for non-default initial.\n    # TODO: Add support for non-default where.\n    # TODO: Add support for non-default keepdims.\n    # TODO: Add support for non-default initial.\n    # TODO: Add support for non-default where.\n    # TODO: Add support for non-default keepdims.\n    # TODO: Add support for non-default initial.\n    # TODO: Add support for non-default where.\n    # TODO: Add support for non-default keepdims.\n    # TODO: Add support for non-default initial.\n    # TODO: Add support for non-default where.\n    # TODO: Add support for non-default keepdims.\n    # TODO: Add support for non-default initial.\n    # TODO: Add support for non-default where.\n    # TODO: Add support for non-default", "CodeBleu_score": 14.79044834307992}]}
{"instance_id": "1424f9541998", "generation_result": [{"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    denorm = (\n        np.sum(\n            np.abs(x),\n            axis=axis,\n            keepdims=True,\n        )\n        if axis is not None\n        else np.sum(np.abs(x))\n    )\n    denorm = np.divide(denorm, np.abs(x) + np.finfo(x.dtype).eps)\n    return np.divide(x, denorm, out=out)", "CodeBleu_score": 41.304119076842966}, {"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if out is None:\n        return np.divide(x, np.reshape(np.sum(np.abs(x), axis), x.shape))\n    else:\n        return np.divide(x, np.reshape(np.sum(np.abs(x), axis), x.shape), out=out)\n\n", "CodeBleu_score": 30.67739122567053}, {"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    denorm = (\n        np.sum(np.abs(x), axis=axis, keepdims=True)\n        if axis is not None\n        else np.sum(np.abs(x.ravel()))\n    )\n    denorm = np.divide(denorm, np.abs(x) + np.finfo(x.dtype).eps)\n    return np.divide(x, denorm, out=out)\n\n", "CodeBleu_score": 44.02208024791554}]}
{"instance_id": "4c3a386a1f05", "generation_result": [{"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    shape = _check_bounds_and_get_shape(alpha, beta, shape)\n    r = np.random.default_rng(seed)\n    out = r.beta(alpha, beta, size=shape, dtype=dtype)\n    return out\n\n", "CodeBleu_score": 59.00827886929236}, {"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    return np.asarray(\n        ivy.beta(\n            alpha,\n            beta,\n            shape=shape,\n            device=device,\n            dtype=dtype,\n            seed=seed,\n            out=out,\n        ),\n        dtype=dtype,\n    )\n\n", "CodeBleu_score": 46.39176407569403}, {"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    shape = beta_check_bounds_and_get_shape(alpha, beta, shape)\n    rng = np.random.default_rng(seed)\n    x1 = rng.gamma(alpha, 1, shape)\n    x2 = rng.gamma(beta, 1, shape)\n    out = x1 / (x1 + x2)\n    if dtype is not None:\n        out = out.astype(dtype)\n    return out\n\n", "CodeBleu_score": 58.032539677624875}]}
{"instance_id": "271200a8b261", "generation_result": [{"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    x = np.array(x)\n    sorted_indices = np.argsort(x)\n    inverse = np.zeros_like(sorted_indices)\n    inverse[sorted_indices] = np.arange(len(x))\n    return np.argsort(inverse)", "CodeBleu_score": 59.91879619513026}, {"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    sorted_indices = np.argsort(x)\n    inverse = np.zeros_like(sorted_indices)\n    inverse[sorted_indices] = np.arange(len(x))\n    return inverse\n\n", "CodeBleu_score": 53.67721297299843}, {"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    sorted_indices = np.argsort(x)\n    inverse = np.zeros_like(sorted_indices)\n    inverse[sorted_indices] = np.arange(len(x))\n    return np.argsort(inverse)", "CodeBleu_score": 58.236116048303955}]}
{"instance_id": "040d73b37229", "generation_result": [{"code": "def plot_medical_charts() -> None\n\t\n    sns.set(style=\"darkgrid\")\n    fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n    plot_daycare_days(axs[0, 0])\n    plot_days_between_vomit(axs[0, 1])\n    plot_monthly_vomit(axs[1, 0])\n    plot_doctor_visit_monthly(axs[1, 1])\n    fig.subplots_adjust(hspace=0.4)\n    export_figure(fig, \"medical_charts\")\n\n", "CodeBleu_score": 23.526336638453422}, {"code": "def plot_medical_charts() -> None\n\t\n    sns.set(style=\"whitegrid\")\n    fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n    plot_daycare_days(ax[0][0])\n    plot_days_between_vomit(ax[0][1])\n    plot_monthly_vomit(ax[1][0])\n    plot_doctor_visit_monthly(ax[1][1])\n    fig.subplots_adjust(hspace=0.3)\n    export_figure(fig, \"medical_charts.png\")\n\n", "CodeBleu_score": 20.716120831955394}, {"code": "def plot_medical_charts() -> None\n\t\n    sns.set(style=\"darkgrid\")\n    fig, axs = plt.subplots(2, 2, figsize=(12, 8))\n    plot_daycare_days(axs[0][0])\n    plot_days_between_vomit(axs[0][1])\n    plot_monthly_vomit(axs[1][0])\n    plot_doctor_visit_monthly(axs[1][1])\n    fig.subplots_adjust(hspace=0.4)\n    export_figure(\"medical_charts.png\")\n\n", "CodeBleu_score": 20.65405663882653}]}
{"instance_id": "7061f4d0c3fc", "generation_result": [{"code": "def plot_feeding_24h_viz() -> None\n\t\n    df = parse_raw_data()\n    sns.set(style=\"darkgrid\")\n    offset = get_end_date() - df[\"solid_feeding_date\"].max()\n    fig_ax = plt.subplots(figsize=(10, 5))\n    fig_ax.scatter(\n        df[\"bottle_feeding_date\"],\n        np.ones(len(df)),\n        color=\"red\",\n        label=\"Bottle feeding\",\n    )\n    fig_ax.scatter(\n        df[\"solid_feeding_date\"],\n        np.ones(len(df)),\n        color=\"blue\",\n        label=\"Solid feeding\",\n    )\n    plt.legend()\n    end_date = get_end_date()\n    format_24h_week_plot_horizontal(end_date, offset)\n    export_figure(\"feeding_24h_viz\")\n\n", "CodeBleu_score": 20.776315136896546}, {"code": "def plot_feeding_24h_viz() -> None\n\t\n    # Import and extract feeding data\n    feeding_data = parse_raw_data()\n\n    # Set up plot with dark grid style\n    sns.set(style=\"darkgrid\")\n\n    # Compute offset from birthday based on the last solid feeding date\n    offset = get_end_date(feeding_data)\n\n    # Create scatter plot of feeding times\n    fig, ax = plt.subplots()\n    ax.scatter(\n        feeding_data.loc[feeding_data[\"Solid\"] == 0][\"Time\"],\n        [1] * len(feeding_data.loc[feeding_data[\"Solid\"] == 0][\"Time\"]),\n        c=\"red\",\n        label=\"Bottle\",\n    )\n    ax.scatter(\n        feeding_data.loc[feeding_data[\"Solid\"] == 1][\"Time\"],\n        [1] * len(feeding_data.loc[feeding_data[\"Solid\"] == 1][\"Time\"]),\n        c=\"blue\",\n        label=\"Solid\",\n    )\n\n    # Add legend to distinguish between bottle and solid feedings\n    ax.legend()\n\n    # Calculate end date for the plot\n    end_date = offset + np.timedelta64(7, \"D\")\n\n    # Format plot to display feeding data over a week in a 24-hour format\n    format_24h_week_plot_horizontal(ax, end_date)\n\n    # Export the figure\n    export_figure(fig, \"feeding_24h_viz\")\n\n", "CodeBleu_score": 22.80709450657563}, {"code": "def plot_feeding_24h_viz() -> None\n\t\n    # Import and extract feeding data\n    feed_df = parse_raw_data()\n\n    # Set up plot with dark grid style\n    sns.set(style=\"darkgrid\")\n\n    # Compute offset from birthday based on last solid feeding date\n    last_solid_feeding_date = feed_df[feed_df[\"Solid/Bottle\"] == \"Solid\"][\"Date\"].max()\n    offset = last_solid_feeding_date - pd.Timestamp(\n        datetime.date(2022, 12, 20)\n    )\n\n    # Create scatter plot of feeding times\n    fig_ax = plt.subplots(figsize=(10, 5))\n    fig_ax.scatter(\n        feed_df[feed_df[\"Solid/Bottle\"] == \"Bottle\"][\"Date\"] - offset,\n        feed_df[feed_df[\"Solid/Bottle\"] == \"Bottle\"][\"Time\"],\n        color=\"red\",\n        label=\"Bottle\",\n    )\n    fig_ax.scatter(\n        feed_df[feed_df[\"Solid/Bottle\"] == \"Solid\"][\"Date\"] - offset,\n        feed_df[feed_df[\"Solid/Bottle\"] == \"Solid\"][\"Time\"],\n        color=\"blue\",\n        label=\"Solid\",\n    )\n\n    # Add legend\n    plt.legend()\n\n    # Calculate end date for plot\n    end_date = get_end_date()\n\n    # Format plot to display feeding data over a week in a 24-hour format\n    format_24h_week_plot_horizontal(end_date)\n\n    # Export figure\n    export_figure(fig_ax, \"24h_week_plot_horizontal\")\n\n", "CodeBleu_score": 24.334264435871955}]}
{"instance_id": "6c1ffa63d122", "generation_result": [{"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n\n    # Get the target counts for the specified classification task\n    target_counts = self._get_target_counts(task)\n\n    # Create a bar plot using seaborn\n    sns.barplot(x=target_counts.index, y=target_counts.values, ax=ax, **kwargs)\n\n    # Set the x-axis labels\n    ax.set_xticklabels(target_counts.index, rotation=90)\n\n    # Set the x-axis and y-axis labels\n    ax.set_xlabel('Target')\n    ax.set_ylabel('Count')\n\n    # Set the plot title\n    ax.set_title(f'Target Counts for {task.value}')\n\n    # Show the plot\n    plt.show()", "CodeBleu_score": 39.69842515878306}, {"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n    target_counts = self._get_target_counts(task)\n    sns.barplot(x=target_counts.index, y=target_counts.values, ax=ax, **kwargs)\n    ax.set_xlabel(\"Target\")\n    ax.set_ylabel(\"Count\")\n    ax.set_title(f\"Target Counts for {task.name}\")\n    return ax", "CodeBleu_score": 40.634182280304465}, {"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n    counts = self._get_target_counts(task)\n    sns.barplot(x=counts.index, y=counts.values, ax=ax, **kwargs)\n    ax.set_title(f\"Target counts for {task.name}\")\n    ax.set_xlabel(\"Target\")\n    ax.set_ylabel(\"Count\")\n\n", "CodeBleu_score": 40.714227859647664}]}
{"instance_id": "2f81a906bad5", "generation_result": [{"code": "def render_to_rgb(figure)\n\t\n    if isinstance(figure, list):\n        return np.stack([render_to_rgb(f) for f in figure], axis=0)\n    canvas = plt_backend_agg.FigureCanvasAgg(figure)\n    canvas.draw()\n    width, height = figure.get_size_inches() * figure.get_dpi()\n    width, height = int(width), int(height)\n    image = np.frombuffer(canvas.buffer_rgba(), dtype='uint8').reshape(height, width, 4)\n    plt.close(figure)\n    return np.moveaxis(image[:, :, :3], 2, 0)", "CodeBleu_score": 41.64843650536774}, {"code": "def render_to_rgb(figure)\n\t\n    if isinstance(figure, list):\n        images = [render_to_rgb(f) for f in figure]\n        return np.stack(images)\n    else:\n        canvas = plt_backend_agg.FigureCanvasAgg(figure)\n        canvas.draw()\n        width, height = canvas.get_width_height()\n        data = np.frombuffer(canvas.buffer_rgba(), dtype=np.uint8).reshape(height, width, 4)\n        plt.close(figure)\n        return data[:, :, :3].transpose(2, 0, 1)\n\n", "CodeBleu_score": 43.230211813320054}, {"code": "def render_to_rgb(figure)\n\t\n    if isinstance(figure, list):\n        return np.stack([render_to_rgb(f) for f in figure], axis=0)\n    else:\n        figure.canvas.draw()\n        data = np.frombuffer(figure.canvas.buffer_rgba(), dtype=np.uint8)\n        w, h = figure.canvas.get_width_height()\n        image = data.reshape((h, w, 4))[:, :, :3]\n        plt.close(figure)\n        return np.moveaxis(image, 2, 0)", "CodeBleu_score": 41.001056617395804}]}
{"instance_id": "c3037b01569c", "generation_result": [{"code": "def beholder_pytorch()\n\t\n    beholder = beholder_lib.Beholder(log_dir=\"/tmp/beholder/pytorch_example\")\n    for i in range(1000):\n        tensors = [\n            tensor_and_name(randn(3, 224, 224), \"image\" + str(i)) for i in range(5)\n        ]\n        tensors += [\n            tensor_and_name(randn(1, 224, 224), \"mask\" + str(i)) for i in range(5)\n        ]\n        beholder.update(tensors, frame=str(i))\n        time.sleep(0.01)\n        print(i)\n\n", "CodeBleu_score": 41.1335884895263}, {"code": "def beholder_pytorch()\n\t\n    beholder = Beholder(\"logs/pytorch\")\n    for i in range(1000):\n        tensors_and_names = [\n            tensor_and_name(randn(100, 100, 3), \"random_tensor_\" + str(i)) for i in range(10)\n        ]\n        tensors_and_names += [\n            tensor_and_name(randn(100, 100, 3), \"random_tensor_\" + str(i)) for i in range(10)\n        ]\n        beholder.update(tensors_and_names, frame=i)\n        sleep(0.1)\n        print(i)\n\n", "CodeBleu_score": 35.070376016639294}, {"code": "def beholder_pytorch()\n\t\n    import torch\n    import beholder_lib\n    import time\n\n    beholder = beholder_lib.Beholder(\"./logs/pytorch_example\")\n\n    for i in range(1000):\n        tensors_and_names = [\n            beholder_lib.tensor_and_name(torch.randn(100, 100), \"random_tensor\"),\n            beholder_lib.tensor_and_name(torch.randn(100, 100), \"random_tensor2\"),\n        ]\n        beholder.update(tensors_and_names, frame=i)\n        time.sleep(0.1)\n        print(i)\n\n", "CodeBleu_score": 28.349603949378515}]}
{"instance_id": "cd57b5de8a88", "generation_result": [{"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_data = summary.tensor.float_val\n    if len(tensor_data) == 0:\n        return\n    tensor_data = np.array(tensor_data)\n    if len(tensor_data.shape) == 1:\n        tensor_data = tensor_data.reshape(1, -1)\n    elif len(tensor_data.shape) == 2:\n        tensor_data = tensor_data.reshape(tensor_data.shape[0], -1)\n    else:\n        raise ValueError(\"Tensor data has more than 2 dimensions.\")\n    thresholds = [float(i) / num_thresholds for i in range(num_thresholds + 1)]\n    TP, FP, TN, FN, precision, recall = np.split(tensor_data, 6, axis=1)\n    pr_data = {\n        \"thresholds\": thresholds,\n        \"TP\": TP.flatten().tolist(),\n        \"FP\": FP.flatten().tolist(),\n        \"TN\": TN.flatten().tolist(),\n        \"FN\": FN.flatten().tolist(),\n        \"precision\": precision.flatten().tolist(),\n        \"recall\": recall.flatten().tolist(),\n    }\n    self.log_asset_data(pr_data, tag, step)\n\n", "CodeBleu_score": 38.1998687029681}, {"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_data = summary.tensor.float_val\n    tensor_data = np.fromiter(tensor_data, np.float32)\n    tensor_data = np.reshape(tensor_data, (num_thresholds, 6))\n    thresholds = [i / num_thresholds for i in range(num_thresholds)]\n    tp, fp, tn, fn, precision, recall = np.vsplit(tensor_data, 6)\n    tp = tp.flatten().tolist()\n    fp = fp.flatten().tolist()\n    tn = tn.flatten().tolist()\n    fn = fn.flatten().tolist()\n    precision = precision.flatten().tolist()\n    recall = recall.flatten().tolist()\n    pr_data = {\n        \"thresholds\": thresholds,\n        \"tp\": tp,\n        \"fp\": fp,\n        \"tn\": tn,\n        \"fn\": fn,\n        \"precision\": precision,\n        \"recall\": recall,\n    }\n    self.log_asset_data(pr_data, tag, step)\n\n", "CodeBleu_score": 35.217960668409795}, {"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_values = summary.tensor.float_val\n    tensor_shape = summary.tensor.tensor_shape\n    if len(tensor_shape) == 3:\n        # reshape tensor data\n        tensor_values = np.reshape(tensor_values, (len(tensor_values) // 5, 5))\n    else:\n        # reshape tensor data\n        tensor_values = np.reshape(tensor_values, (len(tensor_values) // 5, 5))\n\n    thresholds = [float(i) / num_thresholds for i in range(num_thresholds + 1)]\n\n    # split tensor values into true positives (TP), false positives (FP), true negatives (TN), false negatives (FN), precision, and recall\n    TP, FP, TN, FN, precision, recall = np.vsplit(tensor_values, 6)\n\n    # flatten each tensor\n    TP = TP.flatten().tolist()\n    FP = FP.flatten().tolist()\n    TN = TN.flatten().tolist()\n    FN = FN.flatten().tolist()\n    precision = precision.flatten().tolist()\n    recall = recall.flatten().tolist()\n\n    # store values in dictionary\n    pr_data = {\n        \"thresholds\": thresholds,\n        \"TP\": TP,\n        \"FP\": FP,\n        \"TN\": TN,\n        \"FN\": FN,\n        \"precision\": precision,\n        \"recall\": recall,\n    }\n\n    # log data\n    self.log_asset_data(pr_data, tag, step)", "CodeBleu_score": 38.08398106042031}]}
{"instance_id": "7c4ea9beecc9", "generation_result": [{"code": "def load_mnist(images, labels, num)\n\t\n    data = np.zeros((num, 784), dtype=np.uint8)\n    target = np.zeros((num,), dtype=np.uint8)\n\n    with gzip.open(images, 'r') as f_images:\n        f_images.read(16)\n        for i in range(num):\n            for j in range(784):\n                data[i, j] = ord(f_images.read(1))\n\n    with gzip.open(labels, 'r') as f_labels:\n        f_labels.read(8)\n        for i in range(num):\n            target[i] = ord(f_labels.read(1))\n\n    return data, target\n\n", "CodeBleu_score": 49.48498583516335}, {"code": "def load_mnist(images, labels, num)\n\t\n    # Initialize empty arrays for the data and target labels\n    data = []\n    target = []\n\n    # Open the image and label files using gzip\n    with gzip.open(images, 'rb') as f_images, gzip.open(labels, 'rb') as f_labels:\n        # Skip the header bytes in both files\n        f_images.read(16)\n        f_labels.read(8)\n\n        # Read the image and label data byte by byte\n        for i in range(num):\n            # Read the image data and store it in the data array\n            data.append(np.frombuffer(f_images.read(28 * 28), dtype=np.uint8).astype(np.float32))\n            # Read the label data and store it in the target array\n            target.append(np.frombuffer(f_labels.read(1), dtype=np.uint8).astype(np.int64))\n\n    # Convert the data and target arrays to NumPy arrays\n    data = np.array(data)\n    target = np.array(target)\n\n    # Return the data and target arrays\n    return data, target\n\n", "CodeBleu_score": 45.19703527808727}, {"code": "def load_mnist(images, labels, num)\n\t\n    data = np.zeros((num, 784), dtype=np.uint8)\n    target = np.zeros((num,), dtype=np.uint8)\n\n    with gzip.open(images, 'r') as f_images:\n        f_images.read(16)\n        for i in range(num):\n            for j in range(784):\n                data[i][j] = ord(f_images.read(1))\n\n    with gzip.open(labels, 'r') as f_labels:\n        f_labels.read(8)\n        for i in range(num):\n            target[i] = ord(f_labels.read(1))\n\n    return data, target\n\n", "CodeBleu_score": 46.58694315311694}]}
{"instance_id": "bf4f1c828b25", "generation_result": [{"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    self.unique_values = {}\n    self.min_max = {}\n    self.cardinality = {}\n    self.len = len(ldf)\n    for attr in ldf.columns:\n        self.unique_values[attr] = list(ldf.data[attr].unique())\n        self.cardinality[attr] = len(ldf.data[attr].unique())\n        if ldf.data[attr].dtype.kind == \"M\":\n            self.unique_values[attr] = [\n                str(val) for val in list(ldf.data[attr].unique())\n            ]\n            self.min_max[attr] = (\n                str(ldf.data[attr].min()),\n                str(ldf.data[attr].max()),\n            )\n        elif is_float_dtype(ldf.data[attr]):\n            self.min_max[attr] = (ldf.data[attr].min(), ldf.data[attr].max())\n        else:\n            self.min_max[attr] = (ldf.data[attr].min(), ldf.data[attr].max())\n            if ldf.data[attr].isin([0, 1]).all():\n                self.unique_values[attr] = [\n                    True if val == 1 else False for val in self.unique_values[attr]\n                ]\n    if not is_integer_dtype(ldf.data.index):\n        self.unique_values[ldf.data.index.name] = list(\n            ldf.data.index.map(str).unique()\n        )\n        self.cardinality[ldf.data.index.name] = len(ldf.data.index.unique())\n    return self", "CodeBleu_score": 33.50745216208503}, {"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    self.cardinality = {}\n    self.min_max = {}\n    self.unique_values = {}\n    self.len = len(ldf)\n    for attr in ldf.columns:\n        self.unique_values[attr] = list(ldf.unique_values[attr])\n        self.cardinality[attr] = len(ldf.unique_values[attr])\n        if ldf.data_type[attr] == \"quantitative\":\n            self.min_max[attr] = (min(ldf.unique_values[attr]), max(ldf.unique_values[attr]))\n    if not isinstance(ldf.data.index, pd.RangeIndex):\n        self.unique_values[ldf.data.index.name] = list(ldf.unique_values[ldf.data.index.name])\n        self.cardinality[ldf.data.index.name] = len(ldf.unique_values[ldf.data.index.name])\n        if ldf.data_type[ldf.data.index.name] == \"quantitative\":\n            self.min_max[ldf.data.index.name] = (\n                min(ldf.unique_values[ldf.data.index.name]),\n                max(ldf.unique_values[ldf.data.index.name]),\n            )\n\n", "CodeBleu_score": 34.125251887645604}, {"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    self.unique_values = {}\n    self.min_max = {}\n    self.cardinality = {}\n    self.len = len(ldf)\n    for attr in ldf.columns:\n        if attr != ldf.intent:\n            self.unique_values[attr] = list(ldf.data[attr].unique())\n            self.cardinality[attr] = len(ldf.data[attr].unique())\n            if pd.api.types.is_integer_dtype(ldf.data[attr]):\n                self.min_max[attr] = (ldf.data[attr].min(), ldf.data[attr].max())\n            elif pd.api.types.is_float_dtype(ldf.data[attr]):\n                self.min_max[attr] = (ldf.data[attr].min(), ldf.data[attr].max())\n            elif pd.api.types.is_datetime64_any_dtype(ldf.data[attr]):\n                self.unique_values[attr] = [\n                    str(val) for val in list(ldf.data[attr].unique())\n                ]\n                self.min_max[attr] = (\n                    str(ldf.data[attr].min()),\n                    str(ldf.data[attr].max()),\n                )\n            else:\n                self.min_max[attr] = (None, None)\n    if not pd.api.types.is_integer_dtype(ldf.data.index):\n        self.unique_values[ldf.data.index.name] = list(ldf.data.index.unique())\n        self.cardinality[ldf.data.index.name] = len(ldf.data.index.unique())\n        self.min_max[ldf.data.index.name] = (\n            str(ldf.data.index.min()),\n            str(ldf.data.index.max()),\n        )", "CodeBleu_score": 34.340980810627656}]}
{"instance_id": "3e6fc3d2f47c", "generation_result": [{"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    preview_query = tbl.preview_query.format(tbl.table_name, preview_size)\n    df = pd.read_sql(preview_query, lux_conn)\n    return df\n\n", "CodeBleu_score": 22.593309736513138}, {"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    preview_query = \"\"\"SELECT * FROM {} LIMIT {}\"\"\".format(\n        tbl.table_name, preview_size\n    )\n    return pd.read_sql(preview_query, con=tbl.conn)\n\n", "CodeBleu_score": 24.660177767993407}, {"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    preview_query = preview_query_template.format(tbl.table_name, preview_size)\n    return pd.read_sql(preview_query, sql_connection)\n\n", "CodeBleu_score": 21.577499843588768}]}
{"instance_id": "b3dee87be4b8", "generation_result": [{"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    def execute_sampling(tbl: LuxSQLTable):\n        \"\"\"\n        Execute sampling on a SQL table.\n\n        Parameters\n        ----------\n        tbl : LuxSQLTable\n            The SQL table to execute sampling on.\n\n        Returns\n        -------\n        None\n\n        Raises\n        ------\n        ValueError\n            If the sampling configuration is invalid.\n        \"\"\"\n        if lux.config.sampling.SAMPLE_FLAG:\n            if lux.config.sampling.SAMPLE_START:\n                start = lux.config.sampling.SAMPLE_START\n                if lux.config.sampling.SAMPLE_CAP:\n                    cap = lux.config.sampling.SAMPLE_CAP\n                    if start > cap:\n                        raise ValueError(\n                            f\"SAMPLE_START ({start}) cannot be greater than SAMPLE_CAP ({cap}).\"\n                        )\n                else:\n                    cap = start + 10000\n                if start < 0:\n                    raise ValueError(\n                        f\"SAMPLE_START ({start}) cannot be negative.\"\n                    )\n            else:\n                start = 0\n                cap = lux.config.sampling.SAMPLE_CAP\n            if not cap:\n                cap = start + 10000\n            if cap < 0:\n                raise ValueError(\n                    f\"SAMPLE_CAP ({cap}) cannot be negative.\"\n                )\n            if start == cap:\n                raise ValueError(\n                    f\"SAMPLE_START ({start}) cannot be equal to SAMPLE_CAP ({cap}).\"\n                )\n            if lux.config.sampling.SAMPLE_FRAC:\n                frac = lux.config.sampling.SAMPLE_FRAC\n                if frac <= 0 or frac > 1:\n                    raise ValueError(\n                        f\"SAMPLE_FRAC ({frac}) must be a number between 0 and 1.\"\n                    )\n            else:\n                frac = 1\n            tbl.length = tbl.length if tbl.length else len(tbl.unique_values)\n            if tbl.length < cap:\n                cap = tbl", "CodeBleu_score": 19.59061500501804}, {"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    if tbl.tableName == \"\":\n        return\n    sample_flag = lux.config.sampling.SAMPLE_FLAG\n    sample_start = lux.config.sampling.SAMPLE_START\n    sample_cap = lux.config.sampling.SAMPLE_CAP\n    sample_frac = lux.config.sampling.SAMPLE_FRAC\n    if sample_flag:\n        if tbl._sampled is not None:\n            return\n        sql = f\"SELECT COUNT(*) AS N FROM {tbl.tableName}\"\n        result = tbl.conn.execute_and_fetch_sql(sql)\n        length = result[0][\"N\"]\n        limit = min(sample_cap, int(length * sample_frac))\n        sql = f\"SELECT * FROM {tbl.tableName} LIMIT {limit} OFFSET {sample_start}\"\n        tbl._sampled = tbl.conn.execute_and_fetch_sql(sql, return_pandas_df=True)\n        tbl._sampled.columns = [col.split(\".\")[1] for col in tbl._sampled.columns]\n\n", "CodeBleu_score": 34.525950059278486}, {"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    if tbl.sampled:\n        return\n    sample_flag = lux.config.sampling\n    sample_start = lux.config.sampling_start\n    sample_cap = lux.config.sampling_cap\n    sample_frac = lux.config.sampling_frac\n\n    if sample_flag:\n        if sample_start is None:\n            sample_start = 0\n        sql = f\"SELECT COUNT(*) AS N FROM {tbl.tableName}\"\n        length = execute_SQL_return_df(sql)[\"N\"].values[0]\n        if sample_cap and length > sample_cap:\n            length = sample_cap\n        if sample_frac and length * sample_frac < sample_cap:\n            limit = int(length * sample_frac)\n        else:\n            limit = sample_cap\n        sql = f\"SELECT * FROM {tbl.tableName} LIMIT {limit} OFFSET {sample_start}\"\n        tbl._sampled = execute_SQL_return_df(sql)\n    else:\n        tbl._sampled = execute_SQL_return_df(f\"SELECT * FROM {tbl.tableName}\")\n    tbl._sampled.columns = [col.replace(\".\", \"_\") for col in tbl._sampled.columns]\n    tbl._sampled.columns = [col.replace(\" \", \"\") for col in tbl._sampled.columns]\n\n", "CodeBleu_score": 31.353467190223633}]}
{"instance_id": "485253b1088a", "generation_result": [{"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n    override_params = params.pop('text')\n    text = override_params.pop('text')\n    x = override_params.pop('x')\n    y = override_params.pop('y')\n    x_min, x_max, y_min, y_max = background.bounds\n    x = np.interp(x, [0, 1], [x_min, x_max])\n    y = np.interp(y, [0, 1], [y_min, y_max])\n    plt.text(x, y, text, **params)\n\n", "CodeBleu_score": 18.407254807254862}, {"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n    override_params(params, \"text\")\n    text = params.pop(\"text\")\n    x = params.pop(\"x\")\n    y = params.pop(\"y\")\n    x_min, x_max, y_min, y_max = background.bounds\n    x = np.interp(x, (0, 1), (x_min, x_max))\n    y = np.interp(y, (0, 1), (y_min, y_max))\n    plt.text(x, y, text, **params)\n\n", "CodeBleu_score": 17.733476908710582}, {"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n    override_params(params, \"text\")\n    text = params.pop(\"text\")\n    x = params.pop(\"x\")\n    y = params.pop(\"y\")\n\n    x_min, x_max, y_min, y_max = background.bounds\n    x = np.interp(x, [0, 1], [x_min, x_max])\n    y = np.interp(y, [0, 1], [y_min, y_max])\n\n    plt.text(x, y, text, **params)", "CodeBleu_score": 19.537377516897948}]}
{"instance_id": "5f70a88b6b72", "generation_result": [{"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n    if datetime_format is not None:\n        return datetime_format\n\n    # Calculate the average number of days between consecutive dates\n    delta_days = np.diff(mdates.date2num(dates)) / (24 * 60 * 60)\n    avg_delta_days = np.mean(delta_days)\n\n    # Check if the data is intraday (i.e., less than 0.33 days between consecutive points)\n    if avg_delta_days < 0.33:\n        # Check if the data spans multiple days\n        if np.max(delta_days) > 1:\n            return '%b %d, %H:%M'\n        else:\n            return '%H:%M'\n    else:\n        # Check if the data spans multiple years\n        if np.max(delta_days) > 365:\n            return '%Y-%b-%d'\n        else:\n            return '%b %d'\n\n\n", "CodeBleu_score": 36.01783921520039}, {"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n    if datetime_format:\n        return datetime_format\n    deltas = np.diff(mdates.date2num(dates))\n    if len(deltas) > 0:\n        delta = np.median(deltas)\n    else:\n        delta = 1.0\n    if delta < 0.33:\n        if span_multiple_days(dates):\n            return '%b %d, %H:%M'\n        else:\n            return '%H:%M'\n    if span_multiple_years(dates):\n        return '%Y-%b-%d'\n    else:\n        return '%b %d'\n", "CodeBleu_score": 29.119913964530753}, {"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n    if datetime_format is not None:\n        return datetime_format\n    deltas = [ dates[i+1] - dates[i] for i in range( len( dates ) - 1 ) ]\n    avg = sum( deltas, datetime.timedelta( 0 ) ) / len( deltas )\n    if avg < datetime.timedelta( days=0.33 ):\n        if dates[-1].day != dates[0].day:\n            return '%b %d, %H:%M'\n        else:\n            return '%H:%M'\n    else:\n        if dates[-1].year != dates[0].year:\n            return '%Y-%b-%d'\n        else:\n            return '%b %d'\n", "CodeBleu_score": 40.20983684295416}]}
{"instance_id": "f9589bf4666d", "generation_result": [{"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if len(c) == 3:\n        return mcolors.to_rgba(c, alpha)\n    elif len(c) == 4:\n        return mcolors.to_rgba(c)\n    else:\n        raise ValueError(\"RGBA must be a 3- or 4-tuple\")\n\n", "CodeBleu_score": 23.76580153738302}, {"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if c.shape == (3,):\n        c = c.reshape((1, 3))\n    if c.shape == (4,):\n        c = c.reshape((1, 4))\n    if c.shape[1] not in (3, 4):\n        raise ValueError(\"Last dimension of input array must be 3 or 4\")\n    if c.dtype == np.uint8:\n        if not _is_uint8_rgb_or_rgba(c):\n            raise ValueError(\"RGB(A) uint8 arrays must be in range-0-255\")\n        c = c / 255\n    if c.shape[1] == 3:\n        c = np.concatenate((c, np.full((len(c), 1), 1)), axis=1)\n    if alpha is not None:\n        c[:, 3] = alpha\n    return mcolors.to_rgba(c)\n\n", "CodeBleu_score": 26.361596077216063}, {"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if len(c) == 3:\n        return (c[0] / 255.0, c[1] / 255.0, c[2] / 255.0, 1.0)\n    if len(c) == 4:\n        return (c[0] / 255.0, c[1] / 255.0, c[2] / 255.0, c[3])\n    if _is_uint8_rgb_or_rgba(c):\n        if any(x > 1 for x in c):\n            c = tuple(x / 255.0 for x in c)\n        if alpha is not None:\n            c = c[:3] + (alpha,)\n        return c\n    return mcolors.to_rgba(c, alpha)", "CodeBleu_score": 37.36489042655386}]}
{"instance_id": "4202e378ab0b", "generation_result": [{"code": "def subplots(self,*args,**kwargs)\n\t\n    if 'style' in kwargs or not hasattr(self,'mpfstyle'):\n        style = _check_for_and_apply_style(self,kwargs.get('style',None))\n        self.mpfstyle = style\n    else:\n        style = self.mpfstyle\n    if isinstance(style,str):\n        style = [style]\n    result = self.fig.subplots(*args,**kwargs)\n    if isinstance(result,Axes):\n        result.mpfstyle = style\n    elif isinstance(result,np.ndarray):\n        for ax in result.flatten():\n            ax.mpfstyle = style\n    else:\n        raise TypeError(\"Unexpected type for 'result' in subplots\")\n    return result", "CodeBleu_score": 55.49541658865378}, {"code": "def subplots(self,*args,**kwargs)\n\t\n    if 'style' in kwargs or not hasattr(self,'mpfstyle'):\n        self.mpfstyle = _check_for_and_apply_style(self,kwargs)\n    else:\n        _check_for_and_apply_style(self,kwargs)\n    subplots = self.figure.subplots(*args,**kwargs)\n    if isinstance(subplots,Axes):\n        subplots.mpfstyle = self.mpfstyle\n    elif isinstance(subplots,ndarray):\n        for ax in subplots.flatten():\n            ax.mpfstyle = self.mpfstyle\n    elif isinstance(subplots,tuple):\n        for ax in subplots:\n            ax.mpfstyle = self.mpfstyle\n    else:\n        raise TypeError(f\"Unexpected type for subplots: {type(subplots)}\")\n    return subplots\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.37694858431863}, {"code": "def subplots(self,*args,**kwargs)\n\t\n    if 'style' in kwargs:\n        _check_for_and_apply_style(self,kwargs['style'])\n    elif not hasattr(self,'mpfstyle'):\n        _check_for_and_apply_style(self,'default')\n    axlist = self.figure.subplots(*args,**kwargs)\n    if isinstance(axlist,Axes):\n        axlist.mpfstyle = self.mpfstyle\n    elif isinstance(axlist,ndarray):\n        for ax in axlist.flatten():\n            if isinstance(ax,Axes):\n                ax.mpfstyle = self.mpfstyle\n            else:\n                raise TypeError('Unexpected type returned by subplots')\n    else:\n        raise TypeError('Unexpected type returned by subplots')\n    return axlist\n\n", "CodeBleu_score": 42.916083670562465}]}
{"instance_id": "3e2b6dfe4753", "generation_result": [{"code": "def _adjust_figsize(fig,config)\n\t\n    if not fig:\n        return\n    if not config.get(\"figure_size\"):\n        ratio = config.get(\"figure_ratio\")\n        if ratio:\n            ratio = float(ratio)\n            if ratio < 0.5 or ratio > 2:\n                raise ValueError(\"figure_ratio must be between 0.5 and 2\")\n            width, height = fig.get_size_inches()\n            if width / height > ratio:\n                height = width / ratio\n            else:\n                width = height * ratio\n            fig.set_size_inches(width, height)\n        return\n    size = config.get(\"figure_size\")\n    if isinstance(size, str):\n        size = size.split(\"x\")\n        if len(size) != 2:\n            raise ValueError(\"figure_size must be in the format 'widthxheight'\")\n        size = [float(s) for s in size]\n    elif isinstance(size, (list, tuple)):\n        if len(size) != 2:\n            raise ValueError(\"figure_size must be a list or tuple of two values\")\n        size = [float(s) for s in size]\n    elif isinstance(size, float):\n        size = [size, size]\n    else:\n        raise ValueError(\"figure_size must be a string, list, or tuple\")\n    fig.set_size_inches(*size)\n\n", "CodeBleu_score": 28.11881816433083}, {"code": "def _adjust_figsize(fig,config)\n\t\n    if fig is None:\n        return\n    if \"figsize\" not in config:\n        ratio = config[\"figratio\"]\n        if ratio > 1.0:\n            ratio = 1.0 / ratio\n        if ratio < 0.1:\n            ratio = 0.1\n        figsize = (fig.get_figwidth(), fig.get_figheight())\n        if figsize[0] > figsize[1]:\n            figsize = (figsize[1] * ratio, figsize[1])\n        else:\n            figsize = (figsize[0], figsize[0] / ratio)\n    else:\n        figsize = config[\"figsize\"]\n    fig.set_size_inches(figsize)\n\n", "CodeBleu_score": 41.439867994334215}, {"code": "def _adjust_figsize(fig,config)\n\t\n    if fig is None:\n        return\n    if \"figsize\" not in config:\n        figratio = config[\"figratio\"]\n        figratio = figratio if figratio is not None else 1\n        figratio = max(figratio, 1.0)\n        figratio = min(figratio, 1.0)\n        figsize = fig.get_size_inches()\n        figsize = (figsize[0], figsize[0] * figratio)\n        fig.set_size_inches(figsize)\n    else:\n        fig.set_size_inches(config[\"figsize\"])\n\n", "CodeBleu_score": 35.4436074389989}]}
{"instance_id": "986e5804b941", "generation_result": [{"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t\n    if apmav is None:\n        mavs = config[\"mavs\"]\n    else:\n        mavs = apmav\n    if apwidth is None:\n        width = config[\"width\"]\n    else:\n        width = apwidth\n    mavp_list = []\n    if isinstance(mavs, dict):\n        for shift, period in mavs.items():\n            mavp = prices.rolling(period).mean()\n            mavp.shift(shift)\n            mavp_list.append(mavp)\n            ax.plot(xdates, mavp, linewidth=width, color=next(ax._get_lines.prop_cycler)[\"color\"])\n    else:\n        for i, period in enumerate(mavs):\n            if i < 7:\n                mavp = prices.rolling(period).mean()\n                mavp_list.append(mavp)\n                ax.plot(xdates, mavp, linewidth=width, color=next(ax._get_lines.prop_cycler)[\"color\"])\n    return mavp_list\n\n", "CodeBleu_score": 34.91857666547561}, {"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t\n    if apmav is None:\n        mavp_list=[]\n        if isinstance(config['mav'],dict):\n            for shift,period in config['mav'].items():\n                if len(mavp_list)>=7:\n                    break\n                mavp=prices.rolling(period).mean().shift(shift)\n                mavp_list.append(mavp)\n        else:\n            for shift,period in config['mav']:\n                if len(mavp_list)>=7:\n                    break\n                mavp=prices.rolling(period).mean().shift(shift)\n                mavp_list.append(mavp)\n    else:\n        mavp_list=apmav\n    for i,mavp in enumerate(mavp_list):\n        if i>=7:\n            break\n        if apwidth is None:\n            ax.plot(xdates,mavp,linewidth=config['mav_width'],color=config['mav_color'][i%len(config['mav_color'])])\n        else:\n            ax.plot(xdates,mavp,linewidth=apwidth,color=config['mav_color'][i%len(config['mav_color'])])\n    return mavp_list\n\n", "CodeBleu_score": 33.18414707862137}, {"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t\n    if apmav is None:\n        mavp_list = []\n        mavp_dict = config['mavp']\n        if isinstance(mavp_dict,dict):\n            shift_list = mavp_dict['shift']\n            period_list = mavp_dict['period']\n        else:\n            shift_list = [0]\n            period_list = mavp_dict\n        for i,period in enumerate(period_list):\n            if i > 6:\n                break\n            shift = shift_list[i]\n            mavp = prices.rolling(period).mean()\n            mavp_list.append(mavp)\n            mavp = mavp.shift(shift)\n            ax.plot(xdates,mavp,linewidth=apwidth,color=config['mavcolors'][i])\n        return mavp_list\n\n", "CodeBleu_score": 31.09189837455476}]}
{"instance_id": "5308e20f3c90", "generation_result": [{"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    kernel_height, kernel_width = opnode.inputs[1].shape[2:]\n    input_channels = opnode.inputs[0].shape[1]\n    total_output_elements = np.prod(outputs[0].shape)\n    flops = total_output_elements * input_channels * kernel_height * kernel_width\n    if len(opnode.inputs) == 3:\n        flops += total_output_elements\n    return flops\n\n", "CodeBleu_score": 23.649539291602746}, {"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    kernel_h, kernel_w = opnode.kernel_shape\n    input_channels = inputs[0].shape[1]\n    output_h, output_w = outputs[0].shape[2:]\n    total_output_elements = output_h * output_w\n    bias_flops = 1 if opnode.with_bias else 0\n    return (\n        total_output_elements\n        * (kernel_h * kernel_w * input_channels + bias_flops)\n        * 2\n    )\n\n", "CodeBleu_score": 21.58106806753548}, {"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    assert len(inputs) == 1\n    assert len(outputs) == 1\n    x = inputs[0]\n    y = outputs[0]\n    assert x.ndim == 4\n    assert y.ndim == 4\n    assert x.shape[0] == y.shape[0]\n    assert x.shape[2:] == y.shape[2:]\n    kernel_ops = opnode.params.kernel[0] * opnode.params.kernel[1]\n    bias_ops = 1 if opnode.params.bias else 0\n    kernel_ops *= x.shape[1]\n    total_ops = kernel_ops * y.size\n    total_ops += bias_ops\n    return total_ops\n\n", "CodeBleu_score": 30.60529193659882}]}
{"instance_id": "70811d3cf578", "generation_result": [{"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    mge_dtype = np.dtype(mge_dtype)\n    assert isinstance(mge_dtype, np.dtype)\n    return _dtype_to_ir_type[mge_dtype](mge_dtype)", "CodeBleu_score": 21.40981359960167}, {"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    mge_dtype = np.dtype(mge_dtype)\n    assert isinstance(mge_dtype, np.dtype)\n    return _dtype_to_ir_type[mge_dtype](mge_dtype)", "CodeBleu_score": 21.40981359960167}, {"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    mge_dtype = np.dtype(mge_dtype)\n    assert isinstance(mge_dtype, np.dtype)\n    return _dtype_to_ir_type[mge_dtype](mge_dtype)\n\n", "CodeBleu_score": 21.40981359960167}]}
{"instance_id": "a108c9ba2c22", "generation_result": [{"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = np.ascontiguousarray(x, dtype=dtype.canonicalize_dtype(x.dtype))\n    ir_type = mge_dtype_to_ir_type(x.dtype)\n    if ir_type == ir.IntegerType.BOOL:\n        x = np.packbits(x)\n    elif ir_type == ir.F32:\n        x = x.astype(np.float32)\n    elif ir_type == ir.BF16:\n        x = x.astype(np.bfloat16)\n    elif ir_type == ir.F64:\n        x = x.astype(np.float64)\n    return [ir.ops.constant(x.view(dtype=np.uint8), ir_type)]\n\n", "CodeBleu_score": 39.96196182656845}, {"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = x.astype(canonicalize_dtype(x.dtype))\n    ir_type = mge_dtype_to_ir_type(x.dtype)\n    if ir_type == ir.bool():\n        x = x.astype(np.uint8)\n    if ir_type == ir.bfloat16():\n        x = x.astype(np.float32)\n    x = np.ascontiguousarray(x)\n    if x.dtype.itemsize > 1:\n        x = x.view(dtype=np.uint8)\n    elements = get(ir_type, x)\n    return [hlo.ConstantOp(elements).results[0]]", "CodeBleu_score": 40.74179177467695}, {"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = np.ascontiguousarray(x)\n    dtype = mge_dtype_to_ir_type(x.dtype)\n    if dtype == ir.BoolType.get():\n        x = np.packbits(x, axis=None, bitorder=\"little\")\n        x = x.view(np.uint8)\n    elif dtype == ir.BF16Type.get():\n        x = x.astype(np.uint16)\n    x = np.asarray(x, dtype=dtype.get_dtype())\n    elements_attr = ir.DenseElementsAttr.get(x)\n    return [hlo.ConstantOp(elements_attr).get_result()]\n\n", "CodeBleu_score": 47.6099934356}]}
{"instance_id": "3345fe4d008b", "generation_result": [{"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if val.strides.count(0) > 0 and val.size > 0:\n        zero_stride_axes = [i for i, s in enumerate(val.strides) if s == 0]\n        non_zero_stride_axes = [\n            i for i, s in enumerate(val.strides) if s != 0\n        ]\n        val = val.transpose(non_zero_stride_axes + zero_stride_axes)\n        val = val.reshape(val.shape[: len(non_zero_stride_axes)])\n        if canonicalize_types:\n            val = val.astype(val.dtype.canonicalize_dtype())\n        val = _numpy_array_constant(val)\n        return [\n            hlo.BroadcastInDimOp(\n                val,\n                shape=val.shape,\n                broadcast_dimensions=tuple(\n                    range(len(val.shape), len(val.shape) + len(zero_stride_axes))\n                ),\n            ).results[0]\n        ]\n    else:\n        return _numpy_array_constant(val, canonicalize_types)\n\n", "CodeBleu_score": 39.58383086432976}, {"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if val.size == 0:\n        return _numpy_array_constant(val, canonicalize_types)\n    if not val.flags.c_contiguous:\n        val = np.ascontiguousarray(val)\n    if val.strides == (0,) * val.ndim:\n        return _numpy_array_constant(val, canonicalize_types)\n    zero_stride_axes = tuple(\n        i for i, stride in enumerate(val.strides) if stride == 0\n    )\n    non_zero_stride_axes = tuple(\n        i for i, stride in enumerate(val.strides) if stride != 0\n    )\n    collapsed_val = val.transpose(non_zero_stride_axes)[0]\n    if canonicalize_types:\n        collapsed_val = collapsed_val.astype(\n            dtype.canonicalize_dtype(collapsed_val.dtype)\n        )\n    collapsed_val_ir = _numpy_array_constant(collapsed_val, False)\n    broadcast_op = hlo.BroadcastInDimOp(\n        collapsed_val_ir,\n        shape=val.shape,\n        broadcast_dimensions=zero_stride_axes,\n    )\n    return broadcast_op.results\n\n", "CodeBleu_score": 41.717120636385445}, {"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if np.any(val.strides == 0) and val.size > 0:\n        zero_stride_axes = [i for i, stride in enumerate(val.strides) if stride == 0]\n        non_zero_stride_axes = [\n            i for i, stride in enumerate(val.strides) if stride != 0\n        ]\n        collapsed_val = np.squeeze(val, axis=tuple(zero_stride_axes))\n        if canonicalize_types:\n            collapsed_val = collapsed_val.astype(\n                dtype.canonicalize_dtype(collapsed_val.dtype), copy=False\n            )\n        collapsed_val_ir = _numpy_array_constant(collapsed_val)\n        broadcast_op = hlo.BroadcastInDimOp(\n            collapsed_val_ir,\n            collapsed_val.shape,\n            np.array(non_zero_stride_axes, dtype=np.int64),\n        )\n        return [broadcast_op]\n    else:\n        return _numpy_array_constant(val, canonicalize_types)\n\n", "CodeBleu_score": 43.887644091295556}]}
{"instance_id": "91b298678351", "generation_result": [{"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    packed = np.packbits(xs, bitorder=\"little\")\n    if len(xs) == 1:\n        packed = np.zeros_like(packed) if xs[0] else np.ones_like(packed)\n    return ir.DenseElementsAttr.get(\n        np.array(packed, dtype=np.uint8), type=ir.IntegerType.get_signless(1)\n    ).reshape((len(xs),))\n\n", "CodeBleu_score": 46.22141004379542}, {"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    packed = np.packbits(np.array(xs, dtype=np.uint8), bitorder=\"little\")\n    if len(xs) == 1:\n        packed = np.array([packed[0]], dtype=np.uint8)\n    return ir.DenseElementsAttr.get(packed, ir.IntegerType.get_signless(1), shape=len(xs))\n\n", "CodeBleu_score": 47.21093162935561}, {"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    packed = np.packbits(xs, bitorder=\"little\")\n    if len(xs) == 1:\n        packed = np.zeros(1, dtype=np.uint8) if xs[0] else np.ones(1, dtype=np.uint8)\n    return ir.DenseElementsAttr.get(\n        np.array(packed, dtype=np.uint8), type=ir.IntegerType.get_signless(1)\n    ).reshape((len(xs),))\n\n", "CodeBleu_score": 49.61178914249793}]}
{"instance_id": "06ebabf1e0ff", "generation_result": [{"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == 1\n    assert len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    input_var = ctx.vars_in[0]\n    output_var = ctx.vars_out[0]\n    if input_var.bound_data is not None:\n        ctx.module.set_value(input_var, args[0])\n        ctx.module.set_value(output_var, args[0])\n    else:\n        raise AssertionError(\"Only tensor creation from constants is supported\")\n    assert input_var.shape == output_var.shape\n    if output_var.bound_data is not None:\n        output_data = np.asarray(output_var.bound_data, dtype=output_var.dtype)\n    elif input_var.bound_data is not None:\n        output_data = np.asarray(input_var.bound_data, dtype=output_var.dtype)\n    else:\n        raise AssertionError(\"Only tensor creation from constants is supported\")\n    return HLOTensor(output_data, dtype=output_var.dtype)\n\n", "CodeBleu_score": 49.92764606360305}, {"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == 1\n    assert len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n\n    input_var = ctx.vars_in[0]\n    output_var = ctx.vars_out[0]\n\n    if input_var.bound_data is not None:\n        ctx.module.set_value(input_var, np.asarray(input_var.bound_data))\n        ctx.module.set_value(output_var, np.asarray(input_var.bound_data))\n    else:\n        raise AssertionError(\n            \"Only tensor creation from constants is supported at this time.\"\n        )\n\n    assert output_var.shape == input_var.shape\n\n    if output_var.bound_data is not None:\n        output_var.bound_data = np.asarray(output_var.bound_data, dtype=output_var.dtype)\n    else:\n        output_var.bound_data = np.asarray(input_var.bound_data, dtype=output_var.dtype)\n\n    return HLOTensor(output_var)\n\n", "CodeBleu_score": 51.1296631140878}, {"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == 1\n    assert len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n\n    input_var = ctx.vars_in[0]\n    output_var = ctx.vars_out[0]\n\n    if input_var.bound_data is not None:\n        ctx.module.set_value(input_var.name, input_var.bound_data)\n        ctx.module.set_value(output_var.name, input_var.bound_data)\n\n    assert (\n        input_var.shape == output_var.shape\n    ), f\"Shape mismatch: {input_var.shape} vs {output_var.shape}\"\n\n    if output_var.bound_data is not None:\n        data = np.asarray(output_var.bound_data, dtype=output_var.dtype)\n    elif input_var.bound_data is not None:\n        data = np.asarray(input_var.bound_data, dtype=output_var.dtype)\n    else:\n        assert False, \"Only tensor creation from constants is supported\"\n\n    return HLOTensor(data)\n\n", "CodeBleu_score": 57.737295369944164}]}
{"instance_id": "6cd750fa0c8d", "generation_result": [{"code": "def _device_put_scalar(x, device)\n\t\n    return _device_put(np.asarray(_scalar_type_to_dtype(x)), device)\n\n", "CodeBleu_score": 10.553010583149439}, {"code": "def _device_put_scalar(x, device)\n\t\n    if not isinstance(x, np.ndarray):\n        x = _scalar_to_numpy(x)\n    return _device_put(x, device)\n\n", "CodeBleu_score": 21.21272595827164}, {"code": "def _device_put_scalar(x, device)\n\t\n    return _device_put(np.asarray(_scalar_to_dtype(x)), device)\n\n", "CodeBleu_score": 10.201817416918992}]}
{"instance_id": "140de7c2b6a8", "generation_result": [{"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = lhs_shape.tolist()\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = rhs_shape.tolist()\n    assert isinstance(lhs_shape, (tuple, list))\n    assert isinstance(rhs_shape, (tuple, list))\n    if len(lhs_shape) == 0:\n        return True\n    assert isinstance(lhs_shape[0], int)\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for lhs_dim, rhs_dim in zip(lhs_shape, rhs_shape):\n        if lhs_dim != rhs_dim:\n            return False\n    return True\n\n", "CodeBleu_score": 45.48750292895068}, {"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = lhs_shape.tolist()\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = rhs_shape.tolist()\n    assert isinstance(lhs_shape, (tuple, list))\n    assert isinstance(rhs_shape, (tuple, list))\n    if len(lhs_shape) == 0 and len(rhs_shape) == 0:\n        return True\n    assert isinstance(lhs_shape[0], int)\n    assert isinstance(rhs_shape[0], int)\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for lhs_dim, rhs_dim in zip(lhs_shape, rhs_shape):\n        if lhs_dim != rhs_dim:\n            return False\n    return True\n\n", "CodeBleu_score": 50.94043049654204}, {"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = lhs_shape.tolist()\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = rhs_shape.tolist()\n    assert isinstance(lhs_shape, (tuple, list)) and isinstance(rhs_shape, (tuple, list))\n    if len(lhs_shape) == 0 and len(rhs_shape) == 0:\n        return True\n    if len(lhs_shape) > 0:\n        assert isinstance(lhs_shape[0], int)\n    if len(rhs_shape) > 0:\n        assert isinstance(rhs_shape[0], int)\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for lhs_dim, rhs_dim in zip(lhs_shape, rhs_shape):\n        if lhs_dim != rhs_dim:\n            return False\n    return True\n\n", "CodeBleu_score": 54.88020440195655}]}
{"instance_id": "55d0c71a259b", "generation_result": [{"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n    train = pd.read_csv(training_set_filename, dtype=dtypes)\n    test = pd.read_csv(test_set_filename, dtype=dtypes)\n    train_meta = pd.read_csv(training_set_metadata_filename, dtype=meta_dtypes)\n    test_meta = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    meta_dtypes.pop(\"target\")\n    test_meta = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    meta_dtypes[\"target\"] = \"int8\"\n    return train, test, train_meta, test_meta\n\n", "CodeBleu_score": 52.13860737002026}, {"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n    train = pd.read_csv(training_set_filename, dtype=dtypes)\n    test = pd.read_csv(test_set_filename, dtype=dtypes)\n\n    train_meta = pd.read_csv(training_set_metadata_filename, dtype=meta_dtypes)\n    test_meta = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    test_meta[\"target\"] = train_meta[\"target\"]\n    return train, test, train_meta, test_meta\n\n", "CodeBleu_score": 33.68604411669806}, {"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n    train = pd.read_csv(training_set_filename, dtype=dtypes)\n    test = pd.read_csv(test_set_filename, dtype=dtypes)\n    train_meta = pd.read_csv(training_set_metadata_filename, dtype=meta_dtypes)\n    test_meta = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    meta_dtypes.pop(\"target\")\n    test_meta = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    meta_dtypes[\"target\"] = \"int8\"\n    return train, test, train_meta, test_meta\n\n", "CodeBleu_score": 52.13860737002026}]}
{"instance_id": "9e5e02cd73e0", "generation_result": [{"code": "def _show_cmap(cmap)\n\t\n    from matplotlib import rcParams as rcmod\n    axes_style = rcmod.axes_style()\n    fig, ax = plt.subplots(1, 1, figsize=(8, 0.5), subplot_kw=dict(xticks=[], yticks=[]))\n    ax.set(frame_on=False,\n           xlim=[0, 1],\n           ylim=[0, 1])\n    ax.pcolormesh(np.linspace(0, 1, 256).reshape(1, -1), cmap=cmap)\n\n", "CodeBleu_score": 44.10910756485602}, {"code": "def _show_cmap(cmap)\n\t\n    from rcmod import axes_style\n    fig, ax = plt.subplots(figsize=(8, 2), dpi=200)\n    ax.set_axis_off()\n    data = np.linspace(0.0, 1.0, 256).reshape(1, -1)\n    ax.pcolormesh(data, cmap=cmap)\n\n", "CodeBleu_score": 41.87004310162148}, {"code": "def _show_cmap(cmap)\n\t\n    from rcmod import axes_style\n    fig, ax = plt.subplots(figsize=(8, 2))\n    ax.set_axis_off()\n    ax.imshow(np.linspace(0, 1, 256)[None], aspect='auto', cmap=cmap)\n    return\n\n", "CodeBleu_score": 31.838103007102482}]}
{"instance_id": "ad0781b5cc38", "generation_result": [{"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    if obj.axes is not None and obj.get_transform() != obj.axes.transData:\n        points = obj.get_transform().transform(np.array((xdata, ydata)))\n        return points[:, 0], points[:, 1]\n    else:\n        return xdata, ydata\n\n", "CodeBleu_score": 52.66935725366473}, {"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    if obj.axes is not None and obj.get_transform() != obj.axes.transData:\n        points = np.array(xdata, ydata)\n        transData = obj.axes.transData\n        points = transData.transform(points)\n        points = obj.get_transform().inverted().transform(points)\n        return points[:, 0], points[:, 1]\n    else:\n        return xdata, ydata\n\n", "CodeBleu_score": 64.257898749743}, {"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    if obj.axes is not None and obj.get_transform() != obj.axes.transData:\n        points = np.array(xdata), np.array(ydata)\n        transform = obj.get_transform()\n        data_transform = obj.axes.transData.inverted()\n        composite_transform = transform + data_transform\n        return composite_transform.transform(points)\n    else:\n        return xdata, ydata\n\n", "CodeBleu_score": 62.952079308220036}]}
{"instance_id": "bf776cadef8d", "generation_result": [{"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n    data = self._maybe_target_series(data, 'data')\n    if data2 is not None and not is_list_like(data2):\n        data2 = self._df[data2]\n    return self._module.kdeplot(data, data2, *args, **kwargs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 56.13783295127991}, {"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n    data = self._maybe_target_series(data, 'data')\n    if data2 is not None and not is_list_like(data2):\n        data2 = self._df[data2]\n    return self._module.kdeplot(data, data2, *args, **kwargs)", "CodeBleu_score": 56.13783295127991}, {"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n    data = self._maybe_target_series(data, 'data')\n    if data2 is not None and not is_list_like(data2):\n        data2 = self._df[data2]\n    return self._module.kdeplot(data, data2, *args, **kwargs)\n\n", "CodeBleu_score": 56.13783295127991}]}
{"instance_id": "fb44964174d9", "generation_result": [{"code": "def plot_most_used_words(df)\n\t\n\n    # Correct \"programa\" to \"programar\"\n    df['text'] = df['text'].str.replace('programa', 'programar')\n\n    # Tokenize the text and remove stop words\n    tokens = df['text'].apply(lambda x: word_tokenize(x, language='spanish'))\n    stop_words = set(stopwords.words('spanish'))\n    tokens = tokens.apply(lambda x: [word for word in x if word.isalpha() and len(word) > 1 and word.lower() not in stop_words])\n\n    # Count the occurrences of each word\n    word_counts = Counter([word for sublist in tokens for word in sublist])\n\n    # Select the top 20 most frequent words\n    top_words = word_counts.most_common(20)\n\n    # Create a bar plot of the word counts\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x=[word[0] for word in top_words], y=[word[1] for word in top_words])\n    plt.xticks(rotation=45)\n    plt.xlabel('Palabras')\n    plt.ylabel('Frecuencia')\n    plt.title('Palabras m\u00e1s frecuentes')\n    plt.savefig('top_words.png')\n\n", "CodeBleu_score": 32.632480063371105}, {"code": "def plot_most_used_words(df)\n\t\n    # Correct the word \"programa\" to \"programar\"\n    df[\"text\"] = df[\"text\"].str.replace(\"programa\", \"programar\")\n\n    # Filter the dataframe to include only alphabetic tokens that are longer than one character and are not stop words\n    tokens = df[\"text\"].apply(lambda x: [word for word in x.split() if word.isalpha() and len(word) > 1 and word not in stopwords])\n\n    # Count the occurrences of these words\n    word_counts = Counter([word for sublist in tokens for word in sublist])\n\n    # Select the top 20 most frequent words\n    top_words = word_counts.most_common(20)\n\n    # Create a bar plot showing the frequency of these words\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x=[word[0] for word in top_words], y=[word[1] for word in top_words])\n    plt.xlabel(\"Word\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Most Frequent Words\")\n    plt.xticks(rotation=90)\n    plt.savefig(\"most_frequent_words.png\")\n    plt.show()\n\n", "CodeBleu_score": 34.50302009040299}, {"code": "def plot_most_used_words(df)\n\t\n    df['text'] = df['text'].str.replace('programa', 'programar')\n    df = df[df['text'].str.isalpha()]\n    df = df[df['text'].str.len() > 1]\n    df = df[~df['text'].isin(stopwords)]\n    df = df['text'].value_counts()\n    df = df.head(20)\n    plt.figure(figsize=(10, 5))\n    plt.bar(df.index, df.values)\n    plt.xticks(rotation=90)\n    plt.xlabel('Palabras')\n    plt.ylabel('Frecuencia')\n    plt.title('Palabras m\u00e1s frecuentes')\n    plt.savefig('../img/most_used_words.png')\n\n", "CodeBleu_score": 34.23033687691525}]}
{"instance_id": "13414a7eb4e3", "generation_result": [{"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n    import dask.array as da\n\n    a = a.astype(a.dtype.name, casting=\"safe\", copy=False)\n    depth = {\n        \"backward\": window - 1,\n        \"forward\": window - 1,\n        \"center\": window // 2,\n        \"nearest\": 0,\n    }[moving_func.__name__]\n    boundary = {\n        \"backward\": a[..., 0],\n        \"forward\": a[..., -1],\n        \"center\": 0.5 * (a[..., 0] + a[..., -1]),\n        \"nearest\": None,\n    }[moving_func.__name__]\n\n    ag = da.overlap.overlap(\n        a, depth=depth, boundary=boundary, axis=axis, trim=False\n    )\n    out = da.map_blocks(\n        moving_func, ag, window, min_count=min_count, axis=axis\n    )\n    out = da.overlap.trim_internal(out, depth, axis=axis)\n\n    return out\n\n", "CodeBleu_score": 40.2902751326497}, {"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n\n    import dask.array as da\n    import numpy as np\n\n    a = a.astype(a.dtype.type)\n    overlap = window // 2\n    fill_value = a.dtype.type(np.nan)\n\n    # Set boundary fill values\n    boundary = {\n        axis: fill_value\n    }\n\n    # Calculate depth of overlap\n    depth = {\n        axis: overlap\n    }\n\n    # Create overlapped array\n    ag = da.overlap.overlap(a, depth=depth, boundary=boundary)\n\n    # Apply moving function\n    result = da.map_blocks(\n        moving_func,\n        ag,\n        window=window,\n        min_count=min_count,\n        axis=axis,\n        dtype=a.dtype.type\n    )\n\n    # Trim overlapped regions\n    result = da.overlap.trim_internal(result, depth)\n\n    return result\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 48.17308285737906}, {"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n    import dask.array as da\n    from dask.array.overlap import overlap\n    from dask.array.overlap import trim_internal\n\n    a = a.astype(a.dtype.type().maybe_promote(a.dtype))\n\n    depth = {d: 0 for d in range(a.ndim)}\n    depth[axis] = window\n\n    boundary = {d: fill_value(a.dtype) for d in range(a.ndim)}\n\n    ag = overlap(a, depth=depth, boundary=boundary)\n\n    res = da.map_blocks(\n        moving_func, ag, window, min_count=min_count, axis=axis, dtype=a.dtype\n    )\n\n    return trim_internal(res, depth)\n\n", "CodeBleu_score": 57.59808358973895}]}
{"instance_id": "68ce25d325d4", "generation_result": [{"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n\n    # Convert input arrays to Dask arrays\n    lhs = da.from_array(lhs, chunks=(lhs.shape[0], -1))\n    rhs = da.from_array(rhs, chunks=(rhs.shape[0], -1))\n\n    # Handle missing values if skipna is True\n    if skipna:\n        # Reshape rhs if necessary\n        if rhs.ndim == 1:\n            rhs = rhs.reshape(-1, 1)\n        # Apply polynomial fit along axis 0\n        coeffs, residuals, rank, s = da.linalg.lstsq(lhs, rhs, rcond=rcond)\n    else:\n        # Directly compute least squares solution\n        coeffs, residuals, rank, s = da.linalg.lstsq(lhs, rhs, rcond=rcond)\n\n    return coeffs, residuals\n\n", "CodeBleu_score": 25.778445123864337}, {"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n    lhs = da.from_array(lhs, chunks=(chunk_size, chunk_size))\n    rhs = da.from_array(rhs, chunks=(chunk_size,))\n\n    if skipna:\n        # Reshape rhs if necessary\n        if rhs.ndim == 1:\n            rhs = rhs.reshape((rhs.size, 1))\n\n        # Apply polynomial fit along axis 0\n        coeffs, residuals, _, _ = da.linalg.lstsq(lhs, rhs, rcond=rcond)\n    else:\n        # Directly compute least squares solution\n        coeffs, residuals, _, _ = da.linalg.lstsq(lhs, rhs, rcond=rcond)\n\n    return coeffs, residuals", "CodeBleu_score": 25.073167320536406}, {"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n    lhs = da.from_array(lhs, chunks=(rhs.chunks[0], -1))\n    rhs = da.from_array(rhs, chunks=(rhs.chunks[0], -1))\n    if skipna:\n        if lhs.ndim > 1:\n            lhs = lhs.reshape(-1, lhs.shape[-1])\n            rhs = rhs.reshape(-1, rhs.shape[-1])\n        coeffs, residuals, rank, s = da.linalg.lstsq(lhs, rhs)\n        coeffs = coeffs.reshape(rhs.shape[1:] + lhs.shape[1:])\n        residuals = residuals.reshape(rhs.shape[1:] + lhs.shape[1:])\n    else:\n        coeffs, residuals, rank, s = da.linalg.lstsq(lhs, rhs)\n    return coeffs, residuals", "CodeBleu_score": 35.984918891230514}]}
{"instance_id": "c0c2c53b76e0", "generation_result": [{"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n    if isinstance(data, ImplicitToExplicitIndexingAdapter):\n        kwargs[\"meta\"] = np.ndarray\n    return da.from_array(data, chunks, **kwargs)", "CodeBleu_score": 60.97084684521099}, {"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n        if isinstance(data, ImplicitToExplicitIndexingAdapter):\n            kwargs[\"meta\"] = np.ndarray\n        return da.from_array(data, chunks, **kwargs)", "CodeBleu_score": 62.7429358366068}, {"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n    if isinstance(data, ImplicitToExplicitIndexingAdapter):\n        kwargs[\"meta\"] = np.ndarray\n    return da.from_array(data, chunks, **kwargs)", "CodeBleu_score": 60.97084684521099}]}
{"instance_id": "6559019d09a0", "generation_result": [{"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n    if not is_duck_dask_array(self.data):\n        raise AttributeError\n    func, args = self.data.__dask_postpersist__()\n\n    def finalize(\n            graph: Graph,\n            func: PostPersistCallable[Any],\n            *args: Any,\n            **kwargs: Any,\n        ) -> Self:\n        return self\n\n    return finalize, (func, *args)\n\n", "CodeBleu_score": 51.19675076304815}, {"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n    if not is_duck_dask_array(self.data):\n        raise AttributeError(\n            \"__dask_postpersist__ is only defined on Dask arrays\",\n        )\n    func, args = self.data.__dask_postpersist__()\n\n    def finalize(\n            graph: Graph,\n            func: PostPersistCallable[Any],\n            *args: Any,\n            **kwargs: Any,\n    ) -> Self:\n        return func(graph, *args, **kwargs)\n\n    return finalize, (func, *args)\n\n", "CodeBleu_score": 49.35106096348656}, {"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n    if is_duck_dask_array(self.data):\n        (finalize, args) = self.data.__dask_postpersist__(\n            self.graph,\n            self.finalize,\n            self.data,\n            *self.args,\n        )\n        return (finalize, (self, *args))\n    else:\n        raise AttributeError(\n            \"__dask_postpersist__ is only defined on dask arrays\",\n        )\n\n", "CodeBleu_score": 48.16472903633141}]}
{"instance_id": "4a2801bb3851", "generation_result": [{"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n\n    def f(*args, **kwargs):\n        if any(is_duck_dask_array(a) for a in args):\n            if isinstance(dask_module, str):\n                dask_module = import_module(dask_module)\n            f = getattr(dask_module, name)\n        else:\n            f = getattr(eager_module, name)\n        return f(*args, **kwargs)\n\n    return f\n\n", "CodeBleu_score": 61.90389719428342}, {"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n\n    def f(*args, **kwargs):\n        if any(is_duck_dask_array(a) for a in args):\n            if isinstance(dask_module, str):\n                dask_module = import_module(dask_module)\n            f = getattr(dask_module, name)\n        else:\n            f = getattr(eager_module, name)\n        return f(*args, **kwargs)\n\n    return f\n\n", "CodeBleu_score": 61.90389719428342}, {"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n\n    def f(*args, **kwargs):\n        if any(is_duck_dask_array(a) for a in args):\n            if isinstance(dask_module, str):\n                dask_module = import_module(dask_module)\n            f = getattr(dask_module, name)\n        else:\n            f = getattr(eager_module, name)\n        return f(*args, **kwargs)\n\n    return f\n\n", "CodeBleu_score": 61.90389719428342}]}
{"instance_id": "eef8d746d01e", "generation_result": [{"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    if arr1.shape != arr2.shape:\n        return False\n    if is_duck_dask_array(arr1, arr2):\n        return tokenize(arr1) == tokenize(arr2)\n    return None\n\n", "CodeBleu_score": 57.03999595489759}, {"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    if arr1.shape != arr2.shape:\n        return False\n    if is_duck_dask_array(arr1) and is_duck_dask_array(arr2):\n        tok1 = tokenize(arr1)\n        tok2 = tokenize(arr2)\n        if tok1 == tok2:\n            return True\n        else:\n            return None\n    else:\n        return None\n\n", "CodeBleu_score": 80.01583961366433}, {"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    if arr1.shape != arr2.shape:\n        return False\n    if is_duck_dask_array(arr1, arr2):\n        return tokenize(arr1) == tokenize(arr2)\n    return None\n\n", "CodeBleu_score": 57.03999595489759}]}
{"instance_id": "15e830ff5fcb", "generation_result": [{"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    if chunks is None:\n        arr = rng.standard_normal(shape, chunks=chunks)\n    else:\n        arr = rng.standard_normal(shape, chunks=chunks)\n    if frac_nan is not None:\n        n_nans = int(np.ceil(frac_nan * np.prod(shape)))\n        nan_idx = rng.choice(np.prod(shape), size=n_nans, replace=False)\n        arr = arr.flatten()\n        arr[nan_idx] = np.nan\n        arr = arr.reshape(shape)\n    return arr\n\n", "CodeBleu_score": 51.722332931004345}, {"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    if chunks is not None:\n        x = da.random.normal(size=shape, chunks=chunks)\n    else:\n        x = np.random.randn(*shape)\n    if frac_nan is not None:\n        inds = rng.choice(\n            np.arange(x.size), replace=False, size=int(x.size * frac_nan)\n        )\n        x.flat[inds] = np.nan\n    return x\n\n", "CodeBleu_score": 49.39013565291887}, {"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    if chunks:\n        x = da.random.standard_normal(shape, chunks=chunks)\n    else:\n        x = np.random.standard_normal(shape)\n    if frac_nan:\n        inds = rng.choice(range(x.size), int(x.size * frac_nan), replace=False)\n        x.flat[inds] = np.nan\n    return x\n\n", "CodeBleu_score": 49.743415284884364}]}
{"instance_id": "5b57abbbe38b", "generation_result": [{"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError(\"analyst_price_target\")\n    return self._analyst_price_target", "CodeBleu_score": 81.06081450739325}, {"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError(\"analyst_price_target\")\n    return self._analyst_price_target\n\n", "CodeBleu_score": 81.06081450739325}, {"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError(\"analyst_price_target\")\n    return self._analyst_price_target", "CodeBleu_score": 81.06081450739325}]}
{"instance_id": "592e414671e9", "generation_result": [{"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n    if name not in self.allowed_financials:\n        raise ValueError(\n            f\"Financial statement {name} not allowed. Allowed financials are {self.allowed_financials}\"\n        )\n    if timescale not in self.allowed_periods:\n        raise ValueError(\n            f\"Timescale {timescale} not allowed. Allowed periods are {self.allowed_periods}\"\n        )\n    try:\n        return self._create_financials_table(name, timescale, proxy)\n    except ValueError as e:\n        logger = utils.get_yf_logger()\n        logger.error(f\"Error creating financials table: {e}\")\n        return pd.DataFrame()\n\n", "CodeBleu_score": 38.579396242492635}, {"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n    if name not in self._allowed_financials:\n        raise ValueError(f\"{name} is not an allowed financial statement.\")\n    if timescale not in self._allowed_periods:\n        raise ValueError(f\"{timescale} is not an allowed period.\")\n    try:\n        table = self._create_financials_table(name, timescale, proxy)\n    except ValueError as e:\n        logger = utils.get_yf_logger()\n        logger.error(e)\n        return pd.DataFrame()\n    return table", "CodeBleu_score": 36.99723613864465}, {"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n    try:\n        if name not in self.allowed_financial_statements:\n            raise ValueError(\n                \"Invalid financial statement name. Please use one of the following: {}\".format(\n                    \", \".join(self.allowed_financial_statements)\n                )\n            )\n        if timescale not in self.allowed_periods:\n            raise ValueError(\n                \"Invalid timescale. Please use one of the following: {}\".format(\n                    \", \".join(self.allowed_periods)\n                )\n            )\n    except ValueError as e:\n        logger.error(e)\n        return pd.DataFrame()\n\n    try:\n        self._create_financials_table()\n        return self.financials\n    except Exception as e:\n        logger.error(e)\n        return pd.DataFrame()", "CodeBleu_score": 33.66328623716311}]}
{"instance_id": "af01d9bae091", "generation_result": [{"code": "def _parse_fund_ownership(self, data)\n\t\n    ownership = data['fundOwnership']\n    for owner in ownership:\n        self._parse_raw_values(owner)\n        owner.pop('maxAge')\n    df = pd.DataFrame(ownership)\n    if not df.empty:\n        df['reportDate'] = pd.to_datetime(df['reportDate'])\n        df.rename(columns={'value': 'value_', 'name': 'name_'}, inplace=True)\n    self._mutualfund = df", "CodeBleu_score": 35.84720118740017}, {"code": "def _parse_fund_ownership(self, data)\n\t\n    owners = data[\"ownershipList\"]\n    for owner in owners:\n        self._parse_raw_values(owner)\n        del owner[\"maxAge\"]\n    df = pd.DataFrame(owners)\n    if not df.empty:\n        df[\"reportDate\"] = pd.to_datetime(df[\"reportDate\"])\n        df.rename(\n            columns={\n                \"orgId\": \"org_id\",\n                \"reportDate\": \"report_date\",\n                \"portfolioId\": \"portfolio_id\",\n                \"investmentType\": \"investment_type\",\n                \"investmentStyle\": \"investment_style\",\n                \"investmentStrategy\": \"investment_strategy\",\n                \"topHolderType\": \"top_holder_type\",\n                \"weight\": \"weight\",\n                \"weightType\": \"weight_type\",\n            },\n            inplace=True,\n        )\n    self._mutualfund = df\n\n", "CodeBleu_score": 33.35333217360195}, {"code": "def _parse_fund_ownership(self, data)\n\t\n    ownership = data[\"fundOwnership\"]\n    for owner in ownership:\n        raw_values = self._parse_raw_values(owner)\n        raw_values.pop(\"maxAge\")\n        df = pd.DataFrame(raw_values)\n        if not df.empty:\n            df[\"reportDate\"] = pd.to_datetime(df[\"reportDate\"])\n            df = df.rename(\n                columns={\n                    \"reportedHoldingStyle\": \"fund_type\",\n                    \"reportedHoldingStyleName\": \"fund_type_name\",\n                    \"reportedHoldingStyleType\": \"fund_type_type\",\n                }\n            )\n            self._mutualfund = df\n\n", "CodeBleu_score": 40.46020303014947}]}
{"instance_id": "2b5c6f1253db", "generation_result": [{"code": "def currency(self)\n\t\n    if self.currency is not None:\n        return self.currency\n\n    metadata = get_history_metadata(self.ticker, self.proxy)\n    self.currency = metadata[\"currency\"]\n    return self.currency", "CodeBleu_score": 57.166209841360626}, {"code": "def currency(self)\n\t\n    if self.currency is not None:\n        return self.currency\n    try:\n        meta = get_history_metadata(self.ticker, self.period, self.interval, proxy=self.proxy)\n        self.currency = meta['currency']\n    except Exception as e:\n        print(e)\n        self.currency = None\n    return self.currency", "CodeBleu_score": 53.354502614332624}, {"code": "def currency(self)\n\t\n    if self.currency is not None:\n        return self.currency\n    metadata = self.get_history_metadata()\n    self.currency = metadata[\"currency\"]\n    return self.currency", "CodeBleu_score": 52.6840036101247}]}
{"instance_id": "16b80be60e3b", "generation_result": [{"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        self._fetch(proxy='recommendationTrend',\n                    module='recommendationTrend',\n                    method='recommendationTrend',\n                    verbose=self._verbose)\n\n    if self._recommendations is None:\n        self._recommendations = pd.DataFrame()\n        return self._recommendations\n\n    try:\n        self._recommendations = pd.DataFrame(self._recommendations['finance']['result'][0]['recommendationTrend']['trend'])\n    except KeyError:\n        raise YFDataException(f\"Could not parse data for {self._ticker}\")\n\n    return self._recommendations\n\n", "CodeBleu_score": 42.71489801324507}, {"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        try:\n            self._recommendations = self._fetch(\"recommendationTrend\", proxy=self._proxy)\n        except Exception as e:\n            raise YFDataException(f\"Could not fetch recommendations data for {self._ticker}: {e}\")\n\n    if self._recommendations is None:\n        self._recommendations = pd.DataFrame()\n\n    try:\n        self._recommendations = self._recommendations.loc[\"recommendationTrend\", \"recommendationTrend\"]\n        self._recommendations = self._recommendations.loc[\"trend\"]\n    except KeyError:\n        raise YFDataException(f\"Could not parse recommendations data for {self._ticker}\")\n\n    return self._recommendations\n\n", "CodeBleu_score": 43.58988555810636}, {"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        try:\n            self._recommendations = self._fetch(\n                \"recommendationTrend\",\n                proxy=self._recommendationsProxy,\n                interval=\"1d\",\n                ignore_tz=True,\n            )\n        except Exception as e:\n            raise YFDataException(\n                f\"Error fetching recommendations data from proxy: {e}\"\n            )\n        if self._recommendations is None:\n            self._recommendations = pd.DataFrame()\n        else:\n            try:\n                self._recommendations = self._recommendations[\"recommendationTrend\"][\n                    \"trend\"\n                ]\n            except Exception as e:\n                raise YFDataException(\n                    f\"Error parsing recommendations data: {e}\"\n                )\n    return self._recommendations\n\n", "CodeBleu_score": 47.144699124317114}]}
{"instance_id": "abaf8c2a3ecc", "generation_result": [{"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n\n    # Check if the classifier has the attribute 'n_clusters'\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The classifier should have the attribute 'n_clusters'\")\n\n    # Set the cluster range if not provided\n    if cluster_ranges is None:\n        cluster_ranges = range(2, 11)\n\n    # Create a list to store the scores for each number of clusters\n    scores = []\n\n    # Loop through each number of clusters and calculate the score\n    for n_clusters in cluster_ranges:\n        clf.n_clusters = n_clusters\n        score = np.absolute(clf.score(X))\n        scores.append(score)\n\n    # Create a figure and axis object if not provided\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    # Plot the sum of squared errors against the number of clusters\n    ax.plot(cluster_ranges, scores, 'bo-')\n\n    # Set the title and labels for the plot\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel('Number of clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Sum of squared errors', fontsize=text_fontsize)\n\n    # Plot the clustering duration on a secondary y-axis if specified\n    if show_cluster_time:\n        ax2 = ax.twinx()\n        times = []\n        for n_clusters in cluster_ranges:\n            clf.n_clusters = n_clusters\n            start_time = time.time()\n            clf.fit(X)\n            end_time = time.time()\n            times.append(end_time - start_time)\n        ax2.plot(cluster_ranges, times, 'ro-')\n        ax2.set_ylabel('Clustering time (seconds)', fontsize=text_fontsize)\n\n    # Set the tick parameters for the plot\n    ax.tick_params(axis=", "CodeBleu_score": 49.06569489746898}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The classifier input must have a 'n_clusters' attribute\")\n\n    if cluster_ranges is None:\n        cluster_ranges = range(2, 11)\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    # Parallel processing to speed up clustering for a large number of clusters\n    with Parallel(n_jobs=n_jobs) as parallel:\n        # Score the classifier for each cluster number\n        scores = parallel(delayed(clf.set_params)(n_clusters=i) or clf for i in cluster_ranges)\n\n    # Extract the sum of squared errors from the scores\n    sum_squared_errors = [score.inertia_ for score in scores]\n\n    # Plot the sum of squared errors against the number of clusters\n    ax.plot(cluster_ranges, sum_squared_errors, marker='o', label='Sum of Squared Errors')\n\n    # Set the x-axis label and tick marks\n    ax.set_xlabel('Number of Clusters', fontsize=text_fontsize)\n    ax.set_xticks(cluster_ranges)\n\n    # Set the y-axis label\n    ax.set_ylabel('Sum of Squared Errors', fontsize=text_fontsize)\n\n    # Set the title of the plot\n    ax.set_title(title, fontsize=title_fontsize)\n\n    # Plot the clustering duration on a secondary y-axis\n    if show_cluster_time:\n        ax2 = ax.twinx()\n        cluster_times = [score.cluster_time_ for score in scores]\n        ax2.plot(cluster_ranges, cluster_times, marker='o', color='red', label='Clustering Time')\n        ax2.set_ylabel('Clustering Time (s)', fontsize=text_fontsize)\n        ax2.tick_params(axis='y', labelcolor='red')\n\n", "CodeBleu_score": 52.314974779328146}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The classifier passed should have the attribute 'n_clusters'\")\n\n    if cluster_ranges is None:\n        cluster_ranges = range(2, 11)\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    else:\n        fig = ax.get_figure()\n\n    with Parallel(n_jobs=n_jobs) as parallel:\n        res = parallel(delayed(get_score)(clf, X, k) for k in cluster_ranges)\n\n    scores, durations = list(zip(*res))\n\n    ax.plot(cluster_ranges, scores, 'b*-')\n    ax.set_ylabel('Sum of Squared Errors', fontsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.tick_params(axis='both', labelsize=text_fontsize)\n    ax.grid()\n\n    if show_cluster_time:\n        ax2 = ax.twinx()\n        ax2.plot(cluster_ranges, durations, 'r*-')\n        ax2.set_ylabel('Seconds', fontsize=text_fontsize)\n        ax2.tick_params(axis='y', labelsize=text_fontsize)\n\n    return ax\n\n", "CodeBleu_score": 52.42108914496818}]}
{"instance_id": "8a90815c4ee1", "generation_result": [{"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    start_time = time.time()\n    cloned_clf = clone(clf)\n    cloned_clf.set_params(n_clusters=n_clusters)\n    cloned_clf.fit(X)\n    y_pred = cloned_clf.predict(X)\n    score = score(X, y_pred)\n    end_time = time.time()\n    return cloned_clf, score, end_time - start_time\n\n", "CodeBleu_score": 31.45472317425604}, {"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    start_time = time.time()\n    clf_clone = clone(clf)\n    clf_clone.set_params(n_clusters=n_clusters)\n    clf_clone.fit(X)\n    end_time = time.time()\n    return clf_clone.score(X), end_time - start_time\n\n", "CodeBleu_score": 31.29761189566691}, {"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    start_time = time.time()\n    cloned_clf = clone(clf)\n    cloned_clf.set_params(n_clusters=n_clusters)\n    cloned_clf.fit(X)\n    y_pred = cloned_clf.predict(X)\n    end_time = time.time()\n    return (end_time - start_time, score(X, y_pred))\n\n", "CodeBleu_score": 26.951515874170184}]}
{"instance_id": "da40bd5dd81a", "generation_result": [{"code": "def clustering_factory(clf)\n\t\n    if not hasattr(clf, \"fit\"):\n        raise TypeError(\"fit method not found in the clusterer object\")\n    if not hasattr(clf, \"fit_predict\"):\n        raise TypeError(\"fit_predict method not found in the clusterer object\")\n\n    def plot_silhouette(self):\n        \"\"\"The function plot_silhouette takes a clustering object self as an argument.", "CodeBleu_score": 11.726774658955566}, {"code": "def clustering_factory(clf)\n\t\n    if not hasattr(clf, 'fit') or not hasattr(clf, 'fit_predict'):\n        raise TypeError(\"The clusterer object must have 'fit' and 'fit_predict' methods.\")\n\n    additional_methods = {\n        'plot_silhouette': plot_silhouette,\n        'plot_elbow_curve': plot_elbow_curve\n    }\n\n    for method_name, method_func in six.iteritems(additional_methods):\n        if hasattr(clf, method_name):\n            warnings.warn(\n                \"The clusterer object already has a method named '{}', it will be overridden.\".format(method_name),\n                stacklevel=2\n            )\n        setattr(clf, method_name, types.MethodType(method_func, clf))\n\n    return clf\n\n", "CodeBleu_score": 43.230614818590205}, {"code": "def clustering_factory(clf)\n\t\n    if not hasattr(clf, \"fit\") or not hasattr(clf, \"fit_predict\"):\n        raise TypeError(\"{} is not a valid clusterer instance.\".format(clf.__class__.__name__))\n\n    additional_methods = {\n        \"plot_silhouette\": plot_silhouette,\n        \"plot_elbow_curve\": plot_elbow_curve,\n    }\n\n    for method_name, method in six.iteritems(additional_methods):\n        if hasattr(clf, method_name):\n            warnings.warn(\n                \"{} already has a method named {}. It will be overridden.\".format(\n                    clf.__class__.__name__, method_name\n                )\n            )\n        setattr(clf, method_name, types.MethodType(method, clf))\n\n    return clf\n\n", "CodeBleu_score": 41.36220569323805}]}
{"instance_id": "b8d8ba3c0b1b", "generation_result": [{"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    if train_sizes is not None:\n        train_sizes, train_scores, test_scores = learning_curve(\n            clf, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,\n            scoring=scoring)\n        train_scores_mean = np.mean(train_scores, axis=1)\n        train_scores_std = np.std(train_scores, axis=1)\n        test_scores_mean = np.mean(test_scores, axis=1)\n        test_scores_std = np.std(test_scores, axis=1)\n        ax.grid()\n\n        ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                        train_scores_mean + train_scores_std, alpha=0.1,\n                        color=\"r\")\n        ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                        test_scores_mean + test_scores_std, alpha=0.1,\n                        color=\"g\")\n        ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n                label=\"Training score\")\n        ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n                label=\"Cross-validation score\")\n        ax.legend(loc=\"best\", fontsize=text_fontsize)\n    ax.set_xlabel(\"Training examples\", fontsize=text_fontsize)\n    ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n    return ax", "CodeBleu_score": 80.6903512714579}, {"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    if title == 'Learning Curves (SVM, RBF kernel, $\\gamma=0.001$)':\n        ax.set_xlabel(\"Training examples\", fontsize=text_fontsize)\n        ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n        ax.tick_params(axis='both', which='major', labelsize=text_fontsize)\n        ax.grid()\n\n    train_sizes, train_scores, test_scores = \\\n        learning_curve(clf, X, y, cv=cv, n_jobs=n_jobs,\n                       train_sizes=train_sizes, scoring=scoring)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    ax.grid()\n\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1,\n                    color=\"g\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n    ax.legend(loc=\"best\", font", "CodeBleu_score": 71.56812470317024}, {"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    if train_sizes is not None:\n        train_sizes = (1. * train_sizes / len(X)).tolist()\n\n    train_sizes, train_scores, test_scores = learning_curve(\n        clf, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=scoring)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    ax.set_xlabel(\"Training examples\", fontsize=text_fontsize)\n    ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n    ax.grid()\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1,\n                    color=\"g\")\n\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n    ax.legend(loc=\"best\", fontsize=text_fontsize)\n    return ax\n\n", "CodeBleu_score": 82.54082052524922}]}
{"instance_id": "e6e76eb35945", "generation_result": [{"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The classifier should have the n_clusters parameter\")\n\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n\n    scores = []\n    for n_clusters in cluster_ranges:\n        clf_ = clone(clf)\n        setattr(clf_, 'n_clusters', n_clusters)\n        clf_.fit(X)\n        scores.append(np.absolute(clf_.score(X)))\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    ax.plot(cluster_ranges, scores, marker='o')\n    ax.grid(True)\n    ax.set_xlabel(\"Number of clusters\")\n    ax.set_ylabel(\"Score\")\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n\n    return ax", "CodeBleu_score": 58.5753698768394}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The classifier input should have a `n_clusters` attribute for this function to run\")\n\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n\n    scores = []\n    for k in cluster_ranges:\n        clf_k = clone(clf)\n        setattr(clf_k, 'n_clusters', k)\n        clf_k.fit(X)\n        scores.append(np.absolute(clf_k.score(X)))\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    ax.plot(cluster_ranges, scores, linestyle='--', marker='o', color='b')\n    ax.grid(axis='x')\n    ax.set_xticks(cluster_ranges)\n    ax.set_xlabel('k')\n    ax.set_ylabel('sum of squared distances')\n    ax.set_title('Elbow Plot', fontsize=title_fontsize)\n\n    # set size of tick labels\n    ax.tick_params(axis='both', which='major', labelsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n\n    return ax", "CodeBleu_score": 61.019354041092434}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The classifier passed should have a `n_clusters` attribute.\")\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n    scores = []\n    for k in cluster_ranges:\n        clf_k = clone(clf)\n        setattr(clf_k, 'n_clusters', k)\n        clf_k.fit(X)\n        scores.append(np.absolute(clf_k.score(X)))\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    ax.plot(cluster_ranges, scores, linestyle='--', marker='o', color='b')\n    ax.grid(True)\n    ax.set_xlabel('Number of Clusters')\n    ax.set_ylabel('SSE')\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n    return ax\n\n", "CodeBleu_score": 59.00662087664357}]}
{"instance_id": "6f4530c8a20f", "generation_result": [{"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    else:\n        fig = ax.get_figure()\n    X_pca = clf.transform(X)\n    ax.scatter(X_pca[:, 0], X_pca[:, 1], c=y, s=50, cmap=cmap)\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel('First principal component', fontsize=text_fontsize)\n    ax.set_ylabel('Second principal component', fontsize=text_fontsize)\n    ax.tick_params(axis='both', which='major', labelsize=text_fontsize)\n    ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Classes\",\n              fontsize=text_fontsize)\n    return ax\n\n", "CodeBleu_score": 41.82370507942318}, {"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    else:\n        fig = ax.get_figure()\n    t0 = time()\n    X = clf.transform(X)\n    if hasattr(X, \"iloc\"):\n        # get the column names if the input is a dataframe\n        columns = X.columns\n        components_ = clf.components_\n    else:\n        # otherwise just use component 1 and component 2\n        columns = ['component_1', 'component_2']\n        components_ = clf.components_[:2]\n    # color by y-labels if they exist, otherwise use the labels of the\n    # clustering algorithm\n    if y is not None:\n        y_labels = np.unique(y)\n        n_colors = len(y_labels)\n    else:\n        y_labels = np.unique(clf.labels_)\n        n_colors = len(y_labels)\n    cmap = get_cmap(cmap, n_colors)\n    # create colormap based on number of labels\n    if y is None:\n        y = clf.labels_\n    for label in y_labels:\n        mask = y == label\n        ax.scatter(X.loc[mask, columns[0]], X.loc[mask, columns[1]],\n                   c=np.array(cmap(label)).reshape(1, 4), label=label,\n                   edgecolors='black', s=60)\n    score = round(clf.score(X), 2)\n    ax.set_xlabel(f'{columns[0]} ({clf.explained_variance_ratio_[0] * 100:.2f}%)',\n                  fontsize=text_fontsize)\n    ax.set_ylabel(f'{columns[1]} ({clf.explained_variance_ratio_[1] * 100:.2f}%)',\n                  fontsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.tick_params", "CodeBleu_score": 44.03796128787826}, {"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    X_pca = clf.transform(X)\n    ax.set_xlabel('Component 1', fontsize=text_fontsize)\n    ax.set_ylabel('Component 2', fontsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n    targets = np.unique(y)\n    colors = get_cmap(cmap)(np.linspace(0, 1, len(targets)))\n    for target, color in zip(targets, colors):\n        indicesToKeep = y == target\n        ax.scatter(X_pca[indicesToKeep, 0], X_pca[indicesToKeep, 1],\n                   c=color, s=50, label=target)\n    ax.legend(prop={'size': text_fontsize})\n    ax.tick_params(axis='both', which='major', labelsize=text_fontsize)\n    return ax\n\n", "CodeBleu_score": 54.0900897718517}]}
{"instance_id": "e7c2775d024c", "generation_result": [{"code": "def barplot(ax)\n\t\n    clip1 = clip_path(ax, 1, 1, 0.03)\n    clip2 = clip_path(ax, 1, 1, 0.03)\n    Y1 = np.random.uniform(0.5, 1.0, 16)\n    Y2 = np.random.uniform(0.5, 1.0, 16)\n    ax.bar(np.arange(16) - 0.5, Y1, 1, clip_path=clip1, facecolor=\"#cccccc\")\n    ax.bar(np.arange(16) - 0.5, Y2, 1, clip_path=clip1, facecolor=\"#dddddd\")\n    ax.bar(np.arange(16) + 0.5, Y1, 1, clip_path=clip2, facecolor=\"#cccccc\")\n    ax.bar(np.arange(16) + 0.5, Y2, 1, clip_path=clip2, facecolor=\"#dddddd\")\n    ax.set_xlim(-1, 16)\n    ax.text(0.01, 0.02, \"Bar plot\", transform=ax.transAxes, ha=\"left\", va=\"bottom\")\n    ax.text(0.99, 0.02, \"ax.bar()\", transform=ax.transAxes, ha=\"right\", va=\"bottom\", fontfamily=\"monospace\")\n\n", "CodeBleu_score": 32.66798809684827}, {"code": "def barplot(ax)\n\t\n    clip1 = clip_path(ax, (0, 0), 7)\n    clip2 = clip_path(ax, (0, 0), 5)\n    Y1 = 1 + np.arange(16)\n    Y2 = 1 + np.random.uniform(0.5, 1.0, len(Y1))\n    ax.bar(Y1, +Y1, facecolor=\"#cccccc\", edgecolor=\"white\", yerr=Y2, capsize=7,\n           align=\"center\", ecolor=\"black\", clip_path=clip1)\n    ax.bar(Y1, -Y1, facecolor=\"#999999\", edgecolor=\"white\", yerr=Y2, capsize=7,\n           align=\"center\", ecolor=\"black\", clip_path=clip1)\n    ax.bar(Y1, +Y2, facecolor=\"#ff9999\", edgecolor=\"white\", capsize=7,\n           align=\"center\", ecolor=\"black\", clip_path=clip2)\n    ax.bar(Y1, -Y2, facecolor=\"#9999ff\", edgecolor=\"white\", capsize=7,\n           align=\"center\", ecolor=\"black\", clip_path=clip2)\n    ax.set_xlim(-1, 16)\n    ax.text(0.05, 0.95, \"Bar plot\", transform=ax.transAxes,\n            ha=\"left\", va=\"top\", size=16, color=\"black\")\n    ax.text(0.05, 0.91, \"ax.bar()\", transform=ax.transAxes,\n            ha=\"left\", va=\"top\", size=12, color=\"#017500\",\n            family=\"monospace\")\n\n", "CodeBleu_score": 34.50530530808915}, {"code": "def barplot(ax)\n\t\n    clip1 = clip_path(ax, (0, 0), (1, 0))\n    clip2 = clip_path(ax, (0, 0), (0, 1))\n    Y1 = np.random.uniform(0, 1, 16)\n    Y2 = np.random.uniform(0, 1, 16)\n    ax.bar(np.arange(16), Y1, color='#666666', clip_path=clip1)\n    ax.bar(np.arange(16), Y1, color='#999999', clip_path=clip2)\n    ax.bar(np.arange(16), Y2, color='#cccccc', clip_path=clip1)\n    ax.bar(np.arange(16), Y2, color='#aaaaaa', clip_path=clip2)\n    ax.set_xlim(-1, 16)\n    ax.text(0, -0.08, 'Bar plot', transform=ax.transAxes, color='k', ha='left', va='top')\n    ax.text(0, -0.12, 'ax.bar()', transform=ax.transAxes, color='#3333ff', ha='left', va='top', fontfamily='monospace')\n\n", "CodeBleu_score": 28.76756305162625}]}
{"instance_id": "0ec1d146a32b", "generation_result": [{"code": "def split(n_segment)\n\t\n    X0 = np.arange(0, 1, 1 / n_segment)\n    X1 = np.arange(1 / n_segment, 1 + 1 / n_segment, 1 / n_segment)\n    return X0, X1\n\n", "CodeBleu_score": 15.361995652797928}, {"code": "def split(n_segment)\n\t\n    w = width / n_segment\n    pad = (width - n_segment * w) / 2\n    X0 = np.arange(0, n_segment) * w + pad\n    X1 = X0 + w\n    return X0, X1\n\n", "CodeBleu_score": 29.6082689653787}, {"code": "def split(n_segment)\n\t\n    width = width_segment(n_segment)\n    padding = padding_segment(n_segment)\n    X0 = np.arange(0, n_segment * width, width + padding)\n    X1 = X0 + width\n    return X0, X1\n\n", "CodeBleu_score": 27.43860703671842}]}
{"instance_id": "604a3e93ac0d", "generation_result": [{"code": "def pixelated_text(dpi=100)\n\t\n    fig = Figure(figsize=(1, 1), dpi=dpi)\n    canvas = FigureCanvasAgg(fig)\n    ax = fig.gca()\n    ax.text(0.5, 0.5, 'a', fontsize=75, ha='center', va='center')\n    ax.axis('off')\n    canvas.draw()\n    s, (width, height) = canvas.print_to_buffer()\n    im = np.frombuffer(s, np.uint8).reshape((height, width, 4))[:, :, :3].astype(np.float64)\n    im = np.roll(im, 1, axis=-1)\n    return im\n\n", "CodeBleu_score": 49.42750974199847}, {"code": "def pixelated_text(dpi=100)\n\t\n    fig = Figure(figsize=(1, 1), dpi=dpi)\n    canvas = FigureCanvasAgg(fig)\n    ax = fig.gca()\n    ax.text(0.5, 0.5, 'a', fontsize=75, ha='center', va='center')\n    ax.axis('off')\n    canvas.draw()\n    image = np.frombuffer(canvas.tostring_argb(), dtype='uint8')\n    image = image.reshape(canvas.get_width_height()[::-1] + (4,))\n    image = np.roll(image, 1, axis=-1)\n    return image\n\n", "CodeBleu_score": 57.24582534474517}, {"code": "def pixelated_text(dpi=100)\n\t\n    fig = plt.figure(figsize=(1, 1), dpi=dpi)\n    canvas = FigureCanvasAgg(fig)\n    ax = fig.gca()\n    ax.text(0.5, 0.5, 'a', fontsize=75, ha='center', va='center')\n    ax.axis('off')\n    canvas.draw()\n    s, (width, height) = canvas.print_to_buffer()\n    image = np.frombuffer(s, np.uint8).reshape((height, width, 4))[:, :, :3].astype(np.float64) / 255\n    image = np.roll(image, 1, axis=-1)\n    return image\n\n", "CodeBleu_score": 46.613870952036294}]}
{"instance_id": "2a7fc7d560ea", "generation_result": [{"code": "def curve()\n\t\n    n = randint(3, 6)\n    centers = np.linspace(0, 1, n)\n    widths = uniform(0.05, 0.2, n)\n    scales = uniform(0.5, 0.5, n)\n    widths /= widths.sum()\n    scales /= scales.sum()\n    x = np.zeros(100)\n    for c, w, s in zip(centers, widths, scales):\n        x += s * np.exp(-0.5 * ((x - c) / w) ** 2)\n    return x\n\n", "CodeBleu_score": 34.76794979272007}, {"code": "def curve()\n\t\n    n = randint(1, 10)\n    widths = np.abs(normal(10.0, 5.0, n))\n    scales = np.abs(normal(100.0, 50.0, n))\n    centers = np.linspace(0, 1000, n)\n    widths /= widths.sum()\n    scales /= scales.sum()\n    x = np.zeros(1000)\n    for c, w, s in zip(centers, widths, scales):\n        x += s * np.exp(-((np.arange(1000) - c) / w) ** 2)\n    return x\n\n", "CodeBleu_score": 27.71560040125514}, {"code": "def curve()\n\t\n    n = randint(1, 5)\n    centers = np.linspace(0, 1, n)\n    widths = np.random.uniform(0.05, 0.2, n)\n    scales = np.random.uniform(0.5, 1, n)\n    widths = widths / widths.sum()\n    scales = scales / scales.sum()\n    curve = np.zeros(100)\n    for center, width, scale in zip(centers, widths, scales):\n        curve += scale * np.exp(-((np.linspace(0, 1, 100) - center) / width) ** 2)\n    return curve\n\n", "CodeBleu_score": 48.524554985459375}]}
{"instance_id": "be694335ebfc", "generation_result": [{"code": "def difference(derivative, accuracy=1)\n\t\n    derivative = derivative + 1\n    radius = accuracy / derivative\n    points = np.linspace(-radius, radius, derivative)\n    coefficients = np.linalg.inv(np.vander(points))[derivative - 1, :] / math.factorial(derivative - 1)\n    return coefficients, points\n\n", "CodeBleu_score": 49.39486178150606}, {"code": "def difference(derivative, accuracy=1)\n\t\n    derivative = derivative + 1\n    radius = (accuracy + 1) / 2\n    points = np.arange(-radius, radius + 1)\n    coefficients = np.linalg.inv(np.vander(points, derivative))[derivative] * factorial(derivative - 1)\n    return coefficients, points\n\n", "CodeBleu_score": 55.59237894411222}, {"code": "def difference(derivative, accuracy=1)\n\t\n    derivative = derivative + 1\n    radius = np.round(derivative + accuracy / 2) / accuracy\n    x = np.linspace(-radius, radius, derivative + accuracy)\n    x = x[1:]\n    vander = np.vander(x, derivative)\n    return np.linalg.inv(vander)[0, :], x\n\n", "CodeBleu_score": 41.713520202461986}]}
{"instance_id": "fa3fb47f33fa", "generation_result": [{"code": "def interpolate(X, Y, T)\n\t\n    D = np.sqrt(np.diff(X) ** 2 + np.diff(Y) ** 2)\n    Dc = np.cumsum(D)\n    Dc = np.insert(Dc, 0, 0)\n    Xi = np.interp(T, Dc, X)\n    Yi = np.interp(T, Dc, Y)\n    TOTD = Dc[-1]\n    return Xi, Yi, TOTD\n\n", "CodeBleu_score": 38.32493806324773}, {"code": "def interpolate(X, Y, T)\n\t\n    # Compute the distances between consecutive points\n    distances = np.sqrt(np.diff(X)**2 + np.diff(Y)**2)\n\n    # Compute the cumulative distances\n    cumulative_distances = np.cumsum(distances)\n\n    # Compute the total distance\n    total_distance = cumulative_distances[-1]\n\n    # Compute the interpolation points\n    interpolated_x = np.interp(T, cumulative_distances, X)\n    interpolated_y = np.interp(T, cumulative_distances, Y)\n\n    return interpolated_x, interpolated_y, total_distance\n\n", "CodeBleu_score": 26.86286576338225}, {"code": "def interpolate(X, Y, T)\n\t\n    D = np.sqrt(np.diff(X) ** 2 + np.diff(Y) ** 2)\n    C = np.cumsum(D)\n    C = np.insert(C, 0, 0)\n    X_int = np.interp(T, C, X)\n    Y_int = np.interp(T, C, Y)\n    D_int = np.diff(X_int) ** 2 + np.diff(Y_int) ** 2\n    D_int = np.insert(D_int, 0, 0)\n    D_int = np.cumsum(D_int)\n    return X_int, Y_int, D_int\n\n", "CodeBleu_score": 38.98096726261024}]}
{"instance_id": "870a2dad3c66", "generation_result": [{"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None] * 1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)\n        N[I] = n\n        Z[I] = Z[I]**2 + C[I]\n    N[N == maxiter - 1] = 0\n    return Z, N\n\n", "CodeBleu_score": 75.97866235675308}, {"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None] * 1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)\n        N[I] = n\n        Z[I] = Z[I]**2 + C[I]\n    N[N == maxiter-1] = 0\n    return Z, N\n\n", "CodeBleu_score": 73.67980821339879}, {"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None] * 1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)\n        N[I] = n\n        Z[I] = Z[I]**2 + C[I]\n    N[N == maxiter - 1] = 0\n    return Z, N\n\n", "CodeBleu_score": 75.97866235675308}]}
{"instance_id": "e1a908945acf", "generation_result": [{"code": "def smooth2d(A, sigma=3)\n\t\n    A = np.asarray(A)\n    sigma = int(sigma)\n    if sigma < 1:\n        return A\n    window_len = sigma * 4 + 1\n    window_len = max(window_len, 3)\n    if window_len % 2 == 0:\n        window_len += 1\n    window = np.ones(window_len, \"d\")\n    window = np.exp(-(np.arange(-window_len // 2, window_len // 2) ** 2) / (2 * sigma ** 2))\n    window /= sum(window)\n    A = np.transpose(A)\n    A = smooth1d(A, window)\n    A = np.transpose(A)\n    A = smooth1d(A, window)\n    A = np.transpose(A)\n    return A\n\n", "CodeBleu_score": 34.720441513355915}, {"code": "def smooth2d(A, sigma=3)\n\t\n    window_len = max(int(sigma), 3) * 3\n    A = np.asarray(A)\n    A = np.transpose(A)\n    s = np.r_[A[window_len - 1 : 0 : -1], A, A[-1:-window_len:-1]]\n    w = np.zeros(window_len, \"d\")\n    for i in range(window_len):\n        w[i] = w[i - window_len]\n    A = np.convolve(w / w.sum(), s, mode=\"valid\")\n    A = A[window_len - 1 : -window_len + 1]\n    A = np.transpose(A)\n    s = np.r_[A[window_len - 1 : 0 : -1], A, A[-1:-window_len:-1]]\n    w = np.zeros(window_len, \"d\")\n    for i in range(window_len):\n        w[i] = w[i - window_len]\n    A = np.convolve(w / w.sum(), s, mode=\"valid\")\n    A = A[window_len - 1 : -window_len + 1]\n    A = np.transpose(A)\n    return A\n\n", "CodeBleu_score": 37.53906123951627}, {"code": "def smooth2d(A, sigma=3)\n\t\n    # make the radius of the filter equal to...\n    l = int(4 * sigma + 1)\n    # by definition, the filter has to be odd\n    if (l % 2 == 0):\n        l = l + 1\n    B = np.zeros(np.shape(A))\n    # we apply the smoothing to each row\n    for j in range(np.shape(A)[0]):\n        B[j, :] = smooth1d(A[j, :], l)\n    # we apply the smoothing to each column\n    for j in range(np.shape(A)[1]):\n        B[:, j] = smooth1d(B[:, j], l)\n    return B\n\n", "CodeBleu_score": 29.362237222818916}]}
{"instance_id": "94563c54b483", "generation_result": [{"code": "def process_image(self, padded_src, dpi)\n\t\n    ox, oy = self.offsets_px(dpi)\n    return np.roll(np.roll(padded_src, ox, axis=1), oy, axis=0)\n\n", "CodeBleu_score": 18.996887315307475}, {"code": "def process_image(self, padded_src, dpi)\n\t\n    ox, oy = self.get_offsets()\n    px_per_inch = dpi / 72.0\n    ox = int(round(ox * px_per_inch))\n    oy = int(round(oy * px_per_inch))\n    if ox != 0:\n        padded_src = np.roll(padded_src, ox, axis=1)\n    if oy != 0:\n        padded_src = np.roll(padded_src, oy, axis=0)\n    return padded_src\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 32.04619510043377}, {"code": "def process_image(self, padded_src, dpi)\n\t\n    ox, oy = self.get_offsets()\n    px, py = dpi / 0.0254, dpi / 0.0254\n    return np.roll(np.roll(padded_src, int(ox * px), axis=1), int(oy * py), axis=0)\n\n", "CodeBleu_score": 30.48016581285585}]}
{"instance_id": "d71d232872fe", "generation_result": [{"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    shape = tuple(shape)\n    width = tuple(width)\n    center = tuple(center)\n\n    def g(x):\n        return np.exp(-0.5 * (x / width) ** 2)\n\n    grid = np.zeros(shape)\n    it = np.nditer(grid, flags=[\"multi_index\"])\n    while not it.finished:\n        grid[it.multi_index] = g(np.array(it.multi_index) - center)\n        it.iternext()\n\n    return grid\n\n", "CodeBleu_score": 24.368341910537573}, {"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    shape = tuple(shape)\n    width = tuple(width)\n    center = tuple(center)\n    grid = []\n    for i in range(len(shape)):\n        if width[i] == 0.0:\n            grid.append(slice(0, shape[i]))\n        else:\n            start = center[i] - (shape[i] - 1) / 2.0\n            end = start + shape[i]\n            step = width[i]\n            grid.append(np.arange(start, end, step))\n    grid = np.meshgrid(*grid, indexing='ij')\n    g = np.exp(-0.5 * np.sum(np.square(grid), axis=0))\n    return g\n\n", "CodeBleu_score": 30.68690229254582}, {"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    shape = (shape,) if isinstance(shape, int) else shape\n    width = (width,) if isinstance(width, float) else width\n    center = (center,) if isinstance(center, float) else center\n    assert len(shape) == len(width) == len(center)\n    grid = []\n    for i in range(len(shape)):\n        grid.append(np.exp(-0.5 * ((np.arange(shape[i]) - center[i]) / width[i]) ** 2))\n    return np.outer(*grid)\n\n", "CodeBleu_score": 31.059276252155044}]}
{"instance_id": "7bbd08c987bc", "generation_result": [{"code": "def stimulus(position, size, intensity)\n\t\n    x = size * (position[0] - size / 2) / size\n    y = size * (position[1] - size / 2) / size\n    R = (x ** 2 + y ** 2) / 2\n    return np.exp(-R) * intensity\n\n", "CodeBleu_score": 13.552837069129358}, {"code": "def stimulus(position, size, intensity)\n\t\n    x, y = position\n    x, y = np.exp(x), np.exp(y)\n    x, y = x / np.exp(x).max(), y / np.exp(y).max()\n    x, y = x - x.mean(), y - y.mean()\n    x, y = cartesian(x, y)\n    X, Y = np.meshgrid(x, y)\n    R = (X**2 + Y**2)\n    R = np.exp(-R / size**2)\n    R = R * intensity\n    return R\n\n", "CodeBleu_score": 16.19295619176774}, {"code": "def stimulus(position, size, intensity)\n\t\n    x, y = np.exp(position[0]) * np.cos(position[1]), np.exp(position[0]) * np.sin(position[1])\n    x, y = x / np.sqrt(x**2 + y**2), y / np.sqrt(x**2 + y**2)\n    x, y = (x + 1) / 2, (y + 1) / 2\n    x, y = x * size, y * size\n    x, y = np.linspace(0, 1, x), np.linspace(0, 1, y)\n    X, Y = np.meshgrid(x, y)\n    R = np.sqrt((X - x)**2 + (Y - y)**2)\n    return np.exp(-R**2 / size**2) * intensity\n", "CodeBleu_score": 34.49168066226014}]}
{"instance_id": "2b5806238d5d", "generation_result": [{"code": "def plot(ax, text)\n\t\n    ax.set_yticks([])\n    ax.set_xticks([])\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_xlabel(\"x\", fontfamily=\"serif\", fontsize=14)\n    ax.set_ylabel(\"y\", fontfamily=\"serif\", fontsize=14)\n    ax.text(\n        0.5,\n        0.5,\n        text,\n        horizontalalignment=\"center\",\n        verticalalignment=\"center\",\n        fontfamily=\"serif\",\n        fontsize=24,\n        fontweight=\"bold\",\n    )\n    ax.set_title(\"Title\", fontfamily=\"serif\", fontweight=\"bold\")\n\n", "CodeBleu_score": 42.47231475321911}, {"code": "def plot(ax, text)\n\t\n    ax.set_yticks([])\n    ax.set_xlabel(\"\")\n    ax.set_xlim(0, 1)\n    ax.set_xticks([])\n    ax.text(\n        0.5,\n        0.5,\n        text,\n        horizontalalignment=\"center\",\n        verticalalignment=\"center\",\n        transform=ax.transAxes,\n        fontdict={\"fontsize\": 20, \"fontweight\": \"bold\"},\n    )\n    ax.set_title(\"\", fontdict={\"fontsize\": 20, \"fontweight\": \"bold\"})\n\n", "CodeBleu_score": 40.62406349677325}, {"code": "def plot(ax, text)\n\t\n    ax.set_yticks([])\n    ax.set_xlabel('')\n    ax.set_xlim([0, 1])\n    ax.set_xticks([])\n    ax.text(0.5, 0.5, text, ha='center', va='center', fontsize=20, color='white')\n    ax.set_title('Plot Title', fontfamily='serif', fontweight='bold')\n\n", "CodeBleu_score": 31.584796575223844}]}
{"instance_id": "0b42aac61e21", "generation_result": [{"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt, **kwargs)\n    return self.steps[-1][1].predict_cumulative_hazard_function(Xt, **kwargs)\n\n", "CodeBleu_score": 56.33102292632064}, {"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt, **kwargs)\n    return self.steps[-1][1].predict_cumulative_hazard_function(Xt, **kwargs)\n\n", "CodeBleu_score": 56.33102292632064}, {"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt, **kwargs)\n    return self.steps[-1][1].predict_cumulative_hazard_function(Xt, **kwargs)\n\n", "CodeBleu_score": 59.70704625665502}]}
{"instance_id": "c8439e4918ad", "generation_result": [{"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    Xt = X\n    for name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt, **kwargs)\n    return self.steps[-1][1].predict_survival_function(Xt, **kwargs)\n\n", "CodeBleu_score": 55.4153977225078}, {"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    Xt = X\n    for name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt)\n    return self.steps[-1][-1].predict_survival_function(Xt, **kwargs)\n\n", "CodeBleu_score": 68.61634190459837}, {"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    Xt = X\n    for name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt)\n    return self.steps[-1][1].predict_survival_function(Xt, **kwargs)\n\n", "CodeBleu_score": 61.57734279950448}]}
{"instance_id": "216662ca7db4", "generation_result": [{"code": "def _check_success(self, results)\n\t\n    if results.solver.status == SolverStatus.ok and results.solver.termination_condition == TerminationCondition.optimal:\n        pass\n    elif results.solver.status == SolverStatus.ok and results.solver.termination_condition == TerminationCondition.maxIterations:\n        warnings.warn('\n", "CodeBleu_score": 17.919883018209344}, {"code": "def _check_success(self, results)\n\t\n    if results.solver.status == \"ok\":\n        if results.solver.termination_condition == \"optimal\":\n            pass\n        elif results.solver.termination_condition == \"maxIterations\":\n            warnings.warn(\"Optimization terminated with exit status maxIterations\")\n        elif results.solver.termination_condition == \"infeasible\":\n            raise RuntimeError(\"Optimization terminated with exit status infeasible\")\n        elif results.solver.termination_condition == \"unbounded\":\n            raise RuntimeError(\"Optimization terminated with exit status unbounded\")\n        elif results.solver.termination_condition == \"other\":\n            raise RuntimeError(\n                \"Optimization terminated with exit status {}\".format(\n                    results.solver.termination_condition\n                )\n            )\n    else:\n        raise RuntimeError(\n            \"Optimization failed with exit status {}\".format(results.solver.status)\n        )\n\n", "CodeBleu_score": 28.877588581348046}, {"code": "def _check_success(self, results)\n\t\n    exit_flag = results['solver']['termination condition']\n    if exit_flag == tc.locsol.SolverTerminationCondition.optimal:\n        pass\n    elif exit_flag == tc.locsol.SolverTerminationCondition.feasible:\n        pass\n    elif exit_flag == tc.locsol.SolverTerminationCondition.maxIterations:\n        warnings.warn('\n", "CodeBleu_score": 14.870930604418097}]}
{"instance_id": "1fe2e379fca0", "generation_result": [{"code": "def _decompose(self, P)\n\t\n    eigvals, eigvecs = linalg.eigh(P)\n    eigvals = eigvals.astype(np.float64)\n    eigvecs = eigvecs.astype(np.float64)\n    max_eigval = np.max(eigvals)\n    condition_number = max_eigval / (P.shape[0] * np.finfo(P.dtype).eps)\n    not_below_cutoff = eigvals > -np.abs(max_eigval) * np.sqrt(np.finfo(P.dtype).eps) * condition_number\n    P_decomposed = eigvecs[:, not_below_cutoff]\n    P_decomposed *= np.sqrt(eigvals[not_below_cutoff] / np.max(eigvals[not_below_cutoff]))\n    return P_decomposed.T, max_eigval", "CodeBleu_score": 26.61282898046929}, {"code": "def _decompose(self, P)\n\t\n    eigvals, eigvecs = linalg.eigh(P)\n    eigvals = eigvals.real\n    eigvecs = eigvecs.real\n    max_eigval = eigvals.max()\n    condition_number = max_eigval / (s.min(P.shape) * np.finfo(float).eps)\n    if condition_number > 1e15:\n        print('Warning: the matrix is extremely ill-conditioned!!!')\n    not_below_cutoff = eigvals > -abs(max_eigval) * 1e-16\n    eigvals = eigvals[not_below_cutoff]\n    eigvecs = eigvecs[:, not_below_cutoff]\n    eigvals = eigvals / abs(eigvals).max()\n    return eigvecs.T, eigvals.max()", "CodeBleu_score": 33.017939289550576}, {"code": "def _decompose(self, P)\n\t\n    evals, evecs = linalg.eigh(P)\n    evals = evals.astype(np.float64)\n    evecs = evecs.astype(np.float64)\n    evals_max = np.max(evals)\n    condition_number = np.abs(evals_max) * (P.shape[0] ** 2) * np.finfo(np.float64).eps\n    not_below_cutoff = evals > -condition_number\n    evals = evals[not_below_cutoff]\n    evecs = evecs[:, not_below_cutoff]\n    evals_max = np.max(evals)\n    evals = evals / evals_max\n    return evecs.T, evals_max\n\n", "CodeBleu_score": 28.801955186075624}]}
{"instance_id": "20c3f5d05d79", "generation_result": [{"code": "def _update_coef(self, coef, D)\n\t\n    coef = np.flatnonzero(coef)\n    coef = np.array(coef)\n    coef = coef[np.where(coef > 1e-12)]\n    coef = coef[np.where(coef < 1e12)]\n    self.coef_ = coef * D[coef]\n\n", "CodeBleu_score": 25.829113172379}, {"code": "def _update_coef(self, coef, D)\n\t\n    coef[np.flatnonzero(np.abs(coef) > self.threshold)] = 0\n    coef *= D\n    self.coef_ = coef\n\n", "CodeBleu_score": 22.94479329418828}, {"code": "def _update_coef(self, coef, D)\n\t\n    coef = np.flatnonzero(coef)\n    coef = np.append(coef, len(coef))\n    coef = np.diff(coef)\n    self.coef_ = np.append(coef, self.coef_[coef])\n    self.coef_ *= D[coef]\n\n", "CodeBleu_score": 18.86722902766042}]}
{"instance_id": "37c347d00d35", "generation_result": [{"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    event_type, event_time = y_true[:, 0], y_true[:, 1]\n    gradient = self._negative_gradient(event_type, event_time, raw_prediction)\n    if sample_weight is not None:\n        gradient *= sample_weight\n    return gradient\n\n", "CodeBleu_score": 45.607598146544966}, {"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    event_type, event_time = y_true[:, 0], y_true[:, 1]\n    # calculate the gradient\n    hazard = self._hazard(raw_prediction)\n    grad = hazard - event_type\n    # apply sample weights if provided\n    if sample_weight is not None:\n        grad *= sample_weight\n    return grad\n\n", "CodeBleu_score": 44.16567461235862}, {"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    event_type = y_true[:, 0]\n    event_time = y_true[:, 1]\n    # Compute the gradient for the Cox PH model\n    gradient = event_type - np.exp(raw_prediction) * np.exp(\n        np.sum(np.exp(raw_prediction) * event_time)\n    )\n    # Apply sample weights if provided\n    if sample_weight is not None:\n        gradient *= sample_weight\n    return gradient", "CodeBleu_score": 49.658160375440104}]}
{"instance_id": "6be432d27e52", "generation_result": [{"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if not self._support_missing_values:\n        assert_all_finite(X)\n        return None\n    if self._support_missing_values == \"allow_nan\":\n        if np.isnan(X).any():\n            return np.isnan(X).any(axis=0)\n        else:\n            return None\n    if estimator_name is None:\n        estimator_name = self.__class__.__name__\n    if self._support_missing_values == \"warn\":\n        warnings.warn(\n            f\"{estimator_name} does not support missing values, but \"\n            \"GaussianNB.fit was called with missing values anyway.\",\n            UserWarning,\n        )\n    if self._support_missing_values == \"raise\":\n        raise ValueError(\n            f\"{estimator_name} does not support missing values, but \"\n            \"GaussianNB.fit was called with missing values anyway.\"\n        )\n    assert_all_finite(X)\n    return None\n\n", "CodeBleu_score": 30.22598189938577}, {"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if not self._support_missing_values:\n        assert_all_finite(X)\n        return None\n    if self.missing_values == \"nan\":\n        mask = np.isnan(X)\n    elif self.missing_values == \"NaN\":\n        mask = np.isnan(X)\n    else:\n        mask = X == self.missing_values\n    if np.any(mask):\n        with np.errstate(invalid=\"ignore\"):\n            if np.sum(mask) == np.prod(X.shape):\n                return None\n            elif np.sum(mask) == 0:\n                return None\n            else:\n                if self.missing_values != \"NaN\":\n                    return mask\n                else:\n                    return np.isnan(X)\n    else:\n        return None", "CodeBleu_score": 32.61319752214037}, {"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if not self._support_missing_values:\n        assert_all_finite(X, estimator_name)\n        return None\n    else:\n        if self._any_isnan_axis0(X):\n            raise ValueError(\n                \"Input contains NaN, infinity or a value too large for \"\n                \"dtype('float64').\"\n            )\n        if not np.isfinite(np.sum(X)):\n            with np.errstate(invalid=\"ignore\"):\n                _assert_all_finite_element_wise(X)\n        return np.sum(np.isnan(X), axis=0) > 0", "CodeBleu_score": 31.177635215998983}]}
{"instance_id": "dc5bda895a07", "generation_result": [{"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n    self._validate_X_predict(X, check_input)\n    self._check_low_memory()\n    X = self._ensure_sparse_format_for_prediction(X)\n    check_is_fitted(self)\n    preds = self._tree.predict(X)\n    preds = preds[:, 1]\n    if return_array:\n        return preds\n    else:\n        return StepFunction(self.unique_times_, preds)\n\n", "CodeBleu_score": 29.77917574650073}, {"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n    self._validate_X_predict(X)\n    self._check_low_memory()\n    X = self._array_to_step_function(X)\n    self.check_is_fitted()\n    if check_input:\n        X = check_array(X, accept_sparse=True)\n    surv_func = self.tree_.predict(X)\n    surv_func = surv_func[:, 1]\n    if return_array:\n        return surv_func\n    return StepFunction(self.event_times_, surv_func)\n\n", "CodeBleu_score": 47.40441313718948}, {"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n    self._validate_X_predict(X, check_input)\n    self._check_low_memory()\n    X = self._array_to_step_function(X)\n    check_is_fitted(self, 'estimator_')\n    predict_function = self.estimator_.predict\n    if self.low_memory:\n        predict_function = self.estimator_.predict_low_memory\n    predictions = predict_function(X)\n    if return_array:\n        return predictions[:, 1]\n    unique_times = np.unique(X.data)\n    return StepFunction(unique_times, predictions[:, 1], 0)\n\n", "CodeBleu_score": 40.73338476899968}]}
{"instance_id": "84ae915b5933", "generation_result": [{"code": "def _pre_fit(self, X, y)\n\t\n    X = check_array_survival(X, self.allow_min_samples)\n    X = np.asfortranarray(X)\n\n    n_samples, n_features = X.shape\n    X_scales = np.ones(n_features, dtype=X.dtype)\n\n    # center and scale data\n    X_offset = np.zeros(n_features, dtype=X.dtype)\n    X_scale = np.ones(n_features, dtype=X.dtype)\n\n    if self.fit_baseline_model:\n        X_offset = np.mean(X, axis=0)\n        X -= X_offset\n        if self.normalize:\n            X, X_scales = f_normalize(X, axis=0, norm=\"l2\")\n\n    if self.normalize:\n        X /= X_scale\n\n    # sort\n    order = np.argsort(-y[:, 0])\n    X = X[order]\n    y = y[order]\n\n    return X, y[:, 0].astype(np.int_), y[:, 1], X_offset, X_scales\n\n", "CodeBleu_score": 29.930780574254012}, {"code": "def _pre_fit(self, X, y)\n\t\n\n    X, y = check_array_survival(X, y)\n\n    if self.fit_baseline_model:\n        X, y = self._fit_baseline_model(X, y)\n\n    if self.normalize:\n        self.feature_mean = X.mean(axis=0)\n        X -= self.feature_mean\n        self.feature_scale = X.std(axis=0)\n        self.feature_scale[self.feature_scale == 0] = 1\n        X /= self.feature_scale\n    else:\n        self.feature_mean = np.zeros(X.shape[1])\n        self.feature_scale = np.ones(X.shape[1])\n\n    self.n_samples_ = X.shape[0]\n\n    X = np.asfortranarray(X)\n    y = np.asfortranarray(y)\n\n    event, time = np.array(y[:, 0], dtype=int), y[:, 1]\n    order = np.argsort(-time, kind=\"mergesort\")\n\n    X = X[order]\n    event = event[order]\n    time = time[order]\n\n    return X, event, time\n\n", "CodeBleu_score": 26.88655688459215}, {"code": "def _pre_fit(self, X, y)\n\t\n    self._validate_data(X, y)\n    if self.min_samples is not None:\n        if self.min_samples < 1:\n            raise ValueError(\"min_samples must be positive integer\")\n        if self.min_samples > X.shape[0]:\n            raise ValueError(\"min_samples must be less than the number of samples\")\n    X = check_array_survival(X, self.allow_all_finite)\n    if X.dtype != np.float64:\n        X = X.astype(np.float64)\n    if y is not None:\n        y = check_array_survival(y, self.allow_all_finite)\n        event, time = y[:, 0], y[:, 1]\n        if np.any(event < 0) or np.any(event > 2):\n            raise ValueError(\"event must be 0 (censored), 1 (at risk), or 2 (death)\")\n        if np.any(time < 0):\n            raise ValueError(\"time must be non-negative\")\n        if np.any(np.diff(time) < 0):\n            raise ValueError(\"time must be sorted in ascending order\")\n    else:\n        event, time = np.ones(X.shape[0], dtype=np.int32), np.ones(X.shape[0], dtype=np.float64)\n    X_mean = X.mean(0)\n    X -= X_mean\n    if self.normalize:\n        X = f_normalize(X, axis=0)\n    X = np.asfortranarray(X)\n    order = np.argsort(-time)\n    X = X[order]\n    time = time[order]\n    event = event[order]\n    return X, event, time, X_mean, np.ones(X.shape[1], dtype=np.float64)\n\n", "CodeBleu_score": 35.82453984804965}]}
{"instance_id": "c70bb013f85f", "generation_result": [{"code": "def _check_alphas(self)\n\t\n    if self.alphas is None:\n        n_alphas = self.n_alphas\n        if not isinstance(n_alphas, int) or n_alphas <= 0:\n            raise ValueError(\"n_alphas must be a positive integer, got %r\" % n_alphas)\n        alphas = np.empty(n_alphas, dtype=float)\n        alphas[0] = self.alphas_[0]\n        for t in range(1, n_alphas):\n            alphas[t] = alphas[t - 1] + (self.alphas_[1] - self.alphas_[0]) * t / (n_alphas - 1)\n    else:\n        alphas = column_or_1d(self.alphas)\n        alphas = check_non_negative(alphas, \"alpha\")\n        alphas = assert_all_finite(alphas)\n        if len(alphas) < 2:\n            raise ValueError(\"alphas must have at least two elements, got %r\" % alphas)\n        if not alphas.ndim == 1:\n            raise ValueError(\"alphas must be a 1D array, got %r\" % alphas)\n        n_alphas = len(alphas)\n    return alphas, n_alphas\n\n", "CodeBleu_score": 43.43367054613919}, {"code": "def _check_alphas(self)\n\t\n    if self.alphas is None:\n        if self.n_alphas <= 0 or not isinstance(self.n_alphas, int):\n            raise ValueError(\"n_alphas=%r must be a positive integer\" % self.n_alphas)\n        alphas = np.empty(self.n_alphas)\n        self.alphas_ = alphas\n        self.dual_gap_ = np.inf\n        self.n_iter_ = 0\n        return alphas, True\n    else:\n        alphas = column_or_1d(self.alphas).astype(np.float64)\n        check_non_negative(alphas, \"Alphas must be non-negative\")\n        assert_all_finite(alphas)\n        self.alphas_ = alphas\n        self.dual_gap_ = np.inf\n        self.n_iter_ = 0\n        return alphas, False\n\n", "CodeBleu_score": 40.33039204195504}, {"code": "def _check_alphas(self)\n\t\n    if self.alphas is None:\n        n_alphas = self.n_alphas\n        if not (np.isscalar(n_alphas) and isinstance(n_alphas, int) and n_alphas > 0):\n            raise ValueError(\n                \"n_alphas=%r must be a positive integer, got: %r\" % (n_alphas, n_alphas)\n            )\n        alphas = np.empty(n_alphas)\n        self.alphas_ = alphas\n        return alphas, True\n    else:\n        alphas = column_or_1d(self.alphas)\n        alphas = check_non_negative(alphas, \"alpha\")\n        assert_all_finite(alphas)\n        self.alphas_ = alphas\n        return alphas, False\n\n", "CodeBleu_score": 40.4685259670356}]}
{"instance_id": "7b54a0554ba4", "generation_result": [{"code": "def nelson_aalen_estimator(event, time)\n\t\n    event, time = check_y_survival(event, time)\n    time, event = check_consistent_length(time, event)\n    unique_times = np.unique(time)\n    n_times = len(unique_times)\n    n_samples = len(event)\n    n_events = np.sum(event)\n    if n_samples == 0:\n        raise ValueError(\"No samples found.\")\n    if n_events == 0:\n        raise ValueError(\"No events found.\")\n    n_at_risk = n_samples * np.ones(n_times, dtype=float)\n    if n_samples == n_events:\n        raise ValueError(\"All samples have the same time. You cannot compute\" \" an estimator of the survival function.\")\n    for i in range(n_events):\n        mask = time[event == i]\n        n_at_risk -= np.bincount(np.searchsorted(unique_times, mask))\n    n_events = n_samples - n_events\n    if np.min(n_at_risk) < 0:\n        raise ValueError(\"All individuals are censored at one time.\")\n    if np.all(n_at_risk[0] == n_at_risk):\n        raise ValueError(\"All individuals have the same time.\")\n    n_events = n_samples - n_events\n    if np.min(n_at_risk) < 0:\n        raise ValueError(\"All individuals are censored at one time.\")\n    if np.all(n_at_risk[0] == n_at_risk):\n        raise ValueError(\"All individuals have the same time.\")\n    n_events = n_samples - n_events\n    if np.min(n_at_risk) < 0:\n        raise ValueError(\"All individuals are censored at one time.\")\n    if np.all(n_at_risk[0] == n_at_risk):\n        raise ValueError(\"All individuals have the same time.\")\n    n_events = n_samples - n_events\n    if np.min(n_at_risk) < 0", "CodeBleu_score": 26.92936243436256}, {"code": "def nelson_aalen_estimator(event, time)\n\t\n\n    # Validate the input data\n    event, time = check_y_survival(event, time)\n    check_consistent_length(event, time)\n\n    # Compute the unique times\n    unique_times = np.unique(time)\n\n    # Compute the number of events and subjects at risk at each time point\n    n_events = np.cumsum(event)\n    n_risk = np.arange(1, len(time) + 1)\n\n    # Compute the cumulative hazard\n    hazard = np.sum(n_events / n_risk)\n\n    return unique_times, hazard\n\n", "CodeBleu_score": 36.7574230500424}, {"code": "def nelson_aalen_estimator(event, time)\n\t\n    event, time = check_y_survival(event, time)\n    time, event = check_consistent_length(time, event)\n    unique_times = np.unique(time)\n    n_times = len(unique_times)\n    n_samples = len(time)\n    n_events = np.sum(event)\n    risk_set = np.ones(n_samples, dtype=int)\n    for i in range(n_times - 1):\n        val = unique_times[i]\n        ix = time > val\n        risk_set[ix] = np.sum(time > val)\n    # sort by time\n    order = np.argsort(time, kind=\"mergesort\")\n    uniq_event_times = np.zeros(n_events)\n    # loop through event times\n    i = 0\n    at_risk = n_samples\n    for t, e in zip(time[order], event[order]):\n        if e:\n            uniq_event_times[i] = t\n            i += 1\n            at_risk -= 1\n    uniq_event_times = np.unique(uniq_event_times)\n    # estimate cumulative hazard function\n    # divisor at risk\n    # numerator events\n    divisor = np.zeros(n_times, dtype=float)\n    for i, t in enumerate(unique_times):\n        ix = time >= t\n        n_risk = np.sum(risk_set[ix])\n        # handle case where tind all False\n        if n_risk > 0:\n            divisor[i] = n_risk\n    numerator = np.zeros(n_times, dtype=float)\n    for i, t in enumerate(uniq_event_times):\n        ix = time == t\n        numerator[i] = np.sum(event[ix])\n    # return unique times and cumulative sum\n    return unique_times, np.cumsum(numerator / divisor)\n\n", "CodeBleu_score": 28.767059759323406}]}
{"instance_id": "35af806300cc", "generation_result": [{"code": "def ipc_weights(event, time)\n\t\n    if all(event):\n        return np.ones(len(event))\n    km_times, km_survprob = kaplan_meier_estimator(event, time)\n    km_times_reverse = km_times[::-1]\n    km_survprob_reverse = km_survprob[::-1]\n    weights = np.ones(len(event))\n    for i in range(len(event)):\n        if event[i]:\n            t = time[i]\n            idx = max(0, np.searchsorted(km_times_reverse, t) - 1)\n            weights[i] = 1 / max(km_survprob_reverse[idx], 1e-10)\n    return weights\n\n", "CodeBleu_score": 33.41170906697586}, {"code": "def ipc_weights(event, time)\n\t\n    if event.all():\n        return np.ones(len(event))\n    km_times, km_survival = kaplan_meier_estimator(event, time)\n    weights = np.zeros(len(event))\n    weights[event == 1] = 1. / (km_survival[np.searchsorted(km_times, time[event == 1]) - 1])\n    return weights", "CodeBleu_score": 36.723765357576376}, {"code": "def ipc_weights(event, time)\n\t\n    if all(event):\n        return np.ones(len(event))\n    km_times, km_survival = kaplan_meier_estimator(event, time)\n    km_times = np.flipud(km_times)\n    km_survival = np.flipud(km_survival)\n    ipcw = np.zeros(len(event))\n    km_survival_prb = np.zeros(len(event))\n    pos = np.searchsorted(km_times, time)\n    km_survival_prb[pos == len(km_times)] = km_survival[pos == len(km_times)]\n    km_survival_prb[pos != len(km_times)] = km_survival[pos[pos != len(km_times)]]\n    km_survival_prb = np.clip(a=km_survival_prb, a_min=1.0e-300, a_max=None)\n    ipcw[event == 1] = 1.0 / km_survival_prb[event == 1]\n    return ipcw\n\n", "CodeBleu_score": 31.066801914157548}]}
{"instance_id": "72b19985ea11", "generation_result": [{"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n    if isinstance(dfs, pd.DataFrame):\n        dfs = [dfs]\n\n    if isinstance(dfs, BaseConnector):\n        dfs = [dfs]\n\n    if isinstance(dfs, list):\n        connectors = []\n        for df in dfs:\n            df_type = type(df)\n            if df_type is pd.DataFrame:\n                connectors.append(PandasConnector(df))\n            elif df_type is modin.pandas.dataframe.DataFrame:\n                connectors.append(ModinConnector(df))\n            elif df_type is pl.DataFrame:\n                connectors.append(PolarsConnector(df))\n            elif isinstance(df, BaseConnector):\n                connectors.append(df)\n            else:\n                raise ValueError(\n                    f\"Unsupported data type: {df_type}. \"\n                    \"Expected pandas, modin, polars, or a custom connector.\"\n                )\n        return connectors\n    else:\n        raise ValueError(\n            f\"Unsupported data type: {type(dfs)}. \"\n            \"Expected a single dataframe, a connector, or a list of dataframes.\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.552045076078365}, {"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n    if not isinstance(dfs, list):\n        dfs = [dfs]\n    connectors = []\n    for df in dfs:\n        df_type = type(df)\n        if df_type == pd.DataFrame:\n            connectors.append(PandasConnector(df))\n        elif df_type == pd.core.frame.DataFrame:\n            connectors.append(PandasConnector(df))\n        elif df_type == pd.core.frame.ModinDataFrame:\n            connectors.append(ModinConnector(df))\n        elif df_type == pl.DataFrame:\n            connectors.append(PolarsConnector(df))\n        elif df_type == BaseConnector:\n            connectors.append(df)\n        else:\n            raise ValueError(\n                \"Invalid data type. Expected pd.DataFrame, pd.core.frame.DataFrame, pd.core.frame.ModinDataFrame, pl.DataFrame, or BaseConnector.\"\n            )\n    return connectors\n\n\n", "CodeBleu_score": 39.817201178379015}, {"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n    if isinstance(dfs, pd.DataFrame):\n        dfs = [dfs]\n\n    if isinstance(dfs, BaseConnector):\n        dfs = [dfs]\n\n    if not isinstance(dfs, list):\n        raise ValueError(\n            \"Invalid input type. Expected pd.DataFrame, BaseConnector, or list.\"\n        )\n\n    connectors = []\n\n    for df in dfs:\n        df_type = type(df)\n        if df_type == pd.DataFrame:\n            connectors.append(PandasConnector(df))\n        elif df_type == modin.pandas.DataFrame:\n            connectors.append(ModinConnector(df))\n        elif df_type == pl.DataFrame:\n            connectors.append(PolarsConnector(df))\n        elif isinstance(df, BaseConnector):\n            connectors.append(df)\n        else:\n            raise ValueError(\n                f\"Invalid input type: {df_type}. Expected pd.DataFrame, modin.pandas.DataFrame, pl.DataFrame, or BaseConnector.\"\n            )\n\n    return connectors", "CodeBleu_score": 41.683721629608314}]}
{"instance_id": "cf22fb696e90", "generation_result": [{"code": "def execute(self) -> pd.DataFrame\n\t\n    if self._cached:\n        return pd.read_parquet(self._cached)\n    if self._cached_filtered:\n        return pd.read_parquet(self._cached_filtered)\n    if isinstance(self._data, pd.DataFrame):\n        return self._data\n    self._data = self._fetch_data()\n    return self._data", "CodeBleu_score": 58.589036382910145}, {"code": "def execute(self) -> pd.DataFrame\n\t\n    if self._cached:\n        return pd.read_parquet(self._cached)\n    if self._instance is not None:\n        return self._instance\n    self._instance = self._fetch_data()\n    if isinstance(self._instance, pd.DataFrame):\n        return self._instance\n    return self._instance.to_pandas()", "CodeBleu_score": 66.71163767324705}, {"code": "def execute(self) -> pd.DataFrame\n\t\n    if self._cached:\n        return pd.read_parquet(self._cached)\n    if self._filters:\n        return pd.read_parquet(self._cached_with_filters)\n    if isinstance(self._data, pd.DataFrame):\n        return self._data\n    self._data = self._fetch_data()\n    return self._data", "CodeBleu_score": 58.36006645238805}]}
{"instance_id": "21df5ecea95f", "generation_result": [{"code": "def column_hash(self)\n\t\n    if not isinstance(self, pd.DataFrame):\n        self.execute()\n    columns_str = \"|\".join(self.columns)\n    formula_str = self._build_formula()\n    combined_str = columns_str + formula_str\n    return hashlib.sha256(combined_str.encode()).hexdigest()\n\n", "CodeBleu_score": 45.20154538386078}, {"code": "def column_hash(self)\n\t\n    if not isinstance(self, pd.DataFrame):\n        self = self.execute()\n    columns_str = \"|\".join(self.columns)\n    return hashlib.sha256(\n        (columns_str + self._build_formula()).encode()\n    ).hexdigest()", "CodeBleu_score": 46.62098668772055}, {"code": "def column_hash(self)\n\t\n    if not isinstance(self, pd.DataFrame):\n        self.execute()\n    columns_str = \"|\".join(self.columns)\n    formula_str = self._build_formula()\n    return hashlib.sha256((columns_str + formula_str).encode()).hexdigest()\n\n", "CodeBleu_score": 44.12364977611973}]}
{"instance_id": "27ee5f415000", "generation_result": [{"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.Series):\n        df = df.to_frame()\n    elif isinstance(df, pd.DataFrame):\n        pass\n    elif isinstance(df, list):\n        df = pd.DataFrame(df)\n    elif isinstance(df, dict):\n        df = pd.DataFrame(df)\n    elif isinstance(df, str):\n        df = FileImporter.import_from_file(df)\n    else:\n        raise ValueError(\n            f\"Input data type {type(df)} is not supported. Supported types are: pandas.DataFrame, pandas.Series, list, dict, str.\"\n        )\n    return df", "CodeBleu_score": 46.84151064207438}, {"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.Series):\n        df = df.to_frame()\n    elif isinstance(df, pd.DataFrame):\n        pass\n    elif isinstance(df, str):\n        df = FileImporter.import_from_file(df)\n    elif isinstance(df, list):\n        df = pd.DataFrame(df)\n    elif isinstance(df, dict):\n        df = pd.DataFrame(df)\n    else:\n        raise ValueError(\n            \"The input type is not supported. Please provide a pandas DataFrame, pandas Series, list, or dict.\"\n        )\n    return df\n\n", "CodeBleu_score": 48.920718869861716}, {"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.Series):\n        df = df.to_frame()\n    elif isinstance(df, pd.DataFrame):\n        pass\n    elif isinstance(df, list):\n        df = pd.DataFrame(df)\n    elif isinstance(df, dict):\n        df = pd.DataFrame(df)\n    elif isinstance(df, str):\n        if df.endswith(\".csv\"):\n            df = pd.read_csv(df)\n        elif df.endswith(\".xlsx\"):\n            df = pd.read_excel(df)\n        elif df.endswith(\".json\"):\n            df = pd.read_json(df)\n        elif df.endswith(\".parquet\"):\n            df = pd.read_parquet(df)\n        else:\n            raise ValueError(\n                \"The file type is not supported. Please provide a file in one of the following formats: csv, xlsx, json, parquet\"\n            )\n    else:\n        raise ValueError(\n            \"The input type is not supported. Please provide a pandas DataFrame, pandas Series, list, or dictionary\"\n        )\n    return df\n\n", "CodeBleu_score": 45.882616281626845}]}
{"instance_id": "38f48a358606", "generation_result": [{"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n    if len(self) < n:\n        return self.sample(frac=1.0)\n    else:\n        return self._sample_column(n)\n\n", "CodeBleu_score": 11.53079900926008}, {"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n    if n >= len(self.df):\n        return self.df.sample(frac=1).reset_index(drop=True)\n\n    sample_columns = {\n        col: self._sample_column(col, n) for col in self.df.columns\n    }\n\n    sample_df = pd.DataFrame(sample_columns)\n    sample_df = self.anonymize_dataframe_head(sample_df)\n    return sample_df\n\n", "CodeBleu_score": 40.83336176397398}, {"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n    if len(self._dataframe) < n:\n        return self._dataframe.sample(frac=1).reset_index(drop=True)\n    else:\n        sample_dict = {}\n        for column in self._dataframe.columns:\n            if column in self._sample_column:\n                sample_dict[column] = self._sample_column[column](self._dataframe[column], n)\n            else:\n                sample_dict[column] = self._dataframe[column].sample(n).tolist()\n        sample_df = pd.DataFrame(sample_dict)\n        anonymized_sample_df = Anonymizer.anonymize_dataframe_head(sample_df, self._anonymize_columns)\n        return anonymized_sample_df\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.06618965202229}]}
{"instance_id": "8bddad2e31ca", "generation_result": [{"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    name = extras.get(\"name\", \"\")\n    description = extras.get(\"description\", \"\")\n    df_str = df.to_csv()\n    df_str = df_str.replace(\"", "CodeBleu_score": 21.18441274547501}, {"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    df_name = df.name\n    df_description = extras.get(\"description\")\n    df_details = extras.get(\"details\")\n    df_details_str = \"\"\n    if df_details:\n        df_details_str = \"", "CodeBleu_score": 24.72495776717839}, {"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    df_name = df.name\n    df_desc = df.desc\n    df_rows = df.shape[0]\n    df_cols = df.shape[1]\n    df_cols_list = list(df.columns)\n    df_cols_str = \", \".join(df_cols_list)\n    df_csv = df.to_csv(index=False)\n    df_csv_lines = df_csv.split(\"", "CodeBleu_score": 23.023597607700946}]}
{"instance_id": "5380bb60fd39", "generation_result": [{"code": "def convert_df_sql_connector_to_str\n\t\n    # Get the table name and description from the DataFrame metadata\n    table_name = df.get_table_name()\n    table_description = df.get_table_description()\n\n    # Construct the opening table tag with the table name and optional description\n    html = f'<table name=\"{table_name}\">'\n    if table_description:\n        html += f'<p>{table_description}</p>'\n\n    # Add the CSV representation of the DataFrame's head\n    html += df.get_head().to_csv()\n\n    # Close the table tag and return the complete HTML string\n    html += '</table>'\n    return html", "CodeBleu_score": 36.197765589815425}, {"code": "def convert_df_sql_connector_to_str\n\t\n    # Extract the table name and description from the DataFrame metadata\n    table_name = df.get_head\n    description = df.to_csv\n\n    # Construct the opening table tag with the table name and optional description\n    html = f\"<table name='{table_name}'>\"\n    if description:\n        html += f\"<caption>{description}</caption>\"\n\n    # Add the CSV representation of the DataFrame's head\n    html += df.head().to_csv(index=False)\n\n    # Close the table tag and return the complete HTML string\n    html += \"</table>\"\n    return html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.73532870317436}, {"code": "def convert_df_sql_connector_to_str\n\t\n    df = pd.read_csv(\"data.csv\")\n    html = df.to_html()\n    return html\n\n", "CodeBleu_score": 11.918266997027711}]}
{"instance_id": "0afd995716c5", "generation_result": [{"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t\n    json_str = self.convert_df_to_json(df, extras)\n    yml_str = yaml.dump(json_str)\n    if extras.get(\"is_direct_sql\", False):\n        yml_str = f\"<table>{yml_str}</table>\"\n    return yml_str\n\n", "CodeBleu_score": 56.27404385901208}, {"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t\n    json_string = self.convert_df_to_json(df, extras)\n    yaml_string = yaml.dump(json_string)\n    if extras.get(\"is_direct_sql\", False):\n        yaml_string = f\"<table>{yaml_string}</table>\"\n    return yaml_string\n\n", "CodeBleu_score": 51.720844201834524}, {"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t\n    json_str = self.convert_df_to_json(df, extras)\n    yml_str = yaml.dump(json.loads(json_str))\n    if extras.get(\"is_direct_sql\", False):\n        return f\"<table>{yml_str}</table>\"\n    return yml_str\n\n", "CodeBleu_score": 60.20682425019539}]}
{"instance_id": "e2b90ebd4e5d", "generation_result": [{"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if not expected_type:\n        return True\n    if expected_type == \"number\":\n        return isinstance(self.value, (int, float))\n    if expected_type == \"string\":\n        return isinstance(self.value, str)\n    if expected_type == \"dataframe\":\n        return isinstance(self.value, (pd.DataFrame, pd.Series))\n    if expected_type == \"plot\":\n        return isinstance(self.value, str) and re.match(\n            r\"^\\w+\\.(png|jpg|jpeg|gif|svg|pdf)$\", self.value\n        ) or isinstance(self.value, dict)\n    return False\n\n", "CodeBleu_score": 56.143228249579835}, {"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if not expected_type:\n        return True\n    if expected_type == \"number\":\n        return isinstance(self.value, (int, float))\n    if expected_type == \"string\":\n        return isinstance(self.value, str)\n    if expected_type == \"dataframe\":\n        return isinstance(self.value, (pd.DataFrame, pd.Series))\n    if expected_type == \"plot\":\n        return (\n            isinstance(self.value, str)\n            and re.match(r\"^[a-zA-Z0-9_\\-\\.]+\\.(png|jpg|jpeg|gif|svg)$\", self.value)\n            or isinstance(self.value, dict)\n        )\n    return False\n\n", "CodeBleu_score": 57.17107521762564}, {"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if expected_type == \"\":\n        return True\n    if expected_type == \"number\":\n        return isinstance(self.value, int) or isinstance(self.value, float)\n    if expected_type == \"string\":\n        return isinstance(self.value, str)\n    if expected_type == \"dataframe\":\n        return isinstance(self.value, pd.DataFrame) or isinstance(self.value, pd.Series)\n    if expected_type == \"plot\":\n        return isinstance(self.value, str) and re.match(r\"^[a-zA-Z0-9_]+\\.png$\", self.value) or isinstance(self.value, dict)\n    if expected_type == \"list\":\n        return isinstance(self.value, list)\n    if expected_type == \"dict\":\n        return isinstance(self.value, dict)\n    if expected_type == \"bool\":\n        return isinstance(self.value, bool)\n    if expected_type == \"int\":\n        return isinstance(self.value, int)\n    if expected_type == \"float\":\n        return isinstance(self.value, float)\n    if expected_type == \"date\":\n        return isinstance(self.value, datetime.date)\n    if expected_type == \"datetime\":\n        return isinstance(self.value, datetime.datetime)\n    if expected_type == \"time\":\n        return isinstance(self.value, datetime.time)\n    if expected_type == \"timedelta\":\n        return isinstance(self.value, datetime.timedelta)\n    if expected_type == \"set\":\n        return isinstance(self.value, set)\n    if expected_type == \"tuple\":\n        return isinstance(self.value, tuple)\n    if expected_type == \"frozenset\":\n        return isinstance(self.value, frozenset)\n    if expected_type == \"bytes\":\n        return isinstance(self.value, bytes)\n    if expected_type == \"bytearray\":\n        return isinstance(self.value, bytearray)\n    if expected_type == \"memoryview\":\n        return is", "CodeBleu_score": 38.94114862964286}]}
{"instance_id": "d95828fdcbcb", "generation_result": [{"code": " def _distance(self, X, X2=None)\n\t\n    if X2 is None:\n        if isinstance(self.distance, str):\n            return pairwise_distance(X, metric=self.distance, **self.distance_params)\n        else:\n            sig = signature(self.distance)\n            if len(sig.parameters) == 1:\n                return self.distance(X, **self.distance_params)\n            else:\n                return self.distance(X, X, **self.distance_params)\n    else:\n        if isinstance(self.distance, str):\n            return pairwise_distance(X, X2, metric=self.distance, **self.distance_params)\n        else:\n            return self.distance(X, X2, **self.distance_params)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.07417774160735}, {"code": " def _distance(self, X, X2=None)\n\t\n    if X2 is None:\n        if isinstance(self.distance, str):\n            return pairwise_distance(X, metric=self.distance, **self.distance_params)\n        else:\n            sig = signature(self.distance)\n            if len(sig.parameters) == 1:\n                return self.distance(X, **self.distance_params)\n            else:\n                return self.distance(X, X, **self.distance_params)\n    else:\n        if isinstance(self.distance, str):\n            return pairwise_distance(X, X2, metric=self.distance, **self.distance_params)\n        else:\n            return self.distance(X, X2, **self.distance_params)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.07417774160735}, {"code": " def _distance(self, X, X2=None)\n\t\n    if X2 is None:\n        if isinstance(self.distance, str):\n            return pairwise_distance(X, metric=self.distance, **self.distance_params)\n        else:\n            return self.distance(X, **self.distance_params)\n    else:\n        if isinstance(self.distance, str):\n            return pairwise_distance(X, X2, metric=self.distance, **self.distance_params)\n        else:\n            return self.distance(X, X2, **self.distance_params)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 20.165725207265577}]}
{"instance_id": "497d73b298ee", "generation_result": [{"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if not isinstance(X, pd.DataFrame):\n        X = pd.DataFrame(X)\n    if len(X) == 0:\n        raise ValueError(\"X must contain at least one time series.\")\n    if X.shape[0] != X.shape[1]:\n        X_w_ix = X.reset_index(drop=True)\n        X_pivot = X_w_ix.pivot(\n            index=X_w_ix.columns[0], columns=X_w_ix.columns[1], values=X_w_ix.columns[2]\n        )\n        X_pivot = X_pivot.fillna(0)\n        X_np = X_pivot.to_numpy()\n        X_len = X_pivot.apply(lambda x: x.size, axis=1).to_numpy()\n        X_np = np.concatenate([X_len.reshape(-1, 1), X_np], axis=1)\n    else:\n        if isinstance(X.iloc[0, 0], (np.ndarray, np.generic)):\n            X_np = np.concatenate([X.iloc[i, :].values.reshape(1, -1) for i in range(X.shape[0])])\n        else:\n            X_np = X.to_numpy()\n    return X_np", "CodeBleu_score": 40.19425716892644}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    # Check if X is a pandas DataFrame\n    if isinstance(X, pd.DataFrame):\n        # Reset the index of X\n        X_w_ix = X.reset_index()\n        # Pivot the data to convert it to a 2D format\n        X_pivot = X_w_ix.pivot(index=\"index\", columns=\"dim_0\", values=\"value\")\n        # Fill missing values with zeros\n        X_pivot_fill = X_pivot.fillna(0)\n        # Convert the pivoted data to a numpy array\n        X_np = X_pivot_fill.to_numpy()\n        # Calculate the lengths of individual series\n        X_lengths = X_w_ix.groupby(\"index\").size()\n        # Concatenate the lengths as the first column\n        X_np_w_lengths = np.concatenate(\n            (X_lengths.to_numpy().reshape(-1, 1), X_np), axis=1\n        )\n        return X_np_w_lengths\n    # If X is not a pandas DataFrame, check if it is a numpy array\n    elif isinstance(X, np.ndarray):\n        # If X is already a 2D numpy array, return it as is\n        return X\n    # If X is neither a pandas DataFrame nor a numpy array, raise an error\n    else:\n        raise TypeError(\n            f\"Input data X must be either a pandas DataFrame or a 2D numpy array. Got {type(X)} instead.\"\n        )", "CodeBleu_score": 42.36713415823205}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if not isinstance(X, pd.DataFrame):\n        raise ValueError(\"Input data X must be a pandas DataFrame.\")\n    if not all(X.index == X.iloc[0].index):\n        X = X.reset_index(drop=True)\n        X_pivot = X.pivot(\n            index=None, columns=\"series_id\", values=\"value\"\n        )  # pivots dataframe from long to wide format\n        X_pivot = X_pivot.fillna(\n            0\n        )  # fills missing values with 0 (for unequal length series)\n        X = X_pivot.to_numpy()\n        lengths = X_pivot.apply(lambda x: x.count(), axis=1).to_numpy()\n        X = np.concatenate([lengths.reshape(-1, 1), X], axis=1)\n    else:\n        X = X.to_numpy()\n    return X\n\n", "CodeBleu_score": 40.76413432522209}]}
{"instance_id": "8798260a6f12", "generation_result": [{"code": "def is_sklearn_estimator(obj)\n\t\n    return isclass(obj) and issubclass(obj, SklearnBaseEstimator) and not issubclass(\n        obj, BaseObject\n    )\n\n", "CodeBleu_score": 14.606920579869897}, {"code": "def is_sklearn_estimator(obj)\n\t\n    if not isclass(obj):\n        return False\n    if issubclass(obj, SklearnBaseEstimator):\n        return True\n    if issubclass(obj, BaseObject):\n        return False\n    return False\n\n", "CodeBleu_score": 23.551377569063057}, {"code": "def is_sklearn_estimator(obj)\n\t\n    if not isclass(obj):\n        return False\n    if issubclass(obj, SklearnBaseEstimator):\n        return True\n    if issubclass(obj, BaseObject):\n        return False\n    return False\n\n", "CodeBleu_score": 23.551377569063057}]}
{"instance_id": "2ab2596d8520", "generation_result": [{"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        other_pipe = TransformerPipeline([other])\n        return SklearnRegressorPipeline(\n            regressor=self.regressor, transformer=other_pipe * self.transformer\n        )\n    else:\n        return NotImplemented\n\n", "CodeBleu_score": 35.35163937101993}, {"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        other_pipeline = TransformerPipeline([other])\n        return SklearnRegressorPipeline(\n            steps=[*self.steps[:-1], (other.name, other_pipeline)]\n        )\n    else:\n        return NotImplemented\n\n", "CodeBleu_score": 29.944150302793034}, {"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        transformer_pipeline = other * self.transformer_pipeline\n        return SklearnRegressorPipeline(\n            regressor=self.regressor, transformer_pipeline=transformer_pipeline\n        )\n    return NotImplemented\n\n", "CodeBleu_score": 38.387746350314075}]}
{"instance_id": "5c1c6d14ca93", "generation_result": [{"code": "def prep_skl_df(df, copy_df=False)\n\t\n    if copy_df:\n        df = df.copy()\n    cols = df.columns\n    cols = cols.astype(str)\n    if not cols.isin(df.columns).all():\n        df.columns = cols\n    return df", "CodeBleu_score": 61.719080151247915}, {"code": "def prep_skl_df(df, copy_df=False)\n\t\n    if copy_df:\n        df = df.copy()\n    df.columns = df.columns.astype(str)\n    if not all(isinstance(col, str) for col in df.columns):\n        df.columns = df.columns.astype(str)\n    return df\n\n", "CodeBleu_score": 52.43519404087256}, {"code": "def prep_skl_df(df, copy_df=False)\n\t\n    cols = df.columns\n    cols = cols.astype(str)\n    if copy_df:\n        df = df.copy()\n    df.columns = cols\n    return df\n\n", "CodeBleu_score": 33.25700065992481}]}
{"instance_id": "d5e567c20361", "generation_result": [{"code": "def predict(self, X)\n\t\n    check_is_fitted(self)\n    X = self._validate_data(X, reset=False)\n    prob = self.predict_proba(X)\n    rng = check_random_state(self.random_state)\n    return self.classes_[np.flatnonzero(prob == prob.max(axis=1))[\n        rng.choice(np.flatnonzero(prob == prob.max(axis=1)), size=len(X), replace=True)\n    ]]\n\n", "CodeBleu_score": 40.67439731228869}, {"code": "def predict(self, X)\n\t\n    prob = self.predict_proba(X)\n    rng = check_random_state(self.random_state)\n    return self.classes_[np.flatnonzero(prob == prob.max(1))[\n        rng.choice(np.flatnonzero(prob == prob.max(1)), 1)\n    ]]\n\n", "CodeBleu_score": 40.01813517152154}, {"code": "def predict(self, X)\n\t\n    rng = check_random_state(self.random_state)\n    prob = self.predict_proba(X)\n    if prob.ndim == 1:\n        return self.classes_[np.argmax(prob, axis=1)]\n    else:\n        pred = prob.argmax(axis=1)\n        return self.classes_[pred]\n", "CodeBleu_score": 35.483579538842136}]}
{"instance_id": "210b60dffd55", "generation_result": [{"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n    X_transformed = []\n    for i, group in enumerate(groups):\n        X_transformed.append(pcas[i].transform(X[:, group]))\n    X_transformed = np.concatenate(X_transformed, axis=1)\n    X_transformed = np.nan_to_num(X_transformed)\n    if X_transformed.shape[1] != clf.coef_.shape[1]:\n        X_transformed = np.concatenate([X_transformed, np.zeros((X_transformed.shape[0], clf.coef_.shape[1] - X_transformed.shape[1]))], axis=1)\n    probas = clf.predict_proba(X_transformed)\n    if probas.shape[1] != len(self.classes_):\n        probas2 = np.zeros((len(X), len(self.classes_)))\n        for i, c in enumerate(self.classes_):\n            probas2[:, i] = probas[:, c]\n        probas = probas2\n    return probas\n\n", "CodeBleu_score": 45.58421514266314}, {"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n    X_transformed = []\n    for i, pc in enumerate(pcas):\n        X_transformed.append(pc.transform(X[:, groups[i]]))\n    X_transformed = np.concatenate(X_transformed, axis=1)\n    X_transformed = np.nan_to_num(X_transformed)\n    y_proba = clf.predict_proba(X_transformed)\n    if y_proba.shape[1] != self.n_classes_:\n        y_proba_new = np.zeros((y_proba.shape[0], self.n_classes_))\n        for i, j in enumerate(self.classes_):\n            y_proba_new[:, j] = y_proba[:, i]\n        y_proba = y_proba_new\n    return y_proba\n\n", "CodeBleu_score": 44.16802721550354}, {"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n    X_ = np.zeros((X.shape[0], 0))\n    for i, group in enumerate(groups):\n        X_ = np.concatenate((X_, pcas[i].transform(X[:, group])), axis=1)\n    X_ = np.nan_to_num(X_)\n    return clf.predict_proba(X_)\n\n", "CodeBleu_score": 26.33415421923552}]}
{"instance_id": "9436ee0860bb", "generation_result": [{"code": "def predict_proba(self, X)\n\t\n    check_is_fitted(self)\n\n    if self.n_classes_ == 1:\n        return np.ones((X.shape[0], 1))\n\n    if X.ndim == 3:\n        X = np.reshape(X, (X.shape[0], X.shape[1] * X.shape[2]))\n    elif X.ndim == 2:\n        pass\n    else:\n        raise ValueError(\n            \"Array of input data must have 2 or 3 dimensions, but found: \"\n            \"{0}\".format(X.ndim)\n        )\n\n    X = self._validate_data(X, reset=False)\n    X = np.atleast_2d(X)\n\n    predictions = []\n    for instance in range(X.shape[0]):\n        preds = np.zeros(self.n_classes_)\n        self.root.predict_proba(X[instance, :], preds)\n        predictions.append(preds)\n\n    predictions = np.array(predictions)\n    return predictions", "CodeBleu_score": 35.45247494931723}, {"code": "def predict_proba(self, X)\n\t\n    check_is_fitted(self)\n    if self.n_classes_ == 1:\n        return np.ones((X.shape[0], 1))\n    if X.ndim == 3 and X.shape[2] == 1:\n        X = np.reshape(X, (X.shape[0], X.shape[1]))\n    elif X.ndim != 2:\n        raise ValueError(\"X must be 2D or 3D with 1 feature\")\n    X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\", reset=False)\n    proba = np.zeros((X.shape[0], self.n_classes_), dtype=DTYPE)\n    for i in range(X.shape[0]):\n        proba[i, :] = self.root_.predict_proba(X[i, :], self.n_classes_)\n    return proba\n\n", "CodeBleu_score": 36.189579636373445}, {"code": "def predict_proba(self, X)\n\t\n    check_is_fitted(self)\n\n    if self.n_classes_ == 1:\n        return np.ones((X.shape[0], 1))\n\n    if X.ndim == 3 and X.shape[2] == 1:\n        X = np.reshape(X, (X.shape[0], X.shape[1]))\n    elif X.ndim != 2:\n        raise ValueError(\"Input data must be a 2D or 3D numpy array with a single feature.\")\n\n    X = self._validate_data(X, dtype=DTYPE, accept_sparse='csr', reset=False)\n\n    probs = np.zeros((X.shape[0], self.n_classes_), dtype=DTYPE)\n    for i in range(X.shape[0]):\n        probs[i, :] = self.root_.predict_proba(X[i, :])\n\n    return probs\n\n", "CodeBleu_score": 36.51342332065294}]}
{"instance_id": "d7cb1cb66840", "generation_result": [{"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if self.transformers_ is None:\n        return X\n    else:\n        scitype = get_tag(self.transformers_, \"scitype:transform-output\")\n        if scitype == \"Primitives\":\n            return convert_to(X, \"numpy2D\", \"Panel\")\n        elif scitype == \"Series\":\n            return convert_to(X, \"numpyflat\", \"Panel\")\n        else:\n            raise TypeError(\n                \"unexpected output scitype from transformers: \" f\"{scitype}\"\n            )", "CodeBleu_score": 30.036650313578615}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if self.transformers_ is None:\n        return X\n    else:\n        if self.transformers_ == \"drop\":\n            return X\n        else:\n            if self.transformers_ == \"passthrough\":\n                Xt = X\n            else:\n                Xt = self.transformers_.transform(X)\n            if (Xt.ndim > 2) and (self.get_tag(\"scitype:transform-output\") == \"Series\"):\n                Xt = Xt.flatten(order=\"F\")\n            if Xt.ndim == 1:\n                Xt = Xt.reshape(-1, 1)\n            return Xt\n\n", "CodeBleu_score": 33.333949064184765}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if self.transformers_ is None:\n        return X\n\n    scitype = get_tag(self.transformers_, \"scitype:transform-output\")\n    if scitype == \"Primitives\":\n        return convert_to(X, \"numpy3D\")\n    elif scitype == \"Series\":\n        return convert_to(X, \"numpyflat\")\n    else:\n        raise TypeError(\n            f\"unexpected output scitype {scitype} from transformers, \"\n            f\"expected 'Primitives' or 'Series'\"\n        )", "CodeBleu_score": 31.84363287578609}]}
{"instance_id": "497cb75f2b4d", "generation_result": [{"code": "def set_random_state(estimator, random_state=0)\n\t\n    random_state = check_random_state(random_state)\n    params = {}\n    for param in estimator.get_params(deep=False):\n        if param.endswith(\"random_state\"):\n            params[param] = random_state.randint(np.iinfo(np.int32).max)\n    if len(params) > 0:\n        estimator.set_params(**params)\n\n", "CodeBleu_score": 44.17740146449562}, {"code": "def set_random_state(estimator, random_state=0)\n\t\n    random_state = check_random_state(random_state)\n    params = {}\n    for key in sorted(estimator.get_params(deep=True)):\n        if key.endswith('random_state'):\n            params[key] = random_state.randint(np.iinfo(np.int32).max)\n    if params:\n        estimator.set_params(**params)\n\n", "CodeBleu_score": 55.27296739867382}, {"code": "def set_random_state(estimator, random_state=0)\n\t\n    random_state = check_random_state(random_state)\n    params = {}\n    for key in estimator.get_params(deep=True):\n        if key.endswith(\"random_state\") or key.endswith(\"seed\"):\n            params[key] = random_state.randint(0, np.iinfo(np.int32).max)\n    if params:\n        estimator.set_params(**params)\n\n", "CodeBleu_score": 49.073839677657034}]}
{"instance_id": "59ffd1d596a1", "generation_result": [{"code": "def _transform(X, intervals)\n\t\n    n_instances, n_intervals = X.shape[0], intervals.shape[0]\n    transformed = np.empty((n_instances, n_intervals * 3))\n    for i in range(n_intervals):\n        start, end = intervals[i]\n        slice_ = X[:, start:end]\n        mean_ = np.mean(slice_, axis=1)\n        std_ = np.std(slice_, axis=1)\n        slope_ = np.apply_along_axis(_slope, 1, slice_)\n        transformed[:, i * 3] = mean_\n        transformed[:, i * 3 + 1] = std_\n        transformed[:, i * 3 + 2] = slope_\n    return transformed.transpose()\n\n", "CodeBleu_score": 35.22136910385411}, {"code": "def _transform(X, intervals)\n\t\n    num_instances, num_intervals = intervals.shape\n    transformed = np.empty((num_instances, num_intervals * 3))\n    for i in range(num_instances):\n        for j in range(num_intervals):\n            start, end = intervals[i, j]\n            s = X[start:end]\n            m = np.mean(s)\n            std = np.std(s)\n            slope = np.mean(np.diff(s))\n            transformed[i, j * 3 : (j * 3) + 3] = [m, std, slope]\n    return transformed.transpose()\n\n", "CodeBleu_score": 24.716892871408543}, {"code": "def _transform(X, intervals)\n\t\n    n_instances, n_features = X.shape\n    n_intervals = len(intervals)\n    transformed = np.empty((n_instances, n_intervals * 3 * n_features))\n    for i, interval in enumerate(intervals):\n        start, end = interval\n        for j in range(n_features):\n            x = X[:, j]\n            mean = np.mean(x[start:end])\n            std = np.std(x[start:end])\n            slope = np.mean(np.diff(x[start:end]))\n            transformed[:, i * 3 * n_features + j * 3] = mean\n            transformed[:, i * 3 * n_features + j * 3 + 1] = std\n            transformed[:, i * 3 * n_features + j * 3 + 2] = slope\n    return transformed.transpose()\n\n", "CodeBleu_score": 27.828973173105176}]}
{"instance_id": "5a01594eebfb", "generation_result": [{"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n    if annotation_params is None:\n        annotation_params = {}\n    if ax_op_before is None:\n        ax_op_before = []\n    if ax_op_after is None:\n        ax_op_after = []\n    if annotate_params is None:\n        annotate_params = {}\n    self.new_plot(plot, plot_params, *args, **kwargs)\n    self._apply_ax_operations(ax_op_before)\n    self.configure(configuration)\n    self.annotate(annotation_func, annotation_params, *args, **annotate_params)\n    self._apply_ax_operations(ax_op_after)\n    return self._get_output()\n\n", "CodeBleu_score": 48.42116039312476}, {"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n    if annotation_params is None:\n        annotation_params = {}\n    if ax_op_before is None:\n        ax_op_before = []\n    if ax_op_after is None:\n        ax_op_after = []\n    if annotate_params is None:\n        annotate_params = {}\n\n    # Initialize annotation and operation parameters\n    annotation_params = empty_dict_if_none(annotation_params)\n    ax_op_before = empty_dict_if_none(ax_op_before)\n    ax_op_after = empty_dict_if_none(ax_op_after)\n    annotate_params = empty_dict_if_none(annotate_params)\n\n    # Create the plot with given parameters and apply pre-plot axis operations\n    self.new_plot(plot, plot_params)\n    self.annotate(annotation_func, *args, **annotation_params)\n    self.configure(configuration)\n    _apply_ax_operations(self, ax_op_before)\n\n    # Configure and annotate the plot based on provided configuration and annotation functions\n    self.configure(configuration)\n    self.annotate(annotation_func, *args, **annotation_params)\n\n    # Apply post-plot axis operations\n    _apply_ax_operations(self, ax_op_after)\n\n    # Return the output of the plotting process\n    return self._get_output()\n\n", "CodeBleu_score": 53.992501517000825}, {"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n    # Initialize annotation and operation parameters if they are not provided\n    if annotation_params is None:\n        annotation_params = {}\n    if ax_op_before is None:\n        ax_op_before = []\n    if ax_op_after is None:\n        ax_op_after = []\n\n    # Create the plot with given parameters and apply pre-plot axis operations\n    self.new_plot(plot, plot_params, *args, **kwargs)\n    self._apply_ax_operations(ax_op_before)\n\n    # Configure and annotate the plot based on provided configuration and annotation functions\n    self.configure(configuration)\n    self.annotate(annotation_func, *args, **annotation_params)\n\n    # Apply post-plot axis operations\n    self._apply_ax_operations(ax_op_after)\n\n    # Return the output of the plotting process\n    return self._get_output()", "CodeBleu_score": 48.17490535982778}]}
{"instance_id": "b5b17d312c74", "generation_result": [{"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, \"_program\"):\n        raise NotFittedError(\"This %s instance is not fitted yet\" % self.__class__.__name__)\n    X = check_array(X)\n    if X.shape[1] != self._expected_n_features:\n        raise ValueError(\n            \"X has %d features per sample; expecting %d\"\n            % (X.shape[1], self._expected_n_features)\n        )\n    scores = self._program.execute(X)\n    scores = scores.reshape(X.shape[0], 1)\n    probas = np.vstack((1 - scores, scores)).T\n    return probas\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 44.51802360506145}, {"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, \"_program\"):\n        raise NotFittedError(\"This %(name)s instance is not fitted yet\" % {\"name\": type(self).__name__})\n\n    X = check_array(X, accept_sparse=\"csr\")\n    if X.shape[1] != self.n_features_in_:\n        raise ValueError(\"X has %d features per sample; expecting %d\" % (X.shape[1], self.n_features_in_))\n\n    scores = self.execute(X)\n    scores = np.vstack([-scores, scores]).T\n    return softmax(scores)\n\n", "CodeBleu_score": 38.22094541185534}, {"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, \"_program\"):\n        raise NotFittedError(\"This instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.\")\n    X = check_array(X)\n    if X.shape[1] != self._n_features_in:\n        raise ValueError(f\"Expected {self._n_features_in} features, got {X.shape[1]}\")\n    scores = self._execute(X)\n    probs = self._transformer(scores)\n    return np.vstack((1 - probs, probs)).T\n\n", "CodeBleu_score": 35.992509595892734}]}
{"instance_id": "83f71c959df7", "generation_result": [{"code": "def point_mutation(self, random_state)\n\t\n    new_program = self.copy()\n    nodes_to_modify = np.where(random_state.uniform(size=len(new_program)) < self.mutation_probability)[0]\n    for node_index in nodes_to_modify:\n        node = new_program[node_index]\n        if isinstance(node, Function):\n            new_function = self._get_valid_replacement(node, random_state)\n            new_program[node_index] = new_function\n        else:\n            if random_state.uniform() < 0.5:\n                new_program[node_index] = self._get_valid_constant(random_state)\n            else:\n                new_program[node_index] = self._get_valid_variable(random_state)\n    return new_program, nodes_to_modify.tolist()\n\n", "CodeBleu_score": 22.020729669207036}, {"code": "def point_mutation(self, random_state)\n\t\n    program = copy.deepcopy(self)\n    nodes_to_modify = []\n    for i in range(len(program)):\n        if random_state.uniform() < self.mutation_probability:\n            nodes_to_modify.append(i)\n    for node_index in nodes_to_modify:\n        node = program[node_index]\n        if isinstance(node, Function):\n            arity = node.arity\n            valid_functions = [f for f in self.functions if f.arity == arity]\n            new_node = random_state.choice(valid_functions)\n            program[node_index] = new_node\n        elif isinstance(node, Terminal):\n            if random_state.uniform() < 0.5:\n                new_node = random_state.uniform(self.constant_range[0], self.constant_range[1])\n            else:\n                new_node = Variable(random_state.randint(0, self.num_features - 1))\n            program[node_index] = new_node\n    return program, nodes_to_modify\n\n", "CodeBleu_score": 24.859145914660154}, {"code": "def point_mutation(self, random_state)\n\t\n    program = self.copy()\n    nodes_to_modify = np.where(random_state.uniform(0, 1, len(program)) < self.point_mutation_prob)[0]\n    for node_index in nodes_to_modify:\n        node = program[node_index]\n        if isinstance(node, Function):\n            replacement_function = self.random_function(random_state, node.arity)\n            node.function = replacement_function\n        else:\n            if random_state.uniform(0, 1) < 0.5:\n                replacement_constant = random_state.uniform(self.constant_range[0], self.constant_range[1])\n                node.terminal = replacement_constant\n            else:\n                replacement_variable = random_state.randint(0, self.n_features)\n                node.terminal = replacement_variable\n    return program, nodes_to_modify\n\n", "CodeBleu_score": 25.511596819997667}]}
{"instance_id": "f1853251e671", "generation_result": [{"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n    # Validate Arguments\n    close = verify_series(close)\n    length = int(length) if length and length > 0 else 26\n    mamode = mamode.lower() if mamode and isinstance(mamode, str) else \"sma\"\n    offset = get_offset(offset)\n\n    # Calculate Result\n    if mamode == \"ema\":\n        ma = close.ewm(span=length, min_periods=length).mean()\n    else:\n        ma = close.rolling(length).mean()\n\n    bias = (close / ma) - 1\n\n    # Offset\n    if offset != 0:\n        bias = bias.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        bias.fillna(kwargs[\"fillna\"], inplace=True)\n    if \"fill_method\" in kwargs:\n        bias.fillna(method=kwargs[\"fill_method\"], inplace=True)\n\n    # Name and Categorize it\n    bias.name = f\"BIAS_{length}_{mamode}\"\n    bias.category = \"momentum\"\n\n    return bias", "CodeBleu_score": 61.96018440088798}, {"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n    close = verify_series(close)\n    length = int(length) if length and length > 0 else 26\n    min_periods = int(kwargs[\"min_periods\"]) if \"min_periods\" in kwargs and kwargs[\"min_periods\"] is not None else length\n    mamode = mamode.lower() if mamode else \"sma\"\n    offset = get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    if mamode == \"sma\":\n        ma = close.rolling(length, min_periods=min_periods).mean()\n    else:\n        raise ValueError(\"mamode must be either 'sma'\")\n\n    bias = (close - ma) / ma\n\n    # Offset\n    if offset != 0:\n        bias = bias.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        bias.fillna(kwargs[\"fillna\"], inplace=True)\n    if \"fill_method\" in kwargs:\n        bias.fillna(method=kwargs[\"fill_method\"], inplace=True)\n\n    # Name and Categorize it\n    bias.name = f\"BIAS_{length}\"\n    bias.category = \"momentum\"\n\n    return bias", "CodeBleu_score": 57.552855202088956}, {"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n    close = verify_series(close)\n    length = int(length) if length and length > 0 else 26\n    mamode = mamode.lower() if isinstance(mamode, str) else \"sma\"\n    offset = get_offset(offset)\n    if close is None: return\n\n    # Calculate Result\n    if mamode == \"ema\":\n        MA = close.ewm(span=length, min_periods=length).mean()\n    else:\n        MA = close.rolling(length).mean()\n    BIAS = (close / MA) - 1\n\n    # Offset\n    if offset != 0:\n        BIAS = BIAS.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        BIAS.fillna(kwargs[\"fillna\"], inplace=True)\n    if \"fill_method\" in kwargs:\n        BIAS.fillna(method=kwargs[\"fill_method\"], inplace=True)\n\n    # Name and Categorize it\n    BIAS.name = f\"BIAS_{length}\"\n    BIAS.category = \"momentum\"\n\n    return BIAS", "CodeBleu_score": 57.48870269093524}]}
{"instance_id": "77825be37c24", "generation_result": [{"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n\t\n    try:\n        url = _get_data(broker=broker, code=code, ktype=ktype, size=size)\n        print(url)\n        data = apply(url)\n        if broker == 'hb':\n            data = data['data']\n        elif broker == 'bitmex':\n            data = data['result']\n        elif broker == 'okex':\n            data = data['data']\n        elif broker == 'binance':\n            data = data['data']\n        elif broker == 'huobi':\n            data = data['data']\n        elif broker == 'bitfinex':\n            data = data['result']\n        elif broker == 'bitflyer':\n            data = data['result']\n        elif broker == 'poloniex':\n            data = data['result']\n        elif broker == 'bithumb':\n            data = data['data']\n        elif broker == 'bitstamp':\n            data = data['data']\n        elif broker == 'bitbank':\n            data = data['data']\n        elif broker == 'coincheck':\n            data = data['data']\n        elif broker == 'quoine':\n            data = data['data']\n        elif broker == 'kraken':\n            data = data['result']\n        elif broker == 'bitso':\n            data = data['payload']\n        elif broker == 'gdax':\n            data = data['result']\n        elif broker == 'cex':\n            data = data['result']\n        elif broker == 'bitflyer':\n            data = data['result']\n        elif broker == 'coinex':\n            data = data['data']\n        elif broker == 'bittrex':\n            data = data['result']\n        elif broker == 'cryptopia':\n            data = data['result']\n        elif broker == 'bitforex':\n            data = data['data']\n        elif broker == 'hitbtc':\n            data = data['result']\n        elif broker == 'liqui':\n            data = data['result']\n        elif broker == 'kucoin':\n            data = data['data']\n        elif broker == 'exmo':\n            data = data['result']", "CodeBleu_score": 18.942030157516605}, {"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n\t\n    url = _get_data(broker, code, ktype, size)\n    try:\n        data = apply(url)\n        if broker == 'hb':\n            if ktype.strip().upper() == 'D':\n                data = data['data']\n            else:\n                data = data['tick']\n        elif broker == 'okx':\n            if ktype.strip().upper() == 'D':\n                data = data['data']\n            else:\n                data = data['data'][0]\n        else:\n            data = data['data']\n        df = pd.DataFrame(data)\n        if broker == 'hb':\n            if ktype.strip().upper() == 'D':\n                df.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'vol', 'count']\n                df['date'] = df['date'].apply(int2time)\n            elif ktype.strip().upper() == 'W':\n                df.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'count']\n                df['date'] = df['date'].apply(int2time)\n            elif ktype.strip().upper() == 'M':\n                df.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'count']\n                df['date'] = df['date'].apply(int2time)\n            elif ktype.strip().upper() == '15m':\n                df.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'count']\n                df['date'] = df['date'].apply(int2time)\n            elif ktype.strip().upper() == '30m':\n                df.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'count']\n                df['date'] = df['date'].apply(int2time)\n            elif ktype.strip().upper() == '1h':\n                df.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'count']\n", "CodeBleu_score": 31.209727517745193}, {"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n\t\n    _get_data(broker, code, ktype, size)\n    apply(ktype.strip())\n    int2time()\n    pd.to_datetime(df['date'])\n    ktype.strip()\n    df = pd.DataFrame(data, columns=['date', 'open', 'high', 'low', 'close', 'volume'])\n    if broker == 'hb':\n        df['date'] = df['date'].apply(lambda x: str(x)[0:10])\n    if ktype == 'M':\n        df['date'] = df['date'].apply(lambda x: str(x)[0:7])\n    return df\n\n", "CodeBleu_score": 24.863205990128723}]}
{"instance_id": "c6552851da8a", "generation_result": [{"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n\t\n    data = _get_data(broker, code, size)\n    if broker == 'hb':\n        data['time'] = int2time(data['time'])\n    else:\n        data['time'] = pd.to_datetime(data['time'], unit='s')\n    ask = pd.DataFrame(data['asks'])\n    ask.columns = ['ask_price', 'ask_amount']\n    bid = pd.DataFrame(data['bids'])\n    bid.columns = ['bid_price', 'bid_amount']\n    ask['time'] = data['time']\n    bid['time'] = data['time']\n    data = {'ask': ask, 'bid': bid}\n    return pd.Panel(data)\n\n", "CodeBleu_score": 28.830471714347816}, {"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n\t\n    try:\n        data = _get_data(broker, code, size)\n        if broker == 'hb':\n            data['timestamp'] = int2time(data['timestamp'])\n        elif broker == 'lbank':\n            data['timestamp'] = int2time(data['timestamp'] / 1000)\n        else:\n            data['timestamp'] = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(data['timestamp']))\n        ask = pd.DataFrame(data['asks'], columns=['price', 'amount'])\n        ask['timestamp'] = data['timestamp']\n        bid = pd.DataFrame(data['bids'], columns=['price', 'amount'])\n        bid['timestamp'] = data['timestamp']\n        return pd.Panel({'ask': ask, 'bid': bid})\n    except Exception as e:\n        traceback.print_exc()\n\n", "CodeBleu_score": 39.43049881146212}, {"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n\t\n    data = _get_data(broker, code, size)\n    if broker == 'hb':\n        timestamp = int2time(data['timestamp'])\n    else:\n        timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(data['timestamp']))\n    ask_data = pd.DataFrame(data['asks'], columns=['price', 'amount'])\n    bid_data = pd.DataFrame(data['bids'], columns=['price', 'amount'])\n    ask_data['timestamp'] = timestamp\n    bid_data['timestamp'] = timestamp\n    result = {\n        'ask': ask_data,\n        'bid': bid_data,\n    }\n    try:\n        return pd.Panel(result)\n    except:\n        traceback.print_exc()\n\n", "CodeBleu_score": 37.980960500656145}]}
{"instance_id": "8b5fee723398", "generation_result": [{"code": "def coins_trade(broker='hb', code='btc')\n\t\n    url = 'https://api.hbdm.com/market/history/trade?symbol={0}{1}&size=1000'.format(code.upper(), 'usdt')\n    if broker == 'hb':\n        url = 'https://api.hbdm.com/market/history/trade?symbol={0}{1}&size=1000'.format(code.upper(), 'usdt')\n    elif broker == 'ok':\n        url = 'https://www.okx.com/api/v5/market/trades?instId={0}-USDT&limit=1000'.format(code.upper())\n    elif broker == 'chbtc':\n        url = 'https://api.chbtc.com/data/v1/trades?currency={0}&since=0&limit=1000'.format(code.lower())\n    data = _get_data(url)\n    if data is not None:\n        if broker == 'hb':\n            data = data.iloc[:, [1, 0, 2, 3, 4]]\n            data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            data['datetime'] = pd.to_datetime(data['datetime'], unit='s')\n        elif broker == 'ok':\n            data = data['data']\n            data = data.iloc[:, [0, 7, 8, 9, 10]]\n            data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            data['datetime'] = pd.to_datetime(data['datetime'], unit='s')\n        elif broker == 'chbtc':\n            data = data['data']\n            data = data.iloc[:, [0, 2, 3, 4, 5]]\n            data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            data['datetime'] = pd.to_datetime(data['datetime'], unit='s')\n        data = data[['tid', 'datetime', 'price', 'amount', 'type']]\n    return data\n\n", "CodeBleu_score": 39.637871466846484}, {"code": "def coins_trade(broker='hb', code='btc')\n\t\n    data = pd.DataFrame(get_data(broker, code))\n    if data is not None:\n        if broker == 'hb':\n            data = data[['id', 'ts', 'price', 'amount', 'direction']]\n            data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            data['datetime'] = data['datetime'].apply(int2time)\n        elif broker in ['ok', 'chbtc']:\n            data = data[['tid', 'date', 'price', 'amount', 'type']]\n            data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            data['datetime'] = pd.to_datetime(data['datetime'], unit='ms')\n        data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n        return data\n\n", "CodeBleu_score": 41.49286535576647}, {"code": "def coins_trade(broker='hb', code='btc')\n\t\n    url = f'https://api.hbdm.com/market/history/trade?symbol={code.upper()}usdt&size=1000'\n    if broker == 'hb':\n        url = f'https://api.hbdm.com/market/history/trade?symbol={code.upper()}usdt&size=1000'\n        data = pd.DataFrame(hb_get_data(url)['data'])\n        data = data[['id', 'ts', 'data']]\n        data.columns = ['tid', 'datetime', 'data']\n        data['datetime'] = data['datetime'].apply(int2time)\n    elif broker == 'ok':\n        url = f'https://www.okx.com/api/v5/market/trades?instId={code.upper()}-USDT'\n        data = pd.DataFrame(hb_get_data(url)['data'])\n        data = data[['tradeId', 'ts', 'data']]\n        data.columns = ['tid', 'datetime', 'data']\n        data['datetime'] = data['datetime'].apply(int2time)\n    elif broker == 'chbtc':\n        url = f'https://api.chbtc.com/data/v1/trades?currency={code.lower()}&since=0'\n        data = pd.DataFrame(hb_get_data(url)['data'])\n        data = data[['tid', 'date', 'amount', 'price', 'type']]\n        data.columns = ['tid', 'datetime', 'amount', 'price', 'type']\n        data['datetime'] = data['datetime'].apply(int2time)\n    data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n    return data\n\n", "CodeBleu_score": 38.74667021252286}]}
{"instance_id": "25e0a134c45b", "generation_result": [{"code": "def _parse_fund_data(url, fund_type='open')\n\t\n\n    ct._write_console(\"Retrieving \" + fund_type + \" fund data...\")\n\n    try:\n        response = urlopen(url)\n    except:\n        print(\"Error retrieving \" + fund_type + \" fund data\")\n        return\n\n    text = response.read()\n    text = text.decode('utf-8')\n\n    reg = re.compile(r'var\\s+jsonData\\s+=\\s+(\\[.*\\]);')\n    text = reg.sub(r'\\1', text)\n    text = text.replace('\\\\', '')\n    text = text.replace('\"[', '[')\n    text = text.replace(']\"', ']')\n    text = text.replace('\"{', '{')\n    text = text.replace('}\"', '}')\n\n    fund_df = pd.read_json(text)\n    fund_df = fund_df.fillna(0)\n\n    if fund_type == 'open':\n        fund_df.columns = ['date', 'nav', 'cumulative_return']\n    elif fund_type == 'close':\n        fund_df.columns = ['date', 'nav', 'cumulative_return', 'benchmark_nav']\n\n    return fund_df\n\n", "CodeBleu_score": 39.38802659992657}, {"code": "def _parse_fund_data(url, fund_type='open')\n\t\n    print(urlopen(url).read())\n    ct._write_console()\n    try:\n        response = urlopen(url)\n        text = response.read().decode('utf-8')\n        text = text.replace('var r =', '')\n        text = text.replace(';', '')\n        text = text.split('", "CodeBleu_score": 15.309732982834683}, {"code": "def _parse_fund_data(url, fund_type='open')\n\t\n    ct._write_console(f'Retrieving {fund_type} fund data from {url}...')\n    try:\n        response = urlopen(Request(url))\n        text = response.read()\n        text = text.decode('utf-8-sig')\n        text = text.replace('", "CodeBleu_score": 14.350433091311482}]}
{"instance_id": "401d18e122d8", "generation_result": [{"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    if market.upper() == 'CFFEX':\n        f = ct.get_future_daily\n    else:\n        f = ct.get_future_daily_generic\n    if start == None:\n        today = datetime.datetime.today()\n        start = ct.convert_date(today)\n    if end == None:\n        end = ct.convert_date(today)\n    start = ct.convert_date(start)\n    end = ct.convert_date(end)\n    df_list = []\n    for i in range((end - start).days + 1):\n        date = start + datetime.timedelta(days = i)\n        date = ct.convert_date(date)\n        data = f(date, market)\n        if len(data) != 0:\n            df_list.append(data)\n    if len(df_list) != 0:\n        return pd.concat(df_list)\n\n\n", "CodeBleu_score": 44.24137680249748}, {"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    if market == 'CFFEX':\n        f = get_future_daily_cffex\n    elif market == 'CZCE':\n        f = get_future_daily_czce\n    elif market == 'DCE':\n        f = get_future_daily_dce\n    elif market == 'SHFE':\n        f = get_future_daily_shfe\n    else:\n        print('market name input error, NOT FOUND!!')\n        return\n    if start is None:\n        start = datetime.datetime.today().strftime('%Y%m%d')\n    else:\n        start = ct.convert_date(start)\n    if end is None:\n        end = datetime.datetime.today().strftime('%Y%m%d')\n    else:\n        end = ct.convert_date(end)\n    start = datetime.datetime.strptime(start, '%Y%m%d')\n    end = datetime.datetime.strptime(end, '%Y%m%d')\n    df_list = []\n    for d in pd.date_range(start, end):\n        today = d.strftime('%Y%m%d')\n        print(today)\n        df = f(today)\n        if len(df) != 0:\n            df_list.append(df)\n    if len(df_list) != 0:\n        return pd.concat(df_list, ignore_index=True)\n\n", "CodeBleu_score": 50.4201265677309}, {"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    start = ct.convert_date(start)\n    end = ct.convert_date(end)\n    if market.upper() == 'CFFEX':\n        f = get_future_daily_cffex\n    elif market.upper() == 'CZCE':\n        f = get_future_daily_czce\n    elif market.upper() == 'DCE':\n        f = get_future_daily_dce\n    elif market.upper() == 'INE':\n        f = get_future_daily_ine\n    elif market.upper() == 'SHFE':\n        f = get_future_daily_shfe\n    else:\n        print('market name error')\n        return\n    df_list = []\n    for date in pd.date_range(start, end):\n        print('handling ' + str(date)[:10])\n        df = f(date)\n        if len(df) != 0:\n            df_list.append(df)\n    if len(df_list) != 0:\n        df = pd.concat(df_list)\n        return df\n\n", "CodeBleu_score": 49.674836642594656}]}
{"instance_id": "697779825988", "generation_result": [{"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n    url = 'https://www.kobis.or.kr/kobisopenapi/webservice/rest/boxoffice/searchDailyBoxOfficeList.json?key=f5eef3421c602c6cb7ea224104795888&targetDt=20210722'\n    for i in range(retry_count):\n        try:\n            with urlopen(url) as response:\n                contents = response.read().decode('utf-8')\n                data = json.loads(contents)\n                result = data['boxOfficeResult']\n        except:\n            time.sleep(pause)\n        else:\n            if result['boxofficeType'] == '\uc77c\ubcc4 \ubc15\uc2a4\uc624\ud53c\uc2a4':\n                df = pd.DataFrame(result['dailyBoxOfficeList'])\n                df.drop(['movieImg','movieCd'], axis='columns', inplace=True)\n                df.insert(0, 'date', du.get_now('%Y%m%d'))\n                return df\n            time.sleep(pause)\n\n", "CodeBleu_score": 29.160421834162964}, {"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n    for i in range(retry_count):\n        try:\n            url = 'https://www.kobis.or.kr/kobisopenapi/webservice/rest/boxoffice/searchDailyBoxOfficeList.json?key=f5eef3421c602c6cb7ea224104795888&targetDt=20230317'\n            response = urlopen(url)\n            lines = response.read().decode('utf-8')\n            rank_json = json.loads(lines)\n            rank_df = pd.DataFrame(rank_json['boxOfficeResult']['dailyBoxOfficeList'])\n            rank_df.drop(['movieCd','movieImg','movieNmEn'], axis='columns', inplace=True)\n            rank_df['showRange'] = rank_df['showRange'].str.replace(pat=r'~', repl='-', regex=True)\n            rank_df['showRange'] = rank_df['showRange'].str.extract(r'(\\d+)')\n            rank_df['showRange'] = rank_df['showRange'].astype(int)\n            rank_df['showCnt'] = rank_df['showCnt'].astype(int)\n            rank_df['audiCnt'] = rank_df['audiCnt'].astype(int)\n            rank_df['audiAcc'] = rank_df['audiAcc'].astype(int)\n            rank_df['scrnCnt'] = rank_df['scrnCnt'].astype(int)\n            rank_df['showCntRank'] = rank_df['showCntRank'].astype(int)\n            rank_df['timestamp'] = du.get_now('KST')\n            if len(rank_df) > 0:\n                return rank_df\n        except Exception as e:\n            print(f\"Attempt {i+1} failed: {str(e)}\")\n            time.sleep(pause)\n    print(\"Failed to fetch real-time box office data.\")\n    return None", "CodeBleu_score": 33.09443416769363}, {"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n    url = 'http://www.cbooo.cn/BoxOffice/getCBW?pIndex=1&pSize=100&type=1&year=0&month=0&day=0&hour=0&Minute=0&second=0&area=0&order=desc&_=1671560794056'\n    for _ in range(retry_count):\n        try:\n            with urlopen(url) as response:\n                lines = response.read()\n            if len(lines) > 0:\n                df = pd.DataFrame(json.loads(lines.decode('utf-8'))['data2'])\n                df.drop(['MovieImg', 'mId'], axis=1, inplace=True)\n                df['timestamp'] = du.get_now()\n                return df\n        except Exception as e:\n            print(e)\n            time.sleep(pause)\n\n", "CodeBleu_score": 38.79331377326357}]}
