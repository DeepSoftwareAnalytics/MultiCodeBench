{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    self._orig_kazoo_connect(*args)\n    return max(2000, (self.loop_wait - 2) * 1000), self._orig_kazoo_connect.return_value[1]\n", "CodeBleu_score": 46.90458859743553}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    self._orig_kazoo_connect(*args)\n    return max(self.loop_wait - 2, 0) * 1000, self._orig_kazoo_connect(*args)[1]\n\n", "CodeBleu_score": 62.17437338274977}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait_time = max(self.loop_wait - 2, 0) * 1000\n    return (wait_time, self._orig_kazoo_connect(*args))\n\n", "CodeBleu_score": 50.12555250371602}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    self.set_retry_timeout(config['retry_timeout'])\n    self.set_loop_wait_time(config['loop_wait_time'])\n    self.set_ttl(config['ttl'])\n    if self.loop_wait_time!= config['loop_wait_time'] and isinstance(self.client_handler, PatroniSequentialThreadingHandler):\n        self.set_connect_timeout(config['connect_timeout'])\n    try:\n        self.set_ttl(config['ttl'])\n    except Exception:\n        if self.loop_wait_time!= config['loop_wait_time']:\n            self.close()\n            self.set_ttl(config['ttl'])", "CodeBleu_score": 40.36646085398454}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, dict):\n        config = Config(config)\n    self.set_retry_timeout(config.retry_timeout)\n    self.set_ttl(config.ttl)\n    if self.loop_wait!= config.loop_wait:\n        self.loop_wait = config.loop_wait\n        if isinstance(self.handler, PatroniSequentialThreadingHandler):\n            self.set_connect_timeout(config.connect_timeout)\n    try:\n        self.set_ttl(config.ttl)\n    except Exception:\n        if self.loop_wait!= config.loop_wait:\n            self.close()\n            self.set_loop_wait(config.loop_wait)\n            self.set_connect_timeout(config.connect_timeout)\n\n", "CodeBleu_score": 39.20861362241266}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, dict):\n        config = Config(config)\n    self.set_retry_timeout(config.retry_timeout)\n    self.set_ttl(config.ttl)\n    if self.loop_wait!= config.loop_wait:\n        self.loop_wait = config.loop_wait\n        if isinstance(self.client_handler, PatroniSequentialThreadingHandler):\n            self.set_connect_timeout(config.connect_timeout)\n    try:\n        self.set_ttl(config.ttl)\n    except Exception:\n        if self.loop_wait!= config.loop_wait:\n            self.close()\n\n", "CodeBleu_score": 41.15722294380131}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster_config = self._postgresql_cluster_config_loader(path)\n    cluster_init = self._postgresql_cluster_init_loader(path)\n    cluster_timeline_history = self._postgresql_cluster_timeline_history_loader(path)\n    cluster_sync_state = self._postgresql_cluster_sync_state_loader(path)\n    cluster_members = self._postgresql_cluster_members_loader(path)\n    cluster_leader = self._postgresql_cluster_leader_loader(path)\n    cluster_status = self._postgresql_cluster_status_loader(path)\n    cluster_failover = self._postgresql_cluster_failover_loader(path)\n    cluster_failsafe = self._postgresql_cluster_failsafe_loader(path)\n    cluster = Cluster(\n        config=cluster_config,\n        init=cluster_init,\n        timeline_history=cluster_timeline_history,\n        sync_state=cluster_sync_state,\n        members=cluster_members,\n        leader=cluster_leader,\n        status=cluster_status,\n        failover=cluster_failover,\n        failsafe=cluster_failsafe,\n    )\n    return cluster\n\n", "CodeBleu_score": 8.591480901354211}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(path)\n\n    # Check for the initialization state file\n    if os.path.exists(os.path.join(path, \"PG_VERSION\")):\n        cluster.initialized = True\n\n    # Check for the configuration file\n    if os.path.exists(os.path.join(path, \"postgresql.conf\")):\n        cluster.config = self.get_config(path)\n\n    # Check for the timeline history file\n    if os.path.exists(os.path.join(path, \"pg_wal\", \"timeline_history\")):\n        cluster.timeline_history = self.get_timeline_history(path)\n\n    # Check for the synchronization state file\n    if os.path.exists(os.path.join(path, \"pg_wal\", \"sync_state\")):\n        cluster.sync_state = self.get_sync_state(path)\n\n    # Check for the members directory\n    if os.path.exists(os.path.join(path, \"pg_wal\", \"members\")):\n        cluster.members = self.load_members(path)\n\n    # Check for the leader file\n    if os.path.exists(os.path.join(path, \"pg_wal\", \"leader\")):\n        cluster.leader = self.get_leader(path)\n\n    # Check for the cluster status file\n    if os.path.exists(os.path.join(path, \"pg_wal\", \"cluster_status\")):\n        cluster.status = self.get_status(path)\n\n    # Check for the failover state file\n    if os.path.exists(os.path.join(path, \"pg_wal\", \"failover.state\")):\n        cluster.failover = self.get_failover(path)\n\n    # Check for the failsafe configuration file\n    if os.path.exists(os.path.join(path, \"pg_wal\", \"failsafe.conf\")):\n        cluster.failsafe = self.get_failsafe(path)\n\n    return cluster\n", "CodeBleu_score": 15.696090731615062}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(path)\n\n    # Initialize the cluster\n    cluster.initialize()\n\n    # Load the configuration\n    cluster.load_config()\n\n    # Load the timeline history\n    cluster.load_timeline_history()\n\n    # Load the synchronization state\n    cluster.load_sync_state()\n\n    # Load the members\n    cluster.load_members()\n\n    # Load the leader\n    cluster.load_leader()\n\n    # Load the cluster status\n    cluster.load_status()\n\n    # Load the failover state\n    cluster.load_failover()\n\n    # Load the failsafe configuration\n    cluster.load_failsafe_config()\n\n    return cluster\n", "CodeBleu_score": 1.5426310104971557}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        with self.retry:\n            self.zk.create(self.path, ephemeral=True, sequence=True)\n            return True\n    except ConnectionClosedError:\n        raise ZooKeeperError(\"Connection to ZooKeeper is closed.\")\n    except KazooRetryError as e:\n        raise ZooKeeperError(f\"Failed to acquire leader lock: {e}\")\n    except NodeExistsError:\n        logger.info(\"Leader lock is already held by another instance.\")\n        return False\n    except Exception as e:\n        if isinstance(e, KazooException):\n            logger.error(f\"Failed to acquire leader lock: {e}\")\n            raise\n        else:\n            logger.error(f\"Unexpected error: {e}\")\n            return False\n\n", "CodeBleu_score": 40.805714581512035}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        with self.retry:\n            self.zk.create(self.path, ephemeral=True)\n            return True\n    except ZooKeeperError as e:\n        raise\n    except Exception as e:\n        if not isinstance(e, NodeExistsError):\n            logger.error(f\"Failed to acquire lock: {e}\")\n        else:\n            logger.info(\"Lock already acquired\")\n        return False\n\n", "CodeBleu_score": 44.72891505813163}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self._zk.create(self._path, ephemeral=True, sequence=True)\n        return True\n    except ZooKeeperError as e:\n        raise e\n    except Exception as e:\n        if not isinstance(e, NodeExistsError):\n            logger.error(f\"Failed to acquire lock: {e}\")\n        return False\n\n", "CodeBleu_score": 37.058217342466364}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.session!= self._client_id:\n        logger.warning(\n            \"Current client ID does not match leader session. \"\n            \"Attempting to delete old leader ZNode.\"\n        )\n        try:\n            self._zk.delete(leader.path)\n        except NoNodeError:\n            pass\n        except ConnectionClosedError:\n            pass\n        except RetryFailedError:\n            pass\n        else:\n            try:\n                self._zk.create(\n                    leader.path,\n                    leader.client.encode(\"utf-8\"),\n                    ephemeral=True,\n                    sequence=True,\n                )\n            except ConnectionClosedError:\n                pass\n            except RetryFailedError:\n                pass\n            else:\n                return True\n            logger.error(\"Failed to create new leader ZNode.\")\n    return False", "CodeBleu_score": 37.28221583323751}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    try:\n        if self._client_id!= leader.session:\n            logger.warning(\"Client ID mismatch. Deleting old leader.\")\n            try:\n                self._zk.delete(self._leader_path)\n            except NoNodeError:\n                pass\n            except ConnectionClosedError:\n                pass\n            except RetryFailedError:\n                pass\n            else:\n                try:\n                    self._zk.create(self._leader_path, self._client_name.encode(), ephemeral=True)\n                except NodeExistsError:\n                    pass\n                except ConnectionClosedError:\n                    pass\n                except RetryFailedError:\n                    pass\n                else:\n                    return True\n                logger.error(\"Failed to create leader node.\")\n        else:\n            return True\n    except ZooKeeperError:\n        raise\n    return False", "CodeBleu_score": 40.482835949124684}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client_id!= leader.session:\n        logger.warning(\n            \"Client ID %s does not match leader's session %s\",\n            self._client_id,\n            leader.session,\n        )\n        try:\n            self._zk.delete(self._leader_path)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError):\n            pass\n        except Exception as e:\n            logger.error(\"Failed to delete leader ZNode: %s\", e)\n            raise ZooKeeperError(\"Failed to delete leader ZNode\") from e\n    try:\n        self._zk.create(\n            self._leader_path,\n            self._client_id.encode(\"utf-8\"),\n            ephemeral=True,\n            sequence=True,\n        )\n    except Exception as e:\n        logger.error(\"Failed to create leader ZNode: %s\", e)\n        return False\n    return True\n\n", "CodeBleu_score": 44.517375530444504}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    if time.time() - self._last_poll_time < self._poll_interval:\n        return False\n\n    self._last_poll_time = time.time()\n    exhibitors = self._query_exhibitors()\n\n    if not exhibitors:\n        return False\n\n    # Sort the exhibitors by their status, and then by their server ID.\n    exhibitors = sorted(exhibitors, key=lambda e: (e[\"status\"], e[\"server_id\"]))\n\n    # If the first exhibitor is not in the UP state, or if it doesn't have a valid server and port, return False.\n    if exhibitors[0][\"status\"]!= \"UP\" or not exhibitors[0][\"server\"] or not exhibitors[0][\"port\"]:\n        return False\n\n    # Build the ZooKeeper connection string from the server and port of the first exhibitor.\n    connection_string = f\"{exhibitors[0]['server']}:{exhibitors[0]['port']}\"\n\n    # If the connection string has changed, log the change and update the internal state.\n    if connection_string!= self._connection_string:\n        logger.info(f\"ZooKeeper connection string changed to {connection_string}\")\n        self._connection_string = connection_string\n        self._connected = False\n\n    return True\n\n", "CodeBleu_score": 34.17752877862766}, {"code": "def poll(self) -> bool\n\t\n    now = time.time()\n    if now - self._last_poll_time < self._poll_interval:\n        return False\n    self._last_poll_time = now\n    self._query_exhibitors()\n    if self._current_servers!= self._servers:\n        self._current_servers = self._servers\n        self._zk.set_hosts(','.join(self._current_servers))\n        logger.info('Updated ZooKeeper connection string to %s', self._current_servers)\n        return True\n    return False\n\n", "CodeBleu_score": 23.849920626025533}, {"code": "def poll(self) -> bool\n\t\n    if self._query_exhibitors() and self._update_connection_string():\n        return True\n    return False\n\n", "CodeBleu_score": 8.405843192956503}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider is not None:\n        self._ensemble_provider.update_hosts()\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 59.58475154309182}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    cluster = loader(path)\n    if self.ensemble_provider is not None:\n        self.hosts = self.ensemble_provider.get_zookeeper_hosts()\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 60.32435551904287}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider is not None:\n        self._ensemble_provider.update_hosts(self._hosts)\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 61.04751755551}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\n\tString group = getGroup();\n\tString dataId = getDataId();\n\n\tlogUnsubscribeStarted(group, dataId);\n\n\ttry {\n\t\tzookeeperListener.unsubscribe(group, dataId);\n\t} catch (Exception e) {\n\t\tlogUnsubscribeFailed(group, dataId, e);\n\t}\n}", "CodeBleu_score": 73.90108770612738}, {"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = getGroup();\n\tString dataId = getDataId();\n\tlogUnsubscribeStarted(group, dataId);\n\ttry {\n\t\tzookeeperListener.unsubscribe(group, dataId);\n\t} catch (Exception e) {\n\t\tlogUnsubscribeFailed(group, dataId, e);\n\t}\n}", "CodeBleu_score": 73.90108770612738}, {"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = getGroup();\n\tString dataId = getDataId();\n\tlogUnsubscribeStarted(group, dataId);\n\ttry {\n\t\tzookeeperListener.unsubscribe(group, dataId);\n\t} catch (Exception e) {\n\t\tlogUnsubscribeFailed(group, dataId, e);\n\t}\n}", "CodeBleu_score": 73.90108770612738}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn server.getPayload().getMetadata();\n\t}\n\treturn Collections.emptyMap();\n}", "CodeBleu_score": 30.902866569830422}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getPayload().getMetadata();\n\t}\n\treturn Collections.emptyMap();\n}", "CodeBleu_score": 38.497174905089544}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\tZookeeperServer zookeeperServer = (ZookeeperServer) server\n\t\treturn zookeeperServer.getPayload().getMetadata()\n\t}\n\treturn [:]\n}", "CodeBleu_score": 60.31130739203834}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = \"/${group}/${serviceId}\"\n\tNodeCache nodeCache = new NodeCache(client, path)\n\tnodeCache.start(true)\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tzookeeperSubscribeCallback.convertConfig(new String(nodeCache.getCurrentData().getData()))\n\t\t}\n\t}\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener)\n\tzookeeperListener.addListener(zookeeperListener)\n\treturn zookeeperListener\n}", "CodeBleu_score": 59.35428373503386}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = \"/${group}/${serviceId}\"\n\tNodeCache nodeCache = new NodeCache(client, path)\n\tnodeCache.start()\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n\t\t@Override\n\t\tvoid nodeChanged() throws Exception {\n\t\t\tbyte[] data = nodeCache.getCurrentData().getData()\n\t\t\tConfig config = convertConfig(data)\n\t\t\tzookeeperSubscribeCallback.onConfig(config)\n\t\t}\n\t}\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener)\n\tzookeeperListeners.add(zookeeperListener)\n\treturn zookeeperListener\n}", "CodeBleu_score": 58.061593700352276}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = ZookeeperUtil.getConfigPath(group, serviceId);\n\tNodeCache nodeCache = new NodeCache(client, path);\n\tnodeCache.start();\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tString config = new String(nodeCache.getCurrentData().getData());\n\t\t\tzookeeperSubscribeCallback.convertConfig(config);\n\t\t}\n\t};\n\tZookeeperListener zookeeperListener = new ZookeeperListener();\n\tzookeeperListener.addListener(nodeCache, nodeCacheListener);\n\treturn zookeeperListener;\n}", "CodeBleu_score": 69.23379210523939}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tZookeeperServerList zsl = new ZookeeperServerList(config, serviceDiscovery);\n\tzsl.setServerListFilter(this.serverListFilter);\n\tzsl.setServerListUpdater(this.serverListUpdater);\n\tzsl.setClientConfig(config);\n\tzsl.setLoadBalancer(getLoadBalancer());\n\tzsl.setClientName(getClientName(config));\n\tzsl.setServiceId(getServiceId(config));\n\tzsl.setLoadBalanceListenerExecutor(getLoadBalanceListenerExecutor(config));\n\treturn zsl;\n}", "CodeBleu_score": 53.435035527633445}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tZookeeperServerListDecorator list = new ZookeeperServerListDecorator(config, serviceDiscovery);\n\tlist.setClientConfig(config);\n\tlist.setLoadBalancer(loadBalancer);\n\tlist.setServerListUpdater(serverListUpdater);\n\tlist.setServiceId(config.getClientName());\n\tlist.setLoadBalanceListenerExecutor(loadBalancer.getLoadBalancerStats().getPendingTaskExecutor());\n\treturn list;\n}", "CodeBleu_score": 59.80816614366695}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery, config);\n\tserverList.setClientConfig(config);\n\tserverList.setLoadBalanceListenerExecutor(config.getLoadBalanceListenerExecutor());\n\tserverList.setServiceId(config.getClientName());\n\treturn serverList;\n}", "CodeBleu_score": 70.43075129644147}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor executor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\texecutor.onRegister(registration);\n\t}\n\tcatch (BeansException e) {\n\t\t// Ignore\n\t}\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 75.29687234412584}, {"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor listenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tlistenerExecutor.onRegister(registration);\n\t} catch (BeansException e) {\n\t\t// Ignore\n\t}\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 77.08725616141437}, {"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor executor = this.applicationContext.getBean(RegisterListenerExecutor.class);\n\t\texecutor.onRegister(registration);\n\t}\n\tcatch (BeansException e) {\n\t\t// Ignore\n\t}\n\tthis.serviceRegistry.register(registration);\n}", "CodeBleu_score": 64.56240467059504}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t\t// get a RegisterListenerExecutor bean from the application context\n\t// and call its onDeregister method with the registration\n\ttry {\n\t\tRegisterListenerExecutor executor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\texecutor.onDeregister(registration);\n\t}\n\tcatch (BeansException e) {\n\t\t// ignore\n\t}\n\t// finally, the registration is removed from the serviceRegistry\n\tserviceRegistry.remove(registration);\n}", "CodeBleu_score": 70.98810010312427}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor executor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\texecutor.onDeregister(registration);\n\t}\n\tcatch (BeansException e) {\n\t\tlogger.warn(\"Unable to get RegisterListenerExecutor bean\", e);\n\t}\n\tserviceRegistry.remove(registration);\n}", "CodeBleu_score": 64.71502629321202}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor executor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\texecutor.onDeregister(registration);\n\t}\n\tcatch (BeansException e) {\n\t\t// Ignore\n\t}\n\tserviceRegistry.remove(registration);\n}", "CodeBleu_score": 71.00778715016926}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\t\t// TODO Auto-generated method stub\n\ttry {\n\t\tRegisterListenerExecutor listenerExecutor = (RegisterListenerExecutor) getBean(\"registerListenerExecutor\");\n\t\tlistenerExecutor.onClose();\n\t} catch (BeansException e) {\n\t\t// TODO Auto-generated catch block\n\t\te.printStackTrace();\n\t}\n\tserviceRegistry.close();\n}", "CodeBleu_score": 56.67631205699825}, {"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor listenerExecutor = getBean(RegisterListenerExecutor.class);\n\t\tlistenerExecutor.onClose();\n\t}\n\tcatch (BeansException ex) {\n\t\t// ignore\n\t}\n\tserviceRegistry.close();\n}", "CodeBleu_score": 57.51183543336862}, {"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor executor = getBean(RegisterListenerExecutor.class);\n\t\texecutor.onClose();\n\t}\n\tcatch (BeansException ex) {\n\t\t// ignore\n\t}\n\tthis.serviceRegistry.close();\n}", "CodeBleu_score": 52.59190699088243}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = globalConfig? globalConfigGroup : localConfigGroup\n\tString dataId = globalConfig? globalConfigDataId : localConfigDataId\n\tlog.info \"Subscribing to config: ${group} ${dataId}\"\n\n\ttry {\n\t\tZookeeperListener listener = zookeeperOperation.subscribeConfig(group, dataId, {\n\t\t\tConfig config = new Config(it.content)\n\t\t\tlog.info \"Config updated: ${config.toString()}\"\n\t\t\tupdateConfig(config)\n\t\t})\n\t\tlog.info \"Subscribed to config: ${group} ${dataId}\"\n\t\treturn listener\n\t} catch (Exception e) {\n\t\tlog.error \"Failed to subscribe to config: ${group} ${dataId}\", e\n\t\treturn null\n\t}\n}", "CodeBleu_score": 22.1495193090497}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tdef group = globalConfig? globalConfigGroup : configGroup\n\tdef dataId = globalConfig? globalConfigDataId : configDataId\n\tlog.info(\"Subscribing to configuration dataId: $dataId, group: $group\")\n\ttry {\n\t\treturn zookeeperOperation.subscribeConfig(group, dataId, {\n\t\t\tlog.info(\"Configuration update received for dataId: $dataId, group: $group\")\n\t\t\tif (globalConfig) {\n\t\t\t\tglobalConfig = it\n\t\t\t} else {\n\t\t\t\tconfig = it\n\t\t\t}\n\t\t\tif (configCallback) {\n\t\t\t\tconfigCallback(globalConfig, config)\n\t\t\t}\n\t\t})\n\t} catch (e) {\n\t\tlog.error(\"Failed to subscribe to configuration dataId: $dataId, group: $group\", e)\n\t}\n\treturn null\n}", "CodeBleu_score": 34.03346638877448}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\t// Get the group and dataId values\n\tdef group = globalConfig? globalConfigGroup : configGroup\n\tdef dataId = globalConfig? globalConfigDataId : configDataId\n\t// Log the subscription start\n\tlog.info(\"Subscribing to configuration with group: $group and dataId: $dataId\")\n\t// Attempt to subscribe using zookeeperOperation\n\tdef listener = zookeeperOperation.subscribeConfig(group, dataId, {\n\t\t// Define a callback to handle configuration updates\n\t\tdef config = it.config\n\t\tif (config!= null) {\n\t\t\t// If the configuration is not null, log the update and set the configuration\n\t\t\tlog.info(\"Received configuration update: $config\")\n\t\t\tthis.config = config\n\t\t} else {\n\t\t\t// If the configuration is null, log the update and set the configuration to null\n\t\t\tlog.info(\"Received configuration update: null\")\n\t\t\tthis.config = null\n\t\t}\n\t})\n\t// If an exception occurs, log the subscription failure and return null\n\tif (listener == null) {\n\t\tlog.error(\"Failed to subscribe to configuration with group: $group and dataId: $dataId\")\n\t\treturn null\n\t}\n\t// Return the ZookeeperListener\n\treturn listener\n}", "CodeBleu_score": 14.559702599771581}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t\tString connectString = env.getProperty(\"zookeeper.connectString\");\n\tif (StringUtils.isEmpty(connectString)) {\n\t\tthrow new DiscoveryException(\"Zookeeper connection string is empty\");\n\t}\n\tint retryCount = env.getProperty(\"zookeeper.retry.count\", Integer.class, 3);\n\tint sleepTime = env.getProperty(\"zookeeper.retry.sleepTime\", Integer.class, 1000);\n\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(sleepTime, retryCount);\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(connectString)\n\t\t\t.retryPolicy(retryPolicy)\n\t\t\t.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 49.04457124131142}, {"code": "public CuratorFramework curatorFramework(){\n\t\tString connectString = environment.getProperty(\"zookeeper.connectString\", String.class, \"\");\n\tif (connectString.isEmpty()) {\n\t\tthrow new DiscoveryException(\"zookeeper.connectString property is not set\");\n\t}\n\tint retryCount = environment.getProperty(\"zookeeper.retryCount\", Integer.class, 10);\n\tint retrySleepTime = environment.getProperty(\"zookeeper.retrySleepTime\", Integer.class, 1000);\n\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(retrySleepTime, retryCount);\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(connectString, retryPolicy);\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 41.51408327018553}, {"code": "public CuratorFramework curatorFramework(){\n\t\tString connectString = env.getProperty(\"zookeeper.connectString\");\n\tif (StringUtils.isEmpty(connectString)) {\n\t\tthrow new DiscoveryException(\"Zookeeper connectString is empty\");\n\t}\n\tint retryCount = env.getProperty(\"zookeeper.retryCount\", int.class, 3);\n\tint sleepTime = env.getProperty(\"zookeeper.sleepTime\", int.class, 1000);\n\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(sleepTime, retryCount);\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(connectString, retryPolicy);\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 41.617896181782854}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * @return a new instance of GatewayStrategyRouteZookeeperProcessor\n\t */\n\t@Bean\n\t@ConditionalOnMissingBean\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 45.705173012846814}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\tprotected GatewayRouteZookeeperConfiguration(GatewayProperties gatewayProperties) {\n\t}\n\n\t@Bean\n\t@ConditionalOnMissingBean(GatewayStrategyRouteZookeeperProcessor.class)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(GatewayProperties gatewayProperties,\n\t\t\tGatewayStrategyRouteZookeeperProcessor.GatewayStrategyRouteZookeeperProcessorBuilder gatewayStrategyRouteZookeeperProcessorBuilder) {\n\t\treturn gatewayStrategyRouteZookeeperProcessorBuilder.build();\n\t}\n}", "CodeBleu_score": 13.034524178094188}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\tprivate final ApplicationContext applicationContext;\n\n\tpublic GatewayRouteZookeeperConfiguration(ApplicationContext applicationContext) {\n\t\tthis.applicationContext = applicationContext;\n\t}\n\n\t/**\n\t * Route locator for Zookeeper.\n\t * @return the route locator\n\t */\n\t@Bean\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic RouteLocator gatewayRouteLocator() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor(this.applicationContext);\n\t}\n}", "CodeBleu_score": 24.905212925382333}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t\tCuratorFrameworkBuilder builder = CuratorFrameworkFactory.builder()\n\t.connectString(connectString)\n\t.namespace(namespace)\n\t.retryPolicy(retryPolicy)\n\t.sessionTimeoutMs(sessionTimeoutMs)\n\t.connectionTimeoutMs(connectionTimeoutMs)\n\t.canBeReadOnly(canBeReadOnly)\n\t.defaultData(defaultData)\n\t.authorization(authorization)\n\t.aclProvider(aclProvider)\n\t.namespace(namespace)\n\t.retryPolicy(retryPolicy)\n\t.namespace(namespace)\n\t.sessionTimeoutMs(sessionTimeoutMs)\n\t.connectionTimeoutMs(connectionTimeoutMs)\n\t.canBeReadOnly(canBeReadOnly)\n\t.defaultData(defaultData)\n\t.authorization(authorization)\n\t.aclProvider(aclProvider)\n\t.namespace(namespace)\n\t.retryPolicy(retryPolicy)\n\t.namespace(namespace)\n\t.sessionTimeoutMs(sessionTimeoutMs)\n\t.connectionTimeoutMs(connectionTimeoutMs)\n\t.canBeReadOnly(canBeReadOnly)\n\t.defaultData(defaultData)\n\t.authorization(authorization)\n\t.aclProvider(aclProvider)\n\t.namespace(namespace)\n\t.retryPolicy(retryPolicy)\n\t.namespace(namespace)\n\t.sessionTimeoutMs(sessionTimeoutMs)\n\t.connectionTimeoutMs(connectionTimeoutMs)\n\t.canBeReadOnly(canBeReadOnly)\n\t.defaultData(defaultData)\n\t.authorization(authorization)\n\t.aclProvider(aclProvider)\n\t.namespace(namespace)\n\t.retryPolicy(retryPolicy)\n\t.namespace(namespace)\n\t.sessionTimeoutMs(sessionTimeoutMs)\n\t.connectionTimeoutMs(connectionTimeoutMs)\n\t.canBeReadOnly(canBeReadOnly)\n\t.defaultData(defaultData)\n\t.authorization(authorization)\n\t.aclProvider(aclProvider)\n\t.namespace(namespace)\n\t.retryPolicy(retryPolicy)\n\t.namespace(namespace)\n\t.sessionTimeoutMs(sessionTimeoutMs)\n\t.connectionTimeoutMs(connectionTimeoutMs)\n\t.canBeReadOnly(canBeReadOnly)\n\t.defaultData(defaultData)\n\t.authorization(authorization)\n\t.aclProvider(aclProvider)\n\t.namespace(namespace)\n\t.", "CodeBleu_score": 19.98108274711293}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t\tCuratorFrameworkBuilder builder = CuratorFrameworkFactory.builder()\n\t.connectString(zkHosts)\n\t.sessionTimeoutMs(sessionTimeoutMs)\n\t.namespace(namespace)\n\t.retryPolicy(retryPolicy)\n\t.connectString(connectString)\n\t.getZkHosts()\n\t.start()\n\tbuilder\n\tgetNamespace\n}", "CodeBleu_score": 34.35144575344573}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(connectString)\n\t\t\t.sessionTimeoutMs(sessionTimeoutMs)\n\t\t\t.namespace(getNamespace())\n\t\t\t.retryPolicy(retryPolicy)\n\t\t\t.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 39.931184369084875}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\t\tInterProcessMutex mutex = null;\n\ttry {\n\t\tmutex = locksMap.get(path);\n\t\tif (mutex == null) {\n\t\t\tmutex = new InterProcessMutex(zkClient, path);\n\t\t\tlocksMap.put(path, mutex);\n\t\t}\n\t\tmutex.acquire();\n\t} catch (Exception e) {\n\t\tthrow new DistributedLockException(\"Error acquiring lock for path: \" + path, e);\n\t}\n}", "CodeBleu_score": 26.129493752046677}, {"code": "public void lock(String path) throws DistributedLockException{\n\tInterProcessMutex lock = locksMap.get(path);\nif (lock == null) {\ntry {\nlock = new InterProcessMutex(zkClient, path);\nlock.acquire();\nlocksMap.put(path, lock);\n} catch (Exception e) {\nthrow new DistributedLockException(\"Error while acquiring lock for path: \" + path, e);\n}\n} else {\ntry {\nlock.acquire();\n} catch (Exception e) {\nthrow new DistributedLockException(\"Error while re-acquiring lock for path: \" + path, e);\n}\n}\n}", "CodeBleu_score": 32.026805923867954}, {"code": "public void lock(String path) throws DistributedLockException{\n\tInterProcessMutex lock = locksMap.get(path);\nif (lock == null) {\nlock = new InterProcessMutex(zkClient, path);\nlocksMap.put(path, lock);\n}\ntry {\nlock.acquire();\n} catch (Exception e) {\nthrow new DistributedLockException(e);\n}\n}", "CodeBleu_score": 22.886527997985034}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tString nodePath = getNodePath(dtpProperties);\n\tMap<Object, Object> propertiesMap = null;\n\tif (dtpProperties.getConfigType().equalsIgnoreCase(ConfigType.PROPERTIES.getType())) {\n\t\tpropertiesMap = genPropertiesTypeMap(curatorFramework, nodePath);\n\t} else if (dtpProperties.getConfigType().equalsIgnoreCase(ConfigType.JSON.getType())) {\n\t\tString configKey = dtpProperties.getConfigKey();\n\t\tif (StringUtils.isBlank(configKey)) {\n\t\t\tthrow new RuntimeException(\"configKey is blank\");\n\t\t}\n\t\tString configValue = getValue(curatorFramework, nodePath + \"/\" + configKey);\n\t\tpropertiesMap = ConfigHandler.parseConfig(configValue);\n\t}\n\treturn propertiesMap;\n}", "CodeBleu_score": 46.39662608832567}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tString nodePath = getNodePath(dtpProperties);\n\tMap<Object, Object> propertiesMap = null;\n\tif (dtpProperties.getConfigType().equalsIgnoreCase(DtpProperties.CONFIG_TYPE_PROPERTIES)) {\n\t\tpropertiesMap = genPropertiesTypeMap(curatorFramework, nodePath);\n\t} else if (dtpProperties.getConfigType().equalsIgnoreCase(DtpProperties.CONFIG_TYPE_JSON)) {\n\t\tString configKey = dtpProperties.getConfigKey();\n\t\tString val = getValue(curatorFramework, nodePath + \"/\" + configKey);\n\t\tpropertiesMap = ConfigHandler.parseConfig(val);\n\t}\n\treturn propertiesMap;\n}", "CodeBleu_score": 47.16822134137502}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tString nodePath = getNodePath(dtpProperties);\n\tif (dtpProperties.getConfigType().equalsIgnoreCase(\"PROPERTIES\")) {\n\t\treturn genPropertiesTypeMap(curatorFramework, nodePath);\n\t} else {\n\t\tString configKey = dtpProperties.getConfigKey();\n\t\tString val = getValue(curatorFramework, makePath(nodePath, configKey));\n\t\treturn ConfigHandler.parseConfig(val, dtpProperties.getConfigType());\n\t}\n}", "CodeBleu_score": 38.60973699922477}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = bindDtpProperties(environment);\n\tMap<String, Object> propertiesMap = genPropertiesMap(dtpProperties);\n\tcheckPropertyExist(environment, propertiesMap);\n\tcreateZkPropertySource(environment, propertiesMap);\n}", "CodeBleu_score": 45.36523811930645}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = bindDtpProperties(environment, application);\n\tMap<String, Object> propertiesMap = genPropertiesMap(dtpProperties);\n\tcheckPropertyExist(environment, propertiesMap);\n\tcreateZkPropertySource(environment, propertiesMap);\n}", "CodeBleu_score": 46.9435076742862}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = bindDtpProperties(environment);\n\tMap<String, Object> propertiesMap = genPropertiesMap(dtpProperties);\n\tcheckPropertyExist(environment, propertiesMap);\n\tcreateZkPropertySource(environment, propertiesMap);\n}", "CodeBleu_score": 45.36523811930645}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t\tbuilder.RegisterInstance(configInfo).SingleInstance();\n\tbuilder.Register(context => context.Resolve<ConfigInfo>().GetConfig<ZookeeperConfigInfo>()).SingleInstance();\n\tbuilder.Register(context => context.Resolve<ISerializer<string>>()).SingleInstance();\n\tbuilder.Register(context => context.Resolve<ISerializer<byte[]>>()).SingleInstance();\n\tbuilder.Register(context => context.Resolve<IServiceRouteFactory>()).SingleInstance();\n\tbuilder.Register(context => context.Resolve<ILogger<ZooKeeperServiceRouteManager>>()).SingleInstance();\n\tbuilder.Register(context => context.Resolve<IZookeeperClientProvider>()).SingleInstance();\n\tbuilder.RegisterType<ZooKeeperServiceRouteManager>().As<IServiceRouteManager>().SingleInstance();\n\treturn this;\n}", "CodeBleu_score": 51.90855664003894}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t\tbuilder.RegisterInstance(configInfo).As<ConfigInfo>();\n\tbuilder.Register(provider => provider.GetRequiredService<ILogger<ZooKeeperServiceRouteManager>>()).As<ILogger<ZooKeeperServiceRouteManager>>().SingleInstance();\n\tbuilder.Register(provider => provider.GetRequiredService<ISerializer<byte[]>>()).As<ISerializer<byte[]>>().SingleInstance();\n\tbuilder.Register(provider => provider.GetRequiredService<IServiceRouteFactory>()).As<IServiceRouteFactory>().SingleInstance();\n\tbuilder.Register(provider => provider.GetRequiredService<ISerializer<string>>()).As<ISerializer<string>>().SingleInstance();\n\tbuilder.Register(provider => provider.GetRequiredService<IZookeeperClientProvider>()).As<IZookeeperClientProvider>().SingleInstance();\n\treturn this;\n}", "CodeBleu_score": 54.9585180010143}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t\tbuilder.RegisterInstance(configInfo).As<ConfigInfo>().SingleInstance();\n\tbuilder.RegisterType<ZooKeeperServiceRouteManager>().As<IServiceRouteManager>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperClientProvider>().As<IZookeeperClientProvider>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperSerializer>().As<ISerializer<string>>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperSerializer>().As<ISerializer<byte[]>>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperServiceRouteFactory>().As<IServiceRouteFactory>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperServiceRouteManager>().As<IServiceRouteManager>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperSerializer>().As<ISerializer<byte[]>>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperSerializer>().As<ISerializer<string>>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperClientProvider>().As<IZookeeperClientProvider>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperServiceRouteFactory>().As<IServiceRouteFactory>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperServiceRouteManager>().As<IServiceRouteManager>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperSerializer>().As<ISerializer<byte[]>>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperSerializer>().As<ISerializer<string>>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperClientProvider>().As<IZookeeperClientProvider>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperServiceRouteFactory>().As<IServiceRouteFactory>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperServiceRouteManager>().As<IServiceRouteManager>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperSerializer>().As<ISerializer<byte[]>>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperSerializer>().As<ISerializer<string>>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperClientProvider>().As<IZookeeperClientProvider>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperServiceRouteFactory>().As<IServiceRouteFactory>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperServiceRouteManager>().As<IServiceRouteManager>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperSerializer>().As<ISerializer<byte[]>>().SingleInstance();\n\tbuilder.RegisterType<ZookeeperSerializer>().As<ISerializer<string>>().", "CodeBleu_score": 40.58589951088372}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t\tvar provider = builder.Build();\n\tvar commandManager = provider.GetRequiredService<IServiceCommandManager>();\n\tif (commandManager is ZookeeperServiceCommandManager) {\n\t\treturn this;\n\t}\n\tprovider.GetRequiredService<IServiceEntryManager>().Clear();\n\tvar serviceCommandManager = new ZookeeperServiceCommandManager(provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<ISerializer<string>>(), provider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(), provider.GetRequiredService<IServiceRouteManager>(), provider.GetRequiredService<IZookeeperClientProvider>());\n\tserviceCommandManager.SetConfigInfo(configInfo);\n\tbuilder.Update(serviceCommandManager);\n\treturn this;\n}", "CodeBleu_score": 50.84328300643786}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t\tbuilder.RegisterInstance(configInfo).As<ConfigInfo>();\n\tbuilder.RegisterType<ZookeeperServiceCommandManager>().As<IServiceCommandManager>();\n\tbuilder.RegisterType<ServiceEntryManager>().As<IServiceEntryManager>();\n\tbuilder.RegisterType<ServiceRouteManager>().As<IServiceRouteManager>();\n\tbuilder.RegisterType<ZookeeperClientProvider>().As<IZookeeperClientProvider>();\n\tbuilder.RegisterType<ZookeeperServiceCommandManager>().As<IServiceCommandManager>();\n\tbuilder.RegisterType<ServiceEntryManager>().As<IServiceEntryManager>();\n\tbuilder.RegisterType<ServiceRouteManager>().As<IServiceRouteManager>();\n\tbuilder.RegisterType<ZookeeperClientProvider>().As<IZookeeperClientProvider>();\n\tbuilder.RegisterType<ZookeeperServiceCommandManager>().As<IServiceCommandManager>();\n\tbuilder.RegisterType<ServiceEntryManager>().As<IServiceEntryManager>();\n\tbuilder.RegisterType<ServiceRouteManager>().As<IServiceRouteManager>();\n\tbuilder.RegisterType<ZookeeperClientProvider>().As<IZookeeperClientProvider>();\n\tbuilder.RegisterType<ZookeeperServiceCommandManager>().As<IServiceCommandManager>();\n\tbuilder.RegisterType<ServiceEntryManager>().As<IServiceEntryManager>();\n\tbuilder.RegisterType<ServiceRouteManager>().As<IServiceRouteManager>();\n\tbuilder.RegisterType<ZookeeperClientProvider>().As<IZookeeperClientProvider>();\n\tbuilder.RegisterType<ZookeeperServiceCommandManager>().As<IServiceCommandManager>();\n\tbuilder.RegisterType<ServiceEntryManager>().As<IServiceEntryManager>();\n\tbuilder.RegisterType<ServiceRouteManager>().As<IServiceRouteManager>();\n\tbuilder.RegisterType<ZookeeperClientProvider>().As<IZookeeperClientProvider>();\n\tbuilder.RegisterType<ZookeeperServiceCommandManager>().As<IServiceCommandManager>();\n\tbuilder.RegisterType<ServiceEntryManager>().As<IServiceEntryManager>();\n\tbuilder.RegisterType<ServiceRouteManager>().As<IServiceRouteManager>();\n\tbuilder.RegisterType<ZookeeperClientProvider>().As<IZookeeperClientProvider>();\n\tbuilder.RegisterType<ZookeeperServiceCommandManager>().As<IServiceCommandManager>();\n\tbuilder.RegisterType<ServiceEntryManager>().As<IServiceEntryManager>();\n\tbuilder.RegisterType<ServiceRouteManager>().As<IServiceRouteManager>();\n\tbuilder.RegisterType<ZookeeperClientProvider>().As<IZookeeperClientProvider>();\n", "CodeBleu_score": 34.38187585855253}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t\n```\n", "CodeBleu_score": 8.732757383978118}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tCheck.NotNull(builder, nameof(builder));\n\tCheck.NotNull(path, nameof(path));\n\tif (!optional) {\n\t\tCheck.NotNull(provider, nameof(provider));\n\t}\n\tif (string.IsNullOrEmpty(path)) {\n\t\tthrow new ArgumentException(\"The path cannot be null or empty\", nameof(path));\n\t}\n\tif (!Path.IsPathRooted(path)) {\n\t\tthrow new ArgumentException(\"The path must be rooted\", nameof(path));\n\t}\n\tif (provider == null) {\n\t\tprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n\t}\n\tvar source = new ZookeeperConfigurationSource {\n\t\tFileProvider = provider,\n\t\tPath = Path.GetFileName(path),\n\t\tOptional = optional,\n\t\tReloadOnChange = reloadOnChange\n\t};\n\tbuilder.Add(source);\n\treturn builder;\n}", "CodeBleu_score": 59.8711300840196}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tCheck.NotNull(builder, nameof(builder));\n\tCheck.NotNull(path, nameof(path));\n\n\tif (provider == null &&!Path.IsPathRooted(path)) {\n\t\tthrow new ArgumentException(\n\t\t\t$\"The {nameof(IFileProvider)} must be provided when the path is not rooted.\", nameof(provider));\n\t}\n\n\tif (provider == null) {\n\t\tprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n\t}\n\n\tvar source = new ZookeeperConfigurationSource {\n\t\tFileProvider = provider,\n\t\tPath = Path.GetFileName(path),\n\t\tOptional = optional,\n\t\tReloadOnChange = reloadOnChange\n\t};\n\n\tbuilder.Add(source);\n\treturn builder;\n}", "CodeBleu_score": 60.759416481306026}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tCheck.NotNull(builder, nameof(builder));\n\tCheck.NotEmpty(path, nameof(path));\n\tif (!Path.IsPathRooted(path)) {\n\t\tthrow new ArgumentException(\"The path must be rooted.\", nameof(path));\n\t}\n\tif (provider == null) {\n\t\tprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n\t}\n\tvar source = new ZookeeperConfigurationSource {\n\t\tFileProvider = provider,\n\t\tPath = Path.GetFileName(path),\n\t\tOptional = optional,\n\t\tReloadOnChange = reloadOnChange\n\t};\n\tbuilder.Add(source);\n\treturn builder.Build();\n}", "CodeBleu_score": 59.08158494212186}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tvar routes = await GetRoutesAsync();\n\troutes.ForEach(r => r.Address.Except(Address));\n\tawait base.SetRoutesAsync(routes);\n}", "CodeBleu_score": 40.530077588301594}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tvar routes = await GetRoutesAsync();\n\tvar newRoutes = routes.Select(r => r.Except(Address));\n\tawait base.SetRoutesAsync(newRoutes);\n}", "CodeBleu_score": 38.10483178983217}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tvar routes = await base.GetRoutesAsync();\n\tvar routesToRemove = routes.Where(r => r.Address.Except(Address).Any());\n\tforeach (var route in routesToRemove) {\n\t\troute.Address = route.Address.Except(Address).ToList();\n\t}\n\tawait base.SetRoutesAsync(routes);\n}", "CodeBleu_score": 61.10002036237924}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\tvar path = GetRoutePath();\n\tvar zooKeepers = _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tvar oldRouteIds = await zooKeeper.Item2.getChildrenAsync(path);\n\t\tvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n\t\tvar deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n\t\tforeach (var deletedRouteId in deletedRouteIds) {\n\t\t\tvar address = routes.Where(p => p.ServiceDescriptor.Id == deletedRouteId).Select(p => p.Address).FirstOrDefault();\n\t\t\tif (address!= null && address.Contains(hostAddr)) {\n\t\t\t\tawait zooKeeper.Item2.deleteAsync($\"{path}/{deletedRouteId}\");\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 50.929659847083855}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routePath = GetRoutePath();\n\tvar zooKeepers = _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tvar oldRouteIds = await zooKeeper.Item2.getChildrenAsync(routePath);\n\t\tvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n\t\tvar deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n\t\tforeach (var deletedRouteId in deletedRouteIds) {\n\t\t\tvar address = routes.Where(p => p.ServiceDescriptor.Id == deletedRouteId).Select(p => p.Address).FirstOrDefault();\n\t\t\tif (address.Contains(hostAddr)) {\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(routePath + \"/\" + deletedRouteId);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 50.209464875210166}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\tvar path = $\"{_configuration.RoutePath}/{hostAddr.Host}:{hostAddr.Port}\";\n\tvar addresses = routes.Select(i => i.Address).ToArray();\n\tvar zooKeepers = _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tvar oldRouteIds = await zooKeeper.Item2.getChildrenAsync(path);\n\t\tvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n\t\tvar deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n\t\tforeach (var deletedRouteId in deletedRouteIds) {\n\t\t\tvar deletedRouteAddress = routes.Where(p => p.ServiceDescriptor.Id == deletedRouteId).Select(p => p.Address).FirstOrDefault();\n\t\t\tif (addresses.Contains(deletedRouteAddress)) {\n\t\t\t\tawait zooKeeper.Item2.deleteAsync($\"{path}/{deletedRouteId}\");\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 53.33332521151208}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {\n_logger.LogDebug(\"GetRoute: data is null. Returning null.\");\nreturn null;\n}\n\n_logger.LogDebug(\"GetRoute: data is not null. Deserializing data into a ServiceRouteDescriptor.\");\nvar descriptor = _serializer.Deserialize<ServiceRouteDescriptor>(data);\n\n_logger.LogDebug(\"GetRoute: data has been deserialized into a ServiceRouteDescriptor. Creating a ServiceRoute from the descriptor.\");\nreturn (await CreateServiceRoutesAsync(new[] { descriptor })).First();\n}", "CodeBleu_score": 44.436076224569256}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {\nreturn null;\n}\n\nif (_logger.IsEnabled(LogLevel.Debug)) {\n_logger.LogDebug($\"Deserializing route data: {Encoding.UTF8.GetString(data)}\");\n}\n\nvar descriptor = await _serializer.Deserialize<ServiceRouteDescriptor>(data);\nreturn (await _serviceRouteFactory.CreateServiceRoutesAsync(new[] { descriptor })).First();\n}", "CodeBleu_score": 53.285429985665445}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t\nif (data == null) {\n                return null;\n            }\n\nif (_logger.IsEnabled) {\n                _logger.LogDebug(\n$\"Deserializing service route data: {Encoding.UTF8.GetString(data)}\");\n            }\n\nvar descriptor = await _serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\n            return (await _serviceRouteFactory.CreateServiceRoutesAsync(new[] { descriptor })).First();\n        }", "CodeBleu_score": 49.815563702695734}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tf the old and new data are identical, return immediately.\nif (oldData == newData) {\n\n// Retrieve the new route from the newData.\nvar newRoute = await GetRoute(newData);\n\n// Find the corresponding old route.\nvar oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id);\n\n// Update the _routes list by replacing the old route with the new one within a thread-safe lock.\nlock (_routes) {\n_routes = _routes.Where(i => i.ServiceDescriptor.Id!= newRoute.ServiceDescriptor.Id)\n.Concat(new[] { newRoute }).ToArray();\n}\n\n// Trigger the OnChanged event with the new and old route information.\nOnChanged?.Invoke(newRoute, oldRoute);\n}\n}", "CodeBleu_score": 69.28130644163039}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t\u65e7\u6570\u636e\u76f8\u540c\uff0c\u5219\u7acb\u5373\u8fd4\u56de\u3002\n            if (DataEquals(oldData, newData)) {\n                return;\n            }\n\n            //\u4ece\u65b0\u6570\u636e\u4e2d\u83b7\u53d6\u65b0\u7684\u8def\u7531\u4fe1\u606f\u3002\n            var newRoute = await GetRoute(newData);\n\n            //\u67e5\u627e\u65e7\u8def\u7531\u4fe1\u606f\u3002\n            var oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id);\n\n            //\u66f4\u65b0\u8def\u7531\u4fe1\u606f\u5217\u8868\u3002\n            lock (_routes) {\n                _routes = _routes.Where(i => i.ServiceDescriptor.Id!= newRoute.ServiceDescriptor.Id)\n                       .Concat(new[] { newRoute }).ToArray();\n            }\n\n            //\u89e6\u53d1\u8def\u7531\u53d8\u66f4\u4e8b\u4ef6\u3002\n            OnChanged?.Invoke(newRoute, oldRoute);\n        }", "CodeBleu_score": 77.96367535525481}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tldData.SequenceEqual(newData)) {", "CodeBleu_score": 8.773395407973663}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t\tvar serviceSubscribers = await base.GetSubscribersAsync();\n\tforeach (var subscriber in subscribers) {\n\t\tvar existingSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n\t\tif (existingSubscriber!= null) {\n\t\t\tsubscriber.Address = subscriber.Address.Concat(existingSubscriber.Address).Except(subscriber.Address.Intersect(existingSubscriber.Address));\n\t\t}\n\t}\n\tawait base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 67.97721988304181}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t\tforeach (var subscriber in subscribers) {\n\t\tvar serviceSubscribers = base.Subscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id);\n\t\tvar existingSubscriber = serviceSubscribers.FirstOrDefault();\n\t\tif (existingSubscriber!= null) {\n\t\t\texistingSubscriber.Address = existingSubscriber.Address.Concat(subscriber.Address.Except(existingSubscriber.Address)).ToArray();\n\t\t}\n\t}\n\tawait base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 58.77865147893537}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t\tif (subscribers == null)\n\t\treturn;\n\n\tvar serviceSubscribers = await base.GetSubscribersAsync().ConfigureAwait(false);\n\tforeach (var subscriber in subscribers) {\n\t\tvar existingSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n\t\tif (existingSubscriber!= null) {\n\t\t\tif (subscriber.Address!= null) {\n\t\t\t\tif (existingSubscriber.Address == null)\n\t\t\t\t\texistingSubscriber.Address = subscriber.Address;\n\t\t\t\telse\n\t\t\t\t\texistingSubscriber.Address = existingSubscriber.Address.Concat(subscriber.Address.Except(existingSubscriber.Address)).ToArray();\n\t\t\t}\n\t\t\tsubscriber.Address = existingSubscriber.Address;\n\t\t}\n\t}\n\n\tawait base.SetSubscribersAsync(subscribers).ConfigureAwait(false);\n}", "CodeBleu_score": 59.21656342787711}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar subscribers = new List<ServiceSubscriber>();\nvar rootPath = _serviceDiscoveryOptions.SubscribersPath;\n\n_logger.LogDebug\nchildrens.ToArray\nrootPath.EndsWith\n\nforeach (var child in childrens) {\nvar nodePath = Path.Combine(rootPath, child);\nvar subscriber = await GetSubscriber(nodePath);\nsubscribers.Add(subscriber);\n}\n\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 38.45986506606066}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar subscribers = new List<ServiceSubscriber>();\nvar rootPath = _subscriberPath.TrimEnd(new[] { '/' });\n\n_logger.LogDebug\nchildrens.ToArray\nrootPath.EndsWith\n\nforeach (var child in childrens) {\nvar fullPath = Path.Combine(rootPath, child);\nvar subscriber = await GetSubscriber(fullPath);\n\nsubscribers.Add(subscriber);\n}\n\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 36.062329432590076}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t\n_logger.LogDebug\n\"Retrieving subscribers for node {0}.\"\nrootPath\nvar subscribers = new List<ServiceSubscriber>();\nforeach (var child in childrens) {\n\n_logger.LogDebug\n\"Retrieving subscriber for node {0}.\"\nchild\nvar subscriber = await GetSubscriber(child);\nif (subscriber!= null) {\nsubscribers.Add(subscriber);\n}\n}\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 36.441186926885585}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\t\tif (_subscribers!= null) {\n\t\treturn;\n\t}\n\n\tvar zooKeeper = GetZooKeeper();\n\tawait zooKeeper.Item1.WaitOneAsync();\n\tvar result = await zooKeeper.Item2.existsAsync(_subscribersPath);\n\tif (result.Stat!= null) {\n\t\tvar children = await zooKeeper.Item2.getChildrenAsync(_subscribersPath);\n\t\t_subscribers = children.Children.ToArray();\n\t} else {\n\t\t_logger.LogWarning($\"The subscribers path \\\"{_subscribersPath}\\\" does not exist.\");\n\t\t_subscribers = Array.Empty<string>();\n\t}\n}", "CodeBleu_score": 40.3796401710436}, {"code": "private async Task EnterSubscribers(){\n\t\tif (_subscribers!= null) {\n\t\treturn;\n\t}\n\n\tvar zooKeeper = await GetZooKeeper();\n\tawait zooKeeper.Item1.WaitOneAsync();\n\n\ttry {\n\t\tvar result = await zooKeeper.Item2.existsAsync(_subscriberPath);\n\t\tif (result.Stat!= null) {\n\t\t\tvar children = await zooKeeper.Item2.getChildrenAsync(_subscriberPath);\n\t\t\t_subscribers = children.Children.ToArray();\n\t\t} else {\n\t\t\t_logger.LogWarning(\"Subscriber path does not exist.\");\n\t\t\t_subscribers = Array.Empty<string>();\n\t\t}\n\t} finally {\n\t\tzooKeeper.Item1.Set();\n\t}\n}", "CodeBleu_score": 46.572679003136045}, {"code": "private async Task EnterSubscribers(){\n\t\tif (_subscribers!= null) return;\n\tvar zooKeeper = GetZooKeeper();\n\tzooKeeper.Item1.WaitOne();\n\ttry {\n\t\tvar result = await zooKeeper.Item2.existsAsync(_subscriberPath);\n\t\tif (result.Stat!= null) {\n\t\t\tvar children = await zooKeeper.Item2.getChildrenAsync(_subscriberPath);\n\t\t\t_subscribers = children.Children.ToArray();\n\t\t} else {\n\t\t\t_logger.LogWarning(\"Subscriber path does not exist\");\n\t\t\t_subscribers = Array.Empty<string>();\n\t\t}\n\t} catch (Exception ex) {\n\t\t_logger.LogError(ex, \"Failed to get subscribers\");\n\t\t_subscribers = Array.Empty<string>();\n\t}\n}", "CodeBleu_score": 45.0332854253883}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t<summary>", "CodeBleu_score": 4.659981754067967}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t\u65e7\u6570\u636e\u76f8\u540c\uff0c\u5219\u8fd4\u56de\u3002\nif (oldData.DataEquals(newData)) {\nreturn;\n}\n//\u4ece\u65b0\u6570\u636e\u4e2d\u83b7\u53d6\u670d\u52a1\u547d\u4ee4\u3002\nvar newCommand = ServiceCommand.FromBytes(newData);\n//\u4ece\u65e7\u6570\u636e\u4e2d\u83b7\u53d6\u670d\u52a1\u547d\u4ee4\u3002\nvar oldCommand = ServiceCommand.FromBytes(oldData);\n//\u5982\u679c\u65b0\u65e7\u547d\u4ee4\u7684\u670d\u52a1ID\u4e0d\u540c\uff0c\u5219\u8fd4\u56de\u3002\nif (oldCommand.ServiceId!= newCommand.ServiceId) {\nreturn;\n}\n//\u66ff\u6362\u65e7\u547d\u4ee4\u4e3a\u65b0\u547d\u4ee4\u3002\nServiceCommands = ServiceCommands.Where(i => i.ServiceId!= newCommand.ServiceId)\n.Concat(new[] { newCommand }).ToArray();\n//\u89e6\u53d1\u670d\u52a1\u547d\u4ee4\u53d8\u66f4\u4e8b\u4ef6\u3002\nOnChanged?.Invoke(newCommand, oldCommand);\n}", "CodeBleu_score": 61.94010548163571}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tmpare old and new data.\nif (oldData.DataEquals(newData)) {\nreturn;\n}\n// Retrieve the new service command.\nvar newCommand = new ServiceCommand(newData);\n// Update the service commands list by replacing the old command with the new one for the same service ID.\n_serviceCommands = _serviceCommands.Where(i => i.ServiceId \nGetServiceCommand\nerviceId!= newCommand.ServiceId)\n                       .Concat(new[] { newCommand }).ToArray();\n            }", "CodeBleu_score": 40.57500131042125}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tvar action = _action;\n\tif (watchedEvent.Type == EventType.NodeDataChanged) {\n\t\tvar zooKeeper = _zooKeeperCall();\n\t\tvar currentData = zooKeeper.Item2.Data;\n\t\tawait zooKeeper.Item1.GetDataAsync(zooKeeper.Item2.Path, this, out var newData);\n\t\taction(currentData, newData);\n\t\tzooKeeper.Item2.Data = newData;\n\t}\n}", "CodeBleu_score": 49.83513037552304}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.get_Type() == EventType.NodeDataChanged) {\n\t\tvar zooKeeper = await _zooKeeperCall();\n\t\tvar currentData = await zooKeeper.Item2.getDataAsync(watchedEvent.get_Path(), this, null);\n\t\t_action(currentData, zooKeeper.Item1);\n\t\tzooKeeper.Item2.setDataAsync(watchedEvent.get_Path(), zooKeeper.Item1, -1, this, null);\n\t}\n}", "CodeBleu_score": 52.01453282132397}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.get_Type() == EventType.NodeDataChanged) {\n\t\tvar zooKeeper = await _zooKeeperCall(async zooKeeper => {\n\t\t\treturn await zooKeeper.Item2.getDataAsync(watchedEvent.get_Path(), true);\n\t\t});\n\t\tvar currentData = Encoding.UTF8.GetString(zooKeeper.Item1);\n\t\tvar newData = Encoding.UTF8.GetString(zooKeeper.Item2.Result.Data);\n\t\tawait _action(currentData, newData);\n\t\t_watcher.SetCurrentData(newData);\n\t}\n}", "CodeBleu_score": 28.971473070192744}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t\tbuilder.Services.Register(provider =>\n\t\tnew DefaultZookeeperClientProvider(\n\t\t\tGetConfigInfo(configInfo),\n\t\t\tprovider.Resolve<IHealthCheckService>(),\n\t\t\tprovider.Resolve<IZookeeperAddressSelector>(),\n\t\t\tprovider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance();\n\treturn builder;\n}", "CodeBleu_score": 93.26699091378802}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tbuilder.Services.Register(provider =>\n       new DefaultZookeeperClientProvider(\n           GetConfigInfo(configInfo),\n        provider.Resolve<IHealthCheckService>(),\n          provider.Resolve<IZookeeperAddressSelector>(),\n          provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance\nreturn builder\n}", "CodeBleu_score": 77.37806354170344}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t\tvar provider = builder.Services.BuildServiceProvider();\n\tbuilder.Services.Register(provider =>\n\t\tnew DefaultZookeeperClientProvider(\n\t\t\tGetConfigInfo(configInfo),\n\t\t\tprovider.Resolve<IHealthCheckService>(),\n\t\t\tprovider.Resolve<IZookeeperAddressSelector>(),\n\t\t\tprovider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance();\n\treturn builder;\n}", "CodeBleu_score": 86.20941602964766}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\n// Get ZooKeeper clients\nvar zooKeepers = _provider.GetZooKeepers();\n\n// Iterate over ZooKeeper clients\nforeach (var zooKeeper in zooKeepers) {\n\n// Ensure MQTT route path subdirectory exists\nawait EnsurePathAsync(zooKeeper, _configuration.RoutePath);\n\n// Iterate over routes\nforeach (var route in routes) {\n\n// Get MQTT route path\nvar routePath = $\"{_configuration.RoutePath}/{route.Name}\";\n\n// Get route data\nvar routeData = route.Serialize();\n\n// Get existing route data\nvar existingData = await GetDataAsync(zooKeeper, routePath);\n\n// Check if route data is different from existing data\nif (!DataEquals(routeData, existingData)) {\n\n// Create or update node with route data\nawait CreateOrUpdateNodeAsync(zooKeeper, routePath, routeData);\n\n// Log action taken\n_logger.LogInformation($\"Route {route.Name} added or updated.\");\n}\n}\n\n// Log confirmation of successful addition of routes\n_logger.LogInformation(\"Routes added successfully.\");\n}\n}", "CodeBleu_score": 28.722678225168842}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\nvar zooKeepers = _provider.GetZooKeepers();\n\nforeach (var zooKeeper in zooKeepers) {\n\nvar serviceRoute = _configuration.GetSection(\"ServiceRoute\").Get<ServiceRoute>();\n\nvar nodePath = $\"{serviceRoute.Path}/{_configuration.GetValue<string>(\"ServiceName\")}\";\n\nvar nodeExists = await NodeExistsAsync(zooKeeper, nodePath);\n\nif (!nodeExists) {\n\nawait CreateNodeAsync(zooKeeper, nodePath, null);\n\n}\n\nvar nodeData = Encoding.UTF8.GetBytes(JsonSerializer.Serialize(routes));\n\nvar nodeDataExists = await NodeDataEqualsAsync(zooKeeper, nodePath, nodeData);\n\nif (!nodeDataExists) {\n\nawait SetNodeDataAsync(zooKeeper, nodePath, nodeData);\n\n}\n\n}\n\n}", "CodeBleu_score": 25.50195434900878}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\nvar zooKeepers = _zooKeeperProvider.GetZooKeepers();\n\n            foreach (var zooKeeper in zooKeepers) {\n                var nodePath = _configuration.GetZooKeeperNodePath();\n\n                if (!await zooKeeper.ExistsAsync(nodePath)) {\n                    await zooKeeper.CreateAsync(nodePath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n                }\n\n                foreach (var route in routes) {\n                    var serviceRoute = new MqttServiceRoute(route);\n                    var nodePath = _configuration.GetZooKeeperNodePath(serviceRoute);\n\n                    var nodeData = _serializer.Serialize(serviceRoute);\n                    var nodeDataExists = await zooKeeper.ExistsAsync(nodePath)!= null;\n\n                    if (nodeDataExists) {\n                        var nodeDataCurrent = await zooKeeper.GetDataAsync(nodePath);\n\n                        if (!DataEquals(nodeData, nodeDataCurrent)) {\n                            await zooKeeper.SetDataAsync(nodePath, nodeData);\n\n                            _logger.LogInformation(\"\u8282\u70b9\uff1a{nodePath}\u6570\u636e\u5df2\u66f4\u65b0\", nodePath);\n                        }\n                    }\n                    else {\n                        await zooKeeper.CreateAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n\n                        _logger.LogInformation(\"\u8282\u70b9\uff1a{nodePath}\u5df2\u521b\u5efa\", nodePath);\n                    }\n                }\n            }\n\n            _logger.LogInformation(\"\u670d\u52a1\u8def\u7531\u5df2\u6dfb\u52a0\u5230ZooKeeper\");\n        }", "CodeBleu_score": 52.64766283946496}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routeTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n\tvar zooKeepers = _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tvar oldRouteTopics = await zooKeeper.Item2.getChildrenAsync(ZookeeperConstants.ZookeeperRoutePath);\n\t\tvar deletedRouteTopics = oldRouteTopics.Except(routeTopics).ToArray();\n\t\tforeach (var deletedRouteTopic in deletedRouteTopics) {\n\t\t\tif (addresses.Contains(hostAddr)) {\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(ZookeeperConstants.ZookeeperRoutePath + \"/\" + deletedRouteTopic);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 42.126661581914796}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routeTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n\tvar zooKeepers = _zookeeperClientProvider.GetZooKeepers();\n\tvar routePath = RoutePath;\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tvar existingRouteTopics = await zooKeeper.Item2.getChildrenAsync(routePath);\n\t\tvar deletedRouteTopics = existingRouteTopics.Except(routeTopics).ToArray();\n\t\tforeach (var deletedRouteTopic in deletedRouteTopics) {\n\t\t\tvar route = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\n\t\t\tif (route.Addresses.Contains(hostAddr)) {\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(routePath + \"/\" + deletedRouteTopic);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 51.53618157086113}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routeTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n\tvar zooKeepers = _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tvar children = await zooKeeper.Item2.getChildrenAsync(ZookeeperRoutePath);\n\t\tvar deletedRouteTopics = children.Where(p =>!routeTopics.Contains(p)).ToArray();\n\t\tforeach (var deletedRouteTopic in deletedRouteTopics) {\n\t\t\tif (zooKeeper.Item1.Contains(hostAddr.Host)) {\n\t\t\t\tawait zooKeeper.Item2.deleteAsync($\"{ZookeeperRoutePath}/{deletedRouteTopic}\");\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 40.005977497924384}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\n_logger.LogInformation(\"Updating service cache descriptors in Zookeeper\");\n            var cachePath = _configuration.GetCachePath();\n            var zooKeepers = _zooKeeperProvider.GetZooKeepers();\n\n            foreach (var zooKeeper in zooKeepers) {\n                await EnsurePathExistsAsync(zooKeeper, cachePath);\n                foreach (var cacheDescriptor in cacheDescriptors) {\n                    var cacheDescriptorData = _serializer.Serialize(cacheDescriptor);\n                    var cacheDescriptorNodePath = $\"{cachePath}/{cacheDescriptor.ServiceName}\";\n                    var cacheDescriptorNodeExists = await NodeExistsAsync(zooKeeper, cacheDescriptorNodePath);\n\n                    if (!cacheDescriptorNodeExists) {\n                        await CreateNodeAsync(zooKeeper, cacheDescriptorNodePath, cacheDescriptorData, ZooDefs.Ids.OPEN_ACL_UNSAFE);\n                    } else {\n                        var cacheDescriptorNodeData = await zooKeeper.GetDataAsync(cacheDescriptorNodePath);\n                        if (!DataEquals(cacheDescriptorNodeData, cacheDescriptorData)) {\n                            await zooKeeper.SetDataAsync(cacheDescriptorNodePath, cacheDescriptorData);\n                        }\n                    }\n                }\n            }\n\n            _logger.LogInformation(\"Successfully added service caches\");\n        }", "CodeBleu_score": 46.052266251838816}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\n_logger.LogInformation($\"Updating service caches: {string.Join(\", \", cacheDescriptors.Select(c => c.ServiceName))}\");\n\nvar cacheDescriptor = cacheDescriptors.First();\nvar cachePath = $\"/{cacheDescriptor.ServiceName}\";\nvar zooKeepers = await _zooKeeperProvider.GetZooKeepers();\n\nforeach (var zooKeeper in zooKeepers) {\n\nif (!await zooKeeper.ExistsAsync(cachePath)) {\n\nawait zooKeeper.CreateAsync(cachePath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n}\n\nforeach (var cacheDescriptor in cacheDescriptors) {\n\nvar cacheData = _serializer.Serialize(cacheDescriptor);\nvar cacheNodePath = $\"{cachePath}/{cacheDescriptor.CacheName}\";\n\nif (await zooKeeper.ExistsAsync(cacheNodePath) == null) {\n\nawait zooKeeper.CreateAsync(cacheNodePath, cacheData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n} else {\n\nvar nodeData = await zooKeeper.GetDataAsync(cacheNodePath);\n\nif (!DataEquals(nodeData, cacheData)) {\n\nawait zooKeeper.SetDataAsync(cacheNodePath, cacheData);\n}\n}\n}\n}\n\n_logger.LogInformation($\"Successfully updated service caches: {string.Join(\", \", cacheDescriptors.Select(c => c.ServiceName))}\");\n}", "CodeBleu_score": 49.18971984857109}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\n_logger.LogInformation(\"Updating service caches in Zookeeper.\");\n            var cacheDescriptor = cacheDescriptors.First();\n            var cachePath = GetCachePath(cacheDescriptor);\n            var zooKeepers = _zookeeperProvider.GetZooKeepers();\n\n            foreach (var zooKeeper in zooKeepers) {\n                await zooKeeper.EnsurePathExistsAsync(cachePath);\n\n                foreach (var cacheDescriptor in cacheDescriptors) {\n                    var cacheDescriptorBytes = cacheDescriptor.Serialize();\n                    var cacheNodePath = GetCacheNodePath(cacheDescriptor);\n                    var cacheNodeExists = await zooKeeper.ExistsAsync(cacheNodePath)!= null;\n\n                    if (!cacheNodeExists) {\n                        await zooKeeper.CreateAsync(cacheNodePath, cacheDescriptorBytes, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n                    } else {\n                        var cacheNodeData = await zooKeeper.GetDataAsync(cacheNodePath);\n                        if (!cacheDescriptorBytes.SequenceEqual(cacheNodeData)) {\n                            await zooKeeper.SetDataAsync(cacheNodePath, cacheDescriptorBytes);\n                        }\n                    }\n                }\n            }\n\n            _logger.LogInformation(\"Successfully added service caches.\");\n        }", "CodeBleu_score": 44.77282297958233}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t\nzooKeeper.Item2.existsAsync(path, null, ZooDefs", "CodeBleu_score": 8.918952245772827}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t_logger.LogInformation($\"Creating path: {path}\");\nzooKeeper.Item2.existsAsync(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, (rc, path, ctx, stat) => {\nif (rc == KeeperException.Code.NONODE) {\nzooKeeper.Item1.Set();\n}\n}, null);\nzooKeeper.Item1.WaitOne();\nif (zooKeeper.Item2.existsSync(path) == null) {\n_logger.LogInformation($\"Creating path: {path}\");\nvar pathComponents = path.Split(\"/\");\nvar pathBuilder = new StringBuilder();\nforeach (var component in pathComponents) {\npathBuilder.Append(\"/\");\npathBuilder.Append(component);\nif (zooKeeper.Item2.existsSync(pathBuilder.ToString()) == null) {\n_logger.LogInformation($\"Creating path: {pathBuilder.ToString()}\");\nzooKeeper.Item2.createAsync(pathBuilder.ToString(), new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent, null, null);\n}\n}\n}\n}", "CodeBleu_score": 45.09399266660827}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t_logger.LogInformation($\"Creating Subdirectory: {path}\");\nzooKeeper.Item2.existsAsync(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, null).Wait();\nif (zooKeeper.Item2.existsAsync(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, null).Result == null) {\n_logger.LogInformation($\"Subdirectory {path} does not exist, creating...\");\nzooKeeper.Item1.WaitOne();\nvar nodePath = \"/\";\nvar nodePathList = path.Split(\"/\").ToList();\nnodePathList.RemoveAt(0);\nforeach (var node in nodePathList) {\nnodePath += node;\nif (zooKeeper.Item2.existsAsync(nodePath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, null).Result == null) {\n_logger.LogInformation($\"Creating node {nodePath}\");\nzooKeeper.Item2.createAsync(nodePath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent).Wait();\n}\nnodePath += \"/\";\n}\n_logger.LogInformation($\"Subdirectory {path} created\");\n} else {\n_logger.LogInformation($\"Subdirectory {path} already exists\");\n}\n}", "CodeBleu_score": 54.40293745989743}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\n\tforeach (var address in _addresses) {\n\t\tvar healthCheckService = new HealthCheckService(address);\n\t\tif (await healthCheckService.IsHealth()) {\n\t\t\tvar resetEvent = new ManualResetEvent(false);\n\t\t\tvar zooKeeper = new ZooKeeper(address, TimeSpan.FromSeconds(5), new HealthCheckWatcher(resetEvent));\n\t\t\tresult.Add((resetEvent, zooKeeper));\n\t\t}\n\t}\n\treturn result;\n}", "CodeBleu_score": 65.23711099080951}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\n\tforeach (var address in _addresses) {\n\t\tvar healthCheckService = new HealthCheckService(address);\n\t\tif (await healthCheckService.IsHealth()) {\n\t\t\tvar createZooKeeper = CreateZooKeeper(address);\n\t\t\tresult.Add((createZooKeeper.Item1, createZooKeeper.Item2));\n\t\t}\n\t}\n\treturn result;\n}", "CodeBleu_score": 68.29193216545809}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\n\tforeach (var address in _addresses) {\n\t\tvar healthCheckService = new HealthCheckService(address);\n\t\tif (!await healthCheckService.IsHealth()) {\n\t\t\tcontinue;\n\t\t}\n\t\tvar resetEvent = new ManualResetEvent(false);\n\t\tvar zk = new ZooKeeper(address, TimeSpan.FromSeconds(5), new ZooKeeperWatcher(resetEvent));\n\t\tresult.Add((resetEvent, zk));\n\t}\n\treturn result;\n}", "CodeBleu_score": 64.18256398068505}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tZooKeeper zk = null;\n\tsynchronized (this) {\n\t\tzk = zooKeeper;\n\t\tif (zk == null) {\n\t\t\tzk = newZooKeeper();\n\t\t}\n\t}\n\treturn zk;\n}", "CodeBleu_score": 16.220688353346073}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tsynchronized(this) {\n\t\tif (zooKeeper == null) {\n\t\t\tinitZooKeeper();\n\t\t}\n\t}\n\treturn zooKeeper;\n}", "CodeBleu_score": 7.622906213919014}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tif (this.zooKeeper == null) {\n\t\tsynchronized (this) {\n\t\t\tif (this.zooKeeper == null) {\n\t\t\t\tthis.zooKeeper = newZooKeeper();\n\t\t\t}\n\t\t}\n\t}\n\treturn this.zooKeeper;\n}", "CodeBleu_score": 17.925160166628096}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (zk!= null) {\n\t\tif (waitForShutdownTimeoutMs == 0) {\n\t\t\tzk.close();\n\t\t} else {\n\t\t\tzk.register(new Watcher() {\n\t\t\t\t@Override\n\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t}\n\t\t\t});\n\t\t\ttry {\n\t\t\t\tzk.close();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tThread.currentThread().interrupt();\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 28.504115887908117}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (zk!= null) {\n\t\ttry {\n\t\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\t\tzk.register(new Watcher() {\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\tzk.close();\n\t\t\t\tzk = null;\n\t\t\t\ttry {\n\t\t\t\t\tThread.sleep(waitForShutdownTimeoutMs);\n\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\tThread.currentThread().interrupt();\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tzk.close();\n\t\t\t\tzk = null;\n\t\t\t}\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t\tthrow e;\n\t\t}\n\t}\n}", "CodeBleu_score": 38.18464561745129}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (this.zk!= null) {\n\t\ttry {\n\t\t\tthis.zk.register(new Watcher() {\n\t\t\t\t@Override\n\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t}\n\t\t\t});\n\t\t\tthis.zk.close();\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t\tthrow e;\n\t\t}\n\t}\n\tif (waitForShutdownTimeoutMs > 0) {\n\t\ttry {\n\t\t\tthis.waitForShutdownLatch.await(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t\tthrow e;\n\t\t}\n\t}\n}", "CodeBleu_score": 29.303019820292803}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tif (isStarted()) {\n\t\tlong startTime = System.currentTimeMillis();\n\t\tinternalBlockUntilConnectedOrTimedOut();\n\t\tlong endTime = System.currentTimeMillis();\n\t\tlog.debug(\"blockUntilConnectedOrTimedOut took {}ms\", endTime - startTime);\n\t\tdebug(\"blockUntilConnectedOrTimedOut took {}ms\", endTime - startTime);\n\t\treturn isConnected();\n\t} else {\n\t\tlog.warn(\"blockUntilConnectedOrTimedOut called but client is not started\");\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 38.11715156094691}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\treturn blockUntilConnectedOrTimedOut(DEFAULT_TIMEOUT_MILLIS);\n}", "CodeBleu_score": 5.287195273733601}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tif (this.isStarted()) {\n\t\tlog.debug(\"Waiting for connection to become ready\");\n\t\tlong start = System.currentTimeMillis();\n\t\tboolean connected = this.internalBlockUntilConnectedOrTimedOut(start, start + this.connectionTimeout);\n\t\tlog.debug(\"Connection ready: {}\", connected);\n\t\treturn connected;\n\t} else {\n\t\tlog.debug(\"Not connected because the client is not started\");\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 44.232944285958574}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tlog.info(\"Shutting down service...\");\n\tstarted = false;\n\ttry {\n\t\tserver.close(waitForShutdownTimeoutMs);\n\t} catch (IOException e) {\n\t\tcheckInterrupted(e);\n\t\tlog.error(\"Error shutting down service\", e);\n\t}\n}", "CodeBleu_score": 42.707829500792535}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tlog.info(\"Shutting down service\");\n\tstarted = false;\n\ttry {\n\t\tserver.close(waitForShutdownTimeoutMs);\n\t} catch (IOException e) {\n\t\tcheckInterrupted();\n\t\tlog.error(\"Error shutting down service\", e);\n\t}\n}", "CodeBleu_score": 42.335717578382415}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tlog.info(\"Closing service\");\n\tstarted = false;\n\ttry {\n\t\tclose(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n\t} catch (IOException e) {\n\t\tif (Thread.interrupted()) {\n\t\t\tlog.error(\"Interrupted while waiting for shutdown\", e);\n\t\t} else {\n\t\t\tlog.error(\"Error while waiting for shutdown\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 43.63703284665891}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tif (this.state == State.CONNECTED) {\n\t\treturn;\n\t}\n\tfinal CountDownLatch countDown = new CountDownLatch(1);\n\tfinal Watcher watcher = new Watcher() {\n\t\t@Override\n\t\tpublic void process(WatchedEvent event) {\n\t\t\tif (event.getState() == Event.KeeperState.SyncConnected) {\n\t\t\t\tcountDown.countDown();\n\t\t\t}\n\t\t}\n\t};\n\tthis.zk.register(watcher);\n\tif (!countDown.await(this.connectionTimeout, TimeUnit.MILLISECONDS)) {\n\t\tthrow new InterruptedException(\"Cannot connect to zookeeper server within timeout: \" + this.connectionTimeout);\n\t}\n\tthis.zk.unregister(watcher);\n}", "CodeBleu_score": 28.887567779534614}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\t// The connection state is checked within the timeout period.\n\tfinal CountDownLatch latch = new CountDownLatch(1);\n\tfinal AtomicReference<Watcher> watcherRef = new AtomicReference<Watcher>();\n\tfinal Watcher watcher = new Watcher() {\n\t\t@Override\n\t\tpublic void process(WatchedEvent event) {\n\t\t\tif (event.getState() == KeeperState.SyncConnected) {\n\t\t\t\tlatch.countDown();\n\t\t\t}\n\t\t}\n\t};\n\twatcherRef.set(watcher);\n\ttry {\n\t\tclient.getZK().register(watcher);\n\t\tfinal long start = System.currentTimeMillis();\n\t\tfinal long end = start + client.getConf().getConnectionTimeout();\n\t\twhile (true) {\n\t\t\tfinal long waitTime = end - System.currentTimeMillis();\n\t\t\tif (waitTime <= 0) {\n\t\t\t\tthrow new ZkTimeoutException(\"Unable to connect to ZooKeeper service within timeout: \" + client.getConf().getConnectionTimeout());\n\t\t\t}\n\t\t\tif (latch.await(waitTime, TimeUnit.MILLISECONDS)) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tclient.getZK().unregister(watcher);\n\t\t\twatcherRef.set(null);\n\t\t\tif (client.getZK().getState() == KeeperState.SyncConnected) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tclient.getZK().register(watcher);\n\t\t}\n\t} finally {\n\t\tfinal Watcher w = watcherRef.getAndSet(null);\n\t\tif (w!= null) {\n\t\t\tclient.getZK().unregister(w);\n\t\t}\n\t}\n}", "CodeBleu_score": 42.13258571393298}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tif (this.connectionState == ConnectionState.CONNECTED) {\n\t\treturn;\n\t}\n\tfinal CountDownLatch countDown = new CountDownLatch(1);\n\tfinal Watcher watcher = new Watcher() {\n\t\t@Override\n\t\tpublic void process(WatchedEvent event) {\n\t\t\tif (event.getState() == KeeperState.SyncConnected) {\n\t\t\t\tcountDown.countDown();\n\t\t\t}\n\t\t}\n\t};\n\tthis.zk.register(watcher);\n\ttry {\n\t\tif (!countDown.await(this.connectionTimeoutMs, TimeUnit.MILLISECONDS)) {\n\t\t\tthrow new InterruptedException(\"Timed out waiting for connection\");\n\t\t}\n\t} finally {\n\t\tthis.zk.unregister(watcher);\n\t}\n}", "CodeBleu_score": 29.024801975429632}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t\tif (client.getZooKeeper().getSessionId()!= sessionId) {\n\t\tLOG.warn(\"Session {} has changed. Deleting old node: {}\", sessionId, foundNode)\n\t\tclient.delete().forPath(foundNode)\n\t\tsessionId = client.getZooKeeper().getSessionId()\n\t}\n\treturn foundNode\n}", "CodeBleu_score": 26.23103302805395}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t\tif (client.getZooKeeper()!= null && client.getZooKeeper().getSessionId()!= client.getSessionId()) {\n\t\tclient.logError(\"Session has changed. Deleting old node: \" + foundNode)\n\t\tclient.delete().forPath(foundNode)\n\t\tclient.setSessionId(client.getZooKeeper().getSessionId())\n\t}\n\treturn foundNode\n}", "CodeBleu_score": 22.209231364562594}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t\tif (client.getZooKeeper()!= null && client.getZooKeeper().getSessionId()!= client.getSessionId()) {\n\t\tlog.warn(\"Session {} has changed. Deleting node {} and re-creating\", client.getSessionId(), foundNode)\n\t\tclient.delete().forPath(foundNode)\n\t\tclient.getZooKeeper().getSessionId()\n\t\tclient.getZooKeeper().getSessionPasswd()\n\t\tfoundNode = null\n\t}\n\treturn foundNode\n}", "CodeBleu_score": 24.74376749089478}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tfinal Trace trace = newTrace(path, aclList);\n\tfinal String pathInForeground = trace.pathInForeground;\n\tfinal List<ACL> aclListInForeground = trace.aclListInForeground;\n\tfinal Stat stat = new Stat();\n\tretry(new Callable<Void>() {\n\t\t@Override\n\t\tpublic Void call() throws Exception {\n\t\t\tfinal Stat statInForeground = getZooKeeper().setACL(pathInForeground, aclListInForeground, -1);\n\t\t\ttrace.statInForeground = statInForeground;\n\t\t\treturn null;\n\t\t}\n\t});\n\ttrace.commit();\n\treturn stat;\n}", "CodeBleu_score": 38.81675645697158}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tfinal String traceName = \"setACL\";\n\tfinal String traceId = startTrace(traceName, path);\n\ttry {\n\t\treturn retry(new Callable<Stat>() {\n\t\t\tpublic Stat call() throws Exception {\n\t\t\t\treturn setACL(path, aclList);\n\t\t\t}\n\t\t}, traceId, traceName, path);\n\t} finally {\n\t\tcommitTrace(traceId);\n\t}\n}", "CodeBleu_score": 30.68632522540361}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tdef trace = startTrace(\"setACL\", path, aclList)\n\tdef status = null\n\tdef retry = 0\n\twhile (status == null) {\n\t\ttry {\n\t\t\tstatus = zooKeeper.setACL(path, aclList, -1)\n\t\t} catch (Exception e) {\n\t\t\tif (retry++ < 3) {\n\t\t\t\tThread.sleep(100)\n\t\t\t} else {\n\t\t\t\tthrow e\n\t\t\t}\n\t\t}\n\t}\n\ttrace.commit(path, status)\n\treturn status\n}", "CodeBleu_score": 20.900028396108716}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\tthis.client = client;\nthis.membershipPath = membershipPath;\nthis.thisId = thisId;\nthis.payload = payload;\n\n// validate the member ID\nif (this.thisId == null || this.thisId.length() == 0) {\nthrow new IllegalArgumentException(\"member id cannot be null or empty\");\n}\n\n// set up a cache for the membership path\nthis.cache = CuratorCache.builder(client, membershipPath).build();\nthis.cache.start();\n\n// create an ephemeral node for the member\nthis.node = client.create().withMode(CreateMode.EPHEMERAL).forPath(membershipPath + \"/\" + thisId, payload);\n}", "CodeBleu_score": 51.74518666495077}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.memberNode = new PersistentNode(client, new PersistentNode.PersistentNodeListener() {\n\t\t@Override\n\t\tpublic void persistentNodeCreated() {\n\t\t\tmemberNode.start();\n\t\t\tmemberNode.setData(payload);\n\t\t}\n\n\t\t@Override\n\t\tpublic void persistentNodeDeleted() {\n\t\t\tmemberNode.close();\n\t\t\tmemberNode = null;\n\t\t}\n\t}, membershipPath, thisId, payload);\n}", "CodeBleu_score": 41.980267705581866}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client\n\tthis.membershipPath = membershipPath\n\tthis.thisId = thisId\n\tthis.payload = payload\n\tif (thisId == null || thisId.isEmpty()) {\n\t\tthrow new IllegalArgumentException(\"thisId cannot be null or empty\")\n\t}\n\tif (thisId.contains(\"/\")) {\n\t\tthrow new IllegalArgumentException(\"thisId cannot contain '/'\")\n\t}\n\tthis.cache = CuratorCache.build(client, membershipPath)\n\tthis.cache.start()\n\ttry {\n\t\tclient.create().withMode(CreateMode.EPHEMERAL).forPath(membershipPath + \"/\" + thisId, payload)\n\t} catch (NodeExistsException e) {\n\t\tthrow new IllegalStateException(\"thisId already exists: \" + thisId, e)\n\t}\n}", "CodeBleu_score": 31.435574330536976}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t\tclient.create()\n\t\t.creatingParentsIfNeeded()\n\t\t.withMode(CreateMode.PERSISTENT)\n\t\t.forPath(path)\n\t\t.whenComplete((bytes, error) -> {\n\t\t\tif (error == null) {\n\t\t\t\tclient.checkExists()\n\t\t\t\t\t.usingWatcher((client1, event) -> handleWatchedStage(client1, event, path))\n\t\t\t\t\t.forPath(path);\n\t\t\t} else {\n\t\t\t\terror.printStackTrace();\n\t\t\t}\n\t\t});\n}", "CodeBleu_score": 40.09285840506547}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t\ttry {\n\t\tclient.create().forPath(path);\n\t\tclient.watched().forPath(path).whenComplete((watchedPath, event) -> {\n\t\t\thandleWatchedStage(watchedPath, event);\n\t\t});\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n}", "CodeBleu_score": 33.80354662958132}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t\tclient.create().forPath(path);\n\tclient.getCuratorListenable().addListener((client1, event) -> {\n\t\ttry {\n\t\t\thandleWatchedStage(client1, event);\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t});\n}", "CodeBleu_score": 30.23980912648472}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> results = zooKeeper.multi(ops);\n\tif (results.get(0).getStat()!= null) {\n\t\tthrow KeeperException.create(KeeperException.Code.get(results.get(0).getStat().getVersion()), zooKeeper.getZookeeperClient().getZooKeeper().getSessionId());\n\t}\n\treturn results;\n}", "CodeBleu_score": 20.715152772559257}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> results = client.multi(ops);\n\tif (results.get(0).getStat()!= null) {\n\t\tthrow KeeperException.create(KeeperException.Code.get(results.get(0).getStat().getVersion()), path);\n\t}\n\treturn results;\n}", "CodeBleu_score": 16.89046185507207}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> results = null;\n\ttry {\n\t\tresults = this.client.multi(this.ops);\n\t} catch (KeeperException e) {\n\t\t// If the first operation in the list is an error, throw a KeeperException with the corresponding code\n\t\tif (results!= null &&!results.isEmpty()) {\n\t\t\tKeeperException.Code code = results.get(0).getErr();\n\t\t\tthrow KeeperException.create(code);\n\t\t}\n\t\t// Otherwise, rethrow the original KeeperException\n\t\tthrow e;\n\t}\n\treturn results;\n}", "CodeBleu_score": 29.41552327564149}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\tList<String> serviceNames = serviceDiscovery.queryForNames().get();\n\tfor (String serviceName : serviceNames) {\n\t\tList<Instance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(serviceName).get();\n\t\tif (instances.isEmpty()) {\n\t\t\tSystem.err.println(\"No instances found for service \" + serviceName);\n\t\t} else {\n\t\t\tfor (Instance<InstanceDetails> instance : instances) {\n\t\t\t\tSystem.out.println(instance.getRegistration().getName() + \" \" + instance.getUri());\n\t\t\t}\n\t\t}\n\t}\n\tserviceDiscovery.closeQuietly();\n}", "CodeBleu_score": 43.06573291937502}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\tdef names = serviceDiscovery.queryForNames()\n\tfor (name in names) {\n\t\tdef instances = serviceDiscovery.queryForInstances(name)\n\t\tif (instances.isEmpty()) {\n\t\t\tprintln \"No instances found for service: \" + name\n\t\t\tcontinue\n\t\t}\n\t\tprintln \"Instances for service: \" + name\n\t\tfor (instance in instances) {\n\t\t\tprintln \"    \" + instance\n\t\t}\n\t}\n\tcloseQuietly(serviceDiscovery)\n}", "CodeBleu_score": 30.838204648123856}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\t// query for all service names and their corresponding instances\n\tMap<String, List<InstanceDetails>> instances = serviceDiscovery.queryForNames();\n\n\t// print each service name and its instances\n\tfor (Map.Entry<String, List<InstanceDetails>> entry : instances.entrySet()) {\n\t\tString serviceName = entry.getKey();\n\t\tList<InstanceDetails> serviceInstances = entry.getValue();\n\n\t\tprintln \"Service Name: $serviceName\"\n\t\tfor (InstanceDetails instance : serviceInstances) {\n\t\t\tprintln \"\\tInstance: $instance\"\n\t\t}\n\t}\n\n\t// if no instances are registered, catch the NoNodeException and print an error message\n\tif (instances.isEmpty()) {\n\t\tprintln \"No instances found\"\n\t}\n\n\t// close the ServiceDiscovery instance quietly\n\tcloseQuietly(serviceDiscovery);\n}", "CodeBleu_score": 31.733780277958566}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tchildren.removeAll { it == READY_NODE }\n\tchildren.sort()\n\treturn children\n}", "CodeBleu_score": 10.403727219902953}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\treturn children.findAll { it!= READY_NODE }.collect { it as String }.sort()\n}", "CodeBleu_score": 10.143038685302901}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\treturn children.findAll { it!= READY_NODE }*.toInteger().sort()\n}", "CodeBleu_score": 10.43522019047685}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\n\tzk = new ZooKeeper(newHost, 10000, this);\n\tzk.setReadOnly(readOnly);\n\tSystem.out.println(\"Connected to \" + newHost);\n}", "CodeBleu_score": 23.46796253145421}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tzk = new ZooKeeper(newHost, clientTimeout, this);\n\treadOnly = getOption(\"readonly\");\n}", "CodeBleu_score": 25.4404423212915}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tzk = new ZooKeeper(newHost, CLIENT_TIMEOUT, this);\n\tif (readOnly) {\n\t\tzk.setReadOnly(true);\n\t}\n}", "CodeBleu_score": 20.687952454955564}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t\tList<ACL> acls = new ArrayList<ACL>()\n\tif (aclString!= null) {\n\t\tString[] strs = aclString.split(\"\\\\s*,\\\\s*\")\n\t\tfor (String str : strs) {\n\t\t\tint idx = str.indexOf(':')\n\t\t\tif (idx < 0) {\n\t\t\t\tLOG.warn(\"acl string \" + str + \" is not valid, ignoring.\")\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tString scheme = str.substring(0, idx)\n\t\t\tString idStr = str.substring(idx + 1)\n\t\t\tif (idStr.length() == 0) {\n\t\t\t\tLOG.warn(\"acl string \" + str + \" is not valid, ignoring.\")\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tString id = null\n\t\t\tif (idStr.startsWith(\"\\\"\") && idStr.endsWith(\"\\\"\")) {\n\t\t\t\tid = idStr.substring(1, idStr.length() - 1)\n\t\t\t} else {\n\t\t\t\tid = idStr\n\t\t\t}\n\t\t\tif (id.length() == 0) {\n\t\t\t\tLOG.warn(\"acl string \" + str + \" is not valid, ignoring.\")\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif (id.indexOf(':') >= 0) {\n\t\t\t\tLOG.warn(\"acl string \" + str + \" is not valid, ignoring.\")\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tACL acl = new ACL(getPermFromString(idStr))\n\t\t\tacl.setId(new Id(scheme, id))\n\t\t\tacls.add(acl)\n\t\t}\n\t}\n\treturn acls\n}", "CodeBleu_score": 28.085230237466508}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t\tList<ACL> aclList = new ArrayList<ACL>()\n\tif (aclString!= null && aclString.length() > 0) {\n\t\tString[] segments = aclString.split(\",\")\n\t\tfor (String segment : segments) {\n\t\t\ttry {\n\t\t\t\tint index = segment.indexOf(\":\")\n\t\t\t\tif (index < 0) {\n\t\t\t\t\tthrow new IOException(\"Invalid ACL segment: \" + segment)\n\t\t\t\t}\n\t\t\t\tString scheme = segment.substring(0, index)\n\t\t\t\tString id = segment.substring(index + 1)\n\t\t\t\tindex = id.indexOf(\":\")\n\t\t\t\tif (index < 0) {\n\t\t\t\t\tthrow new IOException(\"Invalid ACL segment: \" + segment)\n\t\t\t\t}\n\t\t\t\tString perms = id.substring(index + 1)\n\t\t\t\tid = id.substring(0, index)\n\t\t\t\tACL acl = new ACL(getPermFromString(perms))\n\t\t\t\tacl.setId(id)\n\t\t\t\tacl.setScheme(scheme)\n\t\t\t\taclList.add(acl)\n\t\t\t} catch (IOException e) {\n\t\t\t\tLOG.warn(\"Failed to parse ACL segment: \" + segment, e)\n\t\t\t}\n\t\t}\n\t}\n\treturn aclList\n}", "CodeBleu_score": 27.48804797197113}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t\tif (aclString == null) {\n\t\treturn Collections.emptyList();\n\t}\n\tList<ACL> acls = new ArrayList<ACL>();\n\tfor (String segment : aclString.split(\",\")) {\n\t\tsegment = segment.trim();\n\t\tif (segment.length() == 0) {\n\t\t\tcontinue;\n\t\t}\n\t\tString[] parts = segment.split(\"\\\\s+\");\n\t\tif (parts.length!= 3) {\n\t\t\tLOG.warn(\"Invalid ACL segment: \" + segment);\n\t\t\tcontinue;\n\t\t}\n\t\tString scheme = parts[0];\n\t\tString id = parts[1];\n\t\tString permString = parts[2];\n\t\tFsPermission perm = getPermFromString(permString);\n\t\tif (perm == null) {\n\t\t\tLOG.warn(\"Invalid ACL segment: \" + segment);\n\t\t\tcontinue;\n\t\t}\n\t\tACL acl = new ACL(scheme, id, perm);\n\t\tacls.add(acl);\n\t}\n\treturn acls;\n}", "CodeBleu_score": 27.26973559964614}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t\tif (pathList == null) {\n\t\tthrow new IllegalArgumentException(\"pathList cannot be null\");\n\t}\n\tif (pathList.size() == 0) {\n\t\treturn;\n\t}\n\tassertZookeeperExists(serverId);\n\tZooKeeper zookeeper = zooKeeperMap.get(serverId);\n\tif (pathList.size() < 20) {\n\t\tfor (String path : pathList) {\n\t\t\ttry {\n\t\t\t\tzookeeper.delete(path, -1);\n\t\t\t} catch (KeeperException e) {\n\t\t\t\tif (e.code()!= KeeperException.Code.NONODE) {\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tdeleteAsync(serverId, pathList);\n\t}\n}", "CodeBleu_score": 58.102323285799805}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t\tif (pathList == null || pathList.isEmpty()) {\n\t\treturn;\n\t}\n\tassertZookeeperExists(serverId);\n\tif (pathList.size() < 20) {\n\t\tfor (String path : pathList) {\n\t\t\tdelete(serverId, path);\n\t\t}\n\t} else {\n\t\tdeleteAsync(serverId, pathList);\n\t}\n}", "CodeBleu_score": 62.22399827592575}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t\tassertZookeeperExists(serverId);\n\tif (pathList == null) {\n\t\tthrow new IllegalArgumentException(\"pathList must not be null\");\n\t}\n\tif (pathList.size() < 20) {\n\t\tfor (String path : pathList) {\n\t\t\tdelete(serverId, path);\n\t\t}\n\t} else {\n\t\tdeleteAsync(serverId, pathList);\n\t}\n}", "CodeBleu_score": 61.96732294931676}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\twriter.write(\"Connecting to \" + url + \"\n\");\nCuratorZookeeperClient connection = new CuratorZookeeperConnectionFactory(url, 15000).create();\nZooKeeperClient zooKeeper = connection.getZookeeperClient();\nwriter.write(\"Connected to \" + url + \"\n\");\nZooKeeperMain zkMain = new ZooKeeperMain(zooKeeper, writer);\nreturn new Terminal(id, url, connection, zkMain);\n}", "CodeBleu_score": 41.27043468563741}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t\twriter.write(\"Connecting to \" + url + \"\n\");\n\tZooKeeperConnection connection = CuratorZookeeperConnectionFactory.createConnection(url);\n\tZooKeeperClient client = connection.getZookeeperClient();\n\twriter.write(\"Connected\n\");\n\tZooKeeperMain main = new ZooKeeperMain(client);\n\treturn new Terminal(id, url, connection, main);\n}", "CodeBleu_score": 36.1508613222866}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t\twriter.write(\"Connecting to \" + url + \"...\n\");\n\tCuratorZookeeperClient connection = new CuratorZookeeperConnectionFactory(url).create();\n\twriter.write(\"Connected!\n\");\n\tZooKeeperMain zkMain = new ZooKeeperMain(connection);\n\treturn new Terminal(id, url, connection, zkMain);\n}", "CodeBleu_score": 32.97626239986592}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\t\tint retries = 6;\n\twhile (retries-- > 0) {\n\t\ttry {\n\t\t\tif (isConnected()) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tconnect();\n\t\t\tif (isConnected()) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t} catch (JSchException e) {\n\t\t\tclose();\n\t\t\tthrow new IllegalStateException(\"SSH connection failed\", e);\n\t\t}\n\t\tsleep(1000);\n\t}\n\tclose();\n\tthrow new IllegalStateException(\"SSH connection failed\");\n}", "CodeBleu_score": 29.46695864979882}, {"code": "public void blockUntilConnected(){\n\t\tint attempts = 0;\n\twhile (attempts < 6) {\n\t\ttry {\n\t\t\tif (isConnected()) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tconnect();\n\t\t\treturn;\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"SSH connection attempt failed: \" + e.getMessage());\n\t\t\tclose();\n\t\t}\n\t\tattempts++;\n\t\ttry {\n\t\t\tThread.sleep(1000);\n\t\t} catch (InterruptedException e) {\n\t\t\tlogger.error(\"Thread sleep interrupted\");\n\t\t}\n\t}\n\tclose();\n\tthrow new IllegalStateException(\"SSH connection failed\");\n}", "CodeBleu_score": 41.432421726545705}, {"code": "public void blockUntilConnected(){\n\t\tint retries = 6;\n\twhile (true) {\n\t\ttry {\n\t\t\tconnect();\n\t\t\tbreak;\n\t\t} catch (JSchException e) {\n\t\t\tretries--;\n\t\t\tif (retries <= 0) {\n\t\t\t\tclose();\n\t\t\t\tthrow new IllegalStateException(\"Failed to establish SSH tunnel connection\", e);\n\t\t\t} else {\n\t\t\t\tlog.warn(\"Failed to establish SSH tunnel connection, retrying in 1 second\", e);\n\t\t\t\ttry {\n\t\t\t\t\tThread.sleep(1000);\n\t\t\t\t} catch (InterruptedException e1) {\n\t\t\t\t\t// ignore\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 32.368305637481185}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.delete(serverId, pathList)\n\t} catch (Exception e) {\n\t\tlog.error(\"Failed to delete nodes: ${pathList}\", e)\n\t\tthrow new IllegalStateException(\"Failed to delete nodes: ${pathList}\", e)\n\t}\n}", "CodeBleu_score": 60.500660018970464}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList)\n\t} catch (Exception e) {\n\t\tlog.error(\"Exception deleting node ${pathList} from Zookeeper\", e)\n\t\tthrow new IllegalStateException(\"Exception deleting node ${pathList} from Zookeeper\", e)\n\t}\n}", "CodeBleu_score": 56.34152090810556}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNodes(serverId, pathList)\n\t}\n\tcatch (Exception e) {\n\t\tlog.error(\"Error deleting node: ${e.message}\", e)\n\t\tthrow new IllegalStateException(\"Error deleting node: ${e.message}\", e)\n\t}\n}", "CodeBleu_score": 57.60085199954725}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\t\tPlatform.runLater(new Runnable() {\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tTreeItem<Server> serverTreeItem = getTreeItem(id);\n\t\t\tif (serverTreeItem!= null) {\n\t\t\t\tServer server = serverTreeItem.getValue();\n\t\t\t\tserver.disconnect();\n\t\t\t\tremove(serverTreeItem);\n\t\t\t}\n\t\t}\n\t});\n}", "CodeBleu_score": 33.83740279924899}, {"code": "public void disconnect(String id){\n\t\tPlatform.runLater(() -> {\n\t\tTreeItem<Server> server = serverCache.get(id);\n\t\tif (server!= null) {\n\t\t\tserver.getValue().disconnect();\n\t\t\tserverCache.remove(id);\n\t\t}\n\t});\n}", "CodeBleu_score": 38.031429859909466}, {"code": "public void disconnect(String id){\n\t\tPlatform.runLater(() -> {\n\t\tTreeItem<Server> item = getServer(id);\n\t\tServer server = item.getValue();\n\t\tserver.disconnect();\n\t\tservers.remove(item);\n\t});\n}", "CodeBleu_score": 42.03581456218449}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tServerConfiguration serverConfiguration = serverConfigurationService.getServerConfiguration(serverId);\n\tString connectionUrl = getConnectionUrl(serverConfiguration);\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 24.800512257434516}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tServer server = serverRepository.findById(serverId).orElseThrow(() -> new ServerNotFoundException(serverId));\n\tString connectionUrl = getConnectionUrl(server);\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 29.811229167738652}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tServerConfig serverConfig = getServerConfig(serverId);\n\tString connectionUrl = getConnectionUrl(serverConfig);\n\treturn zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 19.366940569265157}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tservers.get(id).execute(command);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Failed to execute command: \" + command + \" on server: \" + id, e);\n\t\tSystem.out.println(\"Failed to execute command: \" + command + \" on server: \" + id);\n\t}\n}", "CodeBleu_score": 46.510644022304824}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tZooKeeper zooKeeper = zooKeeperMap.get(id);\n\t\tzooKeeper.executeCommand(command);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error executing command {} on server {}\", command, id);\n\t\tSystem.out.println(\"Error executing command \" + command + \" on server \" + id + \". Please retry.\");\n\t}\n}", "CodeBleu_score": 39.83573674262022}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tzk.execute(id, command);\n\t} catch (Exception e) {\n\t\tlog.error(\"Error executing command {} on server {}\", command, id);\n\t\tSystem.out.println(\"Error executing command \" + command + \" on server \" + id + \". Please retry.\");\n\t}\n}", "CodeBleu_score": 52.968353855006335}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties props = new Properties();\n\tFile file = new File(ZOOKEEPER_SYSTEM_PROPERTIES_FILE);\n\tif (file.exists()) {\n\t\ttry (InputStream is = new FileInputStream(file)) {\n\t\t\tprops.load(is);\n\t\t\tlog.info(\"Loaded Zookeeper system properties from {}\", file);\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Failed to load Zookeeper system properties from {}\", file, e);\n\t\t}\n\t} else {\n\t\tlog.error(\"Zookeeper system properties file {} does not exist\", file);\n\t}\n\treturn props;\n}", "CodeBleu_score": 44.80381929148965}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tString filePath = System.getProperty(\"zookeeper.properties.file\");\n\tProperties props = new Properties();\n\tif (filePath!= null &&!filePath.isEmpty()) {\n\t\tFile file = new File(filePath);\n\t\tif (file.exists()) {\n\t\t\ttry {\n\t\t\t\tprops.load(new FileInputStream(file));\n\t\t\t\tlog.info(\"Loaded Zookeeper system properties from file: {}\", filePath);\n\t\t\t\treturn props;\n\t\t\t} catch (IOException e) {\n\t\t\t\tlog.error(\"Failed to load Zookeeper system properties from file: {}\", filePath, e);\n\t\t\t}\n\t\t} else {\n\t\t\tlog.error(\"Zookeeper system properties file does not exist: {}\", filePath);\n\t\t}\n\t}\n\treturn props;\n}", "CodeBleu_score": 41.24178034778705}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties props = new Properties();\n\tString zookeeperPropertiesFile = System.getProperty(\"zookeeper.properties.file\");\n\tif (zookeeperPropertiesFile == null) {\n\t\tzookeeperPropertiesFile = \"zookeeper.properties\";\n\t}\n\tFile file = new File(zookeeperPropertiesFile);\n\tif (file.exists()) {\n\t\ttry (InputStream inputStream = new FileInputStream(file)) {\n\t\t\tprops.load(inputStream);\n\t\t\tLOG.info(\"Loaded zookeeper properties from {}\", file);\n\t\t} catch (IOException e) {\n\t\t\tLOG.error(\"Unable to load zookeeper properties from {}\", file, e);\n\t\t}\n\t} else {\n\t\tLOG.error(\"Unable to find zookeeper properties file {}\", file);\n\t}\n\treturn props;\n}", "CodeBleu_score": 39.633767154181385}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\t\tProperties props = new Properties();\n\ttry {\n\t\tprops.load(new StringReader(content));\n\t} catch (IOException e) {\n\t\tlog.error(\"Error loading properties from content.\", e);\n\t\tshowNotification(\"Error loading properties from content.\", NotificationType.ERROR);\n\t\treturn;\n\t}\n\ttry {\n\t\tprops.store(new OutputStreamWriter(new FileOutputStream(SYS_PROP_PATH), \"UTF-8\"), \"Zookeeper system properties\");\n\t} catch (IOException e) {\n\t\tlog.error(\"Error saving properties to file.\", e);\n\t\tshowNotification(\"Error saving properties to file.\", NotificationType.ERROR);\n\t\treturn;\n\t}\n}", "CodeBleu_score": 31.654860246707717}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\tProperties props = new Properties();\n\ttry {\n\t\tprops.load(new StringReader(content));\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error loading properties from content\", e);\n\t\tshowNotification(\"Error loading properties from content\", NotificationType.ERROR);\n\t\treturn;\n\t}\n\n\ttry {\n\t\tprops.store(new FileOutputStream(SYS_PROP_PATH), \"Zookeeper System Properties\");\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error saving properties to file\", e);\n\t\tshowNotification(\"Error saving properties to file\", NotificationType.ERROR);\n\t}\n}", "CodeBleu_score": 30.808795600453365}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\tProperties props = new Properties();\n\ttry {\n\t\tprops.load(new StringReader(content));\n\t} catch (IOException e) {\n\t\tlog.error(\"Failed to load Zookeeper system properties from content\", e);\n\t\tshowNotification(\"Failed to load Zookeeper system properties from content\", NotificationType.ERROR);\n\t\treturn;\n\t}\n\ttry {\n\t\tprops.store(newOutputStream(new File(SYS_PROP_PATH)), null);\n\t} catch (IOException e) {\n\t\tlog.error(\"Failed to save Zookeeper system properties\", e);\n\t\tshowNotification(\"Failed to save Zookeeper system properties\", NotificationType.ERROR);\n\t}\n}", "CodeBleu_score": 32.055393237090776}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\t\tBufferedReader reader = null\n\ttry {\n\t\treader = new BufferedReader(new InputStreamReader(client.getInputStream()))\n\t\tStringBuilder response = new StringBuilder()\n\t\tString line = null\n\t\twhile ((line = reader.readLine())!= null) {\n\t\t\tresponse.append(line)\n\t\t}\n\t\treturn response.toString()\n\t} finally {\n\t\tcleanup(reader, client)\n\t}\n}", "CodeBleu_score": 43.20445143099854}, {"code": "private String response(Socket client){\n\t\ttry {\n\t\tBufferedReader reader = new BufferedReader(new InputStreamReader(client.getInputStream()))\n\t\tStringBuilder response = new StringBuilder()\n\t\tString line\n\t\twhile ((line = reader.readLine())!= null) {\n\t\t\tresponse.append(line)\n\t\t}\n\t\tcleanup(client)\n\t\treturn response.toString()\n\t} catch (Exception e) {\n\t\tthrow new IllegalStateException(e)\n\t}\n}", "CodeBleu_score": 48.288542903550265}, {"code": "private String response(Socket client){\n\t\tBufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()))\n\tStringBuilder sb = new StringBuilder()\n\tString line\n\twhile ((line = in.readLine())!= null) {\n\t\tsb.append(line)\n\t}\n\tin.close()\n\tclient.close()\n\treturn sb.toString()\n}", "CodeBleu_score": 35.213327316144685}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(params.connectionString, params.sessionTimeout, params.connectionTimeout, new RetryNTimes(params.retryCount, params.retryInterval));\n\tcuratorFramework.start();\n\tif (!curatorFramework.blockUntilConnected(5, TimeUnit.SECONDS)) {\n\t\tcuratorFramework.close();\n\t\tthrow new RuntimeException(\"Unable to connect to Zookeeper.\");\n\t}\n\treturn new CuratorZookeeperConnection(params, curatorFramework);\n}", "CodeBleu_score": 42.67659924492858}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\tdef client = CuratorFrameworkFactory.newClient(params.connectionString, params.sessionTimeoutMs, params.connectionTimeoutMs, params.retryPolicy)\n\tclient.start()\n\ttry {\n\t\tclient.blockUntilConnected(5, TimeUnit.SECONDS)\n\t} catch (Exception e) {\n\t\tclient.close()\n\t\tthrow e\n\t}\n\treturn new CuratorZookeeperConnection(client, params.connectionString)\n}", "CodeBleu_score": 37.64477713916885}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(params.connectionString, params.sessionTimeout, params.connectionTimeout, new RetryNTimes(params.retryPolicy.retryTimes, params.retryPolicy.retryInterval));\n\tcuratorFramework.start();\n\tif (!curatorFramework.blockUntilConnected(5, TimeUnit.SECONDS)) {\n\t\tcuratorFramework.close();\n\t\tthrow new IllegalStateException(\"Failed to connect to Zookeeper.\");\n\t}\n\treturn new CuratorZookeeperConnection(curatorFramework, params.connectionString, params.sessionTimeout, params.connectionTimeout, params.retryPolicy);\n}", "CodeBleu_score": 40.747376134886224}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\tString connectionString = getZookeeperClient().getCurrentConnectionString();\n\tif (!syncInProgress.getAndSet(true)) {\n\t\tlog.debug(\"Starting synchronization for connection string {}\", connectionString);\n\t\ttry {\n\t\t\tfor (ZookeeperNodeListener listener : listeners) {\n\t\t\t\ttreeCache.getListenable().addListener(listener);\n\t\t\t}\n\t\t\ttreeCache.start();\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Failed to start synchronization for connection string {}\", connectionString, e);\n\t\t\tclose();\n\t\t}\n\t} else {\n\t\tlog.info(\"Synchronization already in progress for connection string {}\", connectionString);\n\t}\n}", "CodeBleu_score": 46.09558370850606}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\ttry {\n\t\tString currentConnectionString = zookeeperClient.getCurrentConnectionString();\n\t\tif (currentConnectionString == null) {\n\t\t\treturn;\n\t\t}\n\t\tif (syncInProgress.compareAndSet(false, true)) {\n\t\t\tlog.debug(\"Starting synchronization process for {}.\", currentConnectionString);\n\t\t\ttreeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n\t\t\ttry {\n\t\t\t\ttreeCache.start();\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.error(\"Error while starting tree cache.\", e);\n\t\t\t\tcloseTreeCache();\n\t\t\t}\n\t\t} else {\n\t\t\tlog.info(\"Synchronization already in progress for {}.\", currentConnectionString);\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(\"Error while starting synchronization.\", e);\n\t}\n}", "CodeBleu_score": 38.9065095241462}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\tString connectionString = zookeeperClient.getCurrentConnectionString();\n\tif (connectionString == null) {\n\t\tlog.error(\"Zookeeper connection string is null\");\n\t\treturn;\n\t}\n\n\tif (treeCache!= null) {\n\t\tlog.info(\"Zookeeper node synchronization is already in progress\");\n\t\treturn;\n\t}\n\n\tlog.debug(\"Starting Zookeeper node synchronization\");\n\n\ttreeCache = new TreeCache(zookeeperClient, connectionString);\n\ttreeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n\n\ttry {\n\t\ttreeCache.start();\n\t} catch (Exception e) {\n\t\tlog.error(\"Error starting Zookeeper node synchronization\", e);\n\t\tclose();\n\t}\n}", "CodeBleu_score": 43.128683561988865}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.61037577866037}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.61037577866037}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.61037577866037}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t\tlogger.info(\"Unregistering service\");\n\tfor (String path : paths) {\n\t\ttry {\n\t\t\tclient.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(e.getMessage());\n\t\t}\n\t}\n\tclient.close();\n}", "CodeBleu_score": 50.18241684318189}, {"code": "public void unregisterService(){\n\t\tlog.info(\"unregistering all services\")\n\ttry {\n\t\tfor (String path : servicePaths) {\n\t\t\ttry {\n\t\t\t\tclient.delete().forPath(path)\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.error(\"error unregistering service: ${e.message}\")\n\t\t\t}\n\t\t}\n\t} finally {\n\t\tclient.close()\n\t}\n}", "CodeBleu_score": 46.54493520848991}, {"code": "public void unregisterService(){\n\t\tlog.info(\"unregisterService start\");\n\tfor (String path : paths) {\n\t\ttry {\n\t\t\tclient.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"unregisterService error\", e);\n\t\t}\n\t}\n\tclient.close();\n}", "CodeBleu_score": 46.20868291756236}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\t\tCompletableFuture.runAsync(() -> {\n\t\tmakeClientReady();\n\t\tsubscribeStateChanges(listener);\n\t}).exceptionally(e -> {\n\t\tlog.error(\"Error while adding listener: \" + listener, e);\n\t\treturn null;\n\t});\n}", "CodeBleu_score": 24.270759007023205}, {"code": "public void addListener(IZkStateListener listener){\n\t\tCompletableFuture.runAsync(() -> {\n\t\ttry {\n\t\t\tmakeClientReady();\n\t\t\tclient.subscribeStateChanges(listener);\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Error subscribing state listener\", e);\n\t\t}\n\t});\n}", "CodeBleu_score": 28.16351328963519}, {"code": "public void addListener(IZkStateListener listener){\n\t\tCompletableFuture.runAsync(() -> makeClientReady())\n\t\t.thenRun(() -> subscribeStateChanges(listener))\n\t\t.exceptionally(e -> {\n\t\t\tlog.error(\"Error adding listener\", e);\n\t\t\treturn null;\n\t\t});\n}", "CodeBleu_score": 16.65430196138415}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\t// TODO - implement CuratorZookeeperClient.CuratorZookeeperClient\n\tthrow new UnsupportedOperationException();\n}", "CodeBleu_score": 4.972945214706567}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis.serverAddr = serverAddr\n\tthis.authority = authority\n\tthis.retryPolicy = new ExponentialBackoffRetry(1000, 3)\n\tthis.connectionTimeoutMs = 15000\n\tthis.stateChanged = { CuratorFramework client, ConnectionState newState ->\n\t\tswitch (newState) {\n\t\t\tcase ConnectionState.LOST:\n\t\t\t\tlog.error(\"Connection to Zookeeper lost.\")\n\t\t\t\tbreak\n\t\t\tcase ConnectionState.CONNECTED:\n\t\t\t\tlog.info(\"Connected to Zookeeper.\")\n\t\t\t\tbreak\n\t\t\tcase ConnectionState.RECONNECTED:\n\t\t\t\tlog.info(\"Reconnected to Zookeeper.\")\n\t\t\t\tbreak\n\t\t}\n\t}\n\n\tthis.client = CuratorFrameworkFactory.builder()\n\t\t.connectString(serverAddr)\n\t\t.retryPolicy(retryPolicy)\n\t\t.connectionTimeoutMs(connectionTimeoutMs)\n\t\t.authorization(\"digest\", authority.getBytes())\n\t\t.build()\n\n\tclient.connectionStateListenable.addListener(stateChanged)\n\n\ttry {\n\t\tclient.start()\n\t} catch (Exception e) {\n\t\tthrow new IllegalStateException(\"Failed to initialize CuratorZookeeperClient.\", e)\n\t}\n}", "CodeBleu_score": 37.71137852568909}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis.serverAddr = serverAddr;\n\tthis.authority = authority;\n\n\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n\tclient = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(serverAddr)\n\t\t\t.retryPolicy(retryPolicy)\n\t\t\t.connectionTimeoutMs(10000)\n\t\t\t.build();\n\n\tif (authority!= null) {\n\t\tclient.addAuthInfo(\"digest\", authority.getBytes());\n\t}\n\n\tclient.getConnectionStateListenable().addListener(this);\n\n\tclient.start();\n\n\tif (client.getState()!= CuratorFrameworkState.STARTED) {\n\t\tthrow new IllegalStateException(\"Zookeeper client failed to start\");\n\t}\n}", "CodeBleu_score": 29.439818804726634}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t\t// get the map of listeners for the path\n\tMap<ChildListener, TargetChildListener> listeners = childListenerMap.get(path);\n\tif (listeners!= null) {\n\t\t// get the listener to remove\n\t\tTargetChildListener targetListener = listeners.get(listener);\n\t\tif (targetListener!= null) {\n\t\t\t// remove the listener\n\t\t\tlisteners.remove(listener);\n\t\t\t// remove the corresponding target listener\n\t\t\ttargetChildListenerMap.remove(targetListener);\n\t\t}\n\t}\n}", "CodeBleu_score": 58.3335151552408}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\t// Remove the listener from the listeners map\n\tMap<ChildListener, TargetChildListener> listeners = childListeners.get(path);\n\tif (listeners!= null) {\n\t\tTargetChildListener targetListener = listeners.remove(listener);\n\t\tif (targetListener!= null) {\n\t\t\t// Remove the corresponding TargetChildListener\n\t\t\ttargetChildListeners.remove(path, targetListener);\n\t\t}\n\t}\n}", "CodeBleu_score": 66.54444742774871}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\t// TODO Auto-generated method stub\n\tif (path == null || listener == null) {\n\t\tthrow new IllegalArgumentException(\"Path or listener is null\");\n\t}\n\tif (path.equals(\"\")) {\n\t\tthrow new IllegalArgumentException(\"Path is empty\");\n\t}\n\tif (path.contains(\"/.\")) {\n\t\tthrow new IllegalArgumentException(\"Path contains /.\");\n\t}\n\tif (path.contains(\"/$\")) {\n\t\tthrow new IllegalArgumentException(\"Path contains /$\");\n\t}\n\tif (path.contains(\"//\")) {\n\t\tthrow new IllegalArgumentException(\"Path contains //\");\n\t}\n\tif (path.contains(\"\\u0000\")) {\n\t\tthrow new IllegalArgumentException(\"Path contains null character\");\n\t}\n\tChildListenerWrapper wrapper = new ChildListenerWrapper(listener);\n\tsynchronized (this.listeners) {\n\t\tMap<ChildListenerWrapper, ChildListener> childListeners = this.listeners.get(path);\n\t\tif (childListeners == null) {\n\t\t\treturn;\n\t\t}\n\t\tchildListeners.remove(wrapper);\n\t\tif (childListeners.isEmpty()) {\n\t\t\tthis.listeners.remove(path);\n\t\t}\n\t\tif (this.targetListeners.containsKey(path)) {\n\t\t\tthis.targetListeners.remove(path);\n\t\t}\n\t}\n}", "CodeBleu_score": 38.0452337202874}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (!zh) {\n\t\tLOG_ERR(\"zh is null\");\n\t\treturn ZOO_SYSTEMERROR;\n\t}\n\n\t// Retrieve and delete the IDC host information associated with the handle\n\tstd::string idc_host;\n\tif (lock_ht_find(zh, &idc_host)!= 0) {\n\t\tLOG_ERR(\"Could not find idc_host in lock_ht\");\n\t\treturn ZOO_SYSTEMERROR;\n\t}\n\tlock_ht_delete(zh);\n\n\t// Close the old handle\n\tzookeeper_close(zh);\n\n\t// Deserialize the IDC and host information and initialize a new ZooKeeper handle with this information\n\tstd::string idc;\n\tstd::string host;\n\tdeserialize_from_idc_host(idc_host, &idc, &host);\n\tzhandle_t *new_zh = zookeeper_init(host.c_str(), watcher, 10000, 0, 0, 0);\n\tif (!new_zh) {\n\t\tLOG_ERR(\"Could not initialize new ZooKeeper handle\");\n\t\treturn ZOO_SYSTEMERROR;\n\t}\n\n\t// Initialize the environment for the new handle and reset the table watcher\n\tinit_env_for_zk(new_zh, idc);\n\tif (reset_table_watcher(new_zh)!= 0) {\n\t\tLOG_ERR(\"Could not reset table watcher\");\n\t\treturn ZOO_SYSTEMERROR;\n\t}\n\n\treturn ZOO_OK;\n}", "CodeBleu_score": 29.46294302427489}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (zh == NULL) {\n\t\treturn ZOO_ERR_INVALID_STATE;\n\t}\n\tstd::string idc_host;\n\tif (lock_ht_find(zh, idc_host)!= 0) {\n\t\treturn ZOO_ERR_INVALID_STATE;\n\t}\n\tif (lock_ht_delete(zh)!= 0) {\n\t\treturn ZOO_ERR_INVALID_STATE;\n\t}\n\tzookeeper_close(zh);\n\tstd::string idc;\n\tstd::string host;\n\tdeserialize_from_idc_host(idc_host, idc, host);\n\tzh = zookeeper_init(host.c_str(), watcher_global, 30000, 0, 0, 0);\n\tif (zh == NULL) {\n\t\tLOG_ERR(\"Failed to initialize zookeeper handle\");\n\t\treturn ZOO_ERR_INVALID_STATE;\n\t}\n\tif (init_env_for_zk(zh, idc)!= 0) {\n\t\tLOG_ERR(\"Failed to initialize environment for zookeeper handle\");\n\t\treturn ZOO_ERR_INVALID_STATE;\n\t}\n\tif (reset_table_watcher(zh)!= 0) {\n\t\tLOG_ERR(\"Failed to reset table watcher\");\n\t\treturn ZOO_ERR_INVALID_STATE;\n\t}\n\treturn ZOO_OK;\n}", "CodeBleu_score": 33.61126500893225}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (zh == NULL) {\n\t\treturn ZOO_SYSTEMERROR;\n\t}\n\tstd::string idc_host;\n\tif (lock_ht_find(zh, &idc_host)!= 0) {\n\t\treturn ZOO_SYSTEMERROR;\n\t}\n\tlock_ht_delete(zh);\n\tzookeeper_close(zh);\n\tstd::string idc;\n\tstd::string host;\n\tif (deserialize_from_idc_host(idc_host, &idc, &host)!= 0) {\n\t\treturn ZOO_SYSTEMERROR;\n\t}\n\tzh = zookeeper_init(host.c_str(), watcher, 30000, 0, 0, 0);\n\tif (zh == NULL) {\n\t\treturn ZOO_SYSTEMERROR;\n\t}\n\tif (init_env_for_zk(zh, idc)!= 0) {\n\t\treturn ZOO_SYSTEMERROR;\n\t}\n\tif (set_table_watcher(zh, reinterpret_cast<unsigned long>(zh))!= 0) {\n\t\treturn ZOO_SYSTEMERROR;\n\t}\n\treturn ZOO_OK;\n}", "CodeBleu_score": 25.355233677501822}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\tif (zh == NULL) {\n\t\tLOG_FATAL_ERR(\"Zookeeper handle is NULL\");\n\t\texit(EXIT_FAILURE);\n\t}\n\n\t// Update internal tables with the handle and host information\n\tzk_ht_update(zh, idc_host);\n\tzk_host_ht_update(idc_host, idc);\n\n\t// Check the connection state of the Zookeeper handle\n\tint state = zoo_state(zh);\n\tif (state!= ZOO_CONNECTED_STATE) {\n\t\tLOG_FATAL_ERR(\"Zookeeper handle is not connected\");\n\t\texit(EXIT_FAILURE);\n\t}\n\n\t// Register the current host on the Zookeeper server\n\tint rc = zk_register_ephemeral(zh, idc_host);\n\tif (rc!= ZOK) {\n\t\tLOG_FATAL_ERR(\"Failed to register host on Zookeeper server: %s\", zerror(rc));\n\t\texit(EXIT_FAILURE);\n\t}\n\n\t// Set a watcher on the notify node\n\trc = watch_notify_node(zh);\n\tif (rc!= ZOK) {\n\t\tLOG_FATAL_ERR(\"Failed to set watcher on notify node: %s\", zerror(rc));\n\t\texit(EXIT_FAILURE);\n\t}\n\n\t// Depending on the result of setting the watcher, add the IDC to a gray list or log an error\n\tif (rc == ZNONODE) {\n\t\tLOG_INFO(\"Notify node does not exist yet, adding %s to gray list\", idc.c_str());\n\t\tadd_gray_idc(idc);\n\t} else if (rc!= ZOK) {\n\t\tLOG_FATAL_ERR(\"Failed to set watcher on notify node: %s\", zerror(rc));\n\t\texit(EXIT_FAILURE);\n\t}\n}", "CodeBleu_score": 49.24214642136995}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\tif (zh == NULL) {\n\t\tLOG_FATAL_ERR(\"NULL handle\");\n\t\treturn;\n\t}\n\tif (idc_host.empty() || idc.empty()) {\n\t\tLOG_FATAL_ERR(\"empty host or idc\");\n\t\treturn;\n\t}\n\tif (zoo_state(zh)!= ZOO_CONNECTED_STATE) {\n\t\tLOG_FATAL_ERR(\"not connected\");\n\t\treturn;\n\t}\n\tif (zk_register_ephemeral(zh, idc_host)!= 0) {\n\t\tLOG_FATAL_ERR(\"failed to register host\");\n\t\treturn;\n\t}\n\tif (watch_notify_node(zh)!= 0) {\n\t\tLOG_FATAL_ERR(\"failed to watch notify node\");\n\t\treturn;\n\t}\n\tif (add_gray_idc(idc)!= 0) {\n\t\tLOG_FATAL_ERR(\"failed to add gray idc\");\n\t\treturn;\n\t}\n\tLOG_INFO(\"init env for zk success\");\n}", "CodeBleu_score": 34.91156537941477}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\tif (!zh) {\n\t\tLOG_FATAL_ERR(\"zh is null\");\n\t\treturn;\n\t}\n\tif (idc_host.empty()) {\n\t\tLOG_FATAL_ERR(\"idc_host is empty\");\n\t\treturn;\n\t}\n\tif (idc.empty()) {\n\t\tLOG_FATAL_ERR(\"idc is empty\");\n\t\treturn;\n\t}\n\tif (zoo_state(zh)!= ZOO_CONNECTED_STATE) {\n\t\tLOG_INFO(\"zoo_state is not ZOO_CONNECTED_STATE\");\n\t\treturn;\n\t}\n\tif (zk_register_ephemeral(zh, idc_host, idc)) {\n\t\tLOG_INFO(\"zk_register_ephemeral failed\");\n\t\treturn;\n\t}\n\tif (watch_notify_node(zh)) {\n\t\tLOG_FATAL_ERR(\"watch_notify_node failed\");\n\t\tadd_gray_idc(idc);\n\t\treturn;\n\t}\n}", "CodeBleu_score": 38.670710454219495}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode() + b\":\" + username.encode() + b\":\" + password.encode()).digest()\n    return username + \":\" + b64encode(cred_hash).decode().strip()\n", "CodeBleu_score": 36.66621936760511}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode() + b\":\" + username.encode() + b\":\" + password.encode()).digest()\n    return username + \":\" + b64encode(cred_hash).decode().strip()", "CodeBleu_score": 36.66621936760511}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode() + b':' + username.encode() + b':' + password.encode()).digest()\n    return username + \":\" + b64encode(cred_hash).decode().strip()\n\n", "CodeBleu_score": 34.75722376970498}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if not self.pe:\n        return False\n    lock_path = self.get_lock_path()\n    self.zk.sync(lock_path)\n    lock_value = self.zk.get(lock_path)[0]\n    if lock_value == self.pe.id:\n        return True\n    return False\n\n", "CodeBleu_score": 33.324765207018125}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_path = self.get_lock_path()\n    self.zk.sync(lock_path)\n    lock_value = self.zk.get(lock_path)[0]\n    return lock_value == self.processing_element.id\n\n", "CodeBleu_score": 42.24833917418174}, {"code": "def holds_lock(self)\n\t\n    if self.pe is None:\n        return False\n    lock_path = self.get_lock_path()\n    self.zk.sync(lock_path)\n    lock_value = self.zk.get(lock_path)[0]\n    return lock_value == self.pe.id\n\n", "CodeBleu_score": 35.79971329206122}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    if not self.holds_lock:\n        return False\n    transaction = self.db.transaction()\n    transaction.delete(self.processing_element)\n    self.processing_element = None\n    transaction.commit()\n    return True\n\n", "CodeBleu_score": 29.359126630040333}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    if not self.holds_lock:\n        return False\n    transaction = self.database.transaction()\n    transaction.delete(self.processing_element)\n    self.processing_element = None\n    transaction.commit()\n    return True\n\n", "CodeBleu_score": 29.613011123444334}, {"code": "def consume(self)\n\t\n    if self.processing_element is not None:\n        if self.holds_lock:\n            self.delete()\n            return True\n    return False\n\n", "CodeBleu_score": 14.119299574535502}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header = await self._read_header(read_timeout)\n    except (ConnectionResetError, TimeoutError) as e:\n        self._log.debug(\"Connection reset: %s\", e)\n        raise\n    except asyncio.CancelledError:\n        raise\n    except Exception as e:\n        self._log.debug(\"Error reading header: %s\", e)\n        raise\n    if header.xid == PING_XID:\n        self._log.debug(\"Received ping\")\n        self._outstanding_ping = False\n        return\n    if header.xid == AUTH_XID:\n        if header.err!= 0:\n            self._log.debug(\"Authentication failed: %s\", header.err)\n            self._session_callback.set_exception(AuthFailedError(header.err))\n        else:\n            self._log.debug(\"Authentication succeeded\")\n            self._session_callback.set()\n        return\n    if header.xid == WATCH_XID:\n        await self._read_watch_event(header)\n        return\n    self._log.debug(\"Received header: %s\", header)\n    try:\n        await self._read_response(header)\n    except Exception as e:\n        self._log.debug(\"Error reading response: %s\", e)\n        raise\n\n", "CodeBleu_score": 40.166876532091514}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header = await self._read_header(read_timeout)\n    except Exception as e:\n        log.debug(\"Error reading header: %s\", e)\n        self._read_response(None)\n        return\n    if header.xid == PING_XID:\n        log.debug(\"Received ping\")\n        self._outstanding_ping = False\n    elif header.xid == AUTH_XID:\n        try:\n            await self._read_auth_response(header)\n        except Exception as e:\n            log.debug(\"Error reading auth response: %s\", e)\n            self._read_response(None)\n            return\n    elif header.xid == WATCH_XID:\n        try:\n            await self._read_watch_event(header)\n        except Exception as e:\n            log.debug(\"Error reading watch event: %s\", e)\n            self._read_response(None)\n            return\n    else:\n        log.debug(\"Received header: %s\", header)\n        try:\n            await self._read_response(header)\n        except Exception as e:\n            log.debug(\"Error reading response: %s\", e)\n            self._read_response(None)\n            return\n\n", "CodeBleu_score": 38.46759562773229}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header = await self._read_header(read_timeout)\n        if header.xid == PING_XID:\n            self.logger.debug(\"Received ping response\")\n            self._outstanding_ping = False\n        elif header.xid == AUTH_XID:\n            auth_response = await self._read_auth_response(header)\n            if auth_response.type == AuthFailedResponse.type:\n                self.logger.debug(\"Authentication failed\")\n                self.set_exception(AuthFailedError())\n            else:\n                self.logger.debug(\"Authentication successful\")\n                self.set_result(None)\n        elif header.xid == WATCH_XID:\n            await self._read_watch_event(header)\n        else:\n            self.logger.debug(\"Received header: %s\", header)\n            await self._read_response(header)\n    except Exception as e:\n        self.logger.debug(\"Exception reading socket: %s\", e)\n        self.set_exception(e)\n\n", "CodeBleu_score": 39.51348030230481}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.log.info(\"Starting Zookeeper connection loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.retry.retry(self.client.connect)\n        except Exception as e:\n            self.log.warning(\"Connection to Zookeeper failed: %s\", e)\n        else:\n            self.log.info(\"Connected to Zookeeper\")\n            self.connection_stopped.wait()\n            self.log.info(\"Disconnected from Zookeeper\")\n    self.log.info(\"Stopping Zookeeper connection loop\")\n    self.set_connection_state(ConnectionState.CLOSED)\n    self.connection_stopped.set()\n\n", "CodeBleu_score": 43.63468563612362}, {"code": "def zk_loop(self)\n\t\n    self._log.info('Starting Zookeeper connection loop')\n    self.connection_stopped.clear()\n    while not self.client_stopped.is_set():\n        try:\n            self._log.info('Connecting to Zookeeper')\n            self.retry.reset()\n            self.client.start(self.retry)\n            self._log.info('Connected to Zookeeper')\n            self.connection_stopped.wait()\n        except Exception as e:\n            self._log.warning('Connection to Zookeeper failed: %s', e)\n\n    self._log.info('Stopping Zookeeper connection loop')\n    self.connection_stopped.set()\n    self.session_callback(KazooState.LOST)\n\n", "CodeBleu_score": 44.461651191254454}, {"code": "def zk_loop(self)\n\t\n    self.log.info(\"Starting Zookeeper loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.retry()\n        except Exception as e:\n            self.log.warning(\"Failed to connect to Zookeeper: %s\", e)\n        if not self.stopped.is_set():\n            self.connection_stopped.wait()\n    self.log.info(\"Stopping Zookeeper loop\")\n    self.set_state(State.CLOSED)\n    self.log.info(\"Zookeeper loop stopped\")\n\n", "CodeBleu_score": 37.31730569998943}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    partitions = sorted(partitions)\n    members = sorted(members)\n    index = members.index(identifier)\n    return [partitions[i] for i in range(index, len(partitions), len(members))]\n\n", "CodeBleu_score": 37.61297411761076}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_partitions = sorted(partitions)\n    sorted_members = sorted(members)\n    index = sorted_members.index(identifier)\n    return [sorted_partitions[i] for i in range(index, len(sorted_partitions), len(sorted_members))]\n\n", "CodeBleu_score": 33.809514542699596}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    partitions = sorted(partitions)\n    members = sorted(members)\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 39.65957835883439}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    if not self._participating:\n        return\n    self._participating = False\n    try:\n        self._leave()\n    except:\n        self._best_effort_cleanup\n        raise\n    else:\n        return\n\n", "CodeBleu_score": 37.27017424604429}, {"code": "def leave(self)\n\t\n    self.logger.debug(\"Entering leave\")\n    self._participating = False\n    self._best_effort_cleanup()\n    self._leave()\n    self.logger.debug(\"Leaving leave\")\n\n", "CodeBleu_score": 50.07227778144105}, {"code": "def leave(self)\n\t\n    if self._participating:\n        self._leave()\n    self._participating = False\n\n", "CodeBleu_score": 30.525778512405882}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t\tdef status = status()\n\tif (status.success) {\n\t\tif (status.data.serverStatus == \"RUNNING\") {\n\t\t\treturn new Result(true, \"Server is already running.\")\n\t\t}\n\t}\n\ttry {\n\t\tstartServer()\n\t\treturn new Result(true, \"Server started successfully.\")\n\t} catch (Exception e) {\n\t\treturn new Result(false, \"Error starting server: \" + e.getMessage())\n\t}\n}", "CodeBleu_score": 32.899328149908236}, {"code": "public Result start(){\n\t\tif (status() == \"running\") {\n\t\treturn new Result(true);\n\t}\n\ttry {\n\t\tserver.start();\n\t\treturn new Result(true);\n\t} catch (Exception e) {\n\t\treturn new Result(false, e);\n\t}\n}", "CodeBleu_score": 20.553851691116876}, {"code": "public Result start(){\n\t\tif (!status().isSuccess()) {\n\t\treturn startServer();\n\t} else {\n\t\treturn new Result(true, \"Server already running\");\n\t}\n}", "CodeBleu_score": 11.70368671474669}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t\tif (server.isServerRunning()) {\n\t\ttry {\n\t\t\tserver.stop();\n\t\t\treturn new SuccessResult(\"Server stopped successfully\");\n\t\t} catch (Exception e) {\n\t\t\tlogger.log(Level.SEVERE, \"Error stopping server\", e);\n\t\t\treturn new FailureResult(\"Error stopping server: \" + e.getMessage());\n\t\t}\n\t}\n\treturn new SuccessResult(\"Server is not running\");\n}", "CodeBleu_score": 22.264751981097692}, {"code": "public Result stop(){\n\t\ttry {\n\t\tif (server.isRunning()) {\n\t\t\tserver.stop()\n\t\t\treturn new Success(\"FTP Server stopped.\")\n\t\t}\n\t\telse {\n\t\t\treturn new Failure(\"FTP Server is not running.\")\n\t\t}\n\t}\n\tcatch (Exception e) {\n\t\tlog.error(\"Error stopping FTP Server.\", e)\n\t\treturn new Failure(\"Error stopping FTP Server.\")\n\t}\n}", "CodeBleu_score": 21.821370574907363}, {"code": "public Result stop(){\n\t\tResult result = new Result();\n\tresult.setStatus(ResultStatus.SUCCESS);\n\tresult.setMessage(\"FTP server stopped\");\n\ttry {\n\t\tif (server.isRunning()) {\n\t\t\tserver.stop();\n\t\t}\n\t} catch (Exception e) {\n\t\tresult.setStatus(ResultStatus.FAILURE);\n\t\tresult.setMessage(\"FTP server could not be stopped\");\n\t\tlogger.error(\"FTP server could not be stopped\", e);\n\t}\n\treturn result;\n}", "CodeBleu_score": 32.863356673546065}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tif (authorities.isEmpty()) {\n\t\treturn null;\n\t}\n\n\tfor (AuthorizationAuthority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\trequest = authority.authorize(request);\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn request;\n}", "CodeBleu_score": 40.34949307603931}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tif (authorities.isEmpty()) {\n\t\treturn null;\n\t}\n\tfor (AuthorizationAuthority authority : authorities) {\n\t\tAuthorizationRequest updatedRequest = authority.authorize(request);\n\t\tif (updatedRequest == null) {\n\t\t\treturn null;\n\t\t}\n\t\trequest = updatedRequest;\n\t}\n\treturn request;\n}", "CodeBleu_score": 34.61235096649056}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tif (authorities == null) {\n\t\treturn null;\n\t}\n\tfor (AuthorizationAuthority authority : authorities) {\n\t\tAuthorizationRequest updatedRequest = authority.authorize(request);\n\t\tif (updatedRequest == null) {\n\t\t\treturn null;\n\t\t}\n\t\trequest = updatedRequest;\n\t}\n\treturn request;\n}", "CodeBleu_score": 36.391838244458164}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t\tFileSystem fs = getDfs();\n\tboolean result = false;\n\ttry {\n\t\tresult = fs.mkdirs(fullPath);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n\treturn result;\n}", "CodeBleu_score": 55.10404586565556}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(new Configuration());\n\t\treturn fs.mkdirs(fullPath);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 69.75267687761257}, {"code": "public boolean mkdir(){\n\t\tFileSystem fs = getDfs();\n\tboolean success = false;\n\ttry {\n\t\tsuccess = fs.mkdirs(fullPath);\n\t} catch (IOException e) {\n\t\tprintStackTrace(e);\n\t}\n\treturn success;\n}", "CodeBleu_score": 49.22813402793679}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t\tFileSystem fs = FileSystem.get(new Configuration());\n\ttry {\n\t\tfs.delete(new Path(fullPath), true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 66.19908490971066}, {"code": "public boolean delete(){\n\t\tFileSystem fs = FileSystem.get(conf);\n\ttry {\n\t\treturn fs.delete(fullPath, true);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 61.398160302898845}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(new Configuration());\n\t\treturn fs.delete(new Path(fullPath), true);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 63.00385054046749}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t\tboolean success = false;\n\ttry {\n\t\tFileSystem fs = getDfs();\n\t\tPath parent = new Path(getParent());\n\t\tPath newPath = new Path(parent, ftpFile.getName());\n\t\tsuccess = fs.rename(new Path(ftpFile.getPath()), newPath);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n\treturn success;\n}", "CodeBleu_score": 42.88689230684681}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = getDfs();\n\t\tPath newPath = new Path(getParent(), ftpFile.getName());\n\t\treturn fs.rename(new Path(ftpFile.getPath()), newPath);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 56.16015724386851}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(conf);\n\t\tPath newPath = new Path(ftpFile.getParent().getPath() + \"/\" + ftpFile.getName());\n\t\treturn fs.rename(new Path(ftpFile.getPath()), newPath);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 58.0001244006727}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileSystem fs = getDfs();\n\t\tFileStatus[] statuses = fs.listStatus(new Path(getAbsolutePath()));\n\t\tList<FtpFile> files = new ArrayList<FtpFile>();\n\t\tfor (FileStatus status : statuses) {\n\t\t\tString name = status.getPath().getName();\n\t\t\tif (name.charAt(0) == '.') {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tfiles.add(new FtpFile(name, status));\n\t\t}\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\tlogger.error(e.getMessage(), e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 29.40963938473491}, {"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileSystem fs = getDfs();\n\t\tFileStatus[] statuses = fs.listStatus(new Path(getPath()));\n\t\tList<FtpFile> files = new ArrayList<FtpFile>();\n\t\tfor (FileStatus status : statuses) {\n\t\t\tString name = status.getPath().getName();\n\t\t\tif (name.charAt(0) == '.') {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tFtpFile file = new FtpFile(name, status.isDirectory());\n\t\t\tfile.setPath(getAbsolutePath() + \"/\" + name);\n\t\t\tfile.setReadable(status.getPermission().toString().charAt(1) == 'r');\n\t\t\tfile.setWritable(status.getPermission().toString().charAt(2) == 'w');\n\t\t\tfile.setExecutable(status.getPermission().toString().charAt(3) == 'x');\n\t\t\tfile.setLastModified(status.getModificationTime());\n\t\t\tfile.setSize(status.getLen());\n\t\t\tfiles.add(file);\n\t\t}\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error listing files\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 34.03619352873716}, {"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\t// Get the HDFS file system instance\n\t\tFileSystem fs = getDfs();\n\t\t// List the status of files in the directory\n\t\tRemoteIterator<LocatedFileStatus> fileStatus = fs.listFiles(new Path(getAbsolutePath()), false);\n\t\t// Create an array of FtpFile objects\n\t\tFtpFile[] files = new FtpFile[0];\n\t\twhile (fileStatus.hasNext()) {\n\t\t\t// Get the next file status\n\t\t\tLocatedFileStatus status = fileStatus.next();\n\t\t\t// Construct the virtual file name based on the base directory's virtual path\n\t\t\tString path = getName() + \"/\" + status.getPath().getName();\n\t\t\t// Create the FtpFile object\n\t\t\tFtpFile file = new FtpFile(path, status.isDirectory());\n\t\t\t// Add the FtpFile object to the array\n\t\t\tfiles = Arrays.copyOf(files, files.length + 1);\n\t\t\tfiles[files.length - 1] = file;\n\t\t}\n\t\t// Return an unmodifiable list of the FtpFile objects\n\t\treturn Collections.unmodifiableList(Arrays.asList(files));\n\t} catch (IOException e) {\n\t\t// Log the error\n\t\tlog.error(\"Error listing files from HDFS directory: \" + getAbsolutePath(), e);\n\t\t// Return null\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 38.02703226035571}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t\tsetConfigurationState(true);\n\tinitializeUserDataProperties();\n\ttry {\n\t\tif (userDataFile.exists()) {\n\t\t\tload();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(userDataFile.getPath(), e);\n\t}\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 20.38710378316879}, {"code": "public void configure(){\n\t\tconfigurationState = true\n\tinitializeUserDataProperties()\n\tFile userDataFile = new File(userDataFilePath)\n\tif (userDataFile.exists()) {\n\t\ttry {\n\t\t\tload(userDataFile)\n\t\t} catch (IOException e) {\n\t\t\tthrow new FtpServerConfigurationException(userDataFile.getAbsolutePath(), e)\n\t\t}\n\t}\n\tconvertDeprecatedPropertyNames()\n}", "CodeBleu_score": 29.900857966276767}, {"code": "public void configure(){\n\t\tif (!configured) {\n\t\tconfigured = true;\n\t\tif (userDataFile!= null) {\n\t\t\tFile file = new File(userDataFile);\n\t\t\tif (file.exists()) {\n\t\t\t\ttry {\n\t\t\t\t\tload(file);\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tthrow new FtpServerConfigurationException(\"Unable to load user data file: \" + userDataFile, e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tconvertDeprecatedPropertyNames();\n\t}\n}", "CodeBleu_score": 33.27145477312001}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\t\tif (!userDataFile.getParentFile().exists()) {\n\t\tif (!userDataFile.getParentFile().mkdirs()) {\n\t\t\tthrow new FtpException(\"Could not create user data directory.\");\n\t\t}\n\t}\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tstore(fos);\n\t} catch (IOException e) {\n\t\tlog.error(\"Error saving user data.\", e);\n\t\tthrow new FtpException(\"Error saving user data.\", e);\n\t} finally {\n\t\tclose(fos);\n\t}\n}", "CodeBleu_score": 40.29235625337624}, {"code": "private void saveUserData() throws FtpException{\n\t\tif (!userDataFile.getParentFile().exists()) {\n\t\tif (!userDataFile.getParentFile().mkdirs()) {\n\t\t\tthrow new FtpException(\"Could not create directory: \" + userDataFile.getParentFile());\n\t\t}\n\t}\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tuserData.store(fos, \"User data\");\n\t} catch (IOException e) {\n\t\tlog.error(\"Could not save user data\", e);\n\t\tthrow new FtpException(\"Could not save user data\", e);\n\t} finally {\n\t\tif (fos!= null) {\n\t\t\ttry {\n\t\t\t\tfos.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tlog.error(\"Could not close user data file\", e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 45.622392357649275}, {"code": "private void saveUserData() throws FtpException{\n\t\tFile userFile = new File(userDir, USER_FILE);\n\tFile parentDir = userFile.getParentFile();\n\tif (!parentDir.exists()) {\n\t\tif (!parentDir.mkdirs()) {\n\t\t\tthrow new ConfigurationException(\"Unable to create user data directory\");\n\t\t}\n\t}\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userFile);\n\t\tuserData.store(fos, null);\n\t} catch (IOException e) {\n\t\tlog.error(\"Unable to save user data\", e);\n\t\tthrow new FtpException(\"Unable to save user data\", e);\n\t} finally {\n\t\tif (fos!= null) {\n\t\t\ttry {\n\t\t\t\tfos.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tlog.error(\"Unable to close user data file\", e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 50.20517067284936}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t\tdef result = new Result()\n\ttry {\n\t\tdef manager = new HdfsUserManager()\n\t\tmanager.file = new File(System.getProperty(\"user.dir\") + \"/users.properties\")\n\t\tmanager.delete(user)\n\t\tresult.success = true\n\t\tresult.message = \"User deleted successfully\"\n\t} catch (Exception e) {\n\t\tlog.error(e)\n\t\tresult.success = false\n\t\tresult.message = \"Error deleting user\"\n\t}\n\treturn result\n}", "CodeBleu_score": 28.100370914134594}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t\tdef result = new Result()\n\ttry {\n\t\tdef users = new HdfsUserManager()\n\t\tusers.setFile(\"users.properties\")\n\t\tif (users.delete(user)) {\n\t\t\tresult.setSuccess(true)\n\t\t\tresult.setMessage(\"User ${user} deleted successfully.\")\n\t\t} else {\n\t\t\tresult.setSuccess(false)\n\t\t\tresult.setMessage(\"User ${user} not found.\")\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(e.message, e)\n\t\tresult.setSuccess(false)\n\t\tresult.setMessage(\"Error deleting user ${user}: ${e.message}\")\n\t}\n\treturn result\n}", "CodeBleu_score": 33.48284079143296}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t\ttry {\n\t\tHdfsUserManager manager = new HdfsUserManager()\n\t\tmanager.setFile(new File(\"users.properties\"))\n\t\tmanager.delete(user)\n\t\treturn new Result(true, \"Successfully deleted user: \" + user)\n\t} catch (Exception e) {\n\t\tlog.error(\"Error deleting user: \" + user, e)\n\t\treturn new Result(false, \"Error deleting user: \" + user)\n\t}\n}", "CodeBleu_score": 46.67485635746674}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tlogDebug(\"Opening \" + path + \" with buffer size \" + bufferSize);\n\tpath = getConf().getFileSystem(path.toUri()).makeQualified(path);\n\tFSDataInputStream in = null;\n\ttry {\n\t\tin = store.open(path, bufferSize);\n\t} catch (IOException e) {\n\t\tlogWarn(\"Got exception while opening \" + path + \", will try to open it directly\", e);\n\t\ttry {\n\t\t\tin = openFileForRead(path, bufferSize);\n\t\t} catch (IOException e2) {\n\t\t\tlogWarn(\"Got exception while opening \" + path + \" directly\", e2);\n\t\t}\n\t}\n\treturn in;\n}", "CodeBleu_score": 38.75582408330557}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.debug(\"Opening \" + path + \" with buffer size \" + bufferSize);\n\tfinal String qualifiedPath = getQualifiedPath(path);\n\tfinal FSDataInputStream in;\n\ttry {\n\t\tin = openFileForRead(qualifiedPath, bufferSize);\n\t} catch (IOException e) {\n\t\tLOG.warn(\"open \" + qualifiedPath + \" failed\", e);\n\t\treturn null;\n\t}\n\treturn in;\n}", "CodeBleu_score": 27.27602902662313}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tString src = path.toString();\n\tLOG.debug(\"Opening \" + src + \" for reading with buffer size \" + bufferSize);\n\tsrc = getConf().get(\"fs.default.name\", \"file:///\") + src;\n\tLOG.debug(\"Qualifying \" + src);\n\tsrc = getConf().get(\"fs.file.impl\", FileContext.class.getName()).split(\"\\\\.\")[0] + \"://\" + src;\n\tLOG.debug(\"Opening \" + src);\n\tFSDataInputStream in = null;\n\ttry {\n\t\tin = store.open(src, bufferSize);\n\t} catch (Exception e) {\n\t\tLOG.warn(\"open \" + src + \" failed\", e);\n\t\treturn null;\n\t}\n\treturn in;\n}", "CodeBleu_score": 36.54995394019446}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\tif (isRoot(src)) {\n\t\treturn false;\n\t}\n\tif (src.equals(dst)) {\n\t\treturn true;\n\t}\n\tFileStatus dstStatus = lookupEntry(dst);\n\tif (dstStatus!= null && dstStatus.isDirectory()) {\n\t\tdst = new Path(dst, src.getName());\n\t}\n\tsrc = qualify(src);\n\tdst = qualify(dst);\n\tLOG.debug(\"Rename {} to {}\", src, dst);\n\treturn store.rename(src, dst);\n}", "CodeBleu_score": 41.15601586548725}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\tNameNode.stateChangeLog.info(\"DIR* NameSystem.rename: \" + src + \" to \" + dst);\n\tif (src.isRoot() || src.equals(dst)) {\n\t\treturn false;\n\t}\n\tINode dstINode = dir.lookupEntry(dst, null);\n\tif (dstINode!= null) {\n\t\tif (dstINode.isDirectory()) {\n\t\t\tdst = dst.suffix(src.getName());\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t}\n\tsrc = dir.qualify(src);\n\tdst = dir.qualify(dst);\n\treturn fsdir.renameTo(src, dst);\n}", "CodeBleu_score": 35.612261726452445}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\tif (LOG.isDebugEnabled()) {\n\t\tLOG.debug(\"rename: \" + src + \" to \" + dst);\n\t}\n\tif (isRoot(src)) {\n\t\treturn false;\n\t}\n\tif (src.equals(dst)) {\n\t\treturn true;\n\t}\n\tFileStatus dstStat = lookupEntry(dst);\n\tif (dstStat!= null) {\n\t\tif (dstStat.isDirectory()) {\n\t\t\tdst = new Path(dst, src.getName());\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t}\n\tsrc = qualify(src);\n\tdst = qualify(dst);\n\treturn store.rename(src, dst);\n}", "CodeBleu_score": 42.712125314941815}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t\treturn (capability.toLowerCase().equals(\"hsync\") && supportSync) || (capability.toLowerCase().equals(\"hflush\") && supportFlush);\n}", "CodeBleu_score": 34.7412825804749}, {"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\")) {\n\t\treturn true;\n\t} else if (capability.toLowerCase().equals(\"hflush\")) {\n\t\treturn supportFlush;\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 28.076992366543013}, {"code": "public boolean hasCapability(String capability){\n\t\treturn false;\n}", "CodeBleu_score": 6.236959909826931}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tfinal long start = System.currentTimeMillis()\n\tfinal long bytesToFlush = offset - lastFlushOffset\n\tfinal long bytesToFlushRemaining = bytesToFlush\n\tfinal long bytesToFlushPerIteration = 1024 * 1024 * 100 // 100 MB\n\tfinal long bytesToFlushPerIterationRemaining = bytesToFlushPerIteration\n\tfinal long bytesToFlushPerIterationRemainingMin = 1024 * 1024 * 10 // 10 MB\n\tfinal long bytesToFlushPerIterationRemainingMax = 1024 * 1024 * 100 // 100 MB\n\tlong bytesToFlushPerIterationRemainingCurrent = bytesToFlushPerIterationRemaining\n\tlong bytesToFlushRemainingCurrent = bytesToFlushRemaining\n\tlong bytesToFlushCurrent = 0\n\tlong bytesFlushed = 0\n\tlong bytesFlushedCurrent = 0\n\tlong bytesFlushedRemaining = bytesToFlush\n\tlong bytesFlushedRemainingCurrent = bytesToFlush\n\tlong bytesFlushedPerIteration = 0\n\tlong bytesFlushedPerIterationCurrent = 0\n\tlong bytesFlushedPerIterationRemaining = bytesToFlushPerIteration\n\tlong bytesFlushedPerIterationRemainingCurrent = bytesToFlushPerIteration\n\tlong bytesFlushedPerIterationRemainingMin = bytesToFlushPerIterationRemainingMin\n\tlong bytesFlushedPerIterationRemainingMax = bytesToFlushPerIterationRemainingMax\n\tlong bytesFlushedPerIterationRemainingMinCurrent = bytesToFlushPerIterationRemainingMin\n\tlong bytesFlushedPerIterationRemainingMaxCurrent = bytesToFlushPerIterationRemainingMax\n\tlong bytesFlushedPerIterationRemainingCurrentCurrent = bytesFlushedPerIterationRemainingCurrent\n\tlong bytesFlushedPerIterationRemainingMinCurrentCurrent = bytesFlushedPerIterationRemainingMinCurrent\n\tlong bytesFlushedPerIterationRemainingMaxCurrentCurrent = bytesFlushedPerIterationRemainingMaxCurrent\n\tlong bytesFlushedPerIterationRemainingMinCurrentCurrentCurrent = bytesFlushedPerIterationRemainingMinCurrentCurrent\n\tlong bytesFlushedPerIterationRemainingMaxCurrentCurrentCurrent = bytesFlushedPerIterationRemainingMaxCurrentCurrent\n\tlong bytesFlushedPerIterationRemainingCurrentCurrentCurrent = bytesFlushedPerIterationRemainingCurrentCurrent\n\tlong bytesFlushedPerIterationRemainingCurrentCurrentCurrentCurrent = bytesFlushedPerIterationRemainingCurrentCurrentCurrent\n\tlong", "CodeBleu_score": 17.984948852829223}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tif (offset > lastFlushOffset) {\n\t\tfinal long bytesToFlush = offset - lastFlushOffset;\n\t\tif (bytesToFlush > 0) {\n\t\t\twriteService.write(lastFlushOffset, bytesToFlush, writeBuffer);\n\t\t\twriteMeta.setOffset(offset);\n\t\t\twriteMeta.setLength(bytesToFlush);\n\t\t\twriteMeta.write();\n\t\t}\n\t\tlastFlushOffset = offset;\n\t}\n}", "CodeBleu_score": 27.804293774758516}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal\n\t// flushWrittenBytesToServiceInternal", "CodeBleu_score": 11.704020075608812}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t// flip the buffer to prepare for reading\nbufferToWrite.flip();\n// calculate the byte length\nfinal int byteLength = bufferToWrite.remaining();\n// ensure the task queue is not overloaded\nwaitForTaskToComplete();\n// submit the write task to the completion service\nfinal Future<Integer> future = completionService.submit(new Callable<Integer>() {\n@Override\npublic Integer call() throws Exception {\n// write the data\nfinal int bytesWritten = writeData(bufferToWrite, writePosition);\n// release the buffer\nbufferToWrite.clear();\n// return the number of bytes written\nreturn bytesWritten;\n}\n});\n// record the write operation\nwriteOperations.add(new WriteOperation(future, byteLength));\n// manage the operation queue\nmanageOperationQueue();\n// return the number of bytes written\nreturn byteLength;\n}", "CodeBleu_score": 35.78874888731717}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\tbufferToWrite.flip();\n\tfinal int writeLength = bufferToWrite.remaining();\n\tensureTaskQueueNotOverloaded();\n\tfinal WriteTask writeTask = new WriteTask(bufferToWrite, writePosition);\n\tcompletionService.submit(writeTask);\n\trecordWriteOperation(writeTask);\n\tmanageOperationQueue();\n\treturn writeLength;\n}", "CodeBleu_score": 23.269514998744565}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\tbufferToWrite.flip();\n\tfinal int bytesToWrite = bufferToWrite.remaining();\n\tif (bytesToWrite == 0) {\n\t\treturn 0;\n\t}\n\tif (bytesToWrite > maxWriteSize) {\n\t\tthrow new IOException(\"Write size is too large: \" + bytesToWrite);\n\t}\n\tensureTaskQueueNotOverloaded();\n\tfinal WriteTask writeTask = new WriteTask(bufferToWrite, writePosition);\n\tsubmitWriteTask(writeTask);\n\trecordWriteOperation(writeTask);\n\treturn bytesToWrite;\n}", "CodeBleu_score": 25.238584971330692}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\tFuture<String> result = completionService.poll();\n\t\tif (result == null) {\n\t\t\ttry {\n\t\t\t\tresult = completionService.take();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IOException(\"Interrupted while waiting for task to complete\", e);\n\t\t\t}\n\t\t}\n\t\tif (result.isDone()) {\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 29.940842983021366}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\tFuture<String> result = completionService.poll();\n\t\tif (result == null) {\n\t\t\ttry {\n\t\t\t\tThread.sleep(100);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IOException(e);\n\t\t\t}\n\t\t} else {\n\t\t\ttry {\n\t\t\t\tresult.get();\n\t\t\t} catch (ExecutionException e) {\n\t\t\t\tthrow new IOException(e);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 27.023122127676764}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\tFuture<String> future = completionService.poll();\n\t\tif (future == null) {\n\t\t\ttry {\n\t\t\t\tfuture = completionService.take();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IOException(\"Interrupted while waiting for task to complete\", e);\n\t\t\t}\n\t\t}\n\t\tif (future.isDone()) {\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 29.901199023438163}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\twhile (!writeOperationQueue.isEmpty()) {\n\t\tWriteOperation op = writeOperationQueue.peek();\n\t\tif (op.isDone()) {\n\t\t\ttotalAppendOffset += op.getLength();\n\t\t\twriteOperationQueue.remove();\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 22.60362441122051}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\twhile (!writeOperationQueue.isEmpty()) {\n\t\tWriteOperation op = writeOperationQueue.peek();\n\t\tif (op.isDone()) {\n\t\t\ttotalAppendOffset += op.getLength();\n\t\t\twriteOperationQueue.remove();\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 22.60362441122051}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\twhile (true) {\n\t\tif (writeOperationQueue.isEmpty()) {\n\t\t\treturn;\n\t\t}\n\t\tWriteOperation op = writeOperationQueue.peek();\n\t\tif (op.isDone()) {\n\t\t\twriteOperationQueue.remove();\n\t\t\ttotalAppendOffset += op.getLength();\n\t\t} else {\n\t\t\treturn;\n\t\t}\n\t}\n}", "CodeBleu_score": 23.539319651935042}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null || user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"user and user.getHomeDirectory() must not be null\");\n\t}\n\tthis.homePath = user.getHomeDirectory();\n\tthis.user = user;\n}", "CodeBleu_score": 55.82804474819504}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"user is null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"user.getHomeDirectory() is null\");\n\t}\n\thomePath = user.getHomeDirectory();\n\tthis.user = user;\n}", "CodeBleu_score": 65.74530687712932}, {"code": "protected HdfsFileSystemView(User user){\n\t\tsuper()\n\n\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"user is null\")\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"user home directory is null\")\n\t}\n\n\thomePath = user.getHomeDirectory()\n\tthis.user = user\n}", "CodeBleu_score": 47.32027576570121}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath;\n\tif (dir.startsWith(\"/\")) {\n\t\tnewPath = Paths.get(dir);\n\t} else {\n\t\tnewPath = currentPath.resolve(dir);\n\t}\n\tif (newPath.toFile().isDirectory()) {\n\t\tif (newPath.getParent() == null ||!newPath.getParent().equals(Paths.get(\"/\"))) {\n\t\t\tcurrentPath = newPath;\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 20.66072881111376}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath;\n\tif (dir.startsWith(\"/\")) {\n\t\tnewPath = Paths.get(dir);\n\t} else {\n\t\tnewPath = currentPath.resolve(dir);\n\t}\n\n\tif (newPath.equals(currentPath.getRoot())) {\n\t\treturn false;\n\t}\n\n\tif (Files.isDirectory(newPath)) {\n\t\tcurrentPath = newPath;\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 22.106755912532872}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath;\n\tif (dir.startsWith(\"/\")) {\n\t\tnewPath = new Path(dir);\n\t} else {\n\t\tnewPath = currentPath.resolve(dir);\n\t}\n\tif (newPath.equals(root)) {\n\t\treturn false;\n\t}\n\tif (newPath.isDirectory()) {\n\t\tcurrentPath = newPath;\n\t\treturn true;\n\t}\n\treturn false;\n}", "CodeBleu_score": 23.03304780833223}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis.filerClient = new FilerClient(host, port, grpcPort, conf);\n\tString accessMode = conf.get(\"seaweedfs.access.mode\");\n\tif (accessMode == null) {\n\t\taccessMode = \"direct\";\n\t}\n\tif (accessMode.equals(\"direct\")) {\n\t\tsetAccessVolumeServerByDirect();\n\t} else if (accessMode.equals(\"publicUrl\")) {\n\t\tsetAccessVolumeServerByPublicUrl();\n\t} else if (accessMode.equals(\"filerProxy\")) {\n\t\tsetAccessVolumeServerByFilerProxy();\n\t} else {\n\t\tthrow new IllegalArgumentException(\"Invalid seaweedfs.access.mode: \" + accessMode);\n\t}\n}", "CodeBleu_score": 44.97824699433088}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tsuper(conf);\n\tthis.filerClient = new FilerClient(host, port, grpcPort);\n\tif (conf.get(\"seaweed.fs.access.mode\")!= null) {\n\t\tif (conf.get(\"seaweed.fs.access.mode\").equals(\"direct\")) {\n\t\t\tthis.filerClient.setAccessVolumeServerByDirect();\n\t\t} else if (conf.get(\"seaweed.fs.access.mode\").equals(\"publicUrl\")) {\n\t\t\tthis.filerClient.setAccessVolumeServerByPublicUrl();\n\t\t} else if (conf.get(\"seaweed.fs.access.mode\").equals(\"filerProxy\")) {\n\t\t\tthis.filerClient.setAccessVolumeServerByFilerProxy();\n\t\t}\n\t}\n}", "CodeBleu_score": 43.559368892027884}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tsuper(conf);\n\tthis.host = host;\n\tthis.port = port;\n\tthis.grpcPort = grpcPort;\n\tthis.filerClient = new FilerClient(host, port, grpcPort);\n\tthis.accessVolumeServerByFilerProxy = conf.getBoolean(ACCESS_VOLUME_SERVER_BY_FILER_PROXY, false);\n\tthis.accessVolumeServerByPublicUrl = conf.getBoolean(ACCESS_VOLUME_SERVER_BY_PUBLIC_URL, false);\n\tif (this.accessVolumeServerByFilerProxy && this.accessVolumeServerByPublicUrl) {\n\t\tthrow new IllegalArgumentException(\"Only one of \" + ACCESS_VOLUME_SERVER_BY_FILER_PROXY + \" or \" + ACCESS_VOLUME_SERVER_BY_PUBLIC_URL + \" can be true\");\n\t}\n}", "CodeBleu_score": 37.30009771252566}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\tLOG.debug(\"openFileForRead path: \" + path);\n\tfinal FileEntry entry = lookupEntry(path);\n\tif (entry == null) {\n\t\tthrow new FileNotFoundException(\"File not found: \" + path);\n\t}\n\treturn new SeaweedHadoopInputStream(filerClient, statistics, path);\n}", "CodeBleu_score": 70.23335520571975}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\tLOG.debug(\"openFileForRead: \" + path);\n\tFileEntry entry = lookupEntry(path);\n\tif (entry == null) {\n\t\tthrow new FileNotFoundException(path.toString());\n\t}\n\treturn new SeaweedHadoopInputStream(filerClient, statistics, entry, path);\n}", "CodeBleu_score": 66.9092272106314}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\tlog.debug(\"openFileForRead: {}\", path);\n\tFileEntry entry = lookupEntry(path);\n\tif (entry == null) {\n\t\tthrow new FileNotFoundException(path.toString());\n\t}\n\treturn new SeaweedHadoopInputStream(filerClient, statistics, entry, path.toString());\n}", "CodeBleu_score": 60.79201242131169}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\tthis.localHostName = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tthis.localHostName = \"localhost\";\n\t}\n\tthis.numThreadsPerMap = conf.getInt(\"mapred.map.tasks.speculative.execution.thread.count\", 1);\n\tthis.numFilesPerThread = conf.getInt(\"mapred.map.tasks.speculative.execution.files.per.thread\", 1);\n\tthis.threadPool = Executors.newFixedThreadPool(this.numThreadsPerMap);\n\tfor (int i = 0; i < this.numThreadsPerMap; i++) {\n\t\tthis.threadPool.execute(new Thread(new MapTaskSpeculativeExecutionThread(this.conf, this.numFilesPerThread)));\n\t}\n\tthis.threadPool.setDaemon(true);\n}", "CodeBleu_score": 34.03197223546432}, {"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\tlocalHostName = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tlocalHostName = \"localhost\";\n\t}\n\tthreadsPerMap = conf.getInt(\"mapred.map.tasks.speculative.threads\", 1);\n\tfilesPerThread = conf.getInt(\"mapred.map.tasks.speculative.files\", 1);\n\tthreadPool = Executors.newFixedThreadPool(threadsPerMap, new ThreadFactory() {\n\t\tpublic Thread newThread(Runnable r) {\n\t\t\tThread t = new Thread(r);\n\t\t\tt.setDaemon(true);\n\t\t\treturn t;\n\t\t}\n\t});\n}", "CodeBleu_score": 62.05200191218548}, {"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\tthis.hostName = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tthis.hostName = \"localhost\";\n\t}\n\tthis.threadsPerMap = conf.getInt(\"mapred.map.tasks.speculative.threads\", 1);\n\tthis.filesPerThread = conf.getInt(\"mapred.map.tasks.speculative.files\", 1);\n\tthis.threadPool = Executors.newFixedThreadPool(threadsPerMap);\n\tfor (int i = 0; i < threadsPerMap; i++) {\n\t\tthreadPool.execute(new MapThread());\n\t}\n\tthreadPool.setDaemon(true);\n}", "CodeBleu_score": 38.714356672525156}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t\t// Check if the trash emptier is already running for the specified host\n\tif (isRunning(uri, conf)) {\n\t\treturn;\n\t}\n\t// Create a superuser and initialize a JuiceFileSystemImpl instance as the superuser\n\tUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf().get(CommonConfigurationKeys.HADOOP_SECURITY_SUPERUSER_KEY));\n\tsuperUser.doAs(new PrivilegedExceptionAction<Void>() {\n\t\t@Override\n\t\tpublic Void run() throws Exception {\n\t\t\t// Initialize a JuiceFileSystemImpl instance as the superuser\n\t\t\tJuiceFileSystemImpl fs = new JuiceFileSystemImpl(uri, conf);\n\t\t\t// Start the trash emptier task using the initialized file system and the trash configuration, scheduling it to run every 10 minutes\n\t\t\tfs.getEmptier().schedule(new TrashEmptierTask(fs), 10, TimeUnit.MINUTES);\n\t\t\treturn null;\n\t\t}\n\t});\n}", "CodeBleu_score": 33.238386645370596}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t\tif (isRunning(uri, conf)) {\n\t\treturn;\n\t}\n\tUserGroupInformation superuser = createRemoteUser(uri, conf);\n\tfinal FileSystem fs = superuser.doAs(new PrivilegedExceptionAction<FileSystem>() {\n\t\t@Override\n\t\tpublic FileSystem run() throws IOException {\n\t\t\treturn FileSystem.get(uri, conf);\n\t\t}\n\t});\n\t// schedule the emptier to run every 10 minutes\n\tscheduler.scheduleAtFixedRate(new Emptier(uri, conf, fs), 0, 10, TimeUnit.MINUTES);\n}", "CodeBleu_score": 29.89996225508409}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t\tfinal String host = uri.getHost();\n\tif (host!= null && isRunning(host)) {\n\t\treturn;\n\t}\n\tUserGroupInformation superuser = null;\n\ttry {\n\t\tsuperuser = UserGroupInformation.createRemoteUser(getConf().get(DFSConfigKeys.DFS_SUPERUSER_KEY, DFSConfigKeys.DFS_SUPERUSER_DEFAULT));\n\t} catch (IOException e) {\n\t\tthrow new IOException(\"Failed to create superuser for trash emptier.\", e);\n\t}\n\tfinal UserGroupInformation ugi = superuser;\n\tugi.doAs(new PrivilegedExceptionAction<Void>() {\n\t\t@Override\n\t\tpublic Void run() throws Exception {\n\t\t\tFileSystem fs = FileSystem.get(uri, conf);\n\t\t\tTrash trash = new Trash(fs, conf);\n\t\t\ttrash.setEmptier(new TrashEmptier(fs, trash, conf));\n\t\t\ttrash.getEmptier().schedule(10, TimeUnit.MINUTES);\n\t\t\treturn null;\n\t\t}\n\t});\n}", "CodeBleu_score": 45.138132952283215}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t\tif (context == null) {\n\t\tthrow new Exception(\"Context cannot be null\");\n\t}\n\tString current = getCurrent();\n\tif (current == null) {\n\t\tsetCurrent(context);\n\t} else {\n\t\tif (!isContextValid(current)) {\n\t\t\tsetCurrent(context);\n\t\t} else {\n\t\t\tif (current.indexOf(context) < 0) {\n\t\t\t\tsetCurrent(current + \"|\" + context);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 21.645852830894093}, {"code": "public static void setContext(String context) throws Exception{\n\t\ttry {\n\t\tString currentContext = getCurrent();\n\t\tif (currentContext == null) {\n\t\t\tcurrentContext = build(context);\n\t\t\tsetCurrent(currentContext);\n\t\t} else {\n\t\t\tif (isContextValid(currentContext)) {\n\t\t\t\tif (currentContext.indexOf(context) < 0) {\n\t\t\t\t\tcurrentContext += context;\n\t\t\t\t\tsetCurrent(currentContext);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tcurrentContext = build(context);\n\t\t\t\tsetCurrent(currentContext);\n\t\t\t}\n\t\t}\n\t} catch (Exception e) {\n\t\tthrow e;\n\t}\n}", "CodeBleu_score": 27.465017054082875}, {"code": "public static void setContext(String context) throws Exception{\n\t\t// Get current context\n\tString currentContext = getCurrent();\n\n\t// If current context is invalid or not set, create a new one\n\tif (currentContext == null ||!isContextValid(currentContext)) {\n\t\tcurrentContext = build(context);\n\t\tsetCurrent(currentContext);\n\t} else {\n\t\t// If current context is valid, append the new context to it\n\t\tif (!currentContext.contains(context)) {\n\t\t\tcurrentContext = currentContext + \"/\" + context;\n\t\t\tsetCurrent(currentContext);\n\t\t}\n\t}\n}", "CodeBleu_score": 25.543327394334646}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t\tlibhdfs_->hdfsDelete(connect(uri), uri.to_path().c_str());\n\tRETURN_NOT_OK(Status_HDFSError(libhdfs_->get_last_error()));\n\treturn Status::Ok;\n}", "CodeBleu_score": 33.382750304839995}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t\thdfsFS fs = connect(uri);\n\tif (fs == NULL) {\n\t\treturn Status_HDFSError(uri.to_string(), \"Failed to connect to HDFS\");\n\t}\n\n\tif (hdfsDelete(fs, uri.to_path().c_str(), 0)!= 0) {\n\t\tLOG_STATUS(Status_HDFSError(uri.to_string(), \"Failed to delete file\"));\n\t\treturn Status_HDFSError(uri.to_string(), \"Failed to delete file\");\n\t}\n\n\treturn Status::Ok();\n}", "CodeBleu_score": 54.29953668351749}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t\thdfsFS fs = connect(uri);\n\tif (fs == NULL) {\n\t\treturn Status_HDFSError(\"Failed to connect to HDFS\");\n\t}\n\tif (hdfsDelete(fs, uri.to_path().c_str(), 0)!= 0) {\n\t\tLOG_STATUS(Status_HDFSError(\"Failed to delete file\", uri.to_string()));\n\t\treturn Status_HDFSError(\"Failed to delete file\", uri.to_string());\n\t}\n\tRETURN_NOT_OK(disconnect(fs));\n\treturn Status::OK();\n}", "CodeBleu_score": 53.23441317860361}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS fs = connect(uri);\n\tif (!fs) {\n\t\treturn Status_HDFSError(\"Failed to connect to HDFS\");\n\t}\n\n\tif (!is_file(fs, uri)) {\n\t\treturn Status::Ok;\n\t}\n\n\thdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n\tif (!file) {\n\t\tLOG_STATUS(Status_HDFSError(\"Failed to open file for syncing\"));\n\t\treturn Status_HDFSError(\"Failed to open file for syncing\");\n\t}\n\n\tif (libhdfs_->hdfsHFlush(fs, file)!= 0) {\n\t\tLOG_STATUS(Status_HDFSError(\"Failed to flush file\"));\n\t\treturn Status_HDFSError(\"Failed_to_flush_file\");\n\t}\n\n\tif (libhdfs_->hdfsCloseFile(fs, file)!= 0) {\n\t\tLOG_STATUS(Status_HDFSError(\"Failed to close file\"));\n\t\treturn Status_HDFSError(\"Failed to close file\");\n\t}\n\n\treturn Status::Ok;\n}", "CodeBleu_score": 47.0540990041206}, {"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS fs = connect(uri);\n\tif (fs == NULL) {\n\t\treturn Status_HDFSError(\"Failed to connect to HDFS\");\n\t}\n\n\tif (!is_file(fs, uri)) {\n\t\treturn Status::Ok;\n\t}\n\n\thdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n\tif (file == NULL) {\n\t\tLOG_STATUS(Status_HDFSError(\"Failed to open file \" + uri.to_string()));\n\t\treturn Status_HDFSError(\"Failed to open file \" + uri.to_string());\n\t}\n\n\tif (libhdfs_->hdfsHFlush(fs, file)!= 0) {\n\t\tLOG_STATUS(Status_HDFSError(\"Failed to flush file \" + uri.to_string()));\n\t\treturn Status_HDFSError(\"Failed to flush file \" + uri.to_string());\n\t}\n\n\tif (libhdfs_->hdfsCloseFile(fs, file)!= 0) {\n\t\tLOG_STATUS(Status_HDFSError(\"Failed to close file \" + uri.to_string()));\n\t\treturn Status_HDFSError(\"Failed to close file \" + uri.to_string());\n\t}\n\n\treturn Status::Ok;\n}", "CodeBleu_score": 48.288319147535475}, {"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS fs = connect(uri);\n\tif (!fs) {\n\t\treturn Status::IOError(\"Failed to connect to HDFS\");\n\t}\n\tif (!is_file(uri, fs)) {\n\t\treturn Status::Ok();\n\t}\n\thdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n\tif (!file) {\n\t\tLOG_STATUS(Status_HDFSError(\"Failed to open file for syncing: \" + uri.to_string()));\n\t\treturn Status_HDFSError(\"Failed to open file for syncing: \" + uri.to_string());\n\t}\n\tint ret = libhdfs_->hdfsHFlush(fs, file);\n\tif (ret!= 0) {\n\t\tLOG_STATUS(Status_HDFSError(\"Failed to sync file: \" + uri.to_string()));\n\t\treturn Status_HDFSError(\"Failed to sync file: \" + uri.to_string());\n\t}\n\tRETURN_NOT_OK(libhdfs_->hdfsCloseFile(fs, file));\n\treturn Status::Ok();\n}", "CodeBleu_score": 53.36840528997773}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t\n/*\n * The file_size function retrieves the size of a file in HDFS specified by a URI.\n */", "CodeBleu_score": 3.228306442731161}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t\thdfsFS fs = connect(uri);\n\tif (fs == NULL) {\n\t\treturn Status_HDFSError(\"Failed to connect to HDFS\");\n\t}\n\n\thdfsFileInfo* info = hdfsGetPathInfo(fs, uri.to_path().c_str());\n\tif (info == NULL) {\n\t\thdfsFreeFileInfo(info, 1);\n\t\thdfsDisconnect(fs);\n\t\tLOG_STATUS(Status_HDFSError(\"Failed to get file information\"));\n\t\treturn Status_HDFSError(\"Failed to get file information\");\n\t}\n\n\tif (info->mKind!= kObjectKindFile) {\n\t\thdfsFreeFileInfo(info, 1);\n\t\thdfsDisconnect(fs);\n\t\tLOG_STATUS(Status_HDFSError(\"Path is not a file\"));\n\t\treturn Status_HDFSError(\"Path is not a file\");\n\t}\n\n\t*nbytes = static_cast<uint64_t>(info->mSize);\n\thdfsFreeFileInfo(info, 1);\n\thdfsDisconnect(fs);\n\treturn Status::Ok();\n}", "CodeBleu_score": 52.31462594263792}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t\thdfsFS fs = connect(uri);\n\tif (fs == NULL)\n\t\treturn Status::IOError(\"Failed to connect to HDFS file system\");\n\n\thdfsFileInfo* file_info = hdfsGetPathInfo(fs, uri.to_path().c_str());\n\tif (file_info == NULL) {\n\t\thdfsFreeFileInfo(file_info, 1);\n\t\treturn Status::IOError(\"Failed to get file info\");\n\t}\n\n\tif (file_info->mKind!= kObjectKindFile) {\n\t\thdfsFreeFileInfo(file_info, 1);\n\t\treturn Status::IOError(\"Not a file\");\n\t}\n\n\t*nbytes = static_cast<uint64_t>(file_info->mSize);\n\thdfsFreeFileInfo(file_info, 1);\n\n\treturn Status::Ok();\n}", "CodeBleu_score": 48.355407322630086}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString quorum = null;\n\tString znodeParent = null;\n\tString[] cfgs = hbaseCfgString.split(\",\");\n\tfor (String cfg : cfgs) {\n\t\tString[] kv = cfg.split(\"=\");\n\t\tif (kv[0].equals(\"hbase.zookeeper.quorum\")) {\n\t\t\tquorum = kv[1];\n\t\t\tif (quorum.indexOf(\":\") == -1) {\n\t\t\t\tquorum += \":2181\";\n\t\t\t}\n\t\t} else if (kv[0].equals(\"zookeeper.znode.parent\")) {\n\t\t\tznodeParent = kv[1];\n\t\t}\n\t}\n\tif (znodeParent == null) {\n\t\tznodeParent = \"/hbase\";\n\t}\n\treturn Pair.of(quorum, znodeParent);\n}", "CodeBleu_score": 22.140932957245678}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString[] hbaseCfgArray = hbaseCfgString.split(\",\");\n\tString quorum = null;\n\tString znodeParent = null;\n\tfor (String cfg : hbaseCfgArray) {\n\t\tString[] cfgArray = cfg.split(\"=\");\n\t\tif (cfgArray[0].equals(\"hbase.zookeeper.quorum\")) {\n\t\t\tquorum = cfgArray[1];\n\t\t\tif (!quorum.contains(\":\")) {\n\t\t\t\tquorum = quorum + \":2181\";\n\t\t\t}\n\t\t} else if (cfgArray[0].equals(\"zookeeper.znode.parent\")) {\n\t\t\tznodeParent = cfgArray[1];\n\t\t}\n\t}\n\tif (znodeParent == null) {\n\t\tznodeParent = \"/hbase\";\n\t}\n\treturn new Pair<String, String>(quorum, znodeParent);\n}", "CodeBleu_score": 27.41968240286227}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tif (hbaseCfgString == null || hbaseCfgString.isEmpty()) {\n\t\treturn null;\n\t}\n\tString[] hbaseCfgArray = hbaseCfgString.split(\",\");\n\tString quorum = null;\n\tString znodeParent = null;\n\tfor (String cfg : hbaseCfgArray) {\n\t\tString[] cfgArray = cfg.split(\"=\");\n\t\tif (cfgArray.length!= 2) {\n\t\t\tcontinue;\n\t\t}\n\t\tString key = cfgArray[0].trim();\n\t\tString value = cfgArray[1].trim();\n\t\tif (key.equalsIgnoreCase(\"hbase.zookeeper.quorum\")) {\n\t\t\tquorum = value;\n\t\t\tif (!quorum.contains(\":\")) {\n\t\t\t\tquorum += \":2181\";\n\t\t\t}\n\t\t} else if (key.equalsIgnoreCase(\"zookeeper.znode.parent\")) {\n\t\t\tznodeParent = value;\n\t\t}\n\t}\n\tif (quorum == null) {\n\t\treturn null;\n\t}\n\tif (znodeParent == null) {\n\t\tznodeParent = \"/hbase\";\n\t}\n\treturn new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 32.284784999529705}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\t// Establish a JDBC connection to the HBase database\n\tConnection conn = getJdbcConnection(cfg);\n\ttry {\n\t\t// Check if the specified table exists in the given namespace\n\t\tcheckTable(conn, cfg.getNamespace(), cfg.getTableName());\n\n\t\t// Get the table schema and validate the configured columns\n\t\tResultSet rs = conn.getMetaData().getColumns(cfg.getNamespace(), null, cfg.getTableName(), null);\n\t\tList<String> columns = new ArrayList<>();\n\t\twhile (rs.next()) {\n\t\t\tcolumns.add(rs.getString(\"COLUMN_NAME\"));\n\t\t}\n\n\t\t// Validate the configured columns\n\t\tfor (String column : cfg.getColumns()) {\n\t\t\tif (!columns.contains(column)) {\n\t\t\t\tthrow new AddaxException(String.format(\"Column '%s' does not exist in table '%s'\", column, cfg.getTableName()));\n\t\t\t}\n\t\t}\n\t} catch (SQLException e) {\n\t\tthrow new AddaxException(String.format(\"Error validating configuration for HbaseSQLWriter: %s\", e.getMessage()), e);\n\t} finally {\n\t\ttry {\n\t\t\tconn.close();\n\t\t} catch (SQLException e) {\n\t\t\tthrow new AddaxException(String.format(\"Error closing JDBC connection for HbaseSQLWriter: %s\", e.getMessage()), e);\n\t\t}\n\t}\n}", "CodeBleu_score": 37.03029008274726}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\t// Establish a JDBC connection\n\tConnection conn = getJdbcConnection(cfg);\n\n\t// Check if the specified table exists in the given namespace\n\ttry {\n\t\tDatabaseMetaData dbmd = conn.getMetaData();\n\t\tResultSet rs = dbmd.getTables(null, cfg.getNamespace(), cfg.getTableName(), new String[] {\"TABLE\"});\n\t\tif (!rs.next()) {\n\t\t\tthrow new AddaxException(String.format(\"Table '%s' does not exist in the '%s' namespace.\", cfg.getTableName(), cfg.getNamespace()));\n\t\t}\n\t} catch (SQLException e) {\n\t\tthrow new AddaxException(String.format(\"Error checking table '%s' in the '%s' namespace.\", cfg.getTableName(), cfg.getNamespace()), e);\n\t}\n\n\t// Retrieve the table schema\n\ttry {\n\t\tDatabaseMetaData dbmd = conn.getMetaData();\n\t\tResultSet rs = dbmd.getColumns(null, cfg.getNamespace(), cfg.getTableName(), \"%\");\n\t\tMap<String, String> columnMap = new HashMap<>();\n\t\twhile (rs.next()) {\n\t\t\tcolumnMap.put(rs.getString(\"COLUMN_NAME\"), rs.getString(\"TYPE_NAME\"));\n\t\t}\n\n\t\t// Ensure that all configured columns exist in the target table\n\t\tfor (HbaseSQLWriterColumn column : cfg.getColumns()) {\n\t\t\tif (!columnMap.containsKey(column.getColumnName())) {\n\t\t\t\tthrow new AddaxException(String.format(\"Column '%s' does not exist in the '%s' table.\", column.getColumnName(), cfg.getTableName()));\n\t\t\t}\n\t\t}\n\t} catch (SQLException e) {\n\t\tthrow new AddaxException(String.format(\"Error retrieving table schema for '%s' in the '%s' namespace.\", cfg.getTableName(), cfg.getNamespace()), e);\n\t}\n}", "CodeBleu_score": 39.48624405220405}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\n}", "CodeBleu_score": 0.8914762695562949}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (KerberosUtil.isKerberosEnabled()) {\n\t\tif (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n\t\t\ttry {\n\t\t\t\tHadoopUtil.setConfiguration(KerberosUtil.getHadoopConfiguration(kerberosPrincipal, kerberosKeytabFilePath));\n\t\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t\t} catch (IOException e) {\n\t\t\t\tthrow AddaxException.asAddaxException(HadoopWriterErrorCode.HADOOP_KERBEROS_LOGIN_ERROR,\n\t\t\t\t\tString.format(\"Kerberos login error, principal: %s, keytab file path: %s\", kerberosPrincipal, kerberosKeytabFilePath), e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 47.595025748931825}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n\t\tConfiguration hadoopConf = HadoopConfiguration.get();\n\t\tUserGroupInformation.setConfiguration(hadoopConf);\n\t\ttry {\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tthrow DataXException.asAddaxException(HadoopWriterErrorCode.KERBEROS_LOGIN_ERROR,\n\t\t\t\t\tString.format(HadoopWriterErrorCode.KERBEROS_LOGIN_ERROR.getDescription(), kerberosPrincipal,\n\t\t\t\t\t\t\tkerberosKeytabFilePath), e);\n\t\t}\n\t}\n}", "CodeBleu_score": 49.094746737598605}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n\t\ttry {\n\t\t\tUserGroupInformation.setConfiguration(HadoopUtil.getHadoopConfiguration());\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tthrow DataXException.asAddaxException(HadoopWriterErrorCode.KRB_LOGIN_ERROR,\n\t\t\t\t\tString.format(\"Kerberos login error, principal: %s, keytab file path: %s\", kerberosPrincipal, kerberosKeytabFilePath));\n\t\t}\n\t}\n}", "CodeBleu_score": 41.797585157521866}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> colType = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\nResultSetMetaData rsmd = rs.getMetaData();\nfor (int i = 1; i <= rsmd.getColumnCount(); i++) {\nString name = rsmd.getColumnLabel(i);\nString type = rsmd.getColumnTypeName(i);\nif (name == null || type == null) {\nthrow new SQLException(\"name or type is null\");\n}\ncolType.put(name, new ThinClientPTable.ThinClientPColumn(name, type));\n}\nreturn colType;\n}", "CodeBleu_score": 31.495738478027214}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> colMap = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n\nResultSetMetaData md = rs.getMetaData();\n\nfor (int i = 1; i <= md.getColumnCount(); i++) {\nString colName = md.getColumnLabel(i);\nString colType = md.getColumnTypeName(i);\n\nif (colName == null) {\nthrow new SQLException(\"Column name is null\");\n}\n\nif (colType == null) {\nthrow new SQLException(\"Column type is null\");\n}\n\ncolMap.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n}\n\nreturn colMap;\n}", "CodeBleu_score": 34.670028869190205}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\tMap<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n\tResultSetMetaData rsmd = rs.getMetaData();\n\tint numCols = rsmd.getColumnCount();\n\tfor (int i = 1; i <= numCols; i++) {\n\t\tString colName = rsmd.getColumnLabel(i);\n\t\tif (colName == null || colName.length() == 0) {\n\t\t\tthrow new SQLException(\"Unable to get column label for column \" + i);\n\t\t}\n\t\tString colType = rsmd.getColumnTypeName(i);\n\t\tif (colType == null || colType.length() == 0) {\n\t\t\tthrow new SQLException(\"Unable to get column type for column \" + i);\n\t\t}\n\t\tcolTypeMap.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n\t}\n\treturn colTypeMap;\n}", "CodeBleu_score": 42.90945965819754}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\t\ttry {\n\t\t// unwrap the connection to get the PhoenixConnection\n\t\tPhoenixConnection phoenixConn = (PhoenixConnection) conn;\n\t\t// get the HBase Admin instance\n\t\tAdmin admin = phoenixConn.getQueryServices().getAdmin();\n\t\t// check if the table exists\n\t\tif (!admin.tableExists(TableName.valueOf(tableName))) {\n\t\t\tthrow new AddaxException(\n\t\t\t\t\tString.format(\"The table %s does not exist.\", tableName));\n\t\t}\n\t\t// disable the table\n\t\tadmin.disableTable(TableName.valueOf(tableName));\n\t\t// truncate the table with the option to preserve the splits\n\t\tadmin.truncateTable(TableName.valueOf(tableName), true);\n\t\t// log a debug message indicating the table has been truncated\n\t\tlogger.debug(String.format(\"The table %s has been truncated.\", tableName));\n\t} catch (Exception e) {\n\t\t// throw an exception with a relevant error code and message\n\t\tthrow new AddaxException(\n\t\t\t\tString.format(\"Error truncating the table %s.\", tableName),\n\t\t\t\te,\n\t\t\t\tAddaxException.INTERNAL_ERROR);\n\t} finally {\n\t\t// ensure the Admin instance is closed properly\n\t\tcloseAdmin(admin);\n\t}\n}", "CodeBleu_score": 41.09283547691256}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t\ttry {\n\t\tunwrap(conn).getAdmin().truncateTable(TableName.valueOf(tableName), true);\n\t\tdebug(\"table %s truncated\", tableName);\n\t} catch (Exception e) {\n\t\tthrow addaxException(HBase11Constant.PLUGIN_NAME, HBase11Constant.ERROR_CODE_10000,\n\t\t\tString.format(\"truncate table %s failed\", tableName), e);\n\t} finally {\n\t\tcloseAdmin(conn);\n\t}\n}", "CodeBleu_score": 19.162398048342755}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t\ttry {\n\t\tunwrap(conn).getAdmin().truncateTable(TableName.valueOf(tableName), true);\n\t\tdebug(\"Table %s has been truncated.\", tableName);\n\t} catch (TableNotFoundException e) {\n\t\tthrow asAddaxException(HBase11xConstant.ERROR_CODE_TABLE_NOT_EXIST, e, \"Table %s not exist\", tableName);\n\t} catch (IOException e) {\n\t\tthrow asAddaxException(HBase11xConstant.ERROR_CODE_TRUNCATE_TABLE_FAILED, e, \"Truncate table %s failed\", tableName);\n\t} finally {\n\t\tcloseAdmin(conn);\n\t}\n}", "CodeBleu_score": 25.79275646494655}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\t\tFileType fileType = FileType.getFileType(filePath);\n\tif (fileType == null) {\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.ILLEGAL_VALUE,\n\t\t\tString.format(\"File type of %s is not supported.\", filePath));\n\t}\n\tif (fileType == this.fileType) {\n\t\tinfo(\"Add source file: %s\", filePath);\n\t\tthis.sourceFiles.add(filePath);\n\t} else {\n\t\terror(\"File type of %s is not %s, skip it.\", filePath, this.fileType);\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.ILLEGAL_VALUE,\n\t\t\tString.format(\"File type of %s is not %s, skip it.\", filePath, this.fileType));\n\t}\n}", "CodeBleu_score": 38.14806885488459}, {"code": "private void addSourceFileByType(String filePath){\n\t\tif (isFileTypeMatch(filePath)) {\n\t\tinfo(String.format(\"Add file '%s' to source files list.\", filePath));\n\t\tsourceFileList.add(filePath);\n\t} else {\n\t\terror(String.format(\"Unsupported file type '%s'.\", getFileType(filePath)));\n\t\tthrow asAddaxException(String.format(\"Unsupported file type '%s'.\", getFileType(filePath)));\n\t}\n}", "CodeBleu_score": 23.946436729411953}, {"code": "private void addSourceFileByType(String filePath){\n\tinfo", "CodeBleu_score": 2.165676718186487}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\ntaskPluginCollector.collectDebug(\"Start to read sequence file:\" + sourceSequenceFilePath);\nSequenceFile.Reader reader = null;\ntry {\nreader = new SequenceFile.Reader(new Path(sourceSequenceFilePath), readerSliceConfig);\nClass<?> keyClass = reader.getKeyClass();\nClass<?> valueClass = reader.getValueClass();\ntaskPluginCollector.collectDebug(\"key class:\" + keyClass.getName());\ntaskPluginCollector.collectDebug(\"value class:\" + valueClass.getName());\nWritable key = (Writable) keyClass.newInstance();\nWritable value = (Writable) valueClass.newInstance();\nwhile (reader.next(key, value)) {\nString valueString = value.toString();\nif (StringUtils.isNotBlank(valueString)) {\ntaskPluginCollector.collectDebug(\"read record, key:\" + key + \", value:\" + value);\nStorageReaderUtil.transportOneRecord(recordSender, valueString, taskPluginCollector);\n}\n}\n} catch (Exception e) {\ntaskPluginCollector.collectError(\"read sequence file:\" + sourceSequenceFilePath + \" error\", e);\nthrow DataXException.asAddaxException(CommonErrorCode.READER_HANDLER_ERROR, e);\n} finally {\nif (reader!= null) {\ntry {\nreader.close();\n} catch (IOException e) {\ntaskPluginCollector.collectError(\"close sequence file:\" + sourceSequenceFilePath + \" error\", e);\nthrow DataXException.asAddaxException(CommonErrorCode.READER_HANDLER_ERROR, e);\n}\n}\n}\n}", "CodeBleu_score": 42.53804298144577}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\tlog.info(\"start read sequence file, source path is {}\", sourceSequenceFilePath);\nSequenceFile.Reader reader = null;\ntry {\n    reader = new SequenceFile.Reader(new Path(sourceSequenceFilePath), readerSliceConfig);\n    Writable key = (Writable) ObjectUtil.instantiate(reader.getKeyClass().getName());\n    Writable value = (Writable) ObjectUtil.instantiate(reader.getValueClass().getName());\n    while (reader.next(key, value)) {\n        if (StringUtils.isNotBlank(value.toString())) {\n            StorageReaderUtil.transportOneRecord(recordSender, key, value, taskPluginCollector);\n        }\n    }\n} catch (Exception e) {\n    log.error(\"read sequence file error, source path is {}\", sourceSequenceFilePath, e);\n    throw DataXException.asAddaxException(HDFSReaderErrorCode.READ_FILE_ERROR, e);\n} finally {\n    if (reader!= null) {\n        try {\n            reader.close();\n        } catch (IOException e) {\n            log.error(\"close sequence file error, source path is {}\", sourceSequenceFilePath, e);\n            throw DataXException.asAddaxException(HDFSReaderErrorCode.CLOSE_FILE_ERROR, e);\n        }\n    }\n}\n}", "CodeBleu_score": 51.338793293178355}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\tLOG.info(\"Start to read sequence file from HDFS path: {}\", sourceSequenceFilePath);\nSequenceFile.Reader reader = null;\ntry {\nreader = new SequenceFile.Reader(new Path(sourceSequenceFilePath), readerSliceConfig);\nClass keyClass = reader.getKeyClass();\nClass valueClass = reader.getValueClass();\nLOG.info(\"The key class is {}, the value class is {}\", keyClass, valueClass);\nWritable key = (Writable) keyClass.newInstance();\nWritable value = (Writable) valueClass.newInstance();\nwhile (reader.next(key, value)) {\nif (StringUtils.isNotBlank(value.toString())) {\nStorageReaderUtil.transportOneRecord(recordSender, value, taskPluginCollector);\n}\n}\n} catch (Exception e) {\nLOG.error(\"Error occurs when reading sequence file from HDFS path: {}\", sourceSequenceFilePath, e);\nthrow DataXException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, e);\n} finally {\nif (reader!= null) {\ntry {\nreader.close();\n} catch (IOException e) {\nLOG.error(\"Error occurs when closing sequence file from HDFS path: {}\", sourceSequenceFilePath, e);\n}\n}\n}\n}", "CodeBleu_score": 48.533879765406056}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\tboolean isMatched = false;\n\ttry {\n\t\tFileSystem fs = FileSystem.get(URI.create(filepath), new Configuration());\n\t\tPath path = new Path(filepath);\n\t\tif (fs.exists(path)) {\n\t\t\tFileStatus fileStatus = fs.getFileStatus(path);\n\t\t\tif (fileStatus.isDir()) {\n\t\t\t\treturn isMatched;\n\t\t\t}\n\t\t\tif (isTextFile(fs, path)) {\n\t\t\t\tisMatched = true;\n\t\t\t} else if (isCSVFile(fs, path)) {\n\t\t\t\tisMatched = true;\n\t\t\t} else if (isORCFile(fs, path)) {\n\t\t\t\tisMatched = true;\n\t\t\t} else if (isRCFile(fs, path)) {\n\t\t\t\tisMatched = true;\n\t\t\t} else if (isSequenceFile(fs, path)) {\n\t\t\t\tisMatched = true;\n\t\t\t} else if (isParquetFile(fs, path)) {\n\t\t\t\tisMatched = true;\n\t\t\t} else {\n\t\t\t\tisMatched = false;\n\t\t\t}\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(e.getMessage(), e);\n\t\tthrow DataXException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, e);\n\t}\n\treturn isMatched;\n}", "CodeBleu_score": 33.01875884474842}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\ttry {\n\t\tConfiguration conf = new Configuration();\n\t\tFileSystem fs = FileSystem.get(URI.create(filepath), conf);\n\t\tPath path = new Path(filepath);\n\t\tFSDataInputStream inputStream = fs.open(path);\n\t\tboolean isRCFile = false;\n\t\tboolean isSequenceFile = false;\n\t\tboolean isParquetFile = false;\n\t\tboolean isORCFile = false;\n\t\tif (specifiedFileType.equalsIgnoreCase(\"ORC\")) {\n\t\t\tisORCFile = ORCFile.isOrcFile(conf, path);\n\t\t} else if (specifiedFileType.equalsIgnoreCase(\"RC\")) {\n\t\t\tisRCFile = RCFile.isRCFile(conf, path);\n\t\t} else if (specifiedFileType.equalsIgnoreCase(\"Sequence\")) {\n\t\t\tisSequenceFile = SequenceFile.isFile(conf, path);\n\t\t} else if (specifiedFileType.equalsIgnoreCase(\"Parquet\")) {\n\t\t\tisParquetFile = ParquetFile.isParquetFile(conf, path);\n\t\t} else {\n\t\t\t// If the specifiedFileType is not one of the supported types, return false.\n\t\t\treturn false;\n\t\t}\n\t\tif (isORCFile || isRCFile || isSequenceFile || isParquetFile) {\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t} catch (Exception e) {\n\t\t// Log the error and throw an exception with a relevant error code and message.\n\t\tlog.error(e.getMessage(), e);\n\t\tthrow DataXException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, e);\n\t}\n}", "CodeBleu_score": 37.922550379233144}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\ttry {\n\t\tPath path = new Path(filepath);\n\t\tFileSystem fs = path.getFileSystem(new Configuration());\n\t\tif (fs.isFile(path)) {\n\t\t\tif (specifiedFileType.equalsIgnoreCase(FileType.ORC.name())) {\n\t\t\t\tif (isORCFile(fs, path)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t} else if (specifiedFileType.equalsIgnoreCase(FileType.RC.name())) {\n\t\t\t\tif (isRCFile(fs, path)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t} else if (specifiedFileType.equalsIgnoreCase(FileType.SEQUENCE.name())) {\n\t\t\t\tif (isSequenceFile(fs, path)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t} else if (specifiedFileType.equalsIgnoreCase(FileType.PARQUET.name())) {\n\t\t\t\tif (isParquetFile(fs, path)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t} else if (specifiedFileType.equalsIgnoreCase(FileType.CSV.name())) {\n\t\t\t\tif (isCSVFile(fs, path)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t} else if (specifiedFileType.equalsIgnoreCase(FileType.TEXT.name())) {\n\t\t\t\tif (isTextFile(fs, path)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} catch (Exception e) {\n\t\tLOG.error(e.getMessage(), e);\n\t\tthrow DataXException.asAddaxException(HdfsReaderErrorCode.HDFS_READER_FILE_TYPE_CHECK_ERROR, e);\n\t}\n\treturn false;\n}", "CodeBleu_score": 35.67824089037057}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t\tif (hConnection!= null) {\n\t\ttry {\n\t\t\thConnection.close()\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(\"Unable to close HBase connection. ${e.message}\", 10001)\n\t\t}\n\t}\n}", "CodeBleu_score": 34.286610538342785}, {"code": "public static void closeConnection(Connection hConnection){\n\t\tif (hConnection!= null) {\n\t\ttry {\n\t\t\thConnection.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(e.getMessage(), asAddaxErrorCode.HBASE_CLOSE_CONNECTION_ERROR);\n\t\t}\n\t}\n}", "CodeBleu_score": 42.13908069294148}, {"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection!= null) {\n\t\t\thConnection.close()\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new asAddaxException(\"Error closing HBase connection.\", ErrorCode.HBASE_05)\n\t}\n}", "CodeBleu_score": 38.65198707602681}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(asAddaxErrorCode.HBASE_ADMIN_CLOSE_ERROR, e);\n\t\t}\n\t}\n}", "CodeBleu_score": 46.35523994628766}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(asAddaxErrorCode.HBASE_ADMIN_CLOSE_ERROR, e);\n\t\t}\n\t}\n}", "CodeBleu_score": 46.35523994628766}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close()\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(asAddaxErrorCode.HBASE_CLOSE_ADMIN_ERROR, \"Failed to close HBase Admin: ${e.message}\", e)\n\t\t}\n\t}\n}", "CodeBleu_score": 42.041704193929235}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t// Get the row key from the cell\nString rowKey = Bytes.toString(CellUtil.cloneRow(cell));\n// Get the timestamp from the cell\nlong timestamp = cell.getTimestamp();\n// Get the column family name from the cell\nString familyName = Bytes.toString(CellUtil.cloneFamily(cell));\n// Get the qualifier name from the cell\nString qualifierName = Bytes.toString(CellUtil.cloneQualifier(cell));\n// Get the value from the cell\nString value = Bytes.toString(CellUtil.cloneValue(cell));\n// Get the type for the row key based on the mapping\nString rowKeyType = getTypeName(rowKey);\n// Get the type for the column value based on the mapping\nString valueType = getTypeName(value);\n// Add the row key column to the record\nrecord.addColumn(rowKeyType, rowKey);\n// Add the family name column to the record\nrecord.addColumn(\"family\", familyName);\n// Add the qualifier name column to the record\nrecord.addColumn(\"qualifier\", qualifierName);\n// Add the timestamp column to the record\nrecord.addColumn(\"timestamp\", timestamp);\n// Add the value column to the record\nrecord.addColumn(valueType, value);\n}", "CodeBleu_score": 21.62237115950891}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\n// get the row key\nbyte[] rowKey = cell.getRowArray();\nint rowKeyOffset = cell.getRowOffset();\nint rowKeyLength = cell.getRowLength();\n\n// get the timestamp\nlong timestamp = cell.getTimestamp();\n\n// get the column family\nbyte[] family = cell.getFamilyArray();\nint familyOffset = cell.getFamilyOffset();\nint familyLength = cell.getFamilyLength();\n\n// get the qualifier\nbyte[] qualifier = cell.getQualifierArray();\nint qualifierOffset = cell.getQualifierOffset();\nint qualifierLength = cell.getQualifierLength();\n\n// get the value\nbyte[] value = cell.getValueArray();\nint valueOffset = cell.getValueOffset();\nint valueLength = cell.getValueLength();\n\n// convert the row key to a string\nString rowKeyString = new String(rowKey, rowKeyOffset, rowKeyLength);\n\n// convert the timestamp to a string\nString timestampString = Long.toString(timestamp);\n\n// convert the column family to a string\nString familyString = new String(family, familyOffset, familyLength);\n\n// convert the qualifier to a string\nString qualifierString = new String(qualifier, qualifierOffset, qualifierLength);\n\n// convert the value to a string\nString valueString = new String(value, valueOffset, valueLength);\n\n// add the row key, family, qualifier, timestamp, and value as columns to the record\nrecord.add(rowKeyString, familyString, qualifierString, timestampString, valueString);\n}", "CodeBleu_score": 31.382797313022927}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\n// Get the row key from the cell and convert it to a String\nString rowKey = Bytes.toString(CellUtil.cloneRow(cell));\n\n// Get the timestamp from the cell and convert it to a Long\nlong timestamp = cell.getTimestamp();\n\n// Get the column family and qualifier from the cell and convert them to Strings\nString family = Bytes.toString(CellUtil.cloneFamily(cell));\nString qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));\n\n// Get the value from the cell and convert it to a String\nString value = Bytes.toString(CellUtil.cloneValue(cell));\n\n// Add the row key, family, qualifier, timestamp, and value as columns to the record\nrecord.set(rowKey, family, qualifier, timestamp, value);\n}", "CodeBleu_score": 16.04060636257626}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.getString(START_ROWKEY, \"\");\n\tif (isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t} else {\n\t\tif (isBinary(startRowkey)) {\n\t\t\treturn stringToBytes(startRowkey);\n\t\t} else {\n\t\t\treturn Bytes.toBytes(startRowkey);\n\t\t}\n\t}\n}", "CodeBleu_score": 32.49988660646721}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(HBaseConstants.HBASE_START_ROWKEY);\n\tif (isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t}\n\tif (configuration.get(HBaseConstants.HBASE_ROWKEY_BINARY)) {\n\t\treturn stringToBytes(startRowkey);\n\t}\n\treturn startRowkey.getBytes();\n}", "CodeBleu_score": 41.51890767709773}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(USER_START_ROWKEY);\n\tif (isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t}\n\tif (configuration.getBoolean(ROWKEY_BINARY, false)) {\n\t\treturn stringToBytes(startRowkey);\n\t} else {\n\t\treturn Bytes.toBytes(startRowkey);\n\t}\n}", "CodeBleu_score": 32.29007990871088}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(HBASE_STARTROWKEY_KEY);\n\tif (isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t} else {\n\t\treturn toBytesBinary(startRowkey);\n\t}\n}", "CodeBleu_score": 41.52662564485582}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(START_ROWKEY)\n\tif (isBlank(startRowkey)) {\n\t\treturn new byte[0]\n\t}\n\treturn toBytesBinary(startRowkey)\n}", "CodeBleu_score": 42.37159713026865}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowKey = configuration.get(HBaseConstants.START_ROW_KEY);\n\tif (StringUtils.isBlank(startRowKey)) {\n\t\treturn new byte[0];\n\t}\n\treturn Bytes.toBytesBinary(startRowKey);\n}", "CodeBleu_score": 52.27733868926634}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.key = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders();\n\trecord.headers().forEach(header -> headers.put(header.key(), header.value()));\n\tthis.data = record.value();\n}", "CodeBleu_score": 51.822963328742354}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tif (record == null) {\n\t\tthrow new IllegalArgumentException(\"record cannot be null\");\n\t}\n\tthis.key = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders();\n\trecord.headers().forEach(header -> this.headers.put(header.key(), header.value()));\n\tthis.data = record.value();\n}", "CodeBleu_score": 50.51850499373196}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.key = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders();\n\trecord.headers().forEach(header -> this.headers.put(header.key(), header.value()));\n\tthis.data = record.value();\n}", "CodeBleu_score": 51.36196100084581}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\tKafkaSettings kafkaSettings = settings.getKafka();\n\tString clientId = getServiceId() + \"-transport-notifications-producer\";\n\tString defaultTopic = getNotificationsTopic();\n\treturn new KafkaProducerTemplate<>(kafkaSettings, clientId, defaultTopic, admin);\n}", "CodeBleu_score": 34.86230060715958}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbQueueProducer<>(\n\t\t\tkafkaTemplate,\n\t\t\tadmin,\n\t\t\tclientId,\n\t\t\tsettings.getNotificationsTopic(),\n\t\t\tToTransportMsg.class\n\t);\n\treturn producer;\n}", "CodeBleu_score": 28.763763170498684}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\treturn createTransportNotificationsMsgProducer(getServiceId(), getNotificationsTopic());\n}", "CodeBleu_score": 11.044118324288297}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tTbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> template = new TbKafkaConsumerTemplate<>(\n\t\t\tkafkaTemplate,\n\t\t\tTbProtoQueueMsg.class,\n\t\t\tToCoreNotificationMsg.class,\n\t\t\tdecoder,\n\t\t\tTbProtoQueueMsg.class,\n\t\t\tToCoreNotificationMsg.class,\n\t\t\tdecoder,\n\t\t\tadmin,\n\t\t\tstatsService,\n\t\t\tsettings.getToCoreNotificationsTopic(),\n\t\t\tsettings.getKafkaClientId(),\n\t\t\tsettings.getKafkaGroupId());\n\ttemplate.setClientId(settings.getKafkaClientId());\n\ttemplate.setGroupId(settings.getKafkaGroupId());\n\ttemplate.setTopic(settings.getToCoreNotificationsTopic());\n\ttemplate.setDecoder(decoder);\n\ttemplate.setAdmin(admin);\n\ttemplate.setStatisticsService(statsService);\n\treturn template;\n}", "CodeBleu_score": 37.654330352741695}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tTbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate = new TbKafkaConsumerTemplate<>(\n\t\t\tkafkaConsumerSettings,\n\t\t\tbuildTopicName(getNotificationsTopic()),\n\t\t\tclientId,\n\t\t\tgroupId,\n\t\t\tToCoreNotificationMsg.class,\n\t\t\tadmin,\n\t\t\tstatsService);\n\tconsumerTemplate.setDecoder(ToCoreNotificationMsg::parseFrom);\n\treturn consumerTemplate;\n}", "CodeBleu_score": 23.718244860535698}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tTbKafkaConsumerTemplate<String, ToCoreNotificationMsg> consumerTemplate = new TbKafkaConsumerTemplate<>(\n\t\t\tsettings.getToCoreNotificationsTopic(),\n\t\t\tsettings.getToCoreNotificationsClientId(),\n\t\t\tsettings.getToCoreNotificationsGroupId(),\n\t\t\tnew ToCoreNotificationMsgDecoder(),\n\t\t\tadmin,\n\t\t\tstatsService\n\t);\n\tconsumerTemplate.setHeadersDecoder(new TbProtoQueueMsgHeadersDecoder());\n\treturn consumerTemplate;\n}", "CodeBleu_score": 28.48504178301816}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames) {\n\t\ttopicNames.each { String topicName ->\n\t\t\tif (!kafkaAdminService.topicExists(topicName)) {\n\t\t\t\tkafkaAdminService.createTopic(topicName)\n\t\t\t}\n\t\t\tkafkaConsumer.subscribe(Collections.singleton(topicName))\n\t\t}\n\t} else {\n\t\tlog.info(\"No topics provided for subscription by ${this}\")\n\t\tkafkaConsumer.unsubscribe()\n\t}\n}", "CodeBleu_score": 48.98423047917602}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (!topicNames.isEmpty()) {\n\t\ttopicNames.each { topicName ->\n\t\t\tif (!this.adminClient.listTopics().names().get().contains(topicName)) {\n\t\t\t\tthis.adminClient.createTopics(Collections.singleton(new NewTopic(topicName, 1, (short) 1))).all().get()\n\t\t\t}\n\t\t}\n\t\tthis.consumer.subscribe(topicNames)\n\t\tthis.logger.info(\"Subscribed to topics: ${topicNames}\")\n\t} else {\n\t\tthis.consumer.unsubscribe()\n\t\tthis.logger.info(\"Unsubscribed from all topics\")\n\t}\n}", "CodeBleu_score": 51.00463543228242}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (!topicNames.isEmpty()) {\n\t\t// Ensure all topics exist\n\t\ttopicNames.each { topicName ->\n\t\t\tif (!this.topicExists(topicName)) {\n\t\t\t\tthis.createTopic(topicName)\n\t\t\t}\n\t\t}\n\t\t// Subscribe to all topics\n\t\tthis.subscribe(topicNames)\n\t} else {\n\t\tthis.log.info(\"No topics provided, unsubscribing from all topics\")\n\t\tthis.unsubscribe()\n\t}\n}", "CodeBleu_score": 54.58822987597631}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tStopWatch stopWatch = new StopWatch()\n\tstopWatch.start()\n\tlogger.trace(\"Polling topic {} for {} ms\", topic, durationInMillis)\n\tList<ConsumerRecord<String, byte[]>> records = consumer.poll(ofMillis(durationInMillis)).records(topic)\n\tstopWatch.stop()\n\tlogger.trace(\"Polled {} records in {} ms\", records.size(), stopWatch.getTotalTimeMillis())\n\treturn records.isEmpty()? emptyList() : records\n}", "CodeBleu_score": 47.080673126683}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tdef topic = getTopic()\n\tdef start = System.currentTimeMillis()\n\ttrace(\"Polling topic $topic for $durationInMillis ms\")\n\tdef records = consumer.poll(durationInMillis)\n\tdef end = System.currentTimeMillis()\n\tdef totalTime = end - start\n\ttrace(\"Total time taken to poll topic $topic: $totalTime ms\")\n\tif (records.isEmpty()) {\n\t\ttrace(\"No records found in topic $topic\")\n\t\temptyList()\n\t} else {\n\t\tdef recordsList = records.iterator().collect { record ->\n\t\t\ttrace(\"Found record in topic $topic: $record\")\n\t\t\trecord\n\t\t}\n\t\ttrace(\"Found ${recordsList.size()} records in topic $topic\")\n\t\trecordsList\n\t}\n}", "CodeBleu_score": 42.814381734719746}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tlog.trace(\"doPoll: topic={}, durationInMillis={}\", topic, durationInMillis)\n\tdef stopwatch = Stopwatch.createStarted()\n\tlog.debug(\"doPoll: topic={}, durationInMillis={}\", topic, durationInMillis)\n\tdef records = consumer.poll(durationInMillis)\n\tstopwatch.stop()\n\tlog.debug(\"doPoll: topic={}, durationInMillis={}, totalTimeMillis={}\", topic, durationInMillis, stopwatch.getTotalTimeMillis())\n\tif (records.isEmpty()) {\n\t\tlog.debug(\"doPoll: topic={}, durationInMillis={}, totalTimeMillis={}, isEmpty={}\", topic, durationInMillis, stopwatch.getTotalTimeMillis(), true)\n\t\treturn Collections.emptyList()\n\t}\n\tlog.debug(\"doPoll: topic={}, durationInMillis={}, totalTimeMillis={}, isEmpty={}\", topic, durationInMillis, stopwatch.getTotalTimeMillis(), false)\n\treturn records.stream().collect(Collectors.toList())\n}", "CodeBleu_score": 43.046281714049314}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\tif (initError!= null) {\n\t\tctx.tellFailure(initError);\n\t\treturn;\n\t}\n\n\tString topic = topicPattern.processPattern(msg);\n\tString key = keyPattern.processPattern(msg);\n\tif (topic == null || topic.isEmpty()) {\n\t\tctx.tellFailure(\"Topic is empty\");\n\t\treturn;\n\t}\n\tif (key == null || key.isEmpty()) {\n\t\tctx.tellFailure(\"Key is empty\");\n\t\treturn;\n\t}\n\n\tString message = msg.getMessage();\n\tctx.executeAsync(() -> {\n\t\ttry {\n\t\t\tpublish(topic, key, message);\n\t\t} catch (Exception e) {\n\t\t\tctx.tellFailure(e);\n\t\t}\n\t});\n}", "CodeBleu_score": 30.193570194448682}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\tString topicPattern = getTopicPattern(ctx, msg);\n\tString keyPattern = getKeyPattern(ctx, msg);\n\tString message = getMessage(ctx, msg);\n\tif (topicPattern == null || message == null) {\n\t\treturn;\n\t}\n\texecuteAsync(ctx, new AsyncTask(topicPattern, keyPattern, message));\n}", "CodeBleu_score": 15.739215409657753}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\tif (initError!= null) {\n\t\tctx.tellFailure(initError);\n\t\treturn;\n\t}\n\texecuteAsync(ctx, msg);\n}", "CodeBleu_score": 6.322811039288838}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\tString ctxId = ctx.getSelfId();\n\tString msgId = msg.getMsgId();\n\tString msgData = msg.getData();\n\tString msgType = msg.getMsgType();\n\tString msgSource = msg.getSource();\n\tString msgSourceType = msg.getSourceType();\n\tString msgMetaData = msg.getMetaData();\n\tString msgMetaDataKey = msg.getMetaDataKey();\n\tString msgMetaDataValue = msg.getMetaDataValue();\n\n\ttry {\n\t\tif (msgMetaData!= null) {\n\t\t\tMap<String, String> metaData = new HashMap<>();\n\t\t\tmsg.forEach(new TbMsg.TbMsgConsumer() {\n\t\t\t\t@Override\n\t\t\t\tpublic void accept(String key, String value) {\n\t\t\t\t\tmetaData.put(key, value);\n\t\t\t\t}\n\t\t\t});\n\n\t\t\tHeaders headers = new RecordHeaders();\n\t\t\tmetaData.forEach((key, value) -> headers.add(new RecordHeader(key, value.getBytes())));\n\t\t\tproducer.send(new ProducerRecord<>(topic, key, msgData.getBytes()), new Callback() {\n\t\t\t\t@Override\n\t\t\t\tpublic void onCompletion(RecordMetadata metadata, Exception exception) {\n\t\t\t\t\tif (exception!= null) {\n\t\t\t\t\t\tlog.debug(\"[{}] [{}] [{}] [{}] [{}] [{}] [{}] [{}]\", ctxId, msgId, msgType, msgSource, msgSourceType, msgMetaDataKey, msgMetaDataValue, exception.getMessage());\n\t\t\t\t\t} else {\n\t\t\t\t\t\tlog.debug(\"[{}] [{}] [{}] [{}] [{}] [{}] [{}] [{}] [{}] [{}]\", ctxId, msgId, msgType, msgSource, msgSourceType, msgMetaDataKey, msgMetaDataValue, metadata.topic(), metadata.partition(), metadata.offset());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}, headers);\n\t\t} else {\n\t\t\tproducer.send(new ProducerRecord<>(topic, key, msgData.getBytes()), new Callback() {\n\t\t\t\t@Override\n\t\t\t\tpublic void onCompletion(RecordMetadata metadata, Exception exception) {\n\t\t\t\t\tif (exception!= null) {\n\t\t\t\t\t\tlog.debug(\"[{}] [{}] [{}] [{}] [{}] [{}] [{}] [{}]\", ctxId, msgId, msgType, msgSource, msgSourceType, msgMetaDataKey, msgMetaDataValue, exception.getMessage());\n\t\t\t\t\t} else {\n\t\t\t\t\t\tlog.debug(\"[{}] [{}]", "CodeBleu_score": 29.892473344088767}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\ttry {\n\t\tbyte[] data = msg.getData();\n\t\tif (ctx.getMetaData().isEmpty()) {\n\t\t\tctx.getProducer().send(new ProducerRecord<String, byte[]>(topic, key, data), new TbProducerCallback(ctx, msg));\n\t\t} else {\n\t\t\tMap<String, String> headers = new HashMap<>();\n\t\t\tctx.getMetaData().forEach((k, v) -> headers.put(k, v.toString()));\n\t\t\tctx.getProducer().send(new ProducerRecord<String, byte[]>(topic, key, data, headers), new TbProducerCallback(ctx, msg));\n\t\t}\n\t} catch (Exception e) {\n\t\tctx.debug(ctx.getSelfId(), \"Failed to publish message to Kafka topic \" + topic + \" with key \" + key + \" and data \" + msg.getData());\n\t}\n}", "CodeBleu_score": 37.39637310211226}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\ttry {\n\t\tif (ctx.getMetaData().isEmpty()) {\n\t\t\tsend(ctx, msg, topic, key);\n\t\t} else {\n\t\t\tMap<String, String> metaData = ctx.getMetaData();\n\t\t\tList<Header> headers = new ArrayList<>();\n\t\t\tmetaData.forEach((k, v) -> headers.add(new RecordHeader(k, v.getBytes())));\n\t\t\tsend(ctx, msg, topic, key, headers);\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.debug(\"[{}] [{}] Failed to publish message: {}\", ctx.getCid(), msg.getCid(), e.getMessage());\n\t}\n}", "CodeBleu_score": 38.32169217284645}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\t\tif (producer!= null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Failed to close Kafka producer\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 61.31318402746789}, {"code": "public void destroy(){\n\t\tif (producer!= null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Failed to close producer\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 61.14510470097976}, {"code": "public void destroy(){\n\t\tif (producer!= null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Failed to close producer\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 57.980179354015036}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> builder = new KafkaProducerTemplateBuilder<>();\n\tbuilder.setKafkaSettings(kafkaSettings);\n\tbuilder.setClientId(serviceInfoProvider.getServiceId());\n\tbuilder.setDefaultTopic(defaultTopic);\n\tbuilder.setAdmin(admin);\n\treturn builder.build();\n}", "CodeBleu_score": 40.23496059306427}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tKafkaProducerBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> builder = new KafkaProducerBuilder<TbProtoQueueMsg<ToRuleEngineMsg>>()\n\t\t\t.kafkaSettings(kafkaSettings)\n\t\t\t.clientId(clientId)\n\t\t\t.defaultTopic(defaultTopic)\n\t\t\t.admin(admin);\n\treturn builder.build();\n}", "CodeBleu_score": 34.636139237075334}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tKafkaProducerBuilder<String, TbProtoQueueMsg<ToRuleEngineMsg>> builder = new KafkaProducerBuilder<>(settings);\n\tbuilder.clientId(clientId);\n\tbuilder.defaultTopic(defaultTopic);\n\tbuilder.admin(admin);\n\treturn builder.build();\n}", "CodeBleu_score": 33.691578581692845}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\t\t// Set the timeout duration based on the Kafka response timeout configuration\n\tDuration timeoutDuration = Duration.ofMillis(kafkaConsumer.getKafkaResponseTimeoutMs());\n\n\t// Schedule a task with a fixed delay\n\tscheduler.scheduleWithFixedDelay(new Runnable() {\n\t\t@Override\n\t\tpublic void run() {\n\t\t\t// Check if statistics printing is required\n\t\t\tif (isStatsPrintRequired()) {\n\t\t\t\t// For each monitored consumer group, retrieve and compare group offsets and end offsets to identify topics with lag\n\t\t\t\tfor (String groupId : consumerGroups) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t// Retrieve group offsets and end offsets\n\t\t\t\t\t\tMap<TopicPartition, OffsetAndMetadata> groupOffsets = kafkaConsumer.partitionsToOffsetAndMetadata(groupId);\n\t\t\t\t\t\tMap<TopicPartition, Long> endOffsets = kafkaConsumer.endOffsets(groupOffsets.keySet());\n\n\t\t\t\t\t\t// Identify topics with lag\n\t\t\t\t\t\tList<TopicPartition> laggingTopics = new ArrayList<>();\n\t\t\t\t\t\tfor (Map.Entry<TopicPartition, OffsetAndMetadata> entry : groupOffsets.entrySet()) {\n\t\t\t\t\t\t\tTopicPartition topicPartition = entry.getKey();\n\t\t\t\t\t\t\tOffsetAndMetadata offsetAndMetadata = entry.getValue();\n\t\t\t\t\t\t\tLong endOffset = endOffsets.get(topicPartition);\n\t\t\t\t\t\t\tif (endOffset!= null && offsetAndMetadata.offset() < endOffset) {\n\t\t\t\t\t\t\t\tlaggingTopics.add(topicPartition);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// Log the details of lagging topics\n\t\t\t\t\t\tif (!laggingTopics.isEmpty()) {\n\t\t\t\t\t\t\tlog.info(\"Consumer group {} has lagging topics: {}\", groupId, laggingTopics);\n\t\t\t\t\t\t}\n\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\t// Log a warning with the group ID and error message, along with a detailed error trace\n\t\t\t\t\t\tlog.warn(\"Error while retrieving consumer group offsets for group {}: {}\", groupId, e.getMessage(), e);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}, timeoutDuration.toMillis(), getPrintIntervalMs(), TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 37.61830049346302}, {"code": "private void startLogScheduling(){\n\t\t// Get the Kafka response timeout in milliseconds\n\tlong kafkaResponseTimeoutMs = getKafkaResponseTimeoutMs();\n\t// Schedule a task with a fixed delay based on the Kafka response timeout\n\tscheduleWithFixedDelay(kafkaResponseTimeoutMs, kafkaResponseTimeoutMs, TimeUnit.MILLISECONDS, () -> {\n\t\t// Check if statistics printing is required\n\t\tif (isStatsPrintRequired()) {\n\t\t\t// For each monitored consumer group\n\t\t\tfor (String groupId : getMonitoredGroups().keySet()) {\n\t\t\t\ttry {\n\t\t\t\t\t// Retrieve group offsets and end offsets\n\t\t\t\t\tMap<TopicPartition, OffsetAndMetadata> groupOffsets = listConsumerGroupOffsets(groupId);\n\t\t\t\t\tMap<TopicPartition, Long> endOffsets = endOffsets(groupOffsets.keySet());\n\t\t\t\t\t// Identify topics with lag\n\t\t\t\t\tMap<TopicPartition, Long> topicsWithLag = getTopicsStatsWithLag(groupOffsets, endOffsets);\n\t\t\t\t\t// If lagging topics are found, log their details\n\t\t\t\t\tif (!topicsWithLag.isEmpty()) {\n\t\t\t\t\t\tlog.info(\"Consumer group {} has lagging topics: {}\", groupId, topicsWithLag);\n\t\t\t\t\t}\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t// Log a warning with the group ID and error message, along with a detailed error trace\n\t\t\t\t\tlog.warn(\"Error while retrieving consumer group offsets for group {}: {}\", groupId, e.getMessage(), e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n}", "CodeBleu_score": 27.856113495230083}, {"code": "private void startLogScheduling(){\n\t\t// Set the timeout duration based on the Kafka response timeout configuration\n\tDuration timeoutDuration = Duration.ofMillis(config.getLong(KafkaConfig.KAFKA_RESPONSE_TIMEOUT_MS_CONFIG));\n\t// Schedule a task with a fixed delay\n\tlogTask = scheduler.scheduleWithFixedDelay(() -> {\n\t\t// Check if statistics printing is required\n\t\tif (isStatsPrintRequired()) {\n\t\t\t// For each monitored consumer group\n\t\t\tfor (String groupId : consumerGroups.keySet()) {\n\t\t\t\ttry {\n\t\t\t\t\t// Retrieve and compare group offsets and end offsets to identify topics with lag\n\t\t\t\t\tMap<TopicPartition, OffsetAndMetadata> offsets = listConsumerGroupOffsets(groupId);\n\t\t\t\t\tMap<TopicPartition, Long> endOffsets = adminClient.endOffsets(offsets.keySet());\n\t\t\t\t\tif (!offsets.isEmpty()) {\n\t\t\t\t\t\t// If lagging topics are found, log their details\n\t\t\t\t\t\tfor (TopicPartition topicPartition : offsets.keySet()) {\n\t\t\t\t\t\t\tOffsetAndMetadata offsetAndMetadata = offsets.get(topicPartition);\n\t\t\t\t\t\t\tlong endOffset = endOffsets.get(topicPartition);\n\t\t\t\t\t\t\tif (offsetAndMetadata.offset() < endOffset) {\n\t\t\t\t\t\t\t\tlog.info(\"Topic: {} Partition: {} Offset: {} End Offset: {} Lag: {}\", topicPartition.topic(), topicPartition.partition(), offsetAndMetadata.offset(), endOffset, endOffset - offsetAndMetadata.offset());\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t// If an exception occurs, log a warning with the group ID and error message, along with a detailed error trace\n\t\t\t\t\tlog.warn(\"Error while retrieving consumer group offsets for group {}: {}\", groupId, e.getMessage(), e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}, timeoutDuration.toMillis(), printIntervalMs, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 34.288181863887154}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\t\tProperties props = toProps()\n\tprops.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers)\n\tprops.put(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, retryBackoffMs)\n\treturn props\n}", "CodeBleu_score": 49.40182566161655}, {"code": "protected Properties toAdminProps(){\n\t\tProperties props = toProps()\n\tprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers)\n\tprops.put(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, retryBackoffMs)\n\tprops\n}", "CodeBleu_score": 51.63212629051534}, {"code": "protected Properties toAdminProps(){\n\t\tProperties props = toProps()\n\tprops.setProperty(\"bootstrap.servers\", bootstrapServers)\n\tprops.setProperty(\"retries\", retries.toString())\n\treturn props\n}", "CodeBleu_score": 37.55765217661956}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tString[] tags = getTags(metric);\n\tMetricEvent event = new MetricEvent(scopedName, tags);\n\tif (metric instanceof Counter) {\n\t\tcounters.put(scopedName, event);\n\t} else if (metric instanceof Gauge) {\n\t\tgauges.put(scopedName, event);\n\t} else if (metric instanceof Histogram) {\n\t\thistograms.put(scopedName, event);\n\t} else if (metric instanceof Meter) {\n\t\tmeters.put(scopedName, event);\n\t} else {\n\t\twarn(\"Metric type %s is not supported.\", metric.getClass());\n\t}\n}", "CodeBleu_score": 45.463464272034926}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tList<Tag> tags = getTags(metric, metricName, group);\n\tMetricEvent event = new MetricEvent(scopedName, tags);\n\tif (metric instanceof Counter) {\n\t\tcounters.put(scopedName, event);\n\t} else if (metric instanceof Gauge) {\n\t\tgauges.put(scopedName, event);\n\t} else if (metric instanceof Histogram) {\n\t\thistograms.put(scopedName, event);\n\t} else if (metric instanceof Meter) {\n\t\tmeters.put(scopedName, event);\n\t} else {\n\t\twarn(\"Metric type not supported: \" + metric.getClass().getName());\n\t}\n}", "CodeBleu_score": 47.992874581927886}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tList<Tag> tags = getTags(metric, group);\n\tMetricEvent event = new MetricEvent(scopedName, tags);\n\tif (metric instanceof Counter) {\n\t\tcounters.put(scopedName, (Counter) metric);\n\t\tcounterEvents.put(scopedName, event);\n\t} else if (metric instanceof Gauge) {\n\t\tgauges.put(scopedName, (Gauge) metric);\n\t\tgaugeEvents.put(scopedName, event);\n\t} else if (metric instanceof Histogram) {\n\t\thistograms.put(scopedName, (Histogram) metric);\n\t\thistogramEvents.put(scopedName, event);\n\t} else if (metric instanceof Meter) {\n\t\tmeters.put(scopedName, (Meter) metric);\n\t\tmeterEvents.put(scopedName, event);\n\t} else {\n\t\twarn(\"Metric type not supported: \" + metric.getClass().getName());\n\t}\n}", "CodeBleu_score": 49.51735996611298}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tdef value = gauge.getValue()\n\tif (metricEvent.getFields()) {\n\t\tmetricEvent.addField(field, value)\n\t} else {\n\t\tdef fields = [:]\n\t\tfields.put(field, value)\n\t\tmetricEvent.setFields(fields)\n\t}\n\treturn metricEvent\n}", "CodeBleu_score": 24.535819636509704}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (metricEvent.getFields()!= null) {\n\t\tmetricEvent.getFields().put(field, convert(gauge.getValue()))\n\t} else {\n\t\tmetricEvent.setFields(Collections.singletonMap(field, convert(gauge.getValue())))\n\t}\n\tmetricEvent\n}", "CodeBleu_score": 16.11323768211496}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tdef value = gauge.getValue()\n\tif (metricEvent.getFields()) {\n\t\tmetricEvent.addField(field, value)\n\t} else {\n\t\tdef fields = new HashMap<String, Object>()\n\t\tfields.put(field, value)\n\t\tmetricEvent.setFields(fields)\n\t}\n\treturn metricEvent\n}", "CodeBleu_score": 31.522699687669785}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tdef lag = gauge.getValue()\n\tdef lagComponents = lag.split(':')\n\tdef currentOffset = lagComponents[0]\n\tdef dataTimestamp = lagComponents[1]\n\tdef committedOffset = lagComponents[2]\n\n\tdef kafkaLagTimes = metricEvent.getFields().get('kafkaLagTimes')\n\tif (kafkaLagTimes == null) {\n\t\tkafkaLagTimes = new HashMap<>()\n\t}\n\n\tdef key = \"${metricEvent.getTags().get('topic')}@${metricEvent.getTags().get('partition')}\"\n\tdef lastKafkaLagTime = kafkaLagTimes.get(key)\n\tif (lastKafkaLagTime == null || lastKafkaLagTime!= dataTimestamp) {\n\t\tkafkaLagTimes.put(key, dataTimestamp)\n\n\t\tmetricEvent.getFields().put('currentOffset', currentOffset)\n\t\tmetricEvent.getFields().put('dataTimestamp', dataTimestamp)\n\t\tmetricEvent.getFields().put('committedOffset', committedOffset)\n\t\tmetricEvent.getFields().put('kafkaLagTimes', kafkaLagTimes)\n\n\t\tmetricEvent.setTimestamp(timestamp)\n\t}\n\n\treturn metricEvent\n}", "CodeBleu_score": 31.717504186654594}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tif (gauge == null) {\n\t\treturn metricEvent\n\t}\n\tString metricName = gauge.name.toString()\n\tString[] metricNameComponents = metricName.split(METRIC_NAME_SPLIT_REGEX)\n\tif (metricNameComponents.length < 4) {\n\t\treturn metricEvent\n\t}\n\tString topic = metricNameComponents[2]\n\tString partition = metricNameComponents[3]\n\tString[] tags = metricEvent.getTags()\n\ttags = Arrays.copyOf(tags, tags.length + 2)\n\ttags[tags.length - 2] = \"topic\"\n\ttags[tags.length - 1] = topic\n\tmetricEvent.setTags(tags)\n\tmetricEvent.setFields(Collections.singletonMap(\"partition\", Integer.valueOf(partition)))\n\tLong currentOffset = (Long) gauge.value\n\tLong committedOffset = kafkaLagTimes.get(metricName)\n\tif (committedOffset == null || committedOffset!= currentOffset) {\n\t\tkafkaLagTimes.put(metricName, currentOffset)\n\t\tmetricEvent.setTimestamp(timestamp)\n\t}\n\treturn metricEvent\n}", "CodeBleu_score": 29.266323992779686}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\t// get the Kafka metric value\n\tdef value = gauge.getValue()\n\n\t// extract the topic, partition, and broker from the metric name\n\tdef topic = gauge.metricName.name.split(\"-\")[0]\n\tdef partition = gauge.metricName.name.split(\"-\")[1]\n\tdef broker = gauge.metricName.name.split(\"-\")[2]\n\n\t// get the current offset, lag, and committed offset\n\tdef currentOffset = value.get(\"current-offset\")\n\tdef lag = value.get(\"lag\")\n\tdef committedOffset = value.get(\"committed-offset\")\n\n\t// check for changes in the Kafka lag metrics to avoid duplicates\n\tif (kafkaLagTimes.containsKey(topic) && kafkaLagTimes.get(topic).containsKey(partition) && kafkaLagTimes.get(topic).get(partition).containsKey(broker)) {\n\t\tdef lastTimestamp = kafkaLagTimes.get(topic).get(partition).get(broker)\n\t\tif (timestamp == lastTimestamp) {\n\t\t\treturn metricEvent\n\t\t}\n\t}\n\n\t// update the kafkaLagTimes map with the current timestamp\n\tkafkaLagTimes.putIfAbsent(topic, new HashMap<>())\n\tkafkaLagTimes.get(topic).putIfAbsent(partition, new HashMap<>())\n\tkafkaLagTimes.get(topic).get(partition).put(broker, timestamp)\n\n\t// set the event's timestamp\n\tmetricEvent.setTimestamp(timestamp)\n\n\t// update the MetricEvent's fields with the current offsets, data timestamp, and committed offsets\n\tmetricEvent.setFields([\n\t\t\"topic\": topic,\n\t\t\"partition\": partition,\n\t\t\"broker\": broker,\n\t\t\"currentOffset\": currentOffset,\n\t\t\"lag\": lag,\n\t\t\"committedOffset\": committedOffset,\n\t\t\"timestamp\": timestamp\n\t])\n\n\treturn metricEvent\n}", "CodeBleu_score": 35.684236325907}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tMap<String, Object> globalJobParameters = getGlobalJobParameters();\n\tProperties props = buildKafkaProps(globalJobParameters);\n\tFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), props);\n\tif (time!= null) {\n\t\tconsumer.setStartFromSpecificOffsets(buildOffsetByTime(time));\n\t}\n\treturn env.addSource(consumer);\n}", "CodeBleu_score": 44.687606760028615}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tMap<String, Object> globalJobParameters = getGlobalJobParameters(env);\n\tProperties kafkaProps = buildKafkaProps(globalJobParameters);\n\tFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), kafkaProps);\n\tif (time!= null) {\n\t\tMap<KafkaTopicPartition, Long> startOffsets = buildOffsetByTime(globalJobParameters, topic, time);\n\t\tconsumer.setStartFromSpecificOffsets(startOffsets);\n\t}\n\treturn addSource(env, consumer);\n}", "CodeBleu_score": 53.002915175884354}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\t// get global job parameters\n\tGlobalJobParameters gjp = getGlobalJobParameters(env);\n\t// build kafka props\n\tProperties props = buildKafkaProps(gjp);\n\t// create kafka consumer\n\tFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, buildSchema(), props);\n\t// if start time is provided, set consumer to start from specific offsets\n\tif (time!= null) {\n\t\tsetStartFromSpecificOffsets(consumer, buildOffsetByTime(time, gjp.getKafkaServer()));\n\t}\n\t// add consumer as source to the StreamExecutionEnvironment\n\treturn env.addSource(consumer);\n}", "CodeBleu_score": 40.90821459757721}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tprops.put(ConsumerConfig.GROUP_ID_CONFIG, time.toString())\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)\n\tList<PartitionInfo> partitions = consumer.partitionsFor(parameterTool.getRequired(\"topic\"))\n\tMap<TopicPartition, Long> topicPartitionLongMap = new HashMap<>()\n\tfor (PartitionInfo partition : partitions) {\n\t\ttopicPartitionLongMap.put(new TopicPartition(partition.topic(), partition.partition()), time)\n\t}\n\tMap<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(topicPartitionLongMap)\n\tconsumer.close()\n\tMap<KafkaTopicPartition, Long> partitionOffsetMap = new HashMap<>()\n\toffsets.forEach((topicPartition, offsetAndTimestamp) -> {\n\t\tif (offsetAndTimestamp!= null) {\n\t\t\tpartitionOffsetMap.put(new KafkaTopicPartition(topicPartition.topic(), topicPartition.partition()), offsetAndTimestamp.offset())\n\t\t}\n\t})\n\treturn partitionOffsetMap\n}", "CodeBleu_score": 46.606738145446144}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tprops.put(ConsumerConfig.GROUP_ID_CONFIG, time.toString());\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\tList<PartitionInfo> partitionInfos = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\n\tMap<TopicPartition, Long> topicPartitionLongMap = new HashMap<>();\n\tpartitionInfos.forEach(partitionInfo -> topicPartitionLongMap.put(new TopicPartition(partitionInfo.topic(), partitionInfo.partition()), time));\n\tMap<TopicPartition, OffsetAndTimestamp> offsetAndTimestampMap = consumer.offsetsForTimes(topicPartitionLongMap);\n\tconsumer.close();\n\treturn offsetAndTimestampMap.entrySet().stream().collect(Collectors.toMap(entry -> new KafkaTopicPartition(entry.getKey().topic(), entry.getKey().partition()), Map.Entry::getValue, (e1, e2) -> e1, LinkedHashMap::new));\n}", "CodeBleu_score": 46.416847741486514}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\tString topic = parameterTool.getRequired(\"topic\")\nprops.put(ConsumerConfig.GROUP_ID_CONFIG, \"buildOffsetByTime-\" + time)\nKafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(props)\nList<PartitionInfo> partitionInfos = consumer.partitionsFor(topic)\nMap<TopicPartition, Long> partitionTimestamps = partitionInfos.collectEntries {\nnew AbstractMap.SimpleEntry<>(new TopicPartition(it.topic(), it.partition()), time)\n}\nMap<KafkaTopicPartition, Long> offsets = consumer.offsetsForTimes(partitionTimestamps).collectEntries {\nnew AbstractMap.SimpleEntry<>(new KafkaTopicPartition(it.key().topic(), it.key().partition()), it.value().offset())\n}\nconsumer.close()\noffsets\n}", "CodeBleu_score": 40.173039262597335}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties props = new Properties();\n\tprops.put(\"bootstrap.servers\", \"localhost:9092\");\n\tprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n\tProducer<String, String> producer = new KafkaProducer<>(props);\n\n\tMetricEvent event = new MetricEvent();\n\tevent.setTimestamp(System.currentTimeMillis());\n\tevent.setName(\"my-metric\");\n\tevent.setTags(new HashMap<String, String>() {{ put(\"tag1\", \"value1\"); put(\"tag2\", \"value2\"); }});\n\tevent.setFields(new HashMap<String, Object>() {{ put(\"field1\", 123); put(\"field2\", \"value2\"); }});\n\n\tProducerRecord<String, String> record = new ProducerRecord<>(\"my-topic\", event.toJson());\n\tproducer.send(record);\n\n\tSystem.out.println(\"Sent data: \" + event.toJson());\n\tproducer.flush();\n}", "CodeBleu_score": 46.40341662407575}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t\t// Set up Kafka producer properties\n\tProperties props = new Properties();\n\tprops.put(\"bootstrap.servers\", \"localhost:9092\");\n\tprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n\t// Create Kafka producer\n\tKafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n\t// Create a MetricEvent\n\tMetricEvent metricEvent = new MetricEvent();\n\tmetricEvent.setTimestamp(System.currentTimeMillis());\n\tmetricEvent.setName(\"metric_name\");\n\tmetricEvent.setTags(Collections.singletonMap(\"tag_key\", \"tag_value\"));\n\tmetricEvent.setFields(Collections.singletonMap(\"field_key\", \"field_value\"));\n\n\t// Serialize the MetricEvent and send it to the Kafka topic\n\tProducerRecord<String, String> record = new ProducerRecord<>(\"topic_name\", metricEvent.toJson());\n\tproducer.send(record);\n\n\t// Print the sent data and flush the producer to ensure all data is sent\n\tSystem.out.println(\"Sent data: \" + metricEvent.toJson());\n\tproducer.flush();\n}", "CodeBleu_score": 46.097689964871414}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties props = new Properties();\n\tprops.put(\"bootstrap.servers\", \"localhost:9092\");\n\tprops.put(\"acks\", \"all\");\n\tprops.put(\"retries\", 0);\n\tprops.put(\"batch.size\", 16384);\n\tprops.put(\"linger.ms\", 1);\n\tprops.put(\"buffer.memory\", 33554432);\n\tprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n\tKafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n\tMetricEvent metricEvent = new MetricEvent();\n\tmetricEvent.setTimestamp(System.currentTimeMillis());\n\tmetricEvent.setName(\"test\");\n\tmetricEvent.setTags(new HashMap<>());\n\tmetricEvent.setFields(new HashMap<>());\n\n\tProducerRecord<String, String> record = new ProducerRecord<>(\"test\", metricEvent.toJson());\n\tproducer.send(record);\n\tSystem.out.println(\"Sent data: \" + record);\n\tproducer.flush();\n}", "CodeBleu_score": 48.69379550544039}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\tif (event.getLevel().isMoreSpecificThan(level) &&!event.getLoggerName().contains(\"xxx\")) {\n\t\ttry {\n\t\t\tproducer.send(new ProducerRecord<String, String>(topic, event.toString().toUpperCase()));\n\t\t} catch (Exception e) {\n\t\t\tlogger.warn(\"Unable to send log event to Kafka topic\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 40.77310576097669}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\tif (event.getLevel().isMoreSpecificThan(getLevel()) &&!getLoggerName(event).contains(\"xxx\")) {\n\t\ttry {\n\t\t\tsend(event);\n\t\t} catch (Exception ex) {\n\t\t\tgetLogger().warn(\"Unable to send log event to Kafka topic\", ex);\n\t\t}\n\t}\n}", "CodeBleu_score": 35.03135881376409}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\tif (levels.contains(event.getLevel()) &&!event.getLoggerName().toUpperCase().contains(\"XXX\")) {\n\t\ttry {\n\t\t\tproducer.send(new ProducerRecord<String, String>(topic, event.getMessage().getFormattedMessage()));\n\t\t} catch (Exception e) {\n\t\t\tlogger.warn(\"Error sending log event to Kafka topic: \" + e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 46.35413647920369}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tvalidMethods := []string{\n\t\t\"default\",\n\t\t\"none\",\n\t\t\"topic\",\n\t\t\"topic_prefix\",\n\t\t\"topic_suffix\",\n\t}\n\tfor _, validMethod := range validMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 78.05114911385348}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tvalidMethods := []string{\"none\", \"sha256\"}\n\tfor _, validMethod := range validMethods {\n\t\tif validMethod == method {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 76.63181957803342}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 89.40480295903943}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag!= \"\" {\n\t\tif tag, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn tag, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 55.29278467126518}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\t// If the routing tag is specified, get the value of the tag from the metric's tags.\n\tif k.RoutingTag!= \"\" {\n\t\ttagValue, ok := metric.GetTag(k.RoutingTag)\n\t\tif ok {\n\t\t\treturn tagValue, nil\n\t\t}\n\t}\n\n\t// If the routing key is set to \"random\", generate a new UUID and return it as the key.\n\tif k.RoutingKey == \"random\" {\n\t\tid, err := uuid.NewV4()\n\t\tif err!= nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn id.String(), nil\n\t}\n\n\t// Otherwise, return the routing key as the key.\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 83.34020637798243}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag!= \"\" {\n\t\tif val, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn val, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 55.29278467126518}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, re := range k.TopicRegexps {\n\t\tif r, err := regexp.Compile(re); err!= nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regexp %q: %v\", re, err)\n\t\t} else {\n\t\t\tk.regexps[i] = r\n\t\t}\n\t}\n\treturn nil\n}", "CodeBleu_score": 56.41170477875364}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, 0, len(k.TopicRegexps))\n\tfor _, re := range k.TopicRegexps {\n\t\tr, err := regexp.Compile(re)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"failed to compile topic regexp %q: %s\", re, err)\n\t\t}\n\t\tk.regexps = append(k.regexps, r)\n\t}\n\treturn nil\n}", "CodeBleu_score": 62.97269444991739}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tregexp, err := regexp.Compile(topicRegexp)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"failed to compile topic regexp %q: %s\", topicRegexp, err)\n\t\t}\n\t\tk.regexps[i] = regexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 55.78587294042438}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif ok {\n\t\tmsg.Delivered = true\n\t\tmsg.session.MarkMessage(msg, nil)\n\t\tdelete(h.undelivered, track.ID)\n\t\th.sem <- 1\n\t}\n\th.mu.Unlock()\n\n\tif ok {\n\t\th.log.Errorf(\"ConsumerGroupHandler: message delivery failed: %v\", track.ID)\n\t}\n}", "CodeBleu_score": 56.54031226505742}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\th.mu.Lock()\nmsg, ok := h.undelivered[track.ID]\nh.mu.Unlock()\nif!ok {\nreturn\n}\nmsg.session.MarkMessage(msg.delivery, nil)\ntrack.Delivered()\nh.log.Errorf(\"message delivered: %v\", track)\nh.mu.Lock()\ndelete(h.undelivered, track.ID)\nh.mu.Unlock()\nh.sem.Release(1)\n}", "CodeBleu_score": 45.26870440922694}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif!ok {\n\t\th.mu.Unlock()\n\t\th.log.Errorf(\"Delivery ID %d not found\", track.ID)\n\t\treturn\n\t}\n\tdelete(h.undelivered, track.ID)\n\th.mu.Unlock()\n\tmsg.session.MarkMessage(msg, nil)\n\ttrack.Delivered()\n\th.log.Debugf(\"Message %d delivered\", track.ID)\n}", "CodeBleu_score": 58.792801777817246}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := h.session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif!ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.Handle(ctx, msg); err!= nil {\n\t\t\t\th.acc.AddError(err)\n\t\t\t}\n\t\t\tsession.MarkMessage(msg, \"\")\n\t\t}\n\t}\n}", "CodeBleu_score": 59.34502810054574}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := context.Background()\n\tctx, cancel := context.WithCancel(ctx)\n\tdefer cancel()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif!ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.Handle(ctx, msg); err!= nil {\n\t\t\t\th.acc.AddError(err)\n\t\t\t}\n\t\t\tsession.MarkMessage(msg, \"\")\n\t\t}\n\t}\n}", "CodeBleu_score": 64.33119512730981}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := h.session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif!ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\th.Reserve()\n\t\t\tif err := h.Handle(ctx, msg); err!= nil {\n\t\t\t\th.acc.AddError(err)\n\t\t\t}\n\t\t\tsession.MarkMessage(msg, \"\")\n\t\t}\n\t}\n}", "CodeBleu_score": 62.26484846476033}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\tif (logkafka_id.isEmpty) {\nthrow new IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be empty\")\n}\nif (logkafka_id.equals(\".\")) {\nthrow new IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be '.'\")\n}\nif (logkafka_id.equals(\"..\")) {\nthrow new IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be '..'\")\n}\nif (logkafka_id.length > 100) {\nthrow new IllegalCharacterInLogkafkaId(\"Logkafka ID cannot exceed 100 characters\")\n}\nval rgx = \"\"\"^[a-zA-Z0-9._-]+$\"\"\".r\nif (!rgx.findFirstIn(logkafka_id).isDefined) {\nthrow new IllegalCharacterInLogkafkaId(\"Logkafka ID contains illegal characters\")\n}\n}", "CodeBleu_score": 27.75738606654944}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t\tif (logkafka_id == null || logkafka_id.isEmpty || logkafka_id.equals(\".\") || logkafka_id.equals(\"..\")) {\n\t\tthrow new IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be empty,. or..\")\n\t}\n\tif (logkafka_id.length > MAX_LOGKAFKA_ID_LENGTH) {\n\t\tthrow new IllegalCharacterInLogkafkaId(s\"Logkafka ID cannot exceed ${MAX_LOGKAFKA_ID_LENGTH} characters\")\n\t}\n\tif (!LOGKAFKA_ID_REGEX.findFirstIn(logkafka_id).isDefined) {\n\t\tthrow new IllegalCharacterInLogkafkaId(s\"Logkafka ID can only contain alphanumeric characters, -, _ and.\")\n\t}\n}", "CodeBleu_score": 33.175869519537926}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t\tif (logkafka_id.isEmpty || logkafka_id.equals(\".\") || logkafka_id.equals(\"..\") || logkafka_id.length > 255) {\n\t\tthrow new IllegalCharacterInLogkafkaId(logkafka_id)\n\t}\n\tval rgx = \"\"\"^[a-zA-Z0-9\\-_\\.]+$\"\"\".r\n\tif (!rgx.findFirstIn(logkafka_id).isDefined) {\n\t\tthrow new IllegalCharacterInLogkafkaId(logkafka_id)\n\t}\n}", "CodeBleu_score": 27.430638227049915}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The tryWithKafkaManagerActor function sends a message to the Kafka manager actor and processes the response.", "CodeBleu_score": 6.787148594377509}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The tryWithKafkaManagerActor function sends a message to the Kafka manager actor and processes the response.\n * It takes an input message and a function to transform the output, returning a Future containing either an ApiError or the transformed output.\n * If the actor responds with an error, it logs the failure and returns an ApiError.\n * If the response is successful, it applies the transformation function and handles any exceptions, returning either the transformed output or an ApiError.\n * The function also includes error handling for any thrown exceptions during the process.\n */\n  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] = {\n    -\\/", "CodeBleu_score": 18.77971827267084}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The tryWithKafkaManagerActor function sends a message to the Kafka manager actor and processes the response.", "CodeBleu_score": 6.787148594377509}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The withKafkaManagerActor function sends a message to the Kafka Manager actor and processes the response.", "CodeBleu_score": 14.030131826741995}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The withKafkaManagerActor function sends a message to the Kafka Manager actor and processes the response.", "CodeBleu_score": 14.030131826741995}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The withKafkaManagerActor function sends a message to the Kafka Manager actor and processes the response.", "CodeBleu_score": 14.030131826741995}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n/**\n * The runPreferredLeaderElection function initiates a preferred leader election for specified topics in a given cluster.\nIt constructs a KMClusterCommandRequest with the cluster name and topics, then sends it to the Kafka manager actor.\nThe function returns a Future that maps the command result to a disjunction, indicating success or an error.\n */\n    val command = KMClusterCommandRequest(clusterName, KMPreferredReplicaLeaderElectionCommand(topics))\n    sendCommand(command).map {\n      case (clusterName, KMCommandResult(result)) =>\n        result match {\n          case Left(error) => -\\/(ApiError(error.error, error.message))\n          case Right(clusterContext) => \\/-(clusterContext)\n        }\n    }\n  }", "CodeBleu_score": 22.87852775055983}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n/**\n * The runPreferredLeaderElection function initiates a preferred leader election for specified topics in a given cluster.\nIt constructs a KMClusterCommandRequest with the cluster name and topics, then sends it to the Kafka manager actor.\nThe function returns a Future that maps the command result to a disjunction, indicating success or an error.\n */\n    val request = KMClusterCommandRequest(clusterName, KMPreferredReplicaLeaderElectionCommand(topics))\n    (kafkaManagerActor? request).mapTo[ApiError \\/ ClusterContext].map(_.map(ClusterContext(clusterName, _)))\n  }", "CodeBleu_score": 23.638668950703174}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n/**\n * The getCluster function retrieves the cluster context for the given cluster name from the Kafka manager actor.", "CodeBleu_score": 14.222873900293253}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t\timplicit val ec = ExecutionContext.global\n\tval errorOrTopicList = getTopicList(clusterName)\n\terrorOrTopicList.fold(\n\t\terror => Future.successful(error),\n\t\ttopicList => runPreferredLeaderElection(topicList, clusterName)\n\t)\n}", "CodeBleu_score": 29.382053317734712}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t\timplicit val ec = ExecutionContext.Implicits.global\n\tval errorOrTopicList = getTopicList(clusterName)\n\terrorOrTopicList.fold(\n\t\terror => Future.successful(error),\n\t\ttopicList => runPreferredLeaderElection(topicList, clusterName)\n\t)\n}", "CodeBleu_score": 30.35927776789154}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t\timplicit val ec: ExecutionContext = ExecutionContext.global\n\tgetTopicList(clusterName).flatMap {\n\t\tcase Right(topicList) => runPreferredLeaderElection(topicList)\n\t\tcase Left(error) => Future.successful(Left(error))\n\t}\n}", "CodeBleu_score": 23.998218200386784}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\nval results = tryWithKafkaManagerActor(\n      KMClusterCommandRequest (\n        clusterName,\n        CMManualPartitionAssignments(assignments)\n      )\n    )\nresults.map {\n  case ApiError(error) => error\n  case _ => \"success\"\n}\n}", "CodeBleu_score": 26.458980427492495}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\nimplicit val ec = system.dispatcher\nval results = tryWithKafkaManagerActor(\n      KMClusterCommandRequest (\n        clusterName,\n        CMManualPartitionAssignments(assignments)\n      )\n    )\nresults.map {\ncase ApiError(error) => error\ncase _ => \"Success\"\n}.collect {\ncase error: String => error\n}\n}", "CodeBleu_score": 32.42694527314319}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\timplicit executionContext: ExecutionContext =\ntryWithKafkaManagerActor\ntryWithKafkaManagerActor(\n      KMClusterCommandRequest (\n        clusterName,\n        CMManualPartitionAssignments(assignments)\n      )\n    )\nresults.map\nApiError\n}", "CodeBleu_score": 21.459779077645912}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\tlong timeout = 10000;\n\ttry {\n\t\tDescribeClusterResult describeClusterResult = admin.describeCluster();\n\t\ttry {\n\t\t\tCluster cluster = describeClusterResult.cluster();\n\t\t\tif (cluster.nodes().isEmpty()) {\n\t\t\t\tthrow new ConnectException(\"No Kafka nodes available\");\n\t\t\t}\n\t\t\tNode firstNode = cluster.nodes().iterator().next();\n\t\t\tDescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, firstNode.idString())));\n\t\t\ttry {\n\t\t\t\tConfig config = describeConfigsResult.all().get(firstNode.idString()).iterator().next();\n\t\t\t\treturn config;\n\t\t\t} finally {\n\t\t\t\tdescribeConfigsResult.close();\n\t\t\t}\n\t\t} finally {\n\t\t\tdescribeClusterResult.close();\n\t\t}\n\t} catch (InterruptedException e) {\n\t\tthrow new ConnectException(\"Interrupted while getting Kafka broker configuration\", e);\n\t}\n}", "CodeBleu_score": 46.66196553352805}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\tDescribeClusterResult describeClusterResult = admin.describeCluster();\n\tCollection<Node> nodes = describeClusterResult.nodes().get(timeout, TimeUnit.MILLISECONDS);\n\tif (nodes.isEmpty()) {\n\t\tthrow new ConnectException(\"No Kafka broker available\");\n\t}\n\tNode node = nodes.iterator().next();\n\tDescribeConfigsResult describeConfigsResult = admin.describeConfigs(singleton(new ConfigResource(ConfigResource.Type.BROKER, node.idString())));\n\ttry {\n\t\tMap<ConfigResource, Config> configs = describeConfigsResult.all().get(timeout, TimeUnit.MILLISECONDS);\n\t\tif (configs.isEmpty()) {\n\t\t\tthrow new ConnectException(\"No configuration found for Kafka broker \" + node.idString());\n\t\t}\n\t\treturn configs.values().iterator().next();\n\t} finally {\n\t\tdescribeConfigsResult.close();\n\t}\n}", "CodeBleu_score": 59.86621121938205}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\tDescribeClusterResult describeClusterResult = admin.describeCluster();\n\ttry {\n\t\tdescribeClusterResult.nodes().get(5, TimeUnit.SECONDS);\n\t} catch (TimeoutException e) {\n\t\tthrow new ConnectException(\"Could not retrieve cluster nodes in 5 seconds\", e);\n\t}\n\tif (describeClusterResult.nodes().isEmpty()) {\n\t\tthrow new ConnectException(\"No cluster nodes available\");\n\t}\n\tString firstNodeId = describeClusterResult.nodes().iterator().next().idString();\n\tDescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, firstNodeId)));\n\ttry {\n\t\tdescribeConfigsResult.all().get(5, TimeUnit.SECONDS);\n\t} catch (TimeoutException e) {\n\t\tthrow new ConnectException(\"Could not retrieve broker configuration in 5 seconds\", e);\n\t}\n\tif (describeConfigsResult.all().isEmpty()) {\n\t\tthrow new ConnectException(\"No broker configuration available\");\n\t}\n\treturn describeConfigsResult.all().iterator().next().value();\n}", "CodeBleu_score": 45.82573795023187}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic int validate(final Configuration configuration) {\n\t\t\tif (configuration.getSchemaHistory() == SchemaHistory.KAFKA_SCHEMA_HISTORY) {\n\t\t\t\treturn validator.validate(configuration);\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t};\n}", "CodeBleu_score": 21.605488473006453}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic int validate(final Map<String,?> configs, final boolean isKey) {\n\t\t\tif (configs.get(SCHEMA_HISTORY_CONFIG) == KafkaSchemaHistory.class.getName()) {\n\t\t\t\treturn validator.validate(configs, isKey);\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t};\n}", "CodeBleu_score": 26.543125903292413}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic int validate(final Config config) {\n\t\t\tfinal String schemaHistory = config.getString(SCHEMA_HISTORY);\n\t\t\tif (KAFKA_SCHEMA_HISTORY.equals(schemaHistory)) {\n\t\t\t\treturn validator.validate(config);\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t};\n}", "CodeBleu_score": 30.622041475091393}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tString version = parseVersion(getVersion())\n\tboolean topicCreationEnabled = parseBoolean(config.getOrDefault(\"topic.creation.enable\", \"true\"))\n\treturn (version.compareTo(\"2.6.0\") >= 0 && topicCreationEnabled)\n}", "CodeBleu_score": 29.817438530424965}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t// parse the current Kafka Connect version\n\tString version = VersionUtil.getVersion(getClass());\n\t// parse the Kafka Connect version\n\tVersion parsedVersion = VersionUtil.parseVersion(version);\n\t// get the topic.creation.enable property from the configuration, defaulting to true if not set\n\tBoolean topicCreationEnable = config.getOrDefault(\"topic.creation.enable\", true);\n\t// check if the Kafka Connect version is compatible with topic creation and the property is set to true\n\treturn (parsedVersion.compareTo(Version.parseVersion(\"2.8.0\")) >= 0) && topicCreationEnable;\n}", "CodeBleu_score": 39.26048978278626}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tString version = getVersion()\n\tif (version.startsWith(\"2.0\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"2.1\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"2.2\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"2.3\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"2.4\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"2.5\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"2.6\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"2.7\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"2.8\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"3.0\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"3.1\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"3.2\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"3.3\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"3.4\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"3.5\")) {\n\t\treturn parseBoolean(config, \"topic.creation.enable\", true)\n\t} else if (version.startsWith(\"3.6\")) {\n\t\treturn parseBoolean(config, \"topic.creation", "CodeBleu_score": 17.80439158964546}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\tString clientId = config.get(KafkaOffsetBackingStore.KAFKA_CLIENT_ID_CONFIG)\n\tif (clientId == null) {\n\t\tthrow new IllegalArgumentException(\"Missing mandatory configuration option: ${KafkaOffsetBackingStore.KAFKA_CLIENT_ID_CONFIG}\")\n\t}\n\n\tProperties adminProps = new Properties()\n\tadminProps.putAll(config)\n\tadminProps.put(CommonClientConfigs.CLIENT_ID_CONFIG, clientId + \"-admin\")\n\n\tSharedTopicAdmin admin = new SharedTopicAdmin(adminProps)\n\n\tString converterClassName = config.get(KafkaOffsetBackingStore.KAFKA_OFFSET_STORE_CONVERTER_CONFIG)\n\tOffsetStoreConverter converter\n\tif (converterClassName!= null) {\n\t\ttry {\n\t\t\tconverter = (OffsetStoreConverter) Class.forName(converterClassName).newInstance()\n\t\t} catch (Exception e) {\n\t\t\tthrow new IllegalArgumentException(\"Invalid class name for offset store converter: ${converterClassName}\", e)\n\t\t}\n\t}\n\n\treturn new KafkaOffsetBackingStore(admin, clientId, converter)\n}", "CodeBleu_score": 36.943755277207096}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\t// TODO: This is a temporary workaround for a bug in the compiler that causes a NullPointerException when using the config.require() method.\n\t//       Once the bug is fixed, this code should be replaced with the following line:\n\t//       def clientId = config.require(KafkaOffsetBackingStore.CLIENT_ID_CONFIG)\n\tdef clientId = config[KafkaOffsetBackingStore.CLIENT_ID_CONFIG]\n\tif (!clientId) {\n\t\tthrow new IllegalArgumentException(\"Missing configuration for ${KafkaOffsetBackingStore.CLIENT_ID_CONFIG}\")\n\t}\n\n\tdef adminProps = new Properties()\n\tadminProps.putAll(config)\n\tadminProps.remove(KafkaOffsetBackingStore.CLIENT_ID_CONFIG)\n\tadminProps.remove(KafkaOffsetBackingStore.TOPIC_CONFIG)\n\tadminProps.remove(KafkaOffsetBackingStore.PARTITION_CONFIG)\n\tadminProps.remove(KafkaOffsetBackingStore.OFFSET_CONFIG)\n\tadminProps.remove(KafkaOffsetBackingStore.KEY_CONVERTER_CONFIG)\n\tadminProps.remove(KafkaOffsetBackingStore.VALUE_CONVERTER_CONFIG)\n\n\tdef sharedAdmin = new SharedTopicAdmin(adminProps)\n\n\treturn new KafkaOffsetBackingStore(sharedAdmin, clientId, converterForOffsetStore(config))\n}", "CodeBleu_score": 34.95736476223077}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\tString clientId = config.get(KafkaOffsetBackingStore.CLIENT_ID_CONFIG)\n\tif (clientId == null) {\n\t\tthrow new IllegalArgumentException(\"Missing required configuration property: \" + KafkaOffsetBackingStore.CLIENT_ID_CONFIG)\n\t}\n\tProperties adminProps = new Properties()\n\tadminProps.putAll(config)\n\tadminProps.put(ConsumerConfig.GROUP_ID_CONFIG, clientId)\n\tadminProps.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false)\n\tadminProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\")\n\tadminProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName())\n\tadminProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, ByteArrayDeserializer.class.getName())\n\tadminProps.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 1)\n\tadminProps.put(ConsumerConfig.METADATA_MAX_AGE_CONFIG, 500)\n\tadminProps.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 10000)\n\tadminProps.put(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG, 15000)\n\tadminProps.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 1000)\n\tadminProps.put(ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG, 1048576)\n\tadminProps.put(ConsumerConfig.FETCH_MAX_BYTES_CONFIG, 1048576)\n\tadminProps.put(ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG, 100)\n\tadminProps.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 300000)\n\tadminProps.put(ConsumerConfig.CHECK_CRCS_CONFIG, false)\n\tadminProps.put(ConsumerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG, 540000)\n\tadminProps.put(ConsumerConfig.RECONNECT_BACKOFF_MS_CONFIG, 250)\n\tadminProps.put(ConsumerConfig.RETRY_BACKOFF_MS_CONFIG, ", "CodeBleu_score": 31.04534719227146}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\tif\n(\n!\nnode\n.\nisObject\n(\n)\n)\n{\nthrow\nnew\nIllegalArgumentException\n(\n\"\nKey\nmust\nbe\nan\nobject\n\"\n)\n;\n}\nJsonNode\npayload\n=\nnode\n.\nget\n(\nPAYLOAD\n)\n;\nif\n(\npayload\n!\n=\nnull\n)\n{\nnode\n=\npayload\n;\n}\nif\n(\n!\nnode\n.\nhas\n(\nKEY\n)\n)\n{\nthrow\nnew\nIllegalArgumentException\n(\n\"\nKey\nmust\nhave\na\nkey\nfield\n\"\n)\n;\n}\nJsonNode\nkeyNode\n=\nnode\n.\nget\n(\nKEY\n)\n;\nif\n(\nkeyNode\n.\nisObject\n(\n)\n)\n{\nIterator\n<\nString\n>\nfieldNames\n=\nkeyNode\n.\nfieldNames\n(\n)\n;\nif\n(\n!\nfieldNames\n.\nhasNext\n(\n)\n)\n{\nthrow\nnew\nIllegalArgumentException\n(\n\"\nKey\nmust\nhave\nat\nleast\none\nfield\n\"\n)\n;\n}\nif\n(\n!\nfieldNames\n.\nhasNext\n(\n)\n)\n{\nthrow\nnew\nIllegalArgumentException\n(\n\"\nKey\nmust\nhave\nat\nleast\none\nfield\n\"\n)\n;\n}\nT\nkey\n=\nreadValue\n(\nkeyNode\n,\ntypeFactory\n.\nconstructType\n(\nkeyNode\n.\nget\n(\nfieldNames\n.\nnext\n(\n)\n)\n.\ngetClass\n(\n)\n)\n)\n;\nif\n(\nfieldNames\n.\nhasNext\n(\n)\n)\n{\nthrow\nnew\nIllegalArgumentException\n(\n\"\nKey\nmust\nhave\nexactly\none\nfield\n\"\n)\n;\n}\nreturn\nkey\n;\n}\nelse\n{\nreturn\nreadValue\n(\nkeyNode\n,\ntypeFactory\n.\nconstructType\n(\nkeyNode\n.\ngetClass\n(\n)\n)\n)\n;\n}\n}", "CodeBleu_score": 31.72343159182189}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tif\n(node\n.\nisObject\n(\n)\n)\n{\nJsonNode\npayload\n=\nnode\n.\nget\n(\nPAYLOAD_FIELD_NAME\n)\n;\nif\n(\npayload\n!\n=\nnull\n)\n{\nnode\n=\npayload\n;\n}\n}\nif\n(\nnode\n.\nhas\n(\nFIELD_NAME\n)\n)\n{\nreturn\nreadSimpleKey\n(\nnode\n)\n;\n}\nreturn\nreadCompositeKey\n(\nnode\n)\n;\n}", "CodeBleu_score": 21.758793681725287}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tif\n(!node\n.isObject\n(\n)\n)\n{\nthrow\nnew\nIllegalArgumentException\n(\n\"Invalid key: \"\n+\nnode\n.toString\n(\n)\n)\n;\n}\nJsonNode\npayload\n=\nnode\n.get\n(\nPAYLOAD_FIELD\n)\n;\nif\n(payload\n!=\nnull\n)\n{\nnode\n=\npayload\n;\n}\nIterator\n<\nString\n>\nfieldNames\n=\nnode\n.fieldNames\n(\n)\n;\nif\n(!fieldNames\n.hasNext\n(\n)\n)\n{\nthrow\nnew\nIllegalArgumentException\n(\n\"Invalid key: \"\n+\nnode\n.toString\n(\n)\n)\n;\n}\nT\nkey\n=\nnull\n;\nif\n(!fieldNames\n.hasNext\n(\n)\n)\n{\nkey\n=\nreadValue\n(\nnode\n.get\n(\nfieldNames\n.next\n(\n)\n)\n)\n;\n}\nelse\n{\nkey\n=\nreadValue\n(\nnode\n)\n;\n}\nreturn\nkey\n;\n}", "CodeBleu_score": 33.802731483569026}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t\tString topicName = delegate.topicNameFor(id, prefix, delimiter);\n\tStringBuilder builder = new StringBuilder(topicName);\n\tboolean replaced = false;\n\tfor (int i = 0; i < builder.length(); i++) {\n\t\tchar c = builder.charAt(i);\n\t\tif (!isValidTopicNameCharacter(c)) {\n\t\t\tbuilder.setCharAt(i, '_');\n\t\t\treplaced = true;\n\t\t}\n\t}\n\tif (replaced) {\n\t\tlog.warn(\"Topic name [{}] for [{}] was sanitized to [{}]\", topicName, id, builder.toString());\n\t\treturn builder.toString();\n\t}\n\treturn topicName;\n}", "CodeBleu_score": 44.80941774611489}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t\tString topicName = topicNameForDelegate(id, prefix, delimiter);\n\tStringBuilder sb = new StringBuilder(topicName);\n\tboolean replaced = false;\n\tfor (int i = 0; i < sb.length(); i++) {\n\t\tif (!isValidTopicNameCharacter(sb.charAt(i))) {\n\t\t\tsb.setCharAt(i, '_');\n\t\t\treplaced = true;\n\t\t}\n\t}\n\tif (replaced) {\n\t\tlogger.warn(\"Topic name \" + topicName + \" is invalid, replacing with \" + sb);\n\t\treturn sb.toString();\n\t} else {\n\t\treturn topicName;\n\t}\n}", "CodeBleu_score": 38.60441088435309}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t\tString topicName = topicNameFor(id, prefix, delimiter, null);\n\tStringBuilder sanitizedName = new StringBuilder();\n\tboolean replaced = false;\n\tfor (int i = 0; i < topicName.length(); i++) {\n\t\tchar c = topicName.charAt(i);\n\t\tif (isValidTopicNameCharacter(c)) {\n\t\t\tsanitizedName.append(c);\n\t\t} else {\n\t\t\tsanitizedName.append(replacementCharacter);\n\t\t\treplaced = true;\n\t\t}\n\t}\n\tif (replaced) {\n\t\tlogger.warn(\"Topic name {} contains invalid characters. Using {} instead.\", topicName, sanitizedName);\n\t\treturn sanitizedName.toString();\n\t}\n\treturn topicName;\n}", "CodeBleu_score": 51.97961861011753}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\n}", "CodeBleu_score": 10.3990398260886}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t}", "CodeBleu_score": 10.3990398260886}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t}", "CodeBleu_score": 10.3990398260886}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\tfor (Field field : fields) {\n\t\tif (field.isMandatory() &&!configuration.containsKey(field.getName())) {\n\t\t\tthrow new ConfigException(field.getName() + \" is a mandatory field and must be set\");\n\t\t}\n\t\tif (configuration.containsKey(field.getName())) {\n\t\t\tObject value = configuration.get(field.getName());\n\t\t\tValidationResult validationResult = field.validate(value);\n\t\t\tif (!validationResult.isValid()) {\n\t\t\t\tthrow new ConfigException(validationResult.getErrorMessages().iterator().next());\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 35.470199154786805}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\tfor (Field field : fields) {\n\t\tvalidate(configuration, field);\n\t}\n}", "CodeBleu_score": 8.309445017865732}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\t// Validate the configuration against the fields.\n\tSet<ValidationResult> validationResults = configuration.validate(fields);\n\t// If there are any validation results with error messages, throw a ConfigException with the first error message.\n\tif (!validationResults.isEmpty()) {\n\t\tValidationResult validationResult = validationResults.iterator().next();\n\t\tthrow new ConfigException(validationResult.getErrorMessage());\n\t}\n}", "CodeBleu_score": 29.69692964003341}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\tif (oldSchema.isPrimitive()) {\n\t\treturn oldSchema\n\t}\n\tSchemaBuilder newSchemaBuilder = SchemaBuilder.builder().name(oldSchema.getName()).type(oldSchema.getType())\n\toldSchema.getFields().forEach { Schema.Field oldField ->\n\t\tString oldFieldName = oldField.name()\n\t\tif (nestedFields.contains(oldFieldName)) {\n\t\t\tHeader nestedHeader = headerToProcess.get(oldFieldName)\n\t\t\tSchema nestedSchema = buildNewSchema(oldFieldName, oldField.schema(), headerToProcess, nestedHeader.nestedFields, level + 1)\n\t\t\tnewSchemaBuilder.field(oldFieldName, nestedSchema)\n\t\t\ttrace.debug(\"Copying nested field: ${oldFieldName} at level: ${level}\")\n\t\t} else {\n\t\t\tnewSchemaBuilder.field(oldFieldName, oldField.schema())\n\t\t\ttrace.debug(\"Copying field: ${oldFieldName} at level: ${level}\")\n\t\t}\n\t}\n\theaderToProcess.each { String headerName, Header header ->\n\t\tif (!nestedFields.contains(headerName)) {\n\t\t\tnewSchemaBuilder.field(headerName, header.schema)\n\t\t\ttrace.debug(\"Adding field: ${headerName} at level: ${level}\")\n\t\t}\n\t}\n\treturn newSchemaBuilder.build()\n}", "CodeBleu_score": 35.64371488124137}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\tif (oldSchema.isPrimitive()) {\n\t\treturn oldSchema\n\t}\n\n\tSchemaBuilder builder = SchemaBuilder.builder().name(oldSchema.getName()).namespace(oldSchema.getNamespace()).type(oldSchema.getType())\n\n\toldSchema.getFields().forEach { field ->\n\t\tString name = field.name()\n\t\tSchema schema = field.schema()\n\t\tList<String> newNestedFields = nestedFields.collect { it }\n\t\tnewNestedFields.add(name)\n\t\tString newFieldName = fieldName + \".\" + name\n\t\tif (schema.isPrimitive()) {\n\t\t\tbuilder.field(name, schema)\n\t\t\ttrace(\"field\", name, \"isPrimitive\", \"true\", \"isContainedIn\", fieldName, \"field\", newFieldName, \"isPresent\", headerToProcess.containsKey(newFieldName), \"getFieldName\", getFieldName(headerToProcess, newFieldName), \"type\", schema.getType(), \"size\", schema.getLogicalType().getPrecision())\n\t\t} else {\n\t\t\tbuilder.field(name, buildNewSchema(newFieldName, schema, headerToProcess, newNestedFields, level + 1))\n\t\t}\n\t}\n\n\tif (level == 0) {\n\t\theaderToProcess.each { key, value ->\n\t\t\tString name = key\n\t\t\tString type = value.type\n\t\t\tString size = value.size\n\t\t\tString newFieldName = fieldName + \".\" + name\n\t\t\tif (!oldSchema.getFields().any { it.name() == name }) {\n\t\t\t\tSchema schema = getSchema(type, size)\n\t\t\t\tbuilder.field(name, schema)\n\t\t\t\ttrace(\"field\", name, \"isPrimitive\", \"false\", \"isContainedIn\", fieldName, \"field\", newFieldName, \"isPresent\", headerToProcess.containsKey(newFieldName), \"getFieldName\", getFieldName(headerToProcess, newFieldName), \"type\", schema.getType(), \"size\", schema.getLogicalType().getPrecision())\n\t\t\t}\n\t\t}\n\t}\n\n\treturn builder.build()\n}", "CodeBleu_score": 34.347808304042196}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (isPrimitive(oldSchema)) {\nreturn oldSchema\n}\nSchemaBuilder builder = SchemaBuilder.builder().name(oldSchema.getName()).namespace(oldSchema.getNamespace())\nif (oldSchema.getLogicalType()!= null) {\nbuilder.withLogicalType(oldSchema.getLogicalType())\n}\nif (oldSchema.getDoc()!= null) {\nbuilder.withDoc(oldSchema.getDoc())\n}\nif (oldSchema.getAliases()!= null) {\nbuilder.aliases(oldSchema.getAliases())\n}\noldSchema.getFields().forEach { Schema.Field field ->\nif (field.schema().isPrimitive()) {\nbuilder.field(field.name(), field.schema())\n} else {\nSchema nestedSchema = buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, level + 1)\nbuilder.field(field.name(), nestedSchema)\n}\n}\nif (nestedFields.size() > 0) {\nnestedFields.forEach { String nestedField ->\nif (headerToProcess.containsKey(nestedField)) {\nbuilder.field(nestedField, headerToProcess.get(nestedField).schema)\n}\n}\n}\nSchema newSchema = builder.build()\nif (level == 0) {\nlog.debug(\"Built schema for $fieldName with $newSchema\")\n}\nreturn newSchema\n}", "CodeBleu_score": 37.38566037963036}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tString snapshotString = source.getString(SNAPSHOT_KEY);\n\tif (snapshotString!= null) {\n\t\treturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n\t}\n\treturn null;\n}", "CodeBleu_score": 29.44988052135177}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source!= null && source.schema().field(\"SNAPSHOT_KEY\")!= null) {\n\t\tString snapshotString = source.getString(\"SNAPSHOT_KEY\");\n\t\tif (snapshotString!= null) {\n\t\t\treturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 39.01426674806404}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source.schema().field(SNAPSHOT_KEY).schema().logicalType() instanceof EnumLogicalType) {\n\t\tString snapshotString = source.getString(SNAPSHOT_KEY);\n\t\tif (snapshotString!= null) {\n\t\t\treturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 41.956362561957704}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\ttry {\n\t\tString[] parts = version.split(\"\\\\.\");\n\t\tString[] parts2 = parts[0].split(\"-\");\n\t\treturn Optional.of(Float.parseFloat(parts2[0]));\n\t} catch (Exception e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 55.28180467328956}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null) {\n\t\treturn Optional.empty();\n\t}\n\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOf(parts, 2);\n\t}\n\tString[] parts2 = parts[0].split(\"-\");\n\treturn Optional.of(Float.parseFloat(parts2[0]));\n}", "CodeBleu_score": 55.58757507124873}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null) {\n\t\treturn Optional.empty();\n\t}\n\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOf(parts, 2);\n\t}\n\tparts = parts[0].split(\"-\");\n\ttry {\n\t\treturn Optional.of(Float.parseFloat(parts[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 59.0440620640393}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t\n// createAccessContext\nAccessContext context = AccessContext.builder()\n.cluster(clusterName)\n.action(CONNECT_ACTIONS)\n.build();\n\n// validateAccess\nreturn validateAccess(context, exchange)\n.then(connector.map(newConnector -> {\n\n// build\nConnectorDTO dto = ConnectorDTO.builder()\n.name(newConnector.getName())\n.config(newConnector.getConfig())\n.build();\n\n// audit\naudit(context, AuditSignal.CREATE_CONNECTOR, dto);\n\n// connect\nreturn connect(clusterName, connectName, dto);\n}))\n.then(doOnEach(response -> {\n// audit\naudit(context, AuditSignal.CREATE_CONNECTOR, response.getBody());\n}));\n}", "CodeBleu_score": 52.64253664456587}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t\nreturn connector\n       .flatMap(newConnector -> {\n            AccessContext context = AccessContext.forCluster(clusterName)\n                   .withActions(CONNECT_ACTIONS)\n                   .withConnectName(connectName)\n                   .withConnectorName(newConnector.getName())\n                   .withConnectorConfig(newConnector.getConfig())\n                   .build();\n\n            return validateAccess(context)\n                   .then(kafkaConnectService.createConnector(clusterName, connectName, newConnector))\n                   .flatMap(connectorDTO -> audit(context, exchange, connectorDTO.getName()))\n                   .map(connectorDTO -> ResponseEntity.created(URI.create(connectorDTO.getHref()))\n                           .contentType(MediaType.APPLICATION_JSON)\n                           .body(connectorDTO));\n        });\n}", "CodeBleu_score": 47.383706182147776}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t\treturn AccessContext.create(exchange)\n\t\t\t.map(context -> context.withActions(connectActions.createConnector()))\n\t\t\t.flatMap(context -> validateAccess(context, exchange))\n\t\t\t.flatMap(context -> connector\n\t\t\t\t\t.flatMap(newConnector -> kafkaConnectService.createConnector(clusterName, connectName, newConnector)\n\t\t\t\t\t\t\t.map(connectorDTO -> ResponseEntity.created(URI.create(\n\t\t\t\t\t\t\t\t\t\"/v1/clusters/\" + clusterName + \"/connects/\" + connectName + \"/connectors/\" + connectorDTO.getName()))\n\t\t\t\t\t\t\t\t\t.body(connectorDTO)))\n\t\t\t\t\t.doOnEach(signal -> audit(context, signal)));\n}", "CodeBleu_score": 33.97211913477708}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\treturn Mono.just(clusterName)\n       .map(cluster -> AccessContext.builder()\n               .operation(KAFKA_CONNECT_OPERATION)\n               .operationName(DELETE_CONNECT_CONNECTOR)\n               .clusterName(cluster)\n               .connectName(connectName)\n               .connectorName(connectorName)\n               .build())\n       .flatMap(context -> validateAccess(exchange, context, DELETE_CONNECT_CONNECTOR))\n       .flatMap(context -> kafkaConnectService.deleteConnector(context))\n       .doOnEach(audit(exchange, DELETE_CONNECT_CONNECTOR))\n       .map(ResponseEntity::ok)\n       .onErrorResume(e -> handleException(exchange, e, DELETE_CONNECT_CONNECTOR));\n}", "CodeBleu_score": 31.09679120593039}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\nAccessContext accessContext = AccessContext.forCluster(clusterName)\n.addRequiredActions(connectActions.deleteConnector())\n.build();\n\nreturn validateAccess(accessContext, exchange)\n.then(getCluster(clusterName, exchange))\n.flatMap(cluster -> {\nreturn kafkaConnectService.deleteConnector(cluster, connectName, connectorName)\n.flatMap(response -> {\naudit.doOnEach(audit -> audit.withResourceName(connectorName)\n.withResourceName(connectName)\n.withResourceName(clusterName)\n.withResource(Resource.KAFKA_CONNECT)\n.withAction(Action.DELETE)\n.withResult(Result.SUCCESS));\nreturn Mono.just(ResponseEntity.noContent().build());\n})\n.onErrorResume(e -> {\naudit.doOnEach(audit -> audit.withResourceName(connectorName)\n.withResourceName(connectName)\n.withResourceName(clusterName)\n.withResource(Resource.KAFKA_CONNECT)\n.withAction(Action.DELETE)\n.withResult(Result.FAILURE));\nreturn Mono.error(e);\n});\n});\n}", "CodeBleu_score": 39.453733029449545}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\nreturn validateAccess(exchange, clusterName, connectName, connectActions.deleteConnector(connectorName))\n.then(getCluster(clusterName, exchange))\n.flatMap(cluster -> {\n\nreturn kafkaConnectService.deleteConnector(cluster, connectName, connectorName)\n.then(audit.operation(exchange, cluster, operationName.DELETE_CONNECTOR,\noperationParams(cluster, connectName, connectorName)));\n\n}).thenReturn(ResponseEntity.noContent().build());\n\n}", "CodeBleu_score": 32.61955074422796}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\nreturn getCluster(clusterName)\n.flatMap(cluster -> {\nConnectorDTO connector = cluster.getConnector(connectName, connectorName);\n\nif (connector == null) {\nreturn Mono.error(new ConnectorNotFoundException(connectName, connectorName));\n}\n\nConnectActions connectActions = new ConnectActions(connector);\nList<ConnectAction> actions = connectActions.getActions(action);\n\nAccessContextBuilder builder = AccessContextBuilder.forOperation(OPERATION_NAME)\n.resource(Resource.CLUSTER, clusterName)\n.resource(Resource.CONNECT, connectName)\n.resource(Resource.CONNECTOR, connectorName)\n.action(action.getAction())\n.parameter(OPERATION_PARAMS, action.getParams())\n.build();\n\nreturn validateAccess(exchange, builder)\n.then(kafkaConnectService.updateConnectorState(cluster, connector, actions))\n.doOnEach(audit(exchange, OPERATION_NAME, builder));\n})\n.then(Mono.just(ResponseEntity.ok().build()));\n}", "CodeBleu_score": 44.52430524774119}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\treturn Mono.just(action)\n\t\t\t.map(ConnectorActionDTO::name)\n\t\t\t.map(ConnectorAction::valueOf)\n\t\t\t.flatMap(connectorAction -> {\n\t\t\t\tMap<String, Object> operationParams = new HashMap<>();\n\t\t\t\toperationParams.put(CONNECT_NAME, connectName);\n\t\t\t\toperationParams.put(CONNECTOR_NAME, connectorName);\n\t\t\t\toperationParams.put(ACTION, connectorAction.name());\n\t\t\t\tString operationName = getOperationName(clusterName, connectName, connectorName, action);\n\t\t\t\tAccessContextBuilder builder = AccessContextBuilder.forConnect(connectName)\n\t\t\t\t\t\t.withOperation(operationName)\n\t\t\t\t\t\t.withOperationParams(operationParams)\n\t\t\t\t\t\t.withAction(action)\n\t\t\t\t\t\t.withCluster(clusterName)\n\t\t\t\t\t\t.withConnect(connectName)\n\t\t\t\t\t\t.withConnector(connectorName);\n\t\t\t\treturn validateAccess(builder)\n\t\t\t\t\t\t.then(kafkaConnectService.updateConnectorState(clusterName, connectName, connectorName, connectorAction)\n\t\t\t\t\t\t\t\t.then(audit.doOnEach(AuditSignalType.CONNECT_UPDATE_CONNECTOR_STATE,\n\t\t\t\t\t\t\t\t\t\texchange, builder.build()))\n\t\t\t\t\t\t\t\t.thenReturn(ResponseEntity.ok().build()));\n\t\t\t});\n}", "CodeBleu_score": 40.15786535318989}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\treturn Mono.just(action)\n       .map(ConnectorActionDTO::getAction)\n       .map(action1 -> connectActions.get(action1))\n       .flatMap(connectAction -> {\n            AccessContext accessContext = AccessContext.builder()\n                   .cluster(clusterName)\n                   .connect(connectName)\n                   .connectActions(connectAction)\n                   .operationName(OperationType.UPDATE_CONNECT_CONNECTOR_STATE)\n                   .operationParams(buildOperationParams(action))\n                   .build();\n            return validateAccess(accessContext)\n                   .flatMap(validation -> kafkaConnectService.updateConnectorState(clusterName, connectName, connectorName, action)\n                           .doOnEach(signal -> audit(signal, exchange, accessContext)));\n        })\n       .then(ResponseEntity.noContent().build());\n}", "CodeBleu_score": 43.94285540734637}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\tString cluster\n\tString connect\n\tString pluginName\n\tConnectorPluginConfigValidationRequestDTO requestBody\n\t// TODO: Implement...\n}", "CodeBleu_score": 22.159505290853694}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\tMono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> response = Mono.defer {\n        Mono<ConnectorPluginConfigValidationResponseDTO> validationResult = kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, requestBody)\n        Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> response = validationResult.map {\n            ResponseEntity.ok(it)\n        }\n        return response\n    }\n    return response\n}", "CodeBleu_score": 22.49396313888395}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\n}", "CodeBleu_score": 8.648212644078399}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t\t.initializers(dynamicConfigPropertiesInitializer())\n\t\t\t.run(args);\n}", "CodeBleu_score": 40.474157817515355}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t\t.initializers(dynamicConfigPropertiesInitializer())\n\t\t\t.run(args);\n}", "CodeBleu_score": 40.474157817515355}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\tSpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n\tbuilder.initializers(dynamicConfigPropertiesInitializer);\n\treturn builder.run(args);\n}", "CodeBleu_score": 42.23438861958264}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\tif (search == null) {\n\t\treturn { true }\n\t} else {\n\t\treturn { FullConnectorInfoDTO connector ->\n\t\t\tdef strings = getStringsForSearch(connector)\n\t\t\tstrings.any { it.containsIgnoreCase(search) }\n\t\t}\n\t}\n}", "CodeBleu_score": 51.76894221250077}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\tif (search == null) {\n\t\treturn { true } as Predicate<FullConnectorInfoDTO>\n\t}\n\tfinal String searchTerm = search.toLowerCase()\n\treturn { FullConnectorInfoDTO connector ->\n\t\treturn getStringsForSearch(connector).anyMatch { it.toLowerCase().contains(searchTerm) }\n\t} as Predicate<FullConnectorInfoDTO>\n}", "CodeBleu_score": 46.50148687188176}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\treturn search == null? Predicates.alwaysTrue() : new Predicate<FullConnectorInfoDTO>() {\n\t\t@Override\n\t\tboolean apply(@Nullable final FullConnectorInfoDTO input) {\n\t\t\treturn input.getConnectorName().containsIgnoreCase(search) ||\n\t\t\t\t\tinput.getConnectorType().containsIgnoreCase(search) ||\n\t\t\t\t\tinput.getConnectorVersion().containsIgnoreCase(search) ||\n\t\t\t\t\tinput.getConnectorDescription().containsIgnoreCase(search) ||\n\t\t\t\t\tinput.getConnectorClass().containsIgnoreCase(search)\n\t\t}\n\t}\n}", "CodeBleu_score": 30.967297631665996}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\tMap<String, Object> flattenedProperties = [:]\n\n\tif (propertiesMap) {\n\t  propertiesMap.each { key, value ->\n\t\tString newKey = prefix? \"${prefix}.${key}\" : key\n\n\t\tif (value instanceof Map) {\n\t\t  flattenedProperties += flattenClusterProperties(newKey, value)\n\t\t} else {\n\t\t  flattenedProperties[newKey] = value\n\t\t}\n\t  }\n\t}\n\n\treturn flattenedProperties\n  }", "CodeBleu_score": 34.232595449926805}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\tMap<String, Object> flattenedProperties = [:]\n\tif (propertiesMap == null) {\n\t  return flattenedProperties\n\t}\n\tpropertiesMap.each { key, value ->\n\t  def newKey = prefix? \"${prefix}.${key}\" : key\n\t  if (value instanceof Map) {\n\t\tflattenedProperties.putAll(flattenClusterProperties(newKey, value))\n\t  } else {\n\t\tflattenedProperties.put(newKey, value)\n\t  }\n\t}\n\treturn flattenedProperties\n  }", "CodeBleu_score": 39.47942322215916}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t//    if (propertiesMap == null) {\n//      return Collections.emptyMap();\n//    }\n    Map<String, Object> flattened = new HashMap<>();\n    if (propertiesMap!= null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = entry.getKey();\n        Object value = entry.getValue();\n        String newKey = prefix == null? key : prefix + \".\" + key;\n        if (value instanceof Map) {\n          flattened.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n        } else {\n          flattened.put(newKey, value);\n        }\n      }\n    }\n    return flattened;\n  }", "CodeBleu_score": 55.50753983431363}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n addClientSslSupport(configDef);\n addClientSaslSupport(configDef);\n return configDef.configKeys().entrySet().stream()\n.filter(entry -> entry.getValue().type() == ConfigDef.Type.PASSWORD)\n.map(Map.Entry::getKey)\n.collect(Collectors.toSet());\n}", "CodeBleu_score": 71.14992671394336}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n addClientSslSupport(configDef);\n addClientSaslSupport(configDef);\n return configDef.configKeys().entrySet().stream()\n.filter(entry -> entry.getValue().type() == ConfigDef.Type.PASSWORD)\n.map(Map.Entry::getKey)\n.collect(Collectors.toSet());\n}", "CodeBleu_score": 71.14992671394336}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n addClientSslSupport(configDef);\n addClientSaslSupport(configDef);\n return configDef.configKeys().entrySet().stream().filter(entry -> entry.getValue().type() == Type.PASSWORD).map(Map.Entry::getKey).collect(Collectors.toSet());\n }", "CodeBleu_score": 65.07262453709815}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t\tif (clusterDescription.authorizedOperations().contains(AclOperation.ALTER)) {\n\t\treturn Mono.just(ClusterFeature.KAFKA_ACL_EDIT)\n\t} else if (clusterDescription.authorizedOperations().contains(AclOperation.ALL)) {\n\t\treturn adminClient.describeCluster().flatMap {\n\t\t\tif (it.aclViewEnabled()) {\n\t\t\t\treturn@flatMap Mono.just(ClusterFeature.KAFKA_ACL_EDIT)\n\t\t\t} else {\n\t\t\t\treturn@flatMap Mono.empty()\n\t\t\t}\n\t\t}\n\t} else {\n\t\treturn Mono.empty()\n\t}\n}", "CodeBleu_score": 27.80123992318745}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t\treturn ofNullable(clusterDescription.authorizedOperations())\n\t\t\t.filter(operations -> operations.contains(AclOperation.ALL) || operations.contains(AclOperation.ALTER))\n\t\t\t.flatMap(operations -> ofNullable(clusterDescription.aclViewEnabled())\n\t\t\t\t\t.filter(aclViewEnabled -> aclViewEnabled)\n\t\t\t\t\t.map(aclViewEnabled -> KAFKA_ACL_EDIT))\n\t\t\t.switchIfEmpty(empty());\n}", "CodeBleu_score": 34.46265797939653}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t\treturn ofNullable(clusterDescription)\n\t\t\t.map(ClusterDescription::getAuthorizedOperations)\n\t\t\t.filter(operations -> operations.contains(ACL_OPERATION_ALL) || operations.contains(ACL_OPERATION_ALTER))\n\t\t\t.filter(operations -> clusterDescription.isAclViewEnabled())\n\t\t\t.map(operations -> ClusterFeature.of(KAFKA_ACL_EDIT))\n\t\t\t.orElse(empty());\n}", "CodeBleu_score": 27.162281108569907}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n\nif (prevRange.isEmpty()) {\nseekOperations.forEach((tp, offset) -> {\nnextRange.put(tp, new FromToOffset(offset, offset));\n});\n} else {\nnextRange.putAll(prevRange);\n}\n\nint numMessagesPerPartition = Math.max(1, numMessages / nextRange.size());\n\nnextRange.entrySet().stream()\n.forEach(entry -> {\nTopicPartition tp = entry.getKey();\nFromToOffset fromToOffset = entry.getValue();\n\nlong beginOffset = fromToOffset.getFromOffset();\nlong endOffset = fromToOffset.getToOffset();\n\nif (endOffset - beginOffset < numMessagesPerPartition) {\nendOffset = beginOffset + numMessagesPerPartition;\n}\n\nlong adjustedBeginOffset = Math.max(beginOffset, getOffsetsForSeek(tp).getBeginOffsets().get(tp));\n\nnextRange.put(tp, new FromToOffset(adjustedBeginOffset, endOffset));\n});\n\nreturn nextRange;\n}", "CodeBleu_score": 39.65357105824491}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t\nTreeMap<TopicPartition, FromToOffset> range = new TreeMap<>();\n\nif (prevRange.isEmpty()) {\n\n// If the previous range is empty, use the seek offsets\nseekOperations.forEach((tp, offset) -> {\n\nrange.put(tp, new FromToOffset(offset, offset + pollCount));\n});\n\n} else {\n\n// If the previous range is not empty, adjust the start offset based on the number of messages to poll\nprevRange.forEach((tp, fromToOffset) -> {\n\nlong startOffset = fromToOffset.getFromOffset() + pollCount;\n\n// Make sure the start offset does not go below the beginning offset\nstartOffset = Math.max(startOffset, seekOperations.getBeginOffsets().get(tp));\n\nrange.put(tp, new FromToOffset(startOffset, startOffset + pollCount));\n});\n}\n\nreturn range;\n}", "CodeBleu_score": 30.354432433482238}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t// The next polling range is based on the previous range, but if the previous range is empty,\n// we initialize the next range based on the offsets from seek operations.\nTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\nif (prevRange.isEmpty()) {\nseekOperations.forEach((tp, offset) -> {\nnextRange.put(tp, new FromToOffset(offset, offset));\n});\n} else {\nnextRange.putAll(prevRange);\n}\n\n// Calculate the number of messages to poll per partition.\nint numMessagesPerPartition = (int) Math.ceil((double) maxMessages / nextRange.size());\n\n// For each topic partition, determine the start offset and adjust it based on the number of\n// messages to poll, ensuring it does not go below the beginning offset.\nnextRange.forEach((tp, fromToOffset) -> {\nlong startOffset = fromToOffset.getFrom();\nif (startOffset + numMessagesPerPartition > fromToOffset.getTo()) {\nstartOffset = fromToOffset.getTo();\n} else {\nstartOffset += numMessagesPerPartition;\n}\nnextRange.put(tp, new FromToOffset(startOffset, fromToOffset.getTo()));\n});\n\nreturn nextRange;\n}", "CodeBleu_score": 38.19203539456176}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\t\t// If legacy mode is enabled, validate the corresponding configuration settings for ZooKeeper or bootstrap servers\n\tif (input.isLegacyMode()) {\n\t\tvalidateLegacyModeConfig(input);\n\t}\n\n\t// Wait for the server to be running\n\tfinal MessageInput.Server server = input.getServer();\n\tif (server!= null) {\n\t\tserver.awaitRunning();\n\t}\n\n\t// Register for server lifecycle events\n\tinput.register();\n\n\t// Launch the input based on the mode\n\tif (input.isLegacyMode()) {\n\t\tdoLaunchLegacy(input);\n\t} else {\n\t\tdoLaunchConsumer(input);\n\t}\n\n\t// Schedule a task to update the last second bytes read every second\n\tinput.scheduleAtFixedRate(new Runnable() {\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tinput.setLastSecondBytesRead(input.getConsumer().lastSecondBytesRead());\n\t\t}\n\t}, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 25.073516835923638}, {"code": "public void doLaunch(final MessageInput input){\n\t\tfinal MessageInputConfig config = input.getConfig();\n\tfinal boolean isLegacyMode = config.getBoolean(MessageInputConfig.LEGACY_MODE);\n\tif (isLegacyMode) {\n\t\tvalidateLegacyModeConfig(config);\n\t} else {\n\t\tvalidateConsumerModeConfig(config);\n\t}\n\t// Wait for the server to be running\n\tawaitRunning();\n\t// Register for server lifecycle events\n\tregister(input);\n\t// Launch the input\n\tif (isLegacyMode) {\n\t\tdoLaunchLegacy(input);\n\t} else {\n\t\tdoLaunchConsumer(input);\n\t}\n\t// Schedule a task to update the last second bytes read every second\n\tscheduleAtFixedRate(new Runnable() {\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tinput.setLastSecondBytesRead(input.getReadCounter().getAndSet(0));\n\t\t}\n\t}, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 32.7435399187688}, {"code": "public void doLaunch(final MessageInput input){\n\t\t// 1. \u521d\u59cb\u5316\n\tfinal MessageInput.Mode mode = input.getMode();\n\tfinal String name = input.getName();\n\tfinal String topic = input.getTopic();\n\tfinal String consumerGroup = input.getConsumerGroup();\n\tfinal String bootstrapServers = input.getBootstrapServers();\n\tfinal String zooKeeper = input.getZooKeeper();\n\tfinal String zooKeeperRoot = input.getZooKeeperRoot();\n\tfinal String zooKeeperServers = input.getZooKeeperServers();\n\tfinal String zooKeeperPort = input.getZooKeeperPort();\n\tfinal String zooKeeperSessionTimeout = input.getZooKeeperSessionTimeout();\n\tfinal String zooKeeperConnectionTimeout = input.getZooKeeperConnectionTimeout();\n\tfinal String zooKeeperSyncTime = input.getZooKeeperSyncTime();\n\tfinal String zooKeeperAutoConnect = input.getZooKeeperAutoConnect();\n\tfinal String zooKeeperAutoReset = input.getZooKeeperAutoReset();\n\tfinal String zooKeeperAutoOffsetReset = input.getZooKeeperAutoOffsetReset();\n\tfinal String zooKeeperAutoCommit = input.getZooKeeperAutoCommit();\n\tfinal String zooKeeperAutoCommitInterval = input.getZooKeeperAutoCommitInterval();\n\tfinal String zooKeeperMaxRetries = input.getZooKeeperMaxRetries();\n\tfinal String zooKeeperRetryInterval = input.getZooKeeperRetryInterval();\n\tfinal String zooKeeperBackoffInterval = input.getZooKeeperBackoffInterval();\n\tfinal String zooKeeperBackoffMax = input.getZooKeeperBackoffMax();\n\tfinal String zooKeeperBackoff = input.getZooKeeperBackoff();\n\tfinal String zooKeeperSecurityProtocol = input.getZooKeeperSecurityProtocol();\n\tfinal String zooKeeperSslTruststoreLocation = input.getZooKeeperSslTruststoreLocation();\n\tfinal String zooKeeperSslTruststorePassword = input.getZooKeeperSslTruststorePassword();\n\tfinal String zooKeeperSslKeystoreLocation = input.getZooKeeperSslKeystoreLocation();\n\tfinal String zooKeeperSslKeystorePassword = input.getZooKeeperSslKeystorePassword();\n\tfinal String zooKeeperSslKeyPassword = input.getZooKeeperSslKeyPassword();\n\tfinal String zooKeeperSslEndpointIdentificationAlgorithm = input.getZooKeeper", "CodeBleu_score": 20.067952983991212}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t\ttry {\n\t\tprops.load(new StringReader(customProperties))\n\t} catch (IOException e) {\n\t\tlog.error(\"Failed to load custom properties: ${e.message}\")\n\t}\n}", "CodeBleu_score": 21.311720454134974}, {"code": "private void insertCustomProperties(Properties props){\n\t\ttry {\n\t\tProperties customProps = new Properties()\n\t\tcustomProps.load(new StringReader(customProperties))\n\t\tprops.putAll(customProps)\n\t} catch (IOException e) {\n\t\tlog.error(\"Could not insert custom properties into properties object.\", e)\n\t}\n}", "CodeBleu_score": 34.53640876982014}, {"code": "private void insertCustomProperties(Properties props){\n\t\ttry {\n\t\tProperties customProps = new Properties()\n\t\tcustomProps.load(new StringReader(customProperties))\n\t\tprops.putAll(customProps)\n\t} catch (IOException e) {\n\t\tlog.error(\"Error loading custom properties\", e)\n\t}\n}", "CodeBleu_score": 33.53153859102737}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\tif (entries == null || entries.isEmpty()) {\nreturn;\n}\n\nlong writtenBytes = entries.stream()\n.filter(Objects::nonNull)\n.map(this::map)\n.peek(stream -> stream.mark(Integer.MAX_VALUE))\n.map(this::getMessageBytes)\n.collect(Collectors.summingLong(Long::longValue));\n\ntry {\nwrittenMessages.addAndGet(entries.size());\njournal.write(entries.stream()\n.filter(Objects::nonNull)\n.map(this::map)\n.collect(Collectors.toList()));\n} catch (IOException e) {\nthrow new MessageQueueException(e);\n}\n}", "CodeBleu_score": 32.306204509776116}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\tList<JournalEntry> journalEntries = entries.stream()\n.filter(Objects::nonNull)\n.map(this::mapToJournalEntry)\n.collect(Collectors.toList());\n\nint writtenBytes = 0;\nint writtenMessages = 0;\nfor (JournalEntry entry : journalEntries) {\nwrittenBytes += entry.getMessageBytes().length;\nwrittenMessages++;\n}\n\ntry {\njournal.write(journalEntries);\n} catch (IOException e) {\nthrow new MessageQueueException(e);\n}\n\nwrittenMessagesMetric.addAndGet(writtenMessages);\nwrittenBytesMetric.addAndGet(writtenBytes);\n}", "CodeBleu_score": 30.671422380770665}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\tif (entries == null || entries.isEmpty()) {\nreturn;\n}\n\nList<JournalEntry> journalEntries = entries.stream()\n.filter(Objects::nonNull)\n.map(this::mapToJournalEntry)\n.collect(Collectors.toList());\n\nlong writtenBytes = journalEntries.stream()\n.mapToLong(JournalEntry::getMessageBytes)\n.sum();\n\ntry {\n// Attempt to write the journal entries\njournal.write(journalEntries);\n} catch (Exception e) {\n// If writing fails, retry using an exponential back-off strategy\nint retryCount = 0;\nwhile (retryCount < RETRY_COUNT) {\ntry {\nThread.sleep(RETRY_DELAY * (long) Math.pow(2, retryCount));\njournal.write(journalEntries);\nbreak;\n} catch (Exception ex) {\nretryCount++;\n}\n}\n\n// If all retries fail, throw an exception\nif (retryCount == RETRY_COUNT) {\nthrow new MessageQueueException(\"Failed to write to journal after \" + RETRY_COUNT + \" retries.\", e);\n}\n}\n\n// Update the written messages and bytes metrics\nwrittenMessages.addAndGet(journalEntries.size());\nthis.writtenBytes.addAndGet(writtenBytes);\n}", "CodeBleu_score": 41.90397253572284}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\t\tmessages.stream()\n\t\t.map(Message::getQueueId)\n\t\t.filter(Objects::nonNull)\n\t\t.filter(acknowledgedMessages::contains)\n\t\t.max(Long::compareTo)\n\t\t.ifPresent(acknowledgedMessages::mark);\n}", "CodeBleu_score": 18.491624599344142}, {"code": "public void acknowledge(List<Message> messages){\n\t\tmessages.stream().map(Message::getQueueId).filter(Optional::isPresent).map(Optional::get).max(Long::compareTo).ifPresent(acknowledgedMessages::mark);\n}", "CodeBleu_score": 16.98176449480141}, {"code": "public void acknowledge(List<Message> messages){\n\t\tOptionalInt maxValidQueueId = messages.stream()\n\t\t.map(message -> message.getQueueId())\n\t\t.filter(queueId -> queueId!= -1)\n\t\t.max(Integer::compare);\n\tmaxValidQueueId.ifPresent(queueId -> acknowledge(queueId));\n\tacknowledgedMessages.mark(messages.size());\n}", "CodeBleu_score": 40.96890571072619}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\t\tMap<String, Metric> metrics = registry.getMetrics();\n\tmetrics.entrySet().stream()\n\t\t\t.filter(entry -> entry.getKey().startsWith(LocalKafkaJournal.class.getName()))\n\t\t\t.forEach(entry -> {\n\t\t\t\tString legacyMetricName = entry.getKey().substring(LocalKafkaJournal.class.getName().length() + 1);\n\t\t\t\ttry {\n\t\t\t\t\tregistry.register(legacyMetricName, entry.getValue());\n\t\t\t\t} catch (IllegalArgumentException e) {\n\t\t\t\t\tlog.warn(\"Failed to register legacy metric {} under name {}\", entry.getKey(), legacyMetricName);\n\t\t\t\t}\n\t\t\t});\n}", "CodeBleu_score": 52.93251059954698}, {"code": "private void registerLegacyMetrics(){\n\t\tmetricRegistry.getMetrics().entrySet().stream()\n\t\t.filter(entry -> entry.getKey().startsWith(LocalKafkaJournal.class.getName()))\n\t\t.forEach(entry -> {\n\t\t\tfinal String metricName = entry.getKey().replace(LocalKafkaJournal.class.getName(), \"akka.persistence.kafka.journal\");\n\t\t\ttry {\n\t\t\t\tmetricRegistry.register(metricName, entry.getValue());\n\t\t\t} catch (final IllegalArgumentException e) {\n\t\t\t\tlog.warn(\"Unable to register legacy metric [{}] with name [{}]\", entry.getKey(), metricName);\n\t\t\t}\n\t\t});\n}", "CodeBleu_score": 54.5925329517341}, {"code": "private void registerLegacyMetrics(){\n\t\tMap<String, Metric> metrics = registry.getMetrics();\n\tmetrics.entrySet().stream()\n\t\t.filter(entry -> entry.getKey().startsWith(LocalKafkaJournal.class.getName()))\n\t\t.forEach(entry -> {\n\t\t\tString legacyName = entry.getKey().replace(LocalKafkaJournal.class.getName(), \"akka.persistence.kafka.journal\");\n\t\t\ttry {\n\t\t\t\tregistry.register(legacyName, entry.getValue());\n\t\t\t} catch (IllegalArgumentException e) {\n\t\t\t\tlog.warn(\"Unable to register legacy metric [{}] for metric [{}]\", legacyName, entry.getKey());\n\t\t\t}\n\t\t});\n}", "CodeBleu_score": 52.91250630485082}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\ttry {\n\t\treturn metricRegistry.register(metricName, new HdrTimer())\n\t} catch (IllegalArgumentException iae) {\n\t\treturn metricRegistry.getTimers().get(metricName)\n\t}\n}", "CodeBleu_score": 17.69941830127219}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tfinal Timer timer = metricRegistry.timer(metricName);\n\ttry {\n\t\tmetricRegistry.register(metricName, timer);\n\t} catch (IllegalArgumentException e) {\n\t\ttimer = metricRegistry.getTimers().get(metricName);\n\t}\n\treturn timer;\n}", "CodeBleu_score": 35.02691430111538}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\ttry {\n\t\treturn metricRegistry.register(metricName, new HdrTimer());\n\t} catch (IllegalArgumentException e) {\n\t\treturn metricRegistry.getTimers().get(metricName);\n\t}\n}", "CodeBleu_score": 20.613787288301083}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t\ttry {\n\t\tmetricRegistry.register(name, new Gauge<Integer>() {\n\t\t\t@Override\n\t\t\tpublic Integer getValue() {\n\t\t\t\tif (size() == 0) {\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tif (committedOffset == LogOffset.DEFAULT_OFFSET) {\n\t\t\t\t\treturn logEndOffset - logStartOffset;\n\t\t\t\t}\n\t\t\t\treturn logEndOffset - committedOffset;\n\t\t\t}\n\t\t});\n\t} catch (IllegalArgumentException e) {\n\t\tlog.warn(\"Unable to register uncommitted gauge metric for {}: {}\", name, e.getMessage());\n\t}\n}", "CodeBleu_score": 57.37957906235786}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t\ttry {\n\t\tmetricRegistry.register(name, new Gauge<Integer>() {\n\t\t\t@Override\n\t\t\tpublic Integer getValue() {\n\t\t\t\tif (size() == 0) {\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\tif (committedOffset == DEFAULT_OFFSET) {\n\t\t\t\t\treturn logEndOffset - logStartOffset;\n\t\t\t\t} else {\n\t\t\t\t\treturn logEndOffset - committedOffset;\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t} catch (IllegalArgumentException e) {\n\t\t// ignore\n\t}\n}", "CodeBleu_score": 52.22586924069521}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t\tmetricRegistry.register(name, new Gauge<Integer>() {\n\t\t@Override\n\t\tpublic Integer getValue() {\n\t\t\tif (size() == 0) {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tif (committedOffset == KafkaTopicPartition.DEFAULT_OFFSET) {\n\t\t\t\treturn getLogEndOffset() - getLogStartOffset();\n\t\t\t}\n\t\t\treturn getLogEndOffset() - committedOffset;\n\t\t}\n\t});\n}", "CodeBleu_score": 42.648109172696884}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty) {\nif (log.isDebugEnabled)\nlog.debug(s\"No messages to flush to log $log for partition $partition\")\nreturn 0L\n}\nval messageSet = ByteBufferMessageSet.readFrom(ByteBuffer.wrap(messages.asScala.map(_.payload).toArray))\nif (log.isDebugEnabled)\nlog.debug(s\"Flushing ${messageSet.sizeInBytes} bytes to log $log for partition $partition\")\nval appendInfo = log.append(messageSet, payloadSize)\nif (log.isDebugEnabled)\nlog.debug(s\"Wrote ${messages.size} messages to log $log for partition $partition at offset ${appendInfo.firstOffset} with payload size $payloadSize\")\nmark(messages.size)\nappendInfo.lastOffset\n}", "CodeBleu_score": 33.10300891366046}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty) {\ndebug(\"No messages to flush\")\n} else {\nval messageSet = ByteBufferMessageSet.readFrom(ByteBuffer.wrap(messages.toArray))\ndebug(\"Appending \" + messageSet.sizeInBytes + \" to log \" + log.name)\nval offset = log.append(messageSet)\ndebug(\"Wrote messages to log \" + log.name + \" with last offset \" + offset)\nmark(messages.size)\noffset\n}\n}", "CodeBleu_score": 20.528237188840443}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty) {\ndebug(\"No messages to flush\")\nreturn 0\n}\nval messageSet = ByteBufferMessageSet.readFrom(ByteBuffer.wrap(messages.toArray))\ndebug(\"Flushing \" + messageSet.sizeInBytes + \" byte message set for \" + messages.size + \" messages\")\nval lastOffset = log.append(messageSet)\ndebug(\"Wrote message set with last offset: \" + lastOffset + \" with \" + messages.size + \" messages\")\nmark(messages.size)\nlastOffset\n}", "CodeBleu_score": 22.985391796084187}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\tlog.info(\"Closing Kafka AdminClient for cluster ${clusterPhyId}\")\n\tlock.lock()\n\tdef clientList = adminClientList.get(clusterPhyId)\n\tif (clientList) {\n\t\tlog.info(\"Closing ${clientList.size()} Kafka AdminClient instances for cluster ${clusterPhyId}\")\n\t\tclientList.each { client ->\n\t\t\ttry {\n\t\t\t\tclient.close()\n\t\t\t} catch (e) {\n\t\t\t\tlog.error(\"Error closing Kafka AdminClient for cluster ${clusterPhyId}: ${e.message}\", e)\n\t\t\t}\n\t\t}\n\t\tlog.info(\"Closed ${clientList.size()} Kafka AdminClient instances for cluster ${clusterPhyId}\")\n\t}\n\tlock.unlock()\n}", "CodeBleu_score": 26.914029684725467}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\tlock.lock()\n\ttry {\n\t\tList<AdminClient> clients = adminClientList.get(clusterPhyId)\n\t\tif (clients == null) {\n\t\t\treturn\n\t\t}\n\t\tlogger.info(\"Closing Kafka AdminClient instances for cluster \" + clusterPhyId)\n\t\tfor (AdminClient client : clients) {\n\t\t\ttry {\n\t\t\t\tclient.close()\n\t\t\t} catch (Exception e) {\n\t\t\t\tlogger.error(\"Error closing Kafka AdminClient instance for cluster \" + clusterPhyId, e)\n\t\t\t}\n\t\t}\n\t\tlogger.info(\"Closed Kafka AdminClient instances for cluster \" + clusterPhyId)\n\t} finally {\n\t\tlock.unlock()\n\t}\n}", "CodeBleu_score": 33.92281789082274}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\tdef adminClientList = []\n\tlock.lock()\n\ttry {\n\t\tadminClientList = adminClientMap.get(clusterPhyId)\n\t\tif (adminClientList == null) {\n\t\t\treturn\n\t\t}\n\t\tlog.info(\"Closing Kafka AdminClient for cluster ID: ${clusterPhyId}\")\n\t\tadminClientList.each { adminClient ->\n\t\t\ttry {\n\t\t\t\tadminClient.close()\n\t\t\t\tlog.info(\"Kafka AdminClient for cluster ID: ${clusterPhyId} closed successfully.\")\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.error(\"Failed to close Kafka AdminClient for cluster ID: ${clusterPhyId}\", e)\n\t\t\t}\n\t\t}\n\t} finally {\n\t\tlock.unlock()\n\t}\n}", "CodeBleu_score": 34.018659067180444}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true\n\tif (adminClientList == null) {\n\t\treturn true\n\t}\n\tadminClientList.each { AdminClient adminClient ->\n\t\ttry {\n\t\t\tadminClient.close(30, TimeUnit.SECONDS)\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Failed to close Kafka AdminClient for cluster $clusterPhyId\", e)\n\t\t\tsuccess = false\n\t\t}\n\t}\n\treturn success\n}", "CodeBleu_score": 31.156817717546403}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true\n\tif (adminClientList!= null) {\n\t\tadminClientList.each {\n\t\t\ttry {\n\t\t\t\tit.close(30, TimeUnit.SECONDS)\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.error(\"Error closing AdminClient for cluster ${clusterPhyId}: ${e.getMessage()}\")\n\t\t\t\tsuccess = false\n\t\t\t}\n\t\t}\n\t}\n\treturn success\n}", "CodeBleu_score": 25.581347670406696}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true\n\tif (adminClientList == null) {\n\t\treturn success\n\t}\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30, TimeUnit.SECONDS)\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Error closing AdminClient for cluster $clusterPhyId\", e)\n\t\t\tsuccess = false\n\t\t}\n\t}\n\treturn success\n}", "CodeBleu_score": 41.85333523677277}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\t\tif (app!= null) {\n\t\tapp.stop();\n\t\tint i = 0;\n\t\twhile (app.isRunning() && i++ < 5) {\n\t\t\ttry {\n\t\t\t\tsleep(1000);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 46.572667604987224}, {"code": "public void stop() {\n\t\tif (app!= null) {\n\t\tapp.stop()\n\t\tint attempts = 0\n\t\twhile (app!= null && attempts < 5) {\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000)\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e)\n\t\t\t}\n\t\t\tattempts++\n\t\t}\n\t\tapp = null\n\t}\n}", "CodeBleu_score": 44.815771667894374}, {"code": "public void stop() {\n\t\tif (app!= null) {\n\t\tapp.stop()\n\t\tint count = 0\n\t\twhile (app!= null && count < 5) {\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000)\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e)\n\t\t\t}\n\t\t\tcount++\n\t\t}\n\t\tapp = null\n\t}\n}", "CodeBleu_score": 41.86183660590632}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config)\n\trunner.enableSelfPreservation(false)\n\trunner.setAdditionalCertificates(additionalCertificates)\n\trunner.setTrustStore(trustStore, trustStorePassword)\n\trunner.setKeyStore(keyStore, keyStorePassword)\n\trunner.start()\n\trunner.enableTls(trustStore, trustStorePassword, keyStore, keyStorePassword)\n\trunner.start()\n\trunner\n}", "CodeBleu_score": 32.476942057307355}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config)\n\trunner.enableTls(tlsEnabled)\n\trunner.setKeyStore(keystore, keystorePassword)\n\trunner.setTrustStore(truststore, truststorePassword)\n\trunner.start()\n\trunner\n}", "CodeBleu_score": 37.342395540292785}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config);\n\trunner.enableSelfPreservation(false);\n\trunner.setKeyStore(\"/home/ubuntu/eureka-server/eureka-server.jks\", \"changeit\");\n\trunner.setTrustStore(\"/home/ubuntu/eureka-server/eureka-server.jks\", \"changeit\");\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 37.85393967453116}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\")\n\trunner.enableTlsClient()\n\trunner.start()\n\treturn runner\n}", "CodeBleu_score": 54.35342069872328}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\")\n\tenableTlsClient(runner)\n\trunner.start()\n\trunner\n}", "CodeBleu_score": 51.88987306911225}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\")\n\trunner.enableTlsClient()\n\trunner.start()\n\treturn runner\n}", "CodeBleu_score": 54.35342069872328}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t\tKeyTool caKeyTool = new KeyTool(caKeyToolPath)\n\tcaKeyTool.createCA(caName, caPassword)\n\tsaveCert(caName, caCertPath)\n\tsaveKeyAndCert(caName, caKeyPath, caCertPath)\n\n\tKeyTool serverKeyTool = new KeyTool(serverKeyToolPath)\n\tserverKeyTool.sign(caName, caPassword, serverName, serverPassword)\n\tsaveCert(serverName, serverCertPath)\n\tsaveKeyAndCert(serverName, serverKeyPath, serverCertPath)\n\n\tKeyTool clientKeyTool = new KeyTool(clientKeyToolPath)\n\tclientKeyTool.sign(caName, caPassword, clientName, clientPassword)\n\tsaveCert(clientName, clientCertPath)\n\tsaveKeyAndCert(clientName, clientKeyPath, clientCertPath)\n\n\tKeyTool secondCaKeyTool = new KeyTool(secondCaKeyToolPath)\n\tsecondCaKeyTool.createCA(secondCaName, secondCaPassword)\n\tsaveCert(secondCaName, secondCaCertPath)\n\tsaveKeyAndCert(secondCaName, secondCaKeyPath, secondCaCertPath)\n\n\tKeyTool secondClientKeyTool = new KeyTool(secondClientKeyToolPath)\n\tsecondClientKeyTool.sign(secondCaName, secondCaPassword, secondClientName, secondClientPassword)\n\tsaveCert(secondClientName, secondClientCertPath)\n\tsaveKeyAndCert(secondClientName, secondClientKeyPath, secondClientCertPath)\n}", "CodeBleu_score": 22.77492894104504}, {"code": "static void createCertificates() throws Exception{\n\t\t// Create CA certificate\n\tcreateCA()\n\t// Create server certificate\n\tcreateCert(\"server\", caCert, caKey)\n\t// Create client certificate\n\tcreateCert(\"client\", caCert, caKey)\n\t// Create second CA certificate\n\tcreateCert(\"ca\", null, null)\n\t// Create second client certificate\n\tcreateCert(\"client2\", ca2Cert, ca2Key)\n}", "CodeBleu_score": 7.516794088210732}, {"code": "static void createCertificates() throws Exception{\n\t\t// Create a CA certificate and save it\n\tcreateCA()\n\tsaveCert(caCert, caCertFile)\n\tsaveKeyAndCert(caKey, caCert, caKeyFile, caCertFile)\n\n\t// Create a server certificate and save it\n\tcreateCert(caKey, caCert, serverKey, serverCert, serverCertFile, serverKeyFile, serverAlias, serverSubject)\n\tsaveCert(serverCert, serverCertFile)\n\tsaveKeyAndCert(serverKey, serverCert, serverKeyFile, serverCertFile)\n\n\t// Create a client certificate and save it\n\tcreateCert(caKey, caCert, clientKey, clientCert, clientCertFile, clientKeyFile, clientAlias, clientSubject)\n\tsaveCert(clientCert, clientCertFile)\n\tsaveKeyAndCert(clientKey, clientCert, clientKeyFile, clientCertFile)\n\n\t// Create a second CA certificate and save it\n\tcreateCA()\n\tsaveCert(caCert, ca2CertFile)\n\tsaveKeyAndCert(caKey, caCert, ca2KeyFile, ca2CertFile)\n\n\t// Create a client certificate and save it\n\tcreateCert(caKey, caCert, client2Key, client2Cert, client2CertFile, client2KeyFile, client2Alias, client2Subject)\n\tsaveCert(client2Cert, client2CertFile)\n\tsaveKeyAndCert(client2Key, client2Cert, client2KeyFile, client2CertFile)\n}", "CodeBleu_score": 20.448549802056494}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis()\n\tlong timeLimit = startTime + seconds * 1000\n\twhile (!assertion.getAsBoolean()) {\n\t\tif (System.currentTimeMillis() > timeLimit) {\n\t\t\tthrow new RuntimeException(\"Assertion timed out after $seconds seconds.\")\n\t\t}\n\t\tyield()\n\t}\n}", "CodeBleu_score": 39.18249706942116}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis()\n\tlong timeLimit = startTime + seconds * 1000\n\twhile (System.currentTimeMillis() < timeLimit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn\n\t\t}\n\t}\n\tthrow new RuntimeException(\"Assertion failed within ${seconds} seconds\")\n}", "CodeBleu_score": 42.22033761262758}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong start = System.currentTimeMillis()\n\tlong limit = start + (seconds * 1000)\n\twhile (!assertion.getAsBoolean()) {\n\t\tif (System.currentTimeMillis() > limit) {\n\t\t\tthrow new RuntimeException(\"Assertion failed after $seconds seconds\")\n\t\t}\n\t\tyield()\n\t}\n}", "CodeBleu_score": 40.27957807806042}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\t// Create a certificate builder with the public key and CA information\n\tX509v3CertificateBuilder certBuilder = new JcaX509v3CertificateBuilder(\n\t\t\tnew X500Name(ca),\n\t\t\tBigInteger.valueOf(System.currentTimeMillis()),\n\t\t\tnew Date(System.currentTimeMillis() - 1000L * 60 * 60 * 24 * 30),\n\t\t\tnew Date(System.currentTimeMillis() + (1000L * 60 * 60 * 24 * 365 * 10)),\n\t\t\tnew X500Name(ca),\n\t\t\tkeyPair.getPublic()\n\t);\n\n\t// Add key usage and basic constraints extensions to the certificate\n\tcertBuilder.addExtension(\n\t\t\tExtension.keyUsage,\n\t\t\tfalse,\n\t\t\tnew KeyUsage(KeyUsage.keyEncipherment | KeyUsage.dataEncipherment | KeyUsage.keyAgreement | KeyUsage.digitalSignature)\n\t);\n\tcertBuilder.addExtension(\n\t\t\tExtension.basicConstraints,\n\t\t\ttrue,\n\t\t\tnew BasicConstraints(false)\n\t);\n\n\t// Sign the certificate with the private key\n\tContentSigner signer = new JcaContentSignerBuilder(\"SHA256WithRSA\").build(keyPair.getPrivate());\n\tX509CertificateHolder certHolder = certBuilder.build(signer);\n\treturn new JcaX509CertificateConverter().getCertificate(certHolder);\n}", "CodeBleu_score": 36.307259635229485}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tX509Certificate cert = certBuilder(keyPair, ca)\n\t\t.addExtension(\n\t\t\tExtension.keyUsage,\n\t\t\ttrue,\n\t\t\tnew KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment)\n\t\t)\n\t\t.addExtension(\n\t\t\tExtension.basicConstraints,\n\t\t\ttrue,\n\t\t\tnew BasicConstraints(false)\n\t\t)\n\t\t.build(signCert(keyPair.getPrivate()))\n\treturn cert\n}", "CodeBleu_score": 45.860904411121105}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\t// create cert builder with public key and CA information\n\tX509v3CertificateBuilder certBuilder = new JcaX509v3CertificateBuilder(\n\t\tnew X500Name(ca),\n\t\tBigInteger.valueOf(System.currentTimeMillis()),\n\t\tnew Date(System.currentTimeMillis() - 1000L * 60 * 60 * 24 * 30),\n\t\tnew Date(System.currentTimeMillis() + (1000L * 60 * 60 * 24 * 365 * 10)),\n\t\tnew X500Name(\"CN=test\"),\n\t\tkeyPair.getPublic()\n\t);\n\n\t// add key usage and basic constraints extensions\n\tcertBuilder.addExtension(\n\t\tExtension.keyUsage,\n\t\tfalse,\n\t\tnew KeyUsage(KeyUsage.keyEncipherment | KeyUsage.dataEncipherment | KeyUsage.keyAgreement)\n\t);\n\tcertBuilder.addExtension(\n\t\tExtension.basicConstraints,\n\t\ttrue,\n\t\tnew BasicConstraints(false)\n\t);\n\n\t// sign the certificate with the private key\n\tContentSigner contentSigner = new JcaContentSignerBuilder(\"SHA256WithRSAEncryption\").build(keyPair.getPrivate());\n\tX509CertificateHolder certHolder = certBuilder.build(contentSigner);\n\tX509Certificate cert = new JcaX509CertificateConverter().getCertificate(certHolder);\n\n\treturn cert;\n}", "CodeBleu_score": 36.07600282288025}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\tField registrationClientField = eurekaTransport.class.getDeclaredField(\"registrationClient\");\n\t\t\tregistrationClientField.setAccessible(true);\n\t\t\teurekaHttpClient = (EurekaHttpClient) registrationClientField.get(eurekaTransport);\n\t\t} catch (IllegalAccessException e) {\n\t\t\tlogger.error(\"Cannot access registrationClient field\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 44.31181302946071}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\tField field = eurekaTransport.class.getDeclaredField(\"registrationClient\");\n\t\t\tfield.setAccessible(true);\n\t\t\teurekaHttpClient = (EurekaHttpClient) field.get(eurekaTransport);\n\t\t} catch (IllegalAccessException | NoSuchFieldException e) {\n\t\t\tlogger.error(\"Cannot access registrationClient field\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 38.171142760618096}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\teurekaHttpClient = (EurekaHttpClient) eurekaTransport.registrationClient.getClass().getDeclaredField(\"eurekaHttpClient\").get(eurekaTransport.registrationClient);\n\t\t} catch (IllegalAccessException e) {\n\t\t\tlogger.error(\"Cannot access registrationClient field\", e);\n\t\t} catch (NoSuchFieldException e) {\n\t\t\tlogger.error(\"Cannot access registrationClient field\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 45.76331537133362}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t\tList<Application> applications = getApplications();\n\tif (applications == null || applications.isEmpty()) {\n\t\treturn Collections.emptyList();\n\t}\n\tList<String> services = new ArrayList<>(applications.size());\n\tfor (Application application : applications) {\n\t\tif (application.getInstances()!= null &&!application.getInstances().isEmpty()) {\n\t\t\tservices.add(application.getName().toLowerCase());\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 49.867000007174646}, {"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<>();\n\tApplications applications = eurekaClient.getApplications();\n\tif (applications == null || applications.getRegisteredApplications().isEmpty()) {\n\t\treturn services;\n\t}\n\tfor (Application application : applications.getRegisteredApplications()) {\n\t\tif (application.getInstances()!= null &&!application.getInstances().isEmpty()) {\n\t\t\tservices.add(application.getName().toLowerCase());\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 49.6580831589018}, {"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<>();\n\tApplications applications = eurekaClient.getApplications();\n\tif (applications == null || applications.getRegisteredApplications().isEmpty()) {\n\t\treturn services;\n\t}\n\tfor (Application application : applications.getRegisteredApplications()) {\n\t\tif (application.getInstances().isEmpty()) {\n\t\t\tcontinue;\n\t\t}\n\t\tservices.add(application.getName().toLowerCase());\n\t}\n\treturn services;\n}", "CodeBleu_score": 52.05707697151873}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tthis.healthContributors.forEach { key, value ->\n\t\tif (value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\t((DiscoveryCompositeHealthContributor) value).getIndicators().forEach { indicator ->\n\t\t\t\tif (indicator instanceof HealthIndicator &&!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(key + \":\" + indicator.getName(), indicator)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\thealthContributors.put(key, value)\n\t\t}\n\t}\n}", "CodeBleu_score": 29.180938794653642}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\thealthContributors.forEach((key, value) -> {\n\t\tif (value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\t((DiscoveryCompositeHealthContributor) value).getIndicators().forEach((indicatorKey, indicatorValue) -> {\n\t\t\t\tif (!(indicatorValue instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(indicatorKey, indicatorValue);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t\telse {\n\t\t\thealthContributors.put(key, value);\n\t\t}\n\t});\n}", "CodeBleu_score": 31.973630746051164}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\thealthContributors.forEach((key, value) -> {\n\t\tif (value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\t((DiscoveryCompositeHealthContributor) value).getIndicators().forEach((k, v) -> {\n\t\t\t\tif (!(v instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(k, v);\n\t\t\t\t}\n\t\t\t});\n\t\t} else {\n\t\t\thealthContributors.put(key, value);\n\t\t}\n\t});\n}", "CodeBleu_score": 29.348256864186435}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t\tInstanceInfo instance = discoveryClient.getNextServerFromEureka(\"provider-application\", false);\n\tURI uri = instance.getHomePageUrl();\n\treturn restTemplate.postForObject(uri + \"/echo\", \"hello\", String.class);\n}", "CodeBleu_score": 22.081268281043247}, {"code": "public String hello(){\n\t\tList<ServiceInstance> list = discoveryClient.getInstances(\"provider-application\");\n\tif (list!= null && list.size() > 0 ) {\n\t\tServiceInstance serviceInstance = list.get(0);\n\t\tString uri = serviceInstance.getUri().toString();\n\t\tString result = restTemplate.postForObject(uri + \"/echo\", \"hello\", String.class);\n\t\treturn result;\n\t} else {\n\t\tthrow new RuntimeException(\"no service instance for provider-application\");\n\t}\n}", "CodeBleu_score": 59.77880524167972}, {"code": "public String hello(){\n\t\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances.isEmpty()) {\n\t\tthrow new RuntimeException(\"No instances found for provider-application\");\n\t}\n\tServiceInstance serviceInstance = instances.get(0);\n\tString baseUrl = serviceInstance.getUri().toString();\n\tbaseUrl = baseUrl + \"/echo\";\n\tString response = restTemplate.postForObject(baseUrl, \"Hello World\", String.class);\n\treturn response;\n}", "CodeBleu_score": 59.78815502828076}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t\tServiceInstance serviceInstance = loadBalancerClient.choose(\"provider-application\");\n\tURI uri = serviceInstance.getUri();\n\treturn restTemplate.postForObject(uri + \"/echo\", \"Hello World!\", String.class);\n}", "CodeBleu_score": 37.16913439031043}, {"code": "public String world(){\n\t\tServiceInstance serviceInstance = loadBalancerClient.choose(\"provider-application\");\n\tString baseUrl = serviceInstance.getUri().toString();\n\tbaseUrl = baseUrl + \"/echo\";\n\tRestTemplate restTemplate = new RestTemplate();\n\tString response = restTemplate.postForObject(baseUrl, \"Hello World\", String.class);\n\treturn response;\n}", "CodeBleu_score": 51.3369309275796}, {"code": "public String world(){\n\t\t// Load balancer client\n\tServiceInstance serviceInstance = loadBalancerClient.choose(\"provider-application\");\n\t// Construct URI\n\tURI uri = URI.create(String.format(\"http://%s:%s/echo\", serviceInstance.getHost(), serviceInstance.getPort()));\n\t// Send POST request\n\tString response = restTemplate.postForObject(uri, \"Hello World!\", String.class);\n\treturn response;\n}", "CodeBleu_score": 53.63136020661546}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serviceName == null || ip == null || port == null) {\n\t\treturn false;\n\t}\n\n\tsynchronized (serverMap) {\n\t\tif (!serverMap.containsKey(serviceName)) {\n\t\t\tserverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n\t\t}\n\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\tlogger.info(\"Registered service: \" + serviceName + \" with IP: \" + ip + \" and port: \" + port);\n\t}\n\treturn true;\n}", "CodeBleu_score": 49.62985750978906}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tlogger.info(\"Received registration request for service: \" + serviceName + \" with IP: \" + ip + \" and port: \" + port);\n\tsynchronized (serverMap) {\n\t\tSet<Server> servers = serverMap.getOrDefault(serviceName, new HashSet<>());\n\t\tServer server = new Server(ip, port);\n\t\tif (servers.add(server)) {\n\t\t\tserverMap.put(serviceName, servers);\n\t\t\tlogger.info(\"Registered service: \" + serviceName + \" with IP: \" + ip + \" and port: \" + port);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 57.281900312904085}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tsynchronized (serverMap) {\n\t\tif (!serverMap.containsKey(serviceName)) {\n\t\t\tserverMap.put(serviceName, new HashSet<Server>());\n\t\t}\n\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\tlogger.info(\"Registered service: \" + serviceName + \" with ip: \" + ip + \" and port: \" + port);\n\t\treturn true;\n\t}\n}", "CodeBleu_score": 48.36637897168809}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tServer server = new Server(serviceName, ip, port);\n\tif (serverMap.containsKey(serviceName)) {\n\t\tSet<Server> servers = serverMap.get(serviceName);\n\t\tif (servers.contains(server)) {\n\t\t\tservers.remove(server);\n\t\t\tlogger.info(\"Deregistered server \" + server);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 50.6629512640314}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tlogger.info(\"Deregistering \" + ip + \":\" + port + \" from \" + serviceName);\n\tServer server = new Server(ip, port);\n\tif (serverMap.containsKey(serviceName)) {\n\t\tSet<Server> servers = serverMap.get(serviceName);\n\t\tif (servers.remove(server)) {\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 50.67064851391816}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tServer server = new Server(serviceName, ip, port);\n\tif (serverMap.containsKey(serviceName)) {\n\t\tSet<Server> servers = serverMap.get(serviceName);\n\t\tservers.remove(server);\n\t\tif (servers.isEmpty()) {\n\t\t\tserverMap.remove(serviceName);\n\t\t}\n\t\tlog.info(\"Deregistered server: \" + server);\n\t\treturn true;\n\t}\n\treturn false;\n}", "CodeBleu_score": 50.90974219452472}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getCanonicalName());\n\tif (attributes!= null && attributes.containsKey(\"value\")) {\n\t\tAnnotationAttributes[] clientConfigurations = (AnnotationAttributes[]) attributes.get(\"value\");\n\t\tfor (AnnotationAttributes clientConfiguration : clientConfigurations) {\n\t\t\tString name = clientConfiguration.getString(\"name\");\n\t\t\tClass<?> configClass = clientConfiguration.getClass(\"defaultConfiguration\");\n\t\t\tregisterClientConfiguration(registry, name, configClass);\n\t\t}\n\t}\n}", "CodeBleu_score": 48.26157529053662}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getCanonicalName());\n\tif (attributes!= null) {\n\t\tMultiValueMap<String, Object> clients = (MultiValueMap<String, Object>) attributes.get(\"value\");\n\t\tif (clients!= null) {\n\t\t\tfor (Object client : clients) {\n\t\t\t\tgenerateBeanDefinition(client, registry);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 45.341699445298204}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getCanonicalName());\n\tif (attributes!= null && attributes.containsKey(\"value\")) {\n\t\tAnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(RibbonClient.class);\n\t\tClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(false);\n\t\tscanner.addIncludeFilter(annotationTypeFilter);\n\t\tfor (Object value : (Object[]) attributes.get(\"value\")) {\n\t\t\tif (value instanceof Annotation) {\n\t\t\t\tAnnotation annotation = (Annotation) value;\n\t\t\t\tString name = (String) annotation.annotationType().getAnnotation(RibbonClient.class).name();\n\t\t\t\tif (name.isEmpty()) {\n\t\t\t\t\tname = (String) annotation.annotationType().getAnnotation(RibbonClient.class).value();\n\t\t\t\t}\n\t\t\t\tif (!registry.containsBeanDefinition(name)) {\n\t\t\t\t\tBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(\n\t\t\t\t\t\t\tRibbonClientConfiguration.class);\n\t\t\t\t\tbuilder.addConstructorArgValue(annotation);\n\t\t\t\t\tbuilder.setScope(BeanDefinition.SCOPE_SINGLETON);\n\t\t\t\t\tregistry.registerBeanDefinition(name, builder.getBeanDefinition());\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (value instanceof RibbonClient) {\n\t\t\t\tRibbonClient annotation = (RibbonClient) value;\n\t\t\t\tString name = annotation.name();\n\t\t\t\tif (name.isEmpty()) {\n\t\t\t\t\tname = annotation.value();\n\t\t\t\t}\n\t\t\t\tif (!registry.containsBeanDefinition(name)) {\n\t\t\t\t\tBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(\n\t\t\t\t\t\t\tRibbonClientConfiguration.class);\n\t\t\t\t\tbuilder.addConstructorArgValue(annotation);\n\t\t\t\t\tbuilder.setScope(BeanDefinition.SCOPE_SINGLETON);\n\t\t\t\t\tregistry.registerBeanDefinition(name, builder.getBeanDefinition());\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (value instanceof Class) {\n\t\t\t\tClass<?> clazz = (Class<?>) value;\n\t\t\t\tString name = clazz.getAnnotation(RibbonClient.class).name();\n\t\t\t\tif (name.isEmpty()) {\n\t\t\t\t\tname = clazz.getAnnotation(RibbonClient.class).value();\n\t\t\t\t}\n\t\t\t\tif (!registry.containsBeanDefinition(name)) {\n\t\t\t\t\tBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(\n\t\t\t\t\t\t\tRibbonClientConfiguration.class);", "CodeBleu_score": 37.99488907255104}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\t// Get the service instances from the service discovery\n\tList<TutuServiceInstance> serviceInstances = getServiceInstances(serviceId);\n\n\t// Check if there are any service instances available\n\tif (serviceInstances.isEmpty()) {\n\t\treturn null;\n\t}\n\n\t// Choose a server instance based on the load balancer algorithm\n\tTutuServiceInstance server = chooseServer(serviceInstances);\n\n\t// Create a ServiceInstance object to represent the chosen server\n\treturn new ServiceInstance(server.getServiceId(), server.getHost(), server.getPort());\n}", "CodeBleu_score": 38.89527927486592}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\t// Get the service instance list from the load balancer\n\tList<ServiceInstance> serviceInstances = getLoadBalancer().getReachableServers(serviceId);\n\n\t// If there are no service instances, return null\n\tif (serviceInstances == null || serviceInstances.isEmpty()) {\n\t\treturn null;\n\t}\n\n\t// Get the default context from the request\n\tMap<String, Object> defaultContext = request.getContext();\n\n\t// Choose a server based on the service ID and default context\n\tServiceInstance chosenServer = chooseServer(serviceId, defaultContext);\n\n\t// If a server is chosen, create a TutuServiceInstance representing the chosen server's details\n\tif (chosenServer!= null) {\n\t\treturn new TutuServiceInstance(chosenServer.getServiceId(), chosenServer.getHost(), chosenServer.getPort(), chosenServer.isSecure(), chosenServer.getMetadata());\n\t}\n\n\t// If no server is chosen, return null\n\treturn null;\n}", "CodeBleu_score": 44.73586358987042}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\t// get the context\n\tContext context = getContext(request);\n\t// get the server list\n\tList<TutuServer> servers = getServerList(serviceId, context);\n\t// select a server\n\tTutuServer server = selectServer(servers);\n\t// create and return a TutuServiceInstance\n\tif (server!= null) {\n\t\treturn new TutuServiceInstance(serviceId, server.getHost(), server.getPort());\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 55.39387041185879}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\ttry {\n\t\tURI uri = new URI(server.getScheme(), null, server.getHost(), server.getPort(), original.getPath(), original.getQuery(), null);\n\t\treturn uri;\n\t} catch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 34.32267941447049}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\ttry {\n\t\treturn new URI(original.getScheme(), null, server.getHost(), server.getPort(), original.getPath(), original.getQuery(), null);\n\t} catch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 23.794088728493072}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\ttry {\n\t\tURIBuilder builder = new URIBuilder(original);\n\t\tbuilder.setHost(server.getHost());\n\t\tbuilder.setPort(server.getPort());\n\t\tbuilder.setScheme(server.getScheme());\n\t\treturn builder.build();\n\t} catch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 35.63172921114962}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t\tdef params = [serviceName: serviceName]\n\tdef resp = getServerAddr().get(path: '/list', query: params)\n\tresp.json.collect {\n\t\tnew TutuServer(it.ip, it.port)\n\t}\n}", "CodeBleu_score": 9.7738302160066}, {"code": "private List<TutuServer> getServer(){\n\t\t// Construct the URL for the request\n\tString url = serverAddr + \"/list\"\n\n\t// Create a new HTTP GET request\n\tRequest request = new Request.Builder()\n\t\t.url(url)\n\t\t.build()\n\n\t// Send the request and get the response\n\tResponse response = client.newCall(request).execute()\n\n\t// Parse the JSON array into a list of TutuServer objects\n\tList<TutuServer> servers = new ArrayList<>()\n\tif (response.isSuccessful()) {\n\t\tJSONArray jsonArray = new JSONArray(response.body().string())\n\t\tfor (int i = 0; i < jsonArray.length(); i++) {\n\t\t\tJSONObject jsonObject = jsonArray.getJSONObject(i)\n\t\t\tString ip = jsonObject.getString(\"ip\")\n\t\t\tint port = jsonObject.getInt(\"port\")\n\t\t\tservers.add(new TutuServer(ip, port))\n\t\t}\n\t}\n\n\t// Return the list of TutuServer objects\n\treturn servers\n}", "CodeBleu_score": 33.63375346075282}, {"code": "private List<TutuServer> getServer(){\n\t\tdef params = [\n\t\tserviceName: serviceName\n\t]\n\tdef url = getServerAddr() + \"/list\"\n\tdef response = get(url, params)\n\tdef json = parseArray(response)\n\tdef servers = json.collect {\n\t\tnew TutuServer(\n\t\t\tip: it.ip,\n\t\t\tport: it.port\n\t\t)\n\t}\n\treturn servers\n}", "CodeBleu_score": 19.105715219391584}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t\tfor (String location : this.routeLocator.getRoutes().keySet()) {\n\t\tif (this.pathMatcher.match(location, path)) {\n\t\t\tString routePath = path.substring(location.length());\n\t\t\treturn new Route(location, routePath, this.routeLocator.getRoutes().get(location).getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 31.366351640428725}, {"code": "public Route getMatchingRoute(String path){\n\t\tfor (String routeId : this.routeLocator.getRoutes().keySet()) {\n\t\tRoute route = this.routeLocator.getRoute(routeId);\n\t\tif (route!= null) {\n\t\t\tif (this.pathMatcher.match(route.getPath(), path)) {\n\t\t\t\tString trimmedPath = path.substring(path.indexOf(route.getPath()));\n\t\t\t\treturn new Route(route.getId(), trimmedPath, route.getLocation(),\n\t\t\t\t\t\troute.getRetryable(), route.getCustomSensitiveHeaders(), route.isPrefixStripped(),\n\t\t\t\t\t\troute.isStripPrefix(), route.isRetryable(), route.getPrefix(), route.getServiceId());\n\t\t\t}\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 35.030055461032376}, {"code": "public Route getMatchingRoute(String path){\n\t\tfor (String location : this.routes.keySet()) {\n\t\tif (this.pathMatcher.match(location, path)) {\n\t\t\tString trimmedPath = path.substring(location.length());\n\t\t\treturn new Route(location, trimmedPath, this.routes.get(location).serviceId);\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 31.02593691428708}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\t// \u83b7\u53d6\u5305\u540d\n\tString packageName = getPackageName(importingClassMetadata);\n\t// \u626b\u63cf\u5305\u8def\u5f84\u4e0b\u7684\u7c7b\n\tSet<BeanDefinitionHolder> beanDefinitions = scanPackageByAnnotation(packageName, registry, FeignClient.class);\n\tfor (BeanDefinitionHolder beanDefinition : beanDefinitions) {\n\t\t// \u83b7\u53d6\u6ce8\u89e3\u4fe1\u606f\n\t\tAnnotationMetadata annotationMetadata = beanDefinition.getBeanDefinition().getResource().getAnnotationMetadata();\n\t\t// \u83b7\u53d6\u6ce8\u89e3\u5c5e\u6027\u503c\n\t\tMap<String, Object> attributes = annotationMetadata.getAnnotationAttributes(FeignClient.class.getName());\n\t\t// \u83b7\u53d6\u7c7b\u540d\n\t\tString className = annotationMetadata.getClassName();\n\t\t// \u83b7\u53d6bean\u540d\u79f0\n\t\tString beanName = getBeanName(attributes.get(NAME_ATTRIBUTE), className);\n\t\t// \u6ce8\u518cbean\n\t\tregisterFeignClient(registry, annotationMetadata, attributes, beanName);\n\t}\n}", "CodeBleu_score": 35.97618570273386}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\t// \u83b7\u53d6\u5305\u540d\n\tString packageName = getPackageName(importingClassMetadata);\n\t// \u626b\u63cf\u5305\u540d\u4e0b\u7684\u7c7b\n\tSet<BeanDefinitionHolder> beanDefinitions = scanPackageByAnnotation(packageName, registry, FeignClient.class);\n\tfor (BeanDefinitionHolder holder : beanDefinitions) {\n\t\t// \u83b7\u53d6\u7c7b\u540d\n\t\tString beanName = holder.getBeanName();\n\t\t// \u83b7\u53d6\u7c7b\n\t\tClass<?> beanType = holder.getBeanDefinition().getBeanClassName();\n\t\t// \u83b7\u53d6\u6ce8\u89e3\n\t\tFeignClient annotation = findAnnotation(beanType, FeignClient.class);\n\t\t// \u521b\u5efabean\n\t\tGenericBeanDefinition beanDefinition = new GenericBeanDefinition();\n\t\tbeanDefinition.setBeanClass(FeignClientFactoryBean.class);\n\t\tbeanDefinition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);\n\t\t// \u8bbe\u7f6ebean\u7684\u5c5e\u6027\n\t\tMutablePropertyValues propertyValues = beanDefinition.getPropertyValues();\n\t\tpropertyValues.addPropertyValue(\"contextId\", beanName);\n\t\tpropertyValues.addPropertyValue(\"type\", beanType);\n\t\tpropertyValues.addPropertyValue(\"name\", annotation.name());\n\t\tpropertyValues.addPropertyValue(\"url\", annotation.url());\n\t\tpropertyValues.addPropertyValue(\"path\", annotation.path());\n\t\tpropertyValues.addPropertyValue(\"decode404\", annotation.decode404());\n\t\tpropertyValues.addPropertyValue(\"fallback\", annotation.fallback());\n\t\tpropertyValues.addPropertyValue(\"fallbackFactory\", annotation.fallbackFactory());\n\t\tregistry.registerBeanDefinition(beanName, beanDefinition);\n\t}\n}", "CodeBleu_score": 48.419490934668495}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = importingClassMetadata.getAnnotationAttributes(EnableFeignClients.class.getName());\n\tAnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(FeignClient.class);\n\tClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(false);\n\tscanner.addIncludeFilter(annotationTypeFilter);\n\tfor (String basePackage : getBasePackages(attributes)) {\n\t\tSet<BeanDefinition> candidateComponents = scanner.findCandidateComponents(basePackage);\n\t\tfor (BeanDefinition candidateComponent : candidateComponents) {\n\t\t\tif (candidateComponent instanceof AnnotatedBeanDefinition) {\n\t\t\t\t// verify annotated class is an interface\n\t\t\t\tAnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent;\n\t\t\t\tAnnotationMetadata annotationMetadata = beanDefinition.getMetadata();\n\t\t\t\tAssert.isTrue(annotationMetadata.isInterface(),\n\t\t\t\t\t\t\"@FeignClient can only be specified on an interface\");\n\n\t\t\t\tMap<String, Object> attributes = annotationMetadata\n\t\t\t\t\t\t.getAnnotationAttributes(\n\t\t\t\t\t\t\t\tFeignClient.class.getCanonicalName());\n\n\t\t\t\tString name = getClientName(attributes);\n\t\t\t\tregisterClientConfiguration(registry, name,\n\t\t\t\t\t\tattributes.get(\"configuration\"));\n\n\t\t\t\tregisterFeignClient(registry, annotationMetadata, attributes);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 31.998047688078902}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}]}
