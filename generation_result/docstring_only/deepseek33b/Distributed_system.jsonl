{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n    wait_time = (self.loop_wait - 2) * 1000\n    return wait_time, self._kazoo_client.connection.connect(*args)\n", "CodeBleu_score": 45.10563769163015}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n    loop_wait = max(2, self.loop_wait)\n    wait_time = (loop_wait - 2) * 1000\n    ret = self.original_connect(*args)\n    return wait_time, ret\n\n", "CodeBleu_score": 46.41222341156382}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n    wait = max(2, self.loop_wait - 2) * 1000\n    return wait, self.original_connect(*args)\n", "CodeBleu_score": 49.14796501676952}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\n    if config.get('retry_timeout') is not None:\n        self.retry_timeout = config['retry_timeout']\n    if config.get('loop_wait') is not None:\n        self.loop_wait = config['loop_wait']\n        if self.client_handler.__class__.__name__ == 'PatroniSequentialThreadingHandler':\n            self.client_handler.connect_timeout = self.loop_wait\n    if config.get('ttl') is not None:\n        if not self.update_ttl(config['ttl']):\n            if self.loop_wait != config['loop_wait']:\n                self.client_handler.close()\n            return\n    self.update_callbacks()\n", "CodeBleu_score": 45.15673559338642}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n    if isinstance(config, dict):\n        config = Config(config)\n    self.retry_timeout = config['retry_timeout']\n    self.loop_wait = config['loop_wait']\n    if self.ttl != config['ttl']:\n        if self.ttl:\n            self.ttl.cancel()\n        self.ttl = self.loop.call_later(self.loop_wait * 10, self.ttl_update)\n    if self.loop_wait != self.config['loop_wait'] and isinstance(self.client_handler, PatroniSequentialThreadingHandler):\n        self.client_handler.connect_timeout = self.loop_wait", "CodeBleu_score": 39.87153519389826}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n    if isinstance(config, dict):\n        config = Config(config)\n    self.retry_timeout = config['retry_timeout']\n    self.loop_wait = config['loop_wait']\n    if self.ttl != config['ttl']:\n        self.ttl = config['ttl']\n        if self.loop_wait != config['loop_wait']:\n            self.client.connect_timeout = config['loop_wait']\n        try:\n            self.client.send_command(b'CONFIG', b'SET', b'TTL', self.ttl)\n        except Exception:\n            self.close()\n\n", "CodeBleu_score": 36.00590711851298}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n    if not os.path.exists(path):\n        raise Exception(\"Cluster path does not exist.\")\n\n    # Initialize the cluster object\n    cluster = Cluster(path)\n\n    # Check if the cluster is initialized\n    if not os.path.exists(os.path.join(path, \"postgresql.conf\")):\n        cluster.initialized = False\n        return cluster\n\n    # Load the configuration\n    cluster.config = self._postgresql_config_loader(path)\n\n    # Load the timeline history\n    cluster.timeline_history = self._postgresql_timeline_history_loader(path)\n\n    # Load the synchronization state\n    cluster.synchronization = self._postgresql_synchronization_state_loader(path)\n\n    # Load the members\n    cluster.members = self._postgresql_members_loader(path)\n\n    # Load the leader information\n    cluster.leader = self._postgresql_leader_loader(path)\n\n    # Load the cluster status\n    cluster.status = self._postgresql_cluster_status_loader(path)\n\n    # Load the failover state\n    cluster.failover = self._postgresql_failover_state_loader(path)\n\n    # Load the failsafe configuration\n    cluster.failsafe = self._postgresql_failsafe_config_loader(path)\n\n    return cluster\n\n", "CodeBleu_score": 13.11784634238121}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\n    # Check if the path exists\n    if not os.path.exists(path):\n        raise FileNotFoundError(f\"Path {path} does not exist\")\n\n    # Check if the path is a directory\n    if not os.path.isdir(path):\n        raise NotADirectoryError(f\"Path {path} is not a directory\")\n\n    # Load the cluster initialization state\n    init_state = self._postgresql_cluster_init_state_loader(path)\n\n    # Load the cluster configuration\n    config = self._postgresql_cluster_config_loader(path)\n\n    # Load the timeline history\n    timeline_history = self._postgresql_cluster_timeline_history_loader(path)\n\n    # Load the synchronization state\n    synchronization_state = self._postgresql_cluster_synchronization_state_loader(path)\n\n    # Load the members\n    members = self._postgresql_cluster_members_loader(path)\n\n    # Load the leader information\n    leader = self._postgresql_cluster_leader_loader(path)\n\n    # Load the cluster status\n    status = self._postgresql_cluster_status_loader(path)\n\n    # Load the failover state\n    failover_state = self._postgresql_cluster_failover_state_loader(path)\n\n    # Load the failsafe configuration\n    failsafe_config = self._postgresql_cluster_failsafe_config_loader(path)\n\n    # Create a Cluster object with the loaded information\n    cluster = Cluster(\n        init_state=init_state,\n        config=config,\n        timeline_history=timeline_history,\n        synchronization_state=synchronization_state,\n        members=members,\n        leader=leader,\n        status=status,\n        failover_state=failover_state,\n        failsafe_config=failsafe_config,\n    )\n\n    return cluster\n\n", "CodeBleu_score": 19.296758671086323}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\n    if not self.pg_cluster_exists(path):\n        raise ClusterNotFound(f\"Cluster {path} not found\")\n\n    cluster = Cluster(path=path)\n\n    # Initialize state\n    if self.pg_initialized(path):\n        cluster.init_state = self.pg_initialized(path)\n\n    # Configuration\n    if self.pg_config_exists(path):\n        cluster.config = self.pg_config(path)\n\n    # Timeline history\n    if self.pg_timeline_history_exists(path):\n        cluster.timeline_history = self.pg_timeline_history(path)\n\n    # Synchronization state\n    if self.pg_synchronization_state_exists(path):\n        cluster.synchronization_state = self.pg_synchronization_state(path)\n\n    # Members\n    if self.pg_members_exists(path):\n        cluster.members = self.pg_members(path)\n\n    # Leader information\n    if self.pg_leader_exists(path):\n        cluster.leader = self.pg_leader(path)\n\n    # Cluster status\n    if self.pg_cluster_status_exists(path):\n        cluster.status = self.pg_cluster_status(path)\n\n    # Failover state\n    if self.pg_failover_state_exists(path):\n        cluster.failover_state = self.pg_failover_state(path)\n\n    # Failsafe configuration\n    if self.pg_failsafe_config_exists(path):\n        cluster.failsafe_config = self.pg_failsafe_config(path)\n\n    return cluster\n\n", "CodeBleu_score": 15.71941897270957}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n    try:\n        self.zk.create(self.leader_path, b\"\", ephemeral=True)\n        return True\n    except kazoo.exceptions.KazooException as e:\n        if self.zk.client_state == KazooState.CONNECTED:\n            self.logger.warning(\n                \"Zookeeper connection is open, but leader lock could not be acquired. Retrying...\"\n            )\n            for i in range(self.retry_count):\n                try:\n                    self.zk.create(self.leader_path, b\"\", ephemeral=True)\n                    return True\n                except kazoo.exceptions.KazooException as e:\n                    if i == self.retry_count - 1:\n                        raise e\n                    self.logger.warning(\n                        \"Zookeeper connection is open, but leader lock could not be acquired. Retrying...\"\n                    )\n                    time.sleep(self.retry_delay)\n        else:\n            raise ZooKeeperError(\n                \"Zookeeper connection is closed. Leader lock could not be acquired.\"\n            )\n    except NodeExistsError:\n        self.logger.info(\"Another instance has the leader lock.\")\n    return False\n\n", "CodeBleu_score": 45.444642664599264}, {"code": "def attempt_to_acquire_leader(self) -> bool\n    try:\n        self.zk.create(\n            self.leader_path,\n            ephemeral=True,\n            makepath=True,\n        )\n        return True\n    except kazoo.exceptions.ConnectionClosedError:\n        raise ZooKeeperError(\"ZooKeeper connection closed\")\n    except Exception as e:\n        if not isinstance(e, kazoo.exceptions.NodeExistsError):\n            self.logger.exception(e)\n        else:\n            self.logger.info(f\"Another instance has the lock: {self.leader_path}\")\n        return False\n\n", "CodeBleu_score": 45.247775844405325}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\n    try:\n        self._zk.create(\n            self._leader_path,\n            value=self._hostname.encode(),\n            ephemeral=True,\n        )\n        return True\n    except (ConnectionLoss, SessionExpiredError):\n        raise ZooKeeperError(\"Connection to ZooKeeper lost\")\n    except Exception as e:\n        if not isinstance(e, NodeExistsError):\n            self._logger.exception(\n                \"Error while attempting to acquire leader lock\"\n            )\n        return False\n\n", "CodeBleu_score": 45.86158017669951}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n    if self.client_id != leader.session:\n        logger.warning(\n            \"Current client ID does not match leader's session. \"\n            \"Attempting to delete existing leader ZNode.\"\n        )\n        try:\n            self.client.delete(self.leader_path)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError):\n            pass\n        except Exception as e:\n            raise ZooKeeperError(f\"Error deleting leader ZNode: {e}\")\n\n    try:\n        self.client.create(\n            self.leader_path, self.client_id.encode(\"utf-8\"), ephemeral=True\n        )\n    except Exception as e:\n        logger.warning(f\"Error creating leader ZNode: {e}\")\n        return False\n\n    return True\n\n", "CodeBleu_score": 38.21058657921635}, {"code": "def _update_leader(self, leader: Leader) -> bool\n    if self.client_id != leader.session:\n        logger.warning(\n            f\"Client ID {self.client_id} does not match leader session {leader.session}\"\n        )\n        try:\n            self.zk.delete(self.leader_path)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError):\n            pass\n        except Exception as e:\n            logger.error(f\"Error deleting leader ZNode: {e}\")\n            raise ZooKeeperError(f\"Error deleting leader ZNode: {e}\")\n\n    try:\n        self.zk.create(\n            self.leader_path, self.client_id.encode(\"utf-8\"), ephemeral=True\n        )\n    except (NodeExistsError, ConnectionClosedError, RetryFailedError):\n        logger.warning(\"Leader ZNode already exists\")\n    except Exception as e:\n        logger.error(f\"Error creating leader ZNode: {e}\")\n        raise ZooKeeperError(f\"Error creating leader ZNode: {e}\")\n\n    return True", "CodeBleu_score": 43.34124747029668}, {"code": "def _update_leader(self, leader: Leader) -> bool\n    if leader.session != self._client_id:\n        logger.warning(\n            \"Session ID mismatch. Expected %s, got %s. Trying to delete leader ZNode\",\n            leader.session,\n            self._client_id,\n        )\n        try:\n            self._delete_leader_znode(leader.name)\n        except NoNodeError:\n            pass\n        except (ConnectionClosedError, RetryFailedError):\n            raise ZooKeeperError()\n\n    try:\n        self._create_leader_znode(self._client_name.encode(\"utf-8\"))\n    except (NodeExistsError, NoNodeError):\n        logger.warning(\"Failed to create leader ZNode\")\n        return False\n    except (ConnectionClosedError, RetryFailedError):\n        raise ZooKeeperError()\n\n    return True\n\n", "CodeBleu_score": 38.49451717555622}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n    try:\n        exhibitors = self.get_exhibitors()\n        if exhibitors:\n            for exhibitor in exhibitors:\n                if (\n                    exhibitor.get(\"hostname\")\n                    and exhibitor.get(\"port\")\n                    and exhibitor.get(\"jmx_port\")\n                ):\n                    if (\n                        exhibitor.get(\"hostname\") == self.zk_host\n                        and exhibitor.get(\"port\") == self.zk_port\n                    ):\n                        self.logger.debug(\n                            \"ZooKeeper connection string is already up to date\"\n                        )\n                        return False\n                    else:\n                        self.logger.debug(\n                            \"ZooKeeper connection string has changed, updating\"\n                        )\n                        self.zk_host = exhibitor.get(\"hostname\")\n                        self.zk_port = exhibitor.get(\"port\")\n                        self.zk_jmx_port = exhibitor.get(\"jmx_port\")\n                        self.zk_connection_string = f\"{self.zk_host}:{self.zk_port}\"\n                        self.logger.info(\n                            f\"ZooKeeper connection string updated to {self.zk_connection_string}\"\n                        )\n                        return True\n                else:\n                    self.logger.debug(\n                        \"Exhibitor is not ready yet, skipping ZooKeeper connection string update\"\n                    )\n                    return False\n        else:\n            self.logger.debug(\"No exhibitors found, skipping ZooKeeper connection string update\")\n            return False\n    except Exception as e:\n        self.logger.error(f\"Error while polling exhibitors: {e}\")\n        return False", "CodeBleu_score": 22.235397552533133}, {"code": "def poll(self) -> bool\n    if self.zk_conn_str != self.zk_conn_str_last:\n        self.logger.info(f\"ZooKeeper connection string changed from {self.zk_conn_str_last} to {self.zk_conn_str}\")\n        self.zk_conn_str_last = self.zk_conn_str\n        self.zk_conn_str_last_valid = False\n        self.zk_conn_str_last_valid_time = time.time()\n        self.zk_conn_str_last_valid_data = None\n        self.zk_conn_str_last_valid_data_time = None\n        self.zk_conn_str_last_valid_data_exhibitors = None\n        self.zk_conn_str_last_valid_data_exhibitors_time = None\n        self.zk_conn_str_last_valid_data_exhibitors_last = None\n        self.zk_conn_str_last_valid_data_exhibitors_last_time = None\n        self.zk_conn_str_last_valid_data_exhibitors_last_valid = False\n        self.zk_conn_str_last_valid_data_exhibitors_last_valid_time = None\n        self.zk_conn_str_last_valid_data_exhibitors_last_valid_data = None\n        self.zk_conn_str_last_valid_data_exhibitors_last_valid_data_time = None\n        self.zk_conn_str_last_valid_data_exhibitors_last_valid_data_exhibitors = None\n        self.zk_conn_str_last_valid_data_exhibitors_last_valid_data_exhibitors_time = None\n        self.zk_conn_str_last_valid_data_exhibitors_last_valid_data_exhibitors_last = None\n        self.zk_conn_str_last_valid_data_exhibitors_last_valid_data_exhibitors_last_time = None\n        self.z", "CodeBleu_score": 16.47734523298618}, {"code": "def poll(self) -> bool\n    if self.last_poll is None or self.last_poll + self.poll_interval < time.time():\n        self.last_poll = time.time()\n        try:\n            status = self.zk.get(self.exhibitors_path)\n        except kazoo.exceptions.NoNodeError:\n            return False\n        if not status:\n            return False\n        status = json.loads(status[0].decode(\"utf-8\"))\n        if \"server\" not in status or \"port\" not in status:\n            return False\n        server = status[\"server\"]\n        port = status[\"port\"]\n        if server != self.server or port != self.port:\n            self.server = server\n            self.port = port\n            self.zk_connection_string = f\"{server}:{port}\"\n            logger.info(f\"ZooKeeper connection string changed to {self.zk_connection_string}\")\n            return True\n        return False", "CodeBleu_score": 37.508916848993024}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\n    if not self.ensemble_provider:\n        self.ensemble_provider = ZookeeperEnsembleProvider(\n            hosts=self.hosts,\n            session_timeout=self.session_timeout,\n            chroot_path=self.chroot_path,\n        )\n\n    if self.hosts != self.ensemble_provider.hosts:\n        self.ensemble_provider.hosts = self.hosts\n\n    return super()._load_cluster(path, loader)", "CodeBleu_score": 51.09692476338679}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n    if self.ensemble_provider is not None:\n        self.update_hosts(self.ensemble_provider.get_hosts())\n    return super(ZookeeperCluster, self)._load_cluster(path, loader)", "CodeBleu_score": 65.16897611320509}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n    if not self.ensemble_provider:\n        self.ensemble_provider = KazooClient(hosts=self.hosts)\n        self.ensemble_provider.start()\n    self.update_hosts(self.ensemble_provider.hosts)\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 56.28327857488663}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener)    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}\n", "CodeBleu_score": 71.48704786250138}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener)    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}\n", "CodeBleu_score": 71.48704786250138}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener)    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}\n", "CodeBleu_score": 71.48704786250138}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy()    if (zookeeperListener == null) {\n        return;\n    }\n    String group = zookeeperListener.getGroup();\n    String dataId = zookeeperListener.getDataId();\n    logger.info(\"start unsubscribe group: {}, dataId: {}\", group, dataId);\n    try {\n        zookeeperListener.unsubscribe();\n    } catch (Exception e) {\n        logger.error(\"unsubscribe group: {}, dataId: {} error: \", group, dataId, e);\n    }\n}", "CodeBleu_score": 53.36944767006738}, {"code": "public void destroy()    if (zookeeperListener == null) {\n        return;\n    }\n    String group = zookeeperListener.getGroup();\n    String dataId = zookeeperListener.getDataId();\n    logger.info(\"Unsubscribe zookeeper config. group: {}, dataId: {}\", group, dataId);\n    try {\n        zookeeperListener.unsubscribe();\n    } catch (Exception e) {\n        logger.error(\"Failed to unsubscribe zookeeper config. group: {}, dataId: {}\", group, dataId, e);\n    }\n}", "CodeBleu_score": 52.450571054699026}, {"code": "public void destroy()    if (zookeeperListener == null) {\n        return;\n    }\n    String group = zookeeperListener.getGroup();\n    String dataId = zookeeperListener.getDataId();\n    logger.info(\"start to unsubscribe zookeeper config: group={}, dataId={}\", group, dataId);\n    try {\n        zookeeperListener.unsubscribe();\n    } catch (Exception e) {\n        logger.error(\"unsubscribe zookeeper config failed. group={}, dataId={}\", group, dataId, e);\n    }\n}", "CodeBleu_score": 52.32244347214877}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server)    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zkServer = (ZookeeperServer) server;\n        return zkServer.getPayload().getMetadata();\n    }\n    return Collections.emptyMap();\n}", "CodeBleu_score": 61.09516215737973}, {"code": "public Map<String, String> getServerMetadata(Server server)    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zkServer = (ZookeeperServer) server;\n        return zkServer.getPayload().getMetadata();\n    } else {\n        return Collections.emptyMap();\n    }\n}", "CodeBleu_score": 61.239080222392886}, {"code": "public Map<String, String> getServerMetadata(Server server)    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zookeeperServer = (ZookeeperServer) server;\n        return zookeeperServer.getPayload();\n    } else {\n        return Collections.emptyMap();\n    }\n}", "CodeBleu_score": 65.38439857470163}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception    String path = getPath(group, serviceId);\n    NodeCache nodeCache = new NodeCache(zkClient, path, false);\n    nodeCache.start();\n    NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception {\n            String config = new String(nodeCache.getCurrentData().getData(), StandardCharsets.UTF_8);\n            zookeeperSubscribeCallback.callback(config);\n        }\n    };\n    nodeCache.getListenable().addListener(nodeCacheListener);\n    ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n    listeners.add(zookeeperListener);\n    return zookeeperListener;\n}", "CodeBleu_score": 73.92850959942947}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception    String path = \"/\" + group + \"/\" + serviceId + \"/config\";\n    NodeCache nodeCache = new NodeCache(client, path, false);\n    nodeCache.start(true);\n    NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception {\n            byte[] data = nodeCache.getCurrentData().getData();\n            String config = new String(data, StandardCharsets.UTF_8);\n            zookeeperSubscribeCallback.callback(config);\n        }\n    };\n    ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n    zookeeperListener.addListener();\n    return zookeeperListener;\n}", "CodeBleu_score": 72.03738749035922}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception    String path = getPath(group, serviceId);\n    NodeCache nodeCache = new NodeCache(client, path, false);\n    nodeCache.start(true);\n    NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n\n        @Override\n        public void nodeChanged() throws Exception {\n            String data = new String(nodeCache.getCurrentData().getData());\n            Map<String, String> config = JSON.parseObject(data, Map.class);\n            zookeeperSubscribeCallback.callback(config);\n        }\n    };\n    ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n    addListener(zookeeperListener);\n    return zookeeperListener;\n}\n", "CodeBleu_score": 75.85657442559243}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery)    ZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery, config.getClientName());\n    serverList.initWithNiwsConfig(config);\n    serverList.setLoadBalanceListenerExecutor(this.loadBalanceListenerExecutor);\n    return serverList;\n}", "CodeBleu_score": 63.231485491887405}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery)    ZookeeperServerList serverList = new ZookeeperServerList(serviceDiscovery);\n    serverList.initWithNiwsConfig(config);\n    return serverList;\n}\n", "CodeBleu_score": 41.317195296237344}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery)    ZookeeperServerList serverList = new ZookeeperServerList(serviceDiscovery);\n    serverList.initWithNiwsConfig(config);\n    serverList.setLoadBalanceListenerExecutor(this.loadBalanceListenerExecutor);\n    serverList.setServiceId(config.getClientName());\n    return serverList;\n}", "CodeBleu_score": 67.73360311232237}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration)    try {\n        RegisterListenerExecutor executor = getApplicationContext().getBean(RegisterListenerExecutor.class);\n        executor.onRegister(registration);\n    } catch (BeansException e) {\n        // Ignore\n    }\n    serviceRegistry.register(registration);\n}\n", "CodeBleu_score": 69.5244543820925}, {"code": "public void register(ZookeeperRegistration registration)    try {\n        getRegisterListenerExecutor().onRegister(registration);\n    } catch (BeansException e) {\n        // ignore\n    }\n    serviceRegistry.register(registration);\n}\n", "CodeBleu_score": 43.18471683000245}, {"code": "public void register(ZookeeperRegistration registration)    try {\n        this.applicationContext.getBean(RegisterListenerExecutor.class).onRegister(registration);\n    } catch (BeansException ex) {\n        // ignore\n    }\n    this.serviceRegistry.register(registration);\n}\n", "CodeBleu_score": 35.02051847477638}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration)    try {\n        getRegisterListenerExecutor().onDeregister(registration);\n    } catch (BeansException ex) {\n        // Ignore\n    }\n    serviceRegistry.remove(registration);\n}", "CodeBleu_score": 32.234891665835185}, {"code": "public void deregister(ZookeeperRegistration registration)    try {\n        this.applicationContext.getBean(RegisterListenerExecutor.class).onDeregister(registration);\n    } catch (BeansException var3) {\n    }\n\n    this.serviceRegistry.deregister(registration);\n}", "CodeBleu_score": 35.14119177371837}, {"code": "public void deregister(ZookeeperRegistration registration)    try {\n        this.applicationContext.getBean(RegisterListenerExecutor.class).onDeregister(registration);\n    } catch (BeansException var3) {\n    }\n\n    this.serviceRegistry.deregister(registration);\n}", "CodeBleu_score": 35.14119177371837}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close()    try {\n        getServiceRegistry().close();\n    } finally {\n        try {\n            getRegisterListenerExecutor().onClose();\n        } catch (BeansException ex) {\n            // Ignore.\n        }\n    }\n}", "CodeBleu_score": 27.167557671029225}, {"code": "public void close()    try {\n        RegisterListenerExecutor executor = (RegisterListenerExecutor) this.applicationContext.getBean(\"registerListenerExecutor\", RegisterListenerExecutor.class);\n        executor.onClose();\n    } catch (BeansException var2) {\n    }\n\n    this.serviceRegistry.close();\n}", "CodeBleu_score": 59.355073016512314}, {"code": "public void close()    try {\n        RegisterListenerExecutor executor = (RegisterListenerExecutor) this.applicationContext.getBean(\"registerListenerExecutor\");\n        executor.onClose();\n    } catch (BeansException e) {\n        // ignore\n    }\n    this.serviceRegistry.close();\n}\n", "CodeBleu_score": 66.3802613609857}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig)    String group = globalConfig ? ConfigConstants.CONFIG_GROUP : applicationConfig.getGroup();\n    String dataId = globalConfig ? ConfigConstants.CONFIG_DATA_ID : applicationConfig.getDataId();\n    log.info(\"Subscribe config: group: {}, dataId: {}\", group, dataId);\n    try {\n        return zookeeperOperation.subscribe(group, dataId, new ZookeeperListener() {\n            @Override\n            public void receiveConfigInfo(String config) {\n                log.info(\"Received config: {}\", config);\n                updateConfig(config);\n            }\n        });\n    } catch (Exception e) {\n        log.error(\"Subscribe config error: group: {}, dataId: {}\", group, dataId, e);\n        return null;\n    }\n}", "CodeBleu_score": 45.98458017382775}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig)    try {\n        String group = globalConfig ? \"global\" : \"config\";\n        String dataId = globalConfig ? \"global.properties\" : \"config.properties\";\n        log.info(\"subscribe config: {}\", dataId);\n        return zookeeperOperation.subscribe(group, dataId, new ZookeeperListener() {\n            @Override\n            public void receiveConfigInfo(String config) {\n                log.info(\"receive config: {}\", config);\n                if (globalConfig) {\n                    globalConfigInfo = config;\n                } else {\n                    configInfo = config;\n                }\n            }\n        });\n    } catch (Exception e) {\n        log.error(\"subscribe config error\", e);\n        return null;\n    }\n}\n", "CodeBleu_score": 45.39548629857754}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig)    String group = globalConfig ? globalGroup : groupId;\n    String dataId = globalConfig ? globalDataId : dataId;\n    log.info(\"Start subscribing to the configuration: group={}, dataId={}\", group, dataId);\n    try {\n        return zookeeperOperation.subscribe(group, dataId, new ConfigChangeListener() {\n            @Override\n            public void receiveConfigInfo(String configInfo) {\n                log.info(\"Received the configuration information: {}\", configInfo);\n                // Process the configuration information\n                processConfig(configInfo);\n            }\n        });\n    } catch (Exception e) {\n        log.error(\"Failed to subscribe to the configuration: group={}, dataId={}\", group, dataId, e);\n        return null;\n    }\n}", "CodeBleu_score": 46.67831797014444}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework()    String zookeeperConnectionString = System.getenv(\"ZOOKEEPER_CONNECTION_STRING\");\n    if (zookeeperConnectionString == null) {\n        throw new DiscoveryException(\"ZOOKEEPER_CONNECTION_STRING environment variable is not set\");\n    }\n\n    int retryCount = Integer.parseInt(System.getenv(\"ZOOKEEPER_RETRY_COUNT\"));\n    int sleepTime = Integer.parseInt(System.getenv(\"ZOOKEEPER_SLEEP_TIME\"));\n\n    CuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n            .connectString(zookeeperConnectionString)\n            .retryPolicy(new ExponentialBackoffRetry(sleepTime, retryCount))\n            .build();\n\n    curatorFramework.start();\n\n    return curatorFramework;\n}", "CodeBleu_score": 46.09776817735193}, {"code": "public CuratorFramework curatorFramework()    String zookeeperConnectionString = environment.getProperty(\"zookeeper.connectionString\");\n    if (StringUtils.isEmpty(zookeeperConnectionString)) {\n        throw new DiscoveryException(\"zookeeper connection string is empty\");\n    }\n    int retryCount = environment.getProperty(\"zookeeper.retryCount\", Integer.class, 3);\n    int sleepMsBetweenRetries = environment.getProperty(\"zookeeper.sleepMsBetweenRetries\", Integer.class, 1000);\n    CuratorFramework client = CuratorFrameworkFactory.newClient(zookeeperConnectionString, new ExponentialBackoffRetry(sleepMsBetweenRetries, retryCount));\n    client.start();\n    return client;\n}", "CodeBleu_score": 38.0315192345275}, {"code": "public CuratorFramework curatorFramework()    String zkConnectionString = System.getenv(\"ZK_CONNECTION_STRING\");\n    if (zkConnectionString == null || zkConnectionString.isEmpty()) {\n        throw new DiscoveryException(\"ZK_CONNECTION_STRING environment variable not set\");\n    }\n\n    int retryCount = Integer.parseInt(System.getenv(\"ZK_RETRY_COUNT\"));\n    int sleepTime = Integer.parseInt(System.getenv(\"ZK_SLEEP_TIME\"));\n\n    CuratorFramework client = CuratorFrameworkFactory.newClient(zkConnectionString, new ExponentialBackoffRetry(sleepTime, retryCount));\n    client.start();\n    return client;\n}\n", "CodeBleu_score": 32.373077637394196}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration\n    @Bean\n    @ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n    public GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(\n            ZookeeperClient zookeeperClient,\n            ZookeeperDiscoveryProperties zookeeperDiscoveryProperties,\n            ZookeeperRouteProperties zookeeperRouteProperties,\n            ZookeeperDiscoveryLocatorProperties zookeeperDiscoveryLocatorProperties) {\n        return new GatewayStrategyRouteZookeeperProcessor(zookeeperClient, zookeeperDiscoveryProperties, zookeeperRouteProperties, zookeeperDiscoveryLocatorProperties);\n    }\n\n}", "CodeBleu_score": 36.490256816038794}, {"code": "protected static class GatewayRouteZookeeperConfiguration\n    @Bean\n    @ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\",\n            matchIfMissing = true, havingValue = \"false\")\n    public GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(\n            ZookeeperDiscoveryProperties properties) {\n        return new GatewayStrategyRouteZookeeperProcessor(properties);\n    }\n\n}", "CodeBleu_score": 33.42850891536693}, {"code": "protected static class GatewayRouteZookeeperConfiguration\n    /**\n     * Returns a new instance of GatewayStrategyRouteZookeeperProcessor.\n     *\n     * @param zookeeperProperties the Zookeeper properties\n     * @return a new instance of GatewayStrategyRouteZookeeperProcessor\n     */\n    @Bean\n    @ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true)\n    public GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(ZookeeperProperties zookeeperProperties) {\n        return new GatewayStrategyRouteZookeeperProcessor(zookeeperProperties);\n    }\n\n}", "CodeBleu_score": 36.547770249919004}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework()  CuratorFramework curatorFramework = CuratorFrameworkFactory.builder().namespace(zookeeperProperties.getNamespace()).connectString(zookeeperProperties.getHost()).retryPolicy(new ExponentialBackoffRetry(1000, 3)).build();\n  curatorFramework.start();\n  return curatorFramework;\n}", "CodeBleu_score": 46.33977496579396}, {"code": "public  CuratorFramework createCuratorFramework()    CuratorFramework curatorFramework = CuratorFrameworkFactory.builder().connectString(zookeeperHosts).namespace(zookeeperNamespace).retryPolicy(retryPolicy).build();\n    curatorFramework.start();\n    return curatorFramework;\n  }\n\n  /**\n * The createCuratorFramework function initializes a CuratorFramework instance with specific properties and a retry policy.\\nIt configures the connection settings using ZooKeeper client properties, including hosts, session timeout, and namespace.\\nAfter setting the retry policy, it starts the CuratorFramework and returns the initialized instance.\n */", "CodeBleu_score": 34.969913763731086}, {"code": "public  CuratorFramework createCuratorFramework()  CuratorFramework curatorFramework = CuratorFrameworkFactory.builder().connectString(zookeeperHosts).sessionTimeoutMs(sessionTimeout).connectionTimeoutMs(connectionTimeout).namespace(namespace).retryPolicy(retryPolicy).build();\n  curatorFramework.start();\n  return curatorFramework;\n}", "CodeBleu_score": 42.252508824708826}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException    try {\n        // Check if the current thread already holds a lock for the given path\n        if (locksMap.containsKey(path)) {\n            // Re-acquire the existing lock\n            locksMap.get(path).acquire();\n        } else {\n            // Create a new InterProcessMutex and acquire the lock\n            InterProcessMutex lock = new InterProcessMutex(client, path);\n            lock.acquire();\n            locksMap.put(path, lock);\n        }\n    } catch (Exception e) {\n        throw new DistributedLockException(\"Error acquiring lock for path \" + path, e);\n    }\n}\n", "CodeBleu_score": 26.772985957987082}, {"code": "public void lock(String path) throws DistributedLockException    InterProcessMutex lock = locksMap.get(path);\n    if (lock == null) {\n        lock = new InterProcessMutex(client, path);\n        try {\n            lock.acquire();\n            locksMap.put(path, lock);\n        } catch (Exception e) {\n            throw new DistributedLockException(\"Error acquiring lock for path: \" + path, e);\n        }\n    } else {\n        try {\n            lock.acquire();\n        } catch (Exception e) {\n            throw new DistributedLockException(\"Error acquiring lock for path: \" + path, e);\n        }\n    }\n}", "CodeBleu_score": 37.33101266957689}, {"code": "public void lock(String path) throws DistributedLockException    InterProcessMutex lock = locksMap.get(path);\n    if (lock == null) {\n        lock = new InterProcessMutex(client, path);\n        locksMap.put(path, lock);\n    }\n    try {\n        lock.acquire();\n    } catch (Exception e) {\n        throw new DistributedLockException(e);\n    }\n}\n", "CodeBleu_score": 24.835898967002652}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties)    CuratorFramework client = CuratorFrameworkFactory.newClient(dtpProperties.getEndpoint(), new ExponentialBackoffRetry(1000, 3));\n    client.start();\n    String nodePath = dtpProperties.getNodePath();\n    if (DtpProperties.ConfigType.PROPERTIES == dtpProperties.getType()) {\n        return genPropertiesTypeMap(client, nodePath);\n    } else {\n        nodePath = nodePath + \"/\" + dtpProperties.getConfigKey();\n        String value = getNodeValue(client, nodePath);\n        return ConfigHandler.getInstance().parseMap(value);\n    }\n}", "CodeBleu_score": 40.71654754023779}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties)    CuratorFramework client = CuratorFrameworkFactory.newClient(dtpProperties.getEndpoint(), new RetryNTimes(3, 3000));\n    client.start();\n    String nodePath = \"/config/\" + dtpProperties.getGroupId() + \"/\" + dtpProperties.getDataId();\n    if (dtpProperties.getConfigType() == ConfigTypeEnum.PROPERTIES) {\n        return genPropertiesTypeMap(client, nodePath);\n    } else {\n        String configKey = dtpProperties.getDataId() + \".\" + dtpProperties.getProfile();\n        String value = getValue(client, nodePath, configKey);\n        return ConfigHandler.getInstance().parseMap(value);\n    }\n}", "CodeBleu_score": 42.132781432369846}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties)    CuratorFramework client = CuratorFrameworkFactory.newClient(dtpProperties.getEndpoint(), new ExponentialBackoffRetry(1000, 3));\n    client.start();\n    String nodePath = \"/\" + dtpProperties.getGroupId() + \"/\" + dtpProperties.getDataId();\n    if (dtpProperties.getType() == ConfigTypeEnum.PROPERTIES) {\n        return genPropertiesTypeMap(nodePath, client);\n    } else if (dtpProperties.getType() == ConfigTypeEnum.JSON) {\n        nodePath = nodePath + \".\" + dtpProperties.getConfigKey();\n        String value = client.getData().forPath(nodePath);\n        return ConfigHandler.parseJson(value);\n    }\n    return null;\n}", "CodeBleu_score": 44.18167576753862}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application)    DtpProperties dtpProperties = DtpProperties.bind(environment);\n    Map<String, Object> properties = DtpProperties.of(dtpProperties).toMap();\n    String propertyName = DtpProperties.PREFIX + \".enabled\";\n    if (!environment.containsProperty(propertyName)) {\n        environment.getPropertySources().addFirst(new MapPropertySource(DtpPropertySourceConst.DTP_PROPERTY_SOURCE_NAME, properties));\n    }\n}", "CodeBleu_score": 45.72827459105318}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application)    DtpProperties dtpProperties = DtpProperties.bind(environment);\n    Map<String, Object> properties = dtpProperties.toMap();\n    String requiredProperty = dtpProperties.getRequiredProperty();\n    if (environment.getProperty(requiredProperty) == null) {\n        ZookeeperPropertySource zookeeperPropertySource = new ZookeeperPropertySource(\"zookeeper\", properties);\n        environment.getPropertySources().addFirst(zookeeperPropertySource);\n    }\n}\n", "CodeBleu_score": 44.539500998750135}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application)    DtpProperties dtpProperties = DtpProperties.bind(environment);\n    Properties properties = dtpProperties.toProperties();\n    if (!properties.containsKey(DtpProperty.DTP_ENABLED_PROP)) {\n        ZookeeperPropertySource zookeeperPropertySource = new ZookeeperPropertySource(DtpProperty.DTP_ENABLED_PROP, properties);\n        environment.getPropertySources().addFirst(zookeeperPropertySource);\n    }\n}", "CodeBleu_score": 42.80938897817334}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo)    var serializer = new ZooKeeperServiceRouteSerializer();\n    builder.Register(context => serializer).As<IServiceRouteSerializer>();\n    builder.Register(context => serializer).As<IServiceRouteFactory>();\n    builder.Register(context => serializer).As<IServiceRouteManager>();\n    builder.Register(context => serializer).As<IServiceRouteRepository>();\n    builder.Register(context => serializer).As<IServiceRouteProvider>();\n\n    var logger = new ZooKeeperServiceRouteLogger();\n    builder.Register(context => logger).As<IServiceRouteLogger>();\n\n    var clientProvider = new ZooKeeperClientProvider(configInfo.ZooKeeper.ConnectionString);\n    builder.Register(context => clientProvider).As<IZooKeeperClientProvider>();\n\n    return this;\n}\n", "CodeBleu_score": 39.63232904589515}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo)    // Create the ZooKeeper client provider\n    builder.Register(context => {\n        var zooKeeperClient = new ZooKeeperClient(configInfo.ZooKeeperConnectionString, configInfo.ZooKeeperSessionTimeout, configInfo.ZooKeeperConnectionTimeout);\n        zooKeeperClient.Start();\n        return zooKeeperClient;\n    }).As<IZooKeeperClient>().SingleInstance();\n\n    // Create the ZooKeeper route factory\n    builder.Register(context => {\n        var zooKeeperClient = context.Resolve<IZooKeeperClient>();\n        return new ZooKeeperRouteFactory(zooKeeperClient, configInfo.ZooKeeperRoutePath, configInfo.ZooKeeperSessionTimeout);\n    }).As<IZooKeeperRouteFactory>().SingleInstance();\n\n    // Create the ZooKeeper route manager\n    builder.Register(context => {\n        var zooKeeperRouteFactory = context.Resolve<IZooKeeperRouteFactory>();\n        return new ZooKeeperRouteManager(zooKeeperRouteFactory, configInfo.ZooKeeperRoutePath, configInfo.ZooKeeperSessionTimeout);\n    }).As<IZooKeeperRouteManager>().SingleInstance();\n\n    // Create the ZooKeeper route repository\n    builder.Register(context => {\n        var zooKeeperRouteFactory = context.Resolve<IZooKeeperRouteFactory>();\n        return new ZooKeeperRouteRepository(zooKeeperRouteFactory, configInfo.ZooKeeperRoutePath, configInfo.ZooKeeperSessionTimeout);\n    }).As<IZooKeeperRouteRepository>().SingleInstance();\n\n    // Create the ZooKeeper route manager logger\n    builder.Register(context => {\n        var logger = context.Resolve<ILogger<ZooKeeperRouteManager>>();\n        return new ZooKeeperRouteManagerLogger(logger);\n    }).As<IZooKeeperRouteManagerLogger>().SingleInstance();\n\n    // Create", "CodeBleu_score": 35.3101686239858}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo)    var logger = new LoggerFactory().AddConsole().CreateLogger<ZooKeeperServiceRouteManager>();\n    var serializer = new ZooKeeperServiceRouteSerializer();\n    var routeFactory = new ZooKeeperServiceRouteFactory(serializer);\n    var clientProvider = new ZooKeeperClientProvider(logger, configInfo.ZooKeeper);\n    builder.Register(c => new ZooKeeperServiceRouteManager(clientProvider, logger, routeFactory)).As<IServiceRouteManager>().SingleInstance();\n    return this;\n}\n", "CodeBleu_score": 28.697830084286707}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo)    var zooKeeperService = new ZooKeeperService(configInfo.ZooKeeperConnectionString);\n    zooKeeperService.Start();\n    var zooKeeperServiceCommandManager = new ZooKeeperServiceCommandManager(zooKeeperService);\n    builder.RegisterInstance(zooKeeperServiceCommandManager).As<ICommandManager>();\n    return this;\n  }\n\n  /// <summary>", "CodeBleu_score": 23.293033788328508}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo)    var commandManager = new ZookeeperServiceCommandManager();\n    builder.RegisterInstance(commandManager)\n        .As<IServiceCommandManager>()\n        .As<IHostedService>()\n        .SingleInstance();\n    builder.RegisterInstance(new ZookeeperServiceDiscovery(configInfo.ServiceName, configInfo.ServiceId, configInfo.ZooKeeperAddress))\n        .As<IServiceDiscovery>()\n        .SingleInstance();\n    builder.RegisterInstance(new ZookeeperServiceRegistry(configInfo.ServiceName, configInfo.ServiceId, configInfo.ZooKeeperAddress))\n        .As<IServiceRegistry>()\n        .SingleInstance();\n    return new ZookeeperModule(builder, configInfo);\n}", "CodeBleu_score": 45.41383571816788}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo)    var commandManager = new ZookeeperServiceCommandManager(configInfo.ServiceId);\n    builder.RegisterInstance(commandManager)\n        .As<IServiceCommandManager>()\n        .As<IZookeeperServiceCommandManager>()\n        .SingleInstance();\n    return new ZookeeperModule(builder, configInfo, commandManager);\n}", "CodeBleu_score": 40.29411860853668}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange)    if (builder == null) {\n        throw new ArgumentNullException(nameof(builder));\n    }\n    if (string.IsNullOrEmpty(path)) {\n        throw new ArgumentException(\"Invalid file path\", nameof(path));\n    }\n\n    if (provider == null && Path.IsPathRooted(path)) {\n        provider = new PhysicalFileProvider(Path.GetDirectoryName(path), ExclusionFilters.None);\n        path = Path.GetFileName(path);\n    }\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    };\n    source.ResolveFileProvider();\n    builder.Add(source);\n    return builder;\n}\n", "CodeBleu_score": 69.35073055301385}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange)    if (builder == null) {\n        throw new ArgumentNullException(nameof(builder));\n    }\n\n    if (string.IsNullOrEmpty(path)) {\n        throw new ArgumentException(\"Invalid file path\", nameof(path));\n    }\n\n    if (provider == null && Path.IsPathRooted(path)) {\n        provider = new PhysicalFileProvider(Path.GetDirectoryName(path), ExclusionFilters.Sensitive);\n        path = Path.GetFileName(path);\n    }\n\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    };\n    source.ResolveFileProvider();\n    builder.Add(source);\n    return builder;\n}\n", "CodeBleu_score": 69.18572937285614}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange)    if (builder == null) {\n        throw new ArgumentNullException(nameof(builder));\n    }\n\n    if (string.IsNullOrEmpty(path)) {\n        throw new ArgumentException(\"Invalid file path\", nameof(path));\n    }\n\n    return builder.AddZookeeperFile(s => {\n        s.FileProvider = provider;\n        s.Path = path;\n        s.Optional = optional;\n        s.ReloadOnChange = reloadOnChange;\n        s.ResolveFileProvider();\n    });\n}", "CodeBleu_score": 34.296128820140126}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address)    var routes = await GetRoutesAsync();\n    foreach (var route in routes) {\n        route.Addresses = route.Addresses.Where(a => !Address.Contains(a)).ToList();\n    }\n    await SetRoutesAsync(routes);\n}", "CodeBleu_score": 69.35655652232978}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address)\ttry {\n\t\tvar routes = await GetRoutesAsync();\n\t\tforeach (var route in routes) {\n\t\t\troute.Addresses = route.Addresses.Except(Address).ToList();\n\t\t}\n\t\tawait SetRoutesAsync(routes);\n\t} catch (Exception ex) {\n\t\tthrow new Exception($\"Error removing address: {ex.Message}\");\n\t}\n}", "CodeBleu_score": 66.15967882881542}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address)    try {\n        var routes = await GetRoutesAsync();\n        foreach (var route in routes) {\n            var addresses = route.Addresses.Where(a => !Address.Any(r => r.Address == a.Address));\n            route.Addresses = addresses.ToList();\n        }\n        await SetRoutesAsync(routes);\n    }\n    catch (Exception ex) {\n        Console.WriteLine(ex.Message);\n    }\n}", "CodeBleu_score": 59.04101804384481}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr)    var routePath = GetRoutePath();\n    var clients = await _zookeeperClientFactory.GetClientsAsync();\n    foreach (var client in clients) {\n        var currentRoutes = await client.GetChildrenAsync(routePath);\n        var routesToDelete = currentRoutes.Where(r => !routes.Any(n => n.Address.Host == r.Split(':')[0] && n.Address.Port == int.Parse(r.Split(':')[1])));\n        foreach (var route in routesToDelete) {\n            var routeAddr = AddressModel.Parse(route);\n            if (routeAddr.Host == hostAddr.Host && routeAddr.Port == hostAddr.Port) {\n                await client.DeleteAsync($\"{routePath}/{route}\");\n            }\n        }\n    }\n}\n", "CodeBleu_score": 31.207243902956357}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr)    var routePath = ZookeeperPath.Create(this.serviceName, this.serviceInstanceId, \"routes\");\n    var clients = this.zookeeperClientManager.GetAllClients();\n    foreach (var client in clients) {\n        var children = await client.GetChildrenAsync(routePath);\n        var currentRoutes = children.Select(child => {\n            var data = client.GetData(ZookeeperPath.Combine(routePath, child));\n            return JsonSerializer.Deserialize<ServiceRoute>(data);\n        });\n        var routesToDelete = currentRoutes.Except(routes, new ServiceRouteComparer());\n        foreach (var route in routesToDelete) {\n            if (route.Address.Host.Equals(hostAddr.Host) && route.Address.Port.Equals(hostAddr.Port)) {\n                await client.DeleteAsync(ZookeeperPath.Combine(routePath, route.Id));\n            }\n        }\n    }\n}\n", "CodeBleu_score": 36.21949995409873}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr)    var routePath = _zkConfig.ServiceRoutePath;\n    var clients = _zkConfig.GetZooKeeperClients();\n    foreach (var client in clients) {\n        var currentRoutes = await client.GetChildrenAsync(routePath);\n        var routesToBeDeleted = currentRoutes.Where(r => !routes.Any(nr => nr.Address.Ip == r.Split(':')[0] && nr.Address.Port == int.Parse(r.Split(':')[1]))).ToList();\n        foreach (var route in routesToBeDeleted) {\n            var routeAddr = new AddressModel {\n                Ip = route.Split(':')[0],\n                Port = int.Parse(route.Split(':')[1])\n            };\n            if (routeAddr.Ip == hostAddr.Ip && routeAddr.Port == hostAddr.Port) {\n                await client.DeleteAsync($\"{routePath}/{route}\");\n            }\n        }\n    }\n}", "CodeBleu_score": 33.561697246239476}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data)    if (data == null) {\n        return null;\n    }\n    var descriptor = JsonSerializer.Deserialize<ServiceRouteDescriptor>(data);\n    if (_logger.IsEnabled(LogLevel.Debug)) {\n        _logger.LogDebug(\"ServiceRouteDescriptor: {descriptor}\", descriptor);\n    }\n    return _serviceRouteFactory.Create(descriptor);\n}\n", "CodeBleu_score": 34.35813378684465}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data)    if (data == null) {\n        return null;\n    }\n\n    if (_logger.IsEnabled(LogLevel.Debug)) {\n        _logger.LogDebug(\"Getting route from {0}\", Encoding.UTF8.GetString(data));\n    }\n\n    var descriptor = JsonSerializer.Deserialize<ServiceRouteDescriptor>(data, _jsonSerializerOptions);\n    return await _serviceRouteFactory.CreateServiceRoute(descriptor);\n}\n", "CodeBleu_score": 36.79173430707302}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data)    if (Log.IsEnabled(LogLevel.Debug)) {\n        Log.Debug(\"Route data: {Data}\", Convert.ToBase64String(data));\n    }\n    if (data == null) {\n        return null;\n    }\n    var descriptor = JsonSerializer.Deserialize<ServiceRouteDescriptor>(data, _serializerOptions);\n    return _serviceRouteFactory.Create(descriptor);\n}", "CodeBleu_score": 33.26626622039339}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData)    if (oldData.SequenceEqual(newData)) return;\n\n    var newRoute = new Route(newData);\n    var oldRoute = _routes.FirstOrDefault(r => r.Id == newRoute.Id);\n\n    lock (_routes) {\n        if (oldRoute != null) {\n            _routes.Remove(oldRoute);\n        }\n        _routes.Add(newRoute);\n    }\n\n    OnChanged?.Invoke(newRoute, oldRoute);\n}\n", "CodeBleu_score": 24.57706724006688}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData)    if (oldData.SequenceEqual(newData)) {\n        return;\n    }\n\n    Route newRoute = Route.FromBytes(newData);\n    Route oldRoute = _routes.Find(r => r.Id == newRoute.Id);\n\n    lock (_routes) {\n        _routes[_routes.IndexOf(oldRoute)] = newRoute;\n    }\n\n    OnChanged?.Invoke(newRoute, oldRoute);\n}\n", "CodeBleu_score": 20.491183565144524}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData)    if (oldData == null || newData == null) {\n        return;\n    }\n\n    var oldRoute = _serializer.Deserialize<Route>(oldData);\n    var newRoute = _serializer.Deserialize<Route>(newData);\n\n    if (oldRoute.RouteId == newRoute.RouteId) {\n        return;\n    }\n\n    lock (_routes) {\n        var index = _routes.FindIndex(r => r.RouteId == oldRoute.RouteId);\n        if (index >= 0) {\n            _routes[index] = newRoute;\n        }\n    }\n\n    OnChanged(newRoute, oldRoute);\n}", "CodeBleu_score": 25.53773659967764}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers)    var existingSubscribers = await GetSubscribersAsync();\n\n    foreach (var subscriber in subscribers) {\n        var existingSubscriber = existingSubscribers.FirstOrDefault(s => s.Name == subscriber.Name);\n        if (existingSubscriber != null) {\n            existingSubscriber.Addresses = existingSubscriber.Addresses.Union(subscriber.Addresses).ToList();\n        } else {\n            existingSubscribers.Add(subscriber);\n        }\n    }\n\n    await base.SetSubscribersAsync(existingSubscribers);\n}", "CodeBleu_score": 55.67519562213272}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers)    var existingSubscribers = await GetSubscribersAsync();\n    foreach (var subscriber in subscribers) {\n        var existingSubscriber = existingSubscribers.FirstOrDefault(s => s.Name == subscriber.Name);\n        if (existingSubscriber != null) {\n            subscriber.Addresses = existingSubscriber.Addresses.Union(subscriber.Addresses).ToList();\n        }\n    }\n    await base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 55.00432247400673}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers)    var existingSubscribers = await GetSubscribersAsync();\n    foreach (var subscriber in subscribers) {\n        var existingSubscriber = existingSubscribers.FirstOrDefault(s => s.Name == subscriber.Name);\n        if (existingSubscriber != null) {\n            var mergedAddresses = subscriber.Addresses.Union(existingSubscriber.Addresses);\n            subscriber.Addresses = mergedAddresses.ToList();\n        }\n    }\n    await base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 46.19783012393446}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens)    var rootPath = _config.GetValue<string>(\"ServiceDiscovery:RootPath\");\n    var subscribers = new List<ServiceSubscriber>();\n\n    foreach (var children in childrens) {\n        var nodePath = $\"{rootPath}/{children}\";\n        var subscriber = await _client.GetAsync<ServiceSubscriber>(nodePath);\n        subscribers.Add(subscriber);\n    }\n\n    return subscribers.ToArray();\n}", "CodeBleu_score": 40.462208688487536}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens)    var rootPath = string.Format(\"{0}/{1}\", _config.ZooKeeperRootNode, _config.ZooKeeperSubscribersNode);\n    var subscribers = new List<ServiceSubscriber>();\n\n    foreach (var children in childrens) {\n        var fullPath = string.Format(\"{0}/{1}\", rootPath, children);\n        var subscriber = await GetSubscriber(fullPath);\n        subscribers.Add(subscriber);\n    }\n\n    return subscribers.ToArray();\n}\n", "CodeBleu_score": 40.97009879815947}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens)    var subscribers = new List<ServiceSubscriber>();\n    var rootPath = string.Format(\"{0}/{1}\", _servicePath, _subscribersNode);\n    foreach (var children in childrens) {\n        var nodePath = string.Format(\"{0}/{1}\", rootPath, children);\n        var subscriber = await _client.GetDataAsync<ServiceSubscriber>(nodePath);\n        if (_logger.IsEnabled(LogLevel.Debug)) {\n            _logger.LogDebug($\"Retrieved subscriber {subscriber.Id} from {nodePath}\");\n        }\n        subscribers.Add(subscriber);\n    }\n    return subscribers.ToArray();\n}\n", "CodeBleu_score": 46.928390862521034}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers()    if (_subscribers != null) return;\n    var client = _zkClientFactory.GetClient();\n    await client.WaitForConnection();\n    if (await client.Exists(_subscriberPath) == null) {\n        _logger.LogWarning($\"Subscriber path {_subscriberPath} does not exist.\");\n        _subscribers = new List<Subscriber>();\n        return;\n    }\n    var children = await client.GetChildren(_subscriberPath);\n    _subscribers = children.Select(child => JsonConvert.DeserializeObject<Subscriber>(Encoding.UTF8.GetString(Convert.FromBase64String(child)))).ToList();\n}\n", "CodeBleu_score": 40.42853731802815}, {"code": "private async Task EnterSubscribers()    if (_subscribers != null) {\n        return;\n    }\n\n    using (var zkClient = _zkClientFactory.CreateClient()) {\n        await zkClient.WaitForConnection();\n        if (!await zkClient.ExistsAsync(_subscriberPath)) {\n            _logger.LogWarning(\"Subscriber path {path} does not exist\", _subscriberPath);\n            _subscribers = Array.Empty<Subscriber>();\n            return;\n        }\n\n        var children = await zkClient.GetChildrenAsync(_subscriberPath);\n        _subscribers = children.Select(child => new Subscriber {\n            Id = child,\n            Data = JsonSerializer.Deserialize<SubscriberData>(Encoding.UTF8.GetString(Convert.FromBase64String(child)))\n        }).ToArray();\n    }\n}\n", "CodeBleu_score": 41.734148638159695}, {"code": "private async Task EnterSubscribers()    if (_subscribers != null)\n        return;\n    var zkClient = await _zkClientFactory.GetZooKeeperClient();\n    await zkClient.WaitForConnection();\n    var path = _subscriberPath;\n    var subscribers = await zkClient.GetChildren(path);\n    if (subscribers == null) {\n        _logger.LogWarning($\"Subscriber path {path} does not exist\");\n        _subscribers = Array.Empty<string>();\n    } else {\n        _subscribers = subscribers.ToArray();\n    }\n}\n", "CodeBleu_score": 38.80177261873303}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData)    if (oldData != newData) {\n        var serviceCommand = GetServiceCommand(newData);\n        var oldServiceCommand = _serviceCommands.FirstOrDefault(x => x.ServiceId == serviceCommand.ServiceId);\n        if (oldServiceCommand != null) {\n            _serviceCommands.Remove(oldServiceCommand);\n        }\n        _serviceCommands.Add(serviceCommand);\n        OnChanged?.Invoke(this, new ServiceCommandEventArgs(oldServiceCommand, serviceCommand));\n    }\n}\n", "CodeBleu_score": 35.601973104926216}, {"code": "public void NodeChange(byte[] oldData, byte[] newData)    var oldCommand = _serviceCommands.FirstOrDefault(x => x.ServiceId == newData[0]);\n    var newCommand = new ServiceCommand(newData);\n    if (oldCommand == null || oldCommand.ToString() != newCommand.ToString()) {\n        _serviceCommands.Remove(oldCommand);\n        _serviceCommands.Add(newCommand);\n        OnChanged(newCommand, oldCommand);\n    }\n}", "CodeBleu_score": 24.98315298558496}, {"code": "public void NodeChange(byte[] oldData, byte[] newData)    // Check if the old and new data are different\n    if (oldData.SequenceEqual(newData)) {\n        return;\n    }\n\n    // Get the new service command\n    ServiceCommand newCommand = ServiceCommand.Get(newData);\n\n    // Update the service commands list by replacing the old command with the new one for the same service ID\n    ServiceCommand oldCommand = ServiceCommands.FirstOrDefault(c => c.ServiceId == newCommand.ServiceId);\n    if (oldCommand != null) {\n        ServiceCommands.Remove(oldCommand);\n    }\n    ServiceCommands.Add(newCommand);\n\n    // Trigger the OnChanged event with the new and old commands\n    OnChanged?.Invoke(newCommand, oldCommand);\n}", "CodeBleu_score": 31.411562030026012}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent)    try {\n        var data = await _zooKeeperClient.GetDataAsync(_nodePath, false);\n        var newData = Encoding.UTF8.GetString(data.Data);\n        var currentData = _currentData;\n        _currentData = newData;\n        _action(currentData, newData);\n        await _zooKeeperClient.ExistsAsync(_nodePath, this);\n    } catch (Exception ex) {\n        Console.WriteLine($\"Error processing event: {ex.Message}\");\n    }\n}", "CodeBleu_score": 54.075378907624405}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent)    try {\n        var data = await zooKeeper.GetDataAsync(watchedEvent.Path, false);\n        action(currentData, data.Data);\n        currentData = data.Data;\n        await zooKeeper.ExistsAsync(watchedEvent.Path, this);\n    }\n    catch (KeeperException.NoNodeException) {\n        // ignore\n    }\n    catch (KeeperException.SessionExpiredException) {\n        // ignore\n    }\n    catch (KeeperException e) {\n        throw new Exception($\"Error processing watched event: {e.Message}\", e);\n    }\n}", "CodeBleu_score": 50.20972506123027}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent)    if (watchedEvent.Type == EventType.NodeDataChanged) {\n        var newData = await _zooKeeper.GetDataAsync(watchedEvent.Path, false);\n        _action(newData, _currentData);\n        _currentData = newData;\n        await _zooKeeper.ExistsAsync(watchedEvent.Path, this);\n    }\n}\n", "CodeBleu_score": 46.39693572713782}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo)    builder.Services.AddSingleton<IZookeeperClientProvider, DefaultZookeeperClientProvider>(serviceProvider => {\n        return new DefaultZookeeperClientProvider(\n            serviceProvider.GetRequiredService<IHealthCheckService>(),\n            serviceProvider.GetRequiredService<IAddressSelector>(),\n            serviceProvider.GetRequiredService<ILogger<DefaultZookeeperClientProvider>>(),\n            configInfo);\n    });\n\n    return builder;\n}", "CodeBleu_score": 58.23786835336858}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo)    builder.Services.AddSingleton<IZookeeperClientProvider, DefaultZookeeperClientProvider>(provider => {\n        var healthCheckService = provider.GetService<IHealthCheckService>();\n        var addressSelector = provider.GetService<IAddressSelector>();\n        var logger = provider.GetService<ILogger<DefaultZookeeperClientProvider>>();\n        return new DefaultZookeeperClientProvider(configInfo, healthCheckService, addressSelector, logger);\n    });\n    return builder;\n}\n", "CodeBleu_score": 46.18721880337691}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo)    // Add the Zookeeper client provider to the service collection as a single instance\n    builder.Services.AddSingleton<IZookeeperClientProvider>(sp => new DefaultZookeeperClientProvider(sp, configInfo));\n\n    // Return the modified builder\n    return builder;\n}", "CodeBleu_score": 31.890131383972253}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes)    _logger.LogInformation(\"Setting MQTT routes\");\n    var clients = await _zookeeperClientProvider.GetClientsAsync();\n    foreach (var client in clients) {\n        var routePath = client.GetRoutePath();\n        await client.EnsurePathAsync(routePath);\n        foreach (var route in routes) {\n            var nodePath = client.GetRouteNodePath(route.RouteId);\n            var data = JsonSerializer.SerializeToUtf8Bytes(route);\n            if (await client.ExistsAsync(nodePath)) {\n                await client.SetDataAsync(nodePath, data);\n                _logger.LogInformation(\"Updated route {routeId}\", route.RouteId);\n            } else {\n                await client.CreateAsync(nodePath, data, false, false);\n                _logger.LogInformation(\"Created route {routeId}\", route.RouteId);\n            }\n        }\n    }\n    _logger.LogInformation(\"MQTT routes set\");\n}", "CodeBleu_score": 38.519565379607386}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes)    var clients = await GetZooKeeperClientsAsync();\n    foreach (var client in clients) {\n        var path = GetMqttRoutePath(client.Name);\n        await client.EnsurePathAsync(path);\n        foreach (var route in routes) {\n            var data = JsonSerializer.Serialize(route);\n            var node = await client.GetNodeAsync(path + \"/\" + route.Id);\n            if (node == null) {\n                await client.CreateNodeAsync(path + \"/\" + route.Id, data);\n                _logger.LogInformation(\"Created node: {node}\", path + \"/\" + route.Id);\n            }\n            else {\n                await node.SetDataAsync(data);\n                _logger.LogInformation(\"Updated node: {node}\", path + \"/\" + route.Id);\n            }\n        }\n    }\n    _logger.LogInformation(\"Added routes: {routes}\", routes);\n}\n", "CodeBleu_score": 33.61774180187252}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes)    try {\n        var clients = await _zookeeperClient.GetChildrenAsync($\"/{_zookeeperConfig.RootPath}\");\n        foreach (var client in clients) {\n            var clientPath = $\"/{_zookeeperConfig.RootPath}/{client}\";\n            await _zookeeperClient.EnsurePathAsync($\"{clientPath}/{_zookeeperConfig.ServicePath}\");\n            foreach (var route in routes) {\n                var routeData = JsonSerializer.Serialize(route);\n                var routePath = $\"{clientPath}/{_zookeeperConfig.ServicePath}/{route.ServiceName}\";\n                if (await _zookeeperClient.ExistsAsync(routePath)) {\n                    await _zookeeperClient.SetDataAsync(routePath, Encoding.UTF8.GetBytes(routeData));\n                    _logger.LogInformation($\"Route {route.ServiceName} updated for client {client}\");\n                } else {\n                    await _zookeeperClient.CreateAsync(routePath, Encoding.UTF8.GetBytes(routeData), CreateMode.Persistent);\n                    _logger.LogInformation($\"Route {route.ServiceName} created for client {client}\");\n                }\n            }\n        }\n        _logger.LogInformation(\"Routes added successfully\");\n    } catch (Exception ex) {\n        _logger.LogError(ex, \"Failed to add routes\");\n    }\n}", "CodeBleu_score": 38.910613719185804}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr)    // Construct the route path\n    string routePath = ZookeeperPath.GetServiceRoutePath(hostAddr.Host, hostAddr.Port);\n    // Get the current Zookeeper clients\n    var clients = await GetClientsAsync();\n    foreach (var client in clients) {\n        // Get the existing routes\n        var existingRoutes = await client.GetChildrenAsync(routePath);\n        // Identify routes to be deleted\n        var routesToDelete = existingRoutes.Where(r => !routes.Any(nr => nr.ToString() == r));\n        foreach (var route in routesToDelete) {\n            // If the address of the route to be deleted contains the specified hostAddr, delete the corresponding node from Zookeeper\n            var routeAddr = AddressModel.Parse(route);\n            if (routeAddr.Host == hostAddr.Host && routeAddr.Port == hostAddr.Port) {\n                await client.DeleteAsync(routePath + \"/\" + route);\n            }\n        }\n    }\n}\n", "CodeBleu_score": 33.49138301147576}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr)    var routePath = GetRoutePath(hostAddr);\n    var clients = await _zookeeperClient.GetClientsAsync();\n    foreach (var client in clients) {\n        var currentRoutes = await client.GetChildrenAsync(routePath);\n        var routesToDelete = currentRoutes.Except(routes.Select(r => r.ToString()));\n        foreach (var route in routesToDelete) {\n            var routeAddr = AddressModel.Parse(route);\n            if (routeAddr.Host == hostAddr.Host) {\n                await client.DeleteAsync($\"{routePath}/{route}\");\n            }\n        }\n    }\n}\n", "CodeBleu_score": 29.57545440583284}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr)    var routePath = GetRoutePath();\n    var clients = GetZookeeperClients();\n    foreach (var client in clients) {\n        var children = await client.GetChildrenAsync(routePath);\n        var routesToDelete = children.Except(routes.Select(r => r.ToString()));\n        foreach (var routeToDelete in routesToDelete) {\n            var route = MqttServiceRoute.Parse(routeToDelete);\n            if (route.Address.Equals(hostAddr)) {\n                await client.DeleteAsync($\"{routePath}/{routeToDelete}\");\n            }\n        }\n    }\n}\n", "CodeBleu_score": 29.67120482093631}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors)    _logger.LogInformation(\"Setting service caches\");\n    var cachePath = _options.ServiceCachePath;\n    var clients = _zookeeperClientsProvider.GetZookeeperClients();\n    foreach (var client in clients) {\n        await client.EnsurePathAsync(cachePath);\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var cacheDescriptorJson = JsonConvert.SerializeObject(cacheDescriptor);\n            var cacheDescriptorPath = Path.Combine(cachePath, cacheDescriptor.ServiceName);\n            var nodeExists = await client.ExistsAsync(cacheDescriptorPath);\n            if (!nodeExists) {\n                await client.CreateAsync(cacheDescriptorPath, cacheDescriptorJson.GetBytes(), CreateMode.Persistent);\n            } else {\n                var currentCacheDescriptorJson = (await client.GetDataAsync(cacheDescriptorPath)).GetString();\n                if (currentCacheDescriptorJson != cacheDescriptorJson) {\n                    await client.SetDataAsync(cacheDescriptorPath, cacheDescriptorJson.GetBytes());\n                }\n            }\n        }\n    }\n    _logger.LogInformation(\"Successfully added service caches\");\n}\n", "CodeBleu_score": 36.16345845214621}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors)    _logger.LogInformation(\"Setting service caches...\");\n    var cachePath = Path.Combine(Constants.ZookeeperPaths.Caches, _options.ServiceName);\n    var clients = _zookeeperClientManager.GetAllClients();\n    foreach (var client in clients) {\n        await client.EnsurePathAsync(cachePath);\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var serializedDescriptor = JsonSerializer.Serialize(cacheDescriptor);\n            var nodePath = Path.Combine(cachePath, cacheDescriptor.Name);\n            var exists = await client.ExistsAsync(nodePath);\n            if (!exists) {\n                await client.CreateAsync(nodePath, serializedDescriptor);\n            } else {\n                await client.SetDataAsync(nodePath, serializedDescriptor);\n            }\n        }\n    }\n    _logger.LogInformation(\"Service caches added successfully.\");\n}", "CodeBleu_score": 33.00216050685252}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors)    _logger.LogInformation(\"Setting service caches\");\n\n    var cachePath = _options.CachePath;\n\n    var clients = _zookeeperClients.GetClients();\n\n    foreach (var client in clients) {\n        await EnsureCachePathExistsAsync(client, cachePath);\n\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var serializedCacheDescriptor = JsonSerializer.Serialize(cacheDescriptor);\n            var cacheDescriptorPath = Path.Combine(cachePath, cacheDescriptor.Id);\n\n            if (!await client.ExistsAsync(cacheDescriptorPath)) {\n                await client.CreateAsync(cacheDescriptorPath, serializedCacheDescriptor);\n            } else {\n                var currentData = await client.GetDataAsync(cacheDescriptorPath);\n                var currentDataString = Encoding.UTF8.GetString(currentData);\n\n                if (currentDataString != serializedCacheDescriptor) {\n                    await client.SetDataAsync(cacheDescriptorPath, serializedCacheDescriptor);\n                }\n            }\n        }\n    }\n\n    _logger.LogInformation(\"Successfully added service caches\");\n}", "CodeBleu_score": 37.979065016528956}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path)    var (manualResetEvent, client) = zooKeeper;\n    await Task.Run(() => manualResetEvent.WaitOne());\n    if (await client.ExistsAsync(path) == null) {\n        var subdirectories = path.Split('/');\n        var currentPath = \"\";\n        foreach (var subdirectory in subdirectories) {\n            currentPath += \"/\" + subdirectory;\n            if (await client.ExistsAsync(currentPath) == null) {\n                await client.CreateAsync(currentPath, null, Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n                _logger.LogInformation($\"Created Zookeeper node: {currentPath}\");\n            }\n        }\n    }\n}", "CodeBleu_score": 44.14434954816793}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path)    var (manualResetEvent, client) = zooKeeper;\n    manualResetEvent.WaitOne();\n    var exists = await client.ExistsAsync(path);\n    if (!exists) {\n        var subDirectories = path.Split('/');\n        var currentPath = \"\";\n        foreach (var subDirectory in subDirectories) {\n            if (subDirectory.Length == 0) {\n                continue;\n            }\n            currentPath += $\"/{subDirectory}\";\n            if (!await client.ExistsAsync(currentPath)) {\n                await client.CreateAsync(currentPath, null, Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n                Logger.LogInformation($\"Created Zookeeper node: {currentPath}\");\n            }\n        }\n    }\n}", "CodeBleu_score": 37.02195651766913}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path)    var (manualResetEvent, client) = zooKeeper;\n    manualResetEvent.WaitOne();\n    var exists = await client.ExistsAsync(path);\n    if (!exists) {\n        var subdirectories = path.Split('/');\n        var currentPath = \"\";\n        foreach (var subdirectory in subdirectories) {\n            currentPath += $\"/{subdirectory}\";\n            if (!await client.ExistsAsync(currentPath)) {\n                await client.CreateAsync(currentPath, null, Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n                Console.WriteLine($\"Created {currentPath}\");\n            }\n        }\n    }\n}", "CodeBleu_score": 36.69432224243209}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers()    var zooKeepers = new List<(ManualResetEvent, ZooKeeper)>();\n\n    foreach (var address in _addresses) {\n        var isHealthy = await _healthCheckService.IsHealthy(address);\n\n        if (isHealthy) {\n            var zooKeeper = new ZooKeeper(address);\n            var manualResetEvent = new ManualResetEvent(false);\n            zooKeepers.Add((manualResetEvent, zooKeeper));\n        }\n    }\n\n    return zooKeepers;\n}", "CodeBleu_score": 62.911136488653064}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers()    var result = new List<(ManualResetEvent, ZooKeeper)>();\n    var addresses = _configuration.GetSection(\"ZooKeeperAddresses\").Get<string[]>();\n    foreach (var address in addresses) {\n        var healthCheckService = _serviceProvider.GetRequiredService<IHealthCheckService>();\n        var healthCheckResult = await healthCheckService.CheckHealthAsync(new HealthCheckContext { Registration = new HealthCheckRegistration(\"zookeeper\", new ZooKeeperHealthCheck(address), HealthStatus.Healthy, new string[0]) });\n        if (healthCheckResult.Status == HealthStatus.Healthy) {\n            var zooKeeper = new ZooKeeper(address, _configuration.GetValue<int>(\"ZooKeeperSessionTimeout\"), new Watcher());\n            var manualResetEvent = new ManualResetEvent(false);\n            result.Add((manualResetEvent, zooKeeper));\n        }\n    }\n    return result;\n}", "CodeBleu_score": 56.96927424412635}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers()    var zooKeepers = new List<(ManualResetEvent, ZooKeeper)>();\n\n    foreach (var address in _addresses) {\n        var healthCheckResult = await _healthCheckService.CheckHealthAsync(address);\n\n        if (healthCheckResult.Status == HealthStatus.Healthy) {\n            var zooKeeper = new ZooKeeper(address, _sessionTimeout, _watcher);\n            var resetEvent = new ManualResetEvent(false);\n            zooKeepers.Add((resetEvent, zooKeeper));\n        }\n    }\n\n    return zooKeepers;\n}\n", "CodeBleu_score": 61.12465807064419}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception    synchronized (this) {\n        if (zk == null) {\n            zk = new ZooKeeper(ensembleProvider.getConnectionString(), sessionTimeout, this);\n        }\n        return zk;\n    }\n}\n", "CodeBleu_score": 31.452243881662046}, {"code": "ZooKeeper getZooKeeper() throws Exception    ZooKeeper zk;\n    synchronized (this) {\n        if (zkHandle == null) {\n            zk = new ZooKeeper(ensembleProvider.getConnectionString(), sessionTimeout, this);\n            zkHandle = zk;\n        } else {\n            zk = zkHandle;\n        }\n    }\n    return zk;\n}\n", "CodeBleu_score": 36.54151344247587}, {"code": "ZooKeeper getZooKeeper() throws Exception    synchronized (this) {\n        if (zk == null) {\n            String connectionString = ensembleProvider.getConnectionString();\n            zk = new ZooKeeper(connectionString, sessionTimeout, this);\n            helper = new ZooKeeperHelper(zk, data);\n        }\n        return zk;\n    }\n}\n", "CodeBleu_score": 41.38768410642963}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception    if (this.zooKeeper != null) {\n        ZooKeeper zk = this.zooKeeper;\n        this.zooKeeper = null;\n        if (zk != null) {\n            // If we are closing, then we should not have any watchers\n            zk.removeAllWatches(watcher, true);\n            try {\n                zk.close();\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n                throw e;\n            }\n        }\n        if (waitForShutdownTimeoutMs > 0) {\n            waitForShutdown(waitForShutdownTimeoutMs);\n        }\n    }\n}", "CodeBleu_score": 30.611403655654428}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception    ZooKeeper zk = zkHelper.getZooKeeper();\n    if (zk != null) {\n        zk.register(new DummyWatcher());\n        zk.close();\n    }\n    if (waitForShutdownTimeoutMs > 0) {\n        zkHelper.waitForShutdown(waitForShutdownTimeoutMs);\n    }\n}", "CodeBleu_score": 19.737392477855842}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception    ZooKeeper zk = zkHelper.getZooKeeper();\n    if (zk != null) {\n        zk.register(new Watcher() {\n            public void process(WatchedEvent event) {\n            }\n        });\n        zk.close();\n    }\n    if (waitForShutdownTimeoutMs > 0) {\n        waitForShutdown(waitForShutdownTimeoutMs);\n    }\n}", "CodeBleu_score": 23.742572858296445}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException    long start = System.currentTimeMillis();\n    log.info(\"Starting to block until connected or timed out\");\n    boolean connected = client.blockUntilConnected(timeout, TimeUnit.MILLISECONDS);\n    log.info(\"Blocked until connected or timed out, connected={}\", connected);\n    log.trace(\"Blocked for {}ms\", System.currentTimeMillis() - start);\n    return connected;\n}", "CodeBleu_score": 42.35983468296147}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException    boolean connected = false;\n    try {\n        long startTime = System.currentTimeMillis();\n        LOG.info(\"Blocking until connected or timed out\");\n        while (!connected && !client.isStarted()) {\n            Thread.sleep(1000);\n            if (System.currentTimeMillis() - startTime > timeout) {\n                LOG.info(\"Timeout occurred\");\n                break;\n            }\n        }\n        connected = client.isConnected();\n        LOG.info(\"Connected: \" + connected);\n    } finally {\n        LOG.trace(\"Connection status: \" + connected);\n    }\n    return connected;\n}", "CodeBleu_score": 38.46562340311851}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException    boolean connected = false;\n    try {\n        logger.info(\"Starting to connect to the server\");\n        connected = client.blockUntilConnected(timeout, TimeUnit.SECONDS);\n        logger.info(\"Finished connecting to the server\");\n    } finally {\n        traceConnection(connected);\n    }\n    return connected;\n}", "CodeBleu_score": 33.57330358222792}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs)  log.info(\"Shutting down service {}\", this);\n  started = false;\n  try {\n    state.close(waitForShutdownTimeoutMs);\n  } catch (IOException e) {\n    if (!Thread.currentThread().isInterrupted()) {\n      log.error(\"Error shutting down service {}\", this, e);\n    }\n  }\n}", "CodeBleu_score": 49.23403435421172}, {"code": "public void close(int waitForShutdownTimeoutMs)    log.info(\"Shutting down the service...\");\n    started = false;\n    try {\n        state.close(waitForShutdownTimeoutMs);\n    } catch (IOException e) {\n        if (Thread.interrupted()) {\n            log.warn(\"Interrupted while shutting down the service\");\n        } else {\n            log.error(\"Error while shutting down the service\", e);\n        }\n    }\n}", "CodeBleu_score": 51.81138623747646}, {"code": "public void close(int waitForShutdownTimeoutMs)  logger.info(\"Shutting down the service\");\n  started = false;\n  try {\n    state.close(waitForShutdownTimeoutMs);\n  } catch (IOException e) {\n    if (!Thread.currentThread().isInterrupted()) {\n      logger.error(\"Failed to close the state\", e);\n    }\n  }\n}", "CodeBleu_score": 50.79882011161838}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException   if (this.connectionState.isConnected()) {\n    return;\n  }\n  Watcher watcher = new Watcher() {\n    @Override public void process(    WatchedEvent event) {\n      if (event.getState() == Event.KeeperState.SyncConnected) {\n        connectionState.set(ConnectionState.CONNECTED);\n      }\n      else if (event.getState() == Event.KeeperState.Disconnected) {\n        connectionState.set(ConnectionState.SUSPENDED);\n      }\n    }\n  }", "CodeBleu_score": 22.068508045333118}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException   while (true) {\n    if (state.get() == State.CONNECTED) {\n      return;\n    }\n    if (state.get() == State.CONNECTING) {\n      if (connectionTimeout.get() <= 0) {\n        throw new InterruptedException(\"Connection timed out\");\n      }\n      long remaining = connectionTimeout.addAndGet(-1000);\n      if (remaining <= 0) {\n        throw new InterruptedException(\"Connection timed out\");\n      }\n      try {\n        Thread.sleep(Math.min(remaining, 1000));\n      }\n catch (      InterruptedException e) {\n        throw new InterruptedException(\"Connection timed out\");\n      }\n    }\n  }\n}", "CodeBleu_score": 20.30995480841467}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException   int remaining = timeout;\n  while (remaining > 0) {\n    if (state.isConnected()) {\n      return;\n    }\n    CountDownLatch latch = new CountDownLatch(1);\n    Watcher watcher = new Watcher() {\n      @Override public void process(WatchedEvent event)  {\n        if (event.getState() == KeeperState.SyncConnected) {\n          latch.countDown();\n        }\n      }\n    };\n    try {\n      addWatch(watcher, watcher, watcher);\n    }\n catch (    KeeperException e) {\n      throw new InterruptedException(e.getMessage());\n    }\n    try {\n      latch.await(remaining, TimeUnit.MILLISECONDS);\n    }\n catch (    InterruptedException e) {\n      throw e;\n    }\n finally {\n      removeWatcher(watcher);\n    }\n    remaining = (int)latch.getCount();\n  }\n  throw new InterruptedException(\"Connection timed out\");\n}", "CodeBleu_score": 46.72654575410351}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception    if (createMode == CreateMode.EPHEMERAL_SEQUENTIAL) {\n        String[] split = foundNode.split(\"-\");\n        if (split.length != 2) {\n            throw new IllegalStateException(\"Invalid sequential node: \" + foundNode);\n        }\n        String nodeName = split[0];\n        String sequence = split[1];\n        if (!client.getZookeeperClient().getSessionId().equals(sequence)) {\n            LOG.info(\"Session changed for ephemeral sequential node {} -> {}\", foundNode, nodeName);\n            client.delete().forPath(foundNode);\n            client.getZookeeperClient().setSessionId(sequence);\n        }\n        return nodeName;\n    }\n    return foundNode;\n}", "CodeBleu_score": 39.83115966831239}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception    if (createMode == CreateMode.EPHEMERAL_SEQUENTIAL) {\n        // validate the session\n        if (client.getZookeeperClient().getSessionId() != client.getZookeeperClient().getSessionId()) {\n            LOGGER.warn(\"ZooKeeper session has changed while waiting for a node to be deleted, aborting operation\");\n            // delete the old node associated with the previous session\n            client.delete().forPath(foundNode);\n            // update the session ID\n            client.getZookeeperClient().getSessionId();\n        }\n    }\n    return foundNode;\n}", "CodeBleu_score": 27.724030695624098}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception    if (createMode == CreateMode.EPHEMERAL) {\n        if (client.getSessionId() != client.getSessionId()) {\n            log.info(\"Session changed while waiting for node \" + foundNode);\n            client.delete().forPath(foundNode);\n            client.getSessionId();\n        }\n    }\n    return foundNode;\n}", "CodeBleu_score": 24.193773338789658}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception    final Stat stat = new Stat();\n    final Trace trace = Trace.start(\"pathInForeground\");\n    try {\n        // Retry loop to set the ACL\n        while (true) {\n            try {\n                // Set the ACL using the ZooKeeper API\n                stat.reset();\n                zk.setACL(path, aclList, stat.getVersion());\n                // Return the status of the operation\n                return stat;\n            } catch (KeeperException.SessionExpiredException e) {\n                // Handle session expiration\n                trace.add(\"Session expired\");\n                trace.add(\"Retrying\");\n                continue;\n            } catch (KeeperException.NoNodeException e) {\n                // Handle missing node\n                trace.add(\"No node\");\n                trace.add(\"Retrying\");\n                continue;\n            } catch (KeeperException e) {\n                // Handle other ZooKeeper exceptions\n                trace.add(\"ZooKeeper exception: \" + e.getMessage());\n                trace.add(\"Retrying\");\n                continue;\n            }\n        }\n    } finally {\n        // Commit the trace\n        trace.commit();\n    }\n}", "CodeBleu_score": 25.24416386599079}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception    final Stat stat = new Stat();\n    final int retryCount = 10;\n    int attempt = 0;\n    while (true) {\n        try {\n            return zk.setACL(path, aclList, stat.getVersion());\n        } catch (KeeperException.SessionExpiredException e) {\n            if (++attempt >= retryCount) {\n                throw e;\n            }\n        } catch (KeeperException e) {\n            throw e;\n        }\n    }\n}", "CodeBleu_score": 25.929753403608863}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception    Stat stat = null;\n    while (true) {\n        try {\n            stat = zk.setACL(path, aclList, -1);\n            return stat;\n        } catch (KeeperException e) {\n            if (e instanceof ConnectionLossException) {\n                throw e;\n            }\n            if (e instanceof NoNodeException) {\n                throw e;\n            }\n            if (e instanceof NodeExistsException) {\n                throw e;\n            }\n            if (e instanceof BadVersionException) {\n                throw e;\n            }\n            if (e instanceof NoAuthException) {\n                throw e;\n            }\n            if (e instanceof IllegalArgumentException) {\n                throw e;\n            }\n            if (e instanceof RuntimeException) {\n                throw e;\n            }\n            if (e instanceof InterruptedException) {\n                throw e;\n            }\n            if (e instanceof TimeoutException) {\n                throw e;\n            }\n        }\n    }\n}", "CodeBleu_score": 16.724184731630203}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload)    Preconditions.checkArgument(thisId != null && thisId.length() > 0);\n\n    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.payload = payload;\n\n    cache = new CuratorCache(client, membershipPath);\n    cache.start();\n\n    try {\n        client.create()\n                .creatingParentsIfNeeded()\n                .withMode(CreateMode.EPHEMERAL)\n                .forPath(membershipPath + \"/\" + thisId, payload);\n    } catch (Exception e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 40.00870322407308}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload)    Preconditions.checkArgument(StringUtils.isNotEmpty(thisId), \"id cannot be empty\");\n    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.cache = new CuratorCache(client, membershipPath, false);\n    this.cache.start();\n    try {\n        this.node = client.create()\n                .creatingParentsIfNeeded()\n                .withMode(CreateMode.EPHEMERAL)\n                .forPath(membershipPath + \"/\" + thisId, payload);\n    } catch (Exception e) {\n        throw new IllegalStateException(\"Error while creating node\", e);\n    }\n}", "CodeBleu_score": 45.36627386035915}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload)    if (thisId == null || thisId.length() == 0) {\n        throw new IllegalArgumentException(\"thisId cannot be null or empty\");\n    }\n\n    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.thisMember = new Member(thisId, payload);\n    this.members = new CuratorCache(client, membershipPath);\n    this.members.start();\n\n    try {\n        client.create()\n                .creatingParentsIfNeeded()\n                .withMode(CreateMode.EPHEMERAL)\n                .forPath(membershipPath + \"/\" + thisId, payload);\n    } catch (Exception e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 38.548417584625014}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path)   try {\n    client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(path);\n    client.getData().usingWatcher(new Watcher() {\n      @Override\n      public void process(WatchedEvent event) {\n        System.out.println(\"Received event: \" + event);\n      }\n    }).forPath(path);\n  }\n catch (  Exception e) {\n    e.printStackTrace();\n  }\n}", "CodeBleu_score": 33.62882075537693}, {"code": "public static void createThenWatch(CuratorFramework client, String path)     try {\n        client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(path);\n        client.getData().usingWatcher(new CuratorWatcher() {\n            public void process(WatchedEvent event) throws Exception {\n                System.out.println(\"Received event: \" + event);\n            }\n        }).forPath(path);\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}", "CodeBleu_score": 36.801342132501006}, {"code": "public static void createThenWatch(CuratorFramework client, String path)     try {\n        client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(path);\n        client.getData().usingWatcher(new NodeWatcher()).forPath(path);\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n}", "CodeBleu_score": 29.29726587675208}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception    List<OpResult> results = new ArrayList<OpResult>();\n    try {\n        results = zk.multi(operations);\n    } catch (KeeperException.MultiException e) {\n        // check if we have an error\n        if (e.code == Code.OK) {\n            throw new KeeperException.MultiException(e.code, e.getPath(), e.getTxn());\n        }\n        // get the error code\n        Code code = Code.get(e.code);\n        throw new KeeperException.MultiException(code, e.getPath(), e.getTxn());\n    }\n    return results;\n}", "CodeBleu_score": 35.10703961351685}, {"code": "private List<OpResult> doOperation() throws Exception    List<OpResult> results = new ArrayList<OpResult>();\n    try {\n        results = zk.multi(ops);\n    } catch (KeeperException.MultiException e) {\n        // check if the first result indicates an error\n        if (e.results != null && e.results.size() > 0 && e.results.get(0) != null) {\n            int errorCode = e.results.get(0).getErr();\n            throw KeeperException.create(errorCode);\n        }\n    }\n    return results;\n}", "CodeBleu_score": 33.91605568982868}, {"code": "private List<OpResult> doOperation() throws Exception    List<OpResult> result = new ArrayList<OpResult>();\n    List<Op> ops = new ArrayList<Op>();\n    ops.add(createOp);\n    ops.add(deleteOp);\n    ops.add(setDataOp);\n    ops.add(checkOp);\n    result = zk.multi(ops);\n    if (result.get(0).getType() == OpResult.Error) {\n        int rc = (Integer) result.get(0).getData();\n        throw KeeperException.create(Code.get(rc));\n    }\n    return result;\n}", "CodeBleu_score": 32.78734630632138}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception    try {\n        List<String> serviceNames = serviceDiscovery.queryForNames();\n        for (String serviceName : serviceNames) {\n            List<InstanceDetails> instances = serviceDiscovery.queryForInstances(serviceName);\n            System.out.println(\"Instances of service: \" + serviceName);\n            for (InstanceDetails instance : instances) {\n                System.out.println(\"  \" + instance.getAddress() + \":\" + instance.getPort());\n            }\n        }\n    } catch (NoNodeException e) {\n        System.err.println(\"No service discovery nodes available\");\n    } finally {\n        serviceDiscovery.close();\n    }\n}", "CodeBleu_score": 53.71759608523903}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception    try {\n        List<String> services = serviceDiscovery.queryForNames();\n        for (String service : services) {\n            List<InstanceDetails> instances = serviceDiscovery.queryForInstances(service);\n            System.out.println(\"Instances of service \" + service + \":\");\n            for (InstanceDetails instance : instances) {\n                System.out.println(\"  - \" + instance.getId());\n            }\n        }\n    } catch (NoNodeException e) {\n        System.out.println(\"No service instances found.\");\n    } finally {\n        serviceDiscovery.close();\n    }\n}", "CodeBleu_score": 52.06743603036881}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception    try {\n        for (String serviceName : serviceDiscovery.queryForNames()) {\n            for (InstanceDetails instance : serviceDiscovery.queryForInstances(serviceName)) {\n                System.out.println(serviceName + \" -> \" + instance.getAddress() + \":\" + instance.getPort());\n            }\n        }\n    } catch (NoNodeException e) {\n        System.err.println(\"No node found for service discovery\");\n    } finally {\n        serviceDiscovery.close();\n    }\n}", "CodeBleu_score": 40.45246808419504}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children)    return children.stream()\n            .filter(child -> !READY_NODE.equals(child))\n            .sorted()\n            .collect(Collectors.toList());\n}", "CodeBleu_score": 17.712075488138133}, {"code": "private List<String> filterAndSortChildren(List<String> children)    return children.stream()\n            .filter(child -> !READY_NODE.equals(child))\n            .sorted()\n            .collect(Collectors.toList());\n}", "CodeBleu_score": 17.712075488138133}, {"code": "private List<String> filterAndSortChildren(List<String> children)    return children.stream()\n            .filter(name -> !name.equals(READY_NODE))\n            .sorted()\n            .collect(Collectors.toList());\n}\n", "CodeBleu_score": 17.931472864721197}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException    if (zk != null) {\n        zk.close();\n    }\n    zk = new ZooKeeper(newHost, SESSION_TIMEOUT, this);\n    connectedSignal.await();\n    if (zk.getState() == ZooKeeper.States.CONNECTEDREADONLY) {\n        System.out.println(\"Connected to ZooKeeper in read-only mode\");\n    } else {\n        System.out.println(\"Connected to ZooKeeper in read-write mode\");\n    }\n}", "CodeBleu_score": 31.470905801458983}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException    if (zk != null) {\n        zk.close();\n    }\n    zk = new ZooKeeper(newHost, SESSION_TIMEOUT, this);\n    readOnly = !(newHost.equals(zkHost));\n}", "CodeBleu_score": 28.33447162584486}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException    close();\n    LOG.info(\"Connecting to ZooKeeper at \" + newHost);\n    zk = new ZooKeeper(newHost, ZK_SESSION_TIMEOUT, this);\n    connectedSignal.await();\n    if (zk.getState() == ZooKeeper.States.CONNECTEDREADONLY) {\n        LOG.warn(\"Connected read-only to ZooKeeper at \" + newHost);\n    } else {\n        LOG.info(\"Connected read-write to ZooKeeper at \" + newHost);\n    }\n}", "CodeBleu_score": 26.855934357965218}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException    List<ACL> acls = new ArrayList<>();\n    String[] segments = aclString.split(\",\");\n    for (String segment : segments) {\n        String[] parts = segment.split(\":\");\n        if (parts.length != 3) {\n            LOG.error(\"Invalid ACL format: \" + segment);\n            continue;\n        }\n        String scheme = parts[0];\n        String id = parts[1];\n        String permissions = parts[2];\n        ACL acl = new ACL(permissions);\n        acl.setId(new Id(scheme, id));\n        acls.add(acl);\n    }\n    return acls;\n}", "CodeBleu_score": 30.52251080440016}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException    List<ACL> acls = new ArrayList<ACL>();\n    String[] segments = aclString.split(\",\");\n    for (String segment : segments) {\n        String[] parts = segment.split(\":\");\n        if (parts.length != 3) {\n            log.error(\"Invalid ACL segment: \" + segment);\n            continue;\n        }\n        String scheme = parts[0];\n        String id = parts[1];\n        String perms = parts[2];\n        ACL acl = new ACL(perms);\n        acl.setId(new Id(scheme, id));\n        acls.add(acl);\n    }\n    return acls;\n}", "CodeBleu_score": 30.9754530684453}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException    List<ACL> acls = new ArrayList<>();\n    String[] segments = aclString.split(\",\");\n    for (String segment : segments) {\n        String[] parts = segment.split(\":\");\n        if (parts.length != 3) {\n            logger.error(\"Invalid ACL format: \" + segment);\n            continue;\n        }\n        String scheme = parts[0];\n        String id = parts[1];\n        String permissions = parts[2];\n        ACL acl = new ACL(scheme, id, permissions);\n        acls.add(acl);\n    }\n    return acls;\n}", "CodeBleu_score": 29.420752839949206}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception    if (pathList == null) {\n        return;\n    }\n    ZooKeeper zk = zkClient.getZk(serverId);\n    if (zk == null) {\n        return;\n    }\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            zk.delete(path, -1);\n        }\n    } else {\n        for (String path : pathList) {\n            zk.delete(path, -1, (rc, path1, ctx) -> {\n                if (rc != KeeperException.Code.OK.intValue()) {\n                    log.error(\"delete path error: {}\", path);\n                }\n            }, null);\n        }\n    }\n}", "CodeBleu_score": 52.89358195129535}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception    if (pathList == null) {\n        return;\n    }\n    ZooKeeper zk = zkClient.getZooKeeper(serverId);\n    if (zk == null) {\n        throw new Exception(\"Zookeeper connection not found for serverId: \" + serverId);\n    }\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            deletePath(zk, path);\n        }\n    } else {\n        List<Exception> exceptions = new ArrayList<Exception>();\n        for (String path : pathList) {\n            try {\n                deletePath(zk, path);\n            } catch (Exception e) {\n                exceptions.add(e);\n            }\n        }\n        if (!exceptions.isEmpty()) {\n            throw new Exception(\"Errors occurred while deleting paths: \" + exceptions);\n        }\n    }\n}", "CodeBleu_score": 51.3952807479928}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception    if (pathList == null) {\n        return;\n    }\n    ZooKeeper zk = getZooKeeper(serverId);\n    if (zk == null) {\n        return;\n    }\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            zk.delete(path, -1);\n        }\n    } else {\n        List<String> deletePathList = new ArrayList<String>();\n        for (String path : pathList) {\n            deletePathList.add(path);\n            if (deletePathList.size() == 20) {\n                zk.delete(deletePathList.toArray(new String[0]), -1);\n                deletePathList.clear();\n            }\n        }\n        if (deletePathList.size() > 0) {\n            zk.delete(deletePathList.toArray(new String[0]), -1);\n        }\n    }\n}", "CodeBleu_score": 52.01435379649879}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception    writer.write(\"Connecting to \" + url + \"... \");\n    CuratorFramework client = new CuratorZookeeperConnectionFactory(url, 10000, 30000).createConnection();\n    writer.write(\"OK\\n\");\n    ZooKeeperMain main = new ZooKeeperMain(client);\n    return new Terminal(id, url, client, main);\n}", "CodeBleu_score": 33.03163270521823}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception    writer.write(\"Connecting to \" + url + \" ... \");\n    CuratorZookeeperConnectionFactory connectionFactory = new CuratorZookeeperConnectionFactory(url);\n    ZooKeeper client = connectionFactory.create();\n    writer.write(\"Connected\\n\");\n    ZooKeeperMain main = new ZooKeeperMain(client);\n    return new Terminal(id, url, client, main);\n}", "CodeBleu_score": 37.780054827015185}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception    writer.write(\"Connecting to \" + url + \"...\");\n    CuratorFramework client = CuratorZookeeperConnectionFactory.createClient(url, 10000, 10000, 30000, 10000, new RetryNTimes(Integer.MAX_VALUE, 1000));\n    client.start();\n    writer.write(\"Connected.\");\n    ZooKeeperMain main = new ZooKeeperMain(client);\n    return new Terminal(id, url, client, main);\n}", "CodeBleu_score": 35.828908650535226}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected()    int retryCount = 0;\n    while (true) {\n        try {\n            if (connection.isConnected()) {\n                return;\n            }\n            connection.connect();\n            if (connection.isConnected()) {\n                return;\n            }\n        } catch (Exception e) {\n            try {\n                connection.close();\n            } catch (Exception e2) {\n            }\n            throw new IllegalStateException(\"Failed to establish SSH tunnel connection\", e);\n        }\n        retryCount++;\n        if (retryCount > 6) {\n            try {\n                connection.close();\n            } catch (Exception e3) {\n            }\n            throw new IllegalStateException(\"Failed to establish SSH tunnel connection\");\n        }\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e4) {\n        }\n    }\n}", "CodeBleu_score": 37.85974256885138}, {"code": "public void blockUntilConnected()    int retries = 0;\n    while (!isConnected()) {\n        try {\n            retries++;\n            Thread.sleep(1000);\n            connect();\n        } catch (Exception e) {\n            close();\n            throw new IllegalStateException(e);\n        }\n        if (retries == 6) {\n            close();\n            throw new IllegalStateException(\"Cannot connect to ssh server.\");\n        }\n    }\n}", "CodeBleu_score": 48.21190718994435}, {"code": "public void blockUntilConnected()    for (int i = 0; i < 6; i++) {\n        try {\n            if (this.isConnected()) {\n                return;\n            }\n            Thread.sleep(1000);\n        } catch (Exception e) {\n            this.close();\n            throw new IllegalStateException(\"Failed to connect to \" + this.getHost() + \":\" + this.getPort(), e);\n        }\n    }\n    this.close();\n    throw new IllegalStateException(\"Failed to connect to \" + this.getHost() + \":\" + this.getPort() + \" after 6 attempts\");\n}", "CodeBleu_score": 46.76743565965572}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList)    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        log.error(\"Delete node error: \" + e.getMessage());\n        throw new IllegalStateException(\"Delete node error: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 59.24732813222755}, {"code": "public void deleteNode(String serverId, List<String> pathList)    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        log.error(\"deleteNode error\", e);\n        throw new IllegalStateException(\"deleteNode error\");\n    }\n}", "CodeBleu_score": 69.16590717913009}, {"code": "public void deleteNode(String serverId, List<String> pathList)    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        logger.error(\"deleteNode error\", e);\n        throw new IllegalStateException(\"deleteNode error\");\n    }\n}", "CodeBleu_score": 68.68391120966093}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id)    Platform.runLater(() -> {\n        ServerConfig serverConfig = getServerConfigById(id);\n        if (serverConfig != null) {\n            disconnectFromZookeeper(id);\n            removeServerFromTreeItemCache(serverConfig);\n        }\n    });\n}", "CodeBleu_score": 31.80947742530774}, {"code": "public void disconnect(String id)    Platform.runLater(() -> {\n        ServerConfig config = getServerConfigById(id);\n        if (config != null) {\n            disconnectFromZookeeper(config.getId());\n            removeServerFromCache(config.getId());\n        }\n    });\n}\n", "CodeBleu_score": 40.34956416350686}, {"code": "public void disconnect(String id)    Platform.runLater(() -> {\n        ServerConfig serverConfig = serverConfigs.get(id);\n        if (serverConfig != null) {\n            try {\n                serverConfig.getZooKeeper().close();\n                serverConfigs.remove(id);\n                treeItemCache.remove(id);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n        }\n    });\n}", "CodeBleu_score": 39.27416176893313}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream)    Server server = serverService.findServerById(serverId);\n    if (server == null) {\n        throw new IllegalArgumentException(\"Server not found\");\n    }\n    String connectionUrl = server.getConnectionUrl();\n    if (server.getSshTunnelEnabled()) {\n        String sshTunnelUrl = sshTunnelService.getSshTunnelUrl(server);\n        connectionUrl = sshTunnelUrl;\n    }\n    zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 43.3152496295011}, {"code": "public void startTerminal(String serverId, StringWriter stream)    Server server = serverService.getServer(serverId);\n    if (server == null) {\n        throw new IllegalArgumentException(\"Invalid server ID: \" + serverId);\n    }\n    String connectionUrl = server.getConnectionUrl();\n    if (server.isSshTunnelEnabled()) {\n        String sshUrl = sshTunnelService.getSshUrl(server);\n        connectionUrl = sshUrl + \"/\" + connectionUrl;\n    }\n    zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 43.62330869201284}, {"code": "public void startTerminal(String serverId, StringWriter stream)    Server server = serverService.getServer(serverId);\n    if (server == null) {\n        throw new IllegalArgumentException(\"Server not found\");\n    }\n\n    ServerConfiguration serverConfiguration = server.getServerConfiguration();\n    String connectionUrl = serverConfiguration.getConnectionUrl();\n\n    if (serverConfiguration.isSshTunnelEnabled()) {\n        connectionUrl = zookeeperDomainService.startSshTunnel(serverId, connectionUrl, serverConfiguration.getSshTunnelUsername(), serverConfiguration.getSshTunnelPassword());\n    }\n\n    zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 40.89611822976731}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command)    try {\n        ZookeeperServer server = getServerById(id);\n        server.executeCommand(command);\n    } catch (Exception e) {\n        logger.error(\"Failed to execute command on server \" + id + \": \" + e.getMessage());\n        System.out.println(\"Failed to execute command on server \" + id + \". Please try again.\");\n    }\n}\n", "CodeBleu_score": 40.68660555662888}, {"code": "public void executeCommand(String id, String command)    try {\n        // Execute the command on the Zookeeper server\n        String output = zookeeperService.executeCommand(id, command);\n        // Log the output of the command\n        logger.info(\"Command output: {}\", output);\n    } catch (Exception e) {\n        // Log the error and display an error message\n        logger.error(\"Failed to execute command on Zookeeper server with ID {}: {}\", id, e.getMessage());\n        displayErrorMessage(\"Failed to execute command on Zookeeper server with ID \" + id + \". Please try again later.\");\n    }\n}\n", "CodeBleu_score": 44.89689147353913}, {"code": "public void executeCommand(String id, String command)    try {\n        ZookeeperServer server = zookeeperServers.get(id);\n        server.executeCommand(command);\n    } catch (Exception e) {\n        logger.error(\"Failed to execute command on server \" + id + \": \" + e.getMessage());\n        System.out.println(\"Failed to execute command on server \" + id + \". Please try again.\");\n    }\n}\n", "CodeBleu_score": 40.57252482319767}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties()    Properties properties = new Properties();\n    String filePath = \"/etc/zookeeper/conf/zookeeper-env.sh\";\n    File file = new File(filePath);\n    if (file.exists()) {\n        try (InputStream inputStream = new FileInputStream(file)) {\n            properties.load(inputStream);\n            logger.info(\"Loaded Zookeeper system properties from file: {}\", filePath);\n            logger.info(\"Zookeeper system properties: {}\", properties);\n        } catch (IOException e) {\n            logger.error(\"Error loading Zookeeper system properties from file: {}\", filePath, e);\n        }\n    } else {\n        logger.warn(\"Zookeeper system properties file not found: {}\", filePath);\n    }\n    return properties;\n}", "CodeBleu_score": 47.33481632073547}, {"code": "public Properties loadZookeeperSystemProperties()    Properties properties = new Properties();\n    String filePath = System.getProperty(\"zookeeper.properties.location\");\n    File file = new File(filePath);\n    if (file.exists()) {\n        try (FileInputStream inputStream = new FileInputStream(file)) {\n            properties.load(inputStream);\n            LOG.info(\"Loaded zookeeper properties from {}\", filePath);\n        } catch (IOException e) {\n            LOG.error(\"Failed to load zookeeper properties from {}\", filePath, e);\n        }\n    } else {\n        LOG.info(\"No zookeeper properties found at {}\", filePath);\n    }\n    return properties;\n}", "CodeBleu_score": 45.58806176975511}, {"code": "public Properties loadZookeeperSystemProperties()    Properties properties = new Properties();\n    String filePath = System.getProperty(\"zookeeper.system.properties\");\n    if (filePath != null) {\n        File file = new File(filePath);\n        if (file.exists()) {\n            try (InputStream inputStream = new FileInputStream(file)) {\n                properties.load(inputStream);\n                log.info(\"Loaded Zookeeper system properties from {}\", filePath);\n            } catch (IOException e) {\n                log.error(\"Error loading Zookeeper system properties from {}\", filePath, e);\n            }\n        } else {\n            log.warn(\"Zookeeper system properties file does not exist: {}\", filePath);\n        }\n    } else {\n        log.warn(\"Zookeeper system properties file path not specified\");\n    }\n    return properties;\n}", "CodeBleu_score": 44.87825857945123}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content)    try {\n        Properties properties = new Properties();\n        properties.load(new StringReader(content));\n        properties.store(new FileOutputStream(SYS_PROP_PATH), \"\");\n    } catch (IOException e) {\n        LOG.error(\"Failed to save Zookeeper system properties\", e);\n        Notifications.create().title(\"Failed to save Zookeeper system properties\").text(\"Check log for details\").showError();\n    }\n}", "CodeBleu_score": 24.592607438386167}, {"code": "public void saveZookeeperSystemProperties(String content)    Properties properties = new Properties();\n    try {\n        properties.load(new StringReader(content));\n    } catch (IOException e) {\n        log.error(\"Error loading properties from content\", e);\n        Notifications.create().title(\"Error\").text(\"Error loading properties from content\").showError();\n        return;\n    }\n    try {\n        properties.store(new FileOutputStream(SYS_PROP_PATH), null);\n    } catch (IOException e) {\n        log.error(\"Error saving properties to file\", e);\n        Notifications.create().title(\"Error\").text(\"Error saving properties to file\").showError();\n    }\n}", "CodeBleu_score": 39.56115377122281}, {"code": "public void saveZookeeperSystemProperties(String content)    Properties properties = new Properties();\n    try {\n        properties.load(new StringReader(content));\n    } catch (IOException e) {\n        log.error(\"Error loading properties from content\", e);\n        Notification.show(\"Error loading properties from content\", 3000, Notification.Position.TOP_CENTER);\n        return;\n    }\n    try {\n        properties.store(new FileOutputStream(SYS_PROP_PATH), null);\n    } catch (IOException e) {\n        log.error(\"Error saving properties to file\", e);\n        Notification.show(\"Error saving properties to file\", 3000, Notification.Position.TOP_CENTER);\n    }\n}", "CodeBleu_score": 37.7569327351603}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client)    try {\n        BufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n        StringBuilder response = new StringBuilder();\n        String line;\n        while ((line = in.readLine()) != null) {\n            response.append(line);\n        }\n        client.close();\n        return response.toString();\n    } catch (IOException e) {\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 58.6059646741183}, {"code": "private String response(Socket client)    try {\n        BufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n        StringBuilder response = new StringBuilder();\n        String line;\n        while ((line = in.readLine()) != null) {\n            response.append(line);\n        }\n        in.close();\n        client.close();\n        return response.toString();\n    } catch (IOException e) {\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 58.47448735931384}, {"code": "private String response(Socket client)    try {\n        BufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n        StringBuilder response = new StringBuilder();\n        String line;\n        while ((line = in.readLine()) != null) {\n            response.append(line);\n        }\n        client.close();\n        return response.toString();\n    } catch (IOException e) {\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 58.6059646741183}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params)    CuratorFramework client = CuratorFrameworkFactory.newClient(params.getConnectString(), params.getSessionTimeoutMs(), params.getConnectionTimeoutMs(), new RetryNTimes(params.getRetryCount(), params.getRetryIntervalMs()));\n    client.start();\n    try {\n        if (!client.blockUntilConnected(params.getConnectionTimeoutMs(), TimeUnit.MILLISECONDS)) {\n            throw new ZookeeperConnectionException(\"Failed to connect to Zookeeper within \" + params.getConnectionTimeoutMs() + \" ms.\");\n        }\n    } catch (InterruptedException e) {\n        throw new ZookeeperConnectionException(\"Interrupted while waiting for Zookeeper connection.\", e);\n    }\n    return new CuratorZookeeperConnection(client, params);\n}", "CodeBleu_score": 52.88181439034497}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params)  CuratorFramework client = CuratorFrameworkFactory.newClient(params.getConnectString(), new RetryNTimes(5, 1000));\n  client.start();\n  try {\n    if (!client.blockUntilConnected(5,TimeUnit.SECONDS)) {\n      throw new IllegalStateException(\"Failed to connect to Zookeeper\");\n    }\n  }\n catch (  InterruptedException e) {\n    client.close();\n    throw new RuntimeException(e);\n  }\n  return new CuratorZookeeperConnection(client,params);\n}", "CodeBleu_score": 56.02748239167513}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params)  CuratorFramework client = CuratorFrameworkFactory.newClient(params.getZkConnectString(), new ExponentialBackoffRetry(params.getBaseSleepTimeMs(), params.getMaxRetries()));\n  client.start();\n  try {\n    client.blockUntilConnected(5,TimeUnit.SECONDS);\n  }\n catch (  InterruptedException e) {\n    client.close();\n    throw new RuntimeException(\"Interrupted while waiting to connect to ZooKeeper\",e);\n  }\n  return new CuratorZookeeperConnection(client,params);\n}", "CodeBleu_score": 48.8710708859733}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners)    String connectionString = getConnectionString();\n    if (!isSynchronizing) {\n        LOGGER.info(\"Starting Zookeeper synchronization for connection string: {}\", connectionString);\n        isSynchronizing = true;\n        treeCache.addListener(new CuratorTreeCacheListener(listeners));\n        try {\n            treeCache.start();\n        } catch (Exception e) {\n            LOGGER.error(\"Error starting Zookeeper synchronization for connection string: {}\", connectionString, e);\n            treeCache.close();\n        }\n    } else {\n        LOGGER.info(\"Zookeeper synchronization already in progress for connection string: {}\", connectionString);\n    }\n}", "CodeBleu_score": 42.77148545158707}, {"code": "public void sync(List<ZookeeperNodeListener> listeners)    if (!isSyncing()) {\n        log.info(\"Starting Zookeeper synchronization\");\n        treeCache.addListener(new CuratorTreeCacheListener(listeners));\n        try {\n            treeCache.start();\n        } catch (Exception e) {\n            log.error(\"Error starting Zookeeper synchronization\", e);\n            treeCache.close();\n        }\n    } else {\n        log.info(\"Zookeeper synchronization already in progress\");\n    }\n}", "CodeBleu_score": 37.87194700839819}, {"code": "public void sync(List<ZookeeperNodeListener> listeners)    String zkConnectionString = zookeeperConfig.getZkConnectionString();\n    if (!synchronizing.get()) {\n        synchronizing.set(true);\n        LOGGER.info(\"Starting Zookeeper synchronization for connection string [{}]\", zkConnectionString);\n        treeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n        try {\n            treeCache.start();\n        } catch (Exception e) {\n            LOGGER.error(\"Error starting Zookeeper synchronization\", e);\n            treeCache.close();\n        }\n    } else {\n        LOGGER.info(\"Zookeeper synchronization already in progress for connection string [{}]\", zkConnectionString);\n    }\n}", "CodeBleu_score": 46.139197092818215}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception    PathChildrenCache cache = new PathChildrenCache(client, path, true);\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    cache.getListenable().addListener(listener);\n}\n", "CodeBleu_score": 69.46384447055466}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception    PathChildrenCache cache = new PathChildrenCache(client, path, true);\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    cache.getListenable().addListener(listener);\n}\n", "CodeBleu_score": 69.46384447055466}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception    PathChildrenCache cache = new PathChildrenCache(zkClient, path, true);\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    cache.getListenable().addListener(listener);\n}\n", "CodeBleu_score": 59.484641293389814}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService()    try {\n        log.info(\"Unregistering services\");\n        for (String path : paths) {\n            client.delete().forPath(path);\n        }\n    } catch (Exception e) {\n        log.error(\"Error unregistering services: {}\", e.getMessage());\n    } finally {\n        client.close();\n    }\n}", "CodeBleu_score": 52.4279954887246}, {"code": "public void unregisterService()    log.info(\"Unregistering service: {}\", serviceName);\n    try (CuratorFramework curator = curatorFramework()) {\n        for (String path : paths) {\n            try {\n                curator.delete().forPath(path);\n            } catch (Exception e) {\n                log.error(\"Error deleting path: {}\", path, e);\n            }\n        }\n    } catch (Exception e) {\n        log.error(\"Error creating Curator client\", e);\n    }\n}", "CodeBleu_score": 46.52303585907344}, {"code": "public void unregisterService()    logger.info(\"Unregistering services...\");\n    for (String path : paths) {\n        try {\n            curatorClient.delete().forPath(path);\n        } catch (Exception e) {\n            logger.error(\"Error unregistering service: {}\", e.getMessage());\n        }\n    }\n    curatorClient.close();\n}", "CodeBleu_score": 58.39308054347768}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener)    try {\n        makeClientReady();\n        client.subscribeStateChanges(listener);\n    } catch (Exception e) {\n        throw new RuntimeException(e);\n    }\n}\n", "CodeBleu_score": 28.321815873300228}, {"code": "public void addListener(IZkStateListener listener)    try {\n        makeClientReady();\n        client.subscribeStateChanges(listener);\n    } catch (Exception e) {\n        logger.error(\"Error adding state listener\", e);\n    }\n}\n", "CodeBleu_score": 28.24721946930629}, {"code": "public void addListener(IZkStateListener listener)    try {\n        makeClientReady();\n    } catch (Exception e) {\n        throw new RuntimeException(e);\n    }\n    client.subscribeStateChanges(listener);\n}\n", "CodeBleu_score": 27.910098268823692}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority)    this.serverAddr = serverAddr;\n    this.authority = authority;\n    this.retryPolicy = new ExponentialBackoffRetry(1000, 3);\n    this.connectionTimeoutMs = 30 * 1000;\n    this.zkClient = CuratorFrameworkFactory.builder().connectString(this.serverAddr).retryPolicy(this.retryPolicy).connectionTimeoutMs(this.connectionTimeoutMs).build();\n    if (this.authority != null && !this.authority.isEmpty()) {\n        this.zkClient.addAuthInfo(\"digest\", this.authority.getBytes());\n    }\n    this.zkClient.getConnectionStateListenable().addListener((curatorFramework, connectionState) -> {\n        if (connectionState == ConnectionState.LOST) {\n            LOGGER.error(\"Lost connection to Zookeeper\");\n        } else if (connectionState == ConnectionState.CONNECTED) {\n            LOGGER.info(\"Connected to Zookeeper\");\n        } else if (connectionState == ConnectionState.RECONNECTED) {\n            LOGGER.info(\"Reconnected to Zookeeper\");\n        }\n    });\n    try {\n        this.zkClient.start();\n    } catch (Exception e) {\n        throw new IllegalStateException(\"Failed to initialize Zookeeper client\", e);\n    }\n}", "CodeBleu_score": 47.07380354262865}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority)    this.serverAddr = serverAddr;\n    this.authority = authority;\n    this.retryPolicy = new RetryNTimes(3, 1000);\n    this.connectionTimeout = 3000;\n    this.client = CuratorFrameworkFactory.builder()\n            .connectString(serverAddr)\n            .retryPolicy(retryPolicy)\n            .connectionTimeoutMs(connectionTimeout)\n            .build();\n    if (authority != null) {\n        this.client.getZookeeperClient().getZooKeeper().addAuthInfo(AUTH_SCHEME, authority.getBytes(StandardCharsets.UTF_8));\n    }\n    this.client.getConnectionStateListenable().addListener((client, newState) -> {\n        if (newState == CuratorFrameworkState.CONNECTED) {\n            logger.info(\"Connected to Zookeeper server: {}\", serverAddr);\n        } else if (newState == CuratorFrameworkState.LOST) {\n            logger.warn(\"Lost connection to Zookeeper server: {}\", serverAddr);\n        } else if (newState == CuratorFrameworkState.RECONNECTED) {\n            logger.info(\"Reconnected to Zookeeper server: {}\", serverAddr);\n        }\n    });\n    try {\n        this.client.start();\n    } catch (Exception e) {\n        throw new IllegalStateException(\"Failed to initialize Zookeeper client\", e);\n    }\n}", "CodeBleu_score": 47.81334420865678}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority)    try {\n        if (authority != null) {\n            this.authorization = new AuthInfo(authority);\n        }\n        RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n        this.curatorFramework = CuratorFrameworkFactory.builder().connectString(serverAddr).retryPolicy(retryPolicy).connectionTimeoutMs(15000).build();\n        this.curatorFramework.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n            @Override\n            public void stateChanged(CuratorFramework client, ConnectionState newState) {\n                if (newState == ConnectionState.LOST) {\n                    CuratorZookeeperClient.this.connectionLost();\n                } else if (newState == ConnectionState.CONNECTED) {\n                    CuratorZookeeperClient.this.connectionReestablished();\n                } else if (newState == ConnectionState.RECONNECTED) {\n                    CuratorZookeeperClient.this.connectionReestablished();\n                }\n            }\n        });\n        this.curatorFramework.start();\n    } catch (Exception e) {\n        throw new IllegalStateException(\"Unable to connect to Zookeeper server on \" + serverAddr, e);\n    }\n}", "CodeBleu_score": 54.68933177357109}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener)  Map<ChildListener, TargetChildListener> listeners = this.listeners.get(path);\n  if (listeners != null) {\n    TargetChildListener targetListener = listeners.remove(listener);\n    if (targetListener != null) {\n      this.targetListeners.remove(path, targetListener);\n    }\n  }\n}", "CodeBleu_score": 73.53636658196685}, {"code": "public void removeChildListener(String path, ChildListener listener)    Map<ChildListener, TargetChildListener> listeners = this.listeners.get(path);\n    if (listeners != null) {\n        TargetChildListener targetListener = listeners.remove(listener);\n        if (targetListener != null) {\n            targetListener.removeListener(listener);\n            if (listeners.isEmpty()) {\n                this.listeners.remove(path);\n                this.targetListeners.remove(path);\n            }\n        }\n    }\n}", "CodeBleu_score": 66.22965572006805}, {"code": "public void removeChildListener(String path, ChildListener listener)    Map<ChildListener, TargetChildListener> listeners = this.listeners.get(path);\n    if (listeners != null) {\n        TargetChildListener targetListener = listeners.remove(listener);\n        if (targetListener != null) {\n            this.targetListeners.remove(path, targetListener);\n        }\n    }\n}", "CodeBleu_score": 75.61131310967708}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh)    if (zh == NULL) {\n        return -1;\n    }\n\n    char *idc = NULL;\n    char *host = NULL;\n\n    if (zoo_get_context(zh, &idc) != ZOK) {\n        LOG_ERROR(\"Failed to get IDC from ZooKeeper handle\");\n        return -1;\n    }\n\n    if (zoo_get_context(zh, &host) != ZOK) {\n        LOG_ERROR(\"Failed to get host from ZooKeeper handle\");\n        return -1;\n    }\n\n    if (zoo_close(zh) != ZOK) {\n        LOG_ERROR(\"Failed to close ZooKeeper handle\");\n        return -1;\n    }\n\n    if (deserialize_idc_and_host(idc, &idc, &host) != 0) {\n        LOG_ERROR(\"Failed to deserialize IDC and host\");\n        return -1;\n    }\n\n    zh = zookeeper_init(host, watcher_global_watcher, 10000, NULL, NULL, 0);\n    if (zh == NULL) {\n        LOG_ERROR(\"Failed to initialize ZooKeeper handle\");\n        return -1;\n    }\n\n    if (init_env_for_zh(zh, idc, host) != 0) {\n        LOG_ERROR(\"Failed to initialize environment for ZooKeeper handle\");\n        return -1;\n    }\n\n    if (reset_table_watcher(zh) != 0) {\n        LOG_ERROR(\"Failed to reset table watcher\");\n        return -1;\n    }\n\n    return 0;\n}\n", "CodeBleu_score": 35.317706084359884}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh)    char *idc = NULL;\n    char *host = NULL;\n\n    if (zh == NULL) {\n        return -1;\n    }\n\n    if (zoo_get_context(zh) != NULL) {\n        idc = zoo_get_context(zh);\n        zoo_set_context(zh, NULL);\n        free(idc);\n    }\n\n    if (zoo_get_acl_token(zh) != NULL) {\n        host = zoo_get_acl_token(zh);\n        zoo_set_acl_token(zh, NULL);\n        free(host);\n    }\n\n    zookeeper_close(zh);\n\n    idc = strdup(g_idc);\n    host = strdup(g_host);\n\n    zh = zookeeper_init(host, watcher_global_watcher, 10000, 0, idc, 0);\n    if (zh == NULL) {\n        return -1;\n    }\n\n    zoo_set_context(zh, idc);\n    zoo_set_acl_token(zh, host);\n\n    if (watcher_init_env(zh) != 0) {\n        return -1;\n    }\n\n    watcher_reset_table_watcher();\n\n    return 0;\n}\n", "CodeBleu_score": 30.314043407016822}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh)    if (zh == NULL) {\n        return -1;\n    }\n    char *idc = NULL;\n    char *host = NULL;\n    if (zoo_get_context(zh, &idc, &host, NULL, NULL, NULL, NULL) != ZOK) {\n        zoo_error(zh, 0);\n        return -1;\n    }\n    zoo_set_context(zh, NULL, NULL, NULL, NULL, NULL, NULL);\n    zookeeper_close(zh);\n    zh = zookeeper_init(host, watcher_global_timeout, watcher_global_watcher, idc, watcher_global_flags, watcher_global_context);\n    if (zh == NULL) {\n        return -1;\n    }\n    watcher_init_env(zh);\n    watcher_reset_table_watcher();\n    return 0;\n}\n", "CodeBleu_score": 18.036367732611275}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc)    // Update internal tables with the handle and host information\n    zk_handle_to_host[zh] = idc_host;\n    host_to_zk_handle[idc_host] = zh;\n    zk_handle_to_idc[zh] = idc;\n    idc_to_zk_handle[idc] = zh;\n\n    // Check the connection state of the Zookeeper handle\n    if (zoo_state(zh) != ZOO_CONNECTED_STATE) {\n        return;\n    }\n\n    // Register the current host on the Zookeeper server\n    string host_path = get_host_path(idc_host);\n    string host_data = get_host_data(idc_host);\n    int rc = zoo_create(zh, host_path.c_str(), host_data.c_str(), host_data.length(), &ZOO_OPEN_ACL_UNSAFE, 0, nullptr, 0);\n    if (rc != ZOK && rc != ZNODEEXISTS) {\n        log_error(\"Failed to register host on Zookeeper server: %s\", zerror(rc));\n        return;\n    }\n\n    // Set a watcher on the notify node\n    string notify_path = get_notify_path(idc);\n    rc = zoo_wexists(zh, notify_path.c_str(), notify_watcher, nullptr, nullptr);\n    if (rc != ZOK) {\n        log_error(\"Failed to set watcher on notify node: %s\", zerror(rc));\n        return;\n    }\n\n    // Add the IDC to a gray list if the operation failed\n    if (rc == ZNODEEXISTS) {\n        gray_list.insert(idc);\n    }\n}\n", "CodeBleu_score": 46.87399631905629}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc)    // Update internal tables with the handle and host information\n    g_zk_handle_to_idc_host[zh] = idc_host;\n    g_idc_host_to_idc[idc_host] = idc;\n\n    // Check the connection state of the Zookeeper handle\n    if (zoo_state(zh) != ZOO_CONNECTED_STATE) {\n        return;\n    }\n\n    // Register the current host on the Zookeeper server\n    register_host_on_zk(zh, idc_host);\n\n    // Set a watcher on the notify node\n    int rc = zoo_awexists(zh, g_zk_notify_node.c_str(), watcher, NULL, watcher_ctx);\n\n    // Check the result of setting the watcher\n    if (rc != ZOK) {\n        // Add the IDC to the gray list if the operation fails\n        add_to_gray_list(idc);\n        LOG_ERROR(\"zoo_awexists failed, rc=%d, idc=%s\", rc, idc.c_str());\n    }\n}\n", "CodeBleu_score": 38.78253795112909}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc)    if (!zh) {\n        return;\n    }\n\n    int ret = zoo_state(zh);\n    if (ret != ZOO_CONNECTED_STATE) {\n        return;\n    }\n\n    ret = zoo_create(zh, idc_host.c_str(), idc.c_str(), idc.size(), &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);\n    if (ret != ZOK) {\n        return;\n    }\n\n    ret = zoo_wexists(zh, ZK_NOTIFY_NODE, watcher, NULL, NULL);\n    if (ret != ZOK) {\n        log_error(\"zoo_wexists failed, ret = %d\", ret);\n        return;\n    }\n\n    if (ret == ZNONODE) {\n        log_error(\"zoo_wexists failed, ret = %d\", ret);\n        return;\n    }\n\n    if (ret == ZOK) {\n        log_error(\"zoo_wexists failed, ret = %d\", ret);\n        return;\n    }\n\n    if (ret == ZNOAUTH) {\n        log_error(\"zoo_wexists failed, ret = %d\", ret);\n        return;\n    }\n\n    if (ret == ZBADARGUMENTS) {\n        log_error(\"zoo_wexists failed, ret = %d\", ret);\n        return;\n    }\n\n    if (ret == ZINVALIDSTATE) {\n        log_error(\"zoo_wexists failed, ret = %d\", ret);\n        return;\n    }\n\n    if (ret == ZMARSHALLINGERROR) {\n        log_error(\"zoo_wexists failed, ret = %d\", ret);\n        return;\n    }\n\n    if (ret == ZNOCHILDRENFOREPHEMERALS) {\n        log_error(\"zoo_wexists failed, ret = %d\", ret);\n        return;\n    }\n\n    if (ret == ZNODEEXISTS) {\n        log_error(\"zoo_wexists failed", "CodeBleu_score": 41.667349678551865}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n    import hashlib\n    import base64\n    # Combine the username and password\n    combined = f\"{username}:{password}\"\n    # Hash the combined string using SHA-1\n    hashed = hashlib.sha1(combined.encode()).digest()\n    # Encode the hash in base64\n    encoded = base64.b64encode(hashed).decode()\n    # Return the credential in the format \"username:base64_hash\"\n    return f\"{username}:{encoded}\"\n", "CodeBleu_score": 38.41525542060621}, {"code": "def make_digest_acl_credential(username, password)\n    import hashlib\n    import base64\n\n    # Combine the username and password\n    credential = f\"{username}:{password}\"\n\n    # Hash the credential using SHA-1\n    hashed_credential = hashlib.sha1(credential.encode()).digest()\n\n    # Encode the hashed credential in base64\n    encoded_credential = base64.b64encode(hashed_credential).decode()\n\n    # Return the credential in the format \"username:base64_hash\"\n    return f\"{username}:{encoded_credential}\"\n", "CodeBleu_score": 38.62104792588369}, {"code": "def make_digest_acl_credential(username, password)\n    import hashlib\n    import base64\n    # Combine the username and password\n    combined = f\"{username}:{password}\"\n    # Hash the combined string using SHA-1\n    hashed = hashlib.sha1(combined.encode()).digest()\n    # Encode the hash in base64\n    encoded = base64.b64encode(hashed).decode()\n    # Return the credential in the format \"username:base64_hash\"\n    return f\"{username}:{encoded}\"\n", "CodeBleu_score": 38.41525542060621}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n    if not self.processing_element:\n        return False\n    lock_path = \"/lock/%s\" % self.processing_element\n    self.zk.sync(lock_path)\n    lock_value = self.zk.get(lock_path)\n    return lock_value == self.instance_id\n\n", "CodeBleu_score": 34.754842973422946}, {"code": "def holds_lock(self)\n    if self.processing_element is None:\n        return False\n    lock_path = \"/\" + self.processing_element.name + \"/lock\"\n    with self.zookeeper_client.lock:\n        lock_value = self.zookeeper_client.client.get(lock_path)[0]\n    return lock_value == self.instance_id\n\n", "CodeBleu_score": 45.94348896292308}, {"code": "def holds_lock(self)\n    if not self.processing_element:\n        return False\n    lock_path = self.get_lock_path()\n    with self.zk_client.Lock(lock_path):\n        lock_value = self.zk_client.get(lock_path)[0]\n        return lock_value == self.instance_id", "CodeBleu_score": 35.83266031701593}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n    if self.processing_element is not None and self.locked:\n        with self.db.atomic():\n            self.locked = False\n            self.processing_element.delete_instance()\n            self.processing_element = None\n        return True\n    else:\n        return False", "CodeBleu_score": 32.336809169886386}, {"code": "def consume(self)\n    if self.processing_element is not None and self.lock is not None:\n        with self.lock.transaction() as transaction:\n            transaction.delete(self.lock)\n            transaction.delete(self.entry)\n            self.processing_element = None\n            self.lock = None\n            return True\n    return False\n\n", "CodeBleu_score": 37.2676268624401}, {"code": "def consume(self)\n    if self.processing_element is not None and self.locked:\n        with self.db.begin() as txn:\n            txn.delete(self.processing_element.key)\n            txn.delete(self.lock.key)\n        self.processing_element = None\n        self.lock = None\n        self.locked = False\n        return True\n    else:\n        return False", "CodeBleu_score": 39.453423834284834}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n    self.log.debug(\"Reading from socket\")\n    try:\n        header = self._read_header(read_timeout)\n        self.log.debug(\"Read header: %s\", header)\n        if header.xid == PING_XID:\n            self.log.debug(\"Received ping\")\n            self.outstanding_ping = False\n        elif header.xid == AUTH_XID:\n            self._handle_auth_response(header)\n        elif header.xid == WATCH_XID:\n            self._process_watch_event(header)\n        else:\n            buf = self._read_buffer(header.length)\n            self.log.debug(\"Read buffer: %s\", buf)\n            self._handle_response(header, buf)\n    except socket.timeout:\n        self.log.debug(\"Read timeout\")\n        raise\n    except socket.error as e:\n        self.log.debug(\"Read error: %s\", e)\n        raise\n    except Exception as e:\n        self.log.error(\"Error reading from socket: %s\", e)\n        raise\n\n", "CodeBleu_score": 45.107232937692466}, {"code": "def _read_socket(self, read_timeout)\n    while True:\n        try:\n            header = self._read_header(read_timeout)\n        except socket.timeout:\n            raise TimeoutError(\"Timed out waiting for a response from the server.\")\n        except socket.error:\n            raise ConnectionError(\"Connection to the server was lost.\")\n        if header is None:\n            return\n        xid = header.xid\n        if xid == PING_XID:\n            self._log_debug(\"Received ping.\")\n            self.outstanding_ping = False\n        elif xid == AUTH_XID:\n            self._handle_auth_response(header)\n        elif xid == WATCH_XID:\n            self._process_watch_event(header)\n        else:\n            self._log_debug(\"Received response: %s\", header)\n            response = self._read_buffer(header.zxid, header.data_len)\n            if response is not None:\n                self._handle_response(xid, response)", "CodeBleu_score": 35.243298133223874}, {"code": "def _read_socket(self, read_timeout)\n    try:\n        header = self.read_header(read_timeout)\n    except socket.timeout:\n        raise TimeoutError(\"Connection timed out\")\n    except socket.error as e:\n        raise ConnectionLostError(\"Connection lost\") from e\n\n    xid = header.xid\n    if xid == PING_XID:\n        self.log.debug(\"Received ping\")\n        self.clear_outstanding_ping()\n        return\n\n    if xid == AUTH_XID:\n        self.handle_auth_response(header)\n        return\n\n    if xid == WATCH_XID:\n        self.process_watch_event(header)\n        return\n\n    self.log.debug(\"Received header: %s\", header)\n    response = self.read_response(header)\n    self.log.debug(\"Received response: %s\", response)\n\n    return response", "CodeBleu_score": 36.55702459550283}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n    self.log.info(\"Starting ZK loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.log.info(\"Connecting to Zookeeper\")\n            self.zk.start()\n            self.log.info(\"Connected to Zookeeper\")\n            self.connection_stopped.wait(timeout=None)\n        except Exception as e:\n            self.log.warning(f\"Connection to Zookeeper failed: {e}\")\n        finally:\n            self.zk.stop()\n            self.log.info(\"Stopped ZK loop\")\n            self.trigger_session_callback(ZkState.CLOSED)\n\n", "CodeBleu_score": 43.78302343691971}, {"code": "def zk_loop(self)\n    self.log.info(\"Starting ZK loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.wait(0):\n        try:\n            self.connect()\n        except Exception as e:\n            self.log.warning(\"ZK connection failed: %s\", e)\n            if self.stopped.wait(self.retry_timeout):\n                break\n    self.log.info(\"Stopping ZK loop\")\n    self.connection_stopped.set()\n    self.session_callback(self.STATE_CLOSED)\n\n", "CodeBleu_score": 38.72379120868171}, {"code": "def zk_loop(self)\n    self.log.debug(\"Starting ZK loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.wait(0.1):\n        try:\n            self.log.debug(\"Connecting to ZK\")\n            self.client.start()\n            self.log.debug(\"Connected to ZK\")\n            self.session_callback(self.client, self.client.STATE_CONNECTED)\n            self.client.add_listener(self.session_callback)\n            self.client.add_auth(\"digest\", self.auth_data, self.auth_callback)\n            self.client.wait_for_connected()\n            self.log.debug(\"Session established\")\n            self.session_callback(self.client, self.client.STATE_CONNECTED)\n            self.client.wait_for_closed()\n            self.log.debug(\"Session closed\")\n            self.session_callback(self.client, self.client.STATE_CLOSED)\n        except Exception as e:\n            self.log.warning(\"Failed to connect to ZK: %s\", e)\n            if self.stopped.wait(1):\n                break\n    self.connection_stopped.set()\n    self.log.debug(\"Stopped ZK loop\")", "CodeBleu_score": 41.5402499761532}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    index = sorted_members.index(identifier)\n    return sorted_partitions[index::len(sorted_members)]", "CodeBleu_score": 35.701061449925966}, {"code": "def _partitioner(self, identifier, members, partitions)\n    members = sorted(members)\n    partitions = sorted(partitions)\n    index = members.index(identifier)\n    return partitions[index::self.workers]\n\n", "CodeBleu_score": 31.786138278253613}, {"code": "def _partitioner(self, identifier, members, partitions)\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    index = sorted_members.index(identifier)\n    return sorted_partitions[index::len(members)]\n\n", "CodeBleu_score": 37.493399878959686}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n    try:\n        self.barrier.leave()\n    except Exception as e:\n        if self.participating:\n            self.participating = False\n            self.barrier.abort()\n        raise e\n    self.participating = False\n\n", "CodeBleu_score": 43.80016558842468}, {"code": "def leave(self)\n    self._leave()\n    self._set_participating(False)\n", "CodeBleu_score": 9.771602966762103}, {"code": "def leave(self)\n    try:\n        self._leave()\n    except Exception:\n        self._cleanup()\n    self._participating = False", "CodeBleu_score": 37.558291421557456}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start()    try {\n        ServerStatus serverStatus = getServerStatus();\n        if (serverStatus == ServerStatus.STOPPED) {\n            startServer();\n        }\n        return Result.success();\n    } catch (Exception e) {\n        return Result.error(e.getMessage());\n    }\n}", "CodeBleu_score": 34.214964509490414}, {"code": "public Result start()    try {\n        if (isRunning()) {\n            return Result.success(\"HDFS over FTP server is already running.\");\n        } else {\n            ProcessBuilder processBuilder = new ProcessBuilder(\"./start-hdfsftp.sh\");\n            processBuilder.redirectErrorStream(true);\n            Process process = processBuilder.start();\n            BufferedReader reader = new BufferedReader(new InputStreamReader(process.getInputStream()));\n            String line;\n            while ((line = reader.readLine()) != null) {\n                System.out.println(line);\n            }\n            int exitCode = process.waitFor();\n            if (exitCode == 0) {\n                return Result.success(\"HDFS over FTP server started successfully.\");\n            } else {\n                return Result.error(\"Failed to start HDFS over FTP server.\");\n            }\n        }\n    } catch (Exception e) {\n        return Result.error(e.getMessage());\n    }\n}", "CodeBleu_score": 30.244922133397978}, {"code": "public Result start()    try {\n        if (!isRunning()) {\n            ProcessBuilder pb = new ProcessBuilder(startCommand);\n            pb.redirectErrorStream(true);\n            Process p = pb.start();\n            p.waitFor();\n            if (p.exitValue() == 0) {\n                return Result.success(\"HDFS over FTP server started successfully.\");\n            } else {\n                return Result.error(\"Failed to start HDFS over FTP server.\");\n            }\n        } else {\n            return Result.success(\"HDFS over FTP server is already running.\");\n        }\n    } catch (Exception e) {\n        return Result.error(\"An error occurred while starting the HDFS over FTP server.\", e);\n    }\n}", "CodeBleu_score": 38.508321753588184}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop()    try {\n        if (!isRunning()) {\n            return Result.failure(\"FTP server is not running.\");\n        }\n        server.stop();\n        return Result.success(\"FTP server stopped successfully.\");\n    } catch (Exception e) {\n        logger.error(\"Error stopping FTP server: \" + e.getMessage());\n        return Result.failure(\"Error stopping FTP server: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 39.098121172910524}, {"code": "public Result stop()    if (server.isRunning()) {\n        try {\n            server.stop();\n            return new Result(true, \"Server stopped successfully.\");\n        } catch (Exception e) {\n            logger.error(\"Error stopping server: \" + e.getMessage());\n            return new Result(false, \"Error stopping server: \" + e.getMessage());\n        }\n    } else {\n        return new Result(false, \"Server is not running.\");\n    }\n}", "CodeBleu_score": 37.30570857474444}, {"code": "public Result stop()    if (server.isRunning()) {\n        try {\n            server.stop();\n            return new Result(true, \"Stopped\");\n        } catch (Exception e) {\n            log.error(\"Error stopping server\", e);\n            return new Result(false, \"Error stopping server\");\n        }\n    } else {\n        return new Result(false, \"Server is not running\");\n    }\n}", "CodeBleu_score": 33.91807106176989}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request)    if (authorities == null) {\n        return null;\n    }\n    for (GrantedAuthority authority : authorities) {\n        if (authority.authorize(request)) {\n            return request;\n        }\n    }\n    return null;\n}", "CodeBleu_score": 28.43578865318407}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request)    if (authorities == null) {\n        return null;\n    }\n    for (GrantedAuthority authority : authorities) {\n        if (authority.authorize(request)) {\n            return request;\n        }\n    }\n    return null;\n}", "CodeBleu_score": 28.43578865318407}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request)    if (authorities == null) {\n        return null;\n    }\n    boolean success = false;\n    for (GrantedAuthority authority : authorities) {\n        if (authority.authorize(request)) {\n            success = true;\n        }\n    }\n    return success ? request : null;\n}", "CodeBleu_score": 32.00615810601891}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir()    try {\n        FileSystem fileSystem = FileSystem.get(new URI(hdfsUri), new Configuration());\n        return fileSystem.mkdirs(new Path(fullPath));\n    } catch (IOException | URISyntaxException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 53.41778827147898}, {"code": "public boolean mkdir()    try {\n        FileSystem fs = FileSystem.get(conf);\n        return fs.mkdirs(fullPath);\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 66.17039568651255}, {"code": "public boolean mkdir()    try {\n        FileSystem fileSystem = getFileSystem();\n        return fileSystem.mkdirs(new Path(fullPath));\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 56.53075976024704}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete()    try {\n        FileSystem fs = FileSystem.get(conf);\n        return fs.delete(fullPath, true);\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 62.88503150205447}, {"code": "public boolean delete()    try {\n        FileSystem fs = FileSystem.get(conf);\n        return fs.delete(fullPath, true);\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 62.88503150205447}, {"code": "public boolean delete()    try {\n        FileSystem fileSystem = getFileSystem();\n        return fileSystem.delete(fullPath, true);\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 58.24552658603162}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile)  try {\n    FileSystem fs=getFileSystem();\n    Path path=new Path(ftpFile.getParentDir(),ftpFile.getName());\n    return fs.rename(path,new Path(ftpFile.getAbsolutePath()));\n  }\n catch (  IOException e) {\n    LOG.error(\"Error moving file\",e);\n    return false;\n  }\n}", "CodeBleu_score": 44.37931861824318}, {"code": "public boolean move(FtpFile ftpFile)    try {\n        FileSystem fs = FileSystem.get(context.getConfiguration());\n        Path oldPath = new Path(ftpFile.getAbsolutePath());\n        Path newPath = new Path(ftpFile.getParentDir(), ftpFile.getName());\n        return fs.rename(oldPath, newPath);\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    return false;\n}", "CodeBleu_score": 49.59551655449417}, {"code": "public boolean move(FtpFile ftpFile)    try {\n        FileSystem fs = getFileSystem();\n        Path src = new Path(ftpFile.getAbsolutePath());\n        Path dst = new Path(getHomeDirectory(), ftpFile.getName());\n        if (fs.exists(dst)) {\n            fs.delete(dst, true);\n        }\n        fs.rename(src, dst);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    return false;\n}", "CodeBleu_score": 48.732169590745066}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles()    try {\n        FileSystem fs = getFileSystem();\n        FileStatus[] fss = fs.listStatus(new Path(getPath()));\n        List<FtpFile> files = new ArrayList<FtpFile>();\n        for (FileStatus fsStat : fss) {\n            files.add(new HdfsFtpFile(fsStat, getPath()));\n        }\n        return Collections.unmodifiableList(files);\n    } catch (IOException e) {\n        log.error(\"Could not list files for path \" + getPath(), e);\n        return null;\n    }\n}", "CodeBleu_score": 27.485254703412092}, {"code": "public List<FtpFile> listFiles()    try {\n        FileSystem fs = getFileSystem();\n        FileStatus[] statuses = fs.listStatus(getPath());\n        FtpFile[] files = new FtpFile[statuses.length];\n        for (int i = 0; i < statuses.length; i++) {\n            files[i] = new HdfsFtpFile(getBaseDir(), statuses[i]);\n        }\n        return Collections.unmodifiableList(Arrays.asList(files));\n    } catch (IOException e) {\n        LOG.error(\"Error listing files\", e);\n        return null;\n    }\n}", "CodeBleu_score": 37.146249216857576}, {"code": "public List<FtpFile> listFiles()  try {\n    FileSystem fileSystem=getFileSystem();\n    FileStatus[] statuses=fileSystem.listStatus(path);\n    List<FtpFile> files=new ArrayList<FtpFile>(statuses.length);\n    String base=getVirtualPath();\n    for (    FileStatus status : statuses) {\n      files.add(new HdfsFtpFile(base,status));\n    }\n    return Collections.unmodifiableList(files);\n  }\n catch (  IOException e) {\n    LOG.log(Level.WARNING,\"Unable to list files for \" + path,e);\n    return null;\n  }\n}", "CodeBleu_score": 26.839897335376676}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure()    if (configured) {\n        return;\n    }\n    configured = true;\n    try {\n        File userDataFile = new File(userDataFilePath);\n        if (!userDataFile.exists()) {\n            userDataFile.createNewFile();\n        }\n        properties.load(new FileInputStream(userDataFile));\n    } catch (IOException e) {\n        throw new FtpServerConfigurationException(\"Failed to load user data file: \" + userDataFilePath, e);\n    }\n    convertDeprecatedPropertyNames();\n}", "CodeBleu_score": 40.761720032463906}, {"code": "public void configure()    if (isConfigured) {\n        return;\n    }\n    isConfigured = true;\n    try {\n        if (userDataFile.exists()) {\n            loadUserData();\n        }\n    } catch (IOException e) {\n        throw new FtpServerConfigurationException(\"Could not load user data file \" + userDataFile, e);\n    }\n    convertDeprecatedProperties();\n}", "CodeBleu_score": 31.09481096660144}, {"code": "public void configure()    if (isConfigured) {\n        return;\n    }\n    isConfigured = true;\n    try {\n        loadUserData();\n    } catch (IOException e) {\n        throw new FtpServerConfigurationException(e, \"Failed to load user data from file [%s]\", userDataFilePath);\n    }\n    convertDeprecatedProperties();\n}", "CodeBleu_score": 25.617908094892588}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException    try {\n        File parent = userDataFile.getParentFile();\n        if (!parent.exists()) {\n            if (!parent.mkdirs()) {\n                throw new ConfigurationException(\"Could not create parent directory for user data file\");\n            }\n        }\n        try (FileOutputStream fos = new FileOutputStream(userDataFile)) {\n            fos.write(userData.getBytes(StandardCharsets.UTF_8));\n        }\n    } catch (IOException e) {\n        LOG.error(\"Error saving user data\", e);\n        throw new FtpException(\"Error saving user data\", e);\n    }\n}", "CodeBleu_score": 37.51046190222044}, {"code": "private void saveUserData() throws FtpException    try {\n        File parent = userDataFile.getParentFile();\n        if (!parent.exists() && !parent.mkdirs()) {\n            throw new ConfigurationException(\"Unable to create directory for user data: \" + parent.getAbsolutePath());\n        }\n        try (FileOutputStream fos = new FileOutputStream(userDataFile)) {\n            properties.store(fos, \"FTP Server User Data\");\n        }\n    } catch (IOException e) {\n        logger.error(\"Failed to save user data\", e);\n        throw new FtpException(\"Failed to save user data\", e);\n    }\n}", "CodeBleu_score": 39.404347355951394}, {"code": "private void saveUserData() throws FtpException    try {\n        File parent = userDataFile.getParentFile();\n        if (!parent.exists() && !parent.mkdirs()) {\n            throw new ConfigurationException(\"Failed to create parent directories for user data file\");\n        }\n        try (FileOutputStream fos = new FileOutputStream(userDataFile)) {\n            ObjectOutputStream oos = new ObjectOutputStream(fos);\n            oos.writeObject(userData);\n            oos.close();\n        }\n    } catch (IOException e) {\n        logger.error(\"Failed to save user data\", e);\n        throw new FtpException(\"Failed to save user data\", e);\n    }\n}", "CodeBleu_score": 40.813614608263485}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user)    try {\n        HdfsUserManager hdfsUserManager = new HdfsUserManager();\n        hdfsUserManager.setFile(\"users.properties\");\n        hdfsUserManager.deleteUser(user);\n        return new Result(true, \"success\");\n    } catch (Exception e) {\n        logger.error(e.getMessage());\n        return new Result(false, \"failure\");\n    }\n}\n", "CodeBleu_score": 50.21597154547916}, {"code": "public Result delete(@PathVariable(value = \"user\") String user)    HdfsUserManager hdfsUserManager = new HdfsUserManager();\n    hdfsUserManager.setFile(new File(\"users.properties\"));\n    try {\n        hdfsUserManager.deleteUser(user);\n        return new Result(Result.SUCCESS, \"Successfully deleted user \" + user);\n    } catch (Exception e) {\n        log.error(\"Error deleting user \" + user, e);\n        return new Result(Result.FAILURE, \"Failed to delete user \" + user);\n    }\n}\n", "CodeBleu_score": 57.786484572181095}, {"code": "public Result delete(@PathVariable(value = \"user\") String user)    HdfsUserManager userManager = new HdfsUserManager();\n    userManager.setFile(\"users.properties\");\n    try {\n        userManager.delete(user);\n        return new Result(200, \"success\");\n    } catch (Exception e) {\n        logger.error(\"delete user error\", e);\n        return new Result(500, \"failure\");\n    }\n}", "CodeBleu_score": 45.45418796027387}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException    LOG.info(\"Opening file {} with buffer size {}\", path, bufferSize);\n    Path qualifiedPath = qualify(path);\n    try {\n        return new FSDataInputStream(new BufferedInputStream(store.open(qualifiedPath), bufferSize));\n    } catch (Exception e) {\n        LOG.warn(\"Failed to open file {}\", qualifiedPath, e);\n        return null;\n    }\n}\n", "CodeBleu_score": 32.83741976477316}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException    LOG.warn(\"Opening {} with buffer size {}\", path, bufferSize);\n    String qualifiedPath = qualify(path);\n    try {\n        return new FSDataInputStream(new BufferedInputStream(store.getFileStream(qualifiedPath), bufferSize));\n    } catch (Exception e) {\n        LOG.warn(\"Failed to open {}\", path, e);\n        return null;\n    }\n}\n", "CodeBleu_score": 33.47652074472681}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException    LOG.warn(\"open \" + path + \" with buffer size \" + bufferSize);\n    path = qualify(path);\n    try {\n        return new FSDataInputStream(new BufferedInputStream(new FSInputStream(path)));\n    } catch (Exception e) {\n        LOG.warn(\"open \" + path + \" with buffer size \" + bufferSize + \" failed\", e);\n        return null;\n    }\n}\n", "CodeBleu_score": 31.797748983205885}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException    LOG.debug(\"Rename: {} to {}\", src, dst);\n    if (src.equals(ROOT)) {\n        return false;\n    }\n    if (src.equals(dst)) {\n        return true;\n    }\n    Entry dstEntry = getEntry(dst);\n    if (dstEntry != null && dstEntry.isDir()) {\n        dst = new Path(dst, src.getName());\n    }\n    Path srcQualified = qualify(src);\n    Path dstQualified = qualify(dst);\n    return store.rename(srcQualified, dstQualified);\n}\n", "CodeBleu_score": 47.126945263750265}, {"code": "public boolean rename(Path src, Path dst) throws IOException    LOG.info(\"Rename \" + src + \" to \" + dst);\n    if (src.equals(ROOT)) {\n        return false;\n    }\n    if (src.equals(dst)) {\n        return true;\n    }\n    FileStatus dstEntry = getFileStatus(dst);\n    if (dstEntry.isDirectory()) {\n        dst = new Path(dst, src.getName());\n    }\n    Path srcQualified = qualify(src);\n    Path dstQualified = qualify(dst);\n    return getFileSystemStore().rename(srcQualified, dstQualified);\n}", "CodeBleu_score": 44.556207419680895}, {"code": "public boolean rename(Path src, Path dst) throws IOException    LOG.info(\"Renaming \" + src + \" to \" + dst);\n    if (src.equals(root)) {\n        return false;\n    }\n    if (src.equals(dst)) {\n        return true;\n    }\n    Entry entry = getEntry(dst);\n    if (entry != null && entry.isDirectory()) {\n        dst = new Path(dst, src.getName());\n    }\n    Path srcPath = qualify(src);\n    Path dstPath = qualify(dst);\n    return store.rename(srcPath, dstPath);\n}", "CodeBleu_score": 44.20325676336706}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability)    if (capability.toLowerCase().equals(\"hflush\")) {\n        return supportFlush;\n    } else if (capability.toLowerCase().equals(\"hsync\")) {\n        return true;\n    } else {\n        return false;\n    }\n}", "CodeBleu_score": 33.15017885905651}, {"code": "public boolean hasCapability(String capability)    if (capability.toLowerCase().equals(\"hsync\")) {\n        return supportFlush;\n    } else if (capability.toLowerCase().equals(\"hflush\")) {\n        return supportFlush;\n    }\n    return false;\n}", "CodeBleu_score": 29.22852668707401}, {"code": "public boolean hasCapability(String capability)    if (capability.toLowerCase().equals(\"hsync\")) {\n        return true;\n    } else if (capability.toLowerCase().equals(\"hflush\")) {\n        return supportFlush;\n    } else {\n        return false;\n    }\n}\n", "CodeBleu_score": 33.15017885905651}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException    if (offset > lastFlushOffset) {\n        final long flushOffset = lastFlushOffset;\n        final long flushLength = offset - flushOffset;\n        if (flushLength > 0) {\n            final long startTime = System.currentTimeMillis();\n            final long startNanoTime = System.nanoTime();\n            try {\n                final byte[] bytes = new byte[(int) flushLength];\n                readFully(bytes, flushOffset, flushLength);\n                final long bytesWritten = filerClient.write(bytes);\n                if (bytesWritten != flushLength) {\n                    throw new IOException(\"Failed to flush \" + flushLength + \" bytes to the service, only \" + bytesWritten + \" bytes written\");\n                }\n                filerClient.flush();\n            } catch (final IOException e) {\n                throw e;\n            } catch (final Exception e) {\n                throw new IOException(\"Failed to flush \" + flushLength + \" bytes to the service\", e);\n            } finally {\n                lastFlushOffset = offset;\n                filerClient.writeMetadata(lastFlushOffset, offset);\n                flushTimeNanos.addAndGet(System.nanoTime() - startNanoTime);\n                flushTimeMillis.addAndGet(System.currentTimeMillis() - startTime);\n            }\n        }\n    }\n}", "CodeBleu_score": 30.66716818750147}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException    if (offset == lastFlushOffset) {\n        return;\n    }\n    // \u5199\u5165\u6570\u636e\n    try {\n        filerClient.write(path, offset, writtenBytes, 0, writtenBytes.length);\n    } catch (final Throwable t) {\n        throw new IOException(\"write to filer failed\", t);\n    }\n    // \u66f4\u65b0\u5143\u6570\u636e\n    try {\n        filerClient.update(path, offset + writtenBytes.length);\n    } catch (final Throwable t) {\n        throw new IOException(\"update to filer failed\", t);\n    }\n    // \u66f4\u65b0\u6700\u540e\u4e00\u6b21\u5199\u5165\u7684\u504f\u79fb\u91cf\n    lastFlushOffset = offset + writtenBytes.length;\n}", "CodeBleu_score": 32.146661729198335}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException    if (offset < 0) {\n        throw new IllegalArgumentException(\"offset must be greater than or equal to 0\");\n    }\n    if (offset > lastFlushOffset) {\n        final long numBytesToFlush = offset - lastFlushOffset;\n        final byte[] bytesToFlush = new byte[(int) numBytesToFlush];\n        System.arraycopy(buffer, (int) lastFlushOffset, bytesToFlush, 0, (int) numBytesToFlush);\n        try {\n            filerClient.write(bytesToFlush);\n        } catch (final Exception e) {\n            throw new IOException(\"Error writing to filer client\", e);\n        }\n        lastFlushOffset = offset;\n    }\n}", "CodeBleu_score": 34.39444024515777}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException     bufferToWrite.flip();\n    final int bytesToWrite = bufferToWrite.limit();\n    ensureTaskQueueNotOverloaded();\n    completionService.submit(new WriteTask(bufferToWrite, writePosition));\n    recordWriteOperation(bytesToWrite);\n    manageOperationQueue();\n    return bytesToWrite;\n}\n", "CodeBleu_score": 21.096315304574485}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException     int bytesWritten = 0;\n    bufferToWrite.flip();\n    final int byteLength = bufferToWrite.limit();\n    if (completionService.getQueueSize() > maxQueueSize) {\n        try {\n            completionService.await();\n        } catch (InterruptedException e) {\n            throw new IOException(\"Interrupted while waiting for write completion\", e);\n        }\n    }\n    completionService.submit(new WriteTask(bufferToWrite, writePosition));\n    bytesWritten = byteLength;\n    operations.add(new Operation(writePosition, byteLength, false));\n    return bytesWritten;\n}\n\n", "CodeBleu_score": 29.792032839098916}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException     // Flip the buffer to prepare for reading\n    bufferToWrite.flip();\n    // Calculate the byte length\n    final int byteLength = bufferToWrite.limit();\n    // Ensure the task queue is not overloaded\n    while (taskQueue.size() >= MAX_TASK_QUEUE_SIZE) {\n        try {\n            wait();\n        } catch (final InterruptedException e) {\n            throw new IOException(e);\n        }\n    }\n    // Submit a write task to the completion service\n    final WriteTask writeTask = new WriteTask(bufferToWrite, writePosition);\n    completionService.submit(writeTask);\n    // Record the write operation\n    final WriteOperation writeOperation = new WriteOperation(bufferToWrite, writePosition, byteLength);\n    operationQueue.add(writeOperation);\n    // Manage the operation queue\n    manageOperationQueue();\n    // Return the number of bytes written\n    return byteLength;\n}", "CodeBleu_score": 36.23898870821481}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException    try {\n        while (completionService.poll() == null) {\n            Thread.sleep(10);\n        }\n    } catch (InterruptedException e) {\n        throw new IOException(e);\n    }\n}\n", "CodeBleu_score": 22.456321268990507}, {"code": "private void waitForTaskToComplete() throws IOException    while (true) {\n        try {\n            Future<Integer> result = completionService.take();\n            if (result == null) {\n                break;\n            }\n        } catch (InterruptedException e) {\n            throw new IOException(\"InterruptedException: \" + e.getMessage(), e);\n        }\n    }\n}", "CodeBleu_score": 30.266338644160797}, {"code": "private void waitForTaskToComplete() throws IOException    while (completionService.poll() == null) {\n        try {\n            Thread.sleep(100);\n        } catch (InterruptedException e) {\n            throw new IOException(\"Interrupted\", e);\n        }\n    }\n}", "CodeBleu_score": 23.400992826829576}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException    while (true) {\n        WriteOperation operation = writeOperationQueue.peek();\n        if (operation == null) {\n            break;\n        }\n        if (operation.isDone()) {\n            writeOperationQueue.poll();\n            totalAppendOffset += operation.getLength();\n        } else {\n            break;\n        }\n    }\n}", "CodeBleu_score": 29.570465627917397}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException    while (!writeOperationQueue.isEmpty()) {\n        WriteOperation writeOperation = writeOperationQueue.peek();\n        if (writeOperation.isDone()) {\n            try {\n                totalAppendOffset += writeOperation.get().length;\n                writeOperationQueue.remove();\n            } catch (ExecutionException e) {\n                throw new IOException(e);\n            }\n        } else {\n            break;\n        }\n    }\n}\n", "CodeBleu_score": 40.71691133654182}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException    while (!writeOperationQueue.isEmpty()) {\n        WriteOperation writeOperation = writeOperationQueue.peek();\n        if (writeOperation.isDone()) {\n            writeOperationQueue.remove();\n            totalAppendOffset += writeOperation.getLength();\n        } else {\n            break;\n        }\n    }\n}\n", "CodeBleu_score": 33.50207826332415}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user)    if (user == null) {\n        throw new IllegalArgumentException(\"user cannot be null\");\n    }\n    String homePath = user.getHomeDirectory();\n    if (homePath == null) {\n        throw new IllegalArgumentException(\"user home directory cannot be null\");\n    }\n    this.homePath = homePath;\n    this.user = user;\n}", "CodeBleu_score": 65.81920705597058}, {"code": "protected HdfsFileSystemView(User user)    if (user == null) {\n        throw new IllegalArgumentException(\"user must be non-null\");\n    }\n    String homePath = user.getHomeDirectory();\n    if (homePath == null) {\n        throw new IllegalArgumentException(\"user must have a home directory\");\n    }\n    this.homePath = homePath;\n    this.user = user;\n}", "CodeBleu_score": 62.20189567702309}, {"code": "protected HdfsFileSystemView(User user)  if (user == null) {\n    throw new IllegalArgumentException(\"user is null\");\n  }\n  String homePath = user.getHomeDirectory();\n  if (homePath == null) {\n    throw new IllegalArgumentException(\"user home directory is null\");\n  }\n  this.homePath = homePath;\n  this.user = user;\n}", "CodeBleu_score": 65.74706030808225}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir)    Path newPath;\n    if (dir.startsWith(\"/\")) {\n        newPath = Path.of(dir);\n    } else {\n        newPath = Path.of(currentPath.toString(), dir);\n    }\n    if (newPath.getParent().equals(Path.of(\"/\"))) {\n        return false;\n    }\n    if (Files.isDirectory(newPath)) {\n        currentPath = newPath;\n        return true;\n    } else {\n        return false;\n    }\n}", "CodeBleu_score": 28.807745205614843}, {"code": "public boolean changeWorkingDirectory(String dir)    Path newPath = null;\n    if (Path.of(dir).isAbsolute()) {\n        newPath = Path.of(dir);\n    } else {\n        newPath = currentPath.resolve(dir);\n    }\n    if (newPath.normalize().startsWith(root)) {\n        if (Files.isDirectory(newPath)) {\n            currentPath = newPath;\n            return true;\n        }\n    }\n    return false;\n}", "CodeBleu_score": 19.53915944944466}, {"code": "public boolean changeWorkingDirectory(String dir)    Path newPath = Paths.get(dir);\n    if (newPath.isAbsolute()) {\n        currentPath = newPath;\n    } else {\n        currentPath = currentPath.resolve(newPath);\n    }\n    if (currentPath.getParent().equals(rootPath)) {\n        return false;\n    }\n    if (Files.isDirectory(currentPath)) {\n        return true;\n    } else {\n        return false;\n    }\n}", "CodeBleu_score": 22.40233657430887}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf)    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.get(SeaweedFSConstants.SEAWEEDFS_ACCESS_MODE, \"publicUrl\");\n}", "CodeBleu_score": 36.19080452777847}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf)    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n    this.filerClient = new FilerClient(host, grpcPort, null);\n    this.accessMode = conf.get(Constants.STORAGE_ACCESS_MODE, Constants.STORAGE_ACCESS_MODE_DIRECT);\n}\n", "CodeBleu_score": 28.133795935671646}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf)    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.get(SeaweedFileSystem.ACCESS_MODE, SeaweedFileSystem.ACCESS_MODE_DEFAULT);\n}\n", "CodeBleu_score": 34.146580496160624}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException  LOG.debug(\"Opening file {} for read\", path);\n  final FileEntry entry = filerClient.lookupFile(path);\n  if (entry == null) {\n    throw new FileNotFoundException(path.toString());\n  }\n  return new SeaweedHadoopInputStream(filerClient, statistics, path);\n}\n", "CodeBleu_score": 59.81903291165879}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException    LOG.info(\"Opening {} for read\", path);\n    final FileEntry entry = this.lookupFile(path);\n    if (entry == null) {\n        throw new FileNotFoundException(path.toString());\n    }\n    return new SeaweedHadoopInputStream(this.filerClient, statistics, path.toString());\n}", "CodeBleu_score": 54.28619146268048}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException  LOG.debug(\"openFileForRead: \" + path);\n  FileEntry entry = lookupFile(path);\n  if (entry == null) {\n    throw new FileNotFoundException(\"File not found: \" + path);\n  }\n  return new SeaweedHadoopInputStream(filerClient, statistics, path);\n}\n", "CodeBleu_score": 67.84197001627422}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf)    this.conf = conf;\n    try {\n        this.localHostName = InetAddress.getLocalHost().getHostName();\n    } catch (UnknownHostException e) {\n        this.localHostName = \"localhost\";\n    }\n    this.numThreadsPerMap = conf.getInt(NUM_THREADS_PER_MAP, 1);\n    this.numFilesPerThread = conf.getInt(NUM_FILES_PER_THREAD, 1);\n    this.threadPool = Executors.newFixedThreadPool(this.numThreadsPerMap, new ThreadFactory() {\n        private final AtomicInteger threadNumber = new AtomicInteger(1);\n\n        @Override\n        public Thread newThread(Runnable r) {\n            Thread t = new Thread(r, \"Hadoop-MR-Thread-\" + HadoopMRJob.this.localHostName + \"-\" + HadoopMRJob.this.threadPoolNumber + \"-\" + this.threadNumber.getAndIncrement());\n            t.setDaemon(true);\n            return t;\n        }\n    });\n}\n", "CodeBleu_score": 39.76288126062413}, {"code": "public void configure(JobConf conf)    this.conf = conf;\n    try {\n        this.hostName = InetAddress.getLocalHost().getHostName();\n    } catch (UnknownHostException e) {\n        this.hostName = \"localhost\";\n    }\n    this.threadsPerMap = conf.getInt(\"mapred.map.tasks\", 2);\n    this.filesPerThread = conf.getInt(\"mapred.files.per.thread\", 1);\n    this.threadPool = Executors.newFixedThreadPool(this.threadsPerMap, new DaemonThreadFactory());\n}\n", "CodeBleu_score": 42.15069372628237}, {"code": "public void configure(JobConf conf)    this.conf = conf;\n    try {\n        this.host = InetAddress.getLocalHost().getHostName();\n    } catch (Exception e) {\n        this.host = \"localhost\";\n    }\n    this.numThreadsPerMap = conf.getInt(\"mapred.map.tasks\", 2);\n    this.numFilesPerThread = conf.getInt(\"mapred.files.per.map\", 1);\n    this.threadPool = Executors.newFixedThreadPool(numThreadsPerMap, new DaemonThreadFactory());\n}\n", "CodeBleu_score": 44.10300560500126}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException    final String host = uri.getHost();\n    synchronized (trashEmptiers) {\n        if (trashEmptiers.containsKey(host)) {\n            return;\n        }\n        UserGroupInformation ugi = UserGroupInformation.getSuperUser();\n        FileSystem fs = new JuiceFileSystemImpl(ugi);\n        fs.initialize(uri, conf);\n        Trash trash = new Trash(fs, conf);\n        Trash.TrashConfiguration trashConf = trash.getTrashConfiguration();\n        TrashEmptier emptier = new TrashEmptier(trashConf, trash);\n        emptier.start();\n        trashEmptiers.put(host, emptier);\n    }\n}", "CodeBleu_score": 35.45338160121856}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException  try {\n    final String host = uri.getHost();\n    synchronized (trashEmptier) {\n      if (trashEmptier.containsKey(host)) {\n        return;\n      }\n      UserGroupInformation ugi = UserGroupInformation.getCurrentUser();\n      UserGroupInformation superUser = UserGroupInformation.createSuperUser();\n      ugi.addToCache(superUser);\n      ugi = superUser;\n      FileSystem fs = new JuiceFileSystemImpl();\n      fs.initialize(uri, conf);\n      Trash trash = new Trash(fs, conf);\n      Trash.TrashConfiguration trashConfig = new Trash.TrashConfiguration(conf);\n      trashEmptier.put(host, new Timer(true));\n      trashEmptier.get(host).schedule(new TimerTask() {\n        @Override\n        public void run() {\n          try {\n            trash.emptyTrash(ugi, trashConfig);\n          } catch (IOException e) {\n            LOG.warn(\"Failed to empty trash\", e);\n          }\n        }\n      }, 0, 1000 * 60 * 10);\n    }\n  } catch (Exception e) {\n    throw new IOException(\"Failed to start trash emptier\", e);\n  }\n}", "CodeBleu_score": 44.49547475652644}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException  String host = uri.getHost();\n  synchronized (trashEmptierTasks) {\n    if (trashEmptierTasks.containsKey(host)) {\n      return;\n    }\n    UserGroupInformation ugi = UserGroupInformation.createSuperUser();\n    FileSystem fs = new JuiceFileSystemImpl(ugi, conf);\n    Trash trash = Trash.get(conf);\n    TrashConfig trashConfig = trash.getTrashConfig(uri);\n    TrashEmptierTask task = new TrashEmptierTask(fs, trashConfig);\n    ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(1);\n    scheduler.scheduleWithFixedDelay(task, 0, 10, TimeUnit.MINUTES);\n    trashEmptierTasks.put(host, scheduler);\n  }\n}", "CodeBleu_score": 37.91777424710035}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception    if (context == null) {\n        throw new Exception(\"Context cannot be null\");\n    }\n    String currentContext = getContext();\n    if (currentContext == null || currentContext.isEmpty()) {\n        currentContext = context;\n    } else {\n        String[] currentContextParts = currentContext.split(\"\\\\|\");\n        boolean hasSignature = false;\n        for (String part : currentContextParts) {\n            if (part.startsWith(\"signature=\")) {\n                hasSignature = true;\n                break;\n            }\n        }\n        if (!hasSignature) {\n            currentContext += \"|\" + context;\n        }\n    }\n    setCallerContext(currentContext);\n}", "CodeBleu_score": 32.51084932033533}, {"code": "public static void setContext(String context) throws Exception    String currentContext = getContext();\n    if (currentContext == null || currentContext.isEmpty()) {\n        currentContext = \"context=\" + context;\n    } else {\n        if (!currentContext.contains(\"signature=\")) {\n            currentContext += \",\" + context;\n        }\n    }\n    setCallerContext(currentContext);\n}", "CodeBleu_score": 26.049363314470025}, {"code": "public static void setContext(String context) throws Exception    if (callerContext == null || !callerContext.isValid()) {\n        callerContext = new CallerContext(context);\n        callerContext.set();\n    } else if (!callerContext.isValid() && !callerContext.getContext().contains(context)) {\n        callerContext.appendContext(context);\n        callerContext.set();\n    }\n}", "CodeBleu_score": 28.728766112142708}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri)  auto fs = filesystem::hdfs_filesystem(uri);\n  if (!fs)\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Failed to initialize HDFS filesystem\")));\n\n  if (hdfsDelete(fs.get(), uri.to_path().c_str(), 0) < 0) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Failed to delete file \") + uri.to_string()));\n  }\n\n  return Status::Ok();\n}\n", "CodeBleu_score": 62.03225181102309}, {"code": "Status HDFS::remove_file(const URI& uri)  std::string filename;\n  RETURN_NOT_OK(uri.to_path(&filename));\n\n  auto fs = filesystem::global_fs();\n  if (fs == nullptr)\n    return LOG_STATUS(Status::HDFSError(\"HDFS global filesystem instance not set\"));\n\n  // Check if file exists\n  bool exists;\n  RETURN_NOT_OK(is_file(uri, &exists));\n  if (!exists)\n    return Status::Ok();\n\n  // Delete file\n  if (hdfsDelete(fs, filename.c_str(), 0) < 0) {\n    auto err = std::string(hdfsGetLastError());\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot delete file \") + uri.to_string() +\n        std::string(\"; \") + err));\n  }\n\n  return Status::Ok();\n}\n", "CodeBleu_score": 53.78290388673579}, {"code": "Status HDFS::remove_file(const URI& uri)  if (!uri.is_hdfs()) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"URI is not an HDFS URI: \" + uri.to_string())));\n  }\n\n  // Connect\n  hdfsFS fs = connect();\n  if (fs == nullptr) {\n    return LOG_STATUS(Status::HDFSError(\"Could not connect to HDFS\"));\n  }\n\n  // Delete file\n  int ret = hdfsDelete(fs, uri.to_path().c_str());\n  if (ret < 0) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot delete file \" + uri.to_string() + \": \" +\n                    std::string(hdfsGetLastError()))));\n  }\n\n  // Close file\n  if (hdfsCloseFile(fs, ret) < 0) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot close file \" + uri.to_string() + \": \" +\n                    std::string(hdfsGetLastError()))));\n  }\n\n  return Status::Ok();\n}\n", "CodeBleu_score": 55.54065825063314}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri)  if (uri.get_scheme() != \"hdfs\") {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"URI is not an HDFS URI: \" + uri.to_string())));\n  }\n\n  if (!uri.is_hdfs_path()) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"URI is not an HDFS path: \" + uri.to_string())));\n  }\n\n  // Connect\n  hdfsFS fs = connect();\n  if (fs == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Could not connect to HDFS backend\")));\n  }\n\n  // Check if file exists\n  int exists = hdfsExists(fs, uri.to_path().c_str());\n  if (exists == 0) {\n    return Status::Ok();\n  }\n\n  // Open file\n  hdfsFile f =\n      hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n  if (f == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Could not open file \") + uri.to_string() + \" for syncing\"));\n  }\n\n  // Flush file\n  if (hdfsFlush(fs, f)) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Could not flush file \") + uri.to_string() +\n        \" to HDFS backend: \" + std::string(hdfsGetLastError())));\n  }\n\n  // Close file\n  if (hdfsCloseFile(fs, f)) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Could not close file \") + uri.to_string() +\n        \" from HDFS backend: \" + std::string(hdfsGetLastError())));\n  }\n\n  return Status::Ok();\n}\n", "CodeBleu_score": 56.816163624943904}, {"code": "Status HDFS::sync(const URI& uri)    std::string path = uri.to_path();\n    if (path.empty()) {\n        return Status::InvalidArgument(\"path is empty\");\n    }\n    if (path[0] != '/') {\n        return Status::InvalidArgument(\"path is not absolute\");\n    }\n    hdfsFS fs = _connect();\n    if (fs == nullptr) {\n        return Status::IOError(\"failed to connect to HDFS\");\n    }\n    hdfsFile file = hdfsOpenFile(fs, path.c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n    if (file == nullptr) {\n        int errsv = errno;\n        hdfsDisconnect(fs);\n        return Status::IOError(\"failed to open file\", strerror(errsv));\n    }\n    if (hdfsFlush(fs, file) != 0) {\n        int errsv = errno;\n        hdfsCloseFile(fs, file);\n        hdfsDisconnect(fs);\n        return Status::IOError(\"failed to flush file\", strerror(errsv));\n    }\n    if (hdfsCloseFile(fs, file) != 0) {\n        int errsv = errno;\n        hdfsDisconnect(fs);\n        return Status::IOError(\"failed to close file\", strerror(errsv));\n    }\n    hdfsDisconnect(fs);\n    return Status::OK();\n}\n", "CodeBleu_score": 47.90326616205718}, {"code": "Status HDFS::sync(const URI& uri)  auto hdfs_uri = uri.to_hdfs_path();\n  hdfsFS fs = connect();\n  if (!fs) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to connect to HDFS, URI=\" + uri.to_string())));\n  }\n\n  // Check if file exists\n  int exists = hdfsExists(fs, hdfs_uri.c_str());\n  if (exists == 0) {\n    hdfsDisconnect(fs);\n    return Status::Ok();\n  }\n\n  // Open file\n  hdfsFile file = hdfsOpenFile(\n      fs, hdfs_uri.c_str(), O_WRONLY | O_APPEND, constants::max_write_bytes, 0, 0);\n  if (!file) {\n    hdfsDisconnect(fs);\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to open HDFS file, URI=\" + uri.to_string())));\n  }\n\n  // Flush file\n  if (hdfsFlush(fs, file)) {\n    hdfsCloseFile(fs, file);\n    hdfsDisconnect(fs);\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to flush HDFS file, URI=\" + uri.to_string())));\n  }\n\n  // Close file\n  if (hdfsCloseFile(fs, file)) {\n    hdfsDisconnect(fs);\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to close HDFS file, URI=\" + uri.to_string())));\n  }\n\n  // Disconnect\n  if (hdfsDisconnect(fs)) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to disconnect from HDFS, URI=\" + uri.to_string())));\n  }\n\n  return Status::Ok();\n}\n", "CodeBleu_score": 50.93474826342506}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes)  // Connect to the HDFS file system\n  hdfsFS fs = connect();\n  if (fs == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot connect to HDFS\"));\n  }\n\n  // Get the file info\n  hdfsFileInfo* file_info = hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (file_info == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot get file info\"));\n  }\n\n  // Retrieve file size\n  if (!hdfsIsDirectory(file_info->mKind)) {\n    *nbytes = static_cast<uint64_t>(file_info->mSize);\n  } else {  // Directory\n    *nbytes = 0;\n  }\n\n  // Clean up\n  hdfsFreeFileInfo(file_info, 1);\n  disconnect(fs);\n\n  return Status::Ok();\n}\n", "CodeBleu_score": 48.53428233287097}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes)  auto fs = global_state::hdfs_fs;\n  if (fs == nullptr)\n    return LOG_STATUS(Status::HDFSError(\"HDFS not initialized\"));\n\n  int ret;\n  hdfsFileInfo* file_info = hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (file_info == nullptr) {\n    ret = hdfsGetLastError();\n    std::stringstream errmsg;\n    errmsg << \"Failed to get file info \" << uri.to_string() << \" (\"\n           << strerror(errno) << \")\";\n    return LOG_STATUS(Status::HDFSError(errmsg.str()));\n  }\n\n  if (!hdfsUtils::is_file(file_info->mKind)) {\n    hdfsFreeFileInfo(file_info, 1);\n    return LOG_STATUS(\n        Status::HDFSError(\"Error getting file size; not a file\"));\n  }\n\n  *nbytes = (uint64_t)file_info->mSize;\n  hdfsFreeFileInfo(file_info, 1);\n\n  return Status::Ok();\n}\n", "CodeBleu_score": 51.82635444185916}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes)  // Connect to the HDFS file system\n  hdfsFS fs = connect();\n  if (fs == nullptr) {\n    return LOG_STATUS(Status::HDFSError(\"Cannot connect to HDFS\"));\n  }\n\n  // Get the file information\n  hdfsFileInfo* file_info = hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (file_info == nullptr) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot get file size; HDFS error: \") + strerror(errno)));\n  }\n\n  // Check if the path is a file\n  if (!file_info->mKind == kObjectKindFile) {\n    hdfsFreeFileInfo(file_info, 1);\n    return LOG_STATUS(Status::HDFSError(\"Cannot get file size; Not a file\"));\n  }\n\n  // Set the size in bytes\n  *nbytes = file_info->mSize;\n\n  // Free the file information\n  hdfsFreeFileInfo(file_info, 1);\n\n  // Disconnect from the HDFS file system\n  disconnect(fs);\n\n  // Return success\n  return Status::Ok();\n}\n", "CodeBleu_score": 49.25728343988634}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString)    String quorum = \"\";\n    String znodeParent = \"\";\n    String[] configs = hbaseCfgString.split(\",\");\n    for (String config : configs) {\n        String[] parts = config.split(\"=\");\n        if (parts.length == 2) {\n            String key = parts[0].trim();\n            String value = parts[1].trim();\n            if (key.equalsIgnoreCase(\"hbase.zookeeper.quorum\")) {\n                quorum = value;\n                if (!quorum.contains(\":\")) {\n                    quorum += \":2181\";\n                }\n            } else if (key.equalsIgnoreCase(\"zookeeper.znode.parent\")) {\n                znodeParent = value;\n            }\n        }\n    }\n    if (quorum.isEmpty()) {\n        throw new IllegalArgumentException(\"HBase configuration string must contain 'hbase.zookeeper.quorum'\");\n    }\n    if (znodeParent.isEmpty()) {\n        znodeParent = \"/hbase\";\n    }\n    return new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 32.089381315252474}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString)    String[] hbaseCfg = hbaseCfgString.split(\",\");\n    String quorum = \"\";\n    String znodeParent = \"/hbase\";\n    for (String hbaseCfgPart : hbaseCfg) {\n        String[] hbaseCfgParts = hbaseCfgPart.split(\"=\");\n        if (hbaseCfgParts.length == 2) {\n            if (hbaseCfgParts[0].equals(\"hbase.zookeeper.quorum\")) {\n                quorum = hbaseCfgParts[1];\n                if (!quorum.contains(\":\")) {\n                    quorum += \":2181\";\n                }\n            } else if (hbaseCfgParts[0].equals(\"zookeeper.znode.parent\")) {\n                znodeParent = hbaseCfgParts[1];\n            }\n        }\n    }\n    return new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 30.25929758834814}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString)    String quorum = \"\";\n    String znodeParent = \"\";\n    String[] configs = hbaseCfgString.split(\",\");\n    for (String config : configs) {\n        String[] parts = config.split(\"=\");\n        if (parts.length != 2) {\n            continue;\n        }\n        String key = parts[0].trim();\n        String value = parts[1].trim();\n        if (key.equals(\"hbase.zookeeper.quorum\")) {\n            quorum = value;\n            if (!quorum.contains(\":\")) {\n                quorum += \":2181\";\n            }\n        } else if (key.equals(\"zookeeper.znode.parent\")) {\n            znodeParent = value;\n        }\n    }\n    if (quorum.isEmpty()) {\n        throw new IllegalArgumentException(\"HBase configuration string does not contain a valid Zookeeper quorum.\");\n    }\n    if (znodeParent.isEmpty()) {\n        znodeParent = \"/hbase\";\n    }\n    return new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 32.43850915842831}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg)    try {\n        String url = cfg.getJdbcUrl();\n        String user = cfg.getUser();\n        String password = cfg.getPassword();\n        String table = cfg.getTable();\n        String namespace = cfg.getNamespace();\n        String sql = cfg.getSql();\n        String[] columns = cfg.getColumns();\n        String[] columnTypes = cfg.getColumnTypes();\n        String[] columnFormats = cfg.getColumnFormats();\n        String[] partitionKeys = cfg.getPartitionKeys();\n        String[] partitionValues = cfg.getPartitionValues();\n        String[] partitionFormats = cfg.getPartitionFormats();\n        String[] partitionTypes = cfg.getPartitionTypes();\n        String[] partitionValuesFormat = cfg.getPartitionValuesFormat();\n        String[] partitionValuesType = cfg.getPartitionValuesType();\n        String[] partitionValuesLength = cfg.getPartitionValuesLength();\n        String[] partitionValuesPrecision = cfg.getPartitionValuesPrecision();\n        String[] partitionValuesScale = cfg.getPartitionValuesScale();\n        String[] partitionValuesNullable = cfg.getPartitionValuesNullable();\n        String[] partitionValuesDefault = cfg.getPartitionValuesDefault();\n        String[] partitionValuesComment = cfg.getPartitionValuesComment();\n        String[] partitionValuesPrimaryKey = cfg.getPartitionValuesPrimaryKey();\n        String[] partitionValuesUniqueKey = cfg.getPartitionValuesUniqueKey();\n        String[] partitionValuesIndex = cfg.getPartitionValuesIndex();\n        String[] partitionValuesIndexType = cfg.getPartitionValuesIndexType();\n        String[] partitionValuesIndexComment = cfg.getPartitionValuesIndexComment();\n        String[] partitionValuesIndexName = cfg.getPartitionValuesIndexName();\n        String[] partitionValuesIndexUnique = cfg.getPartitionValuesIndexUnique();\n        String[] partitionValuesIndexPrimaryKey = cfg.getPartitionValuesIndexPrimaryKey();\n        String[] partitionValuesIndexUniqueKey = cfg.getPartitionValuesIndexUniqueKey();\n        String[] partitionValuesIndexIndex = cfg.getPartitionValuesIndexIndex();\n        String[] partitionValuesIndexIndexType = cfg.getPartitionValuesIndexIndexType();\n        String", "CodeBleu_score": 23.105445133462716}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg)    try (Connection conn = DriverManager.getConnection(cfg.getUrl(), cfg.getUsername(), cfg.getPassword()); Statement stmt = conn.createStatement(); ResultSet rs = stmt.executeQuery(String.format(\"SELECT * FROM %s LIMIT 1\", cfg.getTable()))) {\n        ResultSetMetaData metaData = rs.getMetaData();\n        int columnCount = metaData.getColumnCount();\n        for (int i = 1; i <= columnCount; i++) {\n            String columnName = metaData.getColumnName(i);\n            if (!cfg.getColumns().contains(columnName)) {\n                throw new AddaxException(String.format(\"Column %s does not exist in the target table.\", columnName));\n            }\n        }\n    } catch (SQLException e) {\n        throw new AddaxException(String.format(\"Error validating configuration for HbaseSQLWriter: %s\", e.getMessage()), e);\n    }\n}", "CodeBleu_score": 28.28070043805629}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg)    try {\n        Connection conn = DriverManager.getConnection(cfg.getUrl(), cfg.getUsername(), cfg.getPassword());\n        DatabaseMetaData metaData = conn.getMetaData();\n        ResultSet rs = metaData.getTables(null, cfg.getNamespace(), cfg.getTable(), new String[] { \"TABLE\" });\n        if (!rs.next()) {\n            throw new AddaxException(\"Table \" + cfg.getTable() + \" does not exist in namespace \" + cfg.getNamespace());\n        }\n        rs.close();\n        conn.close();\n    } catch (SQLException e) {\n        throw new AddaxException(\"Error validating HbaseSQLWriter configuration: \" + e.getMessage(), e);\n    }\n    try {\n        Connection conn = DriverManager.getConnection(cfg.getUrl(), cfg.getUsername(), cfg.getPassword());\n        DatabaseMetaData metaData = conn.getMetaData();\n        ResultSet rs = metaData.getColumns(null, cfg.getNamespace(), cfg.getTable(), null);\n        while (rs.next()) {\n            String columnName = rs.getString(\"COLUMN_NAME\");\n            if (!cfg.getColumn().contains(columnName)) {\n                throw new AddaxException(\"Column \" + columnName + \" does not exist in table \" + cfg.getTable());\n            }\n        }\n        rs.close();\n        conn.close();\n    } catch (SQLException e) {\n        throw new AddaxException(\"Error validating HbaseSQLWriter configuration: \" + e.getMessage(), e);\n    }\n}", "CodeBleu_score": 42.822506432471634}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath)    if (kerberosPrincipal != null && !kerberosPrincipal.isEmpty() && kerberosKeytabFilePath != null && !kerberosKeytabFilePath.isEmpty()) {\n        try {\n            UserGroupInformation.setConfiguration(new Configuration());\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            logger.error(\"Kerberos login error\", e);\n            throw new RuntimeException(\"Kerberos login error\", e);\n        }\n    }\n}", "CodeBleu_score": 33.698309827124845}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath)    if (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n        try {\n            UserGroupInformation.setConfiguration(new Configuration());\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            LOGGER.error(\"Kerberos login error\", e);\n            throw new RuntimeException(\"Kerberos login error\", e);\n        }\n    }\n}\n", "CodeBleu_score": 38.81879694243866}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath)    if (kerberosPrincipal != null && !kerberosPrincipal.isEmpty() && kerberosKeytabFilePath != null && !kerberosKeytabFilePath.isEmpty()) {\n        try {\n            UserGroupInformation.setConfiguration(new Configuration());\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            LOGGER.error(\"Kerberos login error\", e);\n            throw new RuntimeException(\"Kerberos login error\");\n        }\n    }\n}", "CodeBleu_score": 32.740630688323286}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException    Map<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<>();\n    ResultSetMetaData rsmd = rs.getMetaData();\n    int numColumns = rsmd.getColumnCount();\n    for (int i = 1; i <= numColumns; i++) {\n        String columnName = rsmd.getColumnLabel(i);\n        if (columnName == null) {\n            throw new SQLException(\"Column name is null\");\n        }\n        int columnType = rsmd.getColumnType(i);\n        if (columnType == Types.OTHER) {\n            columnType = rsmd.getColumnTypeName(i).equals(\"GEOMETRY\") ? Types.BINARY : Types.VARCHAR;\n        }\n        ThinClientPTable.ThinClientPColumn column = new ThinClientPTable.ThinClientPColumn(columnName, columnType);\n        colTypeMap.put(columnName, column);\n    }\n    return colTypeMap;\n}", "CodeBleu_score": 46.49233353252799}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException        Map<String, ThinClientPTable.ThinClientPColumn> cols = new LinkedHashMap<>();\n        ResultSetMetaData rsmd = rs.getMetaData();\n        for (int i = 1; i <= rsmd.getColumnCount(); i++) {\n            String colName = rsmd.getColumnLabel(i);\n            String colType = rsmd.getColumnTypeName(i);\n            if (colName == null || colType == null) {\n                throw new SQLException(\"Invalid column metadata\");\n            }\n            cols.put(colName, new ThinClientPTable.ThinClientPColumn(colType));\n        }\n        return cols;\n    }", "CodeBleu_score": 39.44801299381274}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException        Map<String, ThinClientPTable.ThinClientPColumn> map = new HashMap<>();\n        ResultSetMetaData metaData = rs.getMetaData();\n        for (int i = 1; i <= metaData.getColumnCount(); i++) {\n            String type = metaData.getColumnTypeName(i);\n            String name = metaData.getColumnLabel(i);\n            if (type == null || name == null) {\n                throw new SQLException(\"Null column type or name\");\n            }\n            map.put(name, new ThinClientPTable.ThinClientPColumn(type));\n        }\n        return map;\n    }", "CodeBleu_score": 36.83445726542258}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName)    try {\n        PhoenixConnection phoenixConn = (PhoenixConnection) conn;\n        Admin admin = phoenixConn.getHBaseAdmin();\n        if (!admin.tableExists(TableName.valueOf(tableName))) {\n            throw new SQLException(String.format(\"Table '%s' does not exist\", tableName), \"08004\", 100);\n        }\n        admin.disableTable(TableName.valueOf(tableName));\n        admin.truncateTable(TableName.valueOf(tableName), true);\n        LOG.debug(\"Truncated table '{}'\", tableName);\n    } catch (Exception e) {\n        throw new SQLException(String.format(\"Error truncating table '%s': %s\", tableName, e.getMessage()), \"08004\", 100);\n    } finally {\n        try {\n            conn.close();\n        } catch (Exception e) {\n            LOG.error(\"Error closing connection: {}\", e.getMessage());\n        }\n    }\n}", "CodeBleu_score": 39.89757095709008}, {"code": "public static void truncateTable(Connection conn, String tableName)    try {\n        PhoenixConnection phoenixConn = conn.unwrap(PhoenixConnection.class);\n        Admin admin = phoenixConn.getAdmin();\n        TableName tblName = TableName.valueOf(tableName);\n        if (admin.tableExists(tblName)) {\n            admin.disableTable(tblName);\n            admin.truncateTable(tblName, true);\n            logger.debug(\"Table {} truncated successfully\", tableName);\n        } else {\n            throw new SQLException(String.format(\"Table %s does not exist\", tableName), \"08004\");\n        }\n    } catch (SQLException e) {\n        throw new RuntimeException(e);\n    } finally {\n        try {\n            conn.unwrap(PhoenixConnection.class).getAdmin().close();\n        } catch (SQLException e) {\n            throw new RuntimeException(e);\n        }\n    }\n}", "CodeBleu_score": 45.47239170339687}, {"code": "public static void truncateTable(Connection conn, String tableName)    try {\n        PhoenixConnection phoenixConn = conn.unwrap(PhoenixConnection.class);\n        Admin admin = phoenixConn.getHBaseAdmin();\n        if (admin.tableExists(TableName.valueOf(tableName))) {\n            admin.disableTable(TableName.valueOf(tableName));\n            admin.truncateTable(TableName.valueOf(tableName), true);\n            LOG.debug(\"Table {} truncated successfully\", tableName);\n        } else {\n            throw new SQLException(String.format(\"Table %s does not exist\", tableName), \"08004\");\n        }\n    } catch (SQLException e) {\n        throw new RuntimeException(String.format(\"Error truncating table %s: %s\", tableName, e.getMessage()), e);\n    } finally {\n        if (admin != null) {\n            try {\n                admin.close();\n            } catch (IOException e) {\n                LOG.error(\"Error closing admin instance: {}\", e.getMessage());\n            }\n        }\n    }\n}", "CodeBleu_score": 49.036810571828205}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath)    if (filePath.endsWith(fileType)) {\n        logger.info(\"Adding source file: \" + filePath);\n        sourceFiles.add(filePath);\n    } else {\n        logger.error(\"Unsupported file type: \" + filePath);\n        throw new UnsupportedFileTypeException(\"Unsupported file type: \" + filePath);\n    }\n}", "CodeBleu_score": 14.990430594673759}, {"code": "private void addSourceFileByType(String filePath)    String fileType = getFileType(filePath);\n    if (fileType.equals(getFileType())) {\n        log.info(\"Adding file {} to source files list\", filePath);\n        sourceFiles.add(filePath);\n    } else {\n        log.error(\"Unsupported file type: {}\", fileType);\n        throw new UnsupportedFileTypeException(\"Unsupported file type: \" + fileType);\n    }\n}", "CodeBleu_score": 22.50152097472987}, {"code": "private void addSourceFileByType(String filePath)    if (filePath.endsWith(fileType)) {\n        log.info(\"Adding file {} to source files list\", filePath);\n        sourceFiles.add(filePath);\n    } else {\n        log.error(\"Unsupported file type: {}\", filePath);\n        throw new IllegalArgumentException(\"Unsupported file type: \" + filePath);\n    }\n}", "CodeBleu_score": 15.544805531288407}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector)        try {\n            LOG.info(\"start read sequence file:{}\", sourceSequenceFilePath);\n            FileSystem fs = FileSystem.get(new URI(sourceSequenceFilePath), readerSliceConfig);\n            Path path = new Path(sourceSequenceFilePath);\n            SequenceFile.Reader reader = new SequenceFile.Reader(fs, path, readerSliceConfig);\n            Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n            Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), readerSliceConfig);\n            while (reader.next(key, value)) {\n                if (value.toString().trim().length() > 0) {\n                    StorageReaderUtil.transportRecord(recordSender, key, value);\n                }\n            }\n            reader.close();\n            fs.close();\n        } catch (Exception e) {\n            LOG.error(\"read sequence file:{} error\", sourceSequenceFilePath, e);\n            throw new AddaxException(\"read sequence file:\" + sourceSequenceFilePath + \" error\", e);\n        }\n    }", "CodeBleu_score": 48.282813037987104}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector)        LOG.info(\"Start read sequence file : {}\", sourceSequenceFilePath);\n        try (SequenceFile.Reader reader = new SequenceFile.Reader(\n                FileSystem.get(new Configuration()), new Path(sourceSequenceFilePath), readerSliceConfig)) {\n            Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n            Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), readerSliceConfig);\n            while (reader.next(key, value)) {\n                if (value.toString().trim().length() != 0) {\n                    StorageReaderUtil.transport(key.toString(), value.toString(), recordSender, taskPluginCollector);\n                }\n            }\n        } catch (Exception e) {\n            LOG.error(\"Failed to read sequence file {}\", sourceSequenceFilePath);\n            throw new AddaxException(AddaxException.TASK_ERROR, \"Failed to read sequence file \" + sourceSequenceFilePath, e);\n        }\n    }", "CodeBleu_score": 50.67929745980335}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector)        LOG.info(\"Start read sequence file: {}\", sourceSequenceFilePath);\n        try {\n            FileSystem fs = FileSystem.get(readerSliceConfig);\n            Path path = new Path(sourceSequenceFilePath);\n            SequenceFile.Reader reader = new SequenceFile.Reader(fs, path, readerSliceConfig);\n            Text key = new Text();\n            Text value = new Text();\n            while (reader.next(key, value)) {\n                if (value.toString().trim().length() > 0) {\n                    StorageReaderUtil.transportRecord(key.toString(), value.toString(), recordSender, taskPluginCollector);\n                }\n            }\n            reader.close();\n        } catch (Exception e) {\n            LOG.error(\"Read sequence file error: {}\", sourceSequenceFilePath);\n            LOG.error(e.getMessage(), e);\n            throw new AddaxException(ErrorCode.FILE_OP_FAIL, e.getMessage(), e);\n        }\n    }", "CodeBleu_score": 54.798333175093504}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType)    try {\n        FileSystem fs = FileSystem.get(new Configuration());\n        Path path = new Path(filepath);\n        CompressionCodecFactory factory = new CompressionCodecFactory(new Configuration());\n        CompressionCodec codec = factory.getCodec(path);\n\n        if (codec != null) {\n            path = new Path(filepath + codec.getDefaultExtension());\n        }\n\n        switch (specifiedFileType.toLowerCase()) {\n            case \"orc\":\n                return new OrcFile().isOrcFile(path, fs);\n            case \"rc\":\n                return new RCFile().isRCFile(path, fs);\n            case \"sequence\":\n                return new SequenceFile().isSequenceFile(path, fs);\n            case \"parquet\":\n                return new ParquetFile().isParquetFile(path, fs);\n            case \"csv\":\n                return new CsvFile().isCsvFile(path, fs);\n            case \"text\":\n                return new TextFile().isTextFile(path, fs);\n            default:\n                return false;\n        }\n    } catch (IOException e) {\n        logger.error(\"Error while checking file type: \" + e.getMessage());\n        throw new RuntimeException(\"Error while checking file type\", e);\n    }\n}", "CodeBleu_score": 31.052138882650855}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType)    try {\n        FileSystem fs = FileSystem.get(new Configuration());\n        Path path = new Path(filepath);\n\n        if (fs.isFile(path)) {\n            CompressionCodecFactory factory = new CompressionCodecFactory(new Configuration());\n            CompressionCodec codec = factory.getCodec(path);\n            if (codec != null) {\n                filepath = path.getName() + codec.getDefaultExtension();\n            }\n        }\n\n        switch (specifiedFileType) {\n            case \"ORC\":\n                return filepath.endsWith(\".orc\");\n            case \"RC\":\n                return filepath.endsWith(\".rc\");\n            case \"Sequence\":\n                return filepath.endsWith(\".seq\");\n            case \"Parquet\":\n                return filepath.endsWith(\".parquet\");\n            case \"CSV\":\n                return filepath.endsWith(\".csv\");\n            case \"Text\":\n                return filepath.endsWith(\".txt\");\n            default:\n                return false;\n        }\n    } catch (IOException e) {\n        logger.error(\"Error occurred while checking HDFS file type: \" + e.getMessage());\n        throw new RuntimeException(\"Error occurred while checking HDFS file type.\", e);\n    }\n}", "CodeBleu_score": 30.086664282475773}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType)    try {\n        Path path = new Path(filepath);\n        FileSystem fs = FileSystem.get(new Configuration());\n        if (fs.exists(path)) {\n            String fileType = fs.getFileStatus(path).getFileType().toString();\n            if (specifiedFileType.equalsIgnoreCase(\"ORC\")) {\n                return fileType.equals(\"FILE\");\n            } else if (specifiedFileType.equalsIgnoreCase(\"RC\")) {\n                return fileType.equals(\"FILE\");\n            } else if (specifiedFileType.equalsIgnoreCase(\"Sequence\")) {\n                return fileType.equals(\"FILE\");\n            } else if (specifiedFileType.equalsIgnoreCase(\"Parquet\")) {\n                return fileType.equals(\"FILE\");\n            } else if (specifiedFileType.equalsIgnoreCase(\"CSV\")) {\n                return fileType.equals(\"FILE\");\n            } else if (specifiedFileType.equalsIgnoreCase(\"Text\")) {\n                return fileType.equals(\"FILE\");\n            } else {\n                return false;\n            }\n        } else {\n            throw new Exception(\"File does not exist in HDFS\");\n        }\n    } catch (Exception e) {\n        log.error(\"Error while checking HDFS file type: \" + e.getMessage());\n        throw new RuntimeException(\"Error while checking HDFS file type\", e);\n    }\n}", "CodeBleu_score": 39.28746738391142}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection)    if (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new RuntimeException(\"Error closing connection\", e);\n        }\n    }\n}", "CodeBleu_score": 47.643725225563486}, {"code": "public static void closeConnection(Connection hConnection)    try {\n        if (hConnection != null) {\n            hConnection.close();\n        }\n    } catch (IOException e) {\n        throw new HBaseException(HBaseErrorCode.HBASE_CONNECTION_CLOSE_ERROR, e);\n    }\n}", "CodeBleu_score": 55.823364202168726}, {"code": "public static void closeConnection(Connection hConnection)    if (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new CustomException(\"Error closing HBase connection\", 500);\n        }\n    }\n}", "CodeBleu_score": 43.373847869041406}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin)    if (admin != null) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw new RuntimeException(ErrorCode.CLOSE_ADMIN_FAILURE.getCode(), ErrorCode.CLOSE_ADMIN_FAILURE.getDescription(), e);\n        }\n    }\n}", "CodeBleu_score": 55.99645636834485}, {"code": "public static void closeAdmin(Admin admin)    try {\n        if (admin != null) {\n            admin.close();\n        }\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 44.188733191754295}, {"code": "public static void closeAdmin(Admin admin)    if (admin != null) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw new RuntimeException(ErrorCode.HBASE_ADMIN_CLOSE_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 52.204059736924236}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception        String rowKey = Bytes.toString(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength());\n        String family = Bytes.toString(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength());\n        String qualifier = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());\n        String value = Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());\n        long timestamp = cell.getTimestamp();\n        String rowKeyType = rowKeyMappings.get(family);\n        String columnValueType = columnValueMappings.get(family);\n        String rowKeyFormat = rowKeyFormats.get(family);\n        String columnValueFormat = columnValueFormats.get(family);\n        if (rowKeyType != null) {\n            record.addColumn(rowKey, rowKeyType, rowKeyFormat, rowKey);\n        }\n        if (columnValueType != null) {\n            record.addColumn(family + \":\" + qualifier, columnValueType, columnValueFormat, value);\n        }\n        record.addColumn(\"timestamp\", \"long\", \"%d\", timestamp);\n    }", "CodeBleu_score": 35.059378017980144}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception    // Extract the row key, timestamp, column family, qualifier, and value from the cell\n    String rowKey = Bytes.toString(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength());\n    long timestamp = cell.getTimestamp();\n    String columnFamily = Bytes.toString(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength());\n    String qualifier = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());\n    String value = Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());\n\n    // Determine the types and formats for the row key and column value based on predefined mappings\n    // Convert the extracted data to the appropriate types and add them as columns to the record\n    // Add the row key, family and qualifier name, timestamp, and column value as columns to the record\n    record.addColumn(new StringColumn(\"rowkey\", rowKey));\n    record.addColumn(new StringColumn(\"family\", columnFamily));\n    record.addColumn(new StringColumn(\"qualifier\", qualifier));\n    record.addColumn(new LongColumn(\"timestamp\", timestamp));\n    record.addColumn(new StringColumn(\"value\", value));\n}", "CodeBleu_score": 24.86896452553613}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception\n    // Extract the row key, timestamp, column family, qualifier, and value\n    // from the cell\n    byte[] row = cell.getRowArray();\n    long timestamp = cell.getTimestamp();\n    byte[] family = cell.getFamilyArray();\n    byte[] qualifier = cell.getQualifierArray();\n    byte[] value = cell.getValueArray();\n\n    // Determine the types and formats for the row key and column value based\n    // on predefined mappings\n    String rowKeyType = rowKeyMappings.get(new String(row));\n    String columnValueType = columnValueMappings.get(new String(family) + \":\" + new String(qualifier));\n\n    // Convert the extracted data to the appropriate types and add them as\n    // columns to the record\n    record.addColumn(new Column(rowKeyType, new String(row)));\n    record.addColumn(new Column(columnValueType, new String(family) + \":\" + new String(qualifier)));\n    record.addColumn(new Column(columnValueType, Long.toString(timestamp)));\n    record.addColumn(new Column(columnValueType, new String(value)));\n}\n", "CodeBleu_score": 27.74227931142892}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration)  String startRowkey = configuration.get(Constants.USER_START_ROWKEY);\n  if (StringUtils.isBlank(startRowkey)) {\n    return new byte[0];\n  }\n  boolean isBinary = configuration.getBoolean(Constants.USER_START_ROWKEY_BINARY, false);\n  if (isBinary) {\n    return Bytes.toBytesBinary(startRowkey);\n  }\n  else {\n    return Bytes.toBytes(startRowkey);\n  }\n}", "CodeBleu_score": 56.735643744397436}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration)  String startRowkey = configuration.get(Constants.USER_START_ROWKEY);\n  if (startRowkey == null || startRowkey.trim().isEmpty()) {\n    return new byte[0];\n  }\n  if (configuration.getBoolean(Constants.USER_START_ROWKEY_BINARY, false)) {\n    return Bytes.toBytesBinary(startRowkey);\n  }\n  return Bytes.toBytes(startRowkey);\n}", "CodeBleu_score": 42.641153240150345}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration)  String startRowKey = configuration.get(Constants.USER_START_ROWKEY);\n  if (startRowKey == null || startRowKey.length() == 0) {\n    return new byte[0];\n  }\n  if (configuration.getBoolean(Constants.USER_START_ROWKEY_IS_BINARY, false)) {\n    return Bytes.toBytesBinary(startRowKey);\n  }\n  return Bytes.toBytes(startRowKey);\n}", "CodeBleu_score": 40.82577453900102}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration)  String startRowkey = configuration.get(Constants.INNER_START_ROWKEY);\n  if (startRowkey == null || startRowkey.length() == 0) {\n    return new byte[0];\n  }\n  return Bytes.toBytesBinary(startRowkey);\n}", "CodeBleu_score": 57.42802931773806}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration)  String startRowkey = configuration.get(Constants.INNER_START_ROWKEY);\n  if (startRowkey == null) {\n    return new byte[0];\n  }\n  return Bytes.toBytes(startRowkey);\n}", "CodeBleu_score": 50.79369301865063}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration)  String startRowkey = configuration.get(HConstants.STARTROWKEY);\n  if (startRowkey.length() == 0) {\n    return new byte[0];\n  }\n  return Bytes.toBytesBinary(startRowkey);\n}", "CodeBleu_score": 56.58735123970076}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record)    this.key = UUID.fromString(record.key());\n    this.headers = new TbQueueMsgHeaders();\n    record.headers().forEach(header -> headers.put(header.key(), new String(header.value())));\n    this.data = record.value();\n}\n", "CodeBleu_score": 51.89553202136617}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record)    this.key = UUID.fromString(record.key());\n    this.headers = new TbQueueMsgHeaders();\n    for (Header header : record.headers()) {\n        headers.put(header.key(), header.value());\n    }\n    this.data = record.value();\n}", "CodeBleu_score": 53.494682196809904}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record)        this.key = UUID.fromString(record.key());\n        this.headers = new TbQueueMsgHeaders();\n        for (Header header : record.headers()) {\n            this.headers.put(header.key(), header.value());\n        }\n        this.data = record.value();\n    }\n", "CodeBleu_score": 51.5830520765918}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer()    KafkaSettings kafkaSettings = tbTransportNotificationsSettings.getKafka();\n    String clientId = tbTransportNotificationsSettings.getServiceId() + \"-\" + tbTransportNotificationsSettings.getKafka().getClientId();\n    String defaultTopic = tbTransportNotificationsSettings.getKafka().getDefaultTopic();\n    KafkaProducerTemplate<String, byte[]> producerTemplate = new KafkaProducerTemplate<>(kafkaSettings.getBootstrapServers(),\n            kafkaSettings.getKeySerializerClass(), kafkaSettings.getValueSerializerClass(), clientId,\n            kafkaSettings.getProperties());\n    TbQueueAdmin admin = new TbQueueAdmin(kafkaSettings.getBootstrapServers(), kafkaSettings.getProperties());\n    TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbQueueKafkaProducer<>(defaultTopic, producerTemplate, admin);\n    return producer;\n}", "CodeBleu_score": 37.65353625921446}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer()    TbKafkaSettings kafkaSettings = tbTransportNotificationSettings.getKafkaSettings();\n    String clientId = tbTransportNotificationSettings.getServiceId();\n    String topicName = tbTransportNotificationSettings.getTopicName();\n    TbKafkaTemplate<String, byte[]> kafkaTemplate = new TbKafkaTemplate<>(kafkaSettings, clientId);\n    TbKafkaAdmin admin = new TbKafkaAdmin(kafkaSettings);\n    return new TbQueueProducer<>(kafkaTemplate, admin, topicName, new TbProtoSerializer<>(), new TbProtoDeserializer<>());\n}", "CodeBleu_score": 40.948869493613}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer()    KafkaProducerSettings<String, byte[]> settings = KafkaProducerSettings.create(kafkaSettings.getBootstrapServers())\n            .withProperties(kafkaSettings.getDefaultProducerPropsMap())\n            .withClientId(serviceId)\n            .withKeySerializer(StringSerializer.class)\n            .withValueSerializer(ByteArraySerializer.class);\n    TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbQueueProducer<>(settings);\n    producer.setDefaultTopic(transportNotificationSettings.getTopic());\n    producer.setAdmin(kafkaAdmin);\n    return producer;\n}", "CodeBleu_score": 40.89365331164702}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer()    TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate = new TbKafkaConsumerTemplate<>(\n            kafkaSettings.getBootstrapServers(),\n            kafkaSettings.getTopicToCoreNotificationsMsg(),\n            kafkaSettings.getClientId(),\n            kafkaSettings.getGroupId());\n    consumerTemplate.setMessageDecoder(new TbKafkaProtoDecoder<>(ToCoreNotificationMsg.parser()));\n    TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> consumer = new TbQueueConsumer<>(consumerTemplate);\n    consumer.setAdmin(kafkaAdminService);\n    consumer.setStatisticsService(kafkaStatisticsService);\n    return consumer;\n}", "CodeBleu_score": 36.013451019623034}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer()    TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate = new TbKafkaConsumerTemplate<>(kafkaSettings,\n            kafkaSettings.getToCoreNotificationsTopic(),\n            kafkaSettings.getToCoreNotificationsConsumerClientId(),\n            kafkaSettings.getToCoreNotificationsConsumerGroupId());\n    consumerTemplate.setMessageDecoder(new TbProtoQueueMsgDecoder<>(ToCoreNotificationMsg.class));\n    TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> consumer = consumerTemplate.build();\n    consumer.setAdmin(kafkaAdminService);\n    consumer.setStatisticsService(statisticsService);\n    return consumer;\n}\n", "CodeBleu_score": 36.45410147335944}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer()    TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate = new TbKafkaConsumerTemplate<>(kafkaConsumerSettings);\n    TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> consumer = consumerTemplate.createConsumer(TbProtoQueueMsg.class, toCoreNotificationsMsgTopic,\n            \"tb-core-consumer\", \"tb-core-consumer-group\");\n    consumer.setMessageDecoder(new ProtobufMsgDecoder<>(ToCoreNotificationMsg.class));\n    consumer.configure(admin, statisticsService);\n    return consumer;\n}\n", "CodeBleu_score": 23.9070870819895}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames)    if (!topicNames.isEmpty()) {\n        for (String topicName : topicNames) {\n            if (!this.topicExists(topicName)) {\n                this.createTopic(topicName);\n            }\n        }\n        this.subscriber.subscribe(topicNames);\n    } else {\n        this.logger.info(\"No topics provided. Unsubscribing from all topics.\");\n        this.subscriber.unsubscribe();\n    }\n}", "CodeBleu_score": 52.39765251982992}, {"code": "protected void doSubscribe(List<String> topicNames)    if (!topicNames.isEmpty()) {\n        // create topics if they don't exist\n        topicNames.forEach(topicName -> {\n            try {\n                adminClient.createTopics(Collections.singletonList(new NewTopic(topicName, 1, (short) 1)));\n            } catch (Exception e) {\n                // topic probably already exists\n            }\n        });\n        consumer.subscribe(topicNames);\n    } else {\n        logger.info(\"No topics provided. Unsubscribing consumer from all topics.\");\n        consumer.unsubscribe();\n    }\n}", "CodeBleu_score": 60.82596874696754}, {"code": "protected void doSubscribe(List<String> topicNames)    if (topicNames != null && !topicNames.isEmpty()) {\n        for (String topicName : topicNames) {\n            ensureTopicExists(topicName);\n        }\n        logger.info(\"Subscribing to topics: \" + topicNames);\n        consumer.subscribe(topicNames);\n    } else {\n        logger.info(\"No topics provided. Unsubscribing from all topics.\");\n        consumer.unsubscribe();\n    }\n}", "CodeBleu_score": 60.088256052729136}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis)    Stopwatch stopwatch = Stopwatch.createStarted();\n    log.info(\"Polling records from topic {} for {} ms\", topic, durationInMillis);\n    ConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\n    stopwatch.stop();\n    log.info(\"Polled {} records from topic {} in {} ms\", records.count(), topic, stopwatch.elapsed(TimeUnit.MILLISECONDS));\n    if (records.isEmpty()) {\n        return Collections.emptyList();\n    }\n    return records.records(topic).stream().collect(Collectors.toList());\n}\n", "CodeBleu_score": 54.86188162350152}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis)    Stopwatch stopwatch = Stopwatch.createStarted();\n    LOG.debug(\"Polling topic {} for {} ms\", topic, durationInMillis);\n    ConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\n    stopwatch.stop();\n    LOG.debug(\"Polled topic {} in {} ms\", topic, stopwatch.elapsed(TimeUnit.MILLISECONDS));\n    if (records.isEmpty()) {\n        return Collections.emptyList();\n    }\n    return records.records(topic).stream()\n            .map(record -> new ConsumerRecord<>(record.topic(), record.partition(), record.offset(), record.key(), record.value()))\n            .collect(Collectors.toList());\n}\n", "CodeBleu_score": 56.354771441124775}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis)    Stopwatch stopwatch = Stopwatch.createStarted();\n    LOG.info(\"Polling records from topic {} for {} ms\", topic, durationInMillis);\n    ConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\n    stopwatch.stop();\n    LOG.info(\"Polled {} records from topic {} for {} ms\", records.count(), topic, stopwatch.elapsed(TimeUnit.MILLISECONDS));\n    if (records.isEmpty()) {\n        return Collections.emptyList();\n    } else {\n        return records.records(topic).stream().collect(Collectors.toList());\n    }\n}", "CodeBleu_score": 56.926027856306135}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg)  // Get the topic and key patterns from the configuration\n  String topicPattern = config.getString(\"topic\");\n  String keyPattern = config.getString(\"key\");\n\n  // Determine the topic and key based on the patterns and the message\n  String topic = evaluate(topicPattern, msg);\n  String key = evaluate(keyPattern, msg);\n\n  // Execute an asynchronous task to publish the message to Kafka\n  try {\n    asyncTaskExecutor.execute(\n        () -> {\n          try {\n            // Publish the message to Kafka\n            kafkaTemplate.send(topic, key, msg.getData());\n          } catch (Exception e) {\n            // Log the failure and notify the context\n            log.error(\"Failed to publish message to Kafka\", e);\n            ctx.tellFailure(msg, e);\n          }\n        });\n  } catch (Exception e) {\n    // Log the failure and notify the context\n    log.error(\"Failed to execute async task\", e);\n    ctx.tellFailure(msg, e);\n  }\n}\n", "CodeBleu_score": 38.91676237311914}, {"code": "public void onMsg(TbContext ctx, TbMsg msg)    try {\n        String topic = ctx.getNode().getMetaData().getJson().getString(TOPIC_KEY);\n        String key = ctx.getNode().getMetaData().getJson().getString(KEY_KEY);\n        if (topic == null || topic.isEmpty()) {\n            throw new RuntimeException(\"Topic is not defined in node meta data\");\n        }\n        if (key == null || key.isEmpty()) {\n            throw new RuntimeException(\"Key is not defined in node meta data\");\n        }\n        String topicPattern = ctx.getNode().getMetaData().getJson().getString(TOPIC_PATTERN_KEY);\n        String keyPattern = ctx.getNode().getMetaData().getJson().getString(KEY_PATTERN_KEY);\n        if (topicPattern != null && !topicPattern.isEmpty()) {\n            topic = ctx.getNode().getMetaData().getJson().getString(TOPIC_KEY);\n        }\n        if (keyPattern != null && !keyPattern.isEmpty()) {\n            key = ctx.getNode().getMetaData().getJson().getString(KEY_KEY);\n        }\n        String payload = msg.getData();\n        if (payload == null || payload.isEmpty()) {\n            throw new RuntimeException(\"Message is not defined in node meta data\");\n        }\n        String payloadPattern = ctx.getNode().getMetaData().getJson().getString(PAYLOAD_PATTERN_KEY);\n        if (payloadPattern != null && !payloadPattern.isEmpty()) {\n            payload = ctx.getNode().getMetaData().getJson().getString(PAYLOAD_KEY);\n        }\n        try {\n            kafkaTemplate.send(topic, key, payload).get();\n        } catch (Exception e) {\n            throw new RuntimeException(\"Failed to send message to Kafka\", e);\n        }\n    } catch (Exception e) {\n        log.error(\"Failed to process message\", e);\n        ctx.reportError(e);\n    }\n}", "CodeBleu_score": 35.70934195865198}, {"code": "public void onMsg(TbContext ctx, TbMsg msg)    try {\n        String topicPattern = config.get(TOPIC_PATTERN_CONFIG_PARAM);\n        String keyPattern = config.get(KEY_PATTERN_CONFIG_PARAM);\n        if (topicPattern == null || keyPattern == null) {\n            log.error(\"Failed to publish message to Kafka due to missing configuration\");\n            ctx.tellFailure(msg, new RuntimeException(\"Failed to publish message to Kafka due to missing configuration\"));\n            return;\n        }\n        String topic = ctx.jsEval(topicPattern, msg.getData(), msg.getMetaData());\n        String key = ctx.jsEval(keyPattern, msg.getData(), msg.getMetaData());\n        log.debug(\"[{}] Publishing message to Kafka topic [{}] with key [{}]\", ctx.getSelf().getFullId(), topic, key);\n        ctx.getSelf().tell(new PublishToKafkaMsg(topic, key, msg), ctx.getSelf());\n    } catch (Exception e) {\n        log.error(\"Failed to publish message to Kafka\", e);\n        ctx.tellFailure(msg, e);\n    }\n}", "CodeBleu_score": 41.67003734959507}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key)    try {\n        if (metadataHeadersEnabled) {\n            Headers headers = new RecordHeaders();\n            msg.getMetaData().forEach((k, v) -> headers.add(k, v.getBytes()));\n            kafkaTemplate.send(topic, key, msg.getData(), headers).addCallback(new ListenableFutureCallback<>() {\n                @Override\n                public void onSuccess(SendResult<String, byte[]> result) {\n                    processRecord(ctx, msg, result);\n                }\n\n                @Override\n                public void onFailure(Throwable ex) {\n                    processFailure(ctx, msg, ex);\n                }\n            });\n        } else {\n            kafkaTemplate.send(topic, key, msg.getData()).addCallback(new ListenableFutureCallback<>() {\n                @Override\n                public void onSuccess(SendResult<String, byte[]> result) {\n                    processRecord(ctx, msg, result);\n                }\n\n                @Override\n                public void onFailure(Throwable ex) {\n                    processFailure(ctx, msg, ex);\n                }\n            });\n        }\n    } catch (Exception e) {\n        log.debug(\"[{}] Failed to publish message: {}\", ctx.getId(), msg);\n        throw e;\n    }\n}", "CodeBleu_score": 43.883397727165494}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key)    try {\n        if (addMetadataAsHeaders) {\n            Headers headers = new RecordHeaders();\n            msg.getMetaData().forEach((k, v) -> headers.add(k, v.getBytes()));\n            kafkaTemplate.send(topic, key, msg.getData(), headers).addCallback(new ListenableFutureCallback<SendResult<String, byte[]>>() {\n                @Override\n                public void onSuccess(SendResult<String, byte[]> result) {\n                    onSuccess(ctx, msg, result);\n                }\n\n                @Override\n                public void onFailure(Throwable ex) {\n                    onFailure(ctx, msg, ex);\n                }\n            });\n        } else {\n            kafkaTemplate.send(topic, key, msg.getData()).addCallback(new ListenableFutureCallback<SendResult<String, byte[]>>() {\n                @Override\n                public void onSuccess(SendResult<String, byte[]> result) {\n                    onSuccess(ctx, msg, result);\n                }\n\n                @Override\n                public void onFailure(Throwable ex) {\n                    onFailure(ctx, msg, ex);\n                }\n            });\n        }\n    } catch (Exception e) {\n        log.debug(\"[{}] Failed to publish message: {}\", ctx.getId(), msg);\n        throw e;\n    }\n}\n", "CodeBleu_score": 41.53099012044195}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key)    if (metadata.isEmpty()) {\n        try {\n            producer.send(new ProducerRecord<>(topic, key, msg.getData()), (metadata, exception) -> processRecord(ctx, msg, metadata, exception));\n        } catch (Exception e) {\n            log.debug(\"[{}] Failed to publish message: {}\", ctx.getId(), msg);\n        }\n    } else {\n        try {\n            Headers headers = new RecordHeaders();\n            for (Map.Entry<String, String> entry : msg.getMetaData().entrySet()) {\n                headers.add(entry.getKey(), entry.getValue().getBytes(StandardCharsets.UTF_8));\n            }\n            producer.send(new ProducerRecord<>(topic, null, key, msg.getData(), headers), (metadata, exception) -> processRecord(ctx, msg, metadata, exception));\n        } catch (Exception e) {\n            log.debug(\"[{}] Failed to publish message: {}\", ctx.getId(), msg);\n        }\n    }\n}", "CodeBleu_score": 62.77550633717086}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy()    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            logger.error(\"Failed to close Kafka producer\", e);\n        }\n    }\n}", "CodeBleu_score": 67.85682595963371}, {"code": "public void destroy()    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            log.error(\"Failed to close Kafka producer\", e);\n        }\n    }\n}", "CodeBleu_score": 70.93923011541202}, {"code": "public void destroy()    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            logger.error(\"Failed to close Kafka producer\", e);\n        }\n    }\n}", "CodeBleu_score": 67.85682595963371}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer()    KafkaProducerTemplateBuilder<String, TbProtoQueueMsg<ToRuleEngineMsg>> builder =\n            new KafkaProducerTemplateBuilder<>(kafkaSettings,\n                    serviceInfoProvider.getServiceId(),\n                    ruleEngineMsgTopic,\n                    admin);\n    return builder.build();\n}\n", "CodeBleu_score": 35.41466494569027}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer()    KafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> builder = new KafkaProducerTemplateBuilder<>(\n            KafkaSettings.builder()\n                    .bootstrapServers(kafkaSettings.getBootstrapServers())\n                    .acks(kafkaSettings.getAcks())\n                    .retries(kafkaSettings.getRetries())\n                    .batchSize(kafkaSettings.getBatchSize())\n                    .lingerMs(kafkaSettings.getLingerMs())\n                    .bufferMemory(kafkaSettings.getBufferMemory())\n                    .build(),\n            KafkaProducerFactory.STRING_KEY_JSON_VALUE,\n            serviceInfoProvider.getServiceId(),\n            ruleEngineMsgTopic,\n            admin);\n    return builder.build();\n}", "CodeBleu_score": 35.26314850285047}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer()    KafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> builder = new KafkaProducerTemplateBuilder<>();\n    builder.setKafkaSettings(kafkaSettings);\n    builder.setClientId(serviceInfoProvider.getServiceInfo().getId());\n    builder.setDefaultTopic(ruleEngineQueueName);\n    builder.setAdmin(kafkaAdmin);\n    return builder.build();\n}\n", "CodeBleu_score": 38.97678217416786}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling()    // Set a timeout duration based on the Kafka response timeout configuration\n    Duration timeoutDuration = Duration.ofMillis(kafkaProperties.getConsumer().getMetadataMaxAgeMs());\n\n    // Schedule a task with a fixed delay\n    scheduledExecutorService.scheduleWithFixedDelay(() -> {\n        try {\n            // Check if statistics printing is required\n            if (isPrintingRequired()) {\n                // Iterate over each monitored consumer group\n                for (String groupId : monitoredConsumerGroups) {\n                    // Retrieve group offsets and end offsets for the group\n                    Map<TopicPartition, Long> groupOffsets = getGroupOffsets(groupId);\n                    Map<TopicPartition, Long> endOffsets = getEndOffsets(groupId);\n\n                    // Identify topics with lag\n                    List<String> laggingTopics = findLaggingTopics(groupOffsets, endOffsets);\n\n                    // Log details of lagging topics\n                    logLaggingTopics(groupId, laggingTopics);\n                }\n            }\n        } catch (Exception e) {\n            // Log a warning with the group ID and error message\n            LOGGER.warn(\"Failed to log consumer group statistics for groupId: {}\", groupId, e);\n\n            // Log a detailed error trace\n            LOGGER.error(\"Failed to log consumer group statistics for groupId: {}\", groupId, e);\n        }\n    }, 0, timeoutDuration.toMillis(), TimeUnit.MILLISECONDS);\n}\n", "CodeBleu_score": 30.032482122636385}, {"code": "private void startLogScheduling()  long timeout = kafkaResponseTimeout.toMillis();\n  ScheduledExecutorService scheduler = Executors.newSingleThreadScheduledExecutor();\n  scheduler.scheduleWithFixedDelay(() -> {\n    try {\n      if (logScheduling.get()) {\n        for (String groupId : monitoredGroups) {\n          Map<TopicPartition, Long> groupOffsets = getGroupOffsets(groupId);\n          Map<String, TopicPartitionInfo> topicPartitionInfoMap = getTopicPartitionInfoMap(groupId);\n          for (TopicPartition topicPartition : groupOffsets.keySet()) {\n            String topic = topicPartition.topic();\n            TopicPartitionInfo topicPartitionInfo = topicPartitionInfoMap.get(topic);\n            if (topicPartitionInfo == null) {\n              continue;\n            }\n            long groupOffset = groupOffsets.get(topicPartition);\n            long endOffset = topicPartitionInfo.getEndOffset();\n            if (groupOffset < endOffset) {\n              log.warn(\"Group: {}, Topic: {}, Partition: {}, Lag: {}\", groupId, topic, topicPartition.partition(), endOffset - groupOffset);\n            }\n          }\n        }\n      }\n    } catch (Exception e) {\n      log.warn(\"Error while logging Kafka consumer group statistics for group: {}\", groupId, e);\n    }\n  }, 0, timeout, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 33.89145039040306}, {"code": "private void startLogScheduling()    // Set the timeout duration based on the Kafka response timeout configuration\n    Duration timeout = Duration.ofMillis(kafkaProperties.getResponseTimeoutMs());\n    // Schedule a task with a fixed delay\n    scheduledExecutorService.scheduleWithFixedDelay(() -> {\n        // Check if statistics printing is required\n        if (log.isInfoEnabled()) {\n            // Iterate over each monitored consumer group\n            for (String groupId : groupIds) {\n                try {\n                    // Retrieve group offsets and end offsets for the consumer group\n                    Map<TopicPartition, OffsetAndMetadata> groupOffsets = getGroupOffsets(groupId);\n                    Map<TopicPartition, Long> endOffsets = getEndOffsets(groupId);\n                    // Identify topics with lag\n                    List<String> laggingTopics = findLaggingTopics(groupOffsets, endOffsets);\n                    // Log the details of lagging topics\n                    logLaggingTopics(groupId, laggingTopics);\n                } catch (Exception e) {\n                    // Log a warning with the group ID and error message\n                    log.warn(\"Error while retrieving offsets for group {}: {}\", groupId, e.getMessage());\n                    // Log a detailed error trace\n                    log.error(\"Error while retrieving offsets for group {}\", groupId, e);\n                }\n            }\n        }\n    }, 0, kafkaProperties.getResponseTimeoutMs(), TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 34.10899110016137}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps()    Properties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n    return props;\n}\n", "CodeBleu_score": 85.36885561534966}, {"code": "protected Properties toAdminProps()    Properties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    props.put(AdminClientConfig.RETRIES_CONFIG, 0);\n    return props;\n}\n", "CodeBleu_score": 80.16263528452218}, {"code": "protected Properties toAdminProps()    Properties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n    return props;\n}\n", "CodeBleu_score": 85.36885561534966}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group)    MetricEvent event = new MetricEvent(metricName, group.getScopedName(), group.getTags());\n    if (metric instanceof Counter) {\n        counters.add(metric, event);\n    } else if (metric instanceof Gauge) {\n        gauges.add(metric, event);\n    } else if (metric instanceof Histogram) {\n        histograms.add(metric, event);\n    } else if (metric instanceof Meter) {\n        meters.add(metric, event);\n    } else {\n        logger.warn(\"Metric type {} is not supported\", metric.getClass().getName());\n    }\n}", "CodeBleu_score": 51.03064389139054}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group)    String name = MetricRegistry.name(group.getTypePrefix(), group.getName(), metricName);\n    MetricEvent event = new MetricEvent(name, group.getTags());\n    if (metric instanceof Counter) {\n        counters.add((Counter) metric, event);\n    } else if (metric instanceof Gauge) {\n        gauges.add((Gauge) metric, event);\n    } else if (metric instanceof Histogram) {\n        histograms.add((Histogram) metric, event);\n    } else if (metric instanceof Meter) {\n        meters.add((Meter) metric, event);\n    } else {\n        logger.warn(\"Metric type {} is not supported.\", metric.getClass());\n    }\n}", "CodeBleu_score": 60.60605578727214}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group)    MetricEvent event = new MetricEvent(metricName, group.getScopedName(), group.getTags());\n    if (metric instanceof Counter) {\n        counters.add(metric, event);\n    } else if (metric instanceof Gauge) {\n        gauges.add(metric, event);\n    } else if (metric instanceof Histogram) {\n        histograms.add(metric, event);\n    } else if (metric instanceof Meter) {\n        meters.add(metric, event);\n    } else {\n        logger.warn(\"The metric type {} is not supported\", metric.getClass().getName());\n    }\n}", "CodeBleu_score": 51.26564364707929}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge)    Number value = gauge.getValue();\n    if (metricEvent.hasFields()) {\n        metricEvent.addField(field, value instanceof Number ? (Number) value : value.toString());\n    } else {\n        metricEvent.setFields(Collections.singletonMap(field, value instanceof Number ? (Number) value : value.toString()));\n    }\n    return metricEvent;\n}", "CodeBleu_score": 29.492594624678002}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge)    Object value = gauge.getValue();\n    if (metricEvent.hasFields()) {\n        Map<String, Object> fields = metricEvent.getFields();\n        if (value instanceof Number) {\n            fields.put(field, ((Number) value).doubleValue());\n        } else {\n            fields.put(field, value.toString());\n        }\n    } else {\n        Map<String, Object> fields = new HashMap<>();\n        if (value instanceof Number) {\n            fields.put(field, ((Number) value).doubleValue());\n        } else {\n            fields.put(field, value.toString());\n        }\n        metricEvent.setFields(fields);\n    }\n    return metricEvent;\n}", "CodeBleu_score": 58.96685433149924}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge)    Object value = gauge.getValue();\n    if (value instanceof Number) {\n        Number number = (Number) value;\n        metricEvent.addField(field, number);\n    } else if (value instanceof Boolean) {\n        Boolean bool = (Boolean) value;\n        metricEvent.addField(field, bool);\n    } else if (value instanceof String) {\n        String string = (String) value;\n        metricEvent.addField(field, string);\n    } else {\n        metricEvent.addField(field, value.toString());\n    }\n    return metricEvent;\n}", "CodeBleu_score": 45.46875890835577}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge)    String[] kafkaLagMetrics = gauge.getValue().toString().split(\",\");\n    String currentOffsets = kafkaLagMetrics[0];\n    String dataTimestamp = kafkaLagMetrics[1];\n    String committedOffsets = kafkaLagMetrics[2];\n    if (metricEvent.getKafkaLagTimes().containsKey(currentOffsets + dataTimestamp + committedOffsets)) {\n        return null;\n    }\n    metricEvent.getKafkaLagTimes().put(currentOffsets + dataTimestamp + committedOffsets, timestamp);\n    metricEvent.setTimestamp(timestamp);\n    metricEvent.setCurrentOffsets(currentOffsets);\n    metricEvent.setDataTimestamp(dataTimestamp);\n    metricEvent.setCommittedOffsets(committedOffsets);\n    return metricEvent;\n}", "CodeBleu_score": 31.301529057492118}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge)    String[] split = gauge.getValue().toString().split(\":\");\n    String[] currentOffsets = split[0].split(\",\");\n    String[] committedOffsets = split[1].split(\",\");\n    String[] dataTimestamp = split[2].split(\",\");\n    String[] currentOffsetsSplit = currentOffsets[0].split(\"=\");\n    String[] committedOffsetsSplit = committedOffsets[0].split(\"=\");\n    String[] dataTimestampSplit = dataTimestamp[0].split(\"=\");\n    long currentOffset = Long.parseLong(currentOffsetsSplit[1]);\n    long committedOffset = Long.parseLong(committedOffsetsSplit[1]);\n    long dataTimestampValue = Long.parseLong(dataTimestampSplit[1]);\n    String kafkaLagKey = currentOffsetsSplit[0] + \":\" + committedOffsetsSplit[0] + \":\" + dataTimestampSplit[0];\n    Long kafkaLagTime = kafkaLagTimes.get(kafkaLagKey);\n    if (kafkaLagTime == null || kafkaLagTime != dataTimestampValue) {\n        kafkaLagTimes.put(kafkaLagKey, dataTimestampValue);\n        metricEvent.setCurrentOffset(currentOffset);\n        metricEvent.setCommittedOffset(committedOffset);\n        metricEvent.setDataTimestamp(dataTimestampValue);\n        metricEvent.setTimestamp(timestamp);\n    }\n    return metricEvent;\n}", "CodeBleu_score": 35.57487305152712}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge)    String[] parts = gauge.getValue().toString().split(\",\");\n    String currentOffsets = parts[0].split(\"=\")[1];\n    String dataTimestamp = parts[1].split(\"=\")[1];\n    String committedOffsets = parts[2].split(\"=\")[1];\n    if (!kafkaLagTimes.containsKey(currentOffsets)) {\n        kafkaLagTimes.put(currentOffsets, timestamp);\n        metricEvent.setKafkaLagTimestamp(timestamp);\n    }\n    metricEvent.setCurrentOffsets(currentOffsets);\n    metricEvent.setDataTimestamp(dataTimestamp);\n    metricEvent.setCommittedOffsets(committedOffsets);\n    metricEvent.setTimestamp(timestamp);\n    return metricEvent;\n}", "CodeBleu_score": 32.41544504624477}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException  Properties props = new Properties();\n  props.setProperty(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, env.getConfig().get(KAFKA_BOOTSTRAP_SERVERS));\n  props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, env.getConfig().get(KAFKA_GROUP_ID));\n  props.setProperty(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, env.getConfig().get(KAFKA_KEY_DESERIALIZER));\n  props.setProperty(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, env.getConfig().get(KAFKA_VALUE_DESERIALIZER));\n  props.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, env.getConfig().get(KAFKA_AUTO_OFFSET_RESET));\n\n  FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), props);\n\n  if (time != null) {\n    consumer.setStartFromTimestamp(time);\n  }\n\n  env.addSource(consumer).name(\"Kafka Source\").uid(\"kafka-source-\" + topic);\n  return env.addSource(consumer).name(\"Kafka Source\").uid(\"kafka-source-\" + topic);\n}", "CodeBleu_score": 43.556325215806766}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException    Properties properties = new Properties();\n    properties.setProperty(\"bootstrap.servers\", env.getConfig().getGlobalJobParameters().toMap().get(\"kafka.bootstrap.servers\"));\n    properties.setProperty(\"group.id\", env.getConfig().getGlobalJobParameters().toMap().get(\"kafka.group.id\"));\n    FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), properties);\n    if (time != null) {\n        Map<TopicPartition, Long> specificStartOffsets = consumer.offsetsForTimes(Collections.singletonMap(new TopicPartition(topic, 0), time));\n        consumer.setStartFromSpecificOffsets(specificStartOffsets);\n    }\n    env.addSource(consumer).name(topic);\n    return env.addSource(consumer).name(topic);\n}", "CodeBleu_score": 52.71325419994859}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException    Properties properties = new Properties();\n    properties.setProperty(\"bootstrap.servers\", env.getConfig().get(\"kafka.bootstrap.servers\").toString());\n    properties.setProperty(\"group.id\", env.getConfig().get(\"kafka.group.id\").toString());\n    properties.setProperty(\"auto.offset.reset\", env.getConfig().get(\"kafka.auto.offset.reset\").toString());\n    properties.setProperty(\"key.deserializer\", env.getConfig().get(\"kafka.key.deserializer\").toString());\n    properties.setProperty(\"value.deserializer\", env.getConfig().get(\"kafka.value.deserializer\").toString());\n\n    FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), properties);\n    if (time != null) {\n        consumer.setStartFromTimestamp(time);\n    }\n    env.addSource(consumer).name(\"metric-event-source\");\n    return env.fromSource(consumer, WatermarkStrategy.noWatermarks(), \"metric-event-source\");\n}", "CodeBleu_score": 40.01834014580237}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time)    String groupId = parameterTool.getRequired(KAFKA_CONSUMER_GROUP_ID);\n    props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupId + \"_\" + time);\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n    Map<String, List<PartitionInfo>> partitions = consumer.listTopics();\n    List<PartitionInfo> partitionInfoList = partitions.get(parameterTool.getRequired(KAFKA_TOPIC));\n    Map<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\n    for (PartitionInfo partitionInfo : partitionInfoList) {\n        partitionOffsets.put(new KafkaTopicPartition(partitionInfo.topic(), partitionInfo.partition()), time);\n    }\n    Map<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(partitionOffsets);\n    consumer.close();\n    return offsets.entrySet().stream().collect(Collectors.toMap(e -> new KafkaTopicPartition(e.getKey().topic(), e.getKey().partition()), e -> e.getValue().offset()));\n}", "CodeBleu_score": 53.27677867363755}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time)    props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, \"offset-by-time-\" + time);\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n    Map<TopicPartition, Long> partitionTimestamp = new HashMap<>();\n    for (String topic : parameterTool.getList(TOPIC)) {\n        List<PartitionInfo> partitions = consumer.partitionsFor(topic);\n        for (PartitionInfo partitionInfo : partitions) {\n            partitionTimestamp.put(new TopicPartition(topic, partitionInfo.partition()), time);\n        }\n    }\n    Map<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(partitionTimestamp);\n    Map<KafkaTopicPartition, Long> offsetByPartition = new HashMap<>();\n    for (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : offsets.entrySet()) {\n        TopicPartition key = entry.getKey();\n        OffsetAndTimestamp value = entry.getValue();\n        if (value != null) {\n            offsetByPartition.put(new KafkaTopicPartition(key.topic(), key.partition()), value.offset());\n        }\n    }\n    consumer.close();\n    return offsetByPartition;\n}\n", "CodeBleu_score": 52.11273461604118}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time)    String groupId = \"offset-calculator-\" + time;\n    props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupId);\n    KafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(props);\n    Map<String, List<PartitionInfo>> partitions = consumer.listTopics();\n    Map<KafkaTopicPartition, Long> offsets = new HashMap<>();\n    for (String topic : partitions.keySet()) {\n        List<PartitionInfo> partitionInfos = partitions.get(topic);\n        for (PartitionInfo partitionInfo : partitionInfos) {\n            int partition = partitionInfo.partition();\n            TopicPartition topicPartition = new TopicPartition(topic, partition);\n            Map<TopicPartition, OffsetAndTimestamp> offsetsForTimes = consumer.offsetsForTimes(Map.of(topicPartition, time));\n            OffsetAndTimestamp offsetAndTimestamp = offsetsForTimes.get(topicPartition);\n            if (offsetAndTimestamp != null) {\n                offsets.put(new KafkaTopicPartition(topic, partition), offsetAndTimestamp.offset());\n            }\n        }\n    }\n    consumer.close();\n    return offsets;\n}", "CodeBleu_score": 44.69481709277482}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException    Properties props = new Properties();\n    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\n    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    MetricEvent event = new MetricEvent();\n    event.setTimestamp(System.currentTimeMillis());\n    event.setName(\"my_metric\");\n    event.setTags(new HashMap<String, String>() {{\n        put(\"host\", \"localhost\");\n    }});\n    event.setFields(new HashMap<String, Object>() {{\n        put(\"value\", 42);\n    }});\n\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"my_topic\", event.toString());\n    producer.send(record);\n\n    System.out.println(\"Sent data: \" + event.toString());\n    producer.flush();\n}", "CodeBleu_score": 42.98197918412612}, {"code": "public static void writeToKafka() throws InterruptedException    // Set up Kafka producer properties\n    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n    // Create Kafka producer\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    // Create MetricEvent\n    MetricEvent event = new MetricEvent();\n    event.setTimestamp(System.currentTimeMillis());\n    event.setName(\"my_metric\");\n    event.setTags(new HashMap<String, String>() {{\n        put(\"host\", \"localhost\");\n        put(\"region\", \"us-west-2\");\n    }});\n    event.setFields(new HashMap<String, Object>() {{\n        put(\"value\", 42);\n    }});\n\n    // Send MetricEvent to Kafka topic\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"my_topic\", event.toString());\n    producer.send(record);\n\n    // Print sent data\n    System.out.println(\"Sent data: \" + event.toString());\n\n    // Flush producer to ensure all data is sent\n    producer.flush();\n\n    // Wait for user input to exit\n    System.out.println(\"Press enter to exit.\");\n    System.in.read();\n\n    // Close Kafka producer\n    producer.close();\n}", "CodeBleu_score": 51.40761475665864}, {"code": "public static void writeToKafka() throws InterruptedException    // Set up Kafka producer properties\n    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n    // Create a Kafka producer\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    // Create a MetricEvent and populate it with data\n    MetricEvent event = new MetricEvent();\n    event.setTimestamp(System.currentTimeMillis());\n    event.setName(\"my_metric\");\n    event.setTags(new HashMap<>());\n    event.getTags().put(\"host\", \"localhost\");\n    event.getTags().put(\"region\", \"us-west\");\n    event.setFields(new HashMap<>());\n    event.getFields().put(\"value\", 42);\n\n    // Create a ProducerRecord and send it to the Kafka topic\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"my_topic\", event.toString());\n    producer.send(record);\n\n    // Print the sent data\n    System.out.println(\"Sent data: \" + event.toString());\n\n    // Flush the producer to ensure all data is sent\n    producer.flush();\n}", "CodeBleu_score": 50.665150758325794}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event)    try {\n        if (levels.contains(event.getLevel()) && !event.getLoggerName().contains(\"xxx\")) {\n            byte[] bytes = getLayout().toByteArray(event);\n            ProducerRecord<byte[], byte[]> record = new ProducerRecord<>(topic, bytes);\n            producer.send(record);\n        }\n    } catch (Exception ex) {\n        LOGGER.warn(\"Error sending log event to Kafka\", ex);\n    }\n}\n", "CodeBleu_score": 51.205176400581045}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event)    if (this.isFiltered(event)) {\n        return;\n    }\n    try {\n        String message = this.getLayout().toSerializable(event).toString();\n        if (this.shouldSend(event)) {\n            this.send(message);\n        }\n    } catch (Exception ex) {\n        LOGGER.warn(\"Error while appending event to kafka\", ex);\n    }\n}", "CodeBleu_score": 41.45572782816303}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event)    if (event.getLevel().isInRange(Level.INFO, Level.WARN) && !event.getLoggerName().contains(\"xxx\")) {\n        try {\n            byte[] data = getLayout().toByteArray(event);\n            ProducerRecord<String, byte[]> record = new ProducerRecord<>(topic, data);\n            producer.send(record).get();\n        } catch (Exception e) {\n            LOGGER.warn(\"Error sending log event to Kafka\", e);\n        }\n    }\n}", "CodeBleu_score": 49.6047881877485}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error\tvalidMethods := []string{\n\t\t\"\",\n\t\t\"create\",\n\t\t\"update\",\n\t\t\"delete\",\n\t\t\"get\",\n\t\t\"list\",\n\t\t\"watch\",\n\t\t\"patch\",\n\t\t\"deletecollection\",\n\t\t\"connect\",\n\t\t\"disconnect\",\n\t\t\"analyze\",\n\t\t\"explain\",\n\t\t\"stream\",\n\t\t\"truncate\",\n\t\t\"updatestats\",\n\t\t\"rollback\",\n\t\t\"backup\",\n\t\t\"restore\",\n\t\t\"import\",\n\t\t\"export\",\n\t\t\"copy\",\n\t\t\"move\",\n\t\t\"lock\",\n\t\t\"unlock\",\n\t\t\"execute\",\n\t\t\"read\",\n\t\t\"write\",\n\t\t\"admin\",\n\t\t\"debug\",\n\t\t\"profile\",\n\t\t\"trace\",\n\t\t\"log\",\n\t\t\"audit\",\n\t\t\"monitor\",\n\t\t\"report\",\n\t\t\"alert\",\n\t\t\"notify\",\n\t\t\"enforce\",\n\t\t\"authorize\",\n\t\t\"authenticate\",\n\t\t\"validate\",\n\t\t\"synthesize\",\n\t\t\"ingest\",\n\t\t\"aggregate\",\n\t\t\"anonymize\",\n\t\t\"deanonymize\",\n\t\t\"redact\",\n\t\t\"unredact\",\n\t\t\"reidentify\",\n\t\t\"mask\",\n\t\t\"unmask\",\n\t\t\"purge\",\n\t\t\"test\",\n\t\t\"benchmark\",\n\t\t\"loadtest\",\n\t\t\"stresstest\",\n\t\t\"smoketest\",\n\t\t\"endtoendtest\",\n\t\t\"canarytest\",\n\t\t\"build\",\n\t\t\"release\",\n\t\t\"deploy\",\n\t\t\"promote\",\n\t\t\"rollback\",\n\t\t\"scale\",\n\t\t\"resize\",\n\t\t\"migrate\",\n\t\t\"backup\",\n\t\t\"restore\",\n\t\t\"import\",\n\t\t\"export\",\n\t\t\"copy\",\n\t\t\"move\",\n\t\t\"lock\",\n\t\t\"unlock\",\n\t\t\"execute\",\n\t\t\"read\",\n\t\t\"write\",\n\t\t\"admin\",\n\t\t\"debug\",\n\t\t\"profile\",\n\t\t\"trace\",\n\t\t\"log\",\n\t\t\"audit\",\n\t\t\"monitor\",\n\t\t\"report\",\n\t\t\"alert\",\n\t\t\"notify\",\n\t\t\"enforce\",", "CodeBleu_score": 4.768807697457362}, {"code": "func ValidateTopicSuffixMethod(method string) error\tvalidMethods := []string{\"topic\", \"suffix\"}\n\tfor _, validMethod := range validMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}\n", "CodeBleu_score": 81.85281192825045}, {"code": "func ValidateTopicSuffixMethod(method string) error\tvalidMethods := []string{\"topic\", \"suffix\"}\n\n\tfor _, validMethod := range validMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 81.85281192825045}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) \tif k.RoutingTag != \"\" {\n\t\tif value, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn value, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\tuuid, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn uuid.String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}\n", "CodeBleu_score": 82.71318079994415}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) \tif k.RoutingTag != \"\" {\n\t\tif value, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn value, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\tuuid, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn uuid.String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}\n", "CodeBleu_score": 82.71318079994415}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) \tif k.RoutingKey == \"random\" {\n\t\tuuid, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn uuid.String(), nil\n\t}\n\tif k.RoutingTag != \"\" {\n\t\tif value, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn value, nil\n\t\t} else {\n\t\t\treturn \"\", fmt.Errorf(\"routing tag %q not found in metric %v\", k.RoutingTag, metric.Name())\n\t\t}\n\t}\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 72.7170336241473}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error\tregexps := make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, regexpStr := range k.TopicRegexps {\n\t\tregexp, err := regexp.Compile(regexpStr)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regular expression %q: %v\", regexpStr, err)\n\t\t}\n\t\tregexps[i] = regexp\n\t}\n\tk.topicRegexps = regexps\n\treturn nil\n}\n", "CodeBleu_score": 43.63155380865372}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error\tregexps := make([]*regexp.Regexp, len(k.TopicRegexps))\n\n\tfor i, regexpStr := range k.TopicRegexps {\n\t\tregexp, err := regexp.Compile(regexpStr)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regular expression '%s': %w\", regexpStr, err)\n\t\t}\n\n\t\tregexps[i] = regexp\n\t}\n\n\tk.regexps = regexps\n\treturn nil\n}\n", "CodeBleu_score": 44.49578888841221}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error\tregexps := make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, regexStr := range k.TopicRegexps {\n\t\tregex, err := regexp.Compile(regexStr)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regular expression '%s': %v\", regexStr, err)\n\t\t}\n\t\tregexps[i] = regex\n\t}\n\tk.topicRegexps = regexps\n\treturn nil\n}\n", "CodeBleu_score": 43.73907263167985}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo)\th.Lock()\n\tdefer h.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryID]\n\tif !ok {\n\t\treturn\n\t}\n\n\tmsg.MarkAsDelivered()\n\n\tif h.session != nil {\n\t\th.session.MarkMessageAsDelivered(msg)\n\t}\n\n\tdelete(h.undelivered, track.DeliveryID)\n\th.sem.Release(1)\n}\n", "CodeBleu_score": 46.00222251643569}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo)\th.lock.Lock()\n\tdefer h.lock.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryID]\n\tif !ok {\n\t\treturn\n\t}\n\n\tif msg.DeliveryTag == track.DeliveryTag {\n\t\tmsg.Delivery.Ack(false)\n\t\th.session.MarkMessage(msg, \"\")\n\t}\n\n\tdelete(h.undelivered, track.DeliveryID)\n\th.semaphore <- struct{}{}\n}", "CodeBleu_score": 53.80398767557188}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo)\th.lock.Lock()\n\tdefer h.lock.Unlock()\n\n\tmsg, ok := h.undelivered[track.ID]\n\tif !ok {\n\t\treturn\n\t}\n\n\tif msg.Delivered() {\n\t\th.session.MarkMessage(msg, \"\")\n\t}\n\n\tdelete(h.undelivered, track.ID)\n\th.sem.Release(1)\n}\n", "CodeBleu_score": 48.288743409728006}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase message, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\th.handleMessage(session.Context(), message)\n\t\t}\n\t}\n}\n", "CodeBleu_score": 39.3344995561998}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase message, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.handler(ctx, message); err != nil {\n\t\t\t\tlog.Printf(\"error handling message: %v\\n\", err)\n\t\t\t}\n\t\t}\n\t}\n}\n", "CodeBleu_score": 51.502120582591274}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\th.handleMessage(msg)\n\t\t\tsession.MarkMessage(msg, \"\")\n\t\t}\n\t}\n}\n", "CodeBleu_score": 49.14166782041814}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String)  if (logkafka_id.isEmpty) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be empty.\")\n  }\n  if (logkafka_id == \".\" || logkafka_id == \"..\") {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be '.' or '..'.\")\n  }\n  if (logkafka_id.length > logkafkaIdMaxLength) {\n    throw new IllegalArgumentException(s\"Logkafka ID cannot exceed ${logkafkaIdMaxLength} characters.\")\n  }\n  if (!logkafkaIdPattern.matcher(logkafka_id).matches()) {\n    throw new IllegalArgumentException(s\"Logkafka ID can only contain alphanumeric characters, hyphens, underscores, and dots.\")\n  }\n}", "CodeBleu_score": 26.346037996444693}, {"code": "def validateLogkafkaId(logkafka_id: String)  if (logkafka_id.isEmpty) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be empty\")\n  }\n  if (logkafka_id == \".\" || logkafka_id == \"..\") {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be '.' or '..'\")\n  }\n  if (logkafka_id.length > 249) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot exceed 249 characters\")\n  }\n  if (!logkafka_id.matches(\"^[a-zA-Z0-9_.-]+$\")) {\n    throw new IllegalArgumentException(\"Logkafka ID can only contain letters, numbers, '.', '_', and '-'\")\n  }\n}", "CodeBleu_score": 19.740732030757425}, {"code": "def validateLogkafkaId(logkafka_id: String)  if (logkafka_id.isEmpty) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be empty\")\n  }\n  if (logkafka_id == \".\" || logkafka_id == \"..\") {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be '.' or '..'\")\n  }\n  if (logkafka_id.length > LogkafkaId.MAX_LENGTH) {\n    throw new IllegalArgumentException(s\"Logkafka ID cannot exceed ${LogkafkaId.MAX_LENGTH} characters\")\n  }\n  if (!LogkafkaId.VALID_CHARS_PATTERN.matcher(logkafka_id).matches()) {\n    throw new IllegalArgumentException(s\"Logkafka ID can only contain alphanumeric characters, '-', '_', and '.'\")\n  }\n}", "CodeBleu_score": 22.43367383022488}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] =    val future = kafkaManagerActor ? msg\n    future.map {\n      case akka.actor.Status.Failure(ex) =>\n        logger.error(s\"Kafka manager actor failed with $ex\")\n        ApiError.internalError(s\"Kafka manager actor failed with $ex\")\n      case response: Output =>\n        try {\n          Right(fn(response))\n        } catch {\n          case ex: Exception =>\n            logger.error(s\"Failed to process response from Kafka manager actor: $ex\")\n            ApiError.internalError(s\"Failed to process response from Kafka manager actor: $ex\")\n        }\n    }\n  }\n\n  /**\n   * The getTopics method returns a Future containing either an ApiError or a list of topic names.\\nIt sends a GetTopics message to the Kafka manager actor and processes the response using the tryWithKafkaManagerActor function.\\nIf the response is successful, it extracts the topic names from the GetTopicsResponse object and returns them as a Right value.\\nIf the response is unsuccessful, it returns the ApiError as a Left value.\n   */\n  def getTopics: Future[ApiError \\/ List[String]] = {\n    tryWithKafkaManagerActor(GetTopics)(_.topics.map(_.name).toList)\n  }\n\n  /**\n   * The getTopic method takes a topic name and returns a Future containing either an ApiError or a GetTopicResponse object.\\nIt sends a GetTopic message to the Kafka manager actor with the specified topic name and processes the response using the tryWithKafkaManagerActor function.\\nIf the response is successful, it returns the GetTopicResponse object as a Right value.\\nIf the response is unsuccessful, it returns the ApiError as a Left value.\n   */\n  def getTopic(topic: String): Future[ApiError \\/ GetTopicResponse] = {\n    tryWithKafkaManagerActor(GetTopic(topic))(identity)\n  }\n\n  /**\n   * The createTopic method takes a topic name and returns a Future containing either an ApiError or a CreateTopicResponse object", "CodeBleu_score": 34.570469037928284}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] =    val future = kafkaManagerActor ? msg\n    future.map {\n      case akka.actor.Status.Failure(ex) =>\n        logger.error(s\"Kafka manager actor failed with exception: $ex\")\n        ApiError.internalError(s\"Kafka manager actor failed with exception: $ex\")\n      case output: Output =>\n        try {\n          Right(fn(output))\n        } catch {\n          case ex: Exception =>\n            logger.error(s\"Kafka manager actor failed with exception: $ex\")\n            ApiError.internalError(s\"Kafka manager actor failed with exception: $ex\")\n        }\n      case _ =>\n        logger.error(s\"Kafka manager actor failed with unknown response: $future\")\n        ApiError.internalError(s\"Kafka manager actor failed with unknown response: $future\")\n    }\n  }\n\n  /**\n   * The tryWithKafkaManagerActor function sends a message to the Kafka manager actor and processes the response.\\nIt takes an input message and a function to transform the output, returning a Future containing either an ApiError or the transformed output.\\nIf the actor responds with an error, it logs the failure and returns an ApiError.\\nIf the response is successful, it applies the transformation function and handles any exceptions, returning either the transformed output or an ApiError.\\nThe function also includes error handling for any thrown exceptions during the process.\n   */\n  private[this] def tryWithKafkaManagerActor[Input, Output](msg: Input)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ Output] = {\n    val future = kafkaManagerActor ? msg\n    future.map {\n      case akka.actor.Status.Failure(ex) =>\n        logger.error(s\"Kafka manager actor failed with exception: $ex\")\n        ApiError.internalError(s\"Kafka manager actor failed with exception: $ex\")\n      case output: Output =>\n        Right(output)\n      case _ =>\n        logger.error(s\"Kafka manager actor failed with unknown response: $future\")\n        ApiError.internalError(s\"", "CodeBleu_score": 39.279204530448965}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] =    val response = kafkaManagerActor ? msg\n    response.map {\n      case akka.actor.Status.Failure(ex) =>\n        logger.error(s\"Failed to send message to Kafka manager actor: $ex\")\n        ApiError.internalError(\"Failed to send message to Kafka manager actor\")\n      case output: Output =>\n        try {\n          Right(fn(output))\n        } catch {\n          case ex: Exception =>\n            logger.error(s\"Failed to process output from Kafka manager actor: $ex\")\n            ApiError.internalError(\"Failed to process output from Kafka manager actor\")\n        }\n    }\n  }\n\n  /**\n   * The getTopics function sends a message to the Kafka manager actor to retrieve a list of topics, and returns the result as a Future containing either an ApiError or a list of topic names.\n   */\n  def getTopics: Future[ApiError \\/ List[String]] =\n    tryWithKafkaManagerActor(GetTopics)(identity)\n\n  /**\n   * The getTopicInfo function sends a message to the Kafka manager actor to retrieve information about a specific topic, and returns the result as a Future containing either an ApiError or a TopicInfo object.\n   */\n  def getTopicInfo(topicName: String): Future[ApiError \\/ TopicInfo] =\n    tryWithKafkaManagerActor(GetTopicInfo(topicName))(identity)\n\n  /**\n   * The getTopicMessages function sends a message to the Kafka manager actor to retrieve messages from a specific topic, and returns the result as a Future containing either an ApiError or a list of Message objects.\n   */\n  def getTopicMessages(topicName: String, limit: Int): Future[ApiError \\/ List[Message]] =\n    tryWithKafkaManagerActor(GetTopicMessages(topicName, limit))(identity)\n\n  /**\n   * The getConsumerGroups function sends a message to the Kafka manager actor to retrieve a list of consumer groups, and returns the result as a Future containing either an ApiError or a list of consumer group names.\n   */\n  def getConsumerGroups:", "CodeBleu_score": 38.56458473669522}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] =    val future = kafkaManagerActor ? msg\n    future.map {\n      case output: Output => fn(output)\n      case ActorErrorResponse(msg) =>\n        val error = ApiError(s\"Actor error: $msg\")\n        error.left\n      case _ =>\n        val error = ApiError(\"Unexpected response from Kafka Manager actor\")\n        error.left\n    } recover {\n      case t: Throwable =>\n        val error = ApiError(s\"Error: ${t.getMessage}\")\n        error.left\n    }\n  }\n\n  /**\n   * The getTopics function retrieves a list of topics from the Kafka Manager actor.\\nIt takes no input and returns a Future of an ApiError \\/ List[Topic].\\nIt uses the withKafkaManagerActor function to send a GetTopics message to the Kafka Manager actor and process the response.\\nIf the response is a GetTopicsResponse, it returns the topics wrapped in a Right.\\nIf the response is not a GetTopicsResponse, it returns a Left with an ApiError.\n   */\n  def getTopics: Future[ApiError \\/ List[Topic]] = {\n    withKafkaManagerActor(GetTopics) {\n      case GetTopicsResponse(topics) => topics.right\n      case _ => ApiError(\"Unexpected response from Kafka Manager actor\").left\n    }\n  }\n\n  /**\n   * The getTopicInfo function retrieves information about a specific topic from the Kafka Manager actor.\\nIt takes a topic name as input and returns a Future of an ApiError \\/ TopicInfo.\\nIt uses the withKafkaManagerActor function to send a GetTopicInfo message to the Kafka Manager actor and process the response.\\nIf the response is a GetTopicInfoResponse, it returns the topic info wrapped in a Right.\\nIf the response is not a GetTopicInfoResponse, it returns a Left with an ApiError.\n   */\n  def getTopicInfo(topicName: String): Future[ApiError \\/ TopicInfo] = {\n    withKafkaManagerActor(GetTopicInfo(topicName", "CodeBleu_score": 25.872543371339283}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] =    val response = kafkaManagerActor ? msg\n    response.mapTo[Output].map(fn).recover {\n      case e: ActorErrorResponse => Left(ApiError(e.message, e.cause))\n      case t: Throwable => Left(ApiError(t.getMessage, Some(t)))\n    }\n  }\n\n  /**\n   * The withKafkaManagerActor function sends a message to the Kafka Manager actor and processes the response.\\nIt takes an input message and a function to handle the output.\\nIt sends the message to the Kafka Manager actor and applies the provided function to the response if it matches the expected output type.\\nIf an ActorErrorResponse is received, it returns an ApiError.\\nIf a throwable occurs, it recovers by returning an ApiError from the throwable.\n   */\n  private[this] def withKafkaManagerActor[Input, Output](msg: Input)\n    (fn: Output => Future[ApiError \\/ Output])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ Output] = {\n    val response = kafkaManagerActor ? msg\n    response.mapTo[Output].map(fn).recover {\n      case e: ActorErrorResponse => Left(ApiError(e.message, e.cause))\n      case t: Throwable => Left(ApiError(t.getMessage, Some(t)))\n    }\n  }\n\n  /**\n   * The withKafkaManagerActor function sends a message to the Kafka Manager actor and processes the response.\\nIt takes an input message and a function to handle the output.\\nIt sends the message to the Kafka Manager actor and applies the provided function to the response if it matches the expected output type.\\nIf an ActorErrorResponse is received, it returns an ApiError.\\nIf a throwable occurs, it recovers by returning an ApiError from the throwable.\n   */\n  private[this] def withKafkaManagerActor[Input](msg: Input)\n    (fn: Unit => Future[ApiError \\/ Unit])\n    (implicit tag: ClassTag[Unit]): Future[ApiError \\/ Unit] = {\n    val response =", "CodeBleu_score": 46.22919382620913}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] =    val response = kafkaManagerActor ? msg\n    response.mapTo[Output].map {\n      case Success(output) => fn(output)\n      case Failure(error) => Left(ApiError.fromThrowable(error))\n    }.recover {\n      case error => Left(ApiError.fromThrowable(error))\n    }\n  }\n\n  /**\n   * The withKafkaManagerActor function sends a message to the Kafka Manager actor and processes the response.\\nIt takes an input message and a function to handle the output.\\nIt sends the message to the Kafka Manager actor and applies the provided function to the response if it matches the expected output type.\\nIf an ActorErrorResponse is received, it returns an ApiError.\\nIf a throwable occurs, it recovers by returning an ApiError from the throwable.\n   */\n  private[this] def withKafkaManagerActor[Input, Output](msg: Input)\n    (fn: Output => Future[ApiError \\/ Output])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ Output] = {\n    val response = kafkaManagerActor ? msg\n    response.mapTo[Output].map {\n      case Success(output) => fn(output)\n      case Failure(error) => Left(ApiError.fromThrowable(error))\n    }.recover {\n      case error => Left(ApiError.fromThrowable(error))\n    }\n  }\n\n  /**\n   * The withKafkaManagerActor function sends a message to the Kafka Manager actor and processes the response.\\nIt takes an input message and a function to handle the output.\\nIt sends the message to the Kafka Manager actor and applies the provided function to the response if it matches the expected output type.\\nIf an ActorErrorResponse is received, it returns an ApiError.\\nIf a throwable occurs, it recovers by returning an ApiError from the throwable.\n   */\n  private[this] def withKafkaManagerActor[Input, Output](msg: Input)\n    (fn: Output => ApiError \\/ Output)\n    (implicit tag: ClassTag[Output]): Future[", "CodeBleu_score": 44.56393261948241}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] =    val command = KMClusterCommandRequest(clusterName, PreferredLeaderElection(topics))\n    kafkaManager ! command\n    kafkaManager.ask(command).map(_.fold(_.asLeft[ClusterContext], _.asRight[ApiError]))\n  }\n", "CodeBleu_score": 23.395658839453343}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] =    val request = KMClusterCommandRequest(clusterName, PreferredLeaderElection(topics))\n    (kafkaManager ? request).mapTo[ApiError \\/ ClusterContext]\n  }\n", "CodeBleu_score": 21.11291026243417}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] =    val command = KMClusterCommandRequest(clusterName, PreferredLeaderElection(topics))\n    KafkaManager.ask(command).map(_.fold(ApiError.apply, identity))\n  }\n", "CodeBleu_score": 21.37648305562059}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) =    val cluster = getCluster(clusterName)\n    cluster.getTopics.map { topics =>\n        val topicNames = topics.map(_.name)\n        runPreferredLeaderElection(clusterName, topicNames)\n    }\n}\n", "CodeBleu_score": 19.648523409119562}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) =  val topics: Try[Set[String]] = getTopics(clusterName)\n  topics.fold(\n    error => error,\n    topics => runPreferredLeaderElection(clusterName, topics)\n  )\n}\n", "CodeBleu_score": 16.82356496354636}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) =  val topicList = getTopicList(clusterName)\n  topicList.map(topicName => runPreferredLeaderElection(clusterName, topicName))\n}\n", "CodeBleu_score": 14.674102333091094}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) =   implicit val ec = context.dispatcher\n  val request = KMClusterCommandRequest(clusterName, ManualPartitionAssignments(assignments))\n  val future = KafkaManager.ask(request).mapTo[KMClusterCommandResponse]\n  val response = Await.result(future, 10.seconds)\n  val errors = response.errors\n  if (errors.isEmpty) {\n    Success(true)\n  } else {\n    Failure(new Exception(errors.mkString(\"\\n\")))\n  }\n}\n", "CodeBleu_score": 25.52580856915878}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) =     implicit val ec = context.dispatcher\n    val cmd = KMClusterCommandRequest(clusterName, ManualPartitionAssignments(assignments))\n    KafkaManager ! cmd\n    val results = KafkaManager.ask(cmd).mapTo[KMClusterCommandResponse]\n    val errors = results.flatMap {\n      case KMClusterCommandSuccess(_, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _, _,", "CodeBleu_score": 15.283149164014043}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) =   implicit val ec = context.dispatcher\n  val command = KMClusterCommandRequest(clusterName, ManualPartitionAssignments(assignments))\n  KafkaManager.ask(command).mapTo[KMClusterCommandResponse].map {\n    case KMClusterCommandSuccessResponse(_, _, _, _, _, _) =>\n      true\n    case KMClusterCommandErrorResponse(_, _, _, errors) =>\n      errors\n  }\n}", "CodeBleu_score": 22.33360016255934}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception    try {\n        Collection<Node> nodes = admin.describeCluster().nodes().get(brokerConfigTimeoutMs, TimeUnit.MILLISECONDS);\n        if (nodes.isEmpty()) {\n            throw new ConnectException(\"No Kafka nodes available\");\n        }\n        Node node = nodes.iterator().next();\n        ConfigResource configResource = new ConfigResource(ConfigResource.Type.BROKER, node.idString());\n        Config config = admin.describeConfigs(Collections.singleton(configResource)).get(brokerConfigTimeoutMs, TimeUnit.MILLISECONDS).get(configResource);\n        if (config == null) {\n            throw new ConnectException(\"No broker config available\");\n        }\n        return config;\n    } catch (ExecutionException | InterruptedException e) {\n        throw new ConnectException(e);\n    }\n}", "CodeBleu_score": 56.68767234030282}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception    try {\n        DescribeClusterResult clusterResult = admin.describeCluster();\n        List<Node> nodes = clusterResult.nodes().get(10, TimeUnit.SECONDS);\n        if (nodes.isEmpty()) {\n            throw new ConnectException(\"No nodes found in the Kafka cluster\");\n        }\n        Node node = nodes.get(0);\n        ConfigResource configResource = new ConfigResource(ConfigResource.Type.BROKER, node.idString());\n        DescribeConfigsResult configResult = admin.describeConfigs(Collections.singletonList(configResource));\n        Map<ConfigResource, Config> configs = configResult.all().get(10, TimeUnit.SECONDS);\n        if (configs.isEmpty()) {\n            throw new ConnectException(\"No configurations found for the Kafka broker\");\n        }\n        return configs.get(configResource);\n    } catch (ExecutionException | TimeoutException e) {\n        throw new ConnectException(\"Failed to retrieve Kafka broker configuration\", e);\n    }\n}", "CodeBleu_score": 54.57659567107586}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception    // Describe the cluster to get the available nodes within a specified timeout\n    Collection<Node> nodes = admin.describeCluster().nodes().get(30, TimeUnit.SECONDS);\n\n    // If no nodes are available, throw a ConnectException\n    if (nodes.isEmpty()) {\n        throw new ConnectException(\"No Kafka nodes found\");\n    }\n\n    // Select the first node's ID and request its configuration\n    Config config = admin.describeConfigs(Collections.singletonList(nodes.iterator().next().idString()))\n            .all().get(30, TimeUnit.SECONDS);\n\n    // If no configurations are received, throw a ConnectException\n    if (config.isEmpty()) {\n        throw new ConnectException(\"No Kafka broker configurations found\");\n    }\n\n    // Return the broker's configuration\n    return config.values().iterator().next();\n}", "CodeBleu_score": 49.55494709362519}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator)  return (config, version) -> {\n    if (config.schemaHistory() == SchemaHistory.KAFKA_SCHEMA_HISTORY) {\n      return validator.validate(config, version);\n    }\n    return 0;\n  };\n}\n", "CodeBleu_score": 23.901859626382247}, {"code": "private static Validator forKafka(final Validator validator)    return (schema, config) -> {\n        if (schema.history() == SchemaHistory.KAFKA_SCHEMA_HISTORY) {\n            return validator.validate(schema, config);\n        }\n        return 0;\n    };\n}\n", "CodeBleu_score": 23.64843328368326}, {"code": "private static Validator forKafka(final Validator validator)  return new Validator() {\n    @Override\n    public int validate(final Schema schema) {\n      return schema.history() == Schema.KAFKA_SCHEMA_HISTORY ? validator.validate(schema) : 0;\n    }\n  };\n}", "CodeBleu_score": 20.21447781996251}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config)    String kafkaConnectVersion = config.get(KAFKA_CONNECT_VERSION_CONFIG).toString();\n    String topicCreationEnabled = config.get(TOPIC_CREATION_ENABLE_CONFIG).toString();\n    return isTopicCreationEnabled(kafkaConnectVersion, topicCreationEnabled);\n}", "CodeBleu_score": 30.46698749698394}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config)  String kafkaConnectVersion = getKafkaConnectVersion();\n  if (kafkaConnectVersion == null) {\n    return true;\n  }\n  if (kafkaConnectVersion.startsWith(\"2.5.\")) {\n    return true;\n  }\n  if (kafkaConnectVersion.startsWith(\"2.6.\")) {\n    return true;\n  }\n  if (kafkaConnectVersion.startsWith(\"2.7.\")) {\n    return true;\n  }\n  if (kafkaConnectVersion.startsWith(\"2.8.\")) {\n    return true;\n  }\n  if (kafkaConnectVersion.startsWith(\"3.0.\")) {\n    return true;\n  }\n  if (kafkaConnectVersion.startsWith(\"3.1.\")) {\n    return true;\n  }\n  if (kafkaConnectVersion.startsWith(\"3.2.\")) {\n    return true;\n  }\n  if (kafkaConnectVersion.startsWith(\"3.3.\")) {\n    return true;\n  }\n  if (kafkaConnectVersion.startsWith(\"3.4.\")) {\n    return true;\n  }\n  if (kafkaConnectVersion.startsWith(\"3.5.\")) {\n    return true;\n  }\n  return false;\n}", "CodeBleu_score": 20.0057074517215}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config)  if (kafkaConnectVersion == null) {\n    kafkaConnectVersion = getKafkaConnectVersion();\n  }\n  Boolean topicCreationEnabled = (Boolean)config.get(TOPIC_CREATION_ENABLE);\n  if (topicCreationEnabled == null) {\n    topicCreationEnabled = true;\n  }\n  if (kafkaConnectVersion.compareTo(KAFKA_CONNECT_VERSION_WITH_TOPIC_CREATION) >= 0) {\n    return topicCreationEnabled;\n  }\n else {\n    return false;\n  }\n}", "CodeBleu_score": 37.77584758694926}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config)    // Get the client ID from the configuration map\n    String clientId = config.get(KafkaOffsetBackingStore.CONFIG_CLIENT_ID);\n    // Check if the client ID is null or empty\n    if (clientId == null || clientId.isEmpty()) {\n        // Throw an exception if the client ID is missing\n        throw new IllegalArgumentException(\"KafkaOffsetBackingStore requires a non-empty client ID\");\n    }\n\n    // Create a new Properties object to store Kafka admin properties\n    Properties adminProps = new Properties();\n    // Set the bootstrap servers from the configuration map\n    adminProps.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, config.get(KafkaOffsetBackingStore.CONFIG_BOOTSTRAP_SERVERS));\n    // Set the security protocol from the configuration map\n    adminProps.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, config.get(KafkaOffsetBackingStore.CONFIG_SECURITY_PROTOCOL));\n    // Set the SSL keystore location from the configuration map\n    adminProps.put(SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG, config.get(KafkaOffsetBackingStore.CONFIG_SSL_KEYSTORE_LOCATION));\n    // Set the SSL keystore password from the configuration map\n    adminProps.put(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, config.get(KafkaOffsetBackingStore.CONFIG_SSL_KEYSTORE_PASSWORD));\n    // Set the SSL truststore location from the configuration map\n    adminProps.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, config.get(KafkaOffsetBackingStore.CONFIG_SSL_TRUSTSTORE_LOCATION));\n    // Set the SSL truststore password from the configuration map\n    adminProps.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, config.get(KafkaOffsetBackingStore.CONFIG_SSL_TRUSTSTORE_PASSWORD));\n    // Set the SSL key password from the configuration map\n    adminProps.put(SslConfigs.SSL_KEY", "CodeBleu_score": 29.224136781849353}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config)    final String clientId = config.get(CLIENT_ID_CONFIG);\n    if (clientId == null) {\n        throw new IllegalArgumentException(CLIENT_ID_CONFIG + \" is required\");\n    }\n    final Properties adminProperties = new Properties();\n    adminProperties.putAll(config);\n    adminProperties.remove(CLIENT_ID_CONFIG);\n    final SharedTopicAdmin admin = SharedTopicAdmin.create(adminProperties);\n    return new KafkaOffsetBackingStore(admin, clientId, new OffsetStoreConverter());\n}", "CodeBleu_score": 29.75192329613424}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config)    final String clientId = config.get(CLIENT_ID_CONFIG);\n    if (clientId == null) {\n        throw new IllegalArgumentException(String.format(\"Missing mandatory config option '%s'\", CLIENT_ID_CONFIG));\n    }\n    final Properties adminProperties = new Properties();\n    for (final Map.Entry<String, String> entry : config.entrySet()) {\n        if (entry.getKey().startsWith(ADMIN_)) {\n            adminProperties.setProperty(entry.getKey(), entry.getValue());\n        }\n    }\n    final SharedTopicAdmin sharedAdmin = SharedTopicAdmin.create(adminProperties);\n    return new KafkaOffsetBackingStore(sharedAdmin, clientId, new OffsetStoreConverter());\n}", "CodeBleu_score": 36.73940780838642}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException    if (!node.isObject()) {\n        throw new IOException(\"Expected a JSON object, got \" + node);\n    }\n    JsonNode payload = node.get(\"payload\");\n    if (payload != null) {\n        node = payload;\n    }\n    Iterator<String> fieldNames = node.fieldNames();\n    if (fieldNames.hasNext()) {\n        String fieldName = fieldNames.next();\n        if (fieldNames.hasNext()) {\n            return objectMapper.readValue(node.traverse(), keyType);\n        } else {\n            return objectMapper.readValue(node.get(fieldName), keyType);\n        }\n    } else {\n        return null;\n    }\n}\n", "CodeBleu_score": 41.31013719291728}, {"code": "private T readKey(JsonNode node) throws IOException    if (!node.isObject()) {\n        throw new IOException(\"Key must be an object\");\n    }\n    JsonNode payloadNode = node.get(\"payload\");\n    if (payloadNode != null) {\n        node = payloadNode;\n    }\n    Iterator<String> fieldNames = node.fieldNames();\n    if (fieldNames.hasNext()) {\n        String fieldName = fieldNames.next();\n        if (fieldNames.hasNext()) {\n            return objectMapper.readValue(node.toString(), compositeKeyType);\n        } else {\n            return objectMapper.readValue(node.get(fieldName).toString(), simpleKeyType);\n        }\n    } else {\n        return null;\n    }\n}\n", "CodeBleu_score": 40.709946875475936}, {"code": "private T readKey(JsonNode node) throws IOException    if (!node.isObject()) {\n        throw new IOException(\"Expected object, got \" + node.getNodeType());\n    }\n    if (node.has(\"payload\")) {\n        node = node.get(\"payload\");\n    }\n    if (node.size() == 1) {\n        // Simple key\n        Iterator<String> fieldNames = node.fieldNames();\n        String fieldName = fieldNames.next();\n        return objectMapper.treeToValue(node.get(fieldName), keyType);\n    } else {\n        // Composite key\n        return objectMapper.treeToValue(node, keyType);\n    }\n}", "CodeBleu_score": 42.1827087717966}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter)    String topicName = delegate.topicNameFor(id, prefix, delimiter);\n    StringBuilder sb = new StringBuilder(topicName);\n    boolean replaced = false;\n    for (int i = 0; i < sb.length(); i++) {\n        char c = sb.charAt(i);\n        if (c == '.' || c == '+' || c == '#' || c == '$' || c == '/') {\n            sb.setCharAt(i, '_');\n            replaced = true;\n        }\n    }\n    if (replaced) {\n        log.warn(\"Topic name {} contains invalid characters, replacing with _\", topicName);\n        return sb.toString();\n    }\n    return topicName;\n}", "CodeBleu_score": 46.24763246178234}, {"code": "public String topicNameFor(I id, String prefix, String delimiter)    String topicName = topicNameFor(id);\n    if (prefix != null) {\n        topicName = prefix + delimiter + topicName;\n    }\n    StringBuilder sanitizedName = new StringBuilder();\n    boolean modified = false;\n    for (int i = 0; i < topicName.length(); i++) {\n        char c = topicName.charAt(i);\n        if (c == '.' || c == '*' || c == '>') {\n            sanitizedName.append('_');\n            modified = true;\n        } else {\n            sanitizedName.append(c);\n        }\n    }\n    if (modified) {\n        logger.warn(\"Topic name {} contains invalid characters, replacing with '_'.\", topicName);\n        return sanitizedName.toString();\n    }\n    return topicName;\n}", "CodeBleu_score": 49.42306123461435}, {"code": "public String topicNameFor(I id, String prefix, String delimiter)    String topicName = constructTopicName(id, prefix, delimiter);\n    String sanitizedName = topicName;\n    for (int i = 0; i < topicName.length(); i++) {\n        char c = topicName.charAt(i);\n        if (!isValidTopicNameChar(c)) {\n            sanitizedName = sanitizedName.replace(c, REPLACEMENT_CHAR);\n        }\n    }\n    if (!sanitizedName.equals(topicName)) {\n        logger.warn(\"Topic name {} contains invalid characters. Replacing with {}\", topicName, sanitizedName);\n    }\n    return sanitizedName;\n}", "CodeBleu_score": 43.24658892941312}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler)   this.connectorType = connectorType;\n  this.connectorConfig = connectorConfig;\n  this.queue = queue;\n  this.producerThrowable = new AtomicReference<>();\n  this.retryCount = new AtomicInteger(0);\n  if (replacedErrorHandler != null) {\n    this.retryCount.set(replacedErrorHandler.retryCount.get());\n  }\n  this.maxRetries = connectorConfig.maxRetries != null ? connectorConfig.maxRetries : Integer.MAX_VALUE;\n}\n\n", "CodeBleu_score": 55.15316389943653}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler)     this.connectorType = connectorType;\n    this.connectorConfig = connectorConfig;\n    this.queue = queue;\n    this.retryCount = replacedErrorHandler != null ? replacedErrorHandler.getRetryCount() : 0;\n    this.maxRetries = connectorConfig.getInt(CommonConnectorConfig.RETRY_COUNT);\n    this.producerThrowable = new AtomicReference<>();\n}", "CodeBleu_score": 49.350239908944644}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler)     this.connectorType = connectorType;\n    this.connectorConfig = connectorConfig;\n    this.queue = queue;\n    this.retryCount = 0;\n    this.producerThrowable = new AtomicReference<>();\n    this.maxRetries = connectorConfig.getInt(SourceConnectorConfig.RETRY_COUNT);\n    if (maxRetries == 0) {\n        maxRetries = Integer.MAX_VALUE;\n    }\n    if (replacedErrorHandler != null) {\n        this.retryCount = replacedErrorHandler.retryCount;\n    }\n}", "CodeBleu_score": 54.698370797964444}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields)    if (configuration == null) {\n        throw new ConfigException(\"Configuration cannot be null\");\n    }\n    if (fields == null) {\n        throw new ConfigException(\"Fields cannot be null\");\n    }\n    List<ConfigException> exceptions = new ArrayList<>();\n    for (Field field : fields) {\n        List<String> errors = field.validate(configuration);\n        if (errors.size() > 0) {\n            exceptions.add(new ConfigException(field.name(), errors.get(0)));\n        }\n    }\n    if (exceptions.size() > 0) {\n        throw exceptions.get(0);\n    }\n}", "CodeBleu_score": 37.06608838278219}, {"code": "public void validate(Configuration configuration, Field.Set fields)    ValidationResult validationResult = validate(configuration, fields);\n    if (!validationResult.isValid()) {\n        throw new ConfigException(validationResult.getErrorMessages().entrySet().iterator().next().getValue().iterator().next());\n    }\n}", "CodeBleu_score": 28.539454683833764}, {"code": "public void validate(Configuration configuration, Field.Set fields)    ValidationResult validationResult = validate(configuration, fields);\n    Iterator<ValidationResult.Entry> iterator = validationResult.iterator();\n    while (iterator.hasNext()) {\n        ValidationResult.Entry entry = iterator.next();\n        if (entry.hasError()) {\n            throw new ConfigException(entry.errorMessage());\n        }\n    }\n}", "CodeBleu_score": 35.78692872098199}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level)    if (oldSchema.type() == Schema.Type.STRUCT) {\n        SchemaBuilder newSchemaBuilder = SchemaBuilder.struct();\n        for (Field field : oldSchema.fields()) {\n            String fieldName = field.name();\n            Schema fieldSchema = field.schema();\n            if (fieldSchema.type() == Schema.Type.STRUCT) {\n                Schema newFieldSchema = buildNewSchema(fieldName, fieldSchema, headerToProcess, nestedFields, level + 1);\n                newSchemaBuilder.field(fieldName, newFieldSchema);\n            } else {\n                newSchemaBuilder.field(fieldName, fieldSchema);\n            }\n        }\n        if (headerToProcess.containsKey(fieldName)) {\n            Header header = headerToProcess.get(fieldName);\n            List<String> headerFields = header.getFields();\n            for (String headerField : headerFields) {\n                if (!newSchemaBuilder.hasField(headerField)) {\n                    newSchemaBuilder.field(headerField, Schema.OPTIONAL_STRING_SCHEMA);\n                }\n            }\n        }\n        LOGGER.debug(\"Copied fields from old schema to new schema for field: {}\", fieldName);\n        return newSchemaBuilder.build();\n    } else {\n        LOGGER.debug(\"Old schema for field {} is not a struct, returning old schema\", fieldName);\n        return oldSchema;\n    }\n}", "CodeBleu_score": 39.9237219397026}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level)    if (oldSchema.type() == Schema.Type.STRING) {\n        log.debug(\"{}: String schema\", fieldName);\n        return oldSchema;\n    }\n    SchemaBuilder schemaBuilder = SchemaBuilder.struct();\n    if (oldSchema.type() == Schema.Type.ARRAY) {\n        log.debug(\"{}: Array schema\", fieldName);\n        Schema elementSchema = oldSchema.valueSchema();\n        schemaBuilder.field(fieldName, SchemaBuilder.array(buildNewSchema(fieldName, elementSchema, headerToProcess, nestedFields, level)));\n    } else if (oldSchema.type() == Schema.Type.MAP) {\n        log.debug(\"{}: Map schema\", fieldName);\n        Schema valueSchema = oldSchema.valueSchema();\n        schemaBuilder.field(fieldName, SchemaBuilder.map(Schema.STRING_SCHEMA, buildNewSchema(fieldName, valueSchema, headerToProcess, nestedFields, level)));\n    } else if (oldSchema.type() == Schema.Type.STRUCT) {\n        log.debug(\"{}: Struct schema\", fieldName);\n        SchemaBuilder.FieldAssembler<Schema> assembler = schemaBuilder.fields();\n        for (Field field : oldSchema.fields()) {\n            String nestedFieldName = field.name();\n            if (nestedFields.contains(nestedFieldName)) {\n                log.debug(\"{}: Field {} is in nested fields list\", fieldName, nestedFieldName);\n                assembler.field(nestedFieldName, buildNewSchema(nestedFieldName, field.schema(), headerToProcess, nestedFields, level + 1));\n            } else {\n                log.debug(\"{}: Field {} is not in nested fields list\", fieldName, nestedFieldName);\n                assembler.field(nestedFieldName, field.schema());\n            }\n        }\n    } else {\n        log.debug(\"{}: Other schema type: {}\", fieldName, oldSchema.type());\n        schemaBuilder.field(fieldName, oldSchema);\n    }\n    if (headerToProcess.containsKey(fieldName)) {\n        log.debug(\"{}: Adding headers for field\", fieldName);", "CodeBleu_score": 36.17218251280981}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level)    if (oldSchema.type() == Schema.Type.STRUCT) {\n        SchemaBuilder newSchemaBuilder = SchemaBuilder.struct().name(oldSchema.name());\n        for (Field field : oldSchema.fields()) {\n            String fieldName = field.name();\n            Schema fieldSchema = field.schema();\n            if (headerToProcess.containsKey(fieldName)) {\n                Header header = headerToProcess.get(fieldName);\n                if (header.schema() != null) {\n                    fieldSchema = header.schema();\n                }\n                newSchemaBuilder.field(fieldName, fieldSchema);\n                log.debug(\"Added field {} to schema {}\", fieldName, oldSchema.name());\n            } else if (fieldSchema.type() == Schema.Type.STRUCT) {\n                Schema newFieldSchema = buildNewSchema(fieldName, fieldSchema, headerToProcess, nestedFields, level + 1);\n                newSchemaBuilder.field(fieldName, newFieldSchema);\n            } else {\n                newSchemaBuilder.field(fieldName, fieldSchema);\n            }\n        }\n        Schema newSchema = newSchemaBuilder.build();\n        log.debug(\"Built schema {} from old schema {}\", newSchema.name(), oldSchema.name());\n        return newSchema;\n    } else {\n        return oldSchema;\n    }\n}\n\n}", "CodeBleu_score": 43.857462887605436}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source)  if (source == null) {\n    return null;\n  }\n  Schema sourceSchema = source.schema();\n  if (sourceSchema.field(SnapshotRecord.SNAPSHOT_KEY_FIELD) == null) {\n    return null;\n  }\n  String snapshotString = source.getString(SnapshotRecord.SNAPSHOT_KEY_FIELD);\n  if (snapshotString != null) {\n    snapshotString = snapshotString.toUpperCase();\n    for (    SnapshotRecord record : SnapshotRecord.values()) {\n      if (record.name().equals(snapshotString)) {\n        return record;\n      }\n    }\n  }\n  return null;\n}", "CodeBleu_score": 50.94816655099902}, {"code": "public static SnapshotRecord fromSource(Struct source)  if (source == null || !source.schema().field(SNAPSHOT_KEY).schema().name().equals(SNAPSHOT_KEY)) {\n    return null;\n  }\n  String snapshotString=source.getString(SNAPSHOT_KEY);\n  if (snapshotString != null) {\n    snapshotString=snapshotString.toUpperCase();\n    if (SnapshotRecord.contains(snapshotString)) {\n      return SnapshotRecord.valueOf(snapshotString);\n    }\n  }\n  return null;\n}", "CodeBleu_score": 47.53795131603468}, {"code": "public static SnapshotRecord fromSource(Struct source)  if (source == null || source.schema() == null || source.schema().field(SnapshotRecord.SNAPSHOT_KEY) == null) {\n    return null;\n  }\n  String snapshotString=source.getString(SnapshotRecord.SNAPSHOT_KEY);\n  if (snapshotString != null) {\n    snapshotString=snapshotString.toUpperCase();\n  }\n  return SnapshotRecord.valueOf(snapshotString);\n}", "CodeBleu_score": 51.85626647521575}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException    try {\n        String[] parts = version.split(\"\\\\.\");\n        if (parts.length > 2) {\n            parts = Arrays.copyOfRange(parts, 0, 2);\n        }\n        String versionString = parts[0];\n        if (parts.length > 1) {\n            versionString += \".\" + parts[1];\n        }\n        return Optional.of(Float.parseFloat(versionString));\n    } catch (Exception e) {\n        return Optional.empty();\n    }\n}", "CodeBleu_score": 65.4159456411507}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException  try {\n    String[] parts=version.split(\"\\\\.\");\n    if (parts.length > 2)     parts=new String[]{parts[0],parts[1]};\n    String[] subparts=parts[0].split(\"-\");\n    return Optional.of(Float.parseFloat(subparts[0]));\n  }\n catch (  NumberFormatException e) {\n    return Optional.empty();\n  }\n}", "CodeBleu_score": 59.724644741374696}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException  try {\n    String[] parts=version.split(\"\\\\.\");\n    if (parts.length > 2)     parts=new String[]{parts[0],parts[1]};\n    String[] subParts=parts[0].split(\"-\");\n    return Optional.of(Float.parseFloat(subParts[0]));\n  }\n catch (  NumberFormatException e) {\n    return Optional.empty();\n  }\n}", "CodeBleu_score": 59.724644741374696}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange)    AccessContext context = accessContext()\n            .cluster(clusterName)\n            .namespace(NAMESPACE_SERVICE)\n            .operation(OP_CREATE)\n            .parameters(Map.of(\"connectName\", connectName))\n            .resource(Resource.connector(connectName))\n            .build();\n\n    return validateAccess(context)\n            .flatMap(access -> kafkaConnectService.createConnector(clusterName, connectName, connector))\n            .map(ResponseEntity::ok)\n            .doOnEach(audit.signal(Level.INFO, context));\n}", "CodeBleu_score": 52.558953980255374}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange)    AccessContext context = accessManager.createContext(exchange);\n    context.checkGlobalPermission(CREATE_CONNECTOR);\n\n    return connector\n            .flatMap(connectorDTO -> {\n                Cluster cluster = clusterService.validateAndGetCluster(clusterName, context);\n                Connect connect = connectService.validateAndGetConnect(connectName, cluster, context);\n                return kafkaConnectService.createConnector(connect, connectorDTO, context)\n                        .map(created -> new ResponseEntity<>(created, HttpStatus.CREATED));\n            })\n            .doOnSuccess(response -> auditConnector(context, CREATE_CONNECTOR));\n}\n", "CodeBleu_score": 37.66849628354755}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange)    AccessContext context = accessManager.createContext(clusterName, connectName);\n    return accessManager.validateAccess(CREATE_CONNECTOR, context).then(kafkaConnectService.createConnector(context, connector))\n            .map(ResponseEntity::ok)\n            .doOnNext(response -> auditService.audit(context, signal -> signal\n                    .setAction(CREATE_CONNECTOR)\n                    .setResource(connector.map(NewConnectorDTO::getName).orElse(null))\n                    .setResult(response.getStatusCode())))\n            .onErrorResume(e -> Mono.just(ResponseEntity.status(e.getStatus()).build()));\n}\n", "CodeBleu_score": 33.099755629388945}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange)    AccessContext accessContext = accessControlService.buildAccessContext(exchange,\n            clusterName, connectName, KafkaConnectAction.DELETE_CONNECTOR, connectorName);\n    return accessControlService.validateAccess(accessContext)\n            .flatMap(validationResult -> {\n                if (validationResult.isAllowed()) {\n                    return kafkaConnectService.deleteConnector(clusterName, connectName, connectorName)\n                            .map(ResponseEntity::ok);\n                } else {\n                    return Mono.just(ResponseEntity.status(HttpStatus.FORBIDDEN).build());\n                }\n            })\n            .doOnSuccess(response -> auditService.audit(exchange, response));\n}", "CodeBleu_score": 32.39840756607579}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange)    AccessContext accessContext = accessManager.createContext(clusterName, connectName);\n    accessContext.checkPermission(Action.DELETE_CONNECTOR);\n    return kafkaConnectService.deleteConnector(clusterName, connectName, connectorName)\n        .map(ResponseEntity::ok)\n        .doOnSuccess(response -> auditService.audit(clusterName, Action.DELETE_CONNECTOR,\n            exchange.getRequest().getPath().value(), connectorName));\n}", "CodeBleu_score": 33.14733563576987}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange)    AccessContext accessContext = accessManager.createContext(clusterName, connectName);\n    accessContext.checkAccess(Action.WRITE);\n    return kafkaConnectService.deleteConnector(clusterName, connectName, connectorName)\n            .map(ResponseEntity::ok)\n            .doOnSuccess(r -> auditService.audit(exchange, auditEventType, accessContext));\n}", "CodeBleu_score": 29.307254131479056}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange)     return kafkaConnectService.updateConnectorState(clusterName, connectName, connectorName, action)\n            .doOnEach(auditOnNext(exchange,\n                    new AccessContext(clusterName, connectName, connectorName, action.getAction(),\n                            \"updateConnectorState\")))\n            .doOnError(auditOnError(exchange,\n                    new AccessContext(clusterName, connectName, connectorName, action.getAction(),\n                            \"updateConnectorState\")))\n            .map(ResponseEntity::ok);\n}", "CodeBleu_score": 23.169303691671583}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange)   return Mono.just(buildAccessContext(clusterName, connectName, action, \"update-connector-state\",\n      Map.of(\"connectorName\", connectorName)))\n      .flatMap(accessContext -> validateAccess(accessContext, exchange))\n      .flatMap(accessContext -> kafkaConnectService.updateConnectorState(accessContext, connectorName,\n          action.getConfig()))\n      .map(ResponseEntity::ok)\n      .doOnEach(AuditUtil::audit);\n}", "CodeBleu_score": 21.01422517329354}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange)     return Mono.just(accessControlService.validateAccess(\n            new AccessContext(clusterName, connectName, null,\n                    Collections.singletonList(action.getAction()),\n                    \"updateConnectorState\",\n                    new HashMap<>() {{\n                        put(\"connectorName\", connectorName);\n                        put(\"action\", action.getAction());\n                    }})))\n            .flatMap(accessContext -> kafkaConnectService.updateConnectorState(clusterName, connectName, connectorName, action))\n            .doOnNext(responseEntity -> auditService.audit(clusterName, connectName, \"updateConnectorState\", exchange))\n            .doOnError(throwable -> auditService.audit(clusterName, connectName, \"updateConnectorState\", exchange, throwable));\n}", "CodeBleu_score": 24.42186236237238}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig  return kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, requestBody)\n    .map(result -> new ResponseEntity<>(result, HttpStatus.OK));\n}", "CodeBleu_score": 25.176869908208232}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig    return kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, requestBody)\n            .map(ResponseEntity::ok);\n}\n", "CodeBleu_score": 29.296853024622465}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig    return kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, requestBody)\n            .map(ResponseEntity::ok);\n}", "CodeBleu_score": 29.296853024622465}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args)    return new SpringApplicationBuilder(KafkaUiApplication.class).initializers(new DynamicPropertyContextInitializer()).run(args);\n}", "CodeBleu_score": 30.389581447448162}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args)  SpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n  builder.initializers(new KafkaUiApplicationInitializer());\n  return builder.run(args);\n}", "CodeBleu_score": 43.08876250025107}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args)    SpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n    builder.initializers(new DynamicConfigInitializer());\n    return builder.run(args);\n}", "CodeBleu_score": 44.97987164395872}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search)    if (search == null) {\n        return connector -> true;\n    }\n    final String lowerSearch = search.toLowerCase();\n    return connector -> Stream.of(connector.getName(), connector.getDescription(), connector.getType(), connector.getBundle().getGroup(), connector.getBundle().getArtifact())\n        .anyMatch(s -> s.toLowerCase().contains(lowerSearch));\n}", "CodeBleu_score": 50.281174588031305}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search)    if (search == null) {\n        return connector -> true;\n    }\n    final String lowerCaseSearch = search.toLowerCase();\n    return connector -> Stream.of(connector.getName(), connector.getType(), connector.getDescription()).anyMatch(s -> s != null && s.toLowerCase().contains(lowerCaseSearch));\n}", "CodeBleu_score": 51.8586734710754}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search)    if (search == null) {\n        return connector -> true;\n    }\n    final String lowercaseSearch = search.toLowerCase();\n    return connector -> Arrays.stream(connector.getConnector().getType().toString().split(\"_\")).anyMatch(s -> s.toLowerCase().contains(lowercaseSearch))\n            || Arrays.stream(connector.getConnector().getName().split(\" \")).anyMatch(s -> s.toLowerCase().contains(lowercaseSearch));\n}", "CodeBleu_score": 49.033184649962905}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap)    Map<String, Object> flattenedMap = new HashMap<>();\n    if (propertiesMap != null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = prefix == null ? entry.getKey() : prefix + \".\" + entry.getKey();\n        if (entry.getValue() instanceof Map) {\n          flattenedMap.putAll(flattenClusterProperties(key, (Map<String, Object>) entry.getValue()));\n        } else {\n          flattenedMap.put(key, entry.getValue());\n        }\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 51.335522189087676}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap)    Map<String, Object> flattened = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattened;\n    }\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = prefix == null ? entry.getKey() : prefix + \".\" + entry.getKey();\n      if (entry.getValue() instanceof Map) {\n        flattened.putAll(flattenClusterProperties(key, (Map<String, Object>) entry.getValue()));\n      } else {\n        flattened.put(key, entry.getValue());\n      }\n    }\n    return flattened;\n  }\n\n  /**\n * The flattenClusterProperties function recursively flattens a nested map of cluster properties.\\nIt takes an optional prefix and a properties map, initializing an empty map for the flattened result.\\nFor each entry in the properties map, it constructs a new key by combining the prefix and the current key.\\nIf the value is another map, it recursively flattens it with the new key as the prefix.\\nOtherwise, it adds the key-value pair to the flattened map.\\nFinally, it returns the flattened map.\n */\n  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap) {\n    Map<String, Object> flattened = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattened;\n    }\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = prefix == null ? entry.getKey() : prefix + \".\" + entry.getKey();\n      if (entry.getValue() instanceof Map) {\n        flattened.putAll(flattenClusterProperties(key, (Map<String, Object>) entry.getValue()));\n      } else {\n        flattened.put(key, entry.getValue());\n      }\n    }\n    return flattened;\n  }\n\n  /**\n * The flattenClusterProperties function recursively flattens a nested map of cluster properties.\\nIt takes an optional prefix and a properties map, initializing an empty", "CodeBleu_score": 45.242788335911946}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap)    Map<String, Object> flattened = new HashMap<>();\n    if (propertiesMap != null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = prefix != null ? prefix + \".\" + entry.getKey() : entry.getKey();\n        Object value = entry.getValue();\n        if (value instanceof Map) {\n          flattened.putAll(flattenClusterProperties(key, (Map<String, Object>) value));\n        } else {\n          flattened.put(key, value);\n        }\n      }\n    }\n    return flattened;\n  }\n\n  /**\n   * The flattenClusterProperties function takes a ClusterProperties object and returns a flattened map of its properties.\\nIt first retrieves the cluster properties from the ClusterProperties object using the getProperties method.\\nIt then calls the flattenClusterProperties function with an empty prefix and the retrieved properties to flatten the properties.\\nFinally, it returns the flattened map.\n   */\n  public Map<String, Object> flattenClusterProperties(ClusterProperties clusterProperties) {\n    Map<String, Object> propertiesMap = clusterProperties.getProperties();\n    return flattenClusterProperties(null, propertiesMap);\n  }\n\n  /**\n   * The flattenClusterProperties function takes a ClusterProperties object and returns a flattened map of its properties.\\nIt first retrieves the cluster properties from the ClusterProperties object using the getProperties method.\\nIt then calls the flattenClusterProperties function with an empty prefix and the retrieved properties to flatten the properties.\\nFinally, it returns the flattened map.\n   */\n  public Map<String, Object> flattenClusterProperties(ClusterProperties clusterProperties) {\n    Map<String, Object> propertiesMap = clusterProperties.getProperties();\n    return flattenClusterProperties(null, propertiesMap);\n  }\n\n  /**\n   * The flattenClusterProperties function takes a ClusterProperties object and returns a flattened map of its properties.\\nIt first retrieves the cluster properties from the ClusterProperties object using the getProperties method.\\nIt then calls the flattenClusterProperties function with an empty prefix and the retrieved properties to flatten the properties", "CodeBleu_score": 49.50915436819046}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize()  final ConfigDef configDef = new ConfigDef();\n  KafkaConfig.addSslConfig(configDef);\n  KafkaConfig.addSaslConfig(configDef);\n  return configDef.configKeys().stream()\n    .filter(k -> configDef.get(k).type() == ConfigDef.Type.PASSWORD)\n    .collect(Collectors.toSet());\n}\n", "CodeBleu_score": 66.80188113371644}, {"code": " private static Set<String> kafkaConfigKeysToSanitize()    final ConfigDef configDef = new ConfigDef();\n    KafkaConfig.addSslConfig(configDef);\n    KafkaConfig.addSaslConfig(configDef);\n    return configDef.configKeys().stream()\n            .filter(configKey -> configKey.type == ConfigDef.Type.PASSWORD)\n            .map(ConfigKey::name)\n            .collect(Collectors.toSet());\n}", "CodeBleu_score": 68.29474139608477}, {"code": " private static Set<String> kafkaConfigKeysToSanitize()    final ConfigDef configDef = new ConfigDef();\n    SSLConfigs.addClientConfig(configDef, true);\n    SaslConfigs.addClientConfig(configDef, true);\n    return configDef.configKeys().stream()\n            .filter(key -> configDef.get(key).type() == ConfigDef.Type.PASSWORD)\n            .collect(Collectors.toSet());\n}\n", "CodeBleu_score": 67.83539125361592}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription)    return Mono.just(clusterDescription)\n        .filter(clusterDescription1 -> clusterDescription1.authorizedOperations().contains(AuthorizedOperation.ALL) || clusterDescription1.authorizedOperations().contains(AuthorizedOperation.ALTER))\n        .filter(clusterDescription1 -> clusterDescription1.features().containsKey(KAFKA_ACL_EDIT))\n        .map(clusterDescription1 -> new ClusterFeature(clusterDescription1.clusterId(), KAFKA_ACL_EDIT, clusterDescription1.features().get(KAFKA_ACL_EDIT)));\n}", "CodeBleu_score": 29.702770597326754}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription)  return Mono.just(clusterDescription)\n    .filter(cd -> cd.acls().isEmpty() || cd.acls().stream().allMatch(acl -> acl.operation() == AclOperation.ANY || acl.operation() == AclOperation.ALTER))\n    .filter(cd -> cd.features().contains(KAFKA_ACL_VIEW))\n    .map(cd -> KAFKA_ACL_EDIT);\n}", "CodeBleu_score": 26.70643003726077}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription)  return Mono.just(clusterDescription).flatMap(cluster -> {\n    if (cluster.getAuthorizedOperations().contains(AclOperation.ALTER) || cluster.getAuthorizedOperations().contains(AclOperation.ALL)) {\n      return adminClient.describeCluster(cluster.getClusterId()).map(clusterDescription -> {\n        if (clusterDescription.getFeatures().contains(KAFKA_ACL_EDIT)) {\n          return KAFKA_ACL_EDIT;\n        }\n        return null;\n      });\n    }\n    return Mono.empty();\n  });\n}", "CodeBleu_score": 31.82591586480511}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations)    TreeMap<TopicPartition, FromToOffset> range = new TreeMap<>();\n\n    // Initialize the range from the previous range or seek operations\n    for (TopicPartition partition : seekOperations.offsets().keySet()) {\n        FromToOffset prev = prevRange.get(partition);\n        FromToOffset seek = seekOperations.offsets().get(partition);\n        if (prev != null) {\n            range.put(partition, prev);\n        } else if (seek != null) {\n            range.put(partition, seek);\n        } else {\n            range.put(partition, new FromToOffset(0, 0));\n        }\n    }\n\n    // Calculate the number of messages to poll per partition\n    int messagesPerPartition = calculateMessagesPerPartition(range);\n\n    // Adjust the start offset for each partition\n    for (Map.Entry<TopicPartition, FromToOffset> entry : range.entrySet()) {\n        TopicPartition partition = entry.getKey();\n        FromToOffset offsets = entry.getValue();\n\n        // Adjust the start offset based on the number of messages to poll\n        long startOffset = offsets.fromOffset;\n        startOffset = Math.max(startOffset - messagesPerPartition, 0);\n\n        // Update the range with the adjusted start offset\n        range.put(partition, new FromToOffset(startOffset, offsets.toOffset));\n    }\n\n    return range;\n}", "CodeBleu_score": 35.52170580948406}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations)    TreeMap<TopicPartition, FromToOffset> range = new TreeMap<>();\n    for (TopicPartition tp : seekOperations.getSeekOperations().keySet()) {\n        range.put(tp, new FromToOffset(seekOperations.getSeekOperations().get(tp), seekOperations.getSeekOperations().get(tp)));\n    }\n\n    if (prevRange != null && !prevRange.isEmpty()) {\n        for (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\n            if (!range.containsKey(entry.getKey())) {\n                range.put(entry.getKey(), entry.getValue());\n            }\n        }\n    }\n\n    int messagesToPoll = (int) Math.ceil((double) pollIntervalMs / (double) pollTimeoutMs);\n    for (TopicPartition tp : range.keySet()) {\n        long startOffset = range.get(tp).getFromOffset();\n        if (startOffset == -1) {\n            startOffset = seekOperations.getBeginningOffsets().get(tp);\n        }\n        long endOffset = startOffset + messagesToPoll;\n        range.put(tp, new FromToOffset(startOffset, endOffset));\n    }\n    return range;\n}", "CodeBleu_score": 36.675493030666026}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations)    // Initialize the map of offsets to read from based on the previous range or the offsets from seek operations\n    TreeMap<TopicPartition, FromToOffset> range = new TreeMap<>(prevRange);\n    if (range.isEmpty()) {\n        range.putAll(seekOperations.getSeekOffsets());\n    }\n\n    // Calculate the number of messages to poll per partition\n    int messagesToPoll = (int) (maxPollRecords * (1 + (random.nextFloat() * maxPollRecordsJitter)));\n\n    // Determine the start offset for each topic partition\n    for (Map.Entry<TopicPartition, FromToOffset> entry : range.entrySet()) {\n        TopicPartition topicPartition = entry.getKey();\n        FromToOffset fromToOffset = entry.getValue();\n\n        // Adjust the start offset based on the number of messages to poll, ensuring it does not go below the beginning offset\n        long startOffset = Math.max(fromToOffset.fromOffset, fromToOffset.toOffset - messagesToPoll);\n\n        // Update the map of offsets to read from\n        range.put(topicPartition, new FromToOffset(startOffset, fromToOffset.toOffset));\n    }\n\n    return range;\n}", "CodeBleu_score": 36.335492118145}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input)    // Check if legacy mode is enabled and validate the configuration settings for ZooKeeper or bootstrap servers\n    if (legacyMode) {\n        if (input instanceof ZooKeeperMessageInput) {\n            // Validate ZooKeeper configuration settings\n            validateZooKeeperConfig();\n        } else if (input instanceof KafkaMessageInput) {\n            // Validate bootstrap servers configuration settings\n            validateBootstrapServersConfig();\n        }\n    }\n\n    // Wait for the server to be running\n    waitForServerRunning();\n\n    // Register for server lifecycle events\n    registerServerLifecycleListener();\n\n    // Launch the legacy input or a consumer input based on the mode\n    if (legacyMode) {\n        launchLegacyInput(input);\n    } else {\n        launchConsumerInput(input);\n    }\n\n    // Schedule a task to update the last second bytes read every second\n    scheduleUpdateLastSecondBytesRead();\n}\n", "CodeBleu_score": 18.62288704906329}, {"code": "public void doLaunch(final MessageInput input)    if (legacyMode) {\n        if (kafkaZooKeeperConnect == null || kafkaZooKeeperConnect.isEmpty()) {\n            throw new IllegalArgumentException(\"ZooKeeper connection string is required for legacy mode\");\n        }\n        if (kafkaZooKeeperSessionTimeout == null) {\n            throw new IllegalArgumentException(\"ZooKeeper session timeout is required for legacy mode\");\n        }\n        if (kafkaZooKeeperSyncTime == null) {\n            throw new IllegalArgumentException(\"ZooKeeper sync time is required for legacy mode\");\n        }\n        if (kafkaGroupId == null || kafkaGroupId.isEmpty()) {\n            throw new IllegalArgumentException(\"Group ID is required for legacy mode\");\n        }\n        if (kafkaTopic == null || kafkaTopic.isEmpty()) {\n            throw new IllegalArgumentException(\"Topic is required for legacy mode\");\n        }\n    } else {\n        if (kafkaBootstrapServers == null || kafkaBootstrapServers.isEmpty()) {\n            throw new IllegalArgumentException(\"Bootstrap servers are required for new mode\");\n        }\n        if (kafkaGroupId == null || kafkaGroupId.isEmpty()) {\n            throw new IllegalArgumentException(\"Group ID is required for new mode\");\n        }\n        if (kafkaTopic == null || kafkaTopic.isEmpty()) {\n            throw new IllegalArgumentException(\"Topic is required for new mode\");\n        }\n    }\n    // Wait for server to be running\n    waitForServerRunning();\n    // Register for server lifecycle events\n    registerForServerLifecycleEvents();\n    // Launch the input\n    if (legacyMode) {\n        launchLegacyInput(input);\n    } else {\n        launchConsumerInput(input);\n    }\n    // Schedule a task to update the last second bytes read every second\n    executor.scheduleAtFixedRate(new Runnable() {\n        @Override\n        public void run() {\n            updateLastSecondBytesRead();\n        }\n    }, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 28.317848078364715}, {"code": "public void doLaunch(final MessageInput input)  if (isLegacyMode()) {\n    validateLegacyMode();\n  }\n  else {\n    validateKafkaMode();\n  }\n  // wait for server to be running\n  server.waitForRunning();\n  server.registerLifecycleListener(new LifecycleListener() {\n\n    @Override\n    public void onStart(LifecycleEvent event) {\n      // do nothing\n    }\n\n    @Override\n    public void onStop(LifecycleEvent event) {\n      if (event.getState() == LifecycleState.STOPPING) {\n        input.stop();\n      }\n    }\n  });\n  if (isLegacyMode()) {\n    input.launch();\n  }\n  else {\n    input.launchConsumer();\n  }\n  // schedule a task to update the last second bytes read every second\n  scheduler.scheduleAtFixedRate(new Runnable() {\n\n    @Override\n    public void run() {\n      updateLastSecondBytesRead();\n    }\n  }, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 20.923152462861204}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props)    try {\n        String config = System.getProperty(\"config\");\n        if (config != null) {\n            Properties customProps = new Properties();\n            customProps.load(new StringReader(config));\n            props.putAll(customProps);\n        }\n    } catch (IOException e) {\n        logger.error(\"Failed to load custom properties\", e);\n    }\n}", "CodeBleu_score": 49.87309368090534}, {"code": "private void insertCustomProperties(Properties props)    try {\n        String customPropertiesString = getCustomPropertiesString();\n        Properties customProperties = new Properties();\n        customProperties.load(new StringReader(customPropertiesString));\n        props.putAll(customProperties);\n    } catch (IOException e) {\n        LOG.error(\"Error loading custom properties\", e);\n    }\n}", "CodeBleu_score": 51.634955133246606}, {"code": "private void insertCustomProperties(Properties props)    try {\n        String customProperties = System.getProperty(\"custom.properties\");\n        if (customProperties != null) {\n            Properties customProps = new Properties();\n            customProps.load(new StringReader(customProperties));\n            props.putAll(customProps);\n        }\n    } catch (IOException e) {\n        logger.error(\"Failed to load custom properties\", e);\n    }\n}", "CodeBleu_score": 49.22396374559146}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException  if (entries == null || entries.isEmpty()) {\n    return;\n  }\n  List<RawMessageEvent> nonNullEntries=entries.stream().filter(Objects::nonNull).collect(Collectors.toList());\n  if (nonNullEntries.isEmpty()) {\n    return;\n  }\n  List<JournalEntry> journalEntries=nonNullEntries.stream().map(e -> new JournalEntry(e.getPartitionId(),e.getOffset(),e.getBody())).collect(Collectors.toList());\n  long totalBytes=journalEntries.stream().mapToLong(e -> e.getBody().length).sum();\n  int retries=0;\n  while (true) {\n    try {\n      journal.write(journalEntries);\n      break;\n    }\n catch (    IOException e) {\n      if (retries >= maxRetries) {\n        throw new MessageQueueException(String.format(\"Failed to write %d entries to journal after %d retries\",journalEntries.size(),retries),e);\n      }\n      retries++;\n      try {\n        Thread.sleep((long)Math.pow(2,retries) * 1000);\n      }\n catch (      InterruptedException ex) {\n        Thread.currentThread().interrupt();\n        throw new MessageQueueException(String.format(\"Failed to write %d entries to journal after %d retries\",journalEntries.size(),retries),ex);\n      }\n    }\n  }\n  writtenMessages.addAndGet(nonNullEntries.size());\n  writtenBytes.addAndGet(totalBytes);\n}", "CodeBleu_score": 43.54938519856202}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException    if (entries == null) {\n        return;\n    }\n    List<JournalEntry> journalEntries = entries.stream().filter(Objects::nonNull).map(this::mapToJournalEntry).collect(Collectors.toList());\n    long totalBytes = journalEntries.stream().mapToLong(JournalEntry::getBytes).sum();\n    int attempt = 1;\n    while (true) {\n        try {\n            journal.write(journalEntries);\n            break;\n        } catch (JournalException e) {\n            if (attempt >= maxRetries) {\n                throw new MessageQueueException(String.format(\"Failed to write %d entries to journal after %d attempts\", journalEntries.size(), attempt), e);\n            }\n            attempt++;\n            try {\n                Thread.sleep((long) (Math.pow(2, attempt) * 1000));\n            } catch (InterruptedException ex) {\n                Thread.currentThread().interrupt();\n                throw new MessageQueueException(\"Interrupted while waiting for retry\", ex);\n            }\n        }\n    }\n    writtenMessages.addAndGet(journalEntries.size());\n    writtenBytes.addAndGet(totalBytes);\n}", "CodeBleu_score": 41.587042828712335}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException  int totalBytes = 0;\n  List<JournalEntry> journalEntries = new ArrayList<>(entries.size());\n  for (RawMessageEvent entry : entries) {\n    if (entry == null) {\n      continue;\n    }\n    journalEntries.add(entry.toJournalEntry());\n    totalBytes += entry.getData().length;\n  }\n  if (journalEntries.isEmpty()) {\n    return;\n  }\n  int attempt = 0;\n  while (true) {\n    try {\n      journal.write(journalEntries);\n      break;\n    }\n catch (    IOException e) {\n      if (attempt >= maxWriteAttempts) {\n        throw new MessageQueueException(\"Failed to write messages after \" + maxWriteAttempts + \" attempts\", e);\n      }\n      attempt++;\n      try {\n        Thread.sleep((long) Math.pow(2, attempt) * 1000);\n      }\n catch (      InterruptedException e1) {\n        throw new MessageQueueException(\"Interrupted while waiting for write retry\", e1);\n      }\n    }\n  }\n  messagesWritten.mark(journalEntries.size());\n  bytesWritten.mark(totalBytes);\n}", "CodeBleu_score": 32.121727073040965}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages)    Optional<Integer> maxMessageQueueId = messages.stream().map(Message::getMessageQueueId).max(Integer::compareTo);\n    if (maxMessageQueueId.isPresent()) {\n        metrics.markAcknowledgedMessages(maxMessageQueueId.get());\n    }\n}", "CodeBleu_score": 33.40780139107444}, {"code": "public void acknowledge(List<Message> messages)    // Identify the maximum valid message queue ID from the list of messages\n    int maxQueueId = messages.stream()\n        .filter(message -> message.getQueueId() <= MAX_QUEUE_ID)\n        .mapToInt(Message::getQueueId)\n        .max()\n        .orElse(0);\n\n    // Acknowledge the maximum valid message queue ID if present\n    if (maxQueueId > 0) {\n        acknowledge(maxQueueId);\n    }\n\n    // Update the metrics by marking the number of acknowledged messages\n    metrics.mark(messages.size());\n}\n", "CodeBleu_score": 46.78420717504746}, {"code": "public void acknowledge(List<Message> messages)    int maxValidMessageQueueId = getMaxValidMessageQueueId(messages);\n    if (maxValidMessageQueueId > 0) {\n        this.messageQueue.acknowledge(maxValidMessageQueueId);\n    }\n    this.metrics.incrementAcknowledgeCount(messages.size());\n}\n", "CodeBleu_score": 19.245450129463755}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics()  metricRegistry.getMetrics().entrySet().stream().filter(entry -> entry.getKey().startsWith(LocalKafkaJournal.class.getName())).forEach(entry -> {\n    String legacyName=entry.getKey().replace(LocalKafkaJournal.class.getName(),\"kafka.journal\");\n    try {\n      metricRegistry.register(legacyName,entry.getValue());\n    }\n catch (    IllegalArgumentException e) {\n      log.warn(\"Unable to register legacy metric {} under new name {}\",entry.getKey(),legacyName);\n    }\n  }", "CodeBleu_score": 51.20002347978003}, {"code": "private void registerLegacyMetrics()  for (String metricName : metricRegistry.getMetrics().keySet()) {\n    if (metricName.startsWith(LocalKafkaJournal.class.getName())) {\n      String legacyName=metricName.replace(LocalKafkaJournal.class.getName(),\"org.apache.hadoop.hdfs.server.namenode.kafka.LocalKafkaJournal\");\n      try {\n        metricRegistry.register(legacyName,metricRegistry.getMetrics().get(metricName));\n      }\n catch (      IllegalArgumentException e) {\n        LOG.warn(\"Unable to register legacy metric {} under name {}\",metricName,legacyName);\n      }\n    }\n  }\n}", "CodeBleu_score": 40.82541404631293}, {"code": "private void registerLegacyMetrics()  metricRegistry.getMetrics().entrySet().stream().filter(entry -> entry.getKey().startsWith(LocalKafkaJournal.class.getName())).forEach(entry -> {\n    String legacyName=entry.getKey().replace(LocalKafkaJournal.class.getName(),\"kafka.server.LocalKafkaJournal\");\n    try {\n      metricRegistry.register(legacyName,entry.getValue());\n    }\n catch (    Exception e) {\n      log.warn(\"Failed to register legacy metric {} under new name {}\",entry.getKey(),legacyName,e);\n    }\n  }", "CodeBleu_score": 48.73845328455659}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName)  try {\n    return metricRegistry.timer(metricName);\n  }\n catch (  IllegalArgumentException e) {\n    return metricRegistry.getTimers().get(metricName);\n  }\n}", "CodeBleu_score": 17.51851352210746}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName)  try {\n    return metricRegistry.register(metricName, new HdrTimer());\n  }\n catch (  IllegalArgumentException e) {\n    return metricRegistry.getTimers().get(metricName);\n  }\n}", "CodeBleu_score": 18.454985515423346}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName)  try {\n    return metricRegistry.timer(metricName);\n  }\n catch (  IllegalArgumentException e) {\n    return metricRegistry.getTimers().get(metricName);\n  }\n}", "CodeBleu_score": 17.51851352210746}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name)  try {\n    metricRegistry.register(name, (Gauge<Integer>) () -> {\n      if (size == 0) {\n        return 0;\n      }\n      if (committedOffset == -1) {\n        return (int) (logEndOffset - logStartOffset);\n      }\n      return (int) (logEndOffset - committedOffset);\n    });\n  }\n catch (  IllegalArgumentException e) {\n  }\n}", "CodeBleu_score": 36.32858365442389}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name)  try {\n    metricRegistry.register(name, new Gauge<Integer>() {\n      @Override\n      public Integer getValue() {\n        return uncommitted;\n      }\n    });\n  }\n catch (  IllegalArgumentException e) {\n  }\n}", "CodeBleu_score": 26.67974386694114}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name)  try {\n    metricRegistry.register(name, new Gauge<Integer>() {\n      @Override\n      public Integer value() {\n        if (size == 0) {\n          return 0;\n        }\n        if (committedOffset == -1) {\n          return logEndOffset - logStartOffset;\n        }\n        return logEndOffset - committedOffset;\n      }\n    });\n  }\n catch (  IllegalArgumentException e) {\n  }\n}", "CodeBleu_score": 48.09160323926931}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize)    if (messages.isEmpty()) {\n        log.debug(\"No messages to flush\");\n        return -1;\n    }\n\n    ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n    log.trace(\"Flushing {} messages with {} bytes\", messageSet.sizeInBytes(), payloadSize);\n\n    // append the messages to the log\n    long lastOffset = append(messageSet);\n\n    log.trace(\"Flushed {} messages with {} bytes to offset {}\", messageSet.sizeInBytes(), payloadSize, lastOffset);\n    metrics.recordBytesWritten(payloadSize);\n    metrics.recordMessagesWritten(messages.size());\n    return lastOffset;\n}", "CodeBleu_score": 39.775877984762296}, {"code": "private long flushMessages(List<Message> messages, long payloadSize)    if (messages.isEmpty()) {\n        logger.debug(\"No messages to flush\");\n        return -1;\n    }\n    ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n    logger.trace(\"Flushing {} messages with size {}\", messages.size(), payloadSize);\n    long lastOffset = appender.append(messageSet);\n    logger.debug(\"Flushed {} messages with size {}\", messages.size(), payloadSize);\n    appender.markWritten(messages.size());\n    return lastOffset;\n}", "CodeBleu_score": 37.964218988150456}, {"code": "private long flushMessages(List<Message> messages, long payloadSize)    if (messages.isEmpty()) {\n        log.debug(\"No messages to flush\");\n        return -1;\n    }\n    ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n    log.debug(\"Writing {} messages with size {} to log {}\", messageSet.size(), payloadSize, log.name());\n    long lastOffset = log.append(messageSet);\n    log.markNumMessagesWritten(messageSet.size());\n    log.debug(\"Wrote messages with size {} to log {} at offset {}\", payloadSize, log.name(), lastOffset);\n    return lastOffset;\n}", "CodeBleu_score": 36.76349661075099}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId)   synchronized (kafkaAdminClientMap) {\n    List<AdminClient> clients = kafkaAdminClientMap.get(clusterPhyId);\n    if (clients == null) {\n      return;\n    }\n    log.info(\"[KafkaAdminClient] Start closing kafka admin client for cluster {}\", clusterPhyId);\n    boolean success = true;\n    for (AdminClient client : clients) {\n      try {\n        client.close();\n      }\n catch (      Exception e) {\n        log.error(\"[KafkaAdminClient] Failed to close kafka admin client for cluster {}\", clusterPhyId, e);\n        success = false;\n      }\n    }\n    if (success) {\n      log.info(\"[KafkaAdminClient] Successfully closed kafka admin client for cluster {}\", clusterPhyId);\n    }\n else {\n      log.error(\"[KafkaAdminClient] Failed to close kafka admin client for cluster {}\", clusterPhyId);\n    }\n    kafkaAdminClientMap.remove(clusterPhyId);\n  }\n}", "CodeBleu_score": 50.19141911631687}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId)   lock.lock();\n  try {\n    List<AdminClient> clients=clientMap.get(clusterPhyId);\n    if (clients == null || clients.isEmpty()) {\n      return;\n    }\n    logger.info(\"start to close kafka admin client for cluster:{}\",clusterPhyId);\n    for (    AdminClient client : clients) {\n      try {\n        client.close();\n      }\n catch (      Exception e) {\n        logger.error(\"close kafka admin client failed\",e);\n      }\n    }\n    logger.info(\"close kafka admin client success\");\n  }\n  finally {\n    lock.unlock();\n  }\n}", "CodeBleu_score": 36.92955369700986}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId)     try {\n        lock.lock();\n        List<AdminClient> adminClients = adminClientMap.get(clusterPhyId);\n        if (CollectionUtils.isEmpty(adminClients)) {\n            return;\n        }\n        LOGGER.info(\"start to close kafka admin client for clusterId:{}\", clusterPhyId);\n        boolean success = true;\n        for (AdminClient adminClient : adminClients) {\n            try {\n                adminClient.close();\n            } catch (Exception e) {\n                success = false;\n                LOGGER.error(\"close kafka admin client error\", e);\n            }\n        }\n        if (success) {\n            LOGGER.info(\"close kafka admin client success for clusterId:{}\", clusterPhyId);\n        }\n    } finally {\n        lock.unlock();\n    }\n}", "CodeBleu_score": 51.68351288952226}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList)    if (adminClientList == null) {\n        return true;\n    }\n    boolean success = true;\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(30, TimeUnit.SECONDS);\n        } catch (Exception e) {\n            LOGGER.error(\"[closeAdminClientList] close adminClient failed, clusterPhyId:{}\", clusterPhyId, e);\n            success = false;\n        }\n    }\n    return success;\n}", "CodeBleu_score": 73.30168895060409}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList)    boolean success = true;\n    if (adminClientList == null) {\n        return true;\n    }\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30));\n        } catch (Exception e) {\n            log.error(\"close admin client error\", e);\n            success = false;\n        }\n    }\n    return success;\n}", "CodeBleu_score": 69.20666969601803}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList)    boolean success = true;\n    if (adminClientList == null) {\n        return true;\n    }\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30));\n        } catch (Exception e) {\n            log.error(\"close adminClient error, clusterPhyId: {}, error: {}\", clusterPhyId, e.getMessage());\n            success = false;\n        }\n    }\n    return success;\n}", "CodeBleu_score": 69.13675913346536}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop()     if (app != null) {\n        app.stop();\n        int attempts = 0;\n        while (app.isRunning() && attempts < 5) {\n            try {\n                Thread.sleep(1000L);\n            } catch (InterruptedException e) {\n                throw new IllegalStateException(e);\n            }\n            attempts++;\n        }\n        app = null;\n    }\n}", "CodeBleu_score": 67.14698459447781}, {"code": "public void stop()   try {\n    if (app != null) {\n      app.stop();\n      int attempts=0;\n      while (app.isRunning() && attempts < 5) {\n        Thread.sleep(1000);\n        attempts++;\n      }\n    }\n  }\n catch (  InterruptedException e) {\n    throw new IllegalStateException(e);\n  }\n finally {\n    app=null;\n  }\n}", "CodeBleu_score": 62.946286808258066}, {"code": "public void stop()   try {\n    if (app != null) {\n      app.stop();\n      int attempts=0;\n      while (app.isRunning() && attempts < 5) {\n        Thread.sleep(1000);\n        attempts++;\n      }\n      if (app.isRunning()) {\n        throw new IllegalStateException(\"Unable to stop\");\n      }\n      app=null;\n    }\n  }\n catch (  InterruptedException e) {\n    throw new IllegalStateException(e);\n  }\n}", "CodeBleu_score": 54.81289958975473}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config)    EurekaServerRunner eurekaServer = new EurekaServerRunner(config)\n    eurekaServer.enableTls()\n    eurekaServer.setKeystore(keystore, keystorePassword)\n    eurekaServer.setTruststore(truststore, truststorePassword)\n    eurekaServer.start()\n    return eurekaServer\n}\n", "CodeBleu_score": 32.572982350598814}, {"code": "static EurekaServerRunner startEurekaServer(Class config)    EurekaServerRunner server = new EurekaServerRunner(config);\n    server.enableTls(true);\n    server.setKeystore(keystore, keystorePassword);\n    server.setTruststore(truststore, truststorePassword);\n    server.start();\n    return server;\n}", "CodeBleu_score": 53.03601629178342}, {"code": "static EurekaServerRunner startEurekaServer(Class config)    EurekaServerRunner eurekaServer = new EurekaServerRunner(config);\n    eurekaServer.enableTls(true);\n    eurekaServer.setKeystore(\"classpath:keystore.jks\", \"password\");\n    eurekaServer.setTruststore(\"classpath:truststore.jks\", \"password\");\n    eurekaServer.start();\n    return eurekaServer;\n}", "CodeBleu_score": 39.90871438628606}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config)    EurekaClientRunner client = new EurekaClientRunner(config, server, \"testservice\")\n    client.enableTls()\n    client.start()\n    return client\n}\n", "CodeBleu_score": 53.55579334614973}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config)    EurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\")\n    runner.enableTls()\n    runner.start()\n    return runner\n}\n", "CodeBleu_score": 54.78367604027687}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config)    EurekaClientRunner client = new EurekaClientRunner(config, server, \"testservice\")\n    client.enableTLS()\n    client.start()\n    return client\n}\n", "CodeBleu_score": 54.9185888154581}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception    // Generate and save CA certificate and key\n    KeyTool.createCertificateAuthority(caCertificateFile, caKeyFile, caAlias, caCommonName, caOrganization, caOrganizationalUnit, caCity, caState, caCountry, caKeyPassword);\n    saveCert(caCertificateFile, caAlias);\n    saveKeyAndCert(caKeyFile, caCertificateFile, caAlias, caKeyPassword);\n\n    // Generate and save server certificate and key\n    KeyTool.createServerCertificate(serverCertificateFile, serverKeyFile, serverAlias, serverCommonName, serverOrganization, serverOrganizationalUnit, serverCity, serverState, serverCountry, serverKeyPassword, caCertificateFile, caKeyFile, caKeyPassword, caAlias);\n    saveCert(serverCertificateFile, serverAlias);\n    saveKeyAndCert(serverKeyFile, serverCertificateFile, serverAlias, serverKeyPassword);\n\n    // Generate and save client certificate and key\n    KeyTool.createClientCertificate(clientCertificateFile, clientKeyFile, clientAlias, clientCommonName, clientOrganization, clientOrganizationalUnit, clientCity, clientState, clientCountry, clientKeyPassword, caCertificateFile, caKeyFile, caKeyPassword, caAlias);\n    saveCert(clientCertificateFile, clientAlias);\n    saveKeyAndCert(clientKeyFile, clientCertificateFile, clientAlias, clientKeyPassword);\n\n    // Generate and save second CA certificate and key\n    KeyTool.createCertificateAuthority(caCertificateFile2, caKeyFile2, caAlias2, caCommonName2, caOrganization2, caOrganizationalUnit2, caCity2, caState2, caCountry2, caKeyPassword2);\n    saveCert(caCertificateFile2, caAlias2);\n    saveKeyAndCert(caKeyFile2, caCertificateFile2, caAlias2, caKeyPassword2);\n\n    // Generate and save second client certificate and key\n    KeyTool.createClientCertificate(clientCertificateFile2, clientKeyFile2, clientAlias2, clientCommonName2, clientOrganization2, clientOrganizationalUnit2, clientCity2, client", "CodeBleu_score": 21.32485387759623}, {"code": "static void createCertificates() throws Exception    KeyTool keyTool = new KeyTool();\n    keyTool.setKeyStoreType(\"PKCS12\");\n    keyTool.setKeyStore(\"ca.p12\");\n    keyTool.setKeyStorePassword(\"password\");\n    keyTool.setCertificateDN(\"CN=ca\");\n    keyTool.setKeyPairAlgorithm(\"RSA\");\n    keyTool.setKeyPairSize(2048);\n    keyTool.setValidity(365);\n    keyTool.setExtendedKeyUsage(\"serverAuth,clientAuth\");\n    keyTool.createSelfSignedCertificate();\n\n    saveCert(keyTool.getCertificate(), \"ca.pem\");\n    saveKeyAndCert(keyTool.getPrivateKey(), keyTool.getCertificate(), \"ca.p12\", \"password\");\n\n    keyTool.setKeyStore(\"server.p12\");\n    keyTool.setKeyStorePassword(\"password\");\n    keyTool.setCertificateDN(\"CN=localhost\");\n    keyTool.setExtendedKeyUsage(\"serverAuth\");\n    keyTool.createSignedCertificate(\"ca.p12\", \"password\");\n\n    saveCert(keyTool.getCertificate(), \"server.pem\");\n    saveKeyAndCert(keyTool.getPrivateKey(), keyTool.getCertificate(), \"server.p12\", \"password\");\n\n    keyTool.setKeyStore(\"client.p12\");\n    keyTool.setKeyStorePassword(\"password\");\n    keyTool.setCertificateDN(\"CN=client\");\n    keyTool.setExtendedKeyUsage(\"clientAuth\");\n    keyTool.createSignedCertificate(\"ca.p12\", \"password\");\n\n    saveCert(keyTool.getCertificate(), \"client.pem\");\n    saveKeyAndCert(keyTool.getPrivateKey(), keyTool.getCertificate(), \"client.p12\", \"password\");\n\n    keyTool.setKeyStore(\"ca2.p12\");\n    keyTool.setKeyStorePassword(\"password\");\n    keyTool.setCertificateDN(\"CN=ca2\");\n    keyTool.setExtendedKeyUsage(\"serverAuth,clientAuth\");\n    keyTool.createSelfS", "CodeBleu_score": 21.474686502298066}, {"code": "static void createCertificates() throws Exception    KeyTool keyTool = new KeyTool();\n\n    // Generate CA certificate and key\n    Certificate caCert = keyTool.createSelfSignedCertificate(\"CN=CA\", 3650, \"SHA256withRSA\");\n    saveCert(\"ca.crt\", caCert);\n    saveKeyAndCert(\"ca.key\", caCert);\n\n    // Generate server certificate and key\n    Certificate serverCert = keyTool.createCertificate(\"CN=Server\", caCert, 3650, \"SHA256withRSA\");\n    saveCert(\"server.crt\", serverCert);\n    saveKeyAndCert(\"server.key\", serverCert);\n\n    // Generate client certificate and key\n    Certificate clientCert = keyTool.createCertificate(\"CN=Client\", caCert, 3650, \"SHA256withRSA\");\n    saveCert(\"client.crt\", clientCert);\n    saveKeyAndCert(\"client.key\", clientCert);\n\n    // Generate second CA certificate and key\n    Certificate caCert2 = keyTool.createSelfSignedCertificate(\"CN=CA2\", 3650, \"SHA256withRSA\");\n    saveCert(\"ca2.crt\", caCert2);\n    saveKeyAndCert(\"ca2.key\", caCert2);\n\n    // Generate client certificate and key signed by second CA\n    Certificate clientCert2 = keyTool.createCertificate(\"CN=Client2\", caCert2, 3650, \"SHA256withRSA\");\n    saveCert(\"client2.crt\", clientCert2);\n    saveKeyAndCert(\"client2.key\", clientCert2);\n}\n", "CodeBleu_score": 25.809140230986245}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds)    long startTime = System.currentTimeMillis();\n    long timeLimit = seconds * 1000L;\n    while (!assertion.getAsBoolean()) {\n        long elapsedTime = System.currentTimeMillis() - startTime;\n        if (elapsedTime >= timeLimit) {\n            throw new RuntimeException(\"Assertion not met within \" + seconds + \" seconds\");\n        }\n    }\n}", "CodeBleu_score": 42.16828774799033}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds)    long startTime = System.currentTimeMillis();\n    long timeLimit = seconds * 1000L;\n    while (!assertion.getAsBoolean() && (System.currentTimeMillis() - startTime) < timeLimit) {\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n    }\n    if (!assertion.getAsBoolean()) {\n        throw new RuntimeException(\"Assertion failed after \" + seconds + \" seconds\");\n    }\n}\n", "CodeBleu_score": 37.22299718833228}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds)    long startTime = System.currentTimeMillis();\n    long timeLimit = seconds * 1000;\n\n    while (!assertion.getAsBoolean()) {\n        if (System.currentTimeMillis() - startTime >= timeLimit) {\n            throw new RuntimeException(\"Assertion not met within \" + seconds + \" seconds\");\n        }\n    }\n}", "CodeBleu_score": 38.55435223900373}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception    X509v3CertificateBuilder certBuilder = new JcaX509v3CertificateBuilder(\n            new X500Name(\"CN=\" + keyPair.getPublic().getEncoded()),\n            new Date(),\n            new Date(new Date().getTime() + 365 * 24 * 60 * 60 * 1000),\n            new X500Name(ca),\n            keyPair.getPublic());\n\n    certBuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment));\n    certBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\n    ContentSigner contentSigner = new JcaContentSignerBuilder(\"SHA256WithRSA\").build(keyPair.getPrivate());\n    X509CertificateHolder certHolder = certBuilder.build(contentSigner);\n    return new JcaX509CertificateConverter().getCertificate(certHolder);\n}\n", "CodeBleu_score": 35.23451931646}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception    X509v3CertificateBuilder certBuilder = new X509v3CertificateBuilder(\n            new X500Name(\"CN=\" + keyPair.getPublic().getEncoded()),\n            BigInteger.valueOf(System.currentTimeMillis()),\n            new Date(System.currentTimeMillis() + 365 * 24 * 60 * 60 * 1000),\n            new X500Name(ca),\n            keyPair.getPublic());\n\n    certBuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment));\n    certBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\n    ContentSigner contentSigner = new JcaContentSignerBuilder(\"SHA256WithRSA\").build(keyPair.getPrivate());\n    X509CertificateHolder certHolder = certBuilder.build(contentSigner);\n\n    return new JcaX509CertificateConverter().getCertificate(certHolder);\n}\n", "CodeBleu_score": 35.894938718450106}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception    // Load the CA certificate\n    CertificateFactory cf = CertificateFactory.getInstance(\"X.509\");\n    X509Certificate caCert = (X509Certificate) cf.generateCertificate(new ByteArrayInputStream(ca.getBytes()));\n\n    // Create a certificate builder with the public key\n    X509v3CertificateBuilder certBuilder = new JcaX509v3CertificateBuilder(\n            new X500Name(\"CN=Test Certificate\"),\n            new BigInteger(64, new SecureRandom()),\n            new Date(),\n            new Date(System.currentTimeMillis() + 365L * 24 * 60 * 60 * 1000),\n            new X500Name(\"CN=Test CA\"),\n            keyPair.getPublic());\n\n    // Add key usage and basic constraints extensions\n    certBuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment));\n    certBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\n    // Sign the certificate with the private key\n    ContentSigner signer = new JcaContentSignerBuilder(\"SHA256withRSA\").build(keyPair.getPrivate());\n    X509CertificateHolder certHolder = certBuilder.build(signer);\n\n    return new JcaX509CertificateConverter().getCertificate(certHolder);\n}\n", "CodeBleu_score": 34.23667929881019}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient()    if (eurekaHttpClient == null) {\n        try {\n            Field registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n            registrationClientField.setAccessible(true);\n            eurekaHttpClient = (EurekaHttpClient) registrationClientField.get(eurekaTransport);\n        } catch (IllegalAccessException | NoSuchFieldException e) {\n            logger.error(\"Failed to get EurekaHttpClient from EurekaTransport\", e);\n        }\n    }\n    return eurekaHttpClient;\n}\n", "CodeBleu_score": 47.75060366686337}, {"code": "EurekaHttpClient getEurekaHttpClient()    if (eurekaHttpClient == null) {\n        try {\n            Field registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n            registrationClientField.setAccessible(true);\n            eurekaHttpClient = (EurekaHttpClient) registrationClientField.get(eurekaTransport);\n        } catch (IllegalAccessException | NoSuchFieldException e) {\n            log.error(\"Failed to get EurekaHttpClient instance\", e);\n        }\n    }\n    return eurekaHttpClient;\n}\n", "CodeBleu_score": 47.176828991892485}, {"code": "EurekaHttpClient getEurekaHttpClient()    if (eurekaHttpClient == null) {\n        try {\n            Field registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n            registrationClientField.setAccessible(true);\n            eurekaHttpClient = (EurekaHttpClient) registrationClientField.get(eurekaTransport);\n        } catch (NoSuchFieldException | IllegalAccessException e) {\n            logger.error(\"Error accessing registrationClient field from eurekaTransport\", e);\n        }\n    }\n    return eurekaHttpClient;\n}\n", "CodeBleu_score": 47.173805440723314}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices()        List<String> services = new ArrayList<>();\n        Applications applications = eurekaClient.getApplications();\n        if (applications == null) {\n            return services;\n        }\n        for (Application app : applications.getRegisteredApplications()) {\n            if (app.getInstances().size() > 0) {\n                services.add(app.getName().toLowerCase());\n            }\n        }\n        return services;\n    }\n", "CodeBleu_score": 53.50146743691499}, {"code": "public List<String> getServices()    List<String> services = new ArrayList<>();\n    Applications applications = eurekaClient.getApplications();\n    if (applications == null) {\n        return services;\n    }\n    for (Application application : applications.getRegisteredApplications()) {\n        if (application.getInstances().size() > 0) {\n            services.add(application.getName().toLowerCase());\n        }\n    }\n    return services;\n}", "CodeBleu_score": 53.708221510067666}, {"code": "public List<String> getServices()    List<String> services = new ArrayList<>();\n    Applications applications = eurekaClient.getApplications();\n    if (applications == null) {\n        return services;\n    }\n    for (Application application : applications.getRegisteredApplications()) {\n        for (InstanceInfo instanceInfo : application.getInstances()) {\n            services.add(instanceInfo.getAppName().toLowerCase());\n        }\n    }\n    return services;\n}\n", "CodeBleu_score": 52.10807730109626}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors)    healthContributors.forEach((key, value) -> {\n        if (value instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor discoveryCompositeHealthContributor = (DiscoveryCompositeHealthContributor) value;\n            discoveryCompositeHealthContributor.getContributors().forEach((indicatorKey, indicatorValue) -> {\n                if (!(indicatorValue instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(indicatorKey, indicatorValue);\n                }\n            });\n        } else {\n            healthContributors.put(key, value);\n        }\n    });\n}", "CodeBleu_score": 36.09685845805488}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors)    healthContributors.forEach((name, contributor) -> {\n        if (contributor instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor discoveryCompositeHealthContributor = (DiscoveryCompositeHealthContributor) contributor;\n            discoveryCompositeHealthContributor.getContributors().forEach((key, value) -> {\n                if (!(value instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(key, value);\n                }\n            });\n        } else {\n            healthContributors.put(name, contributor);\n        }\n    });\n}", "CodeBleu_score": 36.72374568569717}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors)  for (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n    HealthContributor contributor = entry.getValue();\n    if (contributor instanceof DiscoveryCompositeHealthContributor) {\n      for (HealthIndicator indicator : ((DiscoveryCompositeHealthContributor) contributor).getContributors()) {\n        if (!(indicator instanceof EurekaHealthIndicator)) {\n          healthContributors.put(entry.getKey() + \".\" + indicator.getId(), indicator);\n        }\n      }\n    }\n    else {\n      healthContributors.put(entry.getKey(), contributor);\n    }\n  }\n}", "CodeBleu_score": 40.20009964737571}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello()    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No service instance for provider-application\");\n    }\n\n    String url = instances.get(0).getUri().toString();\n    RestTemplate restTemplate = new RestTemplate();\n    String response = restTemplate.postForObject(url + \"/echo\", \"Hello\", String.class);\n    return response;\n}\n", "CodeBleu_score": 60.19000705491364}, {"code": "public String hello()    List<ServiceInstance> list = discoveryClient.getInstances(\"provider-application\");\n    if (list != null && list.size() > 0) {\n        URI uri = list.get(0).getUri();\n        if (uri != null) {\n            return (new RestTemplate()).postForObject(uri + \"/echo\", \"hello\", String.class);\n        }\n    }\n    throw new RuntimeException(\"No instance available\");\n}\n", "CodeBleu_score": 44.40280342453569}, {"code": "public String hello()    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No instances of provider-application found\");\n    }\n\n    ServiceInstance instance = instances.get(0);\n    String url = instance.getUri().toString() + \"/echo\";\n    String response = restTemplate.postForObject(url, \"Hello\", String.class);\n    return response;\n}", "CodeBleu_score": 60.83686856106927}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world()    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances == null || instances.isEmpty()) {\n        throw new RuntimeException(\"No instance available\");\n    }\n    ServiceInstance serviceInstance = loadBalancerClient.choose(\"provider-application\");\n    URI uri = serviceInstance.getUri();\n    String url = uri + \"/echo?name=\" + \"world\";\n    RestTemplate restTemplate = new RestTemplate();\n    ResponseEntity<String> response = restTemplate.postForEntity(url, null, String.class);\n    return response.getBody();\n}", "CodeBleu_score": 55.111976788701455}, {"code": "public String world()    ServiceInstance instance = loadBalancer.choose(\"provider-application\");\n    if (instance == null) {\n        throw new RuntimeException(\"No instance available\");\n    }\n\n    String url = \"http://\" + instance.getHost() + \":\" + instance.getPort() + \"/echo?message=world\";\n    return restTemplate.getForObject(url, String.class);\n}", "CodeBleu_score": 44.77092667509537}, {"code": "public String world()    ServiceInstance instance = loadBalancer.choose(\"provider-application\");\n    if (instance == null) {\n        throw new RuntimeException(\"Failed to find service instance\");\n    }\n    URI uri = instance.getUri();\n    String url = uri.toString() + \"/echo\";\n    RestTemplate restTemplate = new RestTemplate();\n    ResponseEntity<String> response = restTemplate.postForEntity(url, \"Hello\", String.class);\n    return response.getBody();\n}\n", "CodeBleu_score": 56.05235782521586}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port)    logger.info(\"Registering service: {} with IP: {} and port: {}\", serviceName, ip, port);\n    if (!serverMap.containsKey(serviceName)) {\n        serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n    }\n    serverMap.get(serviceName).add(new Server(ip, port));\n    return true;\n}", "CodeBleu_score": 64.02998318141654}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port)    if (!serverMap.containsKey(serviceName)) {\n        serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n    }\n    serverMap.get(serviceName).add(new Server(ip, port));\n    logger.info(\"Registered service: {} with IP: {} and port: {}\", serviceName, ip, port);\n    return true;\n}\n", "CodeBleu_score": 64.13570660918954}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port)    logger.info(\"Registering service: {} with IP: {} and port: {}\", serviceName, ip, port);\n    if (!serverMap.containsKey(serviceName)) {\n        serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n    }\n    serverMap.get(serviceName).add(new Server(ip, port));\n    return true;\n}\n", "CodeBleu_score": 64.02998318141654}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port)    log.info(\"deregister service: \" + serviceName + \", ip: \" + ip + \", port: \" + port);\n    Set<Server> servers = serverMap.get(serviceName);\n    if (servers == null) {\n        log.error(\"deregister service: \" + serviceName + \" failed, service not found\");\n        return false;\n    }\n    boolean removed = servers.remove(new Server(ip, port));\n    if (!removed) {\n        log.error(\"deregister service: \" + serviceName + \" failed, server not found\");\n    }\n    return removed;\n}\n", "CodeBleu_score": 46.691371714196805}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port)    log.info(\"deregister service: \" + serviceName + \" ip: \" + ip + \" port: \" + port);\n    Set<Server> servers = serverMap.get(serviceName);\n    if (servers == null) {\n        return false;\n    }\n    return servers.remove(new Server(ip, port));\n}\n", "CodeBleu_score": 44.45297308395888}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port)    log.info(\"deregister service: {} {} {}\", serviceName, ip, port);\n    Set<Server> servers = serverMap.get(serviceName);\n    if (servers == null || servers.isEmpty()) {\n        return false;\n    }\n    Server server = new Server(ip, port);\n    servers.remove(server);\n    return true;\n}\n", "CodeBleu_score": 66.94212027660585}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry)    Map<String, Object> attrs = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attrs == null) {\n        return;\n    }\n    Map<String, Object> defaultAttrs = (Map<String, Object>) attrs.get(\"defaultConfiguration\");\n    if (defaultAttrs != null) {\n        String name = (String) defaultAttrs.get(\"name\");\n        registerClientConfiguration(name, defaultAttrs, registry);\n    }\n}", "CodeBleu_score": 54.81254675545777}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry)    Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attributes != null) {\n        Map<String, Object> clientsAttributes = (Map<String, Object>) attributes.get(\"value\");\n        if (clientsAttributes != null) {\n            clientsAttributes.keySet().forEach(name -> registerClientConfiguration(name, clientsAttributes.get(name), registry));\n        }\n        if (attributes.containsKey(\"defaultConfiguration\")) {\n            registerClientConfiguration(DEFAULT_NAMED_CONFIG, attributes.get(\"defaultConfiguration\"), registry);\n        }\n    }\n}\n", "CodeBleu_score": 47.13468405504454}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry)    Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attributes != null) {\n        Map<String, Object> clientAttributes = (Map<String, Object>) attributes.get(\"value\");\n        if (clientAttributes != null) {\n            clientAttributes.forEach((name, configuration) -> registerClientConfiguration(name, (String) configuration, registry));\n        }\n        String defaultConfiguration = (String) attributes.get(\"defaultConfiguration\");\n        if (defaultConfiguration != null) {\n            registerClientConfiguration(RibbonClient.class.getName(), defaultConfiguration, registry);\n        }\n    }\n}\n", "CodeBleu_score": 44.458415176673164}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request)     ServiceInstance instance = super.choose(serviceId, request);\n    if (instance != null) {\n        return new TutuServiceInstance(instance);\n    }\n    return null;\n}\n", "CodeBleu_score": 35.70178994079603}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request)     ServiceInstanceListSupplier supplier = getInstanceListSupplier(serviceId);\n    if (supplier == null) {\n        return null;\n    }\n    ServiceInstance instance = supplier.get(request);\n    if (instance == null) {\n        return null;\n    }\n    return new TutuServiceInstance(instance);\n}\n", "CodeBleu_score": 34.815369976920856}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request)     ServiceInstance instance = super.choose(serviceId, request);\n    if (instance != null) {\n        return new TutuServiceInstance(instance);\n    }\n    return null;\n}\n", "CodeBleu_score": 35.70178994079603}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original)     try {\n        return new URI(\n                original.getScheme(),\n                original.getUserInfo(),\n                server.getHost(),\n                server.getPort(),\n                original.getPath(),\n                original.getQuery(),\n                original.getFragment());\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 31.158188502040296}, {"code": "public URI reconstructURI(ServiceInstance server, URI original)     try {\n        String newURI = \"http://\" + server.getHost() + \":\" + server.getPort() + original.getPath();\n        if (original.getQuery() != null) {\n            newURI += \"?\" + original.getQuery();\n        }\n        return new URI(newURI);\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}\n", "CodeBleu_score": 38.655157078941116}, {"code": "public URI reconstructURI(ServiceInstance server, URI original)     try {\n        return new URI(server.getScheme(), server.getUserInfo(), server.getHost(), server.getPort(),\n                original.getPath(), original.getQuery(), original.getFragment());\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(\"Error reconstructing URI\", e);\n    }\n}\n", "CodeBleu_score": 24.02277759041115}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer()    List<TutuServer> servers = new ArrayList<>();\n    String serverAddress = \"http://127.0.0.1:8848\";\n    String serviceName = \"tutu-server\";\n\n    String url = serverAddress + \"/list?serviceName=\" + serviceName;\n    try {\n        HttpResponse<String> response = HttpClient.newHttpClient().send(HttpRequest.newBuilder().uri(URI.create(url)).build(), HttpResponse.BodyHandlers.ofString());\n        String json = response.body();\n        JSONArray jsonArray = JSON.parseArray(json);\n        for (Object obj : jsonArray) {\n            JSONObject jsonObject = (JSONObject) obj;\n            String ip = jsonObject.getString(\"ip\");\n            int port = jsonObject.getInteger(\"port\");\n            servers.add(new TutuServer(ip, port));\n        }\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n    return servers;\n}", "CodeBleu_score": 38.84703340059287}, {"code": "private List<TutuServer> getServer()    String serviceName = \"tutu-server\";\n    String serverAddress = \"http://localhost:8080\";\n    String url = serverAddress + \"/list?serviceName=\" + serviceName;\n    RestTemplate restTemplate = new RestTemplate();\n    ResponseEntity<String> response = restTemplate.getForEntity(url, String.class);\n    String responseBody = response.getBody();\n    List<TutuServer> tutuServerList = new ArrayList<>();\n    try {\n        JSONArray jsonArray = new JSONArray(responseBody);\n        for (int i = 0; i < jsonArray.length(); i++) {\n            JSONObject jsonObject = jsonArray.getJSONObject(i);\n            String ip = jsonObject.getString(\"ip\");\n            int port = jsonObject.getInt(\"port\");\n            TutuServer tutuServer = new TutuServer(ip, port);\n            tutuServerList.add(tutuServer);\n        }\n    } catch (JSONException e) {\n        e.printStackTrace();\n    }\n    return tutuServerList;\n}\n", "CodeBleu_score": 33.92000797040452}, {"code": "private List<TutuServer> getServer()    String serviceName = \"tutu-server\";\n    String serverAddress = \"http://localhost:8500\";\n    String url = serverAddress + \"/v1/catalog/service/\" + serviceName;\n    RestTemplate restTemplate = new RestTemplate();\n    ResponseEntity<String> response = restTemplate.getForEntity(url, String.class);\n    List<TutuServer> serverList = new ArrayList<>();\n    if (response.getStatusCode() == HttpStatus.OK) {\n        try {\n            JSONArray jsonArray = new JSONArray(response.getBody());\n            for (int i = 0; i < jsonArray.length(); i++) {\n                JSONObject jsonObject = jsonArray.getJSONObject(i);\n                String ip = jsonObject.getString(\"Address\");\n                int port = jsonObject.getInt(\"ServicePort\");\n                TutuServer server = new TutuServer(ip, port);\n                serverList.add(server);\n            }\n        } catch (JSONException e) {\n            e.printStackTrace();\n        }\n    }\n    return serverList;\n}", "CodeBleu_score": 34.275596379679016}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path)    for (ZuulRoute route : routes.values()) {\n        if (pathMatcher.match(route.getPath(), path)) {\n            String targetPath = path.replaceFirst(route.getPath(), \"\");\n            return new Route(targetPath, route.getLocation());\n        }\n    }\n    return null;\n}", "CodeBleu_score": 33.84230329206739}, {"code": "public Route getMatchingRoute(String path)    for (ZuulRoute route : routes.values()) {\n        if (pathMatcher.match(route.getPath(), path)) {\n            String targetPath = path.substring(route.getPath().length());\n            return new Route(targetPath, route.getServiceId());\n        }\n    }\n    return null;\n}\n", "CodeBleu_score": 33.83311414529199}, {"code": "public Route getMatchingRoute(String path)    for (ZuulRoute route : this.routes.values()) {\n        if (pathMatcher.match(route.getPath(), path)) {\n            String targetPath = path.replaceFirst(route.getPath(), \"\");\n            if (targetPath.length() > 0 && !targetPath.startsWith(\"/\")) {\n                targetPath = \"/\" + targetPath;\n            }\n            return new Route(targetPath, route.getLocation());\n        }\n    }\n    return null;\n}\n", "CodeBleu_score": 40.79363332779187}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry)    ClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(false);\n    scanner.addIncludeFilter(new AnnotationTypeFilter(FeignClient.class));\n    Set<BeanDefinition> definitions = scanner.findCandidateComponents(importingClassMetadata.getClassName()).stream()\n            .map(this::getBeanDefinition).collect(Collectors.toSet());\n    for (BeanDefinition definition : definitions) {\n        registry.registerBeanDefinition(definition.getBeanClassName(), definition);\n    }\n}\n", "CodeBleu_score": 26.20089498811586}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry)    ClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(false, environment);\n    scanner.addIncludeFilter(new AnnotationTypeFilter(FeignClient.class));\n    Set<BeanDefinition> definitions = scanner.findCandidateComponents(importingClassMetadata.getClassName()).stream()\n            .map(beanDefinition -> {\n                try {\n                    GenericBeanDefinition definition = new GenericBeanDefinition();\n                    definition.setBeanClass(Class.forName(beanDefinition.getBeanClassName()));\n                    definition.getConstructorArgumentValues().addGenericArgumentValue(definition.getBeanClassName());\n                    definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);\n                    definition.getPropertyValues().add(\"contextId\", definition.getBeanClassName());\n                    definition.getPropertyValues().add(\"type\", definition.getBeanClassName());\n                    return definition;\n                }\n                catch (Throwable ex) {\n                    throw new IllegalStateException(\n                            \"Cannot construct feign client bean definition for \" + beanDefinition, ex);\n                }\n            })\n            .collect(Collectors.toSet());\n    for (BeanDefinition definition : definitions) {\n        registry.registerBeanDefinition(definition.getBeanClassName(), definition);\n    }\n}\n", "CodeBleu_score": 37.2617266061172}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry)    ClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(false);\n    scanner.addIncludeFilter(new AnnotationTypeFilter(FeignClient.class));\n    Set<BeanDefinition> beanDefinitions = scanner.findCandidateComponents(importingClassMetadata.getClassName());\n    for (BeanDefinition beanDefinition : beanDefinitions) {\n        if (logger.isDebugEnabled()) {\n            logger.debug(\"Processing bean creation for FeignClient: \" + beanDefinition.getBeanClassName());\n        }\n        String beanClassName = beanDefinition.getBeanClassName();\n        BeanDefinitionBuilder definition = BeanDefinitionBuilder.genericBeanDefinition(FeignClientFactoryBean.class);\n        definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);\n        definition.addConstructorArgValue(beanClassName);\n        definition.setAttribute(AUTOWIRE_CANDIDATE, true);\n        definition.setAttribute(SCOPE_CANDIDATE, true);\n        definition.setAttribute(PRIMARY_CANDIDATE, true);\n        definition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n        definition.getRawBeanDefinition().setSource(importingClassMetadata);\n        if (StringUtils.hasText(beanClassName)) {\n            if (beanNameGenerator != null) {\n                definition.setBeanName(this.beanNameGenerator.generateBeanName(definition.getBeanDefinition(), registry));\n            }\n            registry.registerBeanDefinition(beanClassName, definition.getBeanDefinition());\n        }\n    }\n}", "CodeBleu_score": 34.6993844621564}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties)    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}\n", "CodeBleu_score": 57.81323246872828}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties)    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}\n", "CodeBleu_score": 57.81323246872828}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties)    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}\n", "CodeBleu_score": 57.81323246872828}]}
